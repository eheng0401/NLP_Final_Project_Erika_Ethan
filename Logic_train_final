text	label
Let $B = \left({S, \vee, \wedge, \neg, \preceq}\right)$ be a [[Definition:Boolean Lattice|Boolean lattice]]. Let $F$ be a [[Definition:Filter|filter]] in $B$. Then :$F$ is a [[Definition:Proper Subset|proper subset]] of $S$ and $F$ is a [[Definition:Prime Filter (Order Theory)|prime filter]] in $B$ {{iff}}: :$F$ is [[Definition:Ultrafilter (Order Theory)|ultrafilter]] on $B$	1
: $\vdash \neg \left ({p \iff q}\right) \iff \left({p \iff \neg q}\right)$	1
[[Definition:Exclusive Or|Exclusive or]] destroys copies of itself: : $p \oplus p \dashv \vdash \bot$	1
:$p \lor q \dashv \vdash \neg \paren {\neg p \land \neg q}$	1
In a [[Definition:Valid Argument|valid argument]], the [[Definition:Premise|premises]] '''logically imply''' the [[Definition:Conclusion|conclusion]]. If the truth of one [[Definition:Statement|statement]] $p$ can be shown in an argument directly to cause the meaning of another statement $q$ to be true, then $q$ follows from $p$ by '''logical implication'''. We may say: :'''$p$, [[Definition:Therefore|therefore]] $q$''' and write $p \vdash q$. :'''$q$, [[Definition:Because|because]] $p$''' and write $q \dashv p$. In [[Definition:Symbolic Logic|symbolic logic]], the concept of '''logical consequence''' occurs in the form of [[Definition:Semantic Consequence|semantic consequence]] and [[Definition:Provable Consequence|provable consequence]]. In the context of [[Definition:Proof|proofs]] of a conventional mathematical nature on {{ProofWiki}}, the notation: :$p \leadsto q$ is preferred, where $\leadsto$ can be read as '''leads to'''. === [[Definition:Semantic Consequence|Semantic Consequence]] === {{:Definition:Semantic Consequence}} === [[Definition:Provable Consequence|Provable Consequence]] === {{:Definition:Provable Consequence}}	1
There exists a [[Definition:Two-Person Zero-Sum Game|two-person zero-sum game]] with more than one [[Definition:Solution of Game|solution]].	1
The '''universe of discourse''', or just '''universe''', is the term used to mean '''everything we are talking about'''. When introducing the symbols $\forall$ (the [[Definition:Universal Quantifier|universal quantifier]]) or $\exists$ (the [[Definition:Existential Quantifier|existential quantifier]]), it is understood that the [[Definition:Object|objects]] referred to are those in the specified '''universe'''. It is usual to define that '''universe'''.	1
The rule of '''double negation elimination''' is a [[Definition:Valid Argument|valid]] deduction [[Definition:Sequent|sequent]] in [[Definition:Propositional Logic|propositional logic]]. === [[Double Negation/Double Negation Elimination/Proof Rule|Proof Rule]] === {{:Double Negation/Double Negation Elimination/Proof Rule}} === [[Double Negation/Double Negation Elimination/Sequent Form|Sequent Form]] === {{:Double Negation/Double Negation Elimination/Sequent Form}}	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, in each case, the [[Definition:Truth Value|truth values]] in the appropriate columns match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c|ccc||c|ccc|} \hline p & p & \iff & \top & p \\ \hline F & F & F & T & F \\ T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
:$(1): \quad p \vdash p \lor q$ :$(2): \quad q \vdash p \lor q$	1
:$\vdash \left({p \lor \left({q \lor r}\right)}\right) \impliedby \left({\left({p \lor q}\right) \lor r}\right)$	1
Let $Q$ be a [[Definition:Valid Argument|valid]] [[Definition:Categorical Syllogism|categorical syllogism]] in [[Definition:Second Figure of Categorical Syllogism|Figure $\text{II}$]]. Then it is a [[Definition:Necessary Condition|necessary condition]] that: :The [[Definition:Major Premise of Syllogism|major premise]] of $Q$ be a [[Definition:Universal Categorical Statement|universal categorical statement]] and :The [[Definition:Conclusion of Syllogism|conclusion]] of $Q$ be a [[Definition:Negative Categorical Statement|negative categorical statement]].	1
: $p \implies q, q \implies r, p \vdash r$	1
The [[Definition:Probability|probability]] of being dealt a complete [[Definition:Suit of Cards|suit]] in a deal at [[Definition:Bridge (Game)|Bridge]] is $1$ in $158 \, 753 \, 389 \, 900$.	1
==== [[Modus Ponendo Tollens/Sequent Form/Case 1|Case 1]] ==== {{:Modus Ponendo Tollens/Sequent Form/Case 1}} ==== [[Modus Ponendo Tollens/Sequent Form/Case 2|Case 2]] ==== {{:Modus Ponendo Tollens/Sequent Form/Case 2}}	1
{{BeginTableau|q \vdash \left({p \implies q}\right) \land \left({\neg p \implies q}\right)}} {{Premise|1|q}} {{SequentIntro|2|1|p \implies q|1|[[True Statement is implied by Every Statement]]}} {{SequentIntro|3|1|\neg p \implies q|1|[[True Statement is implied by Every Statement]]}} {{Conjunction|4|1|\left({p \implies q}\right) \land \left({\neg p \implies q}\right)|2|3}} {{EndTableau}} {{qed}} [[Category:Principle of Dilemma]] 9yblx1tnx4w60wc2mrbf3rgkgc15rnc	1
:$\vdash \paren {\paren {q \land r} \lor p} \iff \paren {\paren {q \lor p} \land \paren {r \lor p} }$	1
'''Aristotelian logic''' is a system of [[Definition:Logic|logic]] which is based upon the philosophy of {{AuthorRef|Aristotle}}. It forms the cornerstone of the entirety of [[Definition:Classical Logic|classical logic]]. The school of '''Aristotelian logic''' consists almost entirely of the relationships between the various [[Definition:Categorical Syllogism|categorical syllogisms]]. This school of philosophy forms the basis of mainstream [[Definition:Mathematics|mathematics]], although, for example, mathematicians of the [[Definition:Intuitionistic Propositional Logic|intuitionistic]] school do not accept the [[Law of Excluded Middle|Law of the Excluded middle value]].	1
{{BeginTableau|p \land \neg q \vdash \left({p \lor q}\right) \land \neg q}} {{Premise|1|p \land \neg q}} {{Simplification|2|1|p|1|1}} {{Addition|3|1|p \lor q|2|1}} {{Simplification|4|1|\neg q|1|2}} {{Conjunction|5|1|\left({p \lor q}\right) \land \neg q|3|4}} {{EndTableau}} {{qed}} ... and its converse: {{BeginTableau|\left({p \lor q}\right) \land \neg q \vdash p \land \neg q}} {{Premise|1|\left({p \lor q}\right) \land \neg q}} {{SequentIntro|2|1|\left({p \land \neg q}\right) \lor \left({q \land \neg q}\right)|1 |[[Conjunction Distributes over Disjunction]] }} {{Assumption|3|q \land \neg q}} {{NonContradiction|4|3|3|3}} {{Contradiction|5||\neg \left ({q \land \neg q}\right)|3|4}} {{SequentIntro|6|1|p \land \neg q|2, 5|[[Disjunctive Syllogism]]}} {{EndTableau}} {{qed}} [[Category:Conjunction]] [[Category:Disjunction]] [[Category:Negation]] tfhj416ip3giibivxe26q54ehzsfkq3	1
:$\vdash \neg p \implies \paren {p \implies q}$	1
Let $\epsilon \in \R_{> 0}$. Since $a_n = \map \OO {b_n}$: :$\exists c \in \R: c \ge 0: \exists n_0 \in \N: \paren {n \ge n_0 \implies \size {a_n} \le c \cdot \size {b_n} }$ Since $c_n = \map o {d_n}$: :$\exists n_1 \in \N: \paren {n \ge n_1 \implies \size {c_n} \le \dfrac \epsilon {c + 1} \cdot \size {d_n} }$ Thus for $n \ge \max \set {n_0, n_1}$: {{begin-eqn}} {{eqn | o = | r = \size {a_n c_n} }} {{eqn | r = \size {a_n} \size {c_n} }} {{eqn | o = \le | r = \paren {c \cdot \size {b_n} } \paren {\frac \epsilon {c + 1} \cdot \size {d_n} } }} {{eqn | o = \le | r = \size {b_n} \paren {\epsilon \cdot \size {d_n} } }} {{eqn | r = \epsilon \cdot \size {b_n d_n} }} {{end-eqn}} Thus $a_n c_n = \map o {b_n d_n}$. {{qed}} [[Category:Asymptotic Notation]] azifd1smnfq9aprpnmw1nhgif54bazq	1
:$p \implies q \vdash \neg \left({p \land \neg q}\right)$	1
Proof by [[Principle of Mathematical Induction|induction]]. Consider the [[Definition:Natural Numbers|natural numbers]] $\N$ defined as the elements of the [[Definition:Minimal Infinite Successor Set|minimal infinite successor set]] $\omega$. From the definition of [[Definition:Addition in Minimal Infinite Successor Set|addition in $\omega$]], we have that: {{begin-eqn}} {{eqn | ll= \forall m, n \in \N: | l = m + 0 | r = m }} {{eqn | l = m + n^+ | r = \paren {m + n}^+ }} {{end-eqn}} For all $n \in \N$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\forall m \in \N: m + n = n + m$ === Basis for the Induction === From [[Natural Number Addition Commutes with Zero]], we have: :$\forall m \in \N: m + 0 = m = 0 + m$ Thus $\map P 0$ is seen to be true. This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 0$, then it logically follows that $\map P {k^+}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]] $\map P k$: :$\forall m \in \N: m + k = k + m$ Then we need to show that $\map P {k^+}$ follows directly from $\map P k$: :$\forall m \in \N: m + k^+ = k^+ + m$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = k^+ + m | r = \paren {k + m}^+ | c = [[Natural Number Addition Commutativity with Successor]] }} {{eqn | r = \paren {m + k}^+ | c = from the [[Natural Number Addition is Commutative/Proof 2#Induction Hypothesis|induction hypothesis]] }} {{eqn | r = m + k^+ | c = by definition }} {{end-eqn}} So $\map P k \implies \map P {k^+}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\forall m, n \in \N: m + n = n + m$ {{qed}}	1
We refer to the [[Definition:Bottom-Up Specification of Propositional Logic|rules of formation]]. From $\mathbf W: TF$, $\top$ and $\bot$ (both of [[Definition:Length of String|length]] 1) are WFFs. From $\mathbf W: \mathcal P_0$, all elements of $\mathcal P_0$ (all of [[Definition:Length of String|length]] 1) are WFFs. Every other rule of formation of the [[Definition:Formal Grammar of Propositional Logic|formal grammar of propositional logic]] consists of an existing WFF in addition to at least one other primitive symbol. Hence the result. {{qed}}	1
{{begin-eqn}} {{eqn | l = p \lor q | o = \dashv \vdash | r = \neg \paren {\neg p \land \neg q} | c = [[De Morgan's Laws (Logic)/Disjunction|De Morgan's Laws (Logic): Disjunction]] }} {{eqn | o = \dashv \vdash | r = \neg p \uparrow \neg q | c = {{Defof|Logical NAND}} }} {{eqn | o = \dashv \vdash | r = \paren {p \uparrow p} \uparrow \paren {q \uparrow q} | c = [[NAND with Equal Arguments]] }} {{end-eqn}} {{qed}}	1
Let $\phi$ be a $\mathcal B$-[[Definition:Well-Formed Formula|WFF]]. If $\phi$ is a [[Definition:Letter|letter]], then it is clearly a $\mathcal T$-[[Definition:Well-Formed Formula|WFF]]. For, it may be formed by replacing the starting [[Definition:Metasymbol|metasymbol]] of $\mathcal T$ by $\phi$. Suppose that $\phi$ is formed from [[Definition:Well-Formed Formula|WFFs]] $\phi_1, \ldots, \phi_n$ by the [[Definition:Rule of Formation|rule of formation]] $\mathbf R_{\mathcal B}$ of $\mathcal B$. Suppose also that each of $\phi_1, \ldots, \phi_n$ is also a $\mathcal T$-[[Definition:Well-Formed Formula|WFF]]. Then by applying the [[Definition:Rule of Formation|rule of formation]] $\mathbf R$ of $\mathcal T$, we obtain a [[Definition:Collation|collation]] with [[Definition:Metasymbol|metasymbols]] $\psi_1, \ldots, \psi_n$. By assumption, we can apply [[Definition:Rule of Formation|rules of formation]] of $\mathcal T$ to each $\psi_i$ to yield the corresponding $\mathcal T$-[[Definition:Well-Formed Formula|WFF]] $\phi_i$. It follows that $\phi$ is also a $\mathcal T$-[[Definition:Well-Formed Formula|WFF]]. By the [[Principle of Structural Induction]], each $\mathcal B$-[[Definition:Well-Formed Formula|WFF]] is also a $\mathcal T$-[[Definition:Well-Formed Formula|WFF]]. Conversely, suppose that $\phi$ is a $\mathcal T$-[[Definition:Well-Formed Formula|WFF]]. Let it be formed by applying the [[Definition:Rule of Formation|rules of formation]] $\mathbf R_1, \ldots, \mathbf R_n$, in succession. We will prove that each [[Definition:Metasymbol|metasymbol]] in the inputs of these [[Definition:Rule of Formation|rules of formation]] will be replaced by a $\mathcal B$-[[Definition:Well-Formed Formula|WFF]]. In particular, then, $\phi$ will be a $\mathcal B$-[[Definition:Well-Formed Formula|WFF]]. Since $\mathbf R_n$ is the last [[Definition:Rule of Formation|rule of formation]] applied, it must replace a [[Definition:Metasymbol|metasymbol]] by a [[Definition:Letter|letter]]. Since [[Definition:Letter|letters]] are $\mathcal B$-[[Definition:Well-Formed Formula|WFFs]], $\mathbf R_n$ satisfies the assertion. Suppose that we have established that all [[Definition:Metasymbol|metasymbols]] in the result of $\mathbf R_i$ will be replaced by $\mathcal B$-[[Definition:Well-Formed Formula|WFFs]]. Then also the [[Definition:Metasymbol|metasymbol]] $\psi$ that $\mathbf R_i$ replaces by a new [[Definition:Collation|collation]] will be replaced by a [[Definition:Well-Formed Formula|WFF]]. This is because the [[Definition:Collation|collation]] resulting from replacing $\psi$ according to $\mathbf R_i$ contains [[Definition:Metasymbol|metasymbols]] $\psi_i$, which by assumption will be replaced by corresponding $\mathcal B$-[[Definition:Well-Formed Formula|WFFs]] $\phi_i$. Now the [[Definition:Rule of Formation|rule of formation]] $\left({\mathbf R_i}\right)_{\mathcal B}$ ensures that $\psi$ will be replaced by a $\mathcal B$-[[Definition:Well-Formed Formula|WFF]]. So each [[Definition:Metasymbol|metasymbol]] $\psi$ in the input of $\mathbf R_i$ will be replaced by a $\mathcal B$-[[Definition:Well-Formed Formula|WFF]]. Hence $\phi$ is a $\mathcal B$-[[Definition:Well-Formed Formula|WFF]]. {{qed}}	1
Let $t$ be an [[Definition:Unmarked Leaf|unmarked leaf]] of the [[Definition:Semantic Tableau|semantic tableau]] $T$ being constructed. Let $\map b t$ be the number of [[Definition:Binary Logical Connective|binary logical connectives]] occurring in its label $\map U t$. Let $\map n t$ be the number of [[Definition:Negation|negations]] occurring in $\map U t$. Let $\map i t$ be the number of [[Definition:Biconditional|biconditionals]] and [[Definition:Exclusive Or|exclusive ors]] occurring in $\map U t$. Define $\map W t$ as: :$\map W t = 3 \, \map b t + \map n t + 4 \, \map i t$<ref>In {{BookLink|Mathematical Logic for Computer Science|ed = 3rd|edpage = Third Edition|M. Ben-Ari}} of $2012$, {{AuthorRef|M. Ben-Ari}} omits the $4 \, \map i t$ term. <br>However, as one can verify, this compromises the $\iff$ and $\neg \oplus$ cases for $\alpha$-formulas.</ref> Next, we aim to prove that: :$\map W {t'} < \map W t$ for every [[Definition:Leaf Node|leaf]] $t'$ that could be added to $t$ in following the [[Semantic Tableau Algorithm]]. First, presume an [[Definition:Alpha-Formula|$\alpha$-formula]] $\mathbf A$ from $\map U t$ is picked. Looking at the mutations from $\map U t$ to $\map U {t'}$, it follows that the claim is reduced to: :$\map W {\mathbf A_1} + \map W {\mathbf A_2} < \map W {\mathbf A}$ This claim can be verified by looking up the appropriate row in the following extension of the [[Definition:Alpha-Formula/Table|table of $\alpha$-formulas]]: ::$\begin{array}{ccc||ccc} \hline \mathbf A & \mathbf A_1 & \mathbf A_2 & \map W {\mathbf A} & \map W {\mathbf A_1} & \map W {\mathbf A_2} \\ \hline \neg \neg \mathbf A_1 & \mathbf A_1 & & \map W {\mathbf A_1} + 2 & \map W {\mathbf A_1} & 0\\ \mathbf A_1 \land \mathbf A_2 & \mathbf A_1 & \mathbf A_2 & \map W {\mathbf A_1} + \map W {\mathbf A_2} + 3 & \map W {\mathbf A_1} & \map W {\mathbf A_2} \\ \neg \paren {\mathbf A_1 \lor \mathbf A_2} & \neg \mathbf A_1 & \neg \mathbf A_2 & \map W {\mathbf A_1} + \map W {\mathbf A_2} + 4 & \map W {\mathbf A_1} + 1 & \map W {\mathbf A_2} + 1 \\ \neg \paren {\mathbf A_1 \implies \mathbf A_2} & \mathbf A_1 & \neg \mathbf A_2 & \map W {\mathbf A_1} + \map W {\mathbf A_2} + 4 & \map W {\mathbf A_1} & \map W {\mathbf A_2} + 1 \\ \neg \paren {\mathbf A_1 \mathbin \uparrow \mathbf A_2} & \mathbf A_1 & \mathbf A_2 & \map W {\mathbf A_1} + \map W {\mathbf A_2} + 4 & \map W {\mathbf A_1} & \map W {\mathbf A_2} \\ \mathbf A_1 \mathbin \downarrow \mathbf A_2 & \neg \mathbf A_1 & \neg \mathbf A_2 & \map W {\mathbf A_1} + \map W {\mathbf A_2} + 3 & \map W {\mathbf A_1} + 1 & \map W {\mathbf A_2} + 1 \\ \mathbf A_1 \iff \mathbf A_2 & \mathbf A_1 \implies \mathbf A_2 & \mathbf A_2 \implies \mathbf A_1 & \map W {\mathbf A_1} + \map W {\mathbf A_2} + 7 & \map W {\mathbf A_1} + 3 & \map W {\mathbf A_2} + 3 \\ \neg \paren {\mathbf A_1 \oplus \mathbf A_2} & \mathbf A_1 \implies \mathbf A_2 & \mathbf A_2 \implies \mathbf A_1 & \map W {\mathbf A_1} + \map W {\mathbf A_2} + 8 & \map W {\mathbf A_1} + 3 & \map W {\mathbf A_2} + 3 \\ \hline \end{array}$ Now presume a [[Definition:Beta-Formula|$\beta$-formula]] $\mathbf B$ from $\map U t$ is picked. Looking at the mutations from $\map U t$ to $\map U {t'}$, it follows that the claim is reduced to: :$\map W {\mathbf B_1}, \map W {\mathbf B_2} < \map W {\mathbf B}$ This claim can be verified by looking up the appropriate row in the following extension of the [[Definition:Beta-Formula/Table|table of $\beta$-formulas]]: ::$\begin{array}{ccc||ccc} \hline \mathbf B & \mathbf B_1 & \mathbf B_2 & \map W {\mathbf B} & \map W {\mathbf B_1} & \map W {\mathbf B_2} \\ \hline \neg \paren {\mathbf B_1 \land \mathbf B_2} & \neg \mathbf B_1 & \neg \mathbf B_2 & \map W {\mathbf B_1} + \map W {\mathbf B_2} + 4 & \map W {\mathbf B_1} + 1 & \map W {\mathbf B_2} + 1 \\ \mathbf B_1 \lor \mathbf B_2 & \mathbf B_1 & \mathbf B_2 & \map W {\mathbf B_1} + \map W {\mathbf B_2} + 3 & \map W {\mathbf B_1} & \map W {\mathbf B_2} \\ \mathbf B_1 \implies \mathbf B_2 & \neg \mathbf B_1 & \mathbf B_2 & \map W {\mathbf B_1} + \map W {\mathbf B_2} + 3 & \map W {\mathbf B_1} + 1 & \map W {\mathbf B_2} \\ \mathbf B_1 \mathbin \uparrow \mathbf B_2 & \neg \mathbf B_1 & \neg \mathbf B_2 & \map W {\mathbf B_1} + \map W {\mathbf B_2} + 3 & \map W {\mathbf B_1} + 1 & \map W {\mathbf B_2} + 1 \\ \neg \paren {\mathbf B_1 \mathbin \downarrow \mathbf B_2} & \mathbf B_1 & \mathbf B_2 & \map W {\mathbf B_1} + \map W {\mathbf B_2} + 4 & \map W {\mathbf B_1} & \map W {\mathbf B_2} \\ \neg \paren {\mathbf B_1 \iff \mathbf B_2} & \neg \paren {\mathbf B_1 \implies \mathbf B_2} & \neg \paren {\mathbf B_2 \implies \mathbf B_1} & \map W {\mathbf B_1} + \map W {\mathbf B_2} + 8 & \map W {\mathbf B_1} + 4 & \map W {\mathbf B_2} + 4 \\ \mathbf B_1 \oplus \mathbf B_2 & \neg \paren {\mathbf B_1 \implies \mathbf B_2} & \neg \paren {\mathbf B_2 \implies \mathbf B_1} & \map W {\mathbf B_1} + \map W {\mathbf B_2} + 7 & \map W {\mathbf B_1} + 4 & \map W {\mathbf B_2} + 4 \\ \hline \end{array}$ Because of the strictly decreasing nature of $\map W t$, it must be that eventually, all [[Definition:Leaf Node|leaves]] of $T$ cannot be extended further. A [[Definition:Leaf Node|leaf]] $t$ cannot be extended {{iff}} $\map U t$ comprises only [[Definition:Literal|literals]]. These finitely many leaves will be [[Definition:Marked Leaf|marked]] by '''Step $3$''' of the [[Semantic Tableau Algorithm]]. In conclusion, the [[Semantic Tableau Algorithm]] terminates, yielding a [[Definition:Semantic Tableau|semantic tableau]] with only [[Definition:Marked Leaf|marked leaves]]. {{qed}}	1
:$\set {\uparrow}$: [[Definition:Logical NAND|NAND]]	1
:$p \land q \dashv \vdash \left({p \iff q}\right) \iff \left({p \lor q}\right)$	1
: $\neg \left ({p \iff q}\right) \dashv \vdash \neg \left({p \implies q}\right) \lor \neg \left({q \implies p}\right)$	1
{{BeginTableau|\neg p \land \neg q \vdash \neg \paren {p \lor q} }} {{Premise|1|\neg p \land \neg q}} {{Simplification|2|1|\neg p|1|1}} {{Simplification|3|1|\neg q|1|2}} {{Assumption|4|p \lor q}} {{Assumption|5|p}} {{NonContradiction|6|1, 5|5|2}} {{Assumption|7|q}} {{NonContradiction|8|1, 7|7|3}} {{ProofByCases|9|1, 4|\bot|4|5|6|7|8}} {{Contradiction|10|1|\neg \paren {p \lor q}|4|9}} {{EndTableau|qed}}	1
: $p \land \top \dashv \vdash p$	1
The [[Rule of Addition/Sequent Form/Formulation 2/Form 2|Rule of Addition]]: :$q \implies (q \lor p)$ is a [[Definition:Tautology (Formal Semantics)|tautology]] in [[Definition:Constructed Semantics/Instance 2|Instance 2]] of [[Definition:Constructed Semantics|constructed semantics]].	1
From the initial definition of [[Definition:Fibonacci Number|Fibonacci numbers]]: :$F_1 = 1, F_2 = 1, F_3 = 2, F_4 = 3$ Let $n = k m - r$ where $0 \le r < m$ We have: :$m \divides n \iff r = 0$ The proof proceeds by [[Principle of Mathematical Induction|induction]] on $k$. For all $k \in \N_{>0}$, let $\map P k$ be the [[Definition:Proposition|proposition]]: :$r = 0 \iff F_m \divides F_{k m - r}$ === Basis for the Induction === $\map P 1$ is the case: :$r = 0 \iff F_m \divides F_{m - r}$ which holds because $F_{m - r} < F_m$ unless $r = 0$. This is our [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k > 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$r = 0 \iff F_m \divides F_{k m - r}$ Then we need to show: :$r = 0 \iff F_m \divides F_{k m + m - r}$ === Induction Step === This is our [[Principle of Mathematical Induction#Induction Step|induction step]]: Let $F_{k m - r} = a F_m + b$ where $0 \le b < F_m$. We have: :$b = 0 \iff F_m \divides F_{k m - r} \iff r = 0$ by the [[Divisibility of Fibonacci Number#Induction Hypothesis|induction hypothesis]]. {{begin-eqn}} {{eqn | l = F_{k m + m - r} | r = F_{m - 1} F_{k m - r} + F_m F_{k m - r + 1} | c = [[Fibonacci Number in terms of Smaller Fibonacci Numbers]] }} {{eqn | r = a F_m F_{m - 1} + b F_{m - 1} + F_m F_{k m - r + 1} | c = }} {{eqn | r = F_m \paren {a F_{m - 1} + F_{k m - r + 1} } + b F_{m - 1} | c = }} {{end-eqn}} We have that $F_{m - 1}$ and $F_m$ are [[Definition:Coprime Integers|coprime]] by [[Consecutive Fibonacci Numbers are Coprime]]. Let $F_m \divides b F_{m - 1}$. Then there exists an integer $k$ such that $k F_m \divides b F_{m - 1}$, by [[Definition:Divisor of Integer|the definition of divisibility]]. Then: :$\dfrac k b = \dfrac {F_{m - 1} } {F_m}$ We have that $F_{m - 1}$ and $F_m$ are [[Definition:Coprime Integers|coprime]]. Thus by [[Coprime Numbers form Fraction in Lowest Terms]]: :$\dfrac {F_{m - 1} } {F_m}$ is in [[Definition:Canonical Form of Rational Number|canonical form]]. Then by [[Ratios of Fractions in Lowest Terms]] :$F_m \divides b$ Because $0 \le b < F_m$, the only case is when $b = 0$. Therefore: :$F_m \divides b F_{m - 1} \iff b = 0$ Therefore: :$F_m \divides F_{k m + m - r} \iff F_m \divides b F_{m - 1} \iff b = 0 \iff r = 0$ So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\forall m, n > 2 : m \divides n \iff F_m \divides F_n$ {{qed}}	1
The proof proceeds by [[Second Principle of Mathematical Induction|strong induction]]. For all $n \in \Z_{\ge 1}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :There are no instances of $2$ $\text a$'s or $3$ $\text b$'s together in $S_n$. $\map P 1$ is the case: :$S_1 = \text a$ === Basis for the Induction === $\map P 2$ is the case: :$S_2 = \text b$ $\map P 3$ is the case: :$S_3 = \text {ba}$ This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that, if $\map P j$ is true, for all $j$ such that $2 \le j \le k$, then it logically follows that $\map P {k + 1}$ is true. This is the [[Definition:Induction Hypothesis|induction hypothesis]]: :There are no instances of $2$ $\text a$'s or $3$ $\text b$'s together in $S_k$. and: :There are no instances of $2$ $\text a$'s or $3$ $\text b$'s together in $S_{k - 1}$. from which it is to be shown that: :There are no instances of $2$ $\text a$'s or $3$ $\text b$'s together in $S_{k + 1}$. === Induction Step === This is the [[Definition:Induction Step|induction step]]: By definition of [[Definition:Fibonacci String|Fibonacci string]]: :$S_{k + 1} = S_k S_{k - 1}$ [[Definition:Concatenation (Formal Systems)|concatenated]]. By the [[Incidence of Double Letters in Fibonacci String#Induction Hypothesis|induction hypothesis]], neither $S_k$ nor $S_{k - 1}$ have any double $\text a$'s or triple $\text b$'s. The only way for $S_{k + 1}$ to have a double $\text a$ is for $S_n$ to end with $\text a$ and for $S_{k - 1}$ to begin with $\text a$. But from [[Fibonacci String Begins with ba]], for all $k > 2$, $S_{k - 1}$ begins with $\text b$. When $k = 2$, $S_{k - 1}$ does begin with $\text a$, but then $S_{k + 1} = \text {ba}$, which has no double $\text a$. Similarly, the only way for $S_{k + 1}$ to have a triple $\text b$, either $S_k$ must end with double $\text b$ or $S_{k - 1}$ must begin with double $\text b$. From [[Fibonacci String Begins with ba]], $S_{k - 1}$ does not begin with double $\text b$. From [[Fibonacci String Ends with ab or ba]], $S_k$ does not begin with double $\text b$. So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Second Principle of Mathematical Induction]]. Therefore: :For all $n \in \Z_{>0}$, there are no instances of $2$ $\text a$'s or $3$ $\text b$'s together in $S_n$. {{qed}}	1
{{BeginTableau|p \lor \bot \vdash p}} {{Premise|1|p \lor \bot}} {{Assumption|2|p}} {{Assumption|3|\bot}} {{Explosion|4|3|p|3}} {{ProofByCases|5|1|p|1|2|2|3|4}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|p \vdash p \lor \bot}} {{Premise|1|p}} {{Addition|2|1|p \lor \bot|1|1}} {{EndTableau}} {{qed}}	1
:If we can conclude $\neg \neg \phi$, then we may infer $\phi$.	1
Let $l \left({\mathbf Q}\right)$ denote the [[Definition:Length of String|length]] of a [[Definition:String|string]] $\mathbf Q$. By definition, $\mathbf S$ is an [[Definition:Initial Part|initial part]] of $\mathbf A$ iff $\mathbf A = \mathbf{ST}$ for some [[Definition:Null String|non-null string]] $\mathbf T$. Thus we note that $l \left({\mathbf S}\right) < l \left({\mathbf A}\right)$. The proof proceeds by [[Second Principle of Mathematical Induction|induction]] on $l \left({\mathbf A}\right)$. === Basis for the Induction === Let $\mathbf A$ be a [[Definition:WFF of Predicate Logic|WFF]] such that $l \left({\mathbf A}\right) = 1$. Then for an [[Definition:Initial Part|initial part]] $\mathbf S$, $l \left({\mathbf S}\right) < 1 = 0$. That is, $\mathbf S$ must be the [[Definition:Null String|null string]], which is not a [[Definition:WFF of Predicate Logic|WFF]]. So the result holds for WFFs of length $1$. This is the [[Second Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Fix $n \in \N$ with $n \ge n_0$. Assume the result holds for all [[Definition:WFF of Predicate Logic|WFFs]] of length $k$ or less. This is our [[Second Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]. === Induction Step === This is our [[Second Principle of Mathematical Induction#Induction Step|induction step]]: Let $\mathbf A$ be a WFF such that $l \left({\mathbf A}\right) = k+1$. Suppose $\mathbf D$ is an initial part of $\mathbf A$ which happens to be a WFF. That is, $\mathbf A = \mathbf{DT}$ where $\mathbf T$ is [[Definition:Null String|non-null]]. We need to investigate the following cases: :$(1): \quad \mathbf A = \neg \mathbf B$, where $\mathbf B$ is a WFF of length $k$. :$(2): \quad \mathbf A = \left({\mathbf B \circ \mathbf C}\right)$ where $\circ$ is one of the binary connectives. :$(3): \quad \mathbf A = p \left({t_1, t_2, \ldots, t_n}\right)$, where $t_1, t_2, \ldots, t_n$ are [[Definition:Term (Predicate Logic)|terms]], and $p \in \mathcal{P}_n$. :$(4): \quad \mathbf A = ( Q x: \mathbf B )$, where $\mathbf B$ is a WFF of length $k-5$, $Q$ is a quantifier ($\forall$ or $\exists$) and $x$ is a [[Definition:Variable|variable]]. We deal with these one by one. Cases $(1)$ and $(2)$ are covered by the argument in [[Initial Part of WFF of PropLog is not WFF]]. :$(3): \quad$ The [[Definition:Atomic WFF of Predicate Logic|atomic WFF]] $\mathbf A = p \left({u_1, u_2, \ldots, u_n}\right)$: Here we have that $\mathbf D$ would be a string of the form: * $p$ where $p$ is an [[Definition:Arity|$n$-ary]] [[Definition:Predicate Symbol|predicate symbol]]. This can not be a WFF. * $p ($ which is also not a WFF. * $p (u_1, u_2, \ldots, u_k$ which can not be a WFF. * $p (u_1, u_2, \ldots, u_k,$ which can not be a WFF. :$(4): \quad \mathbf A = ( Q x: \mathbf B )$: $\mathbf D$ can not be $($, $( Q$, $( Q x$ or $( Q x:$ as none of these are WFFs. Thus $\mathbf D$ is a WFF, starting with $( Q x: $; hence $\mathbf D = ( Q x: \mathbf E )$, where $\mathbf E$ is also a WFF. We remove the initial $( Q x: $ and the last closing [[Definition:Parenthesis|parenthesis]] $)$ from $\mathbf A = \mathbf{DT}$ to get $\mathbf B = \mathbf{ET}'$ (where $\mathbf T'$ results from $\mathbf T$ by removing the last closing [[Definition:Parenthesis|parenthesis]]). Recall that $\mathbf B$ is a WFF of length $k-5$. It has $\mathbf E$ as an initial part, which is itself a WFF. This contradicts the [[Second Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]. Therefore no initial part of $\mathbf A = ( Q x: \mathbf{B} )$ can be a WFF. Thus all four cases have been investigated, and we have found that no initial part of any WFF of length $k+1$ can be a WFF. The result follows by the [[Second Principle of Mathematical Induction]]. {{qed}}	1
:$\vdash \paren {p \land \paren {q \lor r} } \iff \paren {\paren {p \land q} \lor \paren {p \land r} }$	1
{{begin-eqn}} {{eqn | l = p \implies q | o = \dashv \vdash | r = \neg p \lor q | c = [[Rule of Material Implication]] }} {{eqn | o = \dashv \vdash | r = \neg p \lor \neg \neg q | c = [[Double Negation Introduction]] }} {{eqn | o = \dashv \vdash | r = p \uparrow \neg q | c = [[NAND as Disjunction of Negations]] }} {{eqn | o = \dashv \vdash | r = p \uparrow \left({q \uparrow q}\right) | c = [[NAND with Equal Arguments]] }} {{end-eqn}} {{qed}}	1
: $p \vdash \left({p \implies q}\right) \implies q$	1
For each [[Definition:Node (Graph Theory)|node]] $v \in T$, let $p (v)$ be the [[Definition:Path (Graph Theory)|path]] from $v$ to $r_T$, the [[Definition:Root Node|root]] of $T$. This [[Definition:Path (Graph Theory)|path]] is unique by [[Path in Tree is Unique]]. Let $\mathcal V$ be the [[Definition:Rooted Subtree|subtree]] of $T$ consisting those [[Definition:Node (Graph Theory)|nodes]] $v$ of $T$ such that $p (v)$ is not [[Definition:Contradictory Branch|contradictory]]. Suppose that $\mathcal V$ were [[Definition:Infinite Set|infinite]]. Then by [[König's Tree Lemma]], $\mathcal V$ has an [[Definition:Infinite Branch|infinite branch]] $\Gamma$. Since $\mathcal V \subseteq T$, it follows that $\Gamma$ is also a [[Definition:Branch (Graph Theory)|branch]] of $T$. However, by construction, it is impossible that $\Gamma$ is [[Definition:Contradictory Branch|contradictory]]. This contradicts that $T$ is a [[Definition:Tableau Confutation|tableau confutation]]. Hence $\mathcal V$ is [[Definition:Finite Set|finite]]. Next, define a [[Definition:Finite Propositional Tableau|finite propositional tableau]] $T'$ by: :$v \in T' \iff \pi (v) \in \mathcal V$ that is, the [[Definition:Rooted Tree|rooted tree]] formed by $\mathcal V$ and all its [[Definition:Child Node|children]]. Then by construction, for each [[Definition:Leaf Node|leaf node]] $v$ of $T'$, we have that $v \notin \mathcal V$. That is, that $p (v)$ is a [[Definition:Contradictory Branch|contradictory branch]] of $T'$. By [[Leaf of Rooted Tree is on One Branch]], every [[Definition:Branch (Graph Theory)|branch]] of $T'$ is [[Definition:Contradictory Branch|contradictory]]. Hence $T'$ is a [[Definition:Tableau Confutation|tableau confutation]] of $\mathbf H'$, as desired. {{qed}}	1
{{BeginTableau|\vdash \left({\neg \left({p \land \neg q}\right)}\right) \implies \left({p \implies q}\right)}} {{Assumption|1|\neg \left({p \land \neg q}\right)}} {{SequentIntro|2|1|p \implies q|1|[[Implication Equivalent to Negation of Conjunction with Negative/Formulation 1/Reverse Implication|Implication Equivalent to Negation of Conjunction with Negative: Formulation 1]]}} {{Implication|3||\left({\neg \left({p \land \neg q}\right)}\right) \implies \left({p \implies q}\right)|1|2}} {{EndTableau}} {{qed}} {{LEM|Implication Equivalent to Negation of Conjunction with Negative/Formulation 1/Reverse Implication}} [[Category:Implication Equivalent to Negation of Conjunction with Negative]] estsbm4ogmgfblagpg6qq8budnw25nl	1
: $q \implies \left({p \implies r}\right) \vdash p \implies \left({q \implies r}\right)$	1
{{questionable|This only takes on board a subset of $\N$, where we need a subset of $\Z$}} Consider $\N$ defined as a [[Definition:Naturally Ordered Semigroup|naturally ordered semigroup]]. The result follows directly from [[Principle of Mathematical Induction for Naturally Ordered Semigroup/General Result|Principle of Mathematical Induction for Naturally Ordered Semigroup: General Result]]. {{qed}}	1
Let $M$ be the [[Definition:Middle Term of Syllogism|middle term]] of a [[Definition:Valid Argument|valid]] [[Definition:Categorical Syllogism|categorical syllogism]] $Q$. Then $M$ is [[Definition:Distributed Term of Categorical Syllogism|distributed]] in at least one of the [[Definition:Premise of Syllogism|premises]] of $Q$ in which it appears.	1
: $p \implies q, q \implies r, p \vdash r$	1
Let $\MM$ and $\NN$ be $\LL$-[[Definition:First-Order Structure|structures]]. Let $B$ be a [[Definition:Subset|subset]] of the universe of $\MM$ such that there is a [[Definition:Partial Elementary Embedding|partial elementary embedding]] $f: B \to \NN$. There is an [[Definition:Elementary Extension|elementary extension]] $\AA$ of $\MM$ and an [[Definition:Elementary Embedding|elementary embedding]] $g: \NN \to \AA$ such that $\map g {\map f b} = b$ for all $b \in B$. $\array { & & \AA& & \\ &\preceq & & \nwarrow \exists g & & \!\!\!\!\!\!\!\!\!\!\!\!\!: g f = \operatorname {id}_B \\ \MM & & & &\!\!\!\!\!\!\!\! \NN \\ & \supseteq & & \nearrow f \\ & & B& & \\ }$	1
{{BeginTableau|\vdash \neg \neg p \implies p}} {{Assumption|1|\neg \neg p}} {{DoubleNegElimination|2|1|p|1}} {{Implication|3||\neg \neg p \implies p|1|2}} {{EndTableau}} {{Qed}}	1
{{BeginTableau|p \implies q, q \implies r \vdash p \implies r}} {{Premise|1|p \implies q}} {{Premise|2|q \implies r}} {{Assumption|3|p}} {{ModusPonens|4|1, 3|q|1|3}} {{ModusPonens|5|1, 2, 3|r|2|4}} {{Implication|6|1, 2|p \implies r|3|5}} {{EndTableau}} {{qed}}	1
:$\vdash \paren {p \implies q} \lor \paren {q \implies r}$	1
Denote with $\mathscr H_2 - (A2)$ the [[Definition:Proof System|proof system]] resulting from $\mathscr H_2$ by removing [[Definition:Axiom (Formal Systems)|axiom]] $(A2)$. Consider $\mathscr C_3$, [[Definition:Constructed Semantics/Instance 3|Instance 3]] of [[Definition:Constructed Semantics|constructed semantics]]. We will prove that: * $\mathscr H_2 - (A2)$ is [[Definition:Sound Proof System|sound]] for $\mathscr C_3$; * [[Definition:Axiom (Formal Systems)|Axiom]] $(A2)$ is not a [[Definition:Tautology (Formal Semantics)|tautology]] in $\mathscr C_3$ which leads to the conclusion that $(A2)$ is not a [[Definition:Theorem (Formal Systems)|theorem]] of $\mathscr H_2 - (A2)$. === Soundness of $\mathscr H_2 - (A2)$ for $\mathscr C_3$ === Starting with the [[Definition:Axiom (Formal Systems)|axioms]]: {{begin-axiom}} {{axiom|n = A1 |lc = [[Rule of Idempotence/Disjunction/Formulation 2/Reverse Implication|Rule of Idempotence]] |m = (p \lor p) \implies p |rc = [[Definition:Constructed Semantics/Instance 3/Rule of Idempotence|Proof of Tautology]] }} {{axiom|n = A3 |lc = [[Rule of Commutation/Disjunction/Formulation 2/Forward Implication|Rule of Commutation]] |m = (p \lor q) \implies (q \lor p) |rc = [[Definition:Constructed Semantics/Instance 3/Rule of Commutation|Proof of Tautology]] }} {{axiom|n = A4 |lc = [[Factor Principles/Disjunction on Left/Formulation 2|Factor Principle]] |m = (q \implies r) \implies \left({ (p \lor q) \implies (p \lor r)}\right) |rc = [[Definition:Constructed Semantics/Instance 3/Factor Principle|Proof of Tautology]] }} {{end-axiom}} Next it needs to be shown that the [[Definition:Hilbert Proof System/Instance 2|rules of inference of $\mathscr H_2$]] preserve $\mathscr C_3$-[[Definition:Tautology (Formal Semantics)|tautologies]]. ==== Rule $RST \, 1$: Rule of Uniform Substitution ==== By definition, any [[Definition:WFF of Propositional Logic|WFF]] is assigned a value $0$, $1$ or $2$. Thus, in applying [[Definition:Hilbert Proof System/Instance 2|Rule $RST \, 1$]], we are introducing $0$, $1$ or $2$ in the position of a [[Definition:Propositional Variable|propositional variable]]. But all possibilities of assignments of $0$s, $1$s and $2$s to such [[Definition:Propositional Variable|propositional variables]] were shown not to affect the resulting values of the axioms. Hence [[Definition:Hilbert Proof System/Instance 2|Rule $RST \, 1$]] preserves $\mathscr C_3$-[[Definition:Tautology (Formal Semantics)|tautologies]]. ==== Rule $RST \, 2$: Rule of Substitution by Definition ==== Because the definition of $\mathscr C_3$ was given in terms of [[Definition:Hilbert Proof System/Instance 2|Rule $RST \, 2$]], it cannot affect any of its results. ==== Rule $RST \, 3$: Rule of Detachment ==== Suppose $\mathbf A$ and $\mathbf A \implies \mathbf B$ both take value $0$ or $1$. Then using [[Definition:Hilbert Proof System/Instance 2|Rule $RST \, 2$]], definition $(2)$, we get: :$\neg \mathbf A \lor \mathbf B$ taking value $0$ or $1$ by assumption. But $\neg \mathbf A$ takes value $1$ or $2$, by definition of $\neg$. So from the definition of $\lor$, we have the following options: $\begin{array}{|c|c|c|} \hline \mathbf A & \neg \mathbf A \lor \mathbf B & \\ \hline 0 & 0 & 2 \lor \mathbf B = 0 \implies \mathbf B = 0\\ 1 & 0 & 1 \lor \mathbf B = 0 \implies \mathbf B = 0\\ 0 & 1 & 2 \lor \mathbf B = 1 \implies \mathbf B = 1\\ 1 & 1 & 1 \lor \mathbf B = 1 \implies \mathbf B = 1\\ \hline \end{array}$ In each case, we see that the definition of $\lor$ necessitates that $\mathbf B$ takes value $0$ or $1$, respectively. Hence [[Definition:Hilbert Proof System/Instance 2|Rule $RST \, 3$]] also produces only [[Definition:WFF of Propositional Logic|WFFs]] of value $0$ or $1$. ==== Rule $RST \, 4$: Rule of Adjunction ==== Suppose $\mathbf A$ and $\mathbf B$ take value $0$ or $1$. Then using the definitional abbreviations: :$\mathbf A \land \mathbf B =_{\text{def}} \neg ( \neg \mathbf A \lor \neg \mathbf B )$ We compute: :$\begin{array}{|c|ccccc|} \hline \neg & ( \neg & \mathbf A & \lor & \neg & \mathbf B ) \\ \hline 0 & 2 & 0 & 2 & 2 & 0 \\ 0 & 2 & 0 & 2 & 1 & 1 \\ 0 & 1 & 1 & 2 & 2 & 0 \\ 1 & 1 & 1 & 1 & 1 & 1 \\ \hline \end{array}$ proving that [[Definition:Hilbert Proof System/Instance 2|Rule $RST \, 4$]] also produces only $0$s and $1$s from $0$s and $1$s. Hence $\mathscr H_2 - (A2)$ is [[Definition:Sound Proof System|sound]] for $\mathscr C_3$. === $(A2)$ is not a $\mathscr C_3$-tautology === Recall [[Definition:Axiom (Formal Systems)|axiom]] $(A2)$, the [[Rule of Addition/Sequent Form/Formulation 2/Form 2|Rule of Addition]]: :$q \implies (p \lor q)$ Under $\mathscr C_3$, we apply a single definitional abbreviation and have the following: :$\begin{array}{|cc|c|ccc|} \hline \neg & q & \lor & (p & \lor & q) \\ \hline 2 & 0 & 0 & 0 & 0 & 0 \\ 1 & 1 & 0 & 0 & 0 & 1 \\ 0 & 2 & 0 & 0 & 0 & 2 \\ 2 & 0 & 0 & 1 & 0 & 0 \\ 1 & 1 & 1 & 1 & 1 & 1 \\ 0 & 2 & 0 & 1 & 2 & 2 \\ 2 & 0 & 0 & 2 & 0 & 0 \\ 1 & 1 & 2 & 2 & 2 & 1 \\ 0 & 2 & 0 & 2 & 2 & 2 \\ \hline \end{array}$ Hence according to the definition of $\mathscr C_3$, $(A1)$ is not a [[Definition:Tautology (Formal Semantics)|tautology]]. Therefore $(A2)$ is independent from $(A1)$, $(A3)$, $(A4)$. {{qed}}	1
If $P = 0$, the theorem holds trivially. Let $P_n$ be a [[Definition:Polynomial (Analysis)|polynomial]] of [[Definition:Degree of Polynomial over Field|degree $n$]], where $n \ge 0$. The proof proceeds by [[Principle of Mathematical Induction|induction]] on $n$, where $n$ is the [[Definition:Degree of Polynomial|degree of the polynomial]]. === Basis for the Induction === Let $P_0$ be of [[Definition:Degree of Polynomial|degree zero]]. Then $P_0$ is a [[Definition:Polynomial of Degree Zero|constant polynomial]]. By [[Constant Function is of Exponential Order Zero]], $P_0 \in \mathcal E_0$. Therefore, by [[Raising Exponential Order]], it is of exponential order $\epsilon$ as well. This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Fix $n \in \N$ with $n \ge 0$. Assume: :$P_n \in \mathcal E_\epsilon$ That is: :$\size {\map {P_n} t} < K e^{\epsilon t}$ for some $K > 0$, for $\epsilon > 0$ arbitrarily small. This is our [[Definition:Induction Hypothesis|induction hypothesis]]. === Induction Step === Let $P_{n + 1}$ be of [[Definition:Degree of Polynomial over Field|degree $n + 1$]]. By the definition of [[Definition:Polynomial (Analysis)|polynomial]], :$P_{n + 1} = P_n + a_{n + 1} x^{n + 1}$ for some polynomials of degree $n$. $P_n$ is of exponential order $\epsilon$ by the induction hypothesis. Thus, by: :[[Sum of Functions of Exponential Order]] :[[Scalar Multiple of Function of Exponential Order]] :[[Natural Number Power is of Exponential Order Epsilon]] We have that $P_{n + 1}$ is of degree $\epsilon$. The result follows by the [[Principle of Mathematical Induction]]. {{qed}} [[Category:Exponential Order]] [[Category:Proofs by Induction]] jecyo3kibyn6re3xkbrhvioc4fg6hyj	1
{{BeginTableau|p \downarrow p \vdash \neg p}} {{Premise|1|p \downarrow p}} {{SequentIntro|2|1|\neg \left({p \lor p}\right)|1|Definition of [[Definition:Logical NOR|Logical NOR]]}} {{Idempotence|3|1|\neg p|2|Disjunction}} {{EndTableau}} {{BeginTableau|\neg p \vdash p \downarrow p}} {{Premise|1|\neg p}} {{Idempotence|2|1|\neg \left({p \lor p}\right)|1|Disjunction}} {{SequentIntro|3|1|p \downarrow p|2|Definition of [[Definition:Logical NOR|Logical NOR]]}} {{EndTableau}} {{qed}}	1
{{BeginTableau|\neg p \implies q \vdash \neg q \implies p}} {{Premise|1|\neg p \implies q}} {{Assumption|2|\neg q}} {{ModusTollens|3|1, 2|\neg \neg p|1|2}} {{DoubleNegElimination|4|1, 2|p|3}} {{Implication|5|1|\neg q \implies p|2|4}} {{EndTableau}} {{Qed}} {{LEM|Double Negation Elimination|3}}	1
{{BeginTableau|p \uparrow q \vdash q \uparrow p}} {{Premise|1|p \uparrow q}} {{SequentIntro|2|1|\neg \left({p \land q}\right)|1||Definition of [[Definition:Logical NAND|Logical NAND]]}} {{Commutation|3|1|\neg \left({q \land p}\right)|2|Conjunction}} {{SequentIntro|4|1|q \uparrow p|3||Definition of [[Definition:Logical NAND|Logical NAND]]}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|q \uparrow p \vdash p \uparrow q}} {{Premise|1|q \uparrow p}} {{SequentIntro|2|1|\neg \left({q \land p}\right)|1||Definition of [[Definition:Logical NAND|Logical NAND]]}} {{Commutation|3|1|\neg \left({p \land q}\right)|2|Conjunction}} {{SequentIntro|4|1|p \uparrow q|3||Definition of [[Definition:Logical NAND|Logical NAND]]}} {{EndTableau}} {{qed}}	1
: $p \dashv \vdash p \lor p$	1
Consider the [[Definition:Game|game]] defined by the following [[Definition:Payoff Table|payoff table]]: {{PayoffTable|table = $\begin{array} {r {{|}} c {{|}} } & B_1 & B_2 \\ \hline A_1 & 1 & 2 \\ \hline A_2 & 1 & 3 \\ \hline \end{array}$}} This has two [[Definition:Solution of Game|solutions]]: :$(1): \quad A: \left({1, 0}\right), B: \left({1, 0}\right)$ :$(2): \quad A: \left({0, 1}\right), B: \left({1, 0}\right)$ {{explain|The reason why the above are solutions is not indicated.}} Thus both [[Definition:Pure Strategy|pure strategies]] for $A$ are optimal, but $A_1$ is [[Definition:Dominating Strategy|dominated]] by $A_1$. {{qed}}	1
Let $\LL$ be a [[Definition:Formal Language|formal language]]. Let the [[Definition:Formal Grammar|formal grammar]] of $\LL$ be a [[Definition:Bottom-Up Grammar|bottom-up grammar]]. Let $\map P \phi$ be a [[Definition:Statement|statement]] (in the [[Definition:Metalanguage|metalanguage]] of $\LL$) about [[Definition:Well-Formed Formula|well-formed formulas]] $\phi$ of $\LL$. Then $P$ is true for all [[Definition:Well-Formed Formula|WFFs]] of $\LL$ {{iff}} both: :$\map P a$ is true for all [[Definition:Letter|letters]] $a$ of $\LL$, and, for each [[Definition:Rule of Formation|rule of formation]] of $\LL$, if $\phi$ is a [[Definition:Well-Formed Formula|WFF]] resulting from WFFs $\phi_1, \ldots, \phi_n$ by applying that rule, then: :$\map P \phi$ is true only if $\map P {\phi_1}, \ldots, \map P {\phi_n}$ are all true.	1
From the [[Constructive Dilemma]] we have: : $p \implies q, r \implies s \vdash p \lor r \implies q \lor s$ from which, changing the names of letters strategically: : $p \implies q, \neg p \implies q \vdash p \lor \neg p \implies q \lor q$ From [[Law of Excluded Middle]], we have: : $\vdash p \lor \neg p$ From the [[Rule of Idempotence]] we have: : $q \lor q \vdash q$ and the result follows by [[Hypothetical Syllogism]]. {{qed}}	1
{{BeginTableau|p \land p \vdash p}} {{Premise|1|p \land p}} {{Simplification|2|1|p|1|1}} {{EndTableau}} {{qed}} [[Category:Rule of Idempotence]] fegoi2u2sshc3pgst3ks1onazak1ubx	1
Let $\mathbf A, \mathbf B$ be [[Definition:WFF of Predicate Logic|WFFs of predicate logic]]. {{TFAE|def = Semantic Equivalence (Predicate Logic)|semantic equivalence}}	1
: $\vdash p \implies \neg \neg p$	1
{{begin-eqn}} {{eqn | l = p \oplus q | o = \dashv \vdash | r = \paren {p \lor q} \land \neg \paren {p \land q} | c = {{Defof|Exclusive Or}} }} {{eqn | o = \dashv \vdash | r = \neg \paren {p \iff q} | c = [[Non-Equivalence as Conjunction of Disjunction with Negation of Conjunction]] }} {{end-eqn}} {{qed}}	1
Let $\mathcal L$ be a [[Definition:Formal System|formal system]] with [[Definition:Deductive Apparatus|deductive apparatus]] $\mathcal D$. A '''metamodel''' $\mathcal M$ for $\mathcal L$ is an interpretation for $\mathcal L$. Thus, it assigns meanings to all of the [[Definition:Undefined Term|undefined terms]] of $\mathcal L$. Further, it specifies a means for deciding if a [[Definition:Sentence|sentence]] of $\mathcal L$ is to be considered true in $\mathcal M$. It is then required that all the sentences derivable by the [[Definition:Deductive Apparatus|deductive apparatus]] $\mathcal D$ are true in $\mathcal M$. From the above specification, it follows that a '''metamodel''' $\mathcal M$ is a conceptual device, in that it does not require to be founded on rigorous mathematical foundations. Thus, $\mathcal M$ need not be a [[Definition:Set|set]] or some other rigid notion, just something that one can contemplate, denote and convey to others. For example, even without rigid mathematical foundations it is clear to all sane people that there is a concept "set" that one can reason about. One could then try to determine if the collection of these "sets" is a '''metamodel''' for the [[Definition:Language of Set Theory|language of set theory]]. As another example there is the notion of [[Definition:Metacategory|metacategory]], which can be described as being any '''metamodel''' for the [[Definition:Language of Category Theory|language of category theory]].	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc||cccc|} \hline \neg & p & \land & \neg & q & \neg & (p & \lor & q) \\ \hline T & F & T & T & F & T & F & F & F \\ T & F & F & F & T & F & F & T & T \\ F & T & F & T & F & F & T & T & F \\ F & T & F & F & T & F & T & T & T \\ \hline \end{array}$ {{qed}}	1
We note that $m \divides n \iff n = q m$ where $q \in \Z$. So we see that $m \divides n \iff \map \rem {n, m} = 0$ (see [[Remainder is Primitive Recursive]]). Thus we define the [[Definition:Function|function]] $\operatorname{div}: \N^2 \to \N$ as: :$\map {\operatorname {div} } {n, m} = \map {\chi_{\operatorname {eq} } } {\map \rem {n, m}, 0}$ where $\map {\chi_{\operatorname {eq} } } {n, m}$ denotes the [[Definition:Characteristic Function of Relation|characteristic function]] of the equality relation. So we have: :$\map {\operatorname {div} } {n, y} = \begin{cases} 1 & : y \divides n \\ 0 & : y \nmid n \end{cases}$ So $\map {\operatorname {div} } {n, m}$ is defined by [[Definition:Substitution (Mathematical Logic)|substitution]] from: :the [[Remainder is Primitive Recursive|primitive recursive function $\rem$]] :the [[Equality Relation is Primitive Recursive|primitive recursive relation $\operatorname {eq}$]] :the [[Constant Function is Primitive Recursive|constants]] $1$ and $0$. Thus $\operatorname {div}$ is [[Definition:Primitive Recursive Function|primitive recursive]]. Hence the result. {{qed}} [[Category:Primitive Recursive Functions]] 8wsr1duvmpkzioguxnb1iq0ghwdqwlv	1
The proof proceeds by [[Principle of General Induction|general induction]]. Let $x \in M$ be [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$ Let $\map P y$ be the [[Definition:Proposition|proposition]]: :$\map \RR {x, y}$ holds. === Basis for the Induction === By condition $\text D_1$ of the definition of $\RR$: :$\map \RR {x, \O}$ for all $x \in M$. Thus $\map P \O$ is seen to hold. This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that if $\map P y$ is true, where $x \in M$, then it logically follows that $\map P {\map g y}$ is true. So this is the [[Definition:Induction Hypothesis|induction hypothesis]]: :$\map \RR {x, y}$ holds from which it is to be shown that: :$\map \RR {x, \map g y}$ holds === Induction Step === This is the [[Definition:Induction Step|induction step]]: Let $\map \RR {x, y}$ hold. As $x$ is [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$: :$\map \RR {y, x}$ holds. Thus by condition $\text D_2$ of the definition of $\RR$: :$\map \RR {x, \map g y}$ holds. So $\map P x \implies \map P {\map g x}$ and the result follows by the [[Principle of General Induction]]. Therefore: :$\forall x \in M$: if $x$ is a [[Definition:Right Normal Element of Relation|right normal element]] of $M$ with respect to $\RR$, then $x$ is a [[Definition:Left Normal Element of Relation|left normal element]] of $M$ with respect to $\RR$ {{qed}}	1
Let $\struct {S, \vee, \wedge, \neg}$ be a [[Definition:Boolean Algebra/Definition 2|Boolean algebra, defined as in Definition 2]]. Then: :$\exists \bot \in S: \forall a \in S: a \wedge \neg a = \bot$ where $\wedge$ denotes the [[Definition:Boolean Algebra|meet operation in $S$]]. This element $\bot$ is [[Definition:Unique|unique]] for any given $S$, and is named '''bottom'''.	1
[[Definition:Axiom (Formal Systems)|Axiom]] $(A1)$ is [[Definition:Independent Axiom|independent]] from $(A2)$, $(A3)$, $(A4)$.	1
Let $G$ be a [[Definition:Two-Person Zero-Sum Game|two-person zero-sum game]]. Let $G$ have more than one [[Definition:Equilibrium Point|equilibrium point]]. Then every [[Definition:Equilibrium Point|equilibrium point]] of $G$ has the same [[Definition:Payoff|payoff]].	1
Let $\left({S,\circ}\right)$ be a [[Definition:Group|group]]. Let $C$ be the set of [[Definition:Endorelation|relations]] on $S$ which are [[Definition:Relation Compatible with Operation|compatible]] with $\circ$. Then $\left({C, \cap, \cup, \subseteq}\right)$ is a [[Definition:Complete Boolean Lattice|complete Boolean lattice]].	1
The [[Rule of Addition/Sequent Form/Formulation 2/Form 2|Rule of Addition]]: :$q \implies (q \lor p)$ is a [[Definition:Tautology (Formal Semantics)|tautology]] in [[Definition:Constructed Semantics/Instance 5|Instance 5]] of [[Definition:Constructed Semantics|constructed semantics]].	1
Let $F$ be a set of [[Definition:First-Order Formula|first-order formulas]] which has [[Definition:Finite|finite]] [[Definition:Model (Predicate Logic)|models]] of arbitrarily large size. Then $F$ has an [[Definition:Infinite|infinite]] [[Definition:Model (Predicate Logic)|model]].	1
From the [[Constructive Dilemma]] we have: : $p \implies q, r \implies s \vdash p \lor r \implies q \lor s$ from which, changing the names of letters strategically: : $p \implies r, q \implies r \vdash p \lor q \implies r \lor r$ From the [[Rule of Idempotence]] we have: : $r \lor r \vdash r$ and the result follows by [[Hypothetical Syllogism]]. {{qed}}	1
We note that: :$\size {n - m} = \paren {n \mathop {\dot -} m} + \paren {m \mathop {\dot -} n} = \map {\operatorname {add} } {\paren {n \mathop {\dot -} m}, \paren {m \mathop {\dot -} n} }$ Next we note that: :$m \mathop {\dot -} n = \map {\pr^2_2} {n, m} \mathop {\dot -} \map {\pr^2_1} {n, m}$ where $\pr^2_k$ is the [[Definition:Basic Primitive Recursive Function/Projection Function|projection function]]. Then: {{begin-eqn}} {{eqn | l = \map {\operatorname {adf} } {n, m} | r = \size {n - m} | c = }} {{eqn | r = \paren {n \mathop {\dot -} m} + \paren {m \mathop {\dot -} n} | c = }} {{eqn | r = \map {\operatorname {add} } {\paren {n \mathop {\dot -} m}, \paren {m \mathop {\dot -} n} } | c = }} {{eqn | r = \map {\operatorname {add} } {\paren {n \mathop {\dot -} m}, \paren {\map {\pr^2_2} {n, m} \mathop {\dot -} \map {\pr^2_1} {n, m} } } | c = }} {{end-eqn}} Hence we see that $\operatorname {adf}$ is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from: :the [[Cut-Off Subtraction is Primitive Recursive|primitive recursive function $n \mathop {\dot -} m$]] :the [[Addition is Primitive Recursive|primitive recursive function $\map {\operatorname {add} } {n, m}$]] :the [[Definition:Basic Primitive Recursive Function/Projection Function|projection function]]. Hence the result. {{qed}} [[Category:Primitive Recursive Functions]] 80gkgdqvx01gp9gkqlv41rm4j7i8s6b	1
{{BeginTableau|p \vdash p \land p}} {{Premise|1|p}} {{Conjunction|2|1|p \land q|1|1}} {{EndTableau}} {{qed}} [[Category:Rule of Idempotence]] blc5sulas1kx4ojnz6z3l99t5mwqqis	1
We have that [[Golay Ternary Code has Minimum Distance 5]]. The result follows from [[Error Correction Capability of Linear Code]]. {{qed}}	1
: $\neg \left ({p \iff q}\right) \dashv \vdash \neg \left({p \implies q}\right) \lor \neg \left({q \implies p}\right)$	1
The [[Definition:Unlimited Register Machine#Null Program|null URM program]] by definition has no instructions. Therefore, the contents of $R_1$ remain unchanged when "running" it. {{qed}} [[Category:URM Programs]] [[Category:Identity Mappings]] tvva77btbxxa4siytxywya9ssbokgg2	1
From [[Functionally Complete Logical Connectives/Negation and Conjunction|Functionally Complete Logical Connectives: Negation and Conjunction]], we can represent any boolean expression in terms of $\land$ and $\neg$. From [[Conjunction and Implication]], we have that: :$p \land q \dashv \vdash \neg \paren {p \implies \neg q}$ So it follows that we can replace all occurrences of $\land$ by $\implies$ and $\neg$. Thus $\set {\neg, \implies}$ is [[Definition:Functionally Complete|functionally complete]]. {{qed}}	1
Let $\land$ denote the [[Definition:Conjunction|conjunction operation]] of [[Definition:Propositional Logic|propositional logic]]. Then there exists no [[Definition:Binary Logical Connective|binary logical connective]] $\circ$ such that: :$(1): \quad \forall p, q \in \left\{{T, F}\right\}: \left({p \land q}\right) \circ q = p$	1
Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \Z_{> 0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\paren {r \paren {\cos x + i \sin x} }^n = r^n \paren {\map \cos {n x} + i \, \map \sin {n x} }$ $\map P 1$ is the case: :$\paren {r \paren {\cos x + i \sin x} }^1 = r^1 \paren {\map \cos {1 x} + i \, \map \sin {1 x} }$ which is trivially true. === Basis for the Induction === $\map P 2$ is the case: :$\paren {r \paren {\cos x + i \sin x} }^2 = r^2 \paren {\map \cos {n x} + i \, \map \sin {2 x} }$ From [[Product of Complex Numbers in Polar Form]], we have: :$r_1 \paren {\cos x_1 + i \sin x_1 } r_2 \paren {\cos x_2 + i \sin x_2} = r_1 r_2 \paren {\map \cos {x_1 + x_2} + i \, \map \sin {x_1 + x_2} }$ Setting $r_1 = r_2 = r$ and $x_1 = x_2 = x$ gives the result. This is our [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$\paren {r \paren {\cos x + i \sin x} }^k = r^k \paren {\map \cos {k x} + i \, \map \sin {k x} }$ Then we need to show: :$\paren {r \paren {\cos x + i \sin x} }^{k + 1} = r^{k + 1} \paren {\map \cos {\paren {k + 1} x} + i \, \map \sin {\paren {k + 1} x} }$ === Induction Step === This is our [[Principle of Mathematical Induction#Induction Step|induction step]]: {{begin-eqn}} {{eqn| l = \paren {r \paren {\cos x + i \sin x} }^{k + 1} | r = \paren {r \paren {\cos x + i \sin x} }^k \paren {r \paren {\cos x + i \sin x} } }} {{eqn| r = r^k \paren {\map \cos {k x} + i \, \map \sin {k x} } \paren {r \paren {\cos x + i \sin x} } | c = [[De Moivre's Formula/Positive Integer Index/Proof 1#Induction Hypothesis|Induction Hypothesis]] }} {{eqn| r = r^{k + 1} \paren {\map \cos {\paren {k + 1} x} + i \, \map \sin {\paren {k + 1} x} } | c = [[Product of Complex Numbers in Polar Form]] }} {{end-eqn}} Hence, by [[Principle of Mathematical Induction|induction]], for all $n \in \Z_{> 0}$: :$\paren {r \paren {\cos x + i \sin x} }^n = r^n \paren {\map \cos {n x} + i \, \map \sin {n x} }$ {{qed}}	1
Let $\downarrow$ signify the [[Definition:Logical NOR|NOR]] operation. Then there exist [[Definition:Proposition|propositions]] $p, q, r$ such that: :$p \downarrow \paren {q \downarrow r} \not \vdash \paren {p \downarrow q} \downarrow r$ That is, [[Definition:Logical NOR|NOR]] is not [[Definition:Associative|associative]].	1
:$\vdash \paren {p \implies \paren {q \implies r} } \implies \paren {\paren {p \land q} \implies r}$	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc||ccc|} \hline p & \oplus & q & q & \oplus & p \\ \hline F & F & F & F & F & F \\ F & T & T & T & T & F \\ T & T & F & F & T & T \\ T & F & T & T & F & T \\ \hline \end{array}$ {{qed}}	1
We can immediately see that $\Bbb I$ is [[Definition:Infinite|infinite]] as, for example, $\phi: \N \to \Bbb I$ defined as: :$\phi \left({n}\right) = Z \left({n}\right)$ is definitely [[Definition:Injection|injective]]. From [[Unique Code for URM Instruction]], we see that $\beta: \Bbb I \to \N$ is also an [[Definition:Injection|injection]]. The result follows from [[Domain of Injection to Countable Set is Countable]]. {{qed}} [[Category:URM Programs]] [[Category:Countable Sets]] n69gjs30q6i5j68nxtq7ihj5mlfxb16	1
Proceed by the [[Principle of Structural Induction]] on the [[Definition:Term (Predicate Logic)|definition of term]], applied to $\beta$. If $\beta = y$ for some [[Definition:Variable (Logic)|variable]] $y$, then: :$\beta \left({x \gets \tau}\right) = \begin{cases} \tau &: \text{if $y = x$} \\ y &: \text{otherwise} \end{cases}$ In the first case: {{begin-eqn}} {{eqn|l = \mathop{ \operatorname{val}_{\mathcal A} \left({\beta \left({x \gets \tau}\right) }\right) } \left[{\sigma}\right] |r = \mathop{ \operatorname{val}_{\mathcal A} \left({\tau }\right) } \left[{\sigma}\right] }} {{eqn|r = a |c = Definition of $a$ }} {{eqn|r = \left({\sigma + \left({x / a}\right)}\right) \left({x}\right) |c = Definition of [[Definition:Extension of Assignment|Extension of Assignment]] }} {{eqn|r = \mathop{ \operatorname{val}_{\mathcal A} \left({\beta }\right) } \left[{\sigma + \left({x / a}\right)}\right] |c = Definition of [[Definition:Value of Term under Assignment|value under $\sigma + \left({x / a}\right)$]] }} {{end-eqn}} In the second case: {{begin-eqn}} {{eqn|l = \mathop{ \operatorname{val}_{\mathcal A} \left({\beta \left({x \gets \tau}\right) }\right) } \left[{\sigma}\right] |r = \mathop{ \operatorname{val}_{\mathcal A} \left({y}\right) } \left[{\sigma}\right] }} {{eqn|r = \sigma \left({y}\right) |c = Definition of [[Definition:Value of Term under Assignment|value under $\sigma$]] }} {{eqn|r = \left({\sigma + \left({x / a}\right)}\right) \left({y}\right) |c = Definition of [[Definition:Extension of Assignment|Extension of Assignment]] }} {{eqn|r = \mathop{ \operatorname{val}_{\mathcal A} \left({\beta }\right) } \left[{\sigma + \left({x / a}\right)}\right] |c = Definition of [[Definition:Value of Term under Assignment|value under $\sigma + \left({x / a}\right)$]] }} {{end-eqn}} as desired. If $\beta = f \left({\tau_1, \ldots, \tau_n}\right)$ and the induction hypothesis holds for $\tau_1, \ldots, \tau_n$, then: :$\beta \left({x \gets \tau}\right) = f \left({ \tau_1 \left({x \gets \tau}\right), \ldots, \tau_n \left({x \gets \tau}\right) }\right)$ Now: {{begin-eqn}} {{eqn|l = \mathop{ \operatorname{val}_{\mathcal A} \left({\beta \left({x \gets \tau}\right) }\right) } \left[{\sigma}\right] |r = \mathop{ \operatorname{val}_{\mathcal A} \left({f \left({ \tau_1 \left({x \gets \tau}\right), \ldots, \tau_n \left({x \gets \tau}\right) }\right) }\right) } \left[{\sigma}\right] }} {{eqn|r = f_{\mathcal A} \left({ \mathop{ \operatorname{val}_{\mathcal A} \left({\tau_1 \left({x \gets \tau}\right)}\right) } \left[{\sigma}\right], \ldots, \mathop{ \operatorname{val}_{\mathcal A} \left({\tau_n \left({x \gets \tau}\right)}\right) } \left[{\sigma}\right] }\right) |c = Definition of [[Definition:Value of Term under Assignment|value under $\sigma$]] }} {{eqn|r = f_{\mathcal A} \left({ \mathop{ \operatorname{val}_{\mathcal A} \left({\tau_1}\right) } \left[{\sigma + \left({x / a}\right)}\right], \ldots, \mathop{ \operatorname{val}_{\mathcal A} \left({\tau_n}\right) } \left[{\sigma + \left({x / a}\right)}\right] }\right) |c = Induction Hypothesis }} {{eqn|r = \mathop{ \operatorname{val}_{\mathcal A} \left({\beta}\right) } \left[{\sigma + \left({x / a}\right)}\right] |c = Definition of [[Definition:Value of Term under Assignment|value under $\sigma + \left({x / a}\right)$]] }} {{end-eqn}} as desired. The result follows by the [[Principle of Structural Induction]]. {{qed}}	1
Let $\struct {P, s, 0}$ be a [[Definition:Peano Structure|Peano structure]]. Let $\map Q n$ be a [[Definition:Propositional Function|propositional function]] depending on $n \in P$. Suppose that: :$(1): \quad \map Q 0$ is [[Definition:True|true]] :$(2): \quad \forall n \in P: \map Q n \implies \map Q {\map s n}$ Then: :$\forall n \in P: \map Q n$	1
Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \N_{>0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\ds \sum_{j \mathop = 1}^{2 n - 1} F_j F_{j + 1} = {F_{2 n} }^2$ === Basis for the Induction === $\map P 1$ is true, as this just says $F_1 F_2 = 1 \times 1 = 1 = {F_2}^2$. This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\ds \sum_{j \mathop = 1}^{2 k - 1} F_j F_{j + 1} = {F_{2 k} }^2$ Then we need to show: :$\ds \sum_{j \mathop = 1}^{2 k + 1} F_j F_{j + 1} = {F_{2 \paren {k + 1} } }^2$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \sum_{j \mathop = 1}^{2 k + 1} F_j F_{j + 1} | r = \sum_{j \mathop = 1}^{2 k - 1} F_j F_{j + 1} + F_{2 k} F_{2 k + 1} + F_{2 k + 1} F_{2 k + 2} | c = }} {{eqn | r = {F_{2 k} }^2 + F_{2 k} F_{2 k + 1} + F_{2 k + 1} F_{2 k + 2} | c = [[Sum of Odd Sequence of Products of Consecutive Fibonacci Numbers#Induction Hypothesis|Induction hypothesis]] }} {{eqn | r = F_{2 k} \paren {F_{2 k} + F_{2 k + 1} } + F_{2 k + 1} F_{2 k + 2} | c = }} {{eqn | r = F_{2 k} F_{2 k + 2} + F_{2 k + 1} F_{2 k + 2} | c = }} {{eqn | r = F_{2 k + 2} \paren {F_{2 k} + F_{2 k + 1} } | c = }} {{eqn | r = {F_{2 k + 2} }^2 | c = }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\ds \forall n \ge 1: \sum_{j \mathop = 1}^{2 n - 1} F_j F_{j + 1} = {F_{2 n} }^2$ {{qed}}	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc||cccccc|} \hline p & \land & q & \neg & (\neg & p & \lor & \neg & q) \\ \hline F & F & F & F & T & F & T & T & F \\ F & F & T & F & T & F & T & F & T \\ T & F & F & F & F & T & T & T & F \\ T & T & T & T & F & T & F & F & T \\ \hline \end{array}$ {{qed}}	1
By assumption, some [[Definition:Logical Formula|logical formula]] $\phi$ is not an $\mathscr M$-[[Definition:Tautology (Formal Semantics)|tautology]]. Since $\mathscr P$ is [[Definition:Sound Proof System|sound]] for $\mathscr M$, $\phi$ is also not a $\mathscr P$-[[Definition:Theorem (Formal Systems)|theorem]]. But then by definition $\mathscr P$ is [[Definition:Consistent Proof System|consistent]]. {{qed}}	1
{{BeginTableau|\left({\left({p \implies r}\right) \lor \left({q \implies r}\right)}\right) \iff \left({\left({p \land q}\right) \implies r}\right)}} {{Assumption|1|\left({p \implies r}\right) \lor \left({q \implies r}\right)}} {{SequentIntro|2|1|\left({p \land q}\right) \implies r|1|[[Principle of Composition/Formulation 1/Forward Implication|Principle of Composition/Formulation 1]]}} {{Implication|3||\left({\left({p \implies r}\right) \lor \left({q \implies r}\right)}\right) \implies \left({\left({p \land q}\right) \implies r}\right)|1|2}} {{Assumption|4|\left({p \implies r}\right) \lor \left({q \implies r}\right)}} {{SequentIntro|5|4|\left({p \land q}\right) \implies r|4|[[Principle of Composition/Formulation 1/Reverse Implication|Principle of Composition/Formulation 1]]}} {{Implication|6||\left({\left({p \land q}\right) \implies r}\right) \implies \left({\left({p \implies r}\right) \lor \left({q \implies r}\right)}\right)|4|5}} {{BiconditionalIntro|7||\left({\left({p \implies r}\right) \lor \left({q \implies r}\right)}\right) \iff \left({\left({p \land q}\right) \implies r}\right)|3|6}} {{EndTableau}} {{qed}}	1
The '''specific form''' of a given [[Definition:Logical Argument|logical argument]] is that [[Definition:Argument Form|argument form]] from which the [[Definition:Logical Argument|logical argument]] results from replacing each [[Definition:Distinct Elements|distinct]] [[Definition:Statement Variable|statement variable]] by a different [[Definition:Simple Statement|simple statement]].	1
{{BeginTableau|p \iff q, q \iff r \vdash p \iff r}} {{Premise|1|p \iff q}} {{Premise|2|q \iff r}} {{BiconditionalElimination|3|1|p \implies q|1|1}} {{BiconditionalElimination|4|2|q \implies r|2|1}} {{SequentIntro|5|1, 2|p \implies r|1, 2|[[Hypothetical Syllogism/Formulation 1|Hypothetical Syllogism: Formulation 1]]}} {{BiconditionalElimination|6|1|q \implies p|1|2}} {{BiconditionalElimination|7|2|r \implies q|2|2}} {{SequentIntro|8|1, 2|r \implies p|7, 6|[[Hypothetical Syllogism/Formulation 1|Hypothetical Syllogism: Formulation 1]]}} {{BiconditionalIntro|9|1, 2|p \iff r|5|8}} {{EndTableau}}	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the appropriate [[Definition:Truth Value|truth values]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc||ccccc|} \hline p & \implies & q & q & \iff & (p & \lor & q) \\ \hline F & T & F & F & T & F & F & F \\ F & T & T & T & T & F & T & T \\ T & F & F & F & F & T & T & F \\ T & T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
The [[Definition:Language of Propositional Logic|language of propositional logic]] $\mathcal L_0$ has [[Definition:Unique Parsability|unique parsability]].	1
:$\vdash \paren {p \iff q} \iff \paren {\paren {p \land q} \lor \paren {\neg p \land \neg q} }$	1
Let $\mathcal L$ be a [[Definition:Logical Language|logical language]]. Let $\mathscr M$ be a [[Definition:Formal Semantics|formal semantics]] for $\mathcal L$. Let $\mathcal F$ be an [[Definition:Satisfiable Set of Formulas|$\mathscr M$-satisfiable set of formulas]] from $\mathcal L$. Let $\phi$ be a [[Definition:Tautology (Formal Semantics)|tautology]] for $\mathscr M$. Then $\mathcal F \cup \left\{{\phi}\right\}$ is also [[Definition:Satisfiable Set of Formulas|$\mathscr M$-satisfiable]].	1
==== [[Implication Equivalent to Negation of Conjunction with Negative/Formulation 1|Formulation 1]] ==== {{:Implication Equivalent to Negation of Conjunction with Negative/Formulation 1}} ==== [[Implication Equivalent to Negation of Conjunction with Negative/Formulation 2|Formulation 2]] ==== {{:Implication Equivalent to Negation of Conjunction with Negative/Formulation 2}}	1
{{BeginTableau|p \implies \top \vdash \top}} {{Premise|1|p \implies \top}} {{TopIntro|2}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|\top \vdash p \implies \top}} {{Assumption|1|p}} {{Premise|2|\top}} {{Implication|3|1|p \implies \top|1|2}} {{EndTableau}} {{qed}}	1
Let $\mathcal F$ be a [[Definition:Set|set]] of [[Definition:Logical Formula|$\mathcal L$-formulas]]. Then the '''$\mathcal L$-theory of $\mathcal F$''', denoted $T \left({\mathcal F}\right)$ is the [[Definition:Set|set]]: :$\left\{{\phi \in \mathcal L: \mathcal F \models_{\mathscr M} \phi}\right\}$ where $\models_{\mathscr M}$ denotes [[Definition:Semantic Consequence|$\mathscr M$-semantic consequence]].	1
Let $\mathbf A$ be a [[Definition:WFF of Propositional Logic|WFF of propositional logic]]. Let $T$ be a [[Definition:Completed Tableau|completed tableau]] for $\mathbf A$. Suppose that $T$ is [[Definition:Closed Tableau|closed]]. Then $\mathbf A$ is [[Definition:Unsatisfiable (Boolean Interpretations)|unsatisfiable for boolean interpretations]].	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc||ccccc|} \hline p & \uparrow & q & \neg & p & \lor & \neg & q \\ \hline F & T & F & T & F & T & T & F \\ F & T & T & T & F & T & F & T \\ T & T & F & F & T & T & T & F \\ T & F & T & F & T & F & F & T \\ \hline \end{array}$ {{qed}}	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for each [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c||ccc|} \hline p & p & \land & p \\ \hline T & T & T & T \\ F & F & F & F \\ \hline \end{array}$ {{qed}}	1
:$\vdash \paren {p \implies q} \implies \paren {\neg q \implies \neg p}$	1
{{begin-eqn}} {{eqn | lo= \forall n \ge 1: | l = \sum_{j \mathop = 1}^n F_{2 j} | r = F_2 + F_4 + F_6 + \cdots + F_{2 n} | c = }} {{eqn | r = F_{2 n + 1} - 1 | c = }} {{end-eqn}}	1
{{BeginTableau|\vdash \paren {p \lor \paren {q \lor r} } \iff \paren {\paren {p \lor q} \lor r} }} {{Assumption |1|p \lor \paren {q \lor r} }} {{SequentIntro|2|1|\paren {p \lor q} \lor r|1|[[Rule of Association/Disjunction/Formulation 1|Rule of Association: Formulation 1]]}} {{Implication |3||\paren {p \lor \paren {q \lor r} } \implies \paren {\paren {p \lor q} \lor r}|1|2}} {{Assumption |4|\paren {p \lor q} \lor r}} {{SequentIntro|5|4|p \lor \paren {q \lor r}|4|[[Rule of Association/Disjunction/Formulation 1|Rule of Association: Formulation 1]]}} {{Implication |6||\paren {\paren {p \lor q} \lor r} \implies \paren {p \lor \paren {q \lor r} }|4|5}} {{BiconditionalIntro|7||\paren {p \lor \paren {q \lor r} } \iff \paren {\paren {p \lor q} \lor r}|3|6}} {{EndTableau}} {{qed}}	1
Let $U$ be a [[Definition:Set|set]] of [[Definition:WFF of Propositional Logic|WFFs of propositional logic]]. Then $U$ is a [[Definition:Theorem (Formal Systems)|$\mathscr G$-theorem]] [[Definition:Iff|iff]]: :$\bar U$ has a [[Definition:Closed Tableau|closed semantic tableau]] where $\bar U$ is the [[Definition:Set|set]] comprising the [[Definition:Logical Complement|logical complements]] of all [[Definition:WFF of Propositional Logic|WFFs]] in $U$.	1
Let $\sequence {a_n}$, $\sequence {b_n}$ and $\sequence {c_n}$ be [[Definition:Sequence|sequences]] of [[Definition:Real Number|real]] or [[Definition:Complex Number|complex numbers]]. Let $a_n = \map \OO {\sequence {b_n} }$ and $b_n = \map \OO {\sequence {c_n} }$, where $O$ denotes [[Definition:Big-O Notation for Sequences|big-O notation]]. Then $a_n = \map \OO {\sequence {c_n} }$.	1
We apply the [[Method of Truth Tables]]. $\begin{array}{|c|c||ccc|} \hline p & q & p & \land & q\\ \hline F & F & F & F & F \\ F & T & F & F & T \\ T & F & T & F & F \\ T & T & T & T & T \\ \hline \end{array}$ As can be seen, only when both $p$ and $q$ are [[Definition:True|true]], then so is $p \land q$. {{qed}}	1
We apply the [[Method of Truth Tables]]. $\begin{array}{|ccc||c|} \hline p & \land & q & p \\ \hline F & F & F & F \\ F & F & T & F \\ T & F & F & T \\ T & T & T & T \\ \hline \end{array}$ As can be seen, when $p \land q$ is [[Definition:True|true]] so is $p$. {{qed}}	1
For a [[Definition:Definition|definition]] to not be [[Definition:Circular Definition|circular]], the definer must use already defined terms. However, this process cannot go on indefinitely. If we were to insist on ''everything'' being defined only using previously defined terms, we would enter an infinite regress. Concepts that are not defined in terms of previously defined concepts are called '''undefined terms'''. An undefined term is frequently explained by using an [[Definition:Ostensive Definition|ostensive definition]]: that is, a [[Definition:Statement|statement]] that ''shows'' what something is, rather than ''explains''.	1
: $p \iff q \dashv \vdash q \iff p$	1
When translating from a series of sentences in [[Definition:Natural Language|natural language]] into a collection of [[Definition:Propositional Formula|propositional formulas]] in [[Definition:Symbolic Logic|symbolic logic]], it is necessary to replace each [[Definition:Simple Statement|simple statement]] with a [[Definition:Statement Label|statement label]]. As stated in the definition of [[Definition:Statement Label|statement label]], it is imperative that each sentence be replaced with a different label. A '''scheme of abbreviation''' is the list of [[Definition:Simple Statement|simple statements]], together with their associated [[Definition:Statement Label|statement labels]], for reference and unambiguous key in order to translate any [[Definition:Conclusion|conclusion]] reached back into [[Definition:Natural Language|natural language]].	1
There is a disjoint [[Definition:Decomposition (Topology)|decomposition]] of the [[Definition:Sphere (Topology)|sphere]] $\mathbb S^2$ into four sets $A, B, C, D$ such that $A, B, C, B \cup C$ are all [[Definition:Congruence (Topology)|congruent]] and $D$ is [[Definition:Countable|countable]].	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] are [[Definition:True|true]] for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc|c|cccc|} \hline (p & \implies & q) & \iff & (\neg & p & \lor & q) \\ \hline F & T & F & T & T & F & T & F \\ F & T & T & T & T & F & T & T \\ T & F & F & F & T & T & F & F \\ T & T & T & F & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
: $p \dashv \vdash p \lor p$	1
Let $\hat o_1, \ldots, \hat o_m$ be a [[Definition:Finite Sequence|finite sequence]] of [[Definition:Elementary Row Operation|elementary row operations]]. Here, $\hat o_i$ denotes an [[Definition:Elementary Row Operation|elementary row operation]] on a [[Definition:Square Matrix|square matrix]] of [[Definition:Order of Square Matrix|order $n$]] over a [[Definition:Commutative Ring|commutative]] [[Definition:Ring with Unity|ring with unity]] $\struct {R, +, \circ}$. Here, $i \in \set {1, \ldots, m}$. Then there exists $c \in R$ such that for all [[Definition:Square Matrix|square matrices]] of [[Definition:Order of Square Matrix|order $n$]] $\mathbf A$ over $R$: :$\map \det {\mathbf A} = c \map \det {\mathbf A'}$ where $\mathbf A'$ is the [[Definition:Square Matrix|square matrix]] of [[Definition:Order of Square Matrix|order $n$]] that results from applying the [[Definition:Elementary Row Operation|elementary row operations]] $\hat o_1, \ldots, \hat o_m$ on $\mathbf A$.	1
Let $S \left({\MM}\right)$ denote the [[Definition:Set|set]] containing all [[Definition:Complete Type|complete types]] over $M$ of every number of [[Definition:Free Variable|free variables]]. Let $\kappa = \left\vert{S \left({\MM}\right)}\right\vert$. Use a [[Definition:Bijection|bijection]] between $\kappa$ and $S \left({\MM}\right)$ to write the [[Definition:Element|elements]] of $S \left({\MM}\right)$ as $p_\alpha$ for $\alpha < \kappa$. For each $\alpha < \kappa$, let $N_\alpha$ be an [[Definition:Elementary Extension|elementary extension]] of $\MM$ which has an [[Definition:Ordered Tuple|ordered tuple]] $\bar a_\alpha$ [[Definition:Realization|realizing]] $p_\alpha$. Such [[Definition:Elementary Extension|extensions]] and [[Definition:Ordered Tuple|tuples]] exist by [[Type is Realized in some Elementary Extension]]. We will construct the [[Definition:Elementary Extension|extension]] claimed by the theorem as the [[Definition:Union|union]] over a [[Definition:Chain of Elementary Extensions|chain of elementary extensions]] defined using [[Transfinite Induction]]. At each step, we use the [[Elementary Amalgamation Theorem]] to add on $N_\alpha$. Base case $\alpha = 0$: Let $\BB_0 = \MM$. Note that $\BB_0$ is an [[Definition:Elementary Extension|elementary extension]] of $\MM$ by choice of $\NN_0$. [[Definition:Limit Ordinal|Limit ordinals]] $\alpha \le \kappa$: Let $\displaystyle \BB_\alpha = \bigcup_{\beta \mathop < \alpha} \BB_\beta$ $\BB_\alpha$ is an [[Definition:Elementary Extension|elementary extension]] of $\MM$ by [[Union of Elementary Chain is Elementary Extension]]. [[Definition:Successor Ordinal|Successor ordinals]] $\alpha + 1$ for $\alpha < \kappa$: We have that $\BB_\alpha$ and $\NN_\alpha$ are both [[Definition:Elementary Extension|elementary extensions]] of $\MM$. By the [[Elementary Amalgamation Theorem]], there is: :an [[Definition:Elementary Extension|elementary extension]] $\BB_{\alpha + 1}$ of $\BB_\alpha$ and: :an [[Definition:Elementary Embedding|elementary embedding]] $g_\alpha: \NN_\alpha \to \BB_{\alpha + 1}$ which is the [[Definition:Identity Mapping|identity]] on $M$ viewed as a [[Definition:Subset|subset]] of $\NN_\alpha$. Note that $\map {g_\alpha} {\bar a_\alpha}$ [[Definition:Realization|realizes]] $p_\alpha$ in $\BB_{\alpha + 1}$ since $g_\alpha$ is [[Definition:Elementary Embedding|elementary]]. Thus $\BB_{\alpha + 1}$ is an [[Definition:Elementary Extension|elementary extension]] of $\MM$ which contains $\map {g_\alpha} {\bar a_\alpha}$ [[Definition:Realization|realizing]] $p_\alpha$. Now, let $\displaystyle \BB = \bigcup_{\alpha < \kappa} \BB_\alpha$. $\BB$ is an [[Definition:Elementary Extension|elementary extension]] of each $\BB_\alpha$ by [[Union of Elementary Chain is an Elementary Extension]]. In particular, $\BB$ is an [[Definition:Elementary Extension|elementary extension]] of $\BB_0 = \MM$ We have that: :each $p_\alpha$ is [[Definition:Realization|realized]] in $\BB_{\alpha + 1}$ by the corresponding $\map {g_\alpha} {\bar a_\alpha}$ and: :$\BB$ is an [[Definition:Elementary Extension|elementary extension]] of each $\BB_{\alpha + 1}$ Thus we have that $\map {g_\alpha} {\bar a_\alpha}$ [[Definition:Realization|realizes]] $p_\alpha$ in $\BB$. {{qed}} [[Category:Model Theory]] nydyqgv6evfgf48xvhhom5vczk5retb	1
: $p \iff q \dashv \vdash \paren {p \land q} \lor \paren {\neg p \land \neg q}$	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, in each case, the [[Definition:Truth Value|truth values]] in the appropriate columns match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c|c||ccc|} \hline p & \top & p & \lor & \top \\ \hline F & T & F & T & T \\ T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
The proof proceeds by [[Principle of General Induction for Minimally Closed Class|general induction]]. Let an [[Definition:Element of Class|element]] $x$ of $M$ be defined as: :'''[[Definition:Left Normal Element of Relation|left normal]]''' with respect to $\RR$ {{iff}} $\map \RR {x, y}$ for all $y \in M$ :'''[[Definition:Right Normal Element of Relation|right normal]]''' with respect to $\RR$ {{iff}} $\map \RR {y, x}$ for all $y \in M$. Let the hypothesis be assumed. First we demonstrate a [[Definition:Lemma|lemma]]: === [[Double Induction Principle/Minimally Closed Class/Lemma|Lemma]] === {{:Double Induction Principle/Minimally Closed Class/Lemma}}{{qed|lemma}} We now show by [[Principle of General Induction for Minimally Closed Class|general induction]] that every $x \in M$ is [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$. It then follows from the [[Double Induction Principle/Lemma|lemma]] that $\map \RR {x, y}$ for all $x, y \in M$. === Basis for the Induction === $\map P b$ is the case: From condition $\text D_1$ of the definition of $\RR$, we have immediately that: :$\map \RR {x, b}$ for all $x \in M$. That is, that $b$ is [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$. Thus $\map P b$ is seen to hold. This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that if $\map P x$ is true, where $x \in M$, then it logically follows that $\map P {\map g x}$ is true. So this is the [[Definition:Induction Hypothesis|induction hypothesis]]: :$x$ is [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$ from which it is to be shown that: :$\map g x$ is [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$. === Induction Step === This is the [[Definition:Induction Step|induction step]]: Let $x \in M$ be [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$: :$\forall y \in M: \map \RR {y, x}$ By the [[Double Induction Principle/Minimally Closed Class/Lemma|lemma]] we have that $x$ is [[Definition:Left Normal Element of Relation|left normal]] with respect to $\RR$. That is: :$\forall y \in M: \map \RR {x, y}$ Thus by condition $\text D_2$ of the definition of $\RR$: :$\forall y \in M: \map \RR {y, \map g x}$ That is, $\map g x$ is [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$. So $\map P x \implies \map P {\map g x}$ and by the [[Principle of General Induction for Minimally Closed Class]]: :$\forall x \in M$: $x$ is [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$. The result follows. {{qed}} [[Category:Double Induction Principle]] sgs8i1n37qyxovpj6s2h76yrccn4xtn	1
As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccccc||c|} \hline \neg & p & \implies & (q & \land & \neg & q) & p \\ \hline T & F & F & F & F & T & F & F \\ T & F & F & T & F & F & T & F \\ F & T & T & F & F & T & F & T \\ F & T & T & T & F & F & T & T \\ \hline \end{array}$ {{qed}}	1
{{BeginTableau|\neg p \implies q \vdash p \lor q}} {{Premise|1|\neg p \implies q}} {{ExcludedMiddle|2|p \lor \neg p}} {{Assumption|3|p}} {{Addition|4|3|p \lor q|3|1}} {{Assumption|5|\neg p}} {{ModusPonens|6|1, 5|q|1|5}} {{Addition|7|1, 5|p \lor q|6|2}} {{ProofByCases|8|1|p \lor q|2|3|4|5|7}} {{EndTableau|qed}} {{LEM}}	1
Apply the [[Method of Truth Tables]]: :$\begin{array}{|ccccc||ccccc|} \hline p & \downarrow & (q & \downarrow & r) & (p & \downarrow & q) & \downarrow & r \\ \hline F & F & F & T & F & F & T & F & F & F \\ F & T & F & F & T & F & T & F & F & T \\ F & T & T & F & F & F & F & T & T & F \\ F & T & T & F & T & F & F & T & F & T \\ T & F & F & T & F & T & F & F & T & F \\ T & F & F & F & T & T & F & F & F & T \\ T & F & T & F & F & T & F & T & T & F \\ T & F & T & F & T & T & F & T & F & T \\ \hline \end{array}$ As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] do not match for all [[Definition:Boolean Interpretation|boolean interpretations]]. {{qed}}	1
The [[Rule of Conjunction]] can be symbolised in [[Definition:Sequent|sequent]] form as follows:	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc||ccccc|} \hline p & \lor & (q & \lor & r) & (p & \lor & q) & \lor & r \\ \hline F & F & F & F & F & F & F & F & F & F \\ F & T & F & T & T & F & F & F & T & T \\ F & T & T & T & F & F & T & T & T & F \\ F & T & T & T & T & F & T & T & T & T \\ T & T & F & F & F & T & T & F & T & F \\ T & T & F & T & T & T & T & F & T & T \\ T & T & T & T & F & T & T & T & T & F \\ T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
{{BeginTableau|p \iff q \vdash \left({p \lor q}\right) \implies \left({p \land q}\right)}} {{Premise|1|p \iff q}} {{SequentIntro|2|1|\left({p \land q}\right) \lor \left({\neg p \land \neg q}\right)|1|[[Biconditional as Disjunction of Conjunctions]]}} {{DeMorgan|3|1|\left({p \land q}\right) \lor \neg \left({p \lor q}\right)|2|Conjunction of Negations}} {{Commutation|4|1|\neg \left({p \lor q}\right) \lor \left({p \land q}\right)|3|Disjunction}} {{SequentIntro|5|1|\left({p \lor q}\right) \implies \left({p \land q}\right)|4|[[Rule of Material Implication]]}} {{EndTableau}} {{qed}} [[Category:Biconditional iff Disjunction implies Conjunction]] bjqipywjtsnh5w8bf5072djd3n8usvn	1
Let $f: \mathbb B^k \to \mathbb B$ be a [[Definition:Truth Function|truth function]]. The [[Definition:Domain of Mapping|domain]] of $f$ has $2^k$ elements, from [[Cardinality of Cartesian Product]]. The result follows from [[Cardinality of Set of All Mappings]]. {{qed}}	1
Let the statements $P_1, P_2, \ldots, P_n$ be [[Definition:Conclusion|conclusions]] in a [[Definition:Proof|proof]], on various [[Definition:Assumption|assumptions]]. Let $P_1, P_2, \ldots, P_n \vdash Q$ be a [[Definition:Substitution Instance|substitution instance]] of a [[Definition:Sequent|sequent]] for which we already have a proof. {{explain|Question the use of "substitution instance": can we not "just" allow for $P_1, \ldots, P_n$ to be "just" statements?}} Then we may introduce, at any stage of a proof (citing '''SI'''), either: :The [[Definition:Conclusion|conclusion]] $Q$ of the [[Definition:Sequent|sequent]] already proved or: :A [[Definition:Substitution Instance|substitution instance]] of such a [[Definition:Conclusion|conclusion]], together with a reference to the [[Definition:Sequent|sequent]] that is being cited. This conclusion depend upon the [[Definition:Pool of Assumptions|pool of assumptions]] upon which $P_1, P_2, \ldots, P_n \vdash Q$ rests.	1
Let $(a_n)$ and $(b_n)$ be [[Definition:Sequence|sequences]] of [[Definition:Real Number|real]] or [[Definition:Complex Number|complex numbers]]. Let $a_n = O(b_n)$ where $O$ denotes [[Definition:Big-O Notation|big-O notation]]. Let $(n_k)$ be a [[Definition:Divergent Sequence|diverging sequence]] of [[Definition:Natural Number|natural numbers]]. Then $a_{n_k} = O(b_{n_k})$.	1
We will use a proof by [[Principle of Mathematical Induction|induction]] on the [[Definition:Length of Continued Fraction|length]] $n$. For all $n \in \Z_{>0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\sqbrk {a_0, a_1, \ldots, a_n} = \dfrac {p_n} {q_n}$ === Basis for the Induction === $\map P 0$ is the case: :$\sqbrk {a_0} = \dfrac {a_0} 1 = \dfrac {p_0} {q_0}$ This holds for any [[Definition:Continued Fraction|continued fraction]]. $\map P 1$ is the case: {{begin-eqn}} {{eqn | l = \sqbrk {a_0, a_1} | r = a_0 + \frac 1 {a_1} }} {{eqn | r = \frac {a_0 a_1 + 1} {a_1} }} {{eqn | r = \frac {p_1} {q_1} }} {{end-eqn}} This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\sqbrk {a_0, a_1, \ldots, a_k} = \dfrac {p_k} {q_k}$ Then we need to show: :$\sqbrk {a_0, a_1, \ldots, a_k, a_{k + 1} } = \dfrac {p_{k + 1} } {q_{k + 1} }$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: Consider the [[Definition:Continued Fraction|continued fraction]]: :$\sqbrk {a_0, a_1, \ldots, a_k, a_{k + 1} }$ The [[Definition:Numerator|numerators]] are: :$p_0, p_1, \ldots, p_k, p_{k + 1}$ and the [[Definition:Denominator|denominators]] are: :$q_0, q_1, \ldots, q_k, q_{k + 1}$ By definition of [[Definition:Value of Finite Continued Fraction|value of a finite continued fraction]]: :$\sqbrk {a_0, a_1, \ldots, a_k, a_{k + 1} } = \sqbrk {a_0, a_1, \ldots, a_{k - 1}, a_k'}$ where $a_k' = a_k + \dfrac 1 {a_{k + 1} }$ Consider the {{RHS}}. Take the [[Definition:Continued Fraction|continued fraction]]: :$\sqbrk {a_0, a_1, \ldots, a_{k - 1}, a_k'}$ Its [[Definition:Numerator|numerators]] are: :$p_0, p_1, \ldots, p_{k-1}$ and $p_k'$ where $p_k' = \paren {a_k + \dfrac 1 {a_{k + 1} } } p_{k - 1} + p_{k - 2}$ by definition. Its [[Definition:Denominator|denominators]] are: :$q_0, q_1, \ldots, p_{k - 1}$ and $q_k'$ where $q_k' = \paren {a_k + \dfrac 1 {a_{k + 1} } } q_{k - 1} + q_{k - 2}$ by definition. As it has just $k$ [[Definition:Partial Quotient|partial quotients]], the [[Value of Finite Continued Fraction equals Numerator Divided by Denominator#Induction Hypothesis|induction hypothesis]] tells us that its value is: :$\dfrac {p_k'} {q_k'}$ So: {{begin-eqn}} {{eqn | l = \sqbrk {a_0, a_1, \ldots, a_k, a_{k + 1} } | r = \frac {p_k'} {q_k'} | c = }} {{eqn | r = \frac {\paren {a_k + \frac 1 {a_{k + 1} } } p_{k - 1} + p_{k - 2} } {\paren {a_k + \frac 1 {a_{k + 1} } } q_{k - 1} + q_{k - 2} } | c = }} {{eqn | r = \frac {a_{k + 1} \paren {a_k p_{k - 1} + p_{k - 2} } + p_{k - 1} } {a_{k + 1} \paren {a_k q_{k - 1} + q_{k - 2} } + q_{k - 1} } | c = }} {{eqn | r = \frac {a_{k + 1} p_k + p_{k - 1} } {a_{k + 1} q_k + q_{k - 1} } | c = }} {{eqn | r = \frac {p_{k + 1} } {q_{k + 1} } | c = }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\sqbrk {a_0, a_1, \ldots, a_k, a_{k + 1} } = \dfrac {p_{k + 1} } {q_{k + 1} }$ {{qed}} [[Category:Continued Fractions]] [[Category:Proofs by Induction]] koba2avyl8b5h1kyqcgccqhkffnryi2	1
Let $\downarrow$ signify the [[Definition:Logical NOR|NOR]] operation. Then for any [[Definition:Proposition|proposition]] $p$: :$p \downarrow p \dashv \vdash \neg p$ That is, the [[Definition:Logical NOR|NOR]] of a proposition with itself corresponds to the [[Definition:Negation|negation]] operator.	1
From [[Elimination of all but 24 Categorical Syllogisms as Invalid]], all but these $24$ patterns have been shown to be [[Definition:Invalid Argument|invalid]]. It remains to be shown that these remaining syllogisms are in fact [[Definition:Valid Argument|valid]]. {{ProofWanted|Considerable work to be done yet.}}	1
:$\vdash \paren {\neg \paren {p \iff q} } \iff \paren {\paren {\neg p \land q} \lor \paren {p \land \neg q} }$	1
: $p \lor p \vdash p$	1
{{BeginTableau|p \land \bot \vdash \bot}} {{Premise|1|p \land \bot}} {{Simplification|2|1|\bot|1|2}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|\bot \vdash p \land \bot}} {{Premise|1|\bot}} {{Explosion|2|1|p \land \bot|1|From a bottom, we can prove what we like}} {{EndTableau}} {{qed}}	1
:$(1): \quad p \iff q \vdash p \implies q$ :$(2): \quad p \iff q \vdash q \implies p$	1
:$p \lor \paren {q \lor r} \dashv \vdash \paren {p \lor q} \lor r$	1
:$\vdash \paren {\paren {p \implies q} \land \paren {p \implies \neg q} } \implies \neg p$	1
: $p \iff \paren {q \iff r} \dashv \vdash \paren {p \iff q} \iff r$	1
Let $p \implies q$ be a [[Definition:Conditional|conditional]]. Then the [[Definition:Inverse Statement|inverse]] of $p \implies q$ is the [[Definition:Converse Statement|converse]] of its [[Definition:Contrapositive Statement|contrapositive]].	1
{{BeginTableau|\vdash \paren {p \land q} \iff \paren {q \land p} }} {{Assumption |1|p \land q}} {{Commutation|2|1|q \land p|1|Conjunction}} {{Implication|3||\paren {p \land q} \implies \paren {q \land p}|1|2}} {{Assumption |4|q \land p}} {{Commutation|5|4|p \land q|4|Conjunction}} {{Implication|6||\paren {q \land p} \implies \paren {p \land q}|4|5}} {{BiconditionalIntro|7||\left({p \land q}\right) \iff \paren {q \land p}|3|6}} {{EndTableau}} {{qed}}	1
: $p \implies \left({q \implies r}\right) \vdash q \implies \left({p \implies r}\right)$	1
{{BeginTableau|\left({p \implies r}\right) \land \left({q \implies r}\right) \vdash \left({p \lor q}\right) \implies r}} {{Premise|1|\left({p \implies r}\right) \land \left({q \implies r}\right)}} {{Simplification|2|1|p \implies r|1|1}} {{Simplification|3|1|q \implies r|1|2}} {{SequentIntro|4|1|p \lor q \implies r \lor r|2, 3|[[Constructive Dilemma]]}} {{Assumption|5|p \lor q}} {{ModusPonens|6|1, 5|r \lor r|4|5}} {{Idempotence|7|1, 5|r|6|Disjunction}} {{Implication|8|1|p \lor q \implies r|5|7}} {{EndTableau}} {{Qed}}	1
The following is known as the [[Definition:Self Distributive|Self-Distributive]] Law:	1
Let $C$ be a [[Definition:Linear Code|linear code]]. Let $v$ be a [[Definition:Received Word|received word]], which may have [[Definition:Transmission Error|transmission errors]]. To find out the [[Definition:Transmitted Codeword|transmitted codeword]] $u$ corresponding to $v$: :$(1): \quad$ Find $v$ in the [[Definition:Coset Decoding Table|coset decoding table]] for $C$. :$(2): \quad$ The corresponding [[Definition:Transmitted Codeword|transmitted codeword]] $u$ will be found at the top of the [[Definition:Column of Array|column]] where $v$ can be found.	1
==== [[Rule of Distribution/Conjunction Distributes over Disjunction/Right Distributive/Formulation 1|Formulation 1]] ==== {{:Rule of Distribution/Conjunction Distributes over Disjunction/Right Distributive/Formulation 1}} ==== [[Rule of Distribution/Conjunction Distributes over Disjunction/Right Distributive/Formulation 2|Formulation 2]] ==== {{:Rule of Distribution/Conjunction Distributes over Disjunction/Right Distributive/Formulation 2}}	1
{{BeginTableau|q \implies \left({p \implies r}\right) \vdash p \implies \left({q \implies r}\right)}} {{Premise|1|q \implies \left({p \implies r}\right)}} {{Assumption|2|p}} {{Assumption|3|q}} {{ModusPonens|4|1, 3|p \implies r|1|3}} {{ModusPonens|5|1, 2, 3|r|2|4}} {{Implication|6|1, 2|q \implies r|3|5}} {{Implication|7|1|p \implies \left({q \implies r}\right)|2|6}} {{EndTableau}} {{qed}}	1
{{ProofWanted}} [[Category:Asymptotic Notation]] 34yd1nfcmie7stnlonf5x1tv3syz2dh	1
$A$ and $B$ are [[Definition:Primitive Recursive Set|primitive recursive]], therefore so are their [Definition:Characteristic Function of Set|characteristic functions]] $\chi_A$ and $\chi_B$. Let $n \in \N$ be a [[Definition:Natural Numbers|natural number]]. From [[Characteristic Function of Intersection/Variant 1|Characteristic Function of Intersection: Variant 1]]: :$\chi_{A \cap B} \left({n}\right) = \chi_A \left({n}\right) \times \chi_B \left({n}\right)$ So: : $\chi_{A \cap B} \left({n}\right) = \operatorname{mult} \left({\chi_A \left({n}\right), \chi_B \left({n}\right)}\right)$ Thus $A \cap B$ is defined by [[Definition:Substitution (Mathematical Logic)|substitution]] from the [[Definition:Primitive Recursive Function|primitive recursive functions]] $\operatorname{mult}$, $\chi_A$ and $\chi_B$. Hence the result. {{qed}} [[Category:Primitive Recursive Functions]] [[Category:Set Intersection]] f9dru7looqz6dy9n09w241yqb5xr2du	1
The [[Definition:Function|function]] $\operatorname{mult}: \N^2 \to \N$, defined as: :$\map \Mult {n, m} = n \times m$ is [[Definition:Primitive Recursive Function|primitive recursive]].	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] is [[Definition:True|true]] for all [[Definition:Boolean Interpretation|boolean interpretations]]. :$\begin{array}{|ccc|c|ccc|} \hline (p & \land & q) & \implies & (p & \lor & q) \\ \hline F & F & F & T & F & F & F \\ F & F & T & T & F & T & T \\ T & F & F & T & T & T & F \\ T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
{{ProofWanted}} {{Namedfor|Charles Sanders Peirce}} [[Category:Peirce's Law]] epgggbe7bnanpn0c0yyejgf5h701w5q	1
The [[Rule of Idempotence/Disjunction/Formulation 2/Reverse Implication|Rule of Idempotence]]: :$(p \lor p) \implies p$ is a [[Definition:Tautology (Formal Semantics)|tautology]] in [[Definition:Constructed Semantics/Instance 5|Instance 5]] of [[Definition:Constructed Semantics|constructed semantics]].	1
An '''argumentum ad hominem''' is a [[Definition:Logical Argument|logical argument]] that concludes the [[Definition:False|falsehood]] of a [[Definition:Statement|statement]] because it is made by a particular person or group of people. It can be argued that it is reasonable to be suspicious of an [[Definition:Logical Argument|argument]] if most of the [[Definition:Assertion|assertions]] made by said person or group regarding the topic under discussion are [[Definition:False|false]]. However, such reasoning is still [[Definition:Fallacy|fallacious]].	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, in each case, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc||ccccc|} \hline (p & \iff & q) & \iff & r & (p & \oplus & q) & \oplus & r \\ \hline F & T & F & F & F & F & F & F & F & F \\ F & T & F & T & T & F & F & F & T & T \\ F & F & T & T & F & F & T & T & T & F \\ F & F & T & F & T & F & T & T & F & T \\ T & F & F & T & F & T & T & F & T & F \\ T & F & F & F & T & T & T & F & F & T \\ T & T & T & F & F & T & F & T & F & F \\ T & T & T & T & T & T & F & T & T & T \\ \hline \end{array}$ {{qed}} From [[Biconditional is Associative]] and [[Exclusive Or is Associative]], we have that both $\iff$ and $\oplus$ are [[Definition:Associative|associative]], which justifies the rendition of this result without [[Definition:Parenthesis|parentheses]].	1
When demonstrating a [[Definition:Proof|proof]], it is frequently necessary to refer to the specification of the result which is to be proved. This result often contains wording along the lines '''Suppose that ...''' or '''Let ...''' It is convenient to refer back to these specifications during the course of the proof. To do that, the term '''by hypothesis''' is often used.	1
{{begin-eqn}} {{eqn | l = p \lor q | o = \dashv \vdash | r = \neg \neg \paren {p \lor q} | c = [[Double Negation]] }} {{eqn | o = \dashv \vdash | r = \neg \paren {p \downarrow q} | c = {{Defof|Logical NOR}} }} {{eqn | o = \dashv \vdash | r = \paren {p \downarrow q} \downarrow \paren {p \downarrow q} | c = [[NOR with Equal Arguments]] }} {{end-eqn}} {{qed}} [[Category:Logical NOR]] [[Category:Disjunction]] 4dw5e72qt5juo7ko2pxvsrci6p0nyyc	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] on the {{LHS}} match those for $p$ on the {{RHS}} for all [[Definition:Boolean Interpretation|boolean interpretations]]: $\begin{array}{|ccccc||c|} \hline (p & \oplus & q) & \oplus & q & p \\ \hline \F & \F & \F & \F & \F & \F \\ \F & \T & \T & \F & \T & \F \\ \T & \T & \F & \T & \F & \T \\ \T & \F & \T & \T & \T & \T \\ \hline \end{array}$ {{qed}}	1
{{BeginTableau|p \implies q \vdash \paren {p \lor r} \implies \paren {q \lor r} }} {{Premise|1|p \implies q}} {{Assumption|2|p \lor r}} {{Assumption|3|r}} {{Addition|4|3|q \lor r|3|2}} {{Assumption|5|p}} {{ModusPonens|6|1, 5|q|1|5}} {{Addition|7|1, 5|q \lor r|6|1}} {{ProofByCases|8|1, 2|q \lor r|2|5|7|3|4}} {{Implication|9|1|\paren {p \lor r} \implies \paren {q \lor r}|2|8}} {{EndTableau}} {{qed}}	1
:$\left({p \implies r}\right) \lor \left({q \implies r}\right) \dashv \vdash \left({p \land q}\right) \implies r$	1
The [[Definition:Ordering|ordering relations]] on $\N^2$: * $n < m$ * $n \le m$ * $n \ge m$ * $n > m$ are all [[Definition:Primitive Recursive Relation|primitive recursive]].	1
:$\vdash \paren {p \lor \paren {q \lor r} } \iff \paren {\paren {p \lor q} \lor r}$	1
The [[Definition:Probability|probability]] of all $4$ players in a game of [[Definition:Bridge (Game)|Bridge]] being dealt a complete [[Definition:Suit of Cards|suit]] is $1$ in $2 \, 235 \, 197 \, 406 \, 895 \, 366 \, 368 \, 301 \, 560 \, 000$.	1
{{BeginTableau|\vdash p \implies \neg \neg p}} {{Assumption|1|p}} {{DoubleNegIntro|2|1|\neg \neg p|1}} {{Implication|3||p \implies \neg \neg p|1|2}} {{EndTableau}} {{Qed}}	1
[[Definition:Disjunction|Disjunction]] is [[Definition:Associative Operation|associative]]: === [[Rule of Association/Disjunction/Formulation 1|Formulation 1]] === {{:Rule of Association/Disjunction/Formulation 1}} === [[Rule of Association/Disjunction/Formulation 2|Formulation 2]] === {{:Rule of Association/Disjunction/Formulation 2}}	1
{{:De Morgan's Laws (Logic)/Conjunction of Negations/Formulation 1}}	1
Let $T$ be a [[Definition:Propositional Tableau|propositional tableau]]. Let $\Gamma$ be a [[Definition:Contradictory Branch|contradictory branch]] of $T$. Let $\Gamma'$ be an [[Definition:Extension of Branch of Propositional Tableau|extension]] of $\Gamma$. Then $\Gamma'$ is also [[Definition:Contradictory Branch|contradictory]].	1
: $\vdash \left({\neg q \implies \neg p}\right) \implies \left({p \implies q}\right)$	1
: $\left({p \implies q}\right) \land \left({p \implies r}\right) \vdash p \implies \left({q \land r}\right)$	1
Let $x$ be a [[Definition:Right Normal Element of Relation|right normal element]] of $M$ with respect to $\RR$. Then $x$ is also a [[Definition:Left Normal Element of Relation|left normal element]] of $M$ with respect to $\RR$.	1
The proof proceeds by [[Principle of Mathematical Induction|induction]]. By definition, $\Gamma$ is a [[Definition:Finite Sequence|finite sequence]] of [[Definition:Elementary Row Operation|elementary row operations]] on $\mathbf A$. Let $\sequence e_k$ denote a [[Definition:Finite Sequence|finite sequence]] of [[Definition:Elementary Row Operation|elementary row operations]] $\tuple {e_1, e_2, \ldots, e_k}$ applied on $\mathbf A$ in order: first $e_1$, then $e_2$, then $\ldots$, then $e_k$. Let $\Gamma_k$ be the [[Definition:Row Operation|row operation]] which consists of $\sequence e_k$. Let $\mathbf E_k$ denote the [[Definition:Elementary Row Matrix|elementary row matrix]] of [[Definition:Order of Square Matrix|order]] $m$ formed by applying $e_k$ to the [[Definition:Unit Matrix|unit matrix]] $I_m$. For all $r \in \Z_{>0}$, let $\map P r$ be the [[Definition:Proposition|proposition]]: :For all $\Gamma_r$, there exists a [[Definition:Unique|unique]] [[Definition:Invertible Matrix|invertible]] [[Definition:Square Matrix|square matrix]] $\mathbf R_r$ of [[Definition:Order of Square Matrix|order $m$]] such that: ::$\mathbf R_r \mathbf A = \mathbf B_r$ :where: ::$\Gamma_r$ is a [[Definition:Row Operation|row operation]] which transforms $\mathbf A$ to a new [[Definition:Matrix|matrix]] $\mathbf B_r \in \map \MM {m, n}$. ::$\mathbf R_r$ is the [[Definition:Matrix Product (Conventional)|product]] of the [[Definition:Finite Sequence|finite sequence]] of [[Definition:Elementary Row Matrix|elementary row matrices]]: :::$\mathbf R_r = \mathbf E_r \mathbf E_{r - 1} \dotsb \mathbf E_2 \mathbf E_1$ === Basis for the Induction === $\map P 1$ is the case where $\Gamma_1$ is a single-[[Definition:Term of Sequence|term]] [[Definition:Finite Sequence|sequence]] consisting of one [[Definition:Elementary Row Operation|elementary row operation]] $e_1$. Let $e_1$ be an [[Definition:Elementary Row Operation|elementary row operation]] operating on $\mathbf A$, which transforms $\mathbf A$ into $\mathbf B_1$. By definition, there exists [[Definition:Unique|exactly one]] [[Definition:Elementary Row Matrix|elementary row matrix]] $\mathbf E_1$ of [[Definition:Order of Square Matrix|order $m$]] such that $\mathbf E_1$ is the result of applying $e_1$ to the [[Definition:Unit Matrix|unit matrix]] $\mathbf I$ of [[Definition:Order of Square Matrix|order $m$]]. From the [[Elementary Row Operations as Matrix Multiplications/Corollary|corollary to Elementary Row Operations as Matrix Multiplications]]: :$\mathbf E_1 \mathbf A = \mathbf B_1$ By [[Elementary Row Matrix is Invertible]], $E_1$ is [[Definition:Invertible Matrix|invertible]]. Thus $\map P 1$ is seen to hold. This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is the [[Definition:Induction Hypothesis|induction hypothesis]]: :For all $\Gamma_k$, there exists a [[Definition:Unique|unique]] [[Definition:Invertible Matrix|invertible]] [[Definition:Square Matrix|square matrix]] $\mathbf R_k$ of [[Definition:Order of Square Matrix|order $m$]] such that: ::$\mathbf R_k \mathbf A = \mathbf B_k$ from which it is to be shown that: :For all $\Gamma_{k + 1}$, there exists a [[Definition:Unique|unique]] [[Definition:Invertible Matrix|invertible]] [[Definition:Square Matrix|square matrix]] $\mathbf R_{k + 1}$ of [[Definition:Order of Square Matrix|order $m$]] such that: ::$\mathbf R_{k + 1} \mathbf A = \mathbf B_{k + 1}$ === Induction Step === This is the [[Definition:Induction Step|induction step]]: By definition, $\Gamma_{k + 1}$ is a [[Definition:Row Operation|row operation]] consisting of a [[Definition:Finite Sequence|finite sequence]] of [[Definition:Elementary Row Operation|elementary row operations]] $\tuple {e_1, e_2, \ldots, e_k, e_{k + 1} }$ applied on $\mathbf A$ in order. Thus $\Gamma_{k + 1}$ consists of the [[Definition:Finite Sequence|finite sequence]] of [[Definition:Elementary Row Operation|elementary row operations]] $\tuple {e_1, e_2, \ldots, e_k}$ applied on $\mathbf A$ in order, followed by a further [[Definition:Elementary Row Operation|elementary row operation]] $e_{k + 1}$. By the [[Row Operation is Equivalent to Pre-Multiplication by Product of Elementary Matrices#Induction Hypothesis|induction hypothesis]], there exists a [[Definition:Unique|unique]] [[Definition:Invertible Matrix|invertible]] [[Definition:Square Matrix|square matrix]] $\mathbf R_k$ of [[Definition:Order of Square Matrix|order $m$]] such that: :$\mathbf R_k \mathbf A = \mathbf B_k$ where $\mathbf B_k \in \map \MM {m, n}$ is the result of applying $\sequence e_k$ to $\mathbf A$ in order. Let $e_{k + 1}$ be applied to $\mathbf B_k$. By definition, there exists [[Definition:Unique|exactly one]] [[Definition:Elementary Row Matrix|elementary row matrix]] $\mathbf E_{k + 1}$ of [[Definition:Order of Square Matrix|order $m$]] such that $\mathbf E_{k + 1}$ is the result of applying $e_{k + 1}$ to the [[Definition:Unit Matrix|unit matrix]] $\mathbf I$ of [[Definition:Order of Square Matrix|order $m$]]. Then: {{begin-eqn}} {{eqn | l = \mathbf B_{k + 1} | r = \mathbf E_{k + 1} \mathbf B_k | c = [[Elementary Row Operations as Matrix Multiplications/Corollary|Corollary to Elementary Row Operations as Matrix Multiplications]] }} {{eqn | r = \mathbf E_{k + 1} \paren {\mathbf R_k \mathbf A} | c = }} {{eqn | r = \paren {\mathbf E_{k + 1} \mathbf R_k} \mathbf A | c = [[Matrix Multiplication is Associative]] }} {{end-eqn}} By [[Product of Matrices is Invertible iff Matrices are Invertible]], $\mathbf E_{k + 1} \mathbf R_k$ is [[Definition:Invertible Matrix|invertible]]. We have that $\mathbf R_k$ is the [[Definition:Unique|unique]] [[Definition:Invertible Matrix|invertible]] [[Definition:Square Matrix|square matrix]] resulting from the application of $\sequence e_k$ on $\mathbf I_m$. Thus $\mathbf E_{k + 1} \mathbf R_k$ is the [[Definition:Unique|unique]] [[Definition:Invertible Matrix|invertible]] [[Definition:Square Matrix|square matrix]] resulting from the application of $\sequence e_{k + 1}$ on $\mathbf I_m$. So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore, for every [[Definition:Row Operation|row operation]] $\Gamma$ which transforms $\mathbf A$ to a new [[Definition:Matrix|matrix]] $\mathbf B \in \map \MM {m, n}$, there exists a [[Definition:Unique|unique]] [[Definition:Invertible Matrix|invertible]] [[Definition:Square Matrix|square matrix]] $\mathbf R$ of [[Definition:Order of Square Matrix|order $m$]] such that: :$\mathbf R \mathbf A = \mathbf B$ where: :$\mathbf R$ is the [[Definition:Matrix Product (Conventional)|product]] of a [[Definition:Finite Sequence|finite sequence]] of [[Definition:Elementary Row Matrix|elementary row matrices]]. {{qed}}	1
Let $F_n$ denote the $n$th [[Definition:Fibonacci Numbers|Fibonacci number]]. Then: {{begin-eqn}} {{eqn | lo= \forall n \in \Z_{>0}: | l = F_{2 n} | r = \sum_{k \mathop = 1}^n \dbinom n k F_k | c = }} {{eqn | r = \dbinom n 1 F_1 + \dbinom n 2 F_2 + \dbinom n 3 F_3 + \dotsb + \dbinom n {n - 1} F_{n - 1} + \dbinom n n F_n | c = }} {{end-eqn}} where $\dbinom n k$ denotes a [[Definition:Binomial Coefficient|binomial coefficient]].	1
:$\forall n \in \Z_{> 0} : F_{-n} = \left({-1}\right)^{n + 1} F_n$	1
There are $4$ distinct [[Definition:Unary|unary]] [[Definition:Truth Function|truth functions]]: :$(1): \quad$ The [[Definition:Constant Mapping|constant function]] $\map f p = \F$ :$(2): \quad$ The [[Definition:Constant Mapping|constant function]] $\map f p = \T$ :$(3): \quad$ The [[Definition:Identity Mapping|identity function]] $\map f p = p$ :$(4): \quad$ The [[Definition:Logical Not|logical not]] function $\map f p = \neg p$	1
Recall the [[Definition:Axiom (Formal Systems)|axioms]] of $\mathscr H$: {{begin-axiom}} {{axiom | lc = '''Axiom 1:''' | m = \mathbf A \implies \paren {\mathbf B \implies \mathbf A} }} {{axiom | lc = '''Axiom 2:''' | m = \paren {\mathbf A \implies \paren {\mathbf B \implies \mathbf C} } \implies \paren {\paren {\mathbf A \implies \mathbf B} \implies \paren {\mathbf A \implies \mathbf C} } }} {{axiom | lc = '''Axiom 3:''' | m = \paren {\neg \mathbf B \implies \neg \mathbf A} \implies \paren {\mathbf A \implies \mathbf B} }} {{end-axiom}} That these are [[Definition:Tautology (Boolean Interpretations)|tautologies]] is shown on, respectively: :[[True Statement is implied by Every Statement/Formulation 2/Proof 2|True Statement is implied by Every Statement]] :[[Self-Distributive Law for Conditional/Formulation 1/Proof 2|Self-Distributive Law for Conditional]] :[[Rule of Transposition/Formulation 2/Proof 2|Rule of Transposition]] That [[Modus Ponens]] infers [[Definition:Tautology (Boolean Interpretations)|tautologies]] from [[Definition:Tautology (Boolean Interpretations)|tautologies]] is shown on: :[[Modus Ponendo Ponens/Sequent Form/Proof 2|Modus Ponendo Ponens]] Since: :All [[Definition:Axiom (Formal Systems)|axioms]] of $\mathscr H$ are [[Definition:Tautology (Boolean Interpretations)|tautologies]]; :All [[Definition:Rule of Inference|rules of inference]] of $\mathscr H$ preserve [[Definition:Tautology (Boolean Interpretations)|tautologies]] it is guaranteed that every [[Definition:Formal Proof|formal proof]] in $\mathscr H$ results in a [[Definition:Tautology (Boolean Interpretations)|tautology]]. That is, all [[Definition:Theorem (Formal Systems)|$\mathscr H$-theorems]] are [[Definition:Tautology (Boolean Interpretations)|tautologies]]. {{qed}}	1
:$\vdash \paren {\neg p \lor \neg q} \iff \paren {\neg \paren {p \land q} }$	1
Any [[Definition:Propositional Formula|propositional formula]] can be expressed in [[Definition:Negation Normal Form|negation normal form (NNF)]].	1
=== Sufficient Condition === Let $\exists x: \map S x$. Suppose $\mathbf A$ and $\mathbf E$ are both [[Definition:True|true]]. As $\mathbf A$ is [[Definition:True|true]], then by [[Modus Ponendo Ponens]]: :$\map P x$ As $\mathbf E$ is [[Definition:True|true]], then by [[Modus Ponendo Ponens]]: :$\neg \map P x$ It follows by [[Proof by Contradiction]] that $\mathbf A$ and $\mathbf E$ are not both [[Definition:True|true]]. Thus, by definition, $\mathbf A$ and $\mathbf E$ are [[Definition:Contrary Statements|contrary statements]]. {{qed|lemma}} === Necessary Condition === Let $\mathbf A$ and $\mathbf E$ be [[Definition:Contrary Statements|contrary statements]]. Suppose: :$\neg \exists x: \map S x$ that is, $\map S x$ is [[Definition:Vacuous Truth|vacuous]]. From [[Denial of Existence]]: :$\forall x: \neg \map S x \dashv \vdash \neg \exists x: \map S x$ it follows that $\forall x: \map S x$ is [[Definition:False|false]]. From [[False Statement implies Every Statement]]: :$\forall x: \map S x \implies \map P x$ is [[Definition:True|true]], and: :$\forall x: \map S x \implies \neg \map P x$ is also [[Definition:True|true]]. Thus, by definition, $\mathbf A$ and $\mathbf E$ are not [[Definition:Contrary Statements|contrary statements]]. It follows by [[Proof by Contradiction]] that $\exists x: \map S x$. {{qed}}	1
Let $G$ be a [[Definition:Commutative Semigroup|commutative semigroup]]. Let $a, b \in\Z$ be [[Definition:Integer|integers]]. Let $\closedint a b$ be the [[Definition:Integer Interval|integer interval]] between $a$ and $b$. Let $f: \closedint a b \to G$ be a [[Definition:Mapping|mapping]]. Let $\sigma: \closedint a b \to \closedint a b$ be a [[Definition:Permutation|permutation]].	1
:$\top \implies p \dashv \vdash p$	1
=== Sufficient Condition === Let $\exists x: \map S x$. Suppose $\mathbf I$ and $\mathbf O$ are both [[Definition:False|false]]. As $\mathbf I$ is [[Definition:False|false]], then by the [[Rule of Conjunction/Proof Rule|Rule of Conjunction]]: :$\neg \map P x$ As $\mathbf O$ is [[Definition:False|false]], then by the [[Rule of Conjunction/Proof Rule|Rule of Conjunction]]: :$\neg \neg \map P x$ and so by [[Double Negation]]: :$\map P x$ It follows by [[Proof by Contradiction]] that $\mathbf I$ and $\mathbf O$ are not both [[Definition:False|false]]. Thus, by definition, $\mathbf I$ and $\mathbf O$ are [[Definition:Subcontrary Statements|subcontrary statements]]. {{qed|lemma}} === Necessary Condition === Let $\mathbf I$ and $\mathbf O$ be [[Definition:Subcontrary Statements|subcontrary statements]] Suppose $\neg \exists x: \map S x$. From the definition of [[Definition:Conjunction|logical conjunction]], it follows that: :$\neg \paren {\exists x: \map S x \land \map P x}$ Similarly from the definition of [[Definition:Conjunction|logical conjunction]], it follows that: :$\neg \paren {\exists x: \map S x \land \neg \map P x}$ That is, both $\mathbf I$ and $\mathbf O$ are [[Definition:False|false]]. So, by definition, $\mathbf I$ and $\mathbf O$ are not [[Definition:Subcontrary Statements|subcontrary]]. It follows by [[Proof by Contradiction]] that $\exists x: \map S x$. {{qed}}	1
{{BeginTableau|p \lor q \vdash \neg p \implies q}} {{Premise|1|p \lor q}} {{Assumption|2|p|Pick the first of the disjuncts ...}} {{Assumption|3|\neg p|Assume its negation ...}} {{NonContradiction|4|2, 3|2|3|... which introduces a contradiction}} {{Explosion|5|2, 3|q|4| ... from a falsehood, ''any'' statement can be derived - pick $q$}} {{Implication|6|2|\neg p \implies q|3|5}} {{Assumption|7|q|Pick the second of the disjuncts ...}} {{Assumption|8|\neg p|... again assume the negation of $p$}} {{IdentityLaw|9|7|q|7|$q$ still holds}} {{Implication|10|7|\neg p \implies q|8|9}} {{ProofByCases|11|1|\neg p \implies q|1|2|6|7|10}} {{EndTableau}} {{qed}} [[Category:Modus Tollendo Ponens]] 4cs2ci8pnukzednwbx1w4bdyc16iswy	1
$(1)\implies (2)$: Let $\{\bar b_i : i \in I\}$ containing $\bar b$ be [[Definition:Order Indiscernible|order indiscernible]] over $A$. Suppose $\displaystyle \bigcup_{i\in I} \operatorname{tp}(\bar c / A,\bar b_i)$ is not satisfiable. :By [[Compactness Theorem|compactness]], some finite subset $\{\phi_1(x, \bar b_{i_1}), \dots, \phi_k(x, \bar b_{i_k})\}$ is not satisfiable. :Let $\phi$ be $\phi_1 \wedge \cdots \wedge \phi_k$. :Note that $\phi(x, \bar b)$ is in $\operatorname{tp}(\bar c / A,\bar b)$. :$\{\phi(x, \bar b_i ) : i\in I\}$ is not satisfiable since it implies $\{\phi_1(x, \bar b_{i_1}), \dots, \phi_k(x, \bar b_{i_k}))$. :Again by [[Compactness Theorem|compactness]], some finite subset $\{\phi(x, \bar b_{j_1}), \dots, \phi(x, \bar b_{j_h})\}$ is inconsistent. :Since all of the $b_i$ are order-indiscernibles, this means that any [[Definition:Cardinality|cardinality]] $h$ subset of $\{\phi(x, \bar b_i ) : i\in I\}$ is not satisfiable. :This contradicts the assumption that $\operatorname{tp}(\bar c / A,\bar b)$ does not divide over $A$. Thus $\displaystyle \bigcup_{i\in I} \operatorname{tp}(\bar c / A,\bar b_i)$ is satisfiable, and since $\mathfrak C$ is a monster model, it is satisfiable in $\mathfrak C$. By [[Infinite Ramsey's Theorem]] and indiscernibility of $\{\bar b_i : i \in I\}$ over $A$, for each finite set $\Delta$ of formulas with parameters from $A$, there is some $\bar c_\Delta$ such that: :$\bar c_\Delta$ realizes $\displaystyle \bigcup_{i\in I} \operatorname{tp}(\bar c / A, \bar b_i)$, and :for any $i_1 < \cdots < i_k$ and $j_1 < \cdots < j_k$ in $I$, $\mathfrak C \models \phi(b_{i_1}, \dots, b_{i_k}, \bar c_\Delta) \leftrightarrow \phi(b_{j_1}, \dots, b_{j_k}, \bar c_\Delta)$ for all $\phi \in \Delta$. Since $b$ is one of the $b_i$, we have that each $c_\Delta$ realizes $\operatorname{tp}(\bar c / A, \bar b)$. By [[Compactness Theorem|compactness]], since there is a $c_\Delta$ with $\mathfrak C \models \phi(b_{i_1}, \dots, b_{i_k}, \bar c_\Delta) \leftrightarrow \phi(b_{j_1}, \dots, b_{j_k}, \bar c_\Delta)$ for all $\phi \in \Delta$ for each finite $\Delta$, there is a $\bar c'$ with type $\operatorname{tp}(\bar c / A, \bar b)$ and which satisfies $\mathfrak C \models \phi(b_{i_1}, \dots, b_{i_k}, \bar c') \leftrightarrow \phi(b_{j_1}, \dots, b_{j_k}, \bar c')$ for all $\phi$. But this holding for every $\phi$ means that $\{b_i : i\in I\}$ is order-indiscernible over $A,\bar c'$. $(2)\implies (1)$: We prove this case by contradiction. Suppose $\operatorname{tp}(\bar c / A,\bar{b})$ [[Definition:Divide (Model Theory)|divides]] over $A$. By definition, this means that $\operatorname{tp}(\bar c / A,\bar{b})$ implies some $\phi(x, \bar{b})$ with parameters from $A$ which divides over $A$. By definition of dividing, this means that for some $k \in \N$ there is a [[Definition:Sequence|sequence]] $(\bar{b}_i)_{i\in \N}$ such that [[Definition:Type|$\operatorname{tp}(\bar{b}_i / A) = \operatorname{tp}(\bar{b} / A)$]] for each $i\in\N$, and for any distinct $k$-many terms $\bar b_{i_1}, \dots, \bar b_{i_k}$ of the sequence, the set $\{\phi(\bar{x}, \bar{b}_{i_1}), \dots, \phi(\bar{x}, \bar{b}_{i_k})\}$ is not satisfiable in $\mathfrak C$. Since $\operatorname{tp}(\bar{b}_i / A) = \operatorname{tp}(\bar{b} / A)$ for each $i$, we can assume (using an argument involving [[Infinite Ramsey's Theorem]] and partitions based on the formula satisfied by the $b_i$) that $\{\bar b_i : i\in I\}$ is order-indiscernible over $A$. Then, by $(2)$, there is $\bar c'$ with $\operatorname{tp}(\bar c' / A,\bar b) = \operatorname{tp}(\bar c / A,\bar b)$ such that $\{\bar b_i : i\in I\}$ is order-indiscernible over $A,\bar c'$. However, $\operatorname{tp}(\bar c' / A,\bar b) = \operatorname{tp}(\bar c / A,\bar b)$ gives us that $\mathfrak C \models \phi(\bar c', \bar{b})$. So, $\{\bar b_i : i\in I\}$ being order-indiscernible over $A,\bar c'$ gives us that $\mathfrak C \models \phi(\bar c', \bar{b_i})$ for all $i$. This contradicts the non-satisfiability of $\{\phi(\bar{x}, \bar{b}_{i_1}), \dots, \phi(\bar{x}, \bar{b}_{i_k})\}$. Thus, $\operatorname{tp}(\bar c / A,\bar{b})$ does not divide over $A$. $(2)\implies (3)$: Since $c$ and $c'$ have the same type over $A,b$, the function $\bar c' \mapsto \bar c$ is [[Definition:Partial Elementary Embedding|partial elementary]]. Since $\mathfrak C$ is [[Definition:Homogeneous (Model Theory)|homogeneous]], there is an $A, b$-[[Definition:Automorphism (Model Theory)|automorphism]] $f$ which extends $\bar c' \mapsto \bar c$. Let $\{f(\bar b_i) : i \in I\}$ be the image of $\{\bar b_i : i \in I\}$. $\{f(\bar b_i) : i \in I\}$ is order-indiscernible over $A,\bar c$ since if $i_1 < \cdots < i_k$ and $j_1 < \cdots < j_k$, then: {{begin-eqn}} {{eqn | l = \mathfrak C \models \phi(f(\bar b_{i_1}), \dots, f(\bar b_{i_k}), \bar c) | o = \leadstoandfrom | r = \mathfrak C \models \phi(\bar b_{i_1}, \dots, \bar b_{i_k}, \bar c') | c = as $f$ is an automorphism (fixing any parameters in $\phi$ from $A, b$) }} {{eqn | o = \leadstoandfrom | r = \mathfrak C \models \phi(\bar b_{j_1}, \dots, \bar b_{j_k}, \bar c') | c = as the original sequence is order-indiscernible over $A, \bar c'$ }} {{eqn | o = \leadstoandfrom | r = \mathfrak C \models \phi(f(\bar b_{j_1}), \dots, f(\bar b_{j_k}), \bar c) | c = as $f$ is an [[Definition:Automorphism (Model Theory)|automorphism]] }} {{end-eqn}} $(3)\implies (2)$: Let $\bar c' = f^{-1}(\bar c)$. $\{\bar b_i : i \in I\}$ is order-indiscernible over $A, \bar c'$ since if $i_1 < \cdots < i_k$ and $j_1 < \cdots < j_k$, then: {{begin-eqn}} {{eqn | l = \mathfrak C \models \phi(\bar b_{i_1}, \dots, \bar b_{i_k}, \bar c') | o = \leadstoandfrom | r = \mathfrak C \models \phi(f(\bar b_{i_1}), \dots, f(\bar b_{i_k}), \bar c) | c = as $f$ is an [[Definition:Automorphism (Model Theory)|automorphism]] (fixing any parameters in $\phi$ from $A, b$) }} {{eqn | o = \leadstoandfrom | r = \mathfrak C \models \phi(f(\bar b_{j_1}), \dots, f(\bar b_{j_k}), \bar c) | c = as the image sequence is order-indiscernible over $A, \bar c$. }} {{eqn | o = \leadstoandfrom | r = \mathfrak C \models \phi(\bar b_{j_1}, \dots, \bar b_{j_k}, \bar c') | c = as $f$ is an [[Definition:Automorphism (Model Theory)|automorphism]] }} {{end-eqn}} {{qed}} [[Category:Model Theory]] i7s6qjbnrrzd6csyj45oh1fvllrn4wh	1
Let $f: \N^k \to \N$ be a [[Definition:Primitive Recursive Function|primitive recursive function]]. Let $\sigma$ be a [[Definition:Permutation|permutation]] of $\left({1, 2, \ldots, k}\right)$. Then the [[Definition:Function|function]] $h: \N^k \to \N$ defined as: :$h \left({n_1, n_2, \ldots, n_k}\right) = f \left({n_{\sigma \left({1}\right)}, n_{\sigma \left({2}\right)}, \ldots, n_{\sigma \left({k}\right)}}\right)$ is also [[Definition:Primitive Recursive Function|primitive recursive]].	1
Consider the [[Definition:Universal Negative|universal negative]] [[Definition:Categorical Statement|categorical statement]] ''No $S$ is $P$'': :$\mathbf E \left({S, P}\right): \forall x: S \left({x}\right) \implies \neg P \left({x}\right)$ Then ''No $P$ is $S$'': :$\mathbf E \left({P, S}\right)$	1
[[Definition:Rule of Inference|Rule of inference]] $RST \, 4$ is [[Definition:Derivable Rule of Inference|derivable]] from $RST \, 1, RST \, 2, RST \, 3$ and the [[Definition:Axiom (Formal Systems)|axioms]] $(A1)$ through $(A4)$.	1
: $\neg \left ({p \iff q}\right) \dashv \vdash \left({p \lor q} \right) \land \neg \left({p \land q}\right)$	1
: $p \oplus q \dashv \vdash q \oplus p$	1
{{BeginTableau|p \land q \vdash q}} {{Premise|1|p \land q}} {{Simplification|2|1|q|1|2}} {{EndTableau}} {{Qed}}	1
Let us use the following abbreviations {{begin-eqn}} {{eqn | l=\phi | o=\text{ for } | r=p \implies \left({q \land r}\right) | c= }} {{eqn | l=\psi | o=\text{ for } | r=\left({p \implies q}\right) \land \left({p \implies r}\right) | c= }} {{end-eqn}} {{BeginTableau|\left({p \implies \left({q \land r}\right)}\right) \implies \left({\left({p \implies q}\right) \land \left({p \implies r}\right)}\right)}} {{Assumption|1|\phi}} {{SequentIntro|2|1|\psi|1|[[Implication is Left Distributive over Conjunction/Forward Implication/Formulation 1|Implication is Left Distributive over Conjunction: Formulation 1]]}} {{Implication|3||\phi \implies \psi|1|2}} {{EndTableau}} Expanding the abbreviations leads us back to: : $\left({p \implies \left({q \land r}\right)}\right) \implies \left({\left({p \implies q}\right) \land \left({p \implies r}\right)}\right)$ {{qed}}	1
[[Second Principle of Mathematical Induction|Proof by induction]] over $n$. Induction base: :$1^p \equiv 1 \pmod p$ Induction step: Assume $n^p \equiv n \pmod p$ {{begin-eqn}} {{eqn | l = \paren {n + 1}^p | r = \sum_{k \mathop = 0}^p {p \choose k} n^{p - k} \cdot 1^k | c = [[Binomial Theorem]] }} {{eqn | l = \forall k: 0 < k < p: {p \choose k} | o = \equiv | r = 0 \pmod p | c = [[Binomial Coefficient of Prime]] }} {{end-eqn}} and so: {{begin-eqn}} {{eqn | l = \sum_{k \mathop = 0}^p {p \choose k} n^{p - k} | o = \equiv | r = n^p + n^0 \pmod p }} {{eqn | o = \equiv | r = n^p + 1 \pmod p }} {{eqn | o = \equiv | r = n + 1 \pmod p | c = by induction step }} {{end-eqn}} Dividing by $n$: :$\forall n: n^p \equiv n \pmod p \implies n^{p - 1} \equiv 1 \pmod p$ {{qed}}	1
:$p \land \left({q \land r}\right) \dashv \vdash \left({p \land q}\right) \land r$	1
{{BeginTableau|\vdash p \lor \neg p}} {{ExcludedMiddle|1|p \lor \neg p}} {{EndTableau}} {{Qed}}	1
:$p \iff q \dashv \vdash \paren {\paren {p \uparrow p} \uparrow \paren {q \uparrow q} } \uparrow \paren {p \uparrow q}$ where $\iff$ denotes [[Definition:Biconditional|logical biconditional]] and $\uparrow$ denotes [[Definition:Logical NAND|logical NAND]].	1
Let $G$ be a [[Definition:Non-Zero-Sum Game|non-zero-sum game]] for $n$ [[Definition:Player|players]]. Then $G$ can be modelled as a [[Definition:Zero-Sum Game|zero-sum game]] for $n + 1$ [[Definition:Player|players]].	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, in each case, the [[Definition:Truth Value|truth values]] in the appropriate columns match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c|ccc||c|ccc|} \hline p & \top & \implies & p \\ \hline F & T & F & F \\ T & T & T & T \\ \hline \end{array}$ {{qed}}	1
Let $\map P n$ be a [[Definition:Propositional Function|propositional function]] depending on $n \in \N_{>0}$. Suppose that: :$(1): \quad \map P 1$ is [[Definition:True|true]] :$(2): \quad \forall k \in \N_{>0}: \map P 1 \land \map P 2 \land \ldots \land \map P {k - 1} \land \map P k \implies \map P {k + 1}$ Then: :$\map P n$ is [[Definition:True|true]] for all $n \in \N_{>0}$.	1
Suppose that $v$ [[Definition:Model (Boolean Interpretations)|models]] $\mathbf A$: :$v \models \mathbf A$ Then $v \left({\mathbf A}\right) = T$ by definition of [[Definition:Model (Boolean Interpretations)|models]]. By definition of [[Definition:Boolean Interpretation|boolean interpretation]], $v \left({\neg \mathbf A}\right) = F$. In particular, $v (\neg \mathbf A) \ne T$, so that: :$v \not\models \neg \mathbf A$ Hence the result. {{qed}} [[Category:Propositional Logic]] r1x63wssaxbv1ldoku4z649dfz2wow9	1
:$p \downarrow p \dashv \vdash \neg p$ That is, the [[Definition:Logical NOR|NOR]] of a proposition with itself corresponds to the [[Definition:Negation|negation]] operator.	1
Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \N$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\displaystyle \sum_{i \mathop = 1}^n i^2 = \frac {n \paren {n + 1} \paren {2 n + 1} } 6$ When $n = 0$, we see from the definition of [[Definition:Vacuous Summation|vacuous sum]] that: :$0 = \displaystyle \sum_{i \mathop = 1}^0 i^2 = \frac {0 \paren 1 \paren 1} 6 = 0$ and so $\map P 0$ holds. === Basis for the Induction === When $n = 1$: :$\displaystyle \sum_{i \mathop = 1}^1 i^2 = 1^2 = 1$ Now, we have: :$\displaystyle \frac {n \paren {n + 1} \paren {2 n + 1} } 6 = \frac {1 \paren {1 + 1} \paren {2 \times 1 + 1} } 6 = \frac 6 6 = 1$ and $\map P 1$ is seen to hold. This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\displaystyle \sum_{i \mathop = 1}^k i^2 = \frac {k \paren {k + 1} \paren {2 k + 1} } 6$ Then we need to show: :$\displaystyle \sum_{i \mathop = 1}^{k + 1} i^2 = \frac {\paren {k + 1} \paren {k + 2} \paren {2 \paren {k + 1} + 1} } 6$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: Using the properties of summation, we have: :$\displaystyle \sum_{i \mathop = 1}^{k + 1} i^2 = \sum_{i \mathop = 1}^k i^2 + \paren {k + 1}^2$ We can now apply our [[Sum of Sequence of Squares/Proof by Induction#Induction Hypothesis|induction hypothesis]], obtaining: {{begin-eqn}} {{eqn | l = \sum_{i \mathop = 1}^{k + 1} i^2 | r = \frac {k \paren {k + 1} \paren {2 k + 1} } 6 + \paren {k + 1}^2 | c = }} {{eqn | r = \frac {k \paren {k + 1} \paren {2 k + 1} + 6 \paren {k + 1}^2} 6 | c = }} {{eqn | r = \frac {\paren {k + 1} \paren {k \paren {2 k + 1} + 6 \paren {k + 1} } } 6 | c = }} {{eqn | r = \frac {\paren {k + 1} \paren {2 k^2 + 7 k + 6} } 6 | c = }} {{eqn | r = \frac {\paren {k + 1} \paren {k + 2} \paren {2 \paren {k + 1} + 1} } 6 | c = }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: : $\displaystyle \forall n \in \N: \sum_{i \mathop = 1}^n i^2 = \frac {n \paren {n + 1} \paren {2 n + 1} } 6$ {{qed}}	1
The proof is straightforward using the definition of forking and the fact that proofs in first-order logic are finite. Suppose $\pi$ forks over $A$. :By definition, $\pi$ implies a disjunction of formulas which each [[Definition:Divide (Model Theory)|divide]] over $A$. :Since proofs are finite, this means that there is a finite subset of $\pi$ which implies this disjunction, completing this direction of the proof. Suppose a finite subset of $\pi$ forks over $A$. :By definition, the finite subset implies a disjunction of formulas which each [[Definition:Divide (Model Theory)|divide]] over $A$. :But then $\pi$ clearly implies this disjunction as well, completing this direction of the proof. {{qed}} [[Category:Model Theory]] 5xn75ly0rbxveqozd29d7zr8ixy1slr	1
Let $\mathbf B$ a [[Definition:WFF of Propositional Logic|WFF of propositional logic]]. Let $\mathbf A, \mathbf A'$ be [[Definition:Semantic Equivalence for Boolean Interpretations|equivalent]] [[Definition:WFF of Propositional Logic|WFFs]]. Let $\mathbf A$ be a [[Definition:Subformula|subformula]] of $\mathbf B$. Let $\mathbf B' = \mathbf B \left({\mathbf A \,//\, \mathbf A'}\right)$ be the [[Definition:Substitution for Well-Formed Part|substitution]] of $\mathbf A'$ for $\mathbf A$ in $\mathbf B$. Then $\mathbf B$ and $\mathbf B'$ are [[Definition:Semantic Equivalence for Boolean Interpretations|equivalent]].	1
Let $\mathbb D^3$ be centered at the origin, and $D^3$ be some other unit ball in $\R^3$ such that $\mathbb D^3 \cap D^3 = \O$. Let $\mathbb S^2 = \partial \mathbb D^3$. By the [[Hausdorff Paradox]], there exists a [[Definition:Decomposition (Topology)|decomposition]] of $ \mathbb S^2$ into four sets $A, B, C, D$ such that $A, B, C$ and $B \cup C$ are [[Definition:Congruence (Topology)|congruent]], and $D$ is [[Definition:Countable|countable]]. For $r \in \R_{>0}$, define a function $r^*: \R^3 \to \R^3$ as $\map {r^*} {\mathbf x} = r \mathbf x$, and define the [[Definition:Set|sets]]: {{begin-eqn}} {{eqn | l = W | r = \bigcup_{0 \mathop < r \mathop \le 1} \map {r^*} A }} {{eqn | l = X | r = \bigcup_{0 \mathop < r \mathop \le 1} \map {r^*} B }} {{eqn | l = Y | r = \bigcup_{0 \mathop < r \mathop \le 1} \map {r^*} C }} {{eqn | l = Z | r = \bigcup_{0 \mathop < r \mathop \le 1} \map {r^*} D }} {{end-eqn}} Let $T = W \cup Z \cup \set {\mathbf 0}$. $W$ and $X \cup Y$ are clearly congruent by the congruency of $A$ with $B \cup C$, hence $W$ and $X \cup Y$ are [[Definition:Equidecomposable|equidecomposable]]. Since $X$ and $Y$ are congruent, and $W$ and $X$ are congruent, $X \cup Y$ and $W \cup X$ are [[Definition:Equidecomposable|equidecomposable]]. $W$ and $X \cup Y$ as well as $X$ and $W$ are congruent, so $W \cup X$ and $W \cup X \cup Y$ are [[Definition:Equidecomposable|equidecomposable]]. Hence $W$ and $W \cup X \cup Y$ are [[Definition:Equidecomposable|equidecomposable]], by [[Equidecomposability is Equivalence Relation]]. So $T$ and $\mathbb D^3$ are [[Definition:Equidecomposable|equidecomposable]], from [[Equidecomposability Unaffected by Union]]. Similarly we find $X$, $Y$, and $W \cup X \cup Y$ are [[Definition:Equidecomposable|equidecomposable]]. Since $D$ is only [[Definition:Countable|countable]], but $\map {\operatorname {SO} } 3$ is not, we have: :$\exists \phi \in \map {\operatorname {SO} } 3: \map \phi D \subset A \cup B \cup C$ so that $I = \map \phi D \subset W \cup X \cup Y$. Since $X$ and $W \cup X \cup Y$ are [[Definition:Equidecomposable|equidecomposable]], by [[Subsets of Equidecomposable Subsets are Equidecomposable]], $\exists H \subseteq X$ such that $H$ and $I$ are [[Definition:Equidecomposable|equidecomposable]]. Finally, let $p \in X - H$ be a point and define $S = Y \cup H \cup \set p$. Since: :$Y$ and $W \cup X \cup Y$ :$H$ and $Z$ :$\set 0$ and $\set p$ are all [[Definition:Equidecomposable|equidecomposable]] in pairs, $S$ and $\mathbb B^3$ are [[Definition:Equidecomposable|equidecomposable]] by [[Equidecomposability Unaffected by Union]]. Since $D^3$ and $\mathbb D^3$ are congruent, $D^3$ and $S$ are [[Definition:Equidecomposable|equidecomposable]], from [[Equidecomposability is Equivalence Relation]]. By [[Equidecomposability Unaffected by Union]], $T \cup S$ and $\mathbb D^3 \cup D^3$ are [[Definition:Equidecomposable|equidecomposable]]. Hence $T \cup S \subseteq \mathbb D^3 \subset \mathbb D^3 \cup D^3$ are [[Definition:Equidecomposable|equidecomposable]] and so, by the [[Equidecomposable Nested Sets|chain property of equidecomposability]], $\mathbb D^3$ and $\mathbb D^3 \cup D^3$ are [[Definition:Equidecomposable|equidecomposable]]. {{qed}} {{AoC|Hausdorff Paradox}}	1
Let $\mathbf A$ be a [[Definition:WFF of Propositional Logic|WFF]] comprising only the [[Definition:Logical Connective|logical connectives]] $\neg$ and $\iff$. The central claim to this proof is that: :The number of [[Definition:Model (Boolean Interpretations)|models]] for $\mathbf A$ is even. In this claim, we disregard the obvious exceptions of the form $\neg \cdots \neg p$. Firstly, note that including any [[Definition:Propositional Symbol|propositional symbols]] not occurring in $\mathbf A$ in the [[Definition:Truth Table|truth table]] for $\mathbf A$ simply doubles the number of [[Definition:Boolean Interpretation|boolean interpretations]] [[Definition:Model (Boolean Interpretations)|modelling]] $\mathbf A$. Next, it is obvious that if the number of [[Definition:Model (Boolean Interpretations)|models]] of $\mathbf A$ is even, then this also holds for $\neg \mathbf A$. For, by [[Count of Truth Functions]], the total number of [[Definition:Boolean Interpretation|boolean interpretations]] is even. Lastly, to consider $\mathbf A = \mathbf A_1 \iff \mathbf A_2$. Suppose that the claim were verified for $\mathbf A_1$ and $\mathbf A_2$. Then we have the following identities: :$\set {v \mid \map v {\mathbf A_1} = T} = \set {v \mid \map v {\mathbf A_1} = T, \map v {\mathbf A_2} = F} \cup \set {v \mid \map v {\mathbf A_1} = T, \map v {\mathbf A_2} = T}$ :$\set {v \mid \map v {\mathbf A_1} = F} = \set {v \mid \map v {\mathbf A_1} = F, \map v {\mathbf A_2} = F} \cup \set {v \mid \map v {\mathbf A_1} = F, \map v {\mathbf A_2} = T}$ :$\set {v \mid \map v {\mathbf A_2} = T} = \set {v \mid \map v {\mathbf A_1} = T, \map v {\mathbf A_2} = T} \cup \set {v \mid \map v {\mathbf A_1} = F, \map v {\mathbf A_2} = T}$ :$\set {v \mid \map v {\mathbf A_2} = F} = \set {v \mid \map v {\mathbf A_1} = T, \map v {\mathbf A_2} = F} \cup \set {v \mid \map v {\mathbf A_1} = F, \map v {\mathbf A_2} = F}$ The [[Definition:Set|sets]] on the {{RHS}} are [[Definition:Disjoint Sets|disjoint]], while the [[Definition:Set|sets]] on the {{LHS}} have an [[Definition:Even Integer|even number]] of [[Definition:Element|elements]]. Therefore, the [[Definition:Parity|parity]] of the [[Definition:Cardinality|cardinalities]] of the sets on the {{RHS}} must be equal. Then combining the first and fourth equations, the sets: :$\set {v \mid \map v {\mathbf A_1} = T, \map v {\mathbf A_2} = T}$ :$\set {v \mid \map v {\mathbf A_1} = F, \map v {\mathbf A_2} = F}$ have equal [[Definition:Parity|parity]]. Together, these two constitute the set of [[Definition:Model (Boolean Interpretations)|models]] for $\mathbf A$, as can be seen from the [[Definition:Biconditional/Boolean Interpretation|boolean interpretation of $\iff$]]. Therefore, the number of [[Definition:Model (Boolean Interpretations)|models]] for $\mathbf A$ is even. This completes the proof of the claim. On the other hand, the [[Definition:Conditional/Truth Table|truth table]] of $p \implies q$ has three entries $F$, and one $T$. Therefore, $p \implies q$ cannot be expressed in terms of $\neg$ and $\iff$. Hence, $\set {\neg, \iff}$ is not [[Definition:Functionally Complete|functionally complete]]. {{qed}}	1
{{BeginTableau|\neg \left ({p \iff q}\right) \vdash \left({p \lor q} \right) \land \neg \left({p \land q}\right)}} {{Premise|1|\neg \left ({p \iff q}\right)}} {{SequentIntro|2|1|\left({\neg p \land q}\right) \lor \left({p \land \neg q}\right)|1 |[[Non-Equivalence as Disjunction of Conjunctions/Formulation 1|Non-Equivalence as Disjunction of Conjunctions: Formulation 1]] }} {{Commutation|3|1|\left({p \land \neg q}\right) \lor \left({\neg p \land q}\right)|2|Disjunction}} {{Commutation|4|1|\left({p \land \neg q}\right) \lor \left({q \land \neg p}\right)|3|Conjunction}} {{SequentIntro|5|1 |\left ({\left({p \lor q}\right) \land \neg q}\right) \lor \left({\left({q \lor p}\right) \land \neg p}\right) |4 |[[Conjunction of Disjunction with Negation is Conjunction with Negation]] }} {{Commutation|6|1 |\left ({\left({p \lor q}\right) \land \neg q}\right) \lor \left({\left({p \lor q}\right) \land \neg p}\right) |5|Disjunction}} {{SequentIntro|7|1|\left({p \lor q}\right) \land \left({\neg q \lor \neg p}\right)|6 |[[Conjunction Distributes over Disjunction]] }} {{Commutation|8|1|\left({p \lor q}\right) \land \left({\neg p \lor \neg q}\right)|7|Disjunction}} {{DeMorgan|9|1|\left({p \lor q}\right) \land \neg \left({\neg \neg p \land \neg \neg q}\right)|8|Disjunction}} {{DoubleNegElimination|10|1|\left({p \lor q}\right) \land \neg \left({p \land q}\right)|9}} {{EndTableau}} {{BeginTableau|\left({p \lor q} \right) \land \neg \left({p \land q}\right) \vdash \neg \left ({p \iff q}\right)}} {{Premise|1|\left({p \lor q}\right) \land \neg \left({p \land q}\right)}} {{DeMorgan|2|1|\left({p \lor q}\right) \land \left({\neg p \lor \neg q}\right)|1|Disjunction of Negations}} {{Commutation|3|1|\left({p \lor q}\right) \land \left({\neg p \lor \neg q}\right)|2|Disjunction}} {{SequentIntro|4|1 |\left ({\left({p \lor q}\right) \land \neg q}\right) \lor \left({\left({p \lor q}\right) \land \neg p}\right) |3 |[[Conjunction Distributes over Disjunction]] }} {{SequentIntro|5|1|\left({p \land \neg q}\right) \lor \left({q \land \neg p}\right)|4|[[Conjunction of Disjunction with Negation is Conjunction with Negation]]}} {{Commutation|6|1|\left({q \land \neg p}\right) \lor \left({p \land \neg q}\right)|5|Disjunction}} {{Commutation|7|1|\left({\neg p \land q}\right) \lor \left({p \land \neg q}\right)|6|Conjunction}} {{SequentIntro|8|1|\neg \left ({p \iff q}\right)|6|[[Non-Equivalence as Disjunction of Conjunctions/Formulation 1|Non-Equivalence as Disjunction of Conjunctions: Formulation 1]]}} {{EndTableau}} {{qed}}	1
==== [[Rule of Distribution/Disjunction Distributes over Conjunction/Right Distributive/Formulation 1|Formulation 1]] ==== {{:Rule of Distribution/Disjunction Distributes over Conjunction/Right Distributive/Formulation 1}} ==== [[Rule of Distribution/Disjunction Distributes over Conjunction/Right Distributive/Formulation 2|Formulation 2]] ==== {{:Rule of Distribution/Disjunction Distributes over Conjunction/Right Distributive/Formulation 2}}	1
=== Sufficient Condition === Let $\mathcal M$ be an elementary substructure of $\mathcal N$. Then $\mathcal N \models \exists x \phi \left({x, \bar a}\right)$ implies that $\mathcal M \models \exists x \phi \left({x, \bar a}\right)$. Hence there exists some $m$ in $\mathcal M$ such that: :$\mathcal M \models\phi \left({m, \bar a}\right)$. Passing back up to $\mathcal N$ yields the result. {{explain|Worth making it explicit exactly what that result is, so as to clarify what is being sought here.}} {{qed|lemma}} === Necessary Condition === Let $\mathcal M$ be such that: :For every $\mathcal L$-formula $\phi \left({x, \bar v}\right)$ and for every $\bar a$ in $\mathcal M$: ::if there exists an $n$ in $\mathcal N$ such that $\mathcal N \models \phi \left({n, \bar a}\right)$ ::then there exists an $m$ in $\mathcal M$ such that $\mathcal N \models \phi \left({m, \bar a}\right)$. It is to be shown that $\mathcal M$ is an elementary substructure of $\mathcal N$. That is: :for every $\mathcal L$-formula $\psi \left({\bar v}\right)$ and: :for every $\bar a$ in $\mathcal M$: ::$\left({\mathcal M \models \phi \left({\bar a}\right)}\right) \iff \left({\mathcal N \models\phi \left({\bar a}\right)}\right)$ The proof proceeds by induction on complexity of formulas. Let $\psi$ be quantifier free. From [[Quantifier Free Formula is Preserved by Superstructure]], quantifier free formulas with parameters from $\mathcal M$ are preserved when passing to and from superstructures. Hence the result holds. Let the result holds for $\psi$. Consider $\neg \psi$: We have that: :$\left({\mathcal M \models \neg \psi \left({\bar a}\right)}\right) \iff \left({\mathcal M \not \models \psi \left({\bar a}\right)}\right)$ By the inductive hypothesis: :$\left({\mathcal M \not\models\psi \left({\bar a}\right)}\right) \iff \left({\mathcal N \not\models\psi \left({\bar a}\right)}\right)$ Thus the result follows for $\neg \psi$. Let the result hold for $\psi_0$ and $\psi_1$. Consider $\psi_0 \wedge \psi_1$: We have: :$\mathcal M \models \psi_0 \left({\bar a}\right) \wedge \psi_1 \left({\bar a}\right)$ {{iff}}: :$\mathcal M \models\psi_0 \left({\bar a}\right)$ and: :$\mathcal M \models \psi_1 \left({\bar a}\right)$ By the inductive hypothesis: :$\mathcal M \models\psi_0 \left({\bar a}\right)$ and $\mathcal M \models \psi_1 \left({\bar a}\right)$ {{iff}}: :$\mathcal N \models\psi_0 \left({\bar a}\right)$ and $\mathcal N \models \psi_1 \left({\bar a}\right)$ Thus the result follows for $\psi_0 \wedge \psi_1$. Let the result holds for $\psi$. Consider: :$\exists x: \psi \left({x}\right)$ We prove the two directions of this case separately. First let: :$\mathcal M \models \exists x: \psi \left({x, \bar a}\right)$ Then there exists $m \in \mathcal M$ such that: :$\mathcal M \models \psi \left({m, \bar a}\right)$ By the inductive hypothesis: :$\mathcal N \models \psi \left({m, \bar a}\right)$ and so: :$\mathcal N \models \exists x: \psi \left({x, \bar a}\right)$ Conversely, let: :$\mathcal N \models \exists x: \psi \left({x, \bar a}\right)$ By assumption, there exists $m \in \mathcal M$ such that: :$\mathcal N \models \psi \left({m, \bar a}\right)$ By the inductive hypothesis: :$\mathcal M \models \psi \left({m, \bar a}\right)$ and hence: :$\mathcal M \models \exists x: \psi \left({x, \bar a}\right)$ completing the proof. {{qed}}	1
: $\vdash \left({p \implies \left({q \implies r}\right)}\right) \implies \left({q \implies \left({p \implies r}\right)}\right)$	1
{{finish| * every $\mathcal A$ arises as the reduct of some $\mathcal A'$; * every $\mathcal A'$ has the same valuations as its reduct. }}	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the appropriate [[Definition:Truth Value|truth values]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc||c|} \hline p & \land & (p & \lor & q) & p \\ \hline F & F & F & F & F & F \\ F & F & F & T & T & F \\ T & T & T & T & F & T \\ T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
:$p \implies q \dashv \vdash q \iff \left({p \lor q}\right)$	1
:$\displaystyle \sum_{i \mathop \ge 0} \binom n {2 i} = 2^{n - 1}$	1
: $p \implies q \vdash \paren {r \land p} \implies \paren {r \land q}$	1
Consider [[Definition:Constructed Semantics/Instance 1|Instance 1]] of a [[Definition:Constructed Semantics|constructed semantics]], denoted $\mathscr C_1$. Note that $\neg p$ is not a [[Definition:Tautology (Formal Semantics)|tautology]] for $\mathscr C_1$. We will establish that every $\mathscr H_2$-[[Definition:Theorem (Formal Systems)|theorem]] is a $\mathscr C_1$-[[Definition:Tautology (Formal Semantics)|tautology]]. That is, that $\mathscr H_2$ is [[Definition:Sound Proof System|sound]] for $\mathscr C_1$. Starting with the [[Definition:Axiom (Formal Systems)|axioms]]: {{begin-axiom}} {{axiom|n = A1 |lc = [[Rule of Idempotence/Disjunction/Formulation 2/Reverse Implication|Rule of Idempotence]] |m = (p \lor p) \implies p |rc = [[Definition:Constructed Semantics/Instance 1/Rule of Idempotence|Proof of Tautology]] }} {{axiom|n = A2 |lc = [[Rule of Addition/Sequent Form/Formulation 2/Form 2|Rule of Addition]] |m = q \implies (p \lor q) |rc = [[Definition:Constructed Semantics/Instance 1/Rule of Addition|Proof of Tautology]] }} {{axiom|n = A3 |lc = [[Rule of Commutation/Disjunction/Formulation 2/Forward Implication|Rule of Commutation]] |m = (p \lor q) \implies (q \lor p) |rc = [[Definition:Constructed Semantics/Instance 1/Rule of Commutation|Proof of Tautology]] }} {{axiom|n = A4 |lc = [[Factor Principles/Disjunction on Left/Formulation 2|Factor Principle]] |m = (q \implies r) \implies \left({ (p \lor q) \implies (p \lor r)}\right) |rc = [[Definition:Constructed Semantics/Instance 1/Factor Principle|Proof of Tautology]] }} {{end-axiom}} Next it needs to be shown that the [[Definition:Hilbert Proof System/Instance 2|rules of inference of $\mathscr H_2$]] preserve $\mathscr C_1$-[[Definition:Tautology (Formal Semantics)|tautologies]]. === Rule $RST \, 1$: Rule of Uniform Substitution === By definition, any [[Definition:WFF of Propositional Logic|WFF]] is assigned a value $1$ or $2$. Thus, in applying [[Definition:Hilbert Proof System/Instance 2|Rule $RST \, 1$]], we are introducing $1$ or $2$ in the position of a [[Definition:Propositional Variable|propositional variable]]. But all possibilities of assignments of $1$s and $2$s to such [[Definition:Propositional Variable|propositional variables]] were shown not to affect the resulting value $2$ of the axioms. Hence [[Definition:Hilbert Proof System/Instance 2|Rule $RST \, 1$]] preserves $\mathscr C_1$-[[Definition:Tautology (Formal Semantics)|tautologies]]. === Rule $RST \, 2$: Rule of Substitution by Definition === Because the definition of $\mathscr C_1$ was given in terms of [[Definition:Hilbert Proof System/Instance 2|Rule $RST \, 2$]], it cannot affect any of its results. === Rule $RST \, 3$: Rule of Detachment === Suppose $\mathbf A$ and $\mathbf A \implies \mathbf B$ both take value $2$. Then using [[Definition:Hilbert Proof System/Instance 2|Rule $RST \, 2$]], definition $(2)$, we get: :$\neg \mathbf A \lor \mathbf B$ taking value $2$ by assumption. But $\neg \mathbf A$ takes value $1$ by definition of $\neg$. So from the definition of $\lor$ it must be that $\mathbf B$ takes value $2$. Hence [[Definition:Hilbert Proof System/Instance 2|Rule $RST \, 3$]] also produces only [[Definition:WFF of Propositional Logic|WFFs]] of value $2$. === Rule $RST \, 4$: Rule of Adjunction === Suppose $\mathbf A$ and $\mathbf B$ take value $2$. Then: {{begin-eqn}} {{eqn|l = \mathbf A \land \mathbf B |r = 2 \land 2 }} {{eqn|r = \neg ( \neg 2 \lor \neg 2 ) |c = [[Definition:Hilbert Proof System/Instance 2|Rule $RST \, 2 \, (1)$]] }} {{eqn|r = \neg ( 1 \lor 1 ) }} {{eqn|r = \neg 1 }} {{eqn|r = 2 }} {{end-eqn}} proving that [[Definition:Hilbert Proof System/Instance 2|Rule $RST \, 4$]] also produces only $2$s from $2$s. Hence $\mathscr H_2$ is [[Definition:Sound Proof System|sound]] for $\mathscr C_1$. In particular: :$\not\vdash_{\mathscr H_2} \neg p$ Hence $\mathscr H_2$ is [[Definition:Consistent Proof System|consistent]]. {{qed}}	1
Let us use the following abbreviations {{begin-eqn}} {{eqn | l = \phi | o = \text{ for } | r = p \implies q | c = }} {{eqn | l = \psi | o = \text{ for } | r = q \implies r | c = }} {{eqn | l = \chi | o = \text{ for } | r = p \implies r | c = }} {{end-eqn}} From [[Hypothetical Syllogism/Formulation 3|Hypothetical Syllogism: Formulation 3]] we have: : $(1): \quad \vdash \paren {\paren {p \implies q} \land \paren {q \implies r} } \implies \paren {p \implies r}$ {{BeginTableau|\paren {q \implies r} \implies \paren {\paren {p \implies q} \implies \paren {p \implies r} } }} {{Assumption|1|\psi \land \phi}} {{Commutation|2|1|\phi \land \psi|1|Conjunction}} {{SequentIntro|3|1|\chi|2|[[Hypothetical Syllogism/Formulation 3|Hypothetical Syllogism: Formulation 3]] (see $(1)$ above)}} {{Implication|4||\paren {\psi \land \phi} \implies \chi|1|3}} {{SequentIntro|5||\psi \implies \paren {\phi \implies \chi}|4|[[Rule of Exportation]]}} {{EndTableau}} Expanding the abbreviations leads us back to: :$\vdash \paren {q \implies r} \implies \paren {\paren {p \implies q} \implies \paren {p \implies r} }$ {{qed}}	1
By definition, a [[Definition:Minimally Inductive Class under General Mapping|minimally inductive class]] under $g$ is a [[Definition:Minimally Closed Class|minimally closed class under $g$ with respect to $\O$]]. Recall the [[Double Induction Principle for Minimally Closed Class]]: Let $\RR$ be a [[Definition:Relation (Class Theory)|relation]] on $M$ which satisfies: {{begin-axiom}} {{axiom | n = \text D_1 | q = \forall x \in M | m = \map \RR {x, b} }} {{axiom | n = \text D_2 | q = \forall x, y \in M | m = \map \RR {x, y} \land \map \RR {y, x} \implies \map \RR {x, \map g y} }} {{end-axiom}} Then $\map \RR {x, y}$ holds for all $x, y \in M$. In this context: :$b = \O$ and the result follows. {{qed}}	1
: $\vdash \left({\neg p \lor q}\right) \implies \left({p \implies q}\right)$	1
The [[Definition:Conclusion of Syllogism|conclusion]] of a [[Definition:Valid Argument|valid]] [[Definition:Categorical Syllogism|categorical syllogism]] is [[Definition:Negative Categorical Statement|negative]] {{iff}} one of the [[Definition:Premise of Syllogism|premises]] is also [[Definition:Negative Categorical Statement|negative]].	1
Let $F_k$ be the $k$th [[Definition:Fibonacci Numbers|Fibonacci number]]. Then: :$\forall n \ge 2: \gcd \set {F_n, F_{n + 1} } = 1$ where $\gcd \set {a, b}$ denotes the [[Definition:Greatest Common Divisor of Integers|greatest common divisor]] of $a$ and $b$. That is, a [[Definition:Fibonacci Numbers|Fibonacci number]] and the one next to it are [[Definition:Coprime Integers|coprime]].	1
Any [[Definition:Propositional Formula|propositional formula]] can be expressed in [[Definition:Disjunctive Normal Form|disjunctive normal form (DNF)]].	1
{{BeginTableau|p \implies q, q \implies p \vdash p \iff q}} {{Premise|1|p \implies q}} {{Premise|2|q \implies p}} {{BiconditionalIntro|3|1, 2|p \iff q|1|2}} {{EndTableau}} {{Qed}}	1
: $\vdash \left({\left({p \implies q}\right) \land \left({p \implies r}\right)}\right) \implies \left({p \implies \left({q \land r}\right)}\right)$	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] is [[Definition:True|true]] for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc|c|ccccc|} \hline (p & \implies & q) & \iff & (\neg & (p & \land & \neg & q)) \\ \hline F & T & F & T & T & F & F & T & F \\ F & T & T & T & T & F & F & F & T \\ T & F & F & T & F & T & T & T & F \\ T & T & T & T & T & T & F & F & T \\ \hline \end{array}$ {{qed}}	1
:$p \iff q, q \iff r \vdash p \iff r$	1
Let $\map {\mathbf A} x$ be a [[Definition:WFF of Predicate Logic|WFF of predicate logic]]. Let $\tau$ be a [[Definition:Term (Predicate Logic)|term]] which is [[Definition:Freely Substitutable|freely substitutable]] for $x$ in $\mathbf A$. Then $\forall x: \map {\mathbf A} x \implies \map {\mathbf A} \tau$ is a [[Definition:Tautology (Predicate Logic)|tautology]].	1
Let $P$ be a [[Definition:CNF Satisfiability Problem|CNF SAT problem]]. === CNF SAT is NP === A potential solution to $P$ can be verified in polynomial time by checking every clause in $L$ to see if they all have at least one true un-negated variable or one false negated variable. Because a solution can be verified or rejected in polynomial time the problem is [[Definition:NP Complexity Class|NP]] === CNF SAT is NP-hard === We will show this by reducing the [[Definition:Boolean Satisfiability Problem|boolean satisfiability (SAT) problem]] to [[Definition:CNF Satisfiability Problem|CNF SAT]]. The algorithm to convert the [[Definition:Boolean Satisfiability Problem|SAT) problem]] to [[Definition:CNF Satisfiability Problem|CNF SAT]] is recursive. Wherever $A$, $B$,and $C$ are seen in the output it is understood that the algorithm would call itself on those formulas and convert them into [[Definition:Conjunctive Normal Form|CNF]]. ==== iff and xor ==== The first step will be to remove every instance of mutual implication and exclusive or from the problem. In every clause with one of these functions there must be at least one that does not have any instance of mutual implication or exclusive or in its arguments. Introduce a new variable $x$ and replace either: :$A \implies B$ with $x$ or: :$\neg \left({A \implies B}\right)$ with $\neg x$ as appropriate. Then add the following four clauses to $L$: : $A \lor B \lor x$ : $A \lor \neg B \lor \neg x$ : $\neg A \lor B \lor \neg x$ : $\neg A \lor \neg B \lor x$ Repeat this procedure until there are no more mutual implications or exclusive ors in the list of clauses. It is important to note that the amount this procedure adds to the size of the final problem is bounded. Specifically, every instance of mutual implication or exclusive or increases the number of variables by one, increases the number of "new" symbols in $L$ by a fixed number and reproduces every "old" symbol in $L$ at most four times. In total, this step increases the size of the problem at most linearly. The remaining functions that need to be considered can be converted to [[Definition:Conjunctive Normal Form|CNF]] with only a constant amount of increase to the size by a constant amount per production. Given a logical expression it will either be a variable, a unary function, or a binary function. ==== Single Variable ==== If $A$ is a single variable then it is in [[Definition:Conjunctive Normal Form|CNF]] and the task is complete. ==== Unary functions ==== With the two constant functions, one can simply replace $f_F \left({A}\right)$ and $f_T \left({A}\right)$ with $F$ and $T$ respectively. These can then be removed from the final expression as appropriate. {{explain|Link to the results linking $F$ and $T$ with disjunctions / conjunctions etc.}} For the identity function, replace $f_I \left({A}\right)$ with the [[Definition:Conjunctive Normal Form|CNF]] conversion of $A$. With the $\neg$ function the replacement depends on the argument. If the argument is a single variable $x$ then the output $\neg x$ is in [[Definition:Conjunctive Normal Form|CNF]]. If the argument is one of the constant functions then replace $\neg f_F \left({A}\right)$ and $\neg f_T \left({A}\right)$ with $T$ and $F$ respectively. If the argument is a binary function of the form $f \left({A, B}\right)$ then replace the function with the appropriate one, following the list below: : $\neg f_F \left({A, B}\right) \to f_T \left({A, B}\right)$ : $\neg f_T \left({A, B}\right) \to f_F \left({A, B}\right)$ : $\neg A \land B \to A \uparrow B$ : $\neg A \uparrow B \to A \land B$ : $\neg \left({A \implies B}\right) \to \neg \left({A \implies B}\right)$ : $\neg \neg \left({A \implies B}\right) \to \left({A \implies B}\right)$ : $\neg \operatorname{pr}_1 \left({A, B}\right) \to \overline {\operatorname{pr}_1} \left({A, B}\right)$ : $\neg \overline {\operatorname{pr}_1} \left({A, B}\right) \to \operatorname{pr}_1 \left({A, B}\right)$ : $\neg \left({B \implies A}\right) \to \neg \left({B \implies A}\right)$ : $\neg \neg \left({B \implies A}\right) \to \left({B \implies A}\right)$ : $\neg \operatorname{pr}_2 \to \overline {\operatorname{pr}_2}$ : $\neg \overline {\operatorname{pr}_2} \to \operatorname{pr}_2$ : $\neg A \lor B \to A \downarrow B$ : $\neg A \downarrow B \to A \lor B$ ==== Binary Functions ==== Replace $f_T \left({A, B}\right)$ with $T$. $A \lor B$ is already in [[Definition:Conjunctive Normal Form|CNF]]. Replace $A \implies B$ with $\neg A \lor B$. Replace $\operatorname{pr}_1 \left({A, B}\right)$ with $A$. Replace $B \implies A$ with $A \lor \neg B$. Replace $\operatorname{pr}_2 \left({A, B}\right)$ with $B$. In the case of $A \land B$ the clause takes either the form: : $A \land B$ or: :$\left({A \land B}\right) \lor C$ In the first case simply replace the clause with the two clauses $A$ and $B$. In the second case introduce the new variable $x$ and replace the clause with the three clauses: : $x \lor C$ : $\neg x \lor A$ : $\neg x \lor B$ A simple case analysis will show that the above clauses have a solution {{iff}} $\left({A \land B}\right) \lor C$. Replace $A \uparrow B$ with $\neg A \lor \neg B$ Replace $\overline {\operatorname{pr}_2} \left({A, B}\right)$ with $\neg B$. Replace $\neg \left({A \implies B}\right)$ with $A \land \neg B$ and use the rule for $A \land B$. Replace $\overline {\operatorname{pr}_2} \left({A, B}\right)$ with $\neg A$. Replace $\neg \left({B \implies A}\right)$ with $\neg A \land B$ and use the rule for $A \land B$. Replace $A \downarrow B$ with $\neg A \land \neg B$ and use the rule for $A \land B$. Replace $f_F \left({A, B}\right)$ with $F$. At this point there may be some instances of $T$ and $F$ in the clauses. They can be removed by: :deleting any clause from $L$ that contains $T$ in any of its conjunctions and: :removing $F$ from any clause that contains it. Note that if any clause simplifies to $F$ the problem is trivially unsatisfiable and the task is complete. In the end the size and number of variables in the CNF problem is $O(n)$ where $n$ is the number of symbols required to write down the original [[Definition:Boolean Satisfiability Problem|SAT problem]]. Hence the conversion can be done in polynomial time. We have that [[Boolean Satisfiability Problem is NP-hard]]. But [[Definition:Boolean Satisfiability Problem|SAT]] is reducible to [[Definition:CNF Satisfiability Problem|CNF SAT]]. Therefore [[Definition:CNF Satisfiability Problem|CNF SAT]] is [[Definition:NP-Hard|NP-hard]]. [[Definition:CNF Satisfiability Problem|CNF SAT]] is [[Definition:NP-Complete|NP-complete]]. {{explain|The logical steps need to be clarified in the above.}} {{qed}} [[Category:Mathematical Logic]] 8fhj0sypbhdkrrdnp5fv8a0zfherp05	1
Defining $1$ as $\map s 0$ and $2$ as $\map s {\map s 0}$, the statement to be proven becomes: :$\map s 0 + \map s 0 = \map s {\map s 0}$ By the [[Definition:Addition/Peano Structure|definition of addition]]: :$\forall m \in P: \forall n \in P: m + \map s n = \map s {m + n}$ Letting $m = \map s 0$ and $n = 0$: {{begin-eqn}} {{eqn | n = 1 | l = \map s 0 + \map s 0 | r = \map s {\map s 0 + 0} }} {{end-eqn}} By the [[Definition:Addition/Peano Structure|definition of addition]]: :$\forall m: m + 0 = m$ Letting $m = \map s 0$: :$\map s 0 + 0 = \map s 0$ Taking the [[Definition:Successor Mapping on Natural Numbers|successor]] of both sides: {{begin-eqn}} {{eqn | n = 2 | l = \map s {\map s 0 + 0} | r = \map s {\map s 0} }} {{end-eqn}} Applying [[Equality is Transitive]] to $(1)$ and $(2)$ we have: :$\map s 0 + \map s 0 = \map s {\map s 0}$ Hence the result. {{qed}}	1
{{BeginTableau|p \lor \paren {q \land r} \vdash \paren {p \lor q} \land \paren {p \lor r} }} {{Premise | 1|p \lor \paren {q \land r} }} {{Assumption | 2|p}} {{Addition | 3|2|p \lor q|2|1}} {{Addition | 4|2|p \lor r|2|1}} {{Conjunction | 5|2|\paren {p \lor q} \land \paren {p \lor r}|3|4}} {{Assumption | 6|q \land r}} {{Simplification | 7|6|q|6|1}} {{Simplification | 8|6|r|6|2}} {{Addition | 9|6|p \lor q|7|2}} {{Addition |10|6|p \lor r|8|2}} {{Conjunction |11|6|\paren {p \lor q} \land \paren {p \lor r}|7|8}} {{ProofByCases |12|1|\paren {p \lor q} \land \paren {p \lor r}|1|2|5|6|11}} {{EndTableau}} {{qed}} [[Category:Rule of Distribution]] i25mmyxvwb862jvl4ipx120n568xzpk	1
Let $S_n$ denote the $n$th [[Definition:Fibonacci String|Fibonacci string]]. Then: :$(1):\quad$ There are no instances of $2$ $\text a$'s together :$(2):\quad$ There are no instances of $3$ $\text b$'s together in $S_n$.	1
=== [[Rule of Transposition/Formulation 1/Forward Implication/Proof|Proof of Forward Implication]] === {{:Rule of Transposition/Formulation 1/Forward Implication/Proof}} === [[Rule of Transposition/Formulation 1/Reverse Implication/Proof|Proof of Reverse Implication]] === {{:Rule of Transposition/Formulation 1/Reverse Implication/Proof}}	1
An '''inductive argument''' is a form of [[Definition:Logical Argument|argument]] in which, if all the [[Definition:Premise|premises]] are true, the [[Definition:Conclusion|conclusion]] is ''probably true'', but might not be. Such lines of reasoning are ubiquitous in everyday life and in most human endeavors. However, '''inductive arguments''' are only [[Definition:Conjecture|conjectures]] in the field of [[Definition:Mathematics|mathematics]]. Such arguments are not [[Definition:Truth Preservation|truth preserving]] and therefore they are not [[Definition:Proof|proofs]].	1
The proof proceeds by [[Second Principle of Mathematical Induction|strong induction]]. For all $n \in \Z_{\ge 3}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$S_n$ has $F_{n - 2}$ instances of $\text a$ and $F_{n - 1}$ instances of $\text b$. === Basis for the Induction === $\map P 3$ is the case: :$S_n = \text {ba}$ It can be seen that $S_n$ has $F_1 = 1$ instance of $\text a$ and $F_2 = 1$ instance of $\text b$. Thus $\map P 3$ is seen to hold. $\map P 4$ is the case: :$S_n = \text {bab}$ It can be seen that $S_n$ has $F_2 = 1$ instance of $\text a$ and $F_3 = 2$ instances of $\text b$. Thus $\map P 4$ is seen to hold. This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that, if $\map P j$ is true, for all $j$ such that $4 \le j \le k$, then it logically follows that $\map P {k + 1}$ is true. This is the [[Definition:Induction Hypothesis|induction hypothesis]]: :$S_k$ has $F_{k - 2}$ instances of $\text a$ and $F_{k - 1}$ instances of $\text b$ and: :$S_{k - 1}$ has $F_{k - 3}$ instances of $\text a$ and $F_{k - 2}$ instances of $\text b$ from which it is to be shown that: :$S_{k + 1}$ has $F_{k - 1}$ instances of $\text a$ and $F_k$ instances of $\text b$. === Induction Step === This is the [[Definition:Induction Step|induction step]]: By definition of [[Definition:Fibonacci String|Fibonacci string]]: :$S_{k + 1} = S_k S_{k - 1}$ [[Definition:Concatenation (Formal Systems)|concatenated]]. By the [[Count of a's and b's in Fibonacci String#Induction Hypothesis|induction hypothesis]]: :$S_k$ has $F_{k - 2}$ instances of $\text a$ and $F_{k - 1}$ instances of $\text b$ and: :$S_{k - 1}$ has $F_{k - 3}$ instances of $\text a$ and $F_{k - 2}$ instances of $\text b$ So: :$S_{k + 1}$ has $F_{k - 2} + F_{k - 3}$ instances of $\text a$ and so by definition of [[Definition:Fibonacci Number|Fibonacci numbers]]: :$S_{k + 1}$ has $F_{k - 1}$ instances of $\text a$ and: :$S_{k + 1}$ has $F_{k - 1} + F_{k - 2}$ instances of $\text b$ and so by definition of [[Definition:Fibonacci Number|Fibonacci numbers]]: :$S_{k + 1}$ has $F_k$ instances of $\text b$. So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Second Principle of Mathematical Induction]]. Therefore: :for all $n \in \Z$ such that $n \ge 3$: $S_n$ has $F_{n - 2}$ instances of $\text a$ and $F_{n - 1}$ instances of $\text b$. {{qed}}	1
:If we can conclude both $\phi$ and $\neg \phi$, we may infer a [[Definition:Contradiction|contradiction]].	1
: $\neg \left ({p \iff q}\right) \dashv \vdash \neg \left({p \implies q}\right) \lor \neg \left({q \implies p}\right)$	1
Let $\LL$ be a [[Definition:Formal Language|formal language]]. Let the [[Definition:Formal Grammar|formal grammar]] of $\LL$ be a [[Definition:Bottom-Up Grammar|bottom-up grammar]] with [[Definition:Unique Parsability|unique parsability]]. A [[Definition:Definition|definition]] $\map D \phi$ (in the [[Definition:Metalanguage|metalanguage]] of $\LL$) for all [[Definition:Well-Formed Formula|well-formed formulas]] $\phi$ of $\LL$ is uniquely specified by: :$(1): \quad$ A definition $\map D a$ for each [[Definition:Letter|letter]] $a$ of $\LL$ :$(2): \quad$ For each [[Definition:Rule of Formation|rule of formation]] for $\LL$, a definition $\map D \phi$ of the resultant [[Definition:Well-Formed Formula|WFF]] $\phi$ in terms of the constituent [[Definition:Well-Formed Formula|WFF]]s' definitions $\map D {\phi_1}, \ldots, \map D {\phi_n}$.	1
:$p \vdash \left({p \implies q}\right) \implies q$	1
A '''logical argument''' (or just '''argument''') is a process of creating a new [[Definition:Statement|statement]] from one or more existing [[Definition:Statement|statements]]. An '''argument''' proceeds from a set of [[Definition:Premise|premises]] to a [[Definition:Conclusion|conclusion]], by means of [[Definition:Logical Implication|logical implication]], via a procedure called [[Definition:Logical Inference|logical inference]]. An '''argument''' may have more than one [[Definition:Premise|premise]], but only one [[Definition:Conclusion|conclusion]]. While [[Definition:Statement|statements]] may be classified as either '''[[Definition:True|true]]''' or '''[[Definition:False|false]]''', an '''argument''' may be classified as either [[Definition:Valid Argument|valid]] or [[Definition:Invalid Argument|invalid]].	1
{{proof wanted|While an exercise, this basically requires construction of the syntactic model in order to achieve full rigour}}	1
:$p \lor \left({q \lor r}\right) \dashv \vdash \left({p \lor q}\right) \lor r$	1
:$\left({q \land r}\right) \lor p \dashv \vdash \left({q \lor p}\right) \land \left({r \lor p}\right)$	1
This is a straightforward application of the downward [[Löwenheim-Skolem Theorem]]. {{qed}} {{refactor|From here on down, decide where it belongs and how it is to be presented. At the moment it is too much like an encyclopedia article to be compatible with {{ProofWiki}}'s dictionary style.}}	1
The only [[Definition:WFF of Propositional Logic|WFFs of propositional logic]] of [[Definition:Length of String|length]] $1$ are: * The [[Definition:Letter|letters]] of the [[Definition:Formal Grammar of Propositional Logic|formal grammar of propositional logic]] $\mathcal L_0$ * The [[Definition:Top (Logic)|tautology symbol]] $\top$ * The [[Definition:Bottom (Logic)|contradiction symbol]] $\bot$.	1
Let $S_n$ be a [[Definition:Fibonacci String|Fibonacci string]] of [[Definition:Length of String|length]] $n$. Then for $n \ge 3$, $S_n$ begins with $\text{ba}$.	1
Let $\mathscr M$ be a [[Definition:Formal Semantics|formal semantics]] for a [[Definition:Formal Language|formal language]] $\mathcal L$. Let $\mathcal F$ be a collection of [[Definition:Well-Formed Formula|WFFs]] of $\mathcal L$. Let $\map {\mathscr M} {\mathcal F}$ be the [[Definition:Formal Semantics|formal semantics]] obtained from $\mathscr M$ by retaining only the [[Definition:Structure (Formal Systems)|structures]] of $\mathscr M$ that are [[Definition:Model of Set of Formulas|models]] of $\mathcal F$. Let $\phi$ be a [[Definition:Tautology (Formal Semantics)|tautology]] for $\map {\mathscr M} {\mathcal F}$. Then $\phi$ is called a '''semantic consequence of $\mathcal F$''', and this is denoted as: :$\mathcal F \models_{\mathscr M} \phi$ That is to say, $\phi$ is a '''semantic consequence of $\mathcal F$''' {{iff}}, for each $\mathscr M$-[[Definition:Structure (Formal Systems)|structure]] $\mathcal M$: :$\mathcal M \models_{\mathscr M} \mathcal F$ implies $\mathcal M \models_{\mathscr M} \phi$ where $\models_{\mathscr M}$ is the [[Definition:Model (Logic)|models]] relation. Note in particular that for $\mathcal F = \O$, the notation agrees with the notation for a $\mathscr M$-[[Definition:Tautology (Formal Semantics)|tautology]]: :$\models_{\mathscr M} \phi$ The concept naturally generalises to [[Definition:Set|sets]] of [[Definition:Logical Formula|formulas]] $\mathcal G$ on the {{RHS}}: :$\mathcal F \models_{\mathscr M} \mathcal G$ {{iff}} $\mathcal F \models_{\mathscr M} \phi$ for every $\phi \in \mathcal G$.	1
:$\paren {p \lor r} \land \paren {q \lor \neg r} \vdash p \lor q$	1
Let $T$ be a [[Definition:Term of Syllogism|term]] of the [[Definition:Conclusion of Syllogism|conclusion]] $C$ of a [[Definition:Valid Argument|valid]] [[Definition:Categorical Syllogism|categorical syllogism]] $Q$. Let $T$ be [[Definition:Distributed Term of Categorical Syllogism|distributed]] in $C$. Then $T$ is also [[Definition:Distributed Term of Categorical Syllogism|distributed]] in whichever [[Definition:Premise of Syllogism|premise]] of $Q$ in which it appears.	1
{{BeginTableau|\paren {p \implies q} \land \paren {r \implies s}, \neg q \lor \neg s \vdash \neg p \lor \neg r}} {{Premise|1|\paren {p \implies q} \land \paren {r \implies s} }} {{Premise|2|\neg q \lor \neg s}} {{Simplification|3|1|p \implies q|1|1}} {{Simplification|4|1|r \implies s|1|2}} {{Assumption|5|\neg q}} {{ModusTollens|6|1, 5|\neg p|3|5}} {{Addition|7|1, 5|\neg p \lor \neg r|6|1}} {{Assumption|8|\neg s}} {{ModusTollens|9|1, 8|\neg r|4|8}} {{Addition|10|1, 8|\neg p \lor \neg r|9|2}} {{ProofByCases|11|1, 2|\neg p \lor \neg r|2|5|7|8|10}} {{EndTableau}} {{qed}}	1
Let $\mathbf A$ be a [[Definition:Semantic Consequence|semantic consequence]] of $\mathbf H$ for [[Definition:Boolean Interpretation|boolean interpretations]]. That is, if $v \models_{\mathrm{BI}} \mathbf H$, also $v \models_{\mathrm{BI}} \mathbf A$. By the [[Definition:Logical Not/Truth Function|truth function for $\neg$]], it follows that for such $v$: :$v \not\models_{\mathrm{BI}} \neg \mathbf A$ Therefore, $\mathbf H' := \mathbf H \cup \left\{{\mathbf A}\right\}$ is [[Definition:Unsatisfiable|unsatisfiable]] for [[Definition:Boolean Interpretation|boolean interpretations]]. Since $\mathbf H'$ is [[Definition:Countable Set|countable]], it follows from the [[Compactness Theorem for Boolean Interpretations]] that: :Some [[Definition:Finite Set|finite]] $\mathbf H'' \subseteq \mathbf H'$ is [[Definition:Unsatisfiable|unsatisfiable]]. By the [[Tableau Extension Lemma]], there exists a [[Definition:Finite Propositional Tableau|finite]] [[Definition:Finished Propositional Tableau|finished tableau]] $T$ for $\mathbf H''$. By definition of [[Definition:Finished Propositional Tableau|finished tableau]], every [[Definition:Branch (Graph Theory)|branch]] of $T$ is [[Definition:Finished Branch of Propositional Tableau|finished]] or [[Definition:Contradictory Branch|contradictory]]. From the [[Finished Branch Lemma/Corollary|Corollary to the Finished Branch Lemma]], $\Phi \left[{\Gamma}\right]$ is [[Definition:Satisfiable|satisfiable]] for any [[Definition:Finished Branch of Propositional Tableau|finished branch]] $\Gamma$. But since $\mathbf H'' \subseteq \Phi \left[{\Gamma}\right]$, this would imply $\mathbf H''$ is also [[Definition:Satisfiable|satisfiable]], which is a contradiction. It follows that every [[Definition:Branch (Graph Theory)|branch]] of $T$ is [[Definition:Contradictory Branch|contradictory]]. Since $\mathbf H'' \subseteq \mathbf H'$, replacing the [[Definition:Hypothesis Set|hypothesis set]] $\mathbf H'$ of $T$ with $\mathbf H''$ yields another [[Definition:Propositional Tableau|propositional tableau]] $T'$. Since every [[Definition:Branch (Graph Theory)|branch]] of $T'$ is [[Definition:Contradictory Branch|contradictory]], $T'$ is a [[Definition:Tableau Confutation|tableau confutation]] of $\mathbf H'$. Recalling that $\mathbf H' = \mathbf H \cup \left\{{\neg\mathbf A}\right\}$, we conclude that $T'$ is a [[Definition:Tableau Proof (Propositional Tableaus)|tableau proof]] of $\mathbf A$ from $\mathbf H$: :$\mathbf H \vdash_{\mathrm{PT}} \mathbf A$ {{qed}}	1
:$p \land q := \neg \left({\neg p \lor \neg q}\right)$	1
{{BeginTableau|\neg p \implies \left({q \land \neg q}\right) \vdash p}} {{Premise|1|\neg p \implies \left({q \land \neg q}\right)}} {{Assumption|2|\neg p}} {{ModusPonens|3|1, 2|q \land \neg q|1|2}} {{Simplification|4|1, 2|q|3|1}} {{Simplification|5|1, 2|\neg q|3|2}} {{NonContradiction|6|1, 2|4|5}} {{Contradiction|7|1|\neg \neg p|2|6}} {{DoubleNegElimination|8|1|p|7}} {{EndTableau}} {{qed}}	1
Let $\mathcal M$ be an $\mathcal L$-[[Definition:First-Order Structure|structure]], and let $A$ be a subset of the universe of $\mathcal M$. The [[Definition:Type Space|type space]] $S_n^{\mathcal M}(A)$ of $n$-types over $A$ is [[Definition:Compact Topological Space|compact]].	1
Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \N_{>0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\displaystyle \sum_{j \mathop = 1}^n {F_j}^2 = F_n F_{n + 1}$ === Basis for the Induction === $\map P 1$ is the case ${F_1}^2 = 1 = F_3 - 1$, which holds from the definition of [[Definition:Fibonacci Numbers|Fibonacci numbers]]. {{begin-eqn}} {{eqn | l = \sum_{j \mathop = 1}^1 {F_j}^2 | r = {F_1}^2 | c = }} {{eqn | r = 1 \times 1 | c = }} {{eqn | r = F_1 \times F_2 | c = }} {{end-eqn}} demonstrating that $\map P 1$ holds. This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\displaystyle \sum_{j \mathop = 1}^k {F_j}^2 = F_k F_{k + 1}$ Then we need to show: :$\displaystyle \sum_{j \mathop = 1}^{k + 1} {F_j}^2 = F_{k + 1} F_{k + 2}$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \sum_{j \mathop = 1}^{k + 1} {F_j}^2 | r = \sum_{j \mathop = 1}^k {F_j}^2 + {F_{k + 1} }^2 | c = }} {{eqn | r = F_k F_{k + 1} + {F_{k + 1} }^2 | c = [[Sum of Sequence of Squares of Fibonacci Numbers#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \paren {F_k + F_{k + 1} } F_{k + 1} | c = }} {{eqn | r = F_{k + 2} F_{k + 1} | c = {{Defof|Fibonacci Number}} }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\forall n \ge 1: \displaystyle \sum_{j \mathop = 1}^n {F_j}^2 = F_n F_{n + 1}$ {{qed}}	1
The proof proceeds by [[Principle of General Induction|general induction]]. Let an [[Definition:Element of Class|element]] $x$ of $M$ be defined as: :'''[[Definition:Left Normal Element of Relation|left normal]]''' with respect to $\RR$ {{iff}} $\map \RR {x, y}$ for all $y \in M$ :'''[[Definition:Right Normal Element of Relation|right normal]]''' with respect to $\RR$ {{iff}} $\map \RR {y, x}$ for all $y \in M$. Let the hypothesis be assumed. First we demonstrate a [[Definition:Lemma|lemma]]: === [[Double Induction Principle/Lemma|Lemma]] === {{:Double Induction Principle/Lemma}}{{qed|lemma}} We now show by [[Principle of General Induction|general induction]] that every $x \in M$ is [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$. It then follows from the [[Double Induction Principle/Lemma|lemma]] that $\map \RR {x, y}$ for all $x, y \in M$. === Basis for the Induction === $\map P \O$ is the case: From condition $\text D_1$ of the definition of $\RR$, we have immediately that: :$\map \RR {x, \O}$ for all $x \in M$. That is, that $\O$ is [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$. Thus $\map P \O$ is seen to hold. This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that if $\map P x$ is true, where $x \in M$, then it logically follows that $\map P {\map g x}$ is true. So this is the [[Definition:Induction Hypothesis|induction hypothesis]]: :$x$ is [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$ from which it is to be shown that: :$\map g x$ is [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$. === Induction Step === This is the [[Definition:Induction Step|induction step]]: Let $x \in M$ be [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$: :$\forall y \in M: \map \RR {y, x}$ By the [[Double Induction Principle/Lemma|lemma]] we have that $x$ is [[Definition:Left Normal Element of Relation|left normal]] with respect to $\RR$. That is: :$\forall y \in M: \map \RR {x, y}$ Thus by condition $\text D_2$ of the definition of $\RR$: :$\forall y \in M: \map \RR {y, \map g x}$ That is, $\map g x$ is [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$. So $\map P x \implies \map P {\map g x}$ and by the [[Principle of General Induction]]: :$\forall x \in M$: $x$ is [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$. The result follows. {{qed}}	1
=== [[Rule of Addition/Sequent Form/Formulation 2/Proof 1/Form 1|Form 1]] === {{:Rule of Addition/Sequent Form/Formulation 2/Proof 1/Form 1}} === [[Rule of Addition/Sequent Form/Formulation 2/Proof 1/Form 2|Form 2]] === {{:Rule of Addition/Sequent Form/Formulation 2/Proof 1/Form 2}}	1
[[Definition:Tableau Proof (Propositional Tableaus)|Tableau proofs]] (in terms of [[Definition:Propositional Tableau|propositional tableaus]]) are a [[Definition:Strongly Sound Proof System|strongly sound proof system]] for [[Definition:Boolean Interpretation|boolean interpretations]]. That is, for every collection $\mathbf H$ of [[Definition:WFF of Propositional Logic|WFFs of propositional logic]] and every [[Definition:WFF of Propositional Logic|WFF]] $\mathbf A$: :$\mathbf H \vdash_{\mathrm{PT}} \mathbf A$ implies $\mathbf H \models_{\mathrm{BI}} \mathbf A$	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] is [[Definition:True|true]] for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc|c|ccccccc|} \hline p & \lor & (q & \land & r) & \iff & (p & \lor & q) & \land & (p & \lor & r) \\ \hline F & F & F & F & F & T & F & F & F & F & F & F & F \\ F & F & F & F & T & T & F & F & F & F & F & T & T \\ F & F & T & F & F & T & F & T & T & F & F & F & F \\ F & T & T & T & T & T & F & T & T & T & F & T & T \\ T & T & F & F & F & T & T & T & F & T & T & T & F \\ T & T & F & F & T & T & T & T & F & T & T & T & T \\ T & T & T & F & F & T & T & T & T & T & T & T & F \\ T & T & T & T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
:$\left({p \lor q}\right) \land \neg q \dashv \vdash p \land \neg q$	1
: $\vdash \left({p \land q}\right) \iff \left({\neg \left({\neg p \lor \neg q}\right)}\right)$	1
Every [[Definition:URM Computability#Function|URM computable function]] is [[Definition:Recursive Function|recursive]].	1
{{BeginTableau|p \land q \vdash q \land p}} {{Premise|1|p \land q}} {{Simplification|2|1|p|1|1}} {{Simplification|3|1|q|1|2}} {{Conjunction|4|1|q \land p|3|2}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|q \land p \vdash p \land q}} {{Premise|1|q \land p}} {{Simplification|2|1|q|1|1}} {{Simplification|2|1|p|1|2}} {{Conjunction|4|1|p \land q|3|2}} {{EndTableau}} {{qed}}	1
We can define $p$ recursively by: :$p \left({n + 1}\right) = \text{the smallest } y \in \N \text { such that } y \text { is prime and } p \left({n}\right) \le y$ Hence we can express it as: :$p \left({n + 1}\right) = \mu y \left({\chi_\Bbb P \left({y}\right) = 1 \land p \left({n}\right) \le y}\right)$ where: * $\chi_\Bbb P \left({y}\right)$ is the [[Definition:Characteristic Function of Set|characteristic function]] of the [[Definition:Set|set]] of [[Definition:Prime Number|prime numbers]] $\Bbb P$ * $\mu y \left({\mathcal R}\right)$ means '''the smallest $y \in \N$ such that the [[Definition:Relation|relation]] $\mathcal R$ holds'''. {{questionable|Sure about the less-than-or equal-to at the end of those expressions? Surely it should be less-than? See talk page.}} Now consider the [[Definition:Relation|relation]] $\mathcal S$ given by: :$\mathcal S \left({m, y}\right) \iff \chi_\Bbb P \left({y}\right) = 1$. We have a reason for making $\mathcal S$ a binary relation, even though $m$ is not actually invoked in its definition. Then we have: :$\chi_\mathcal S \left({m, y}\right) = \chi_{\operatorname{eq}} \left({\chi_\Bbb P \left({y}\right), 1}\right)$. So $\chi_\mathcal S$ is [[Definition:Primitive Recursive Function|primitive recursive]] as it is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from: * the [[Equality Relation is Primitive Recursive|primitive recursive function $\chi_{\operatorname{eq}}$]] * the [[Set of Prime Numbers is Primitive Recursive|primitive recursive function $\chi_\Bbb P$]]. Then we have that [[Ordering Relations are Primitive Recursive|$<$ is primitive recursive]]. So we define the [[Definition:Relation|relation]] $\mathcal R$ by: :$\mathcal R \left({m, y}\right) \iff \mathcal S \left({m, y}\right) \land m < y \iff \chi_\Bbb P \left({y}\right) = 1 \land m < y$. This is [[Definition:Primitive Recursive Relation|primitive recursive]] from the above and [[Set Operations on Primitive Recursive Relations]]. Now let us define the [[Definition:Function|function]] $g: \N^2 \to \N$ as: :$g \left({m, z}\right) = \mu y \le z \left({\chi_\Bbb P \left({y}\right) = 1 \land m < y}\right)$ which is [[Definition:Primitive Recursive Function|primitive recursive]] by [[Bounded Minimization is Primitive Recursive]]. We note that $g \left({p \left({n}\right), z}\right) = p \left({n + 1}\right)$ as long as $p \left({n + 1}\right) \le z$. Next, let $h: \N \to \N$ be defined as $h \left({n}\right) = \exp \left({2, \exp \left({2, n}\right)}\right)$. Then $h$ is [[Definition:Primitive Recursive Function|primitive recursive]] since it is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from: * the [[Exponentiation is Primitive Recursive|primitive recursive function $\exp$]]; * the [[Constant Function is Primitive Recursive|constant $2$]]. From [[Upper Bounds for Prime Numbers]], we have $p \left({n+1}\right) \le 2^{2^n} = h \left({n}\right)$. It follows that: :$p \left({n+1}\right) = g \left({p \left({n}\right), h \left({n}\right)}\right)$ where $g$ and $h$ are both [[Definition:Primitive Recursive Function|primitive recursive]]. So using the definition of $p$ as given above, we have: :$p \left({0}\right) = 1$ :$p \left({n+1}\right) = g \left({p \left({n}\right), h \left({n}\right)}\right)$. So $p$ is defined by [[Definition:Primitive Recursion|primitive recursion]] from the [[Constant Function is Primitive Recursive|constant $1$]] and the [[Definition:Primitive Recursive Function|primitive recursive functions]] $g$ and $h$. {{qed}}	1
{{BeginTableau|p \oplus q \vdash q \oplus p}} {{Premise|1|p \oplus q}} {{SequentIntro|2|1|\left({p \lor q} \right) \land \neg \left({p \land q}\right)|1|Definition of [[Non-Equivalence|Exclusive Or]]}} {{Commutation|3|1|\left({q \lor p} \right) \land \neg \left({p \land q}\right)|2|Disjunction}} {{Commutation|4|1|\left({q \lor p} \right) \land \neg \left({q \land p}\right)|3|Conjunction}} {{SequentIntro|5|1|q \oplus p|4|Definition of [[Non-Equivalence|Exclusive Or]]}} {{EndTableau}} {{BeginTableau|q \oplus p \vdash p \oplus q}} {{Premise|1|q \oplus p}} {{SequentIntro|2|1|\left({q \lor p} \right) \land \neg \left({q \land p}\right)|1|Definition of [[Non-Equivalence|Exclusive Or]]}} {{Commutation|3|1|\left({q \lor p} \right) \land \neg \left({p \land q}\right)|2|Conjunction}} {{Commutation|4|1|\left({p \lor q} \right) \land \neg \left({p \land q}\right)|3|Disjunction}} {{SequentIntro|5|1|p \oplus q|4|Definition of [[Non-Equivalence|Exclusive Or]]}} {{EndTableau}} {{qed}}	1
Let $E \subseteq \N$ be the [[Definition:Set|set]] of all [[Definition:Even Integer|even]] [[Definition:Natural Numbers|natural numbers]]. Then $E$ is [[Definition:Primitive Recursive Set|primitive recursive]].	1
The proof uses [[Principle of Mathematical Induction|induction]] on the number $n$ of elements of $\mathbf H$. Suppose we are given the result for the case $n = 1$, that is, when $\mathbf H$ is a [[Definition:Singleton|singleton]]. Suppose also that we are given the result for all sets $\mathbf H'$ with $n$ [[Definition:Element|elements]]. Now, given a set $\mathbf H' = \left\{{\mathbf A_1, \ldots, \mathbf A_{n+1}}\right\}$ with $n+1$ [[Definition:Element|elements]]. Let $T$ be a [[Definition:Finite Propositional Tableau|finite propositional tableau]]. By induction hypothesis, there is a [[Definition:Finished Propositional Tableau|finished]] [[Definition:Finite Propositional Tableau|finite propositional tableau]] $T'$ containing $T$ as a [[Definition:Subgraph|subgraph]], and with [[Definition:Root of Propositional Tableau|root]] $\mathbf H \cup \left\{{\mathbf A_1, \ldots, \mathbf A_n}\right)$. Now apply the case $n = 1$ to this resulting [[Definition:Propositional Tableau|propositional tableau]] $T'$ and the set $\left\{{\mathbf A_{n+1}}\right\}$. This yields a [[Definition:Finished Propositional Tableau|finished]] [[Definition:Finite Propositional Tableau|finite propositional tableau]] $T''$ which: $(1):\quad$ has [[Definition:Root of Propositional Tableau|root]] $\mathbf H \cup \left\{{\mathbf A_1, \ldots, \mathbf A_n}\right\} \cup \left\{{\mathbf A_{n+1}}\right\} = \mathbf H \cup \mathbf H'$; $(2):\quad$ contains $T'$ as a [[Definition:Subgraph|subgraph]]. But then $T''$ also contains $T$ as a [[Definition:Subgraph|subgraph]], proving the result for $\mathbf H'$. It thus only remains to take care of the base cases $n = 0$ and $n = 1$. First, the case $n = 0$. Let $T$ be a [[Definition:Finite Propositional Tableau|finite propositional tableau]]. To find the [[Definition:Finite Propositional Tableau|finite propositional tableau]] $T'$ with the desired properties, we use some of the [[Definition:Propositional Tableau/Definition 2|tableau construction rules]], starting with $T$. Let $t$ be any [[Definition:Leaf Node|leaf node]] of $T$, and let $\Gamma_t$ be the [[Definition:Branch (Graph Theory)|branch]] from [[Leaf of Rooted Tree is on One Branch]]. Let $n \left({\Gamma_t}\right)$ be the number of non-[[Definition:Basic WFF|basic WFFs]] that were not [[Definition:Used WFF|used]] to add any of the [[Definition:Node (Graph Theory)|nodes]] of $\Gamma_t$ to $T$. It is seen that for any application of the [[Definition:Propositional Tableau/Definition 2|tableau construction rules]] on $t$: :If $s$ is added by the rule, then $n \left({\Gamma_s}\right) \le n \left({\Gamma_t}\right)$. Moreover, it is seen that any rule reduces the total count $m \left({\Gamma_t}\right)$ of [[Definition:Logical Connective|logical connectives]] occurring in these non-[[Definition:Basic WFF|basic]], [[Definition:Used WFF|unused]] [[Definition:WFF of Propositional Logic|WFFs]] [[Definition:Occurrence along Branch|along]] $\Gamma_t$. In conclusion: :If $s$ is added by a rule, then $m \left({\Gamma_s}\right) < m \left({\Gamma_t}\right)$ By the [[Method of Infinite Descent]] applied to $m \left({\Gamma_t}\right)$, only finitely many rules can be applied, starting from $t$. Since $T$ has only finitely many [[Definition:Leaf Node|leaves]] and corresponding [[Definition:Branch (Graph Theory)|branches]], only finitely many rules can be applied to $T$ in total. Let $T'$ be the [[Definition:Finite Propositional Tableau|finite propositional tableau]] resulting from applying all these possible rules. By construction of $T'$, it follows that every [[Definition:Branch (Graph Theory)|branch]] of $\Gamma$ is either [[Definition:Contradictory Branch|contradictory]] or [[Definition:Finished Branch of Propositional Tableau|finished]]. That is, $T'$ is [[Definition:Finished Propositional Tableau|finished]]. Finally, the last case, $n = 1$. Let $\mathbf A$ be a [[Definition:WFF of Propositional Logic|WFF of propositional logic]]. Let $T$ be a [[Definition:Finite Propositional Tableau|finite propositional tableau]]. First, using the case $n = 0$, extend $T$ to a [[Definition:Finished Propositional Tableau|finished]] [[Definition:Finite Propositional Tableau|finite propositional tableau]] $T'$. Again using the case $n = 0$, let $T_{\mathbf A}$ be a [[Definition:Finished Propositional Tableau|finished]] [[Definition:Finite Propositional Tableau|finite propositional tableau]] with [[Definition:Root of Propositional Tableau|root]] $\left\{{\mathbf A}\right\}$. Now add $\mathbf A$ to the [[Definition:Root of Propositional Tableau|root]] of $T'$. Then at every [[Definition:Leaf Node|leaf]] $t$ of $T'$, $\mathbf A$ is the only [[Definition:WFF of Propositional Logic|WFF]] that is not used yet. As far as the [[Definition:Propositional Tableau/Definition 2|rules for propositional tableaus]] are concerned, there is no difference between: :$t$ as a [[Definition:Leaf Node|leaf]] of $T'$, and :the [[Definition:Propositional Tableau|tableau]] consisting only of a [[Definition:Root of Propositional Tableau|root]] and with [[Definition:Hypothesis Set|hypothesis set]] $\mathbf A$. Therefore, the rules allow to "paste", as it were, the [[Finished Propositional Tableau|finished tableau]] $T_{\mathbf A}$ under every [[Definition:Leaf Node|leaf]] $t$ of $T'$. Denote the resulting [[Definition:Propositional Tableau|tableau]] with $T'_{\mathbf A}$. Then for any [[Definition:Branch (Graph Theory)|branch]] $\Gamma$ of $T'_{\mathbf A}$ and every non-[[Definition:Basic WFF|basic WFF]] $\mathbf B$ [[Definition:Occurrence along Branch|along]] it: :$\mathbf B$ is on $T'$, or: :$\mathbf B$ is on a copy of $T_{\mathbf A}$. In either case, the [[Definition:Finished Propositional Tableau|finished]] nature of these [[Definition:Propositional Tableau|tableaus]] implies that: :$\mathbf B$ is [[Definition:Used WFF|used]] at some [[Definition:Node (Graph Theory)|node]] of $\Gamma$ Hence $\Gamma$ is [[Definition:Contradictory Branch|contradictory]] or [[Definition:Finished Branch of Propositional Tableau|finished]]. In conclusion, $T'_{\mathbf A}$ is [[Definition:Finished Propositional Tableau|finished]], and contains $T$ as a [[Definition:Subgraph|subgraph]]. The result follows from the [[Principle of Mathematical Induction]]. {{qed}}	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] is [[Definition:True|true]] for all [[Definition:Boolean Interpretation|boolean interpretations]], proving a [[Definition:Tautology (Boolean Interpretations)|tautology]]. $\begin{array}{|ccccccc|} \hline (p & \implies & q) & \lor & (q & \implies & p) \\ \hline F & T & F & T & F & T & F \\ F & T & T & T & T & F & F \\ T & F & F & T & F & T & T \\ T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
{{BeginTableau|p \implies \paren {q \lor r} \vdash \paren {p \implies q} \lor \paren {p \implies r} }} {{Assumption|1|p \implies \paren {q \lor r} }} {{Assumption|2|p}} {{ModusPonens|3|1, 2|q \lor r|1|2}} {{IdentityLaw|4|2|p|2}} {{Assumption|5|q}} {{Implication|6|5|p \implies q|4|5}} {{Addition|7|5|\paren {p \implies q} \lor \paren {p \implies r}|6|1}} {{Assumption|8|r}} {{SequentIntro|9|8|p \implies r|8|[[True Statement is implied by Every Statement]]}} {{Addition|10|8|\paren {p \implies q} \lor \paren {p \implies r}|9|2}} {{ProofByCases|11|1|\paren {p \implies q} \lor \paren {p \implies r}|3|2|7|8|10}} {{EndTableau}} {{qed}} [[Category:Implication is Left Distributive over Disjunction]] iuw2ti0tdligmxfmhge8tid9aanq9iv	1
:$\neg p \implies \neg \paren {p \land q}$	1
: $\left({p \implies q}\right) \land \left({\neg p \implies q}\right) \vdash q$	1
Let $\mathbf A$ be a [[Definition:WFF of Predicate Logic|WFF of predicate logic]]. Let $\mathbf S$ be an [[Definition:Initial Part|initial part]] of $\mathbf A$. Then $\mathbf S$ is not a [[Definition:WFF of Predicate Logic|WFF of predicate logic]].	1
A '''definition''' lays down the meaning of a concept. It is a [[Definition:Statement|statement]] which tells the reader '''what something is'''. It can be understood as an [[Definition:Equation|equation]] in (usually) [[Definition:Natural Language|natural language]].	1
{{BeginTableau|p \implies \neg q \vdash \neg \paren {p \land q} }} {{Premise|1|p \implies \neg q}} {{Assumption|2|p \land q|Assume the opposite of what is to be proved ...}} {{Simplification|3|2|p|2|1}} {{Simplification|4|2|q|2|2}} {{ModusPonens|5|1, 2|\neg q|1|3}} {{NonContradiction|6|1, 2|4|5|... and demonstrate a contradiction}} {{Contradiction|7|1|\neg \paren {p \land q}|2|6}} {{EndTableau|qed}} [[Category:Modus Ponendo Tollens]] 5z8tpfk79jnx16ntyyx18hj42odr2ag	1
:$\vdash p \implies \left({\left({p \implies q}\right) \implies q}\right)$	1
:$\vdash \paren {p \lor q} \iff \paren {q \lor p}$	1
Because $a_n = \map \OO {\sequence {b_n} }$, there exists $K \ge 0$ and $n_0 \in \N$ such that $\size {a_n} \le K \cdot \size {b_n}$ for $n \ge n_0$. Because $b_n = \map \OO {\sequence {c_n} }$, there exists $L \ge 0$ and $n_1 \in \N$ such that $\size {b_n} \le L \cdot \size {c_n}$ for $n \ge n_1$. Then $\size {a_n} \le K L \cdot \size {c_n}$ for $n \ge \max \set {n_0, n_1}$. Thus $a_n = \map \OO {\sequence {c_n} }$. {{qed}} [[Category:Asymptotic Notation]] irejv5z2pk0odh7n08v6of2ee5kohph	1
Consider the [[Definition:Basic Primitive Recursive Function|basic primitive recursive functions]]. To each [[Definition:Basic Primitive Recursive Function|basic primitive recursive function]] $f$ let us assign a code number $\delta \left({f}\right)$, as follows: * $\delta \left({\operatorname{zero}}\right) = 3$ * $\delta \left({\operatorname{succ}}\right) = 9$ * $\forall k, m \in \N^*: m \le k: \delta \left({\operatorname{pr}^k_m}\right) = 2^k 3^m$ Suppose the [[Definition:Function|function]] $h$ is defined by [[Definition:Substitution (Mathematical Logic)|substitution]] from the functions $f, g_1, g_2, \ldots, g_t$ to which we have already assigned code numbers. Then we put: :$\delta \left({h}\right) = 2^{\delta \left({f}\right)} 3^{\delta \left({g_1}\right)} 5^{\delta \left({g_2}\right)} \cdots p_{t+1}^{\delta \left({g_t}\right)} + 1$ Suppose the [[Definition:Function|function]] $h$ is defined by [[Definition:Primitive Recursion|primitive recursion]] from the functions $f$ and $g$ to which we have already assigned code numbers. Then we put: :$\delta \left({h}\right) = 2^{\delta \left({f}\right)} 3^{\delta \left({g}\right)} + 2$ Thus we assign a '''code number''' to every definition of a [[Definition:Primitive Recursive Function|primitive recursive function]]. Given any [[Definition:Natural Numbers|natural number]] $m$ we can determine whether $m$ is the code number for a definition of a primitive recursive function, and if so, work out what definition it encodes. In particular, given any such $m$ we can work out whether it encodes a [[Definition:Primitive Recursive Function|primitive recursive function]] $f: \N \to \N$, and determine how $f$ is built up from [[Definition:Basic Primitive Recursive Function|basic primitive recursive functions]] on up. From this definition, we can compute all the values of $f$ for all inputs $n \in \N$. So, we define the [[Definition:Function|function]] $\Phi: \N^2 \to \N$ as follows: :$\Phi \left({m, n}\right) = \begin{cases} f \left({n}\right) & : \text{if } m \text { codes a definition of the primitive recursive function } f: \N \to \N \\ 0 & : \text{otherwise} \end{cases}$ It is deducible by arguments derived from proofs of the various [[:Category:Primitive Recursive Functions|primitive recursive functions]] that there is a [[Definition:URM Program|URM program]] for computing the values of $\Phi$. That is, $\Phi$ can be shown to be [[Definition:URM Computability#Function|URM computable]] Now we apply [[Cantor's Diagonal Argument]] to create the following [[Definition:URM Computability#Function|URM computable function]] $g: \N \to \N$: :$g \left({n}\right) = \Phi \left({n, n}\right) + 1$ We have that $\Phi$ is [[Definition:URM Computability#Function|URM computable]]. So it follows that $g \left({n}\right)$ is also [[Definition:URM Computability#Function|URM computable]]. Now, let $f$ be a [[Definition:Primitive Recursive Function|primitive recursive function]] and let $m$ code some definition of $f$. So, for all $n \in \N$, we have: :$f \left({n}\right) = \Phi \left({m, n}\right)$ Thus $f \left({m}\right) = \Phi \left({m, m}\right)$. Now, since $g \left({m}\right) = \Phi \left({m, m}\right) + 1$, we see that $g \left({m}\right) \ne f \left({m}\right)$, whatever $f$ may happen to be. Hence $g \ne f$. So $g$ is different from any [[Definition:Primitive Recursive Function|primitive recursive function]] $f$ that we care to devise. Therefore $g$ is a [[Definition:URM Computability#Function|URM computable function]] which is not [[Definition:Primitive Recursive Function|primitive recursive]]. Hence the result. {{qed}} [[Category:URM Programs]] [[Category:Primitive Recursive Functions]] gt9vhp22oxc6upgupjyo65kswvimwk9	1
{{BeginTableau|p \implies q, p \vdash q}} {{Premise|1|p \implies q}} {{Premise|2|p}} {{ModusPonens|3|1, 2|q|1|2}} {{EndTableau}} {{Qed}}	1
Let $G$ be a [[Definition:Two-Person Zero-Sum Game|two-person zero-sum game]]. Let each [[Definition:Player|player]] of $G$ have a [[Definition:Finite Set|finite set]] of [[Definition:Strategy|strategies]] available. Then $G$ has at least one [[Definition:Solution of Game|solution]].	1
We note that: : $n < m \iff m \mathop{\dot -} n > 0$ : $n \ge m \iff m \mathop{\dot -} n = 0$ So it can be seen that the [[Definition:Characteristic Function of Relation|characteristic function]] of $<$ is given by: :$\chi_< \left({n, m}\right) = \operatorname{sgn} \left({m \mathop{\dot -} n}\right)$ So $\chi_{<}$ is defined by [[Definition:Substitution (Mathematical Logic)|substitution]] from: : the [[Signum Function is Primitive Recursive|primitive recursive function $\operatorname{sgn}$]] : the [[Cut-Off Subtraction is Primitive Recursive|primitive recursive function $\dot -$]] Thus $\chi_<$ is [[Definition:Primitive Recursive Function|primitive recursive]]. So $<$ is a [[Definition:Primitive Recursive Relation|primitive recursive relation]]. Next we see that $n \le m \iff n < m \lor n = m$ from the definition of [[Definition:Strictly Precede|strictly precedes]]. From [[Equality Relation is Primitive Recursive]], we have that $=$ is [[Definition:Primitive Recursive Relation|primitive recursive]]. From above, we have that $<$ is [[Definition:Primitive Recursive Relation|primitive recursive]]. Thus $\le$ is [[Definition:Primitive Recursive Relation|primitive recursive]] from [[Set Operations on Primitive Recursive Relations]]. We could use the same reasoning for $>$ and $\ge$ but there's a different approach. Note that $n \le m \iff n \not > m$, and so $>$ is [[Definition:Primitive Recursive Relation|primitive recursive]] from [[Set Operations on Primitive Recursive Relations]]. Finally the same applies to $\ge$. Hence the result. {{qed}} [[Category:Primitive Recursive Functions]] j4jqu1qfaeq6n6rjpbyvsxw36m8yess	1
{{BeginTableau|\left({p \lor q}\right) \implies \left({p \land q}\right) \vdash p \iff q}} {{Premise|1|\left({p \lor q}\right) \implies \left({p \land q}\right)}} {{SequentIntro|2|1|\neg \left({p \lor q}\right) \lor \left({p \land q}\right)|1|[[Rule of Material Implication]]}} {{Commutation|3|1|\left({p \land q}\right) \lor \neg \left({p \lor q}\right)|2|Disjunction}} {{DeMorgan|4|1|\left({p \land q}\right) \lor \left({\neg p \land \neg q}\right)|3|Conjunction of Negations}} {{SequentIntro|5|1|\left ({p \implies q}\right) \land \left ({q \implies p}\right)|4 |[[Biconditional as Disjunction of Conjunctions]]}} {{SequentIntro|6|1|p \iff q|5|[[Rule of Material Equivalence]]}} {{EndTableau}} {{qed}} {{LEM|Rule of Material Implication}} [[Category:Biconditional iff Disjunction implies Conjunction]] fs5pn4li3zbnvspkihv62321uytc5kk	1
Note that the [[Definition:Zero Codeword|zero codeword]] is in $C^+$ as it has a [[Definition:Weight of Linear Codeword|weight]] of $0$ which is [[Definition:Even Integer|even]]. Let $c$ and $d$ be of [[Definition:Even Integer|even]] [[Definition:Weight of Linear Codeword|weight]], where $c$ and $d$ agree in $k$ ordinates. Let $\map w c$ denote the [[Definition:Weight of Linear Codeword|weight]] of $c$. Then: {{begin-eqn}} {{eqn | l = \map w {c + d} | r = \map w c - k + \map w d - k | c = }} {{eqn | r = \map w c + \map w d - 2 k | c = }} {{end-eqn}} which is [[Definition:Even Integer|even]]. Since the negative of a [[Definition:Vector (Linear Algebra)|vector]] $\mathbf v$ in $\Z_2$ equals $\mathbf v$, it follows that the [[Definition:Inverse Element|inverse]] of $c \in C$ is also in $C$. It follows from the [[Two-Step Subgroup Test]] that $C^+$ is a [[Definition:Subgroup|subgroup]] of $C$. Let $C \ne C^+$. Then $C$ contains a [[Definition:Codeword of Linear Code|codeword]] $c$ of [[Definition:Odd Integer|odd]] [[Definition:Weight of Linear Codeword|weight]]. Let $C^-$ denote the [[Definition:Subset|subset]] of $C$ consisting of all the [[Definition:Codeword of Linear Code|codewords]] of $C$ which have [[Definition:Odd Integer|odd]] [[Definition:Weight of Linear Codeword|weight]]. Adding $c$ to each [[Definition:Codeword of Linear Code|codeword]] of $C^+$ gives distinct [[Definition:Codeword of Linear Code|codewords]] of [[Definition:Odd Integer|odd]] [[Definition:Weight of Linear Codeword|weight]], so: :$\order {C^-} \ge \order {C^+}$ Similarly, adding $c$ to each [[Definition:Codeword of Linear Code|codeword]] of $C^-$ gives distinct [[Definition:Codeword of Linear Code|codewords]] of [[Definition:Even Integer|even]] [[Definition:Weight of Linear Codeword|weight]], so: :$\order {C^-} \le \order {C^+}$ As $C = C^+ \cup C^-$ it follows that: :$\order C = 2 \order {C^+}$ Hence the result. {{qed}}	1
Each [[Definition:Unlimited Register Machine|basic instruction]] $I$ in a [[Definition:URM Program|URM Program]] can be identified with a unique '''code number''' $\beta \left({I}\right)$. We also define the following sets: * $\operatorname{Zinstr}$ is the [[Definition:Set|set]] of codes of all the <tt>Zero</tt> instructions * $\operatorname{Sinstr}$ is the [[Definition:Set|set]] of codes of all the <tt>Successor</tt> instructions * $\operatorname{Cinstr}$ is the [[Definition:Set|set]] of codes of all the <tt>Copy</tt> instructions * $\operatorname{Jinstr}$ is the [[Definition:Set|set]] of codes of all the <tt>Jump</tt> instructions. Then we define $\operatorname{Instr}$ to be the [[Definition:Set|set]] of codes of all [[Definition:Unlimited Register Machine|basic URM instructions]]. That is: :$\operatorname{Instr} = \operatorname{Zinstr} \cup \operatorname{Sinstr} \cup \operatorname{Cinstr} \cup \operatorname{Jinstr}$.	1
This follows immediately from: * a [[Definition:Set|set]] is [[Definition:Primitive Recursive Set|primitive recursive]] if its [[Definition:Characteristic Function of Set|characteristic function]] is [[Definition:Primitive Recursive Function|primitive recursive]] * the fact that every [[Primitive Recursive Function is URM Computable]]. {{qed}}	1
A '''binary logical connective''' (or '''two-place connective''') is a [[Definition:Logical Connective|connective]] whose effect on its [[Definition:Compound Statement|compound statement]] is determined by the [[Definition:Truth Value|truth value]] of ''two'' [[Definition:Substatement of Compound Statement|substatements]]. In standard [[Definition:Aristotelian Logic|Aristotelian logic]], there are 16 '''binary logical connectives''', cf. [[Binary Truth Functions]]. In the field of [[Definition:Symbolic Logic|symbolic logic]], the following four ([[Definition:Symbol|symbols]] for) '''binary logical connectives''' are commonly used: * [[Definition:Conjunction|Conjunction]]: the '''And''' [[Definition:Logical Connective|connective]] $p \land q$: '''$p$ is true ''and'' $q$ is true'''. * [[Definition:Disjunction|Disjunction]]: the '''Or''' [[Definition:Logical Connective|connective]] $p \lor q$: '''$p$ is true ''or'' $q$ is true, ''or possibly both'''''. * The [[Definition:Conditional|conditional]] [[Definition:Logical Connective|connective]] $p \implies q$: '''''If'' $p$ is true, ''then'' $q$ is true'''. * The [[Definition:Biconditional|biconditional]] [[Definition:Logical Connective|connective]] $p \iff q$: '''$p$ is true ''if and only if'' $q$ is true''', or '''$p$ ''is equivalent to'' $q$'''.	1
:$p \implies q \vdash \paren {r \land p} \implies \paren {r \land q}$	1
: $\vdash \left({\left({p \implies q}\right) \implies p}\right) \implies p$	1
:$\forall x: \neg \map P x \dashv \vdash \neg \exists x: \map P x$ ::''If everything '''is not''', there exists nothing that '''is'''.''	1
{{:De Morgan's Laws (Predicate Logic)/Assertion of Universality}}	1
The optimum [[Definition:Strategy|strategy]] for [[Definition:Matching Pennies|matching pennies]], for both [[Definition:Player|players]], is to randomise both their [[Definition:Pure Strategy|pure strategies]]. Hence the result by definition of [[Definition:Completely Mixed Game|completely mixed game]].	1
An '''argumentum ad baculum''' is a [[Definition:Logical Argument|logical argument]] that, rather than [[Definition:Proof|prove]] or present evidence for a claim, threatens any who dare argue with the person or group making the claim. The presence of such a threat is often a good reason to avoid ''stating'' an opposing view, but manifestly does not support the [[Definition:True|truth]] or [[Definition:False|falsity]] of the claim under consideration.	1
: $p \implies \left({q \implies r}\right) \dashv \vdash q \implies \left({p \implies r}\right)$	1
==== [[Rule of Material Implication/Formulation 1|Formulation 1]] ==== {{:Rule of Material Implication/Formulation 1}} ==== [[Rule of Material Implication/Formulation 2|Formulation 2]] ==== {{:Rule of Material Implication/Formulation 2}}	1
Let the [[Definition:Function|functions]] $f: \N^t \to \N, g_1: \N^k \to \N, g_2: \N^k \to \N, \ldots, g_t: \N^k \to \N$ all be [[Definition:URM Computability|URM computable functions]]. Let $h: \N^k \to \N$ be defined from $f, g_1, g_2, \ldots, g_t$ by [[Definition:Substitution (Mathematical Logic)|substitution]]. Then $h$ is also [[Definition:URM Computability|URM computable]].	1
Let $\Z_{\ge n_0} := \set {n \in \Z: n \ge n_0}$. {{AimForCont}} $S \ne \Z_{\ge n_0}$. Let $S' = \Z_{\ge n_0} \setminus S$. Because $S \ne \Z_{\ge n_0}$ and $S \subseteq \Z_{\ge n_0}$, we have that $S' \ne \O$. By definition, $\Z_{\ge n_0}$ is [[Definition:Bounded Below Set|bounded below]] by $n_0$. From [[Set of Integers Bounded Below by Integer has Smallest Element]], $S'$ has a [[Definition:Minimal Element|minimal element]]. Let $k$ be this [[Definition:Minimal Element|minimal element]] of $S'$. By $(1)$ we have that: :$n_0 \in S$ and so: :$n_0 \notin S'$ Hence: :$k \ne n_0$ and so: :$k > n_0$ It follows that: :$k - 1 \le n_0$ Because $k$ is the [[Definition:Minimal Element|minimal element]] of $S'$: :$k - 1 \notin S'$ and so: :$k - 1 \in S$ But by $(2)$: :$\paren {k - 1} + 1 = k \in S$ So we have: :$k \in S$ and: :$k \notin S$ Hence by [[Proof by Contradiction]] $S = \Z_{\ge n_0}$. {{qed}}	1
:$\vdash \left({p \iff q}\right) \iff \left({\left({p \implies q}\right) \land \left({q \implies p}\right)}\right)$	1
Let $\mathbf A$ be a [[Definition:WFF of Propositional Logic|WFF of propositional logic]]. Then $\mathbf A$ is a [[Definition:Tautology (Boolean Interpretations)|tautology]] [[Definition:Iff|iff]] its [[Definition:Negation|negation]] $\neg \mathbf A$ is [[Definition:Unsatisfiable (Boolean Interpretations)|unsatisfiable]].	1
{{BeginTableau|q \vdash p \lor q}} {{Premise|1|q}} {{Addition|2|1|p \lor q|1|2}} {{EndTableau}} {{Qed}}	1
The [[Definition:Converse Statement|converse]] of $p \implies q$ is: :$q \implies p$ The [[Definition:Inverse Statement|inverse]] of $p \implies q$ is: :$\neg p \implies \neg q$ The [[Definition:Contrapositive Statement|contrapositive]] of $\neg p \implies \neg q$ is: :$\neg\neg q \implies \neg\neg p$ By [[Double Negation/Formulation 1|Double Negation]], the two are seen to be equal. {{qed}} [[Category:Implication]] plj00q6y1603076aolfow75v0tbe9y3	1
: $\neg \left({\neg p \lor \neg q}\right) \vdash p \land q$	1
'''[[Definition:Ultraproduct]] is well-defined.''' More specificly, following the definitions on [[Definition:Ultraproduct]], we are going to prove that: :(1) $f^\mathcal M$ is well-defined :(2) $R^\mathcal M$ is well-defined	1
{{BeginTableau|\vdash \left({p \implies q}\right) \lor \left({q \implies p}\right)}} {{ExcludedMiddle|1|p \lor \neg p}} {{Assumption|2|p}} {{SequentIntro|3|2|q \implies p|2|[[True Statement is implied by Every Statement]]}} {{Addition|4|2|\left({p \implies q}\right) \lor \left({q \implies p}\right)|2|2}} {{Assumption|5|\neg p}} {{SequentIntro|6|5|p \implies q|5|[[False Statement implies Every Statement]]}} {{Addition|7|5|\left({p \implies q}\right) \lor \left({q \implies p}\right)|7|1}} {{ProofByCases|8||\left({p \implies q}\right) \lor \left({q \implies p}\right)|1|2|4|5|7}} {{EndTableau}} {{qed}}	1
:$\vdash \paren {p \implies q} \iff \paren {\neg p \lor q}$	1
At each [[Definition:Outcome of Game|outcome]], the total [[Definition:Payoff|payoff]] of $G$ will be an amount which will (for at least one [[Definition:Outcome of Game|outcome]]) not be [[Definition:Zero (Number)|zero]] Let an $n + 1$th [[Definition:Player|player]] be introduced to $G$ who has one [[Definition:Move|move]]: :$(1): \quad$ Select any [[Definition:Player|player]] $m$. :$(2): \quad$ If the total [[Definition:Payoff|payoff]] of $G$ is $+k$, receive in payment $k$ from [[Definition:Player|player]] $m$. :$(3): \quad$ If the total [[Definition:Payoff|payoff]] of $G$ is $-k$, [[Definition:Pay|pay]] $k$ to [[Definition:Player|player]] $m$. This new [[Definition:Game|game]] is the same as $G$ but with an extra (dummy) [[Definition:Player|player]], and is now [[Definition:Zero-Sum Game|zero-sum]]. {{qed}}	1
'''A priori''' knowledge is the sort of knowledge which comes from reason alone. That is, it does not require the exercise of experience to know it. For example: :''If Fred Bloggs has committed a crime, then he is guilty'' as opposed to: :''Fred Bloggs has committed the crime of usury.''	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, in both cases, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc||ccc|} \hline p & \lor & q & q & \lor & p \\ \hline \F & \F & \F & \F & \F & \F \\ \F & \T & \T & \T & \T & \F \\ \T & \T & \F & \F & \T & \T \\ \T & \T & \T & \T & \T & \T \\ \hline \end{array}$ {{qed}}	1
:$p \implies q \dashv \vdash \neg q \implies \neg p$	1
We apply the [[Method of Truth Tables]]. $\begin{array}{|ccc||ccc|ccc|} \hline p & \iff & q & p & \implies & q & q & \implies & p \\ \hline F & T & F & F & T & F & F & T & F \\ F & F & T & F & T & T & T & F & F \\ T & F & F & T & F & F & F & T & T \\ T & T & T & T & F & T & T & T & T \\ \hline \end{array}$ As can be seen, when $p \iff q$ is [[Definition:True|true]] so are both $p \implies q$ and $q \implies p$. {{qed}}	1
Let $\mathcal R$ be a [[Definition:Relation|$k+1$-ary relation]] on $\N^{k+1}$. Then the [[Definition:Function|function]] $g: \N^{k+1} \to \N$ defined as: :$g \left({n_1, n_2, \ldots, n_k, z}\right) = \mu y \ \mathcal R \left({n_1, n_2, \ldots, n_k, y}\right)$ where $\mu y \ \mathcal R \left({n_1, n_2, \ldots, n_k, y}\right)$ is the [[Definition:Minimization/Relation|minimization operation on $\mathcal R$]] is equivalent to [[Definition:Minimization/Relation|minimization]] on a [[Definition:Function|total function]].	1
We have: {{begin-eqn}} {{eqn | l = n | r = \sqbrk {a_r a_{r - 1} \dotso a_1 a_0}_H | c = }} {{eqn | r = \sum_{j \mathop = 0}^r a_j 16^j | c = {{Defof|Hexadecimal Notation}} }} {{end-eqn}} We have that: :$0 \le a_j < 16$ and so: {{begin-eqn}} {{eqn | l = a_j | r = \sqbrk {b_{j 3} b_{j 2} b_{j 1} b_{j 0} }_2 | c = }} {{eqn | r = \sum_{k \mathop = 0}^3 b_{j k} 2^k | c = {{Defof|Binary Notation}} }} {{end-eqn}} and so: {{begin-eqn}} {{eqn | l = n | r = \sqbrk {a_r a_{r - 1} \dotso a_1 a_0}_H | c = }} {{eqn | r = \sum_{j \mathop = 0}^r a_j 16^j | c = {{Defof|Hexadecimal Notation}} }} {{eqn | r = \sum_{j \mathop = 0}^r \paren {\sum_{k \mathop = 0}^3 b_{j k} 2^k} 16^j | c = {{Defof|Binary Notation}} }} {{eqn | r = \sum_{j \mathop = 0}^r \paren {\sum_{k \mathop = 0}^3 b_{j k} 2^k} 2^{4 j} | c = }} {{eqn | r = \sum_{j \mathop = 0}^r \paren {\sqbrk {b_{j 3} b_{j 2} b_{j 1} b_{j 0} }_2} 2^{4 j} | c = {{Defof|Binary Notation}} }} {{eqn | r = \sqbrk {b_{r 3} b_{r 2} b_{r 1} b_{r 0} }_2 2^{4 r} + \sqbrk {b_{\paren {r - 1} 3} b_{\paren {r - 1} 2} b_{\paren {r - 1} 1} b_{\paren {r - 1} 0} }_2 2^{4 {r - 1} } + \cdots + \sqbrk {b_{1 3} b_{1 2} b_{1 1} b_{1 0} }_2 2^4 + \sqbrk {b_{0 3} b_{0 2} b_{0 1} b_{0 0} }_2 | c = }} {{eqn | r = \sqbrk {b_{r 3} b_{r 2} b_{r 1} b_{r 0} b_{\paren {r - 1} 3} b_{\paren {r - 1} 2} b_{\paren {r - 1} 1} b_{\paren {r - 1} 0} \dotso b_{1 3} b_{1 2} b_{1 1} b_{1 0} b_{0 3} b_{0 2} b_{0 1} b_{0 0} }_2 | c = }} {{end-eqn}} Hence the result. {{qed}}	1
:$q \vdash p \lor q$	1
Let $M$ be the [[Definition:Set|set]] of all $n \in \N_{>0}$ for which $\map P n$ holds. By $(1)$ we have that $1 \in M$. By $(2)$ we have that if $k \in M$ then $k + 1 \in M$. From the [[Axiom:Axiomatization of 1-Based Natural Numbers|Axiomatization of $1$-Based Natural Numbers]], Axiom $(F)$, it follows that $M = \N_{>0}$. {{qed}}	1
:$\vdash (p \land q) \lor (\lnot p \land q) \lor (p \land \lnot q) \lor (\lnot p \land \lnot q)$	1
The proof proceeds by [[Principle of General Induction|general induction]]. Let an [[Definition:Element of Class|element]] $x$ of $M$ be defined as: :'''[[Definition:Left Normal Element of Relation|left normal]]''' with respect to $\RR$ {{iff}} $\map \RR {x, y}$ for all $y \in M$ :'''[[Definition:Right Normal Element of Relation|right normal]]''' with respect to $\RR$ {{iff}} $\map \RR {y, x}$ for all $y \in M$. Let the hypothesis be assumed. First we demonstrate a [[Definition:Lemma|lemma]]: === [[Double Induction Principle/Lemma|Lemma]] === {{:Double Induction Principle/Lemma}}{{qed|lemma}} We now show by [[Principle of General Induction|general induction]] that every $x \in M$ is [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$. It then follows from the [[Double Induction Principle/Lemma|lemma]] that $\map \RR {x, y}$ for all $x, y \in M$. === Basis for the Induction === $\map P \O$ is the case: From condition $\text D_1$ of the definition of $\RR$, we have immediately that: :$\map \RR {x, \O}$ for all $x \in M$. That is, that $\O$ is [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$. Thus $\map P \O$ is seen to hold. This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that if $\map P x$ is true, where $x \in M$, then it logically follows that $\map P {\map g x}$ is true. So this is the [[Definition:Induction Hypothesis|induction hypothesis]]: :$x$ is [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$ from which it is to be shown that: :$\map g x$ is [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$. === Induction Step === This is the [[Definition:Induction Step|induction step]]: Let $x \in M$ be [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$: :$\forall y \in M: \map \RR {y, x}$ By the [[Double Induction Principle/Lemma|lemma]] we have that $x$ is [[Definition:Left Normal Element of Relation|left normal]] with respect to $\RR$. That is: :$\forall y \in M: \map \RR {x, y}$ Thus by condition $\text D_2$ of the definition of $\RR$: :$\forall y \in M: \map \RR {y, \map g x}$ That is, $\map g x$ is [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$. So $\map P x \implies \map P {\map g x}$ and by the [[Principle of General Induction]]: :$\forall x \in M$: $x$ is [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$. The result follows. {{qed}}	1
:$p \lor q \dashv \vdash q \lor p$	1
{{begin-eqn}} {{eqn | l = \sum_{j \mathop = 1}^n \paren {2 j - 1} | r = n^2 | c = [[Odd Number Theorem]] }} {{eqn | ll= \leadsto | l = \sum_{j \mathop = 1}^n \paren {2 j - 1} + \sum_{j \mathop = 1}^n 1 | r = n^2 + n | c = }} {{eqn | ll= \leadsto | l = \sum_{j \mathop = 1}^n \paren {2 j} | r = n \paren {n + 1} | c = }} {{eqn | ll= \leadsto | l = \sum_{j \mathop = 1}^n j | r = \frac {n \paren {n + 1} } 2 | c = }} {{end-eqn}} {{qed}}	1
Because $g = \map O h$, there exists a [[Definition:Neighborhood of Point in Topological Space|neighborhood]] $V$ of $y_0$ and a [[Definition:Real Number|real number]] $c$ such that: :$\norm {\map g x} \le c \cdot \norm {\map h x}$ for all $y \in V$. By definition of [[Definition:Continuous Mapping at Point (Topology)|continuity]], there exists a [[Definition:Neighborhood of Point in Topological Space|neighborhood]] $U$ of $x_0$ with $\map f U \subset V$. For $x \in U$, we have: :$\norm {\map g {\map f x} } \le c \cdot \norm {\map h {\map f x} }$ Thus $g \circ f = \map O {h \circ f}$ as $x \to x_0$. {{qed}} [[Category:Asymptotic Notation]] 9s3z4pj7o5jlquyp13g5r1u6ap5193l	1
We apply the [[Method of Truth Tables]] to the propositions in turn. As can be seen for all [[Definition:Boolean Interpretation|boolean interpretations]] by inspection, where the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] on the {{LHS}} is $T$, that under the one on the {{RHS}} is also $T$: $\begin{array}{|ccccccc||ccc|} \hline (p & \implies & q) & \land & (q & \implies & r) & p & \implies & r \\ \hline F & T & F & T & F & T & F & F & T & F \\ F & T & F & T & F & T & T & F & T & T \\ F & T & T & F & T & F & F & F & T & F \\ F & T & T & T & T & T & T & F & T & T \\ T & F & F & F & F & T & F & T & F & F \\ T & F & F & F & F & T & T & T & T & T \\ T & T & T & F & T & F & F & T & F & F \\ T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ Hence the result. {{qed}}	1
The [[Definition:Constant Mapping|constant function]] $f_c: \N \to \N$, defined as: :$\map {f_c} n = c$ where $c \in \N$ is [[Definition:Primitive Recursive Function|primitive recursive]].	1
=== Necessary Condition === Assume that $\mathcal F \models_{\mathrm{BI}} \mathbf A$. Suppose $\displaystyle \bigwedge \mathcal F \implies \mathbf A$ were not a [[Definition:Tautology (Boolean Interpretations)|tautology]]. Then there exists a [[Definition:Boolean Interpretation|boolean interpretation]] $v$ such that: :$v \left({\displaystyle \bigwedge \mathcal F}\right) = T$ :$v \left({\mathbf A}\right) = F$ by definition of the [[Definition:Boolean Interpretation of Conditional|boolean interpretation of $\implies$]]. It now follows from the [[Definition:Boolean Interpretation of Conjunction|boolean interpretation of conjunction]] that: :$v \left({\mathbf B}\right) = T$ for every $\mathbf B \in \mathcal F$. Hence, by definition of [[Definition:Model (Boolean Interpretations)|model]]: :$v \models_{\mathrm{BI}} \mathcal F$. It now follows from our assumption that $v \left({\mathbf A}\right) = T$. This is a contradiction, hence $\displaystyle \bigwedge \mathcal F \implies \mathbf A$ is a [[Definition:Tautology (Boolean Interpretations)|tautology]]. {{qed|lemma}} === Sufficient Condition === Assume that $\displaystyle \bigwedge \mathcal F \implies \mathbf A$ is a [[Definition:Tautology (Boolean Interpretations)|tautology]]. Let $v$ be an arbitrary [[Definition:Model (Boolean Interpretations)|model]] of $\mathcal F$. Then: :$v \left({\mathbf B}\right) = T$ for every $\mathbf B \in \mathcal F$, whence by the [[Definition:Boolean Interpretation of Conjunction|boolean interpretation of conjunction]]: :$v \left({\displaystyle \mathcal F}\right) = T$ Since $\displaystyle \bigwedge \mathcal F \implies \mathbf A$ is a [[Definition:Tautology (Boolean Interpretations)|tautology]], it must be that: :$v \left({\mathbf A}\right) = T$ Hence, since $v$ was arbitrary: :$\mathcal F \models_{\mathrm{BI}} \mathbf A$ {{qed}}	1
If [[Definition:Statement|statement]] $p$ [[Definition:Logical Implication|logically implies]] statement $q$, then we may say: : '''$q$, because $p$.''' The symbol $\dashv$ is interpreted to mean '''because'''. Thus: : $r \dashv p, q$ means: :'''Given as premises $p$ and $q$, we may validly conclude $r$''' or :'''$r$, because $p$ and $q$.'''	1
We prove the $\LL$-[[Definition:Classes of WFFs/Sentence|sentences]] case by induction on the complexity of formulas. The general case trivially follows this proof. We appeal to the interpretations of language symbols in the ultraproduct when viewed as an $\LL$-structure, the properties of ultrafilters, and make use of the [[Axiom:Axiom of Choice|Axiom of Choice]]. The theorem holds trivially for statements of equality of terms and for relations, by definition of how to interpret language symbols for the ultraproduct. Suppose the theorem holds for $\psi_0$ and $\psi_1$. If $\phi$ is $\neg \psi_0$: We are assuming that $\MM \models \psi_0$ {{iff}}: :$\set {i: \MM_i \models \psi_0} \in \UU$. Thus: :$\MM \models \phi$ {{iff}} $\set {i: \MM_i \models \psi_0} \notin \UU$ follows by negating both sides of this statement. Since $\UU$ is an ultrafilter, a set is absent from $\UU$ {{iff}} the set's complement is present in $\UU$. So, we may again rewrite the above statement equivalently as: :$\MM \models \phi \iff I \setminus \set {i: \MM_i \models \psi_0} \in \UU$ Finally, we can further rewrite this set difference to see that: :$\MM \models \phi \iff \set {i: \MM_i \models \phi} \in \UU$ which is the statement that the theorem holds for $\phi$. Let $\phi$ be $\psi_0 \wedge \psi_1$: For both $k \in \left\{{0, 1}\right\}$, we are assuming that: :$\MM \models \psi_k \iff \set {i: \MM_i \models \psi_k} \in \UU$ By choice of $\phi$, we have $\MM \models \phi$ {{iff}} $\MM \models \psi_0 \wedge \psi_1$. The right side of this {{iff}} statement can be rewritten as $\MM \models \psi_0$ and $\MM \models \psi_1$. Thus, using the inductive hypothesis stated above for each $\psi_k$: :$\MM \models \phi \iff \set {i: \MM_i \models \psi_0} \in \UU$ and $\set {i: \MM_i \models \psi_1} \in \UU$ Since $\UU$ is a filter, it is closed under intersections, and hence the right side of this statement can be written as: :$\set {i: \MM_i \models \psi_0 \text{ and } \MM_i \models \psi_1} \in \UU$ Thus: :$\MM \models \phi \iff \set {i: \MM_i \models \phi} \in \UU$ which is the statement that the theorem holds for $\phi$. Let $\phi$ be $\exists x \psi_0 \left({x}\right)$: If $x$ is not free in $\psi_0$ then earlier cases cover this, so we may assume $x$ is free in $\psi_0$. We are assuming then that for all $m = \left\langle{m_i}\right\rangle_\UU$ in $\MM$: : $\MM \models \psi_0 \left({m}\right) \iff \left\{{i \in I: \MM_i \models \psi_0 \left({m_i}\right)}\right\}\in \UU$ Thus: : $\MM \models \phi \iff \exists m = \left\langle{m_i}\right\rangle_\UU \in \MM$ for which: : $\left\{{i \in I: \MM_i \models \psi_0 \left({m_i}\right)}\right\}\in \UU$ One direction of the theorem follows easily, since this above statement gives us the witnesses $m_i$: :$\MM \models \phi \implies \left\{{i \in I: \MM_i \models \psi_0 \left({m_i}\right)}\right\} \in \UU$ And this above set is included in the set we're looking for, so that is an element of the ultrafilter as well: :$\left\{{i \in I: \MM_i \models \psi_0 \left({m_i}\right)}\right\} \subseteq \left\{{i \in I: \MM_i \models \exists x \psi_0 \left({x}\right)}\right\}\in \UU$ For the converse, we need to find some appropriate $\left\langle{m_i}\right\rangle_\UU$ in order to apply the above [[Definition:Biconditional|biconditional statement]]. To this end, let $\left\{{i \in I: \MM_i \models \exists x \psi_0 \left({x}\right)}\right\} \in \UU$, and apply the [[Axiom:Axiom of Choice|Axiom of Choice]] as follows: Select for each $i \in \left\{{i \in I: \MM_i \models \exists x \psi_0 \left({x}\right)}\right\}$ a witness $m_i \in \MM_i$ such that $\MM_i \models \psi_0 \left({m_i}\right)$ Select for each $i$ not in this set an arbitrary element $m_i$ of $\MM_i$. Taking $\left\langle{m_i}\right\rangle_\UU$ as our element of $\MM$ then allows us to apply the above [[Definition:Biconditional|biconditional statement]] and complete the proof. {{qed}} {{Namedfor|Jerzy Maria Michał Łoś|cat = Łoś}} [[Category:Model Theory]] [[Category:Mathematical Logic]] 97y8pu12rwidx7gtprot9k9zlpin4m6	1
The [[Definition:Inverse Statement|inverse]] of $p \implies q$ is: :$\neg p \implies \neg q$ The [[Definition:Converse Statement|converse]] of $p \implies q$ is: :$q \implies p$ The [[Definition:Contrapositive Statement|contrapositive]] of $q \implies p$ is: :$\neg p \implies \neg q$ The two are seen to be equal. {{qed}} [[Category:Implication]] 9b8kfzy0f04jach47afrtwkv29o2wg3	1
Let $n$ be a [[Definition:Positive Integer|(positive) integer]] expressed in [[Definition:Hexadecimal Notation|hexadecimal notation]] as: :$n = \sqbrk {a_r a_{r - 1} \dotso a_1 a_0}_H$ Then $n$ can be expressed in [[Definition:Binary Notation|binary notation]] as: :$n = \sqbrk {b_{r 3} b_{r 2} b_{r 1} b_{r 0} b_{\paren {r - 1} 3} b_{\paren {r - 1} 2} b_{\paren {r - 1} 1} b_{\paren {r - 1} 0} \dotso b_{1 3} b_{1 2} b_{1 1} b_{1 0} b_{0 3} b_{0 2} b_{0 1} b_{0 0} }_2$ where $\sqbrk {b_{j 3} b_{j 2} b_{j 1} b_{j 0} }_2$ is the expression of the [[Definition:Hexadecimal Notation|hexadecimal digit]] $a_j$ in [[Definition:Binary Notation|binary notation]]. That is, you take the [[Definition:Binary Notation|binary expression]] of each [[Definition:Hexadecimal Notation|hexadecimal digit]], padding them out with [[Definition:Zero Digit|zeroes]] to make them $4$ [[Definition:Bit|bits]] long, and simply [[Definition:Concatenation (Formal Systems)|concatenate]] them.	1
If [[Definition:Statement|statement]] $p$ [[Definition:Logical Implication|logically implies]] statement $q$, then we may say: :'''$p$, therefore $q$'''. The symbology: :$p, q \vdash r$ means: :'''Given as premises $p$ and $q$, we may validly conclude $r$''' So the symbol $\vdash$ is interpreted to mean '''therefore'''. Thus, $p, q \vdash r$ reads as: :'''$p$ and $q$, therefore $r$.''' A [[Definition:Fallacy|fallacy]] may be indicated by $p, q \not \vdash r$, which can be interpreted as: :'''Given as premises $p$ and $q$, we may ''not'' validly conclude $r$.'''	1
Defining $1$ as $\map s 0$ and $2$ as $\map s {\map s 0}$, the statement to be proven becomes: :$\map s 0 + \map s 0 = \map s {\map s 0}$ By the [[Definition:Addition/Peano Structure|definition of addition]]: :$\forall m \in P: \forall n \in P: m + \map s n = \map s {m + n}$ Letting $m = \map s 0$ and $n = 0$: {{begin-eqn}} {{eqn | n = 1 | l = \map s 0 + \map s 0 | r = \map s {\map s 0 + 0} }} {{end-eqn}} By the [[Definition:Addition/Peano Structure|definition of addition]]: :$\forall m: m + 0 = m$ Letting $m = \map s 0$: :$\map s 0 + 0 = \map s 0$ Taking the [[Definition:Successor Mapping on Natural Numbers|successor]] of both sides: {{begin-eqn}} {{eqn | n = 2 | l = \map s {\map s 0 + 0} | r = \map s {\map s 0} }} {{end-eqn}} Applying [[Equality is Transitive]] to $(1)$ and $(2)$ we have: :$\map s 0 + \map s 0 = \map s {\map s 0}$ Hence the result. {{qed}}	1
We assume the truth of '''[[Well-Ordering Principle|WOP]]'''. Let $S \subseteq \N$ which satisfy: :$(D): \quad 0 \in S$ :$(E): \quad n \in S \implies n+1 \in S$. We want to show that $S = \N$, that is, the '''[[Principle of Finite Induction|PFI]]''' is true. {{AimForCont}} that: :$S \ne \N$ Consider $S' = \N \setminus S$, where $\setminus$ denotes [[Definition:Set Difference|set difference]]. From [[Set Difference is Subset]], $S' \subseteq \N$. So from '''[[Well-Ordering Principle|WOP]]''', $S'$ has a [[Definition:Minimal Element|minimal element]]. A [[Definition:Lower Bound of Set|lower bound]] of $\N$ is $0$. By [[Lower Bound for Subset]], $0$ is also a [[Definition:Lower Bound of Set|lower bound]] for $S'$. By hypothesis, $0 \in S$. From the definition of [[Definition:Set Difference|set difference]], $0 \notin S'$. So this [[Definition:Minimal Element|minimal element]] of $S'$ has the form $k + 1$ where $k \in \N$. We can consider the [[Definition:Von Neumann Construction of Natural Numbers|von Neumann construction of the natural numbers]]. By definition of [[Definition:Natural Number Addition|natural number addition]], it is noted that $k + 1 \in \N$ is the [[Definition:Immediate Successor Element|immediate successor element]] of $k \in \N$. Thus $k \in S$ but $k + 1 \notin S$. From $(E)$, this [[Definition:Contradiction|contradicts]] the definition of $S$. Thus if $S' \ne \O$, it has no [[Definition:Minimal Element|minimal element]]. This [[Definition:Contradiction|contradicts]] the [[Well-Ordering Principle]], and so $S' = \O$. So $S = N$. Thus we have proved that '''[[Well-Ordering Principle|WOP]]''' implies '''[[Principle of Finite Induction|PFI]]'''.	1
{{BeginTableau|\paren {p \implies q} \land \paren {r \implies s}, p \lor r \vdash q \lor s}} {{Premise|1|\paren {p \implies q} \land \paren {r \implies s} }} {{Premise|2|p \lor r}} {{Conjunction|3|1, 2|\paren {p \lor r} \land \paren {p \implies q} \land \paren {r \implies s}|2|1|[[Conjunction is Associative|Associativity is implicit]]}} {{TheoremIntro|4|\paren {\paren {p \lor r} \land \paren {p \implies q} \land \paren {r \implies s} } \implies \paren {q \lor s}|[[Constructive Dilemma/Formulation 2|Constructive Dilemma: Formulation 2]]}} {{ModusPonens|5|1, 2|q \lor s|4|3}} {{EndTableau}} {{qed}}	1
{{BeginTableau|p \iff q \vdash \left({p \implies q}\right) \land \left({q \implies p}\right)}} {{Premise|1|p \iff q}} {{BiconditionalElimination|2|1|p \implies q|1|1}} {{BiconditionalElimination|3|1|q \implies p|1|2}} {{Conjunction|4|1|\left({p \implies q}\right) \land \left({q \implies p}\right)|2|3}} {{EndTableau}} {{BeginTableau|\left({p \implies q}\right) \land \left({q \implies p}\right) \vdash p \iff q}} {{Premise|1|\left({p \implies q}\right) \land \left({q \implies p}\right)}} {{Simplification|2|1|p \implies q|1|1}} {{Simplification|3|1|q \implies p|1|2}} {{BiconditionalIntro|4|1|p \iff q|2|3}} {{EndTableau}} {{qed}}	1
:$p \land \paren {p \lor q} \dashv \vdash p$	1
From [[Minimization on Relation Equivalent to Minimization on Function]], minimization on $\mathcal R$ is equivalent to minimization on $\overline{\operatorname{sgn}} \circ \chi_\mathcal R$. We have that a [[Primitive Recursive Function is URM Computable]]. By definition, if $\mathcal R$ is [[Definition:URM Computability|URM computable]] then so is its [[Definition:Characteristic Function of Relation|characteristic function]] $\chi_\mathcal R$. We have that [[Signum Function is Primitive Recursive|$\overline{\operatorname{sgn}}$ is primitive recursive]] and thus [[Definition:URM Computability|URM computable]]. Thus, from [[Function Obtained by Substitution from URM Computable Functions]], $\overline{\operatorname{sgn}} \circ \chi_\mathcal R$ is [[Definition:URM Computability|URM computable]]. {{qed}} [[Category:URM Programs]] fzshhimc3aj5rj89l50k8up7xog7b2x	1
Any [[Definition:Propositional Formula|propositional formula]] can be expressed in [[Definition:Conjunctive Normal Form|conjunctive normal form (CNF)]].	1
{{BeginTableau|\vdash p \implies \paren{ q \implies \paren{ p \land q } }|[[Definition:Hilbert Proof System/Instance 2|Instance 2 of the Hilbert-style systems]]}} {{TableauLine |n = 1 |f = \neg p \lor p |rlnk = Law of Excluded Middle/Sequent Form/Proof 3 |rtxt = Law of Excluded Middle }} {{TableauLine |n = 2 |f = \paren{ \neg p \lor p } \implies \paren{ p \lor \neg p } |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Axiom $A3$ |c = $\neg p \,/\, p, p \,/\, q$ }} {{TableauLine |n = 3 |f = p \lor \neg p |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 3$ |dep = 1,2 }} {{TableauLine |n = 4 |f = \paren{ \neg p \lor \neg q } \lor \neg \paren{ \neg p \lor \neg q } |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 1$ |dep = 3 |c = $\paren{ \neg p \lor \neg q } \,/\, p$ }} {{TableauLine |n = 5 |f = \paren{ \neg p \lor \neg q } \lor \paren{ p \land q } |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 2 (1)$ }} {{TableauLine |n = 6 |f = \paren{ \paren{ \neg p \lor \neg q } \lor \paren{ p \land q } } \implies \paren{ \neg p \lor \paren{ \neg q \lor \paren{ p \land q } } } |rlnk = Rule of Association/Disjunction/Formulation 2/Reverse Implication |rtxt = Rule of Association |c = $\neg p \,/\, p, \neg q \,/\, q, \paren{ p \land q } \,/\, r$ }} {{TableauLine |n = 7 |f = \neg p \lor \paren{ \neg q \lor \paren{ p \land q } } |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 3$ |dep = 5,6 }} {{TableauLine |n = 8 |f = p \implies \paren{ q \implies \paren{ p \land q } } |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 2 (2)$ |dep = 7 }} {{EndTableau}} {{qed}}	1
All [[Primitive Recursive Function is URM Computable|primitive recursive functions are URM computable]]. The set of $\mathbf U$ of [[URM Programs are Countably Infinite|URM programs is countably infinite]]. The set of $\Bbb F$ of [[Natural Number Functions are Uncountable|natural number functions is uncountably infinite]]. Hence there is no [[Definition:Surjection|surjection]] from $\mathbf U \to \Bbb F$. Hence $\mathbf U \subsetneq \Bbb F$. Hence $\exists f \in \Bbb F: f \notin \mathbf U$. {{qed}} [[Category:Primitive Recursive Functions]] 0urfc305jilu8erji55syap7v41nfft	1
Every [[Definition:Primitive Recursive Function|primitive recursive function]] is [[Definition:URM Computability|URM computable]].	1
: $\vdash \left({p \lor q}\right) \iff \left({\neg \left({\neg p \land \neg q}\right)}\right)$	1
: $\vdash \left({p \implies q}\right) \implies \left({\neg p \lor q}\right)$	1
{{begin-eqn}} {{eqn | l = p \implies q | o = \dashv \vdash | r = \neg p \lor q | c = [[Rule of Material Implication]] }} {{eqn | o = \dashv \vdash | r = \neg p \lor \neg \neg q | c = [[Double Negation Introduction]] }} {{eqn | o = \dashv \vdash | r = p \uparrow \neg q | c = [[NAND as Disjunction of Negations]] }} {{eqn | o = \dashv \vdash | r = p \uparrow \left({q \uparrow q}\right) | c = [[NAND with Equal Arguments]] }} {{end-eqn}} {{qed}}	1
We prove this by [[Principle of Mathematical Induction|induction]] on $m$. For all $m \in \N$, let $\map P m$ be the [[Definition:Proposition|proposition]]: :$F_{m n + 1} \equiv \paren {\begin{cases} F_1 & : m \bmod 4 = 0 \\ F_{n - 1} & : m \bmod 4 = 1 \\ \paren {-1}^n F_1 & : m \bmod 4 = 2 \\ \paren {-1}^n F_{n - 1} & : m \bmod 4 = 3 \end{cases} } \pmod {F_n}$ === Basis for the Induction === $\map P 0$ is the case: :$F_1 \equiv F_1 \pmod {F_n}$ So $\map P 0$ is true. This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P m$ is true then it logically follows that $\map P {m + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$F_{m n + 1} \equiv \paren {\begin{cases} F_1 & : m \bmod 4 = 0 \\ F_{n - 1} & : m \bmod 4 = 1 \\ \paren {-1}^n F_1 & : m \bmod 4 = 2 \\ \paren {-1}^n F_{n - 1} & : m \bmod 4 = 3 \end{cases} } \pmod {F_n}$ Then we need to show: {{begin-eqn}} {{eqn | l = F_{\paren {m + 1} n + 1} | o = \equiv | r = \paren {\begin{cases} F_1 & : \paren {m + 1} \bmod 4 = 0 \\ F_{n - 1} & : \paren {m + 1} \bmod 4 = 1 \\ \paren {-1}^n F_1 & : \paren {m + 1} \bmod 4 = 2 \\ \paren {-1}^n F_{n - 1} & : \paren {m + 1} \bmod 4 = 3 \end{cases} } \pmod {F_n} }} {{eqn | o = \equiv | r = \paren {\begin{cases} F_{n - 1} & : m \bmod 4 = 0 \\ \paren {-1}^n & : m \bmod 4 = 1 \\ \paren {-1}^n F_{n - 1} & : m \bmod 4 = 2 \\ 1 & : m \bmod 4 = 3 \end{cases} } \pmod {F_n} }} {{end-eqn}} === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = F_{\paren {m + 1} n + 1} | r = F_{m n + r - 1} F_n + F_{m n + r} F_{n + 1} | c = [[Fibonacci Number in terms of Smaller Fibonacci Numbers]] }} {{eqn | o = \equiv | r = F_{m n + r} F_{n + 1} \quad \pmod {F_n} | c = }} {{eqn | o = \equiv | r = \paren {\begin{cases} F_1 F_{n + 1} & : m \bmod 4 = 0 \\ F_{n - 1} F_{n + 1} & : m \bmod 4 = 1 \\ \paren {-1}^n F_1 F_{n + 1} & : m \bmod 4 = 2 \\ \paren {-1}^n F_{n - 1} F_{n + 1} & : m \bmod 4 = 3 \end{cases} } \pmod {F_n} | c = [[Residue of Fibonacci Number Modulo Fibonacci Number/Lemma#Induction Hypothesis|induction hypothesis]] }} {{eqn | o = \equiv | r = \paren {\begin{cases} F_{n + 1} & : m \bmod 4 = 0 \\ F_{n - 1} F_{n + 1} - F_n^2 & : m \bmod 4 = 1 \\ \paren {-1}^n F_{n + 1} & : m \bmod 4 = 2 \\ \paren {-1}^n \paren {F_{n - 1} F_{n + 1} - F_n^2} & : m \bmod 4 = 3 \end{cases} } \pmod {F_n} | c = }} {{eqn | o = \equiv | r = \paren {\begin{cases} F_n + F_{n - 1} & : m \bmod 4 = 0 \\ F_{n - 1} F_{n + 1} - F_n^2 & : m \bmod 4 = 1 \\ \paren {-1}^n \paren {F_n + F_{n - 1} } & : m \bmod 4 = 2 \\ \paren {-1}^n \paren {F_{n - 1} F_{n + 1} - F_n^2} & : m \bmod 4 = 3 \end{cases} } \pmod {F_n} | c = {{Defof|Fibonacci Numbers}} }} {{eqn | o = \equiv | r = \paren {\begin{cases} F_n + F_{n - 1} & : m \bmod 4 = 0 \\ \paren {-1}^n & : m \bmod 4 = 1 \\ \paren {-1}^n \paren {F_n + F_{n - 1} } & : m \bmod 4 = 2 \\ \paren {-1}^n \paren {-1}^n & : m \bmod 4 = 3 \end{cases} } \pmod {F_n} | c = [[Cassini's Identity]] }} {{eqn | o = \equiv | r = \paren {\begin{cases} F_{n - 1} & : m \bmod 4 = 0 \\ \paren {-1}^n & : m \bmod 4 = 1 \\ \paren {-1}^n F_{n - 1} & : m \bmod 4 = 2 \\ 1 & : m \bmod 4 = 3 \end{cases} } \pmod {F_n} | c = }} {{end-eqn}} So $\map P m \implies \map P {m + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. {{qed}} [[Category:Proofs by Induction]] [[Category:Residue of Fibonacci Number Modulo Fibonacci Number]] 5pvan7n5g8ac5azn1lhli07uuh3jwxt	1
Let $x_1, x_2, \ldots, x_k \in F$, where $F$ is a [[Definition:Field (Abstract Algebra)|field]]. Then: :$\displaystyle \paren {x_1 + x_2 + \cdots + x_m}^n = \sum_{k_1 \mathop + k_2 \mathop + \mathop \cdots \mathop + k_m \mathop = n} \binom n {k_1, k_2, \ldots, k_m} {x_1}^{k_1} {x_2}^{k_2} \cdots {x_m}^{k_m}$ where: :$m \in \Z_{> 0}$ is a [[Definition:Positive Integer|positive integer]] :$n \in \Z_{\ge 0}$ is a [[Definition:Non-Negative Integer|non-negative integer]] :$\dbinom n {k_1, k_2, \ldots, k_m} = \dfrac {n!} {k_1! \, k_2! \, \cdots k_m!}$ denotes a [[Definition:Multinomial Coefficient|multinomial coefficient]]. The sum is taken for all non-negative integers $k_1, k_2, \ldots, k_m$ such that $k_1 + k_2 + \cdots + k_m = n$, and with the understanding that wherever $0^0$ may appear it shall be considered to have a value of $1$. The '''multinomial theorem''' is a generalization of the [[Binomial Theorem]].	1
{{BeginTableau|p \land \bot \vdash \bot}} {{Premise|1|p \land \bot}} {{Simplification|2|1|\bot|1|2}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|\bot \vdash p \land \bot}} {{Premise|1|\bot}} {{Explosion|2|1|p \land \bot|1|From a bottom, we can prove what we like}} {{EndTableau}} {{qed}}	1
A '''conclusion''' is a [[Definition:Statement|statement]] that is obtained as the result of the process of an [[Definition:Logical Argument|argument]].	1
The proof appeals to the [[Principle of Structural Induction]], applied to the [[Definition:Statement|statement]]: :If $\mathbf C$ [[Definition:Occurrence along Branch|occurs]] along $\Gamma$, then $v \models_{\mathrm{BI}} \mathbf C$. When $\mathbf C$ is [[Definition:Basic WFF|basic]], the result holds per assumption. Suppose $\mathbf C$ is not [[Definition:Basic WFF|basic]]. It is seen that one of the [[Definition:Propositional Tableau/Construction|propositional tableau construction rules]] applies to $\mathbf C$. If $\mathbf C = \neg\neg\mathbf A$, then it can only be [[Definition:Used WFF|used]] by the $\boxed{\neg\neg}$ rule. Hence, $\mathbf A \in \Phi \left[{\Gamma}\right]$, and by induction hypothesis, $v \models_{\mathrm{BI}} \mathbf A$. By [[Double Negation/Formulation 1/Proof 2|Double Negation]], $v \models_{\mathrm{BI}} \neg\neg\mathbf A$. If $\mathbf C$ is $\mathbf A \land \mathbf B$, then it can only be [[Definition:Used WFF|used]] by the $\boxed\land$ rule. Therefore, $\mathbf A, \mathbf B \in \Phi \left[{\Gamma}\right]$, and by induction hypothesis: :$v \models_{\mathrm{BI}} \mathbf A,\mathbf B$ By the [[Definition:Conjunction/Truth Function|truth function for $\land$]], it follows that: :$v \models_{\mathrm{BI}} \mathbf A \land \mathbf B$ If $\mathbf C$ is $\neg \left({\mathbf A \land \mathbf B}\right)$, then it can only be [[Definition:Used WFF|used]] by the $\boxed{\neg\land}$ rule. Therefore, $\neg\mathbf A \in \Phi \left[{\Gamma}\right]$ or $\neg\mathbf B \in \Phi \left[{\Gamma}\right]$. By induction hypothesis, it follows that: :$v \models_{\mathrm{BI}} \neg\mathbf A$ or $v \models_{\mathrm{BI}} \neg\mathbf B$ By the [[Definition:Conjunction/Truth Function|truth function for $\land$]], it follows that: :$v \models_{\mathrm{BI}} \neg \left({\mathbf A \land \mathbf B}\right)$ If $\mathbf C$ is $\mathbf A \lor \mathbf B$, then it can only be [[Definition:Used WFF|used]] by the $\boxed\lor$ rule. Therefore, $\mathbf A \in \Phi \left[{\Gamma}\right]$ or $\mathbf B \in \Phi \left[{\Gamma}\right]$. By induction hypothesis, it follows that: :$v \models_{\mathrm{BI}} \mathbf A$ or $v \models_{\mathrm{BI}} \mathbf B$ By the [[Definition:Disjunction/Truth Function|truth function for $\lor$]], it follows that: :$v \models_{\mathrm{BI}} \mathbf A \lor \mathbf B$ If $\mathbf C$ is $\neg \left({\mathbf A \lor \mathbf B}\right)$, then it can only be [[Definition:Used WFF|used]] by the $\boxed{\neg\lor}$ rule. Therefore, $\neg\mathbf A, \neg\mathbf B \in \Phi \left[{\Gamma}\right]$, and by induction hypothesis: :$v \models_{\mathrm{BI}} \neg\mathbf A,\neg\mathbf B$ By the [[Definition:Disjunction/Truth Function|truth function for $\lor$]], it follows that: :$v \models_{\mathrm{BI}} \neg \left({\mathbf A \lor \mathbf B}\right)$ If $\mathbf C$ is $\mathbf A \implies \mathbf B$, then it can only be [[Definition:Used WFF|used]] by the $\boxed\implies$ rule. Therefore, $\neg\mathbf A \in \Phi \left[{\Gamma}\right]$ or $\mathbf B \in \Phi \left[{\Gamma}\right]$. By induction hypothesis, it follows that: :$v \models_{\mathrm{BI}} \neg\mathbf A$ or $v \models_{\mathrm{BI}} \mathbf B$ By the [[Definition:Conditional/Truth Function|truth function for $\implies$]], it follows that: :$v \models_{\mathrm{BI}} \mathbf A \implies \mathbf B$ If $\mathbf C$ is $\neg \left({\mathbf A \implies \mathbf B}\right)$, then it can only be [[Definition:Used WFF|used]] by the $\boxed{\neg\implies}$ rule. Therefore, $\mathbf A, \neg\mathbf B \in \Phi \left[{\Gamma}\right]$, and by induction hypothesis: :$v \models_{\mathrm{BI}} \mathbf A,\neg\mathbf B$ By the [[Definition:Conditional/Truth Function|truth function for $\implies$]], it follows that: :$v \models_{\mathrm{BI}} \neg \left({\mathbf A \implies \mathbf B}\right)$ If $\mathbf C$ is $\mathbf A \iff \mathbf B$, then it can only be [[Definition:Used WFF|used]] by the $\boxed\iff$ rule. Therefore, $\mathbf A\land \mathbf B \in \Phi \left[{\Gamma}\right]$ or $\neg\mathbf A \land \neg\mathbf B \in \Phi \left[{\Gamma}\right]$. By induction hypothesis, it follows that: :$v \models_{\mathrm{BI}} \mathbf A,\mathbf B$ or $v \models_{\mathrm{BI}} \neg\mathbf A,\neg\mathbf B$ By the [[Definition:Biconditional/Truth Function|truth function for $\iff$]], it follows that: :$v \models_{\mathrm{BI}} \mathbf A \iff \mathbf B$ If $\mathbf C$ is $\neg \left({\mathbf A \iff \mathbf B}\right)$, then it can only be [[Definition:Used WFF|used]] by the $\boxed{\neg\iff}$ rule. Therefore, $\mathbf A\land \neg\mathbf B \in \Phi \left[{\Gamma}\right]$ or $\neg\mathbf A \land \mathbf B \in \Phi \left[{\Gamma}\right]$. By induction hypothesis, it follows that: :$v \models_{\mathrm{BI}} \mathbf A,\neg\mathbf B$ or $v \models_{\mathrm{BI}} \neg\mathbf A,\mathbf B$ By the [[Definition:Biconditional/Truth Function|truth function for $\iff$]], it follows that: :$v \models_{\mathrm{BI}} \neg \left({\mathbf A \iff \mathbf B}\right)$ Having dealt with all cases, it follows from the [[Principle of Structural Induction]] that: :$v \models_{\mathrm{BI}} \mathbf C$ for all [[Definition:WFF of Propositional Logic|WFFs]] $\mathbf C$ that [[Definition:Occurrence along Branch|occur]] along $\Gamma$ That is to say: :$v \models_{\mathrm{BI}} \Phi \left[{\Gamma}\right]$ {{qed}} [[Category:Propositional Tableaus]] da9sr6r7oljqe5xoif0lui89r0445rn	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, the [[Definition:Truth Value|truth values]] in the appropriate columns match. $\begin{array}{|c||cc|} \hline \top & \neg & \bot \\ \hline T & T & F \\ \hline \end{array}$ {{qed}}	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, in each case, the [[Definition:Truth Value|truth values]] in the appropriate columns match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c|ccc||c|ccc|} \hline \bot & p & \land & \bot & p \\ \hline F & F & F & F & F \\ F & T & F & F & T \\ \hline \end{array}$ {{qed}}	1
Let $\struct {S, \circ, \preceq}$ be a [[Definition:Naturally Ordered Semigroup|naturally ordered semigroup]]. Let $p \in S$. Let $T \subseteq S$ such that: :$x \in T \implies p \preceq x \land \paren {x \in T \implies x \circ 1 \in T}$ Then: :$S \setminus S_p \subseteq T$ where: :$\setminus$ denotes [[Definition:Set Difference|set difference]] :$S_p$ denotes the [[Definition:Initial Segment|set of all elements of $S$ preceding $p$]].	1
{{:Double Negation/Double Negation Introduction/Sequent Form/Formulation 1}}	1
Let $n \in \Z: n \ge 1$. Let $n$ be expressed in [[Definition:Binary Notation|binary notation]]: :$n = 2^{e_1} + 2^{e_2} + \cdots + 2^{e_r}$ where $e_1 > e_2 > \cdots > e_r \ge 0$. Let $n!$ be the [[Definition:Factorial|factorial]] of $n$. Then $n!$ is [[Definition:Divisor of Integer|divisible]] by $2^{n-r}$, but not by $2^{n-r+1}$.	1
:$\paren {p \implies r} \lor \paren {q \implies r} \vdash \paren {p \land q} \implies r$	1
{{BeginTableau|\vdash \paren {p \land \neg q} \implies \paren {\neg \paren {p \implies q} } }} {{Assumption|1|p \land \neg q}} {{SequentIntro|2|1|\neg \paren {p \implies q}|1|[[Conjunction with Negative Equivalent to Negation of Implication/Formulation 1/Forward Implication|Conjunction with Negative Equivalent to Negation of Implication: Formulation 1]]}} {{Implication|3||\paren {p \land \neg q} \implies \paren {\neg \paren {p \implies q} }|1|2}} {{EndTableau}} {{qed}}	1
Let $\LL$ be a [[Definition:Logical Language|logical language]]. Let $\mathscr M$ be a [[Definition:Formal Semantics|formal semantics]] for $\LL$. Let $\FF$ be an [[Definition:Unsatisfiable Set of Formulas|$\mathscr M$-unsatisfiable set of formulas]] from $\LL$. Let $\phi$ be a [[Definition:Logical Formula|logical formula]]. Then $\FF \cup \set \phi$ is also [[Definition:Unsatisfiable Set of Formulas|$\mathscr M$-unsatisfiable]].	1
There are $16$ [[Definition:Distinct Elements|distinct]] [[Definition:Binary Operation|binary]] [[Definition:Truth Function|truth functions]]: * Two [[Definition:Constant Mapping|constant functions]]: ** $\map {f_\F} {p, q} = \F$ ** $\map {f_\T} {p, q} = \T$ * Two [[Definition:Projection (Mapping Theory)|projections]]: ** $\map {\pr_1} {p, q} = p$ ** $\map {\pr_2} {p, q} = q$ * Two [[Definition:Logical Not|negated]] [[Definition:Projection (Mapping Theory)|projections]]: ** $\map {\overline {\pr_1} } {p, q} = \neg p$ ** $\map {\overline {\pr_2} } {p, q} = \neg q$ * The [[Definition:Conjunction|conjunction]]: $p \land q$ * The [[Definition:Disjunction|disjunction]]: $p \lor q$ * Two [[Definition:Conditional|conditionals]]: ** $p \implies q$ ** $q \implies p$ * The [[Definition:Biconditional|biconditional]]: $p \iff q$ * The [[Definition:Exclusive Or|exclusive or]]: $\map \neg {p \iff q}$ * Two [[Definition:Logical Not|negated]] [[Definition:Conditional|conditionals]]: ** $\map \neg {p \implies q}$ ** $\map \neg {q \implies p}$ * The [[Definition:Logical NAND|NAND]]: $p \uparrow q$ * The [[Definition:Logical NOR|NOR]]: $p \downarrow q$	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|cccc||ccccccccc|} \hline \neg & (p & \iff & q) & (\neg & p & \land & q) & \lor & (p & \land & \neg & q) \\ \hline F & F & T & F & T & F & F & F & F & F & F & T & F \\ T & F & F & T & T & F & T & T & T & F & F & F & T \\ T & T & F & F & F & T & F & F & T & T & T & T & F \\ F & T & T & T & F & T & F & T & F & T & F & F & T \\ \hline \end{array}$ {{qed}}	1
{{BeginTableau|p \implies q \vdash \neg p \lor q}} {{Premise|1|p \implies q}} {{ExcludedMiddle|2|p \lor \neg p}} {{Assumption|3|\neg p}} {{Addition|4|3|\neg p \lor q|3|1}} {{Assumption|5|p}} {{ModusPonens|6|1, 5|q|1|5}} {{Addition|7|1, 5|\neg p \lor q|6|2}} {{ProofByCases|8|1|\neg p \lor q|2|3|4|5|7}} {{EndTableau}} {{qed}}	1
:$(1): \quad p \vdash p \lor q$ :$(2): \quad q \vdash p \lor q$	1
From the initial definition of [[Definition:Fibonacci Number|Fibonacci numbers]], we have: :$F_0 = 0, F_1 = 1, F_2 = 1, F_3 = 2, F_4 = 3$ By definition of the [[Definition:Fibonacci Number for Negative Index|extension of the Fibonacci numbers to negative integers]]: :$F_n = F_{n + 2} - F_{n - 1}$ The proof proceeds by [[Principle of Mathematical Induction|induction]]. For all $n \in \N_{>0}$, let $P \left({n}\right)$ be the [[Definition:Proposition|proposition]]: :$F_{-n} = \left({-1}\right)^n F_n$ === Basis for the Induction === $P \left({1}\right)$ is the case: {{begin-eqn}} {{eqn | l = F_{-1} | r = F_1 - F_0 | c = }} {{eqn | r = 1 - 0 | c = }} {{eqn | r = 1 | c = }} {{eqn | r = \left({-1}\right)^{1 + 1} F_1 | c = }} {{end-eqn}} So $P(1)$ is seen to hold. $P \left({2}\right)$ is the case: {{begin-eqn}} {{eqn | l = F_{-2} | r = F_0 - F_{-1} | c = }} {{eqn | r = 0 - 1 | c = }} {{eqn | r = -1 | c = }} {{eqn | r = \left({-1}\right)^{2 + 1} F_2 | c = }} {{end-eqn}} So $P(2)$ is seen to hold. This is our [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $P \left({k}\right)$ and $P \left({k-1}\right)$ are true, where $k > 1$, then it logically follows that $P \left({k+1}\right)$ is true. So this is our [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$F_{-\left({k - 1}\right)} = \left({-1}\right)^k F_{k - 1}$ :$F_{-k} = \left({-1}\right)^{k + 1} F_k$ Then we need to show: :$F_{-\left({k + 1}\right)} = \left({-1}\right)^{k + 2} F_{k + 1}$ === Induction Step === This is our [[Principle of Mathematical Induction#Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = F_{- \left({k + 1}\right)} | r = F_{-\left({k - 1}\right)} - F_{-k} | c = {{Defof|Fibonacci Number for Negative Index}} }} {{eqn | r = \left({-1}\right)^k F_{k - 1} - \left({-1}\right)^{k + 1} F_k | c = [[Fibonacci Number with Negative Index#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \left({-1}\right)^k F_{k - 1} + \left({-1}\right)^k F_k | c = }} {{eqn | r = \left({-1}\right)^k \left({F_{k - 1} + F_k}\right) | c = }} {{eqn | r = \left({-1}\right)^k \left({F_{k + 1} }\right) | c = {{Defof|Fibonacci Number}} }} {{eqn | r = \left({-1}\right)^{k + 2} \left({F_{k + 1} }\right) | c = }} {{end-eqn}} So $P \left({k}\right) \land P \left({k-1}\right) \implies P \left({k + 1}\right)$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\forall n \in \Z_{>0} : F_{-n} = \left({-1}\right)^{n + 1} F_n$ {{qed}}	1
:$(1): \quad p \land q \vdash p$ :$(2): \quad p \land q \vdash q$	1
Let $\mathcal L$ be a [[Definition:Logical Language|logical language]]. Let $\mathscr M$ be a [[Definition:Formal Semantics|formal semantics]] for $\mathcal L$. Let $\mathcal F, \mathcal G$ and $\mathcal H$ be [[Definition:Set|sets]] of [[Definition:Logical Formula|$\mathcal L$-formulas]]. Suppose that: :$\mathcal F \models_{\mathscr M} \mathcal G$ :$\mathcal G \models_{\mathscr M} \mathcal H$ Then $\mathcal F \models_{\mathscr M} \mathcal H$.	1
Let $\struct {M, \circ}$ be a [[Definition:Monoid|monoid]] whose [[Definition:Identity Element|identity element]] is $e$. Then: :$\forall n \in \Z: e^n = e$	1
{{BeginTableau|\neg \paren {\paren {p \uparrow q} \uparrow r \implies p \uparrow \paren {q \uparrow r} } }} {{Assumption|1|\paren {p \uparrow q} \uparrow r \implies p \uparrow \paren {q \uparrow r} }} {{Assumption|2|p \land \neg r}} {{Simplification|3|2|p|2|1}} {{Simplification|4|2|\neg r|2|2}} {{Addition|5|2|\paren {\neg q} \lor \paren {\neg r}|4|2}} {{DeMorgan|6|2|\neg \paren {q \land r}|5|Disjunction of Negations}} {{SequentIntro|7|2|q \uparrow r|6 |Definition of [[Definition:Logical NAND|Logical NAND]]}} {{Conjunction|8|2|p \land \paren {q \uparrow r}|3|7}} {{DoubleNegIntro|9|2|\neg \neg \paren {p \land \paren {q \uparrow r} }|8}} {{SequentIntro|10|2|\neg \paren {p \uparrow \paren {q \uparrow r} }|9 |Definition of [[Definition:Logical NAND|Logical NAND]]}} {{Addition|11|2|\paren {\neg \paren {p \uparrow q} } \lor \paren {\neg r}|4|2}} {{DeMorgan|12|2|\neg \paren {\paren {p \uparrow q} \land r}|11|Disjunction of Negations}} {{SequentIntro|13|2|\paren {p \uparrow q} \uparrow r|12 |Definition of [[Definition:Logical NAND|Logical NAND]]}} {{DoubleNegIntro|14|2|\neg \neg \paren {\paren {p \uparrow q} \uparrow r}|13}} {{Conjunction|15|2|\neg \neg \paren {\paren {p \uparrow q} \uparrow r} \land \neg \paren {p \uparrow \paren {q \uparrow r} }|13|10}} {{DeMorgan|16|2|\neg \paren {\neg \paren {\paren {p \uparrow q} \uparrow r} \lor \paren {p \uparrow \paren {q \uparrow r} } }|15|Conjunction of Negations}} {{SequentIntro|17|2 |\neg \paren {\paren {p \uparrow q} \uparrow r \implies p \uparrow \paren {q \uparrow r} } |16 |[[Disjunction and Implication]] }} {{NonContradiction|18|1, 2|1|17}} {{EndTableau}} Taking $p = \top$, $r = \bot$, we find $\vdash p \land \neg r$, and conclude our initial assumption was false. {{qed}}	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc||ccccccc|} \hline p & \land & (q & \lor & r) & (p & \land & q) & \lor & (p & \land & r) \\ \hline F & F & F & F & F & F & F & F & F & F & F & F \\ F & F & F & T & T & F & F & F & F & F & F & T \\ F & F & T & T & F & F & F & T & F & F & F & F \\ F & F & T & T & T & F & F & T & F & F & F & T \\ T & F & F & F & F & T & F & F & F & T & F & F \\ T & T & F & T & T & T & F & F & T & T & T & T \\ T & T & T & T & F & T & T & T & T & T & F & F \\ T & T & T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
From [[Sum of Binomial Coefficients over Lower Index]] we have: :$\displaystyle \sum_{i \mathop \in \Z} \binom n i = 2^n$ That is: :$\dbinom n 0 + \dbinom n 1 + \dbinom n 2 + \dbinom n 3 + \cdots + \dbinom n n = 2^n$ as $\dbinom n i = 0$ for $i < 0$ and $i > n$. This can be written more conveniently as: :$\dbinom n 0 + \dbinom n 1 + \dbinom n 2 + \dbinom n 3 + \dbinom n 4 + \cdots = 2^n$ Similarly, from [[Alternating Sum and Difference of Binomial Coefficients for Given n]] we have: :$\displaystyle \sum_{i \mathop \in \Z} \left({-1}\right)^i \binom n i = 0$ That is: :$\dbinom n 0 - \dbinom n 1 + \dbinom n 2 - \dbinom n 3 + \dbinom n 4 - \cdots = 0$ Adding them together, we get: :$2 \dbinom n 0 + 2 \dbinom n 2 + 2 \dbinom n 4 + \cdots = 2^n$ as the odd index coefficients cancel out. Dividing by $2$ throughout gives us the result. {{qed}}	1
Let $S$ be a [[Definition:Set|set]], and let $\powerset S$ be its [[Definition:Power Set|power set]]. Denote with $\cup$, $\cap$ and $\complement$ the operations of [[Definition:Set Union|union]], [[Definition:Set Intersection|intersection]] and [[Definition:Complement|complement]] on $\powerset S$, respectively. Then $\struct {\powerset S, \cup, \cap, \complement}$ is a [[Definition:Boolean Algebra|Boolean algebra]].	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|cccc||ccccccccc|} \hline \neg & (p & \iff & q) & \neg & (p & \implies & q) & \lor & \neg & (q & \implies & p) \\ \hline F & F & T & F & F & F & T & F & F & F & F & T & F \\ T & F & F & T & F & F & T & T & T & T & T & F & F \\ T & T & F & F & T & T & F & F & T & F & F & T & T \\ F & T & T & T & F & T & T & T & F & F & T & T & T \\ \hline \end{array}$ {{qed}}	1
{{BeginTableau|\vdash \left({\neg q \implies p}\right) \implies \left({\neg p \implies q}\right)}} {{Assumption|1|\neg q \implies p}} {{Assumption|2|\neg p}} {{ModusTollens|3|1, 2|\neg \neg q|1|2}} {{DoubleNegElimination|4|1, 2|q|3}} {{Implication|5|1|\neg p \implies q|2|4}} {{Implication|6||\left({\neg q \implies p}\right) \implies \left({\neg p \implies q}\right)|1|5}} {{EndTableau}} {{Qed}} {{LEM|Double Negation Elimination|4}}	1
We first consider the case where $L$ is [[Definition:Finite Set|finite]]. Let $S \subseteq \N$ be the set of all $n \in \N$ such that: :For every [[Definition:Finite Set|finite]] [[Definition:Generator of Vector Space|generator]] $F$ of $V$, if $\card {L \setminus F} \le n$, then $\card L \le \card F$ where: :$L \setminus F$ denotes the [[Definition:Set Difference|set difference]] between $L$ and $F$ :$\card L$ and $\card F$ denote the [[Definition:Cardinality|cardinality]] of $L$ and $F$ respectively. We use the [[Principle of Finite Induction]] to prove that $S = \N$. === Basis of the Induction === Let $\card {L \setminus F} \le 0$. Then from [[Cardinality of Empty Set]]: :$L \setminus F = \O$ By [[Set Difference with Superset is Empty Set]]: :$L \subseteq F$ By [[Cardinality of Subset of Finite Set]]: :$\card L \le \card F$ Hence: :$0 \in S$ This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === It is to be shown that if $k \in S$ where $k \ge 1$, then it follows that $k + 1 \in S$. This is the [[Definition:Induction Hypothesis|induction hypothesis]]: :For every [[Definition:Finite Set|finite]] [[Definition:Generator of Vector Space|generator]] $F$ of $V$, if $\card {L \setminus F} \le k$, then $\card L \le \card F$ It is to be demonstrated that it follows that: :For every [[Definition:Finite Set|finite]] [[Definition:Generator of Vector Space|generator]] $F$ of $V$, if $\card {L \setminus F} \le k + 1$, then $\card L \le \card F$ === Induction Step === This is the [[Definition:Induction Step|induction step]]: Assume the [[Size of Linearly Independent Subset is at Most Size of Finite Generator/Proof 1#Induction Hypothesis|induction hypothesis]] that $n \in S$. Let $F$ be a [[Definition:Finite Set|finite]] [[Definition:Generator of Vector Space|generator]] of $V$ such that: :$\card {L \setminus F} = n + 1$ Let $v \in L \setminus F$. Let $L' = L \cap \paren {F \cup \set v}$. By [[Intersection is Subset]]: :$L' \subseteq L$ By [[Subset of Linearly Independent Set]], it follows that $L'$ is [[Definition:Linearly Independent Set|linearly independent]] over $R$. Also by [[Intersection is Subset]]: :$L' \subseteq F \cup \set v$ Therefore, by [[Vector Space has Basis Between Linearly Independent Set and Finite Spanning Set]]: :[[Definition:Existential Quantifier|there exists]] a [[Definition:Basis (Linear Algebra)|basis]] $B$ of $V$ such that: ::$L' \subseteq B \subseteq F \cup \set v$ Since $v \notin F$ is a [[Definition:Linear Combination of Subset|linear combination]] of $F$, it follows that $F \cup \set v$ is [[Definition:Linearly Dependent Set|linearly dependent]] over $R$. Therefore: :$B \subsetneq F \cup \set v$ By [[Cardinality of Subset of Finite Set]]: :$\card B < \card {F \cup \set v} = \card F + 1$ Hence: :$\card B \le \card F$ We have that: {{begin-eqn}} {{eqn | l = \card {L \setminus B} | o = \le | r = \card {L \setminus L'} | c = [[Relative Complement inverts Subsets]] and [[Cardinality of Subset of Finite Set]] }} {{eqn | r = \card {L \setminus \paren {F \cup \set v} } | c = [[Set Difference with Intersection is Difference]] }} {{eqn | r = \card {\paren {L \setminus F} \setminus \set v} | c = [[Set Difference with Union]] }} {{eqn | r = n + 1 - 1 | c = [[Cardinality of Set Difference with Subset]] }} {{eqn | r = n }} {{end-eqn}} Since $n \in S$: :$\card L \le \card B \le \card F$ Hence: :$n + 1 \in S$ and so the [[Definition:Induction Step|induction step]] has been completed. By [[Set Difference is Subset]]: :$L \setminus F \subseteq L$ From [[Subset of Finite Set is Finite]]: :$L \setminus F$ is [[Definition:Finite Set|finite]]. Therefore, we can apply the fact that $S = \N$ to conclude that: :$\card L \le \card F$ Let $L$ be [[Definition:Infinite Set|infinite]]. Then by [[Set is Infinite iff exist Subsets of all Finite Cardinalities]], there exists a [[Definition:Finite Set|finite]] [[Definition:Subset|subset]] $L' \subseteq L$ such that: :$\card {L'} = \card F + 1$ By [[Subset of Linearly Independent Set]], it follows that $L'$ is [[Definition:Linearly Independent Set|linearly independent]] over $R$. It is proven above that this is impossible. Hence the result. {{qed}}	1
:$p \land \neg q \vdash \neg \paren {p \implies q}$	1
There are $2^{\paren {2^k} }$ [[Definition:Distinct Elements|distinct]] [[Definition:Truth Function|truth functions]] on $k$ variables.	1
The [[Definition:Golay Ternary Code|Golay ternary code]] corrects $2$ [[Definition:Transmission Error|transmission errors]].	1
The [[Rule of Commutation/Disjunction/Formulation 2/Forward Implication|Rule of Commutation]]: :$\left({p \lor q}\right) \implies \left({q \lor p}\right)$ is a [[Definition:Tautology (Formal Semantics)|tautology]] in [[Definition:Constructed Semantics/Instance 5|Instance 5]] of [[Definition:Constructed Semantics|constructed semantics]].	1
We have that $\phi$ is a [[Definition:Provable Consequence|provable consequence]] of $\mathcal F$. Hence it is a [[Definition:Theorem (Formal Systems)|theorem]] of $\mathscr P (\mathcal F)$, the [[Definition:Proof System|proof system]] obtained from $\mathscr P$ by adding all of $\mathcal F$ as [[Definition:Axiom (Formal Systems)|axioms]]. Now in the [[Definition:Formal Proof|formal proof]] of $\phi$ in $\mathscr P (\mathcal F)$, both [[Definition:Axiom (Formal Systems)|axioms]] and [[Definition:Rule of Inference|rules of inference]] are used. Each [[Definition:Rule of Inference|rule of inference]] of $\mathscr P (\mathcal F)$ is also a [[Definition:Rule of Inference|rule of inference]] of $\mathscr P$. Similarly, by construction, each [[Definition:Axiom (Formal Systems)|axiom]] of $\mathscr P (\mathcal F)$ is either an [[Definition:Axiom (Formal Systems)|axiom]] of $\mathscr P$ or an element of $\mathcal F$. But the elements of $\mathcal F$ are [[Definition:Theorem (Formal Systems)|theorems]] of $\mathscr P$, each of which thus has a [[Definition:Formal Proof|formal proof]] in $\mathscr P$. By definition, the [[Definition:Rule of Inference|rules of inference]] of a [[Definition:Proof System|proof system]] do not distinguish between [[Definition:Theorem (Formal Systems)|theorems]] and [[Definition:Axiom (Formal Systems)|axioms]]. Therefore the [[Definition:Formal Proof|formal proofs]] of the following can be combined: :$\vdash_{\mathscr P} \mathcal F$ :$\vdash_{\mathscr P (\mathcal F)} \phi$ by letting the latter follow the former. This yields a new [[Definition:Formal Proof|formal proof]], which is entirely formulated in $\mathscr P$. This is the desired [[Definition:Formal Proof|formal proof]] of $\phi$ from $\mathscr P$, and we conclude: :$\vdash_{\mathscr P} \phi$ {{qed}} [[Category:Formal Systems]] hxt2j7f4evu5cyiu6zmbl4f6gmmagd2	1
{{begin-eqn}} {{eqn | l = a | r = b | c = }} {{eqn | ll= \vdash | l = \map P a | o = \iff | r = \map P b | c = [[Axiom:Leibniz's Law|Leibniz's Law]] }} {{eqn | ll= \vdash | l = \map P b | o = \iff | r = \map P a | c = [[Biconditional is Commutative]] }} {{eqn | ll= \vdash | l = b | r = a | c = [[Axiom:Leibniz's Law|Leibniz's Law]] }} {{end-eqn}} {{qed}}	1
: $\vdash p \implies p$	1
:$\vdash \neg \left({p \implies q}\right) \implies \neg q$	1
{{ProofWanted|Proof given later in book. Chapter III gets technical.}}	1
:$\vdash \paren {p \land \neg q} \iff \paren {\neg \paren {p \implies q} }$	1
From [[Peirce's Law]]: :$\left({p \implies q}\right) \implies p \vdash p$ follows [[Clavius's Law]]: :$\neg p \implies p \vdash p$	1
Let $C$ be a [[Definition:Linear Code|linear $\tuple {n, k}$-code]] whose [[Definition:Master Code|master code]] is $\map V {n, p}$ Let $G$ be a [[Definition:Standard Generator Matrix for Linear Code|(standard) generator matrix]] for $C$. Let $P$ be a [[Definition:Standard Parity Check Matrix|standard parity check matrix]] for $C$. Let $u, v \in \map V {n, p}$. Then $u$ and $v$ have the same [[Definition:Syndrome|syndrome]] {{iff}} they are in the same [[Definition:Coset|coset]] of $C$.	1
Let us verify the axioms for a [[Definition:Boolean Algebra|Boolean algebra]] in turn. === $(BA \ 0)$: Closure === Follows from [[Induced Operations Preserve Closure]]. {{qed|lemma}} === $(BA \ 1)$: Commutativity === Follows from [[Induced Operations Preserve Commutativity]]. {{qed|lemma}} === $(BA \ 2)$: Distributivity === Follows from [[Induced Operations Preserve Distributivity]]. {{qed|lemma}} === $(BA \ 3)$: Identities === Follows from [[Identity for Induced Operation]]. {{qed|lemma}} === $(BA \ 4)$: Complements === Follows from [[Induced Operations Preserve Identities]]. {{qed|lemma}} Having verified all the axioms, we conclude $\mathbf 2^X$ is a [[Definition:Boolean Algebra|Boolean algebra]]. {{qed}}	1
For each $n \in \N$, let $\map {P'} n$ be defined as: :$\map {P'} n := \map P 0 \land \dots \land \map P n$ It suffices to show that $\map {P'} n$ is true for all $n \in \N$. It is immediate from the assumption $\map P 0$ that $\map {P'} 0$ is [[Definition:True|true]]. Now suppose that $\map {P'} n$ holds. By $(2)$, this implies that $\map P {n + 1}$ holds as well. Consequently, $\map {P'} n \land \map P {n + 1} = \map {P'} {n + 1}$ holds. Thus by the [[Principle of Mathematical Induction]]: :$\map {P'} n$ holds for all $n \in \N$ as desired. {{Qed}}	1
Let $B = \struct {S, \vee, \wedge, \neg, \preceq}$ be a [[Definition:Boolean Lattice|Boolean lattice]]. Let $F$ be a [[Definition:Filter|filter]] in $B$. Then :$F$ is [[Definition:Prime Filter (Order Theory)|prime]] {{iff}} :$\forall x \in S: x \in F \lor \left({\neg x}\right) \in F$	1
=== Sufficient Condition === Let $\exists x: \map S x$. Let $\map {\mathbf A} {S, P}$ be [[Definition:True|true]]. As $\map {\mathbf A} {S, P}$ is [[Definition:True|true]], then by [[Modus Ponendo Ponens]]: :$\map P x$ From the [[Rule of Conjunction/Proof Rule|Rule of Conjunction]]: :$\map S x \land \map P x$ Thus $\map {\mathbf I} {S, P}$ holds. So by the [[Rule of Implication]]: :$\map {\mathbf A} {S, P} \implies \map {\mathbf I} {S, P}$ {{qed|lemma}} === Necessary Condition === Let $\map {\mathbf A} {S, P} \implies \map {\mathbf I} {S, P}$. Suppose: :$\neg \exists x: \map S x$ that is, $\map S x$ is [[Definition:Vacuous Truth|vacuous]]. From [[De Morgan's Laws (Predicate Logic)/Denial of Existence|De Morgan's Laws: Denial of Existence]]: :$\forall x: \neg \map S x \dashv \vdash \neg \exists x: \map S x$ it follows that $\forall x: \map S x$ is [[Definition:False|false]]. From [[False Statement implies Every Statement]]: :$\forall x: \map S x \implies \map P x$ is [[Definition:True|true]]. So $\map {\mathbf A} {S, P}$ holds. Again, $\neg \exists x: \map S x$. Then by the [[Rule of Conjunction/Proof Rule|Rule of Conjunction]]: :$\neg \paren {\exists x: \map S x \land \map P x}$ That is, $\mathbf I$ does not hold. So $\map {\mathbf A} {S, P}$ is [[Definition:True|true]] and $\map {\mathbf I} {S, P}$ is [[Definition:False|false]]. This [[Proof by Contradiction|contradicts]] $\map {\mathbf A} {S, P} \implies \map {\mathbf I} {S, P}$ by definition of [[Definition:Conditional|implication]]. Thus $\exists x: \map S x$ must hold. {{qed}}	1
By definition, $T$ is [[Definition:Finitely Satisfiable|finitely satisfiable]] means that every [[Definition:Finite Subset|finite subset]] of $T$ is [[Definition:Satisfiable|satisfiable]]. Since the direction :$T$ [[Definition:Satisfiable Set of Formulas|satisfiable]] implies $T$ [[Definition:Finitely Satisfiable|finitely satisfiable]] is trivial, the proofs below all justify the converse :$T$ [[Definition:Finitely Satisfiable|finitely satisfiable]] implies $T$ [[Definition:Satisfiable Set of Formulas|satisfiable]].	1
{{BeginTableau|p \vdash p \lor p}} {{Premise|1|p}} {{Addition|2|1|p \lor p|1|1}} {{EndTableau}} {{qed}}	1
Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \Z_{> 0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$16^n \equiv 16 \pmod {20}$ === Basis for the Induction === $\map P 1$ is the case: :$16^1 \equiv 16 \pmod {20}$ Thus $\map P 1$ is seen to hold. This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is the [[Definition:Induction Hypothesis|induction hypothesis]]: :$16^k \equiv 16 \pmod {20}$ from which it is to be shown that: :$16^{k + 1} \equiv 16 \pmod {20}$ === Induction Step === This is the [[Definition:Induction Step|induction step]]: We have: {{begin-eqn}} {{eqn | l = 16^{k + 1} | r = 16^k \times 16 }} {{eqn | o = \equiv | r = 16 \times 16 | rr= \pmod {20} | c = [[Powers of 16 Modulo 20#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | o = \equiv | r = 256 | rr= \pmod {20} }} {{eqn | o = \equiv | r = 16 | rr= \pmod {20} | c = }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and thus it follows by the [[Principle of Mathematical Induction]] that: :$\forall n \in \Z_{> 0}: 16^n \equiv 16 \pmod {20}$ {{qed}}	1
:$(1): \quad$ ''All humans are mortal.'' :$(2): \quad$ ''{{AuthorRef|Socrates}} is human.'' :$(3): \quad$ ''Therefore {{AuthorRef|Socrates}} is mortal.''	1
: $p \implies q, q \implies r, p \vdash r$	1
{{BeginTableau|\vdash \paren {p \land \neg p} \implies q}} {{Assumption|1|p \land \neg p}} {{Simplification|2|1|p|1|1}} {{Simplification|3|1|\neg p|1|2}} {{Addition|4|1|p \lor q|2|1}} {{ModusTollendoPonens|5|1|q|4|3}} {{EndTableau|qed}}	1
[[Definition:By Hypothesis|By hypothesis]] and [[Definition:Substitution Instance|substitution instance]] we have a proof, using primitive rules, of: : $P_1, P_2, \ldots, P_n \vdash Q$ By the [[Extended Rule of Implication]], we have: : $\vdash P_1 \implies \left({P_2 \implies \left({P_3 \implies \left({\ldots \implies \left({P_n \implies Q}\right) \ldots }\right)}\right)}\right)$ {{Qed}}	1
By definition, a [[Definition:Strictly Competitive Game|strictly competitive game]] is a [[Definition:Game|game]] in which the interests of each [[Definition:Player|player]] are diametrically opposed. Recall the [[Definition:Matching Pennies/Payoff Table|payoff table]] of [[Definition:Matching Pennies|Matching Pennies]]: {{:Definition:Matching Pennies/Payoff Table}} It can be seen by inspection that exchanging $\text A$ and $\text B$ results in exactly the same [[Definition:Entry in Payoff Table|entries]] in the [[Definition:Matching Pennies/Payoff Table|payoff table]]. From the nature of a [[Definition:Matching Pennies/Payoff Table|payoff table]] it follows that the fortunes of each [[Definition:Player|player]] are opposite and equal. Hence the result. {{qed}}	1
:$\vdash \paren {q \implies r} \implies \paren {\paren {p \implies q} \implies \paren {p \implies r} }$	1
{{BeginTableau|p \lor \paren {q \lor r} \vdash \paren {p \lor q} \lor r}} {{Premise|1|p \lor \paren {q \lor r} }} {{Assumption|2|p|By assuming the first main disjunct ...}} {{Addition|3|2|p \lor q|2|1}} {{Addition|4|2|\paren {p \lor q} \lor r|3|1|... the conclusion is derived}} {{Assumption|5|q \lor r|Then assume the second main disjunct ...}} {{Assumption|6|q|... and by assuming the first disjunct of that second main disjunct ...}} {{Addition|7|6|p \lor q|6|2}} {{Addition|8|6|\paren {p \lor q} \lor r|7|1|... the conclusion is derived}} {{Assumption|9|r|Then assume the second disjunct of that second main disjunct ...}} {{Addition|10|9|\paren {p \lor q} \lor r|9|2|... and likewise the same conclusion is derived}} {{ProofByCases|11|5|\paren {p \lor q} \lor r|5|6|8|9|10}} {{ProofByCases|12|1|\paren {p \lor q} \lor r|1|2|4|5|11}} {{EndTableau|lemma}} {{BeginTableau|\paren {p \lor q} \lor r \vdash p \lor \paren {q \lor r} }} {{Premise|1|\paren {p \lor q} \lor r}} {{Assumption|2|p \lor q}} {{Assumption|3|p}} {{Addition|4|3|p \lor \paren {q \lor r}|3|1}} {{Assumption|5|q}} {{Addition|6|5|q \lor r|5|1}} {{Addition|7|5|p \lor \paren {q \lor r}|6|2}} {{ProofByCases|8|2|p \lor \paren {q \lor r}|2|3|4|5|7}} {{Assumption|9|r}} {{Addition|10|9|q \lor r|9|2}} {{Addition|11|9|p \lor \paren {q \lor r}|10|2}} {{ProofByCases|12|1|p \lor \paren {q \lor r}|1|2|8|9|11}} {{EndTableau|qed}}	1
As can be seen for all [[Definition:Boolean Interpretation|boolean interpretations]] by inspection, where the [[Definition:Truth Value|truth value]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] on the {{LHS}} is $T$, that under the one on the {{RHS}} is also $T$: :$\begin{array}{|ccc||ccc||ccccccc|} \hline p & q & r & (p & \implies & q) & (p & \lor & r) & \implies & (q & \lor & r) \\ \hline F & F & F & F & T & F & F & F & F & T & F & F & F \\ F & F & T & F & T & F & F & T & T & T & F & T & T \\ F & T & F & F & T & T & F & F & F & T & T & T & F \\ F & T & T & F & T & T & F & T & T & T & T & T & T \\ T & F & F & T & F & F & T & T & F & F & F & F & F \\ T & F & T & T & F & F & T & T & T & T & F & T & T \\ T & T & F & T & T & T & T & T & F & T & T & T & F \\ T & T & T & T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
=== Definition 1 implies Definition 2 === Suppose that $\neg \vdash_{\mathscr P} \phi$. Suppose additionally that there is some [[Definition:Logical Formula|logical formula]] $\psi$ such that: :$\vdash_{\mathscr P} \psi, \neg \psi$ By the [[Rule of Explosion/Variant 3|Rule of Explosion]]: :$\psi, \neg \psi \vdash_{\mathscr P} \phi$ By [[Provable Consequence of Theorems is Theorem]], we conclude: :$\vdash_{\mathscr P} \phi$ in contradiction to our assumption. {{qed|lemma}} === Definition 2 implies Definition 1 === Suppose either $\phi$ or $\neg \phi$ is not a [[Definition:Theorem (Formal Systems)|theorem]] of $\mathscr P$. The implication follows trivially. {{qed}}	1
The [[Definition:Max Operation|maximum function]] $\max: \N^2 \to \N$, defined as: :$\max \left({n, m}\right) = \begin{cases} m: & n \le m \\ n: & m \le n \end{cases}$ is [[Definition:Primitive Recursive Function|primitive recursive]].	1
: $\neg \left({p \land q}\right) \vdash p \implies \neg q$	1
Let $f: \N \to \N$ and $g: \N \to \N$ be [[Definition:URM Computability|URM computable functions]] of one variable. Let $f \circ g$ be the [[Definition:Composite Function|composition]] of $f$ and $g$. Then $f \circ g: \N \to \N$ is a [[Definition:URM Computability|URM computable function]].	1
Consider $\N$ defined as a [[Definition:Peano Structure|Peano structure]]. The result follows from [[Principle of Mathematical Induction for Peano Structure]]. {{qed}}	1
: $\left({p \implies q}\right) \land \left({r \implies s}\right) \vdash \left({p \land r}\right) \implies \left({q \land s}\right)$	1
:$p, q \vdash p \land q$	1
: $\vdash \left({\left({p \iff q}\right) \land \left({q \iff r}\right)}\right) \implies \left({p \iff r}\right)$	1
Two [[Definition:Statement|statements]] are said to be '''contrary''' if they can both be [[Definition:False|false]], but they cannot both be [[Definition:True|true]].	1
The result follows directly from the [[Definition:Truth Table|truth table]] for the [[Definition:Biconditional|biconditional]]: $\begin{array}{|cc||ccc|} \hline p & q & p & \iff & q \\ \hline F & F & F & T & F \\ F & T & F & F & T \\ T & F & F & F & F \\ T & T & F & T & T \\ \hline \end{array}$ By inspection, it is seen that $\mathcal M \left({p \iff q}\right) = T$ precisely when $\mathcal M \left({p}\right) = \mathcal M \left({q}\right)$. {{qed}}	1
Let $\struct {S, \vee, \wedge}$ be a [[Definition:Boolean Algebra/Definition 1|Boolean algebra, defined as in Definition 1]]. Then for all $a, b \in S$: :$a = a \vee \paren {a \wedge b}$ :$a = a \wedge \paren {a \vee b}$ That is, $\vee$ [[Definition:Absorb|absorbs]] $\wedge$, and $\wedge$ [[Definition:Absorb|absorbs]] $\vee$.	1
:$p \vdash p \lor \paren {p \land q}$	1
The [[Factor Principles/Disjunction on Left/Formulation 2|Factor Principle]]: :$\left({p \implies q}\right) \implies \left({\left({r \lor p}\right) \implies \left ({r \lor q}\right)}\right)$ is a [[Definition:Tautology (Formal Semantics)|tautology]] in [[Definition:Constructed Semantics/Instance 2|Instance 2]] of [[Definition:Constructed Semantics|constructed semantics]].	1
:$\neg q \implies \neg p \vdash p \implies q$	1
==== [[Rule of Transposition/Variant 1/Formulation 1|Formulation 1]] ==== {{:Rule of Transposition/Variant 1/Formulation 1}} ==== [[Rule of Transposition/Variant 1/Formulation 2|Formulation 2]] ==== {{:Rule of Transposition/Variant 1/Formulation 2}}	1
Let $\left({S, \vee, \wedge, \neg}\right)$ be a [[Definition:Boolean Algebra|Boolean algebra]]. Let $a, b, c \in S$, and suppose that: {{begin-eqn}} {{eqn | l = a \vee c | r = b \vee c }} {{eqn | l = a \vee \neg c | r = b \vee \neg c }} {{end-eqn}} Then $a = b$.	1
A [[Definition:Tautology|tautology]] implies and is implied by the [[Definition:Logical Not|negation]] of a [[Definition:Contradiction|contradiction]]: :$\top \dashv \vdash \neg \bot$ That is, a truth can not be false, and a non-falsehood must be a truth.	1
==== [[Biconditional Equivalent to Biconditional of Negations/Formulation 1|Formulation 1]] ==== {{:Biconditional Equivalent to Biconditional of Negations/Formulation 1}} ==== [[Biconditional Equivalent to Biconditional of Negations/Formulation 2|Formulation 2]] ==== {{:Biconditional Equivalent to Biconditional of Negations/Formulation 2}}	1
{{BeginTableau|p \implies q \vdash \paren {p \lor r} \implies \paren {q \lor r} }} {{Premise|1|p \implies q}} {{Assumption|2|p \lor r}} {{Commutation|3|2|r \lor p|2|Disjunction}} {{SequentIntro|4|1|\paren {r \lor p} \implies \paren {r \lor q}|1|[[Factor Principles/Disjunction on Left/Formulation 1]]}} {{ModusPonens|5|1,2|r \lor q|4|3}} {{Commutation|6|1,2|q \lor r|5|Disjunction}} {{Implication|7|1|\paren {p \lor r} \implies \paren {q \lor r}|2|6}} {{EndTableau}} {{qed}}	1
: $p \implies q \vdash \left({r \land p}\right) \implies \left ({r \land q}\right)$	1
Let $a, b \in S$. Then: {{begin-eqn}} {{eqn | l = a \vee \paren {a \wedge b} | r = \paren {a \wedge \top} \vee \paren {a \wedge b} | c = [[Definition:Boolean Algebra/Axioms/Definition 1|Boolean Algebra: Axiom $(BA_1 \ 3)$]]: $\top$ is the [[Definition:Identity Element|identity]] for $\wedge$ }} {{eqn | r = a \wedge \paren {\top \vee b} | c = [[Definition:Boolean Algebra/Axioms/Definition 2|Boolean Algebra: Axiom $(BA_1 \ 2)$]]: $\wedge$ [[Definition:Distributive Operation|distributes]] over $\vee$ }} {{eqn | r = a \wedge \top | c = [[Identities of Boolean Algebra also Zeroes]] }} {{eqn | r = a | c = [[Definition:Boolean Algebra/Axioms/Definition 1|Boolean Algebra: Axiom $(BA_1 \ 3)$]] $\top$ is the [[Definition:Identity Element|identity]] for $\wedge$ }} {{end-eqn}} as desired. {{qed|lemma}} The result: :$a = a \wedge \paren {a \vee b}$ follows from the [[Duality Principle (Boolean Algebras)|Duality Principle]]. {{qed}}	1
A [[Definition:Linear Code|linear code]] $C$ can be obtained from $G$ by: :considering the [[Definition:Row of Matrix|rows]] of $G$ as [[Definition:Codeword of Linear Code|codewords]] :forming all possible [[Definition:Linear Combination|linear combinations]] of those [[Definition:Codeword of Linear Code|codewords]], considering them as [[Definition:Vector (Linear Algebra)|vectors]] of a [[Definition:Vector Space|vector space]].	1
Let $\mathcal A$ be the [[Definition:Set|set]] of finitely satisfiable extensions of $T$. By the [[Finitely Satisfiable Theory has Maximal Finitely Satisfiable Extension/Lemma|lemma]], for each element $S$ of $\mathcal A$ and each $\mathcal L$-sentence $\phi$, either $S \cup \left\{ {\phi}\right\} \in \mathcal A$ or $S \cup \left\{ {\neg \phi}\right\} \in \mathcal A$. $\mathcal A$ has [[Definition:Finite Character|finite character]], by the following argument: Let $S \in \mathcal A$. Let $F$ be a [[Definition:Finite Subset|finite subset]] of $S$. Then $S$ is satisfiable and hence finitely satisfiable. Thus in $\mathcal A$. Let $S$ be a theory on $\mathcal L$. Let every [[Definition:Finite Subset|finite subset]] of $S$ be finitely satisfiable. Then every [[Definition:Finite Subset|finite subset]] of $S$ is satisfiable. Therefore $S$ is finitely satisfiable. Thus $\mathcal A$ has finite character. By the [[Restricted Tukey-Teichmüller Theorem]], $\mathcal A$ has an element $T'$ such that: :for each $\mathcal L$-sentence $\phi$, either $\phi \in T'$ or $\neg \phi \in T'$. {{qed}}	1
:$\paren {p \vdash \bot} \vdash \neg p$	1
The [[Definition:Game|game]] of [[Definition:Matching Pennies|Matching Pennies]] is [[Definition:Strictly Competitive Game|strictly competitive]].	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|cccc||ccccccccc|} \hline \neg & (p & \iff & q) & \neg & (p & \implies & q) & \lor & \neg & (q & \implies & p) \\ \hline F & F & T & F & F & F & T & F & F & F & F & T & F \\ T & F & F & T & F & F & T & T & T & T & T & F & F \\ T & T & F & F & T & T & F & F & T & F & F & T & T \\ F & T & T & T & F & T & T & T & F & F & T & T & T \\ \hline \end{array}$ {{qed}}	1
Let $f: X \to X$ be a [[Definition:Periodic Function|periodic function]], where $X$ is either the [[Definition:Real Number|set of real numbers $\R$]] or the [[Definition:Complex Number|set of complex numbers $\C$]]. Let $L$ be a [[Definition:Periodic Element|periodic element]] of $f$. Then: :$\forall n \in \Z: \forall x \in X: \map f x = \map f {x + n L}$ That is, after every distance $L$, the function $f$ repeats itself.	1
=== For finite languages === For any ''finite'' regular language $L_{fin}$, the proof is simple. Let $s_{maxlen} \in L_{fin}$. Thus: :$\forall s \in L_{fin}: \left|{s}\right| \le \left|{s_{maxlen}}\right|$ Now choose $n_0 > \left|{s_{maxlen}}\right|$. The implication now trivially holds because the premise: :$\left({\left|{z}\right| > n_0}\right)$ is false. {{qed|lemma}} === For infinite languages === For any one ''infinite'' regular language $L_{inf}$, the following holds: :$(1): \quad$ There exists a finite automaton: ::::$F = \left({\Sigma, Q, q_0, A, \delta}\right)$ :::such that: :::: $\mathcal L \left({F}\right) = L_{inf}$. See [[Equivalence of Finite Automata and Regular Languages]] for a demonstration of this. :$(2): \quad$ There exists an infinite number of words $s \in L_{inf}$ with: ::::$\left|{s}\right| \ge \left|{Q}\right|$ Let $s \in L_{inf}$ be one of these words. Let $n_0 = \left|{Q}\right| + 1$. Consider all prefixes of this $s$. We have: :$\left|{s}\right| > \left|{Q}\right|$ Thus from the [[Pigeonhole Principle]], for at least two of them $F$ needs to end in the same state. Let the first two indices in $s$ for which this is the case be $i$ and $j$. The difference between $prefix_i$ and $prefix_j$ ($v$ in this formulation of the theorem) is a "loop" in $F$. This loop can be traversed any number of times (including 0) and $F$ will still be in the same state immediately afterwards. Hence: :$\forall i \N_0: u v^i w \in L_{inf}$ Furthermore: :$\left|{u v}\right| = j - 1 < n_0$ And since $i \ne j$ it follows that: :$\left|{v}\right| > 0$ {{qed|lemma}} === General case === Since it could be shown that the theorem holds for both all finite and all infinite regular languages, it can be stated that it holds for all regular languages. {{qed}}	1
There are $20$ ways to make the $1$st move by White: :Each of the $8$ [[Definition:Chess Pawn|pawns]] may be moved either $1$ or $2$ squares forward, making $16$ moves :Each of the $2$ [[Definition:Chess Knight|knights]] may be moved to either of $2$ squares before it, making $4$ moves. For each of those $20$ first moves by White, Black has the same $20$ options. Thus there are $20 \times 20$ possible different games after the $2$nd move. To count the $3$rd moves, one needs to consider cases. First note that after the $1$st move, whatever it was, there are $7$ [[Definition:Chess Pawn|pawns]] on the $2$nd rank, each of which can be moved $1$ or $2$ squares forward, making $14$ moves for each of those $400$ possibilities. Note that if a [[Definition:Chess Knight|knight]] was one of the pieces to have moved first, the [[Definition:Chess Pawn|pawn]] in the square behind where it ends up cannot move -- hence the $7$ [[Definition:Chess Pawn|pawns]] on the $2$nd rank that can move. Thus there are $400 \times 14 = 5600$ possible moves involving a so-far unmoved [[Definition:Chess Pawn|pawn]]. For each of the $400$ positions, there are exactly $8$ which consist of two [[Definition:Chess Pawn|pawns]] in opposition on the $4$th and $5$th rank. There are also another $4 \times 20 = 80$ positions in which white moved a [[Definition:Chess Knight|knight]]. For all other $400 - 88 = 312$ positions, the already-moved [[Definition:Chess Pawn|pawn]] has the option of moving another square forward. This gives another $312$ options for the $3$rd move. We now need to take into account the possibility that White may be able to capture a Black [[Definition:Chess Pawn|pawn]]. {{finish|Each case needs to be investigated.}}	1
: $\vdash \left({\neg \left({p \land q}\right)}\right) \iff \left({p \implies \neg q}\right)$	1
=== [[Non-Equivalence as Equivalence with Negation/Formulation 1/Forward Implication/Proof|Forward Implication: Proof]] === {{:Non-Equivalence as Equivalence with Negation/Formulation 1/Forward Implication/Proof}} === [[Non-Equivalence as Equivalence with Negation/Formulation 1/Reverse Implication/Proof|Reverse Implication: Proof]] === {{:Non-Equivalence as Equivalence with Negation/Formulation 1/Reverse Implication/Proof}}	1
Let $\mathcal M$ be a [[Definition:Model (Logic)|model]] of $\mathcal F \setminus \left\{{\psi}\right\}$. Since $\psi$ is a [[Definition:Tautology|tautology]], it follows that: :$\mathcal M \models_{\mathscr M} \psi$ Hence: :$\mathcal M \models \mathcal F$ which, by hypothesis, entails: :$\mathcal M \models \phi$ Since $\mathcal M$ was arbitrary, it follows by definition of [[Definition:Semantic Consequence|semantic consequence]] that: :$\mathcal F \setminus \left\{{\psi}\right\} \models_{\mathscr M} \phi$ {{qed}}	1
The proof proceeds by [[Second Principle of Mathematical Induction|strong induction]] on the [[Definition:Length of String|length]] of a [[Definition:WFF of Propositional Logic|WFF of propositional logic]]. Let $l \left({\mathbf Q}\right)$ denote the [[Definition:Length of String|length]] of a [[Definition:String|string]] $\mathbf Q$. For all $n \in \N_{> 0}$, let $P \left({n}\right)$ be the [[Definition:Proposition|proposition]]: :The [[Definition:Initial Part|initial part]] of $\mathbf A$ such that $l \left({\mathbf A}\right) = n$ is not a [[Definition:WFF of Propositional Logic|WFF of propositional logic]]. By definition, $\mathbf S$ is an [[Definition:Initial Part|initial part]] of $\mathbf A$ {{iff}} $\mathbf A = \mathbf {S T}$ for some [[Definition:Null String|non-null string]] $\mathbf T$. Thus we note that $l \left({\mathbf S}\right) < l \left({\mathbf A}\right)$. === Basis for the Induction === Let $\mathbf A$ be a [[Definition:WFF of Propositional Logic|WFF]] such that $l \left({\mathbf A}\right) = 1$. Then for an [[Definition:Initial Part|initial part]] $\mathbf S$: :$l \left({\mathbf S}\right) < 1 = 0$ That is, $\mathbf S$ must be the [[Definition:Null String|null string]], which is not a [[Definition:WFF of Propositional Logic|WFF]]. So the result holds for [[Definition:WFF of Propositional Logic|WFFs]] of [[Definition:Length of String|length]] $1$. That is, $P \left({1}\right)$ is true. This is our [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that for $k \ge 1$, if $P \left({j}\right)$ is true for all $j \le k$, then it logically follows that $P \left({k + 1}\right)$ is true. So this is our [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :The [[Definition:Initial Part|initial part]] of $\mathbf A$ such that $l \left({\mathbf A}\right) = k$ is not a [[Definition:WFF of Propositional Logic|WFF of propositional logic]]. Then we need to show: :The [[Definition:Initial Part|initial part]] of $\mathbf A$ such that $l \left({\mathbf A}\right) = k + 1$ is not a [[Definition:WFF of Propositional Logic|WFF of propositional logic]]. === Induction Step === This is our [[Principle of Mathematical Induction#Induction Step|induction step]]: Let $\mathbf A$ be a [[Definition:WFF of Propositional Logic|WFF]] such that $l \left({\mathbf A}\right) = k + 1$. Suppose $\mathbf D$ is an [[Definition:Initial Part|initial part]] of $\mathbf A$ which happens to be a [[Definition:WFF of Propositional Logic|WFF]]. That is, $\mathbf A = \mathbf{D T}$ where: : $\mathbf D$ is a [[Definition:WFF of Propositional Logic|WFF]] : $\mathbf T$ is [[Definition:Null String|non-null]]. There are two cases: $(1): \quad \mathbf A = \neg \mathbf B$ where $\mathbf B$ is a [[Definition:WFF of Propositional Logic|WFF]] of [[Definition:Length of String|length]] $k$. Thus $\mathbf D$ is a [[Definition:WFF of Propositional Logic|WFF]] starting with $\neg$. So: :$\mathbf D = \neg \mathbf E$ where $\mathbf E$ is also a [[Definition:WFF of Propositional Logic|WFF]]. We remove the initial $\neg$ from $\mathbf A = \mathbf{D T}$ to get: :$\mathbf B = \mathbf{E T}$ But then $\mathbf B$ is a [[Definition:WFF of Propositional Logic|WFF]] of [[Definition:Length of String|length]] $k$ which has $\mathbf E$ as an [[Definition:Initial Part|initial part]] which is itself a [[Definition:WFF of Propositional Logic|WFF]]. This contradicts the [[Initial Part of WFF of PropLog is not WFF#Induction Hypothesis|induction hypothesis]]. Therefore no [[Definition:Initial Part|initial part]] of $\mathbf A = \neg \mathbf B$ can be a [[Definition:WFF of Propositional Logic|WFF]]. {{qed|lemma}} $(2): \quad \mathbf A = \left({\mathbf B \circ \mathbf C}\right)$ where $\circ$ is one of the [[Definition:Binary Logical Connective|binary connectives]]. In this case, $\mathbf D$ is a [[Definition:WFF of Propositional Logic|WFF]] starting with $($, so: :$\mathbf D = \left({\mathbf E * \mathbf F}\right)$ for some [[Definition:Binary Logical Connective|binary connectives]] $*$ and some [[Definition:WFF of Propositional Logic|WFF]]s $\mathbf E$ and $\mathbf F$. Thus: :$\mathbf B \circ \mathbf C) = \mathbf E * \mathbf F) \mathbf T$. Both $\mathbf B$ and $\mathbf E$ are [[Definition:WFF of Propositional Logic|WFF]]s of [[Definition:Length of String|length]] less than $k + 1$. Therefore, by the [[Initial Part of WFF of PropLog is not WFF#Induction Hypothesis|induction hypothesis]], neither $\mathbf B$ nor $\mathbf E$ can be an [[Definition:Initial Part|initial part]] of the other. But since both $\mathbf B$ and $\mathbf E$ start at the same place in $\mathbf A$, they must be the same: :$\mathbf B = \mathbf E$ Therefore: :$\mathbf B \circ \mathbf C) = \mathbf B * \mathbf F) \mathbf T$ So $\circ = *$ and: :$\mathbf C) = \mathbf F) \mathbf T$ But then the [[Definition:WFF of Propositional Logic|WFF]] $\mathbf F$ is an [[Definition:Initial Part|initial part]] of the [[Definition:WFF of Propositional Logic|WFF]] $\mathbf C$ of [[Definition:Length of String|length]] less than $k + 1$. This contradicts our [[Initial Part of WFF of PropLog is not WFF#Induction Hypothesis|induction hypothesis]]. Therefore no [[Definition:Initial Part|initial part]] of $\mathbf A = \left({\mathbf B \circ \mathbf C}\right)$ can be a [[Definition:WFF of Propositional Logic|WFF]]. {{qed|lemma}} As $\mathbf A$ is arbitrary, it follows that no [[Definition:Initial Part|initial part]] of any [[Definition:WFF of Propositional Logic|WFF]] of [[Definition:Length of String|length]] $k + 1$ can be a [[Definition:WFF of Propositional Logic|WFF]]. So $P \left({k}\right) \implies P \left({k+1}\right)$ and the result follows by [[Second Principle of Mathematical Induction|strong induction]]. Therefore, for all $n \in \N_{> 0}$, the [[Definition:Initial Part|initial part]] of $\mathbf A$ such that $l \left({\mathbf A}\right) = n$ is not a [[Definition:WFF of Propositional Logic|WFF of propositional logic]]. Hence the result. {{qed}}	1
Let $v$ be an arbitrary [[Definition:Boolean Interpretation|interpretation]]. Then by definition of [[Definition:Interderivable|interderivable]]: :$\map v {p \iff q}$ {{iff}} $\map v p = \map v q$ Since $v$ is arbitrary, $\map v p = \map v q$ holds in all [[Definition:Boolean Interpretation|interpretations]]. That is: :$p \dashv \vdash q$ {{qed}}	1
{{BeginTableau|\vdash \left({\neg p \land \neg q}\right) \iff \left({\neg \left({p \lor q}\right)}\right)}} {{Assumption|1|\neg p \land \neg q}} {{SequentIntro|2|1|\neg \left({p \lor q}\right)|1|[[De Morgan's Laws (Logic)/Disjunction of Negations/Formulation 1/Forward Implication|De Morgan's Laws (Logic): Disjunction of Negations: Formulation 1]]}} {{Implication|3||\left({\neg p \land \neg q}\right) \implies \left({\neg \left({p \lor q}\right)}\right)|1|2}} {{Assumption|4|\neg \left({p \lor q}\right)}} {{SequentIntro|5|4|\neg p \land \neg q|4|[[De Morgan's Laws (Logic)/Disjunction of Negations/Formulation 1/Reverse Implication|De Morgan's Laws (Logic): Disjunction of Negations: Formulation 1]]}} {{Implication|6||\left({\neg \left({p \lor q}\right)}\right) \implies \left({\neg p \land \neg q}\right)|4|5}} {{BiconditionalIntro|7||\left({\neg p \land \neg q}\right) \iff \left({\neg \left({p \lor q}\right)}\right)|3|6}} {{EndTableau}} {{qed}}	1
Let $S$ be a [[Definition:Set|set]] of [[Definition:Literal|literals]]. Then $S$ is [[Definition:Satisfiable (Boolean Interpretations)|satisfiable]] {{iff}} it contains no [[Definition:Complementary Pair|complementary pairs]].	1
{{BeginTableau|p \implies \left({q \land r}\right) \vdash \left({p \implies q}\right) \land \left({p \implies r}\right)}} {{Premise|1|p \implies \left({q \land r}\right)}} {{Assumption|2|p}} {{ModusPonens|3|1, 2|q \land r|1|2}} {{Simplification|4|1, 2|q|3|1}} {{Simplification|5|1, 2|r|3|2}} {{Implication|6|1|p \implies q|2|4}} {{Implication|7|1|p \implies r|2|5}} {{Conjunction|8|1|\left({p \implies q}\right) \land \left({p \implies r}\right)|6|7}} {{EndTableau}} {{qed}}	1
This is simply the [[Definition:Contrapositive Statement|contrapositive]] of [[Gödel's First Incompleteness Theorem]]. {{qed}} {{Namedfor|Kurt Friedrich Gödel}}	1
:$p \implies q, r \implies s \vdash \neg q \lor \neg s \implies \neg p \lor \neg r$	1
:$\vdash \paren {p \land \neg q} \implies \paren {\neg \paren {p \implies q} }$	1
:$p \implies q \dashv \vdash \neg q \implies \neg p$	1
Let $S \subseteq \N$ be [[Definition:Primitive Recursive Set|primitive recursive]]. Then its [[Definition:Relative Complement|relative complement]] $\N \setminus S$ of $S$ in $\N$ is [[Definition:Primitive Recursive Set|primitive recursive]].	1
Let $\phi$ be a [[Definition:Propositional Formula|propositional formula]] whose [[Definition:Simple Statement|atoms]] are $p_1, p_2, \ldots, p_n$. Let $l$ be the line number of any row in the [[Definition:Truth Table|truth table]] of $\phi$. For all $i: 1 \le i \ne n$, let $\hat {p_i}$ be defined as: : $\hat {p_i} = \begin{cases} p_i & : \text {the entry in line } l \text { of } p_i \text { is } T \\ \neg p_i & : \text {the entry in line } l \text { of } p_i \text { is } F \end{cases}$ Then: * $\hat {p_1}, \hat {p_2}, \ldots, \hat {p_n} \vdash \phi$ is provable if the entry for $\phi$ in line $l$ is $T$ * $\hat {p_1}, \hat {p_2}, \ldots, \hat {p_n} \vdash \neg \phi$ is provable if the entry for $\phi$ in line $l$ is $F$	1
Let us use the following abbreviations {{begin-eqn}} {{eqn | l = \phi | o = \text{ for } | r = p \implies q | c = }} {{eqn | l = \psi | o = \text{ for } | r = q \implies r | c = }} {{eqn | l = \chi | o = \text{ for } | r = p \implies r | c = }} {{end-eqn}} {{BeginTableau|\paren {\paren {p \implies q} \land \paren {q \implies r} } \implies \paren {p \implies r} }} {{Assumption|1|\phi \land \psi}} {{Simplification|2|1|\phi|1|1}} {{Simplification|3|1|\psi|1|2}} {{SequentIntro|4|1|\chi|2, 3|[[Hypothetical Syllogism/Formulation 1|Hypothetical Syllogism: Formulation 1]]}} {{Implication|5||\paren {\phi \land \psi} \implies \chi|1|4}} {{EndTableau}} Expanding the abbreviations leads us back to: :$\paren {\paren {p \implies q} \land \paren {q \implies r} } \implies \paren {p \implies r}$ {{qed}}	1
Let $f: \N \to \N$ and $g: \N \to \N$ be [[Definition:URM Computability|URM computable functions]] of one variable. Let $P$ be a [[Definition:URM Program|URM program]] which computes $f$. Let $Q$ be a [[Definition:URM Program|URM program]] which computes $g$. Let $s = \lambda \left({Q}\right)$ be the [[Definition:Unlimited Register Machine#Length of Program|number of basic instructions]] in $Q$. Let $u = \rho \left({Q}\right)$ be the [[Definition:Unlimited Register Machine#Number of Registers Used|number of registers used]] by $Q$. In order to compute $f \circ g$ the program must compute $g$ first (by running $Q$), then use the [[Definition:Unlimited Register Machine#Output|output]] of $Q$ as the [[Definition:Unlimited Register Machine#Input|input]] of $P$, which must then compute $f$. After $Q$ has computed the value of $g \left({n}\right)$, its output is to be found in $R_1$. Its [[Definition:Unlimited Register Machine#Instruction Pointer|instruction pointer]] is greater than $s$, and may at this point be [[Definition:Indeterminate Variable|indeterminate]]. Also, the contents of $R_2, R_3, \ldots, R_u$ are also [[Definition:Indeterminate Variable|indeterminate]]. So we need to do the following things: # The [[Definition:Unlimited Register Machine#Instruction Pointer|instruction pointer]] needs to be set to the line immediately after the end of $Q$, that is, to line $s+1$. # The registers used by $Q$, except $R_1$, the one holding the output of $Q$, must be set to $0$. So a [[Clear Registers Program]] $Z \left({2, u}\right)$ must be appended to the end of $Q$. # The program $P$ must be appended to the end of $Q$ with $Z \left({2, u}\right)$ appended. However, $P$ no longer starts at line $1$ but at line $\left({q + u - 1}\right)$, so any <tt>Jump</tt> instructions of the form $J \left({m, n, q}\right)$ in $P$ must have $q$ changed to $\left({q + u - 1}\right)$. When that has been achieved, the following happens: # The program runs $Q$, amended if necessary so that the [[Definition:Unlimited Register Machine#Instruction Pointer|instruction pointer]] ends up at $s+1$. # The contents of $R_2$ to $R_u$ are then set to zero. # $P$ is now run, with the [[Definition:Unlimited Register Machine#Output|output]] of $Q$ in its [[Definition:Unlimited Register Machine#Input|input]] $R_1$, and all the other registers set to zero. The [[Definition:Unlimited Register Machine#Output|output]] of $P$ can now be found in $R_1$. The resulting program $Q$ followed by $Z \left({2, u}\right)$ followed by $P$ is called: * the '''concatenation of $Q$ and $P$''', or, in general: * a '''concatenated''' program, and is denoted $Q * P$. Note that this is read: * Run $Q$ first; * Then run $P$. So it is read from '''left to right'''. In that sense the notation is different from that of $f \circ g$ for the [[Definition:Composite Function|composition]] of $f$ and $g$, which is read from '''right to left'''. So $f \circ g$ is [[Definition:URM Computability|computed]] by $Q * P$. {{qed}} Its length $\lambda \left({Q * P}\right)$ is given as: :$\left({Q * P}\right) = \lambda \left({Q}\right) + \left({u-1}\right) \lambda \left({P}\right)$. The $u-1$ comes from the length of the [[Clear Registers Program]]. Thus we have an [[Definition:Algorithm|algorithm]] for concatenating two [[Definition:URM Program|URM programs]], as follows:	1
Proceed by the [[Principle of Structural Induction]] applied to the [[Definition:Term (Predicate Logic)|definition of a term]]. If $\tau = x$, then: {{begin-eqn}} {{eqn|l = \mathop{ \operatorname{val}_{\mathcal A} \left({\tau}\right) } \left[{\sigma}\right] |r = \sigma \left({x}\right) |c = Definition of [[Definition:Value of Term under Assignment|value under $\sigma$]] }} {{eqn|r = \sigma' \left({x}\right) |c = Assumption on $\sigma, \sigma'$ }} {{eqn|r = \mathop{ \operatorname{val}_{\mathcal A} \left({\tau}\right) } \left[{\sigma'}\right] |c = Definition of [[Definition:Value of Term under Assignment|value under $\sigma$]] }} {{end-eqn}} as desired. If $\tau = f \left({\tau_1, \ldots, \tau_n}\right)$ and the induction hypothesis applies to each $\tau_i$, then: {{begin-eqn}} {{eqn|l = \mathop{ \operatorname{val}_{\mathcal A} \left({\tau}\right) } \left[{\sigma}\right] |r = f_{\mathcal A} \left({ \mathop{ \operatorname{val}_{\mathcal A} \left({\tau_1}\right) } \left[{\sigma}\right], \ldots, \mathop{ \operatorname{val}_{\mathcal A} \left({\tau_n}\right) } \left[{\sigma}\right] }\right) |c = Definition of [[Definition:Value of Term under Assignment|value under $\sigma$]] }} {{eqn|r = f_{\mathcal A} \left({ \mathop{ \operatorname{val}_{\mathcal A} \left({\tau_1}\right) } \left[{\sigma'}\right], \ldots, \mathop{ \operatorname{val}_{\mathcal A} \left({\tau_n}\right) } \left[{\sigma'}\right] }\right) |c = Induction Hypothesis }} {{eqn|r = \mathop{ \operatorname{val}_{\mathcal A} \left({\tau}\right) } \left[{\sigma'}\right] |c = Definition of [[Definition:Value of Term under Assignment|value under $\sigma'$]] }} {{end-eqn}} The result follows from the [[Principle of Structural Induction]]. {{qed}} [[Category:Predicate Logic]] 10ma1jy4vmkw964isbnsakdzd6mfpgc	1
{{BeginTableau|\vdash \left({\neg q \implies \neg p}\right) \implies \left({p \implies q}\right)}} {{Assumption|1|\neg q \implies \neg p}} {{Assumption|2|p}} {{DoubleNegIntro|3|2|\neg \neg p|2}} {{ModusTollens|4|1, 2|\neg \neg q|1|3}} {{DoubleNegElimination|5|1, 2|q|4}} {{Implication|6|1|p \implies q|2|5}} {{Implication|7||\left({\neg q \implies \neg p}\right) \implies \left({p \implies q}\right)|1|6}} {{EndTableau}} {{Qed}} {{LEM|Double Negation Elimination|4}}	1
The [[Definition:Boolean Satisfiability Problem|Boolean Satisfiability Problem]] is [[Definition:NP-Complete|NP-Complete]].	1
Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \N_{>0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\displaystyle n^2 = \sum_{j \mathop = 1}^n \paren {2 j - 1}$ === Basis for the Induction === $\map P 1$ is true, as this just says $1^2 = 1$. This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\displaystyle k^2 = \sum_{j \mathop = 1}^k \paren {2 j - 1}$ Then we need to show: :$\displaystyle \paren {k + 1}^2 = \sum_{j \mathop = 1}^{k + 1} \paren {2 j - 1}$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \paren {k + 1}^2 | r = k^2 + 2 k + 1 | c = }} {{eqn | r = \sum_{j \mathop = 1}^k \paren {2 j - 1} + 2 k + 1 | c = [[Odd Number Theorem#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \sum_{j \mathop = 1}^k \paren {2 j - 1} + 2 \paren {k + 1} - 1 | c = }} {{eqn | r = \sum_{j \mathop = 1}^{k + 1} \paren {2 j - 1} | c = }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\displaystyle \forall n \in \N: n^2 = \sum_{j \mathop = 1}^n \paren {2 j - 1}$ {{qed}}	1
:$\neg \paren {p \iff q} \dashv \vdash \paren {p \iff \neg q}$	1
There are two cases: :$(1): \quad$ Everyone in the pub is drinking. :$(2): \quad$ Someone in the pub is not drinking. Suppose first that everyone in the pub is drinking. Then $x$ can be chosen to be any person in the pub. Suppose instead that someone in the pub is not drinking. Then $x$ can be chosen to be any person in the pub who is not drinking. {{qed}} {{Namedfor|Raymond Merrill Smullyan|cat = Smullyan}} [[Category:Paradoxes]] [[Category:Logic]] hv93wwf21gkw1kb9kszxod78i3sag3o	1
This follows immediately from: * The fact that the [[Single Instruction URM Programs#Basic Primitive Recursive Functions |basic primitive recursive functions are URM computable]]; * [[Function Obtained by Substitution from URM Computable Functions|Functions obtained by substitution from URM computable functions are URM computable]]; * [[Function Obtained by Primitive Recursion from URM Computable Functions|Functions obtained by primitive recursion from URM computable functions are URM computable]]; * The definition of [[Definition:Primitive Recursive Function|primitive recursive function]]. {{qed}}	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, in each case, the [[Definition:Truth Value|truth values]] in the appropriate columns match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c|ccc||c|} \hline p & p & \land & \top & \top \\ \hline F & F & F & T & T \\ T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
{{BeginTableau|\vdash q \implies \paren {p \implies q} }} {{Assumption|1|q}} {{SequentIntro|2|1|p \implies q|1|[[True Statement is implied by Every Statement/Formulation 1|True Statement is implied by Every Statement: Formulation 1]]}} {{Implication|3||q \implies \paren {p \implies q}|1|2}} {{EndTableau}} {{qed}}	1
Consider the [[Definition:Categorical Statement|categorical statements]]: :$\map {\mathbf A} {S, P}: \quad$ The [[Definition:Universal Affirmative|universal affirmative]]: $\forall x: \map S x \implies \map P x$ :$\map {\mathbf I} {S, P}: \quad$ The [[Definition:Particular Affirmative|particular affirmative]]: $\exists x: \map S x \land \map P x$ Then: :$\map {\mathbf A} {S, P} \implies \map {\mathbf I} {S, P}$ {{iff}}: :$\exists x: \map S x$ Using the [[Definition:Symbolic Logic|symbology]] of [[Definition:Predicate Logic|predicate logic:]] :$\exists x: \map S x \iff \paren {\paren {\forall x: \map S x \implies \map P x} \implies \paren {\exists x: \map S x \land \map P x} }$	1
The [[Rule of Commutation/Disjunction/Formulation 2/Forward Implication|Rule of Commutation]]: :$\left({p \lor q}\right) \implies \left({q \lor p}\right)$ is a [[Definition:Tautology (Formal Semantics)|tautology]] in [[Definition:Constructed Semantics/Instance 2|Instance 2]] of [[Definition:Constructed Semantics|constructed semantics]].	1
Let $C$ be a [[Definition:Linear Code|linear $\tuple {n, k}$-code]] whose [[Definition:Master Code|master code]] is $\map V {n, p}$ To decode a given [[Definition:Vector (Linear Algebra)|vector]] $v$ of $\map V {n, p}$, the [[Definition:Syndrome|syndrome]] of $v$ can be used as follows. Create an [[Definition:Array|array]] $T$ of $2$ [[Definition:Column of Array|column]] consisting of the following: :The top [[Definition:Row of Array|row]] contains: ::in [[Definition:Column of Array|column]] $1$: the [[Definition:Zero Codeword|zero]] of $C$ ::in [[Definition:Column of Array|column]] $2$: its [[Definition:Syndrome|syndrome]]. :The $r$th [[Definition:Row of Array|row]] subsequent contains: ::in [[Definition:Column of Array|column]] $1$: any [[Definition:Element|element]] of $\map V {n, p}$ of minimum [[Definition:Weight of Linear Codeword|weight]] which is not already included in the first $r - 1$ [[Definition:Row of Array|rows]] ::in [[Definition:Column of Array|column]] $2$: its [[Definition:Syndrome|syndrome]]. To decode a given [[Definition:Vector (Linear Algebra)|vector]] $v$ of $\map V {n, p}$: :Calculate its [[Definition:Syndrome|syndrome]] :Find it in [[Definition:Column of Array|column]] $2$ of $T$ :See what is in [[Definition:Column of Array|column]] $1$ of $T$, and call it $u$, say :Subtract $u$ from $v$.	1
{{BeginTableau|\vdash \neg p \implies \left({p \implies q}\right)}} {{Assumption|1|\neg p}} {{Assumption|2|p}} {{NonContradiction|3|1, 2|2|1}} {{Explosion|4|1, 2|q|3}} {{Implication|5|1|p \implies q|2|4}} {{Implication|6||\neg p \implies \left({p \implies q}\right)|1|5}} {{EndTableau}} {{qed}}	1
{{begin-eqn}} {{eqn | l = p \land q | o = \dashv \vdash | r = \neg \neg \paren {p \land q} | c = [[Double Negation]] }} {{eqn | o = \dashv \vdash | r = \neg \paren {p \uparrow q} | c = {{Defof|Logical NAND}} }} {{eqn | o = \dashv \vdash | r = \paren {p \uparrow q} \uparrow \paren {p \uparrow q} | c = [[NAND with Equal Arguments]] }} {{end-eqn}} {{qed}}	1
[[Definition:Tableau Proof (Propositional Tableaus)|Tableau proofs]] (in terms of [[Definition:Propositional Tableau|propositional tableaus]]) are a [[Definition:Sound Proof System|sound proof system]] for [[Definition:Boolean Interpretation|boolean interpretations]]. That is, for every [[Definition:WFF of Propositional Logic|WFF]] $\mathbf A$: :$\vdash_{\mathrm{PT}} \mathbf A$ implies $\models_{\mathrm{BI}} \mathbf A$	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc||ccc|} \hline p & \oplus & q & q & \oplus & p \\ \hline F & F & F & F & F & F \\ F & T & T & T & T & F \\ T & T & F & F & T & T \\ T & F & T & T & F & T \\ \hline \end{array}$ {{qed}}	1
=== [[Rule of Simplification/Sequent Form/Formulation 2/Proof 1/Form 1|Form 1]] === {{:Rule of Simplification/Sequent Form/Formulation 2/Proof 1/Form 1}} === [[Rule of Simplification/Sequent Form/Formulation 2/Proof 1/Form 2|Form 2]] === {{:Rule of Simplification/Sequent Form/Formulation 2/Proof 1/Form 2}}	1
A '''proposition''' is a [[Definition:Statement|statement]] which is offered up for investigation as to its [[Definition:True|truth]] or [[Definition:False|falsehood]]. Loosely, a '''proposition''' is a [[Definition:Statement|statement]] which is about to be [[Definition:Proof|proved]] (or disproved).	1
{{begin-eqn}} {{eqn | o = | r = \mathbf E | c = }} {{eqn | ll= \therefore | l = \forall x: | o = | r = \map S x \implies \neg \map P x | c = Definition of $\mathbf E$ }} {{eqn | ll= \therefore | l = \forall x: | o = | r = \neg \paren {\map S x \land \map P x} | c = [[Modus Ponendo Tollens/Variant|Modus Ponendo Tollens]] }} {{eqn | ll= \therefore | l = \neg \exists x: | o = | r = \map S x \land \map P x | c = [[De Morgan's Laws (Predicate Logic)/Denial of Existence|De Morgan's Laws: Denial of Existence]] }} {{eqn | ll= \therefore | o = | r = \neg \mathbf I | c = Definition of $\mathbf I$ }} {{end-eqn}} The argument reverses: {{begin-eqn}} {{eqn | o = | r = \mathbf I | c = }} {{eqn | ll= \therefore | l = \exists x: | o = | r = \map S x \land \map P x | c = Definition of $\mathbf I$ }} {{eqn | ll= \therefore | l = \exists x: | o = | r = \neg \paren {\map S x \implies \neg \map P x} | c = [[Conjunction Equivalent to Negation of Implication of Negative]] }} {{eqn | ll= \therefore | l = \neg \forall x: | o = | r = \map S x \implies \neg \map P x | c = [[De Morgan's Laws (Predicate Logic)/Denial of Universality|De Morgan's Laws: Denial of Universality]] }} {{eqn | ll= \therefore | o = | r = \neg \mathbf E | c = Definition of $\mathbf E$ }} {{end-eqn}} The result follows by definition of [[Definition:Contradictory Statements|contradictory]]. {{qed}}	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|cccc||cccccccc|} \hline \neg & (p & \iff & q) & (p & \lor & q) & \land & \neg & (p & \land & q) \\ \hline F & F & T & F & F & F & F & F & T & F & F & F \\ T & F & F & T & F & T & T & T & T & F & F & T \\ T & T & F & F & T & T & F & T & T & T & F & F \\ F & T & T & T & T & T & T & F & F & T & T & T \\ \hline \end{array}$ {{qed}}	1
:$p \iff q \dashv \vdash \paren {p \implies q} \land \paren {q \implies p}$	1
{{BeginTableau|\vdash \paren {p \implies q} \land \paren {\neg p \implies q} \implies q}} {{Assumption|1|\paren {p \implies q} \land \paren {\neg p \implies q} }} {{SequentIntro|2|1|q|1|[[Principle of Dilemma/Formulation 1/Forward Implication|Principle of Dilemma: Formulation 1]]}} {{Implication|3||\paren {p \implies q} \land \paren {\neg p \implies q} \implies q|1|2}} {{EndTableau|qed}}	1
:$\vdash \paren {p \implies \paren {q \implies r} } \iff \paren {\paren {p \implies q} \implies \paren {p \implies r} }$	1
:$\forall n \ge 1: \displaystyle \sum_{j \mathop = 1}^n {F_j}^2 = F_n F_{n + 1}$ That is: :${F_1}^2 + {F_2}^2 + {F_3}^2 + \cdots + {F_n}^2 = F_n F_{n + 1}$	1
{{BeginTableau|p \iff q \vdash p \implies q}} {{Premise|1|p \iff q}} {{BiconditionalElimination|2|1|p \implies q|1|1}} {{EndTableau}} {{Qed}}	1
: $\left({p \land q}\right) \lor \left({r \land s}\right) \vdash p \lor r$	1
Recall the four [[Definition:Figure of Categorical Syllogism|figures]] of the [[Definition:Categorical Syllogism|categorical syllogism]]: :$\begin{array}{r|rl} \text I & & \\ \hline \\ \text{Major Premise}: & \mathbf \Phi_1 & \tuple {M, P} \\ \text{Minor Premise}: & \mathbf \Phi_2 & \tuple {S, M} \\ \hline \\ \text{Conclusion}: & \mathbf \Phi_3 & \tuple {S, P} \\ \end{array} \qquad \begin{array}{r|rl} \text {II} & & \\ \hline \\ \text{Major Premise}: & \mathbf \Phi_1 & \tuple {P, M} \\ \text{Minor Premise}: & \mathbf \Phi_2 & \tuple {S, M} \\ \hline \\ \text{Conclusion}: & \mathbf \Phi_3 & \tuple {S, P} \\ \end{array}$ :$\begin{array}{r|rl} \text {III} & & \\ \hline \\ \text{Major Premise}: & \mathbf \Phi_1 & \tuple {M, P} \\ \text{Minor Premise}: & \mathbf \Phi_2 & \tuple {M, S} \\ \hline \\ \text{Conclusion}: & \mathbf \Phi_3 & \tuple {S, P} \\ \end{array} \qquad \begin{array}{r|rl} \text {IV} & & \\ \hline \\ \text{Major Premise}: & \mathbf \Phi_1 & \tuple {P, M} \\ \text{Minor Premise}: & \mathbf \Phi_2 & \tuple {M, S} \\ \hline \\ \text{Conclusion}: & \mathbf \Phi_3 & \tuple {S, P} \\ \end{array}$ By the definition of a [[Definition:Categorical Syllogism|categorical syllogism]], the following are fixed: :$(1): \quad$ The order of the [[Definition:Categorical Statement|categorical statements]]: [[Definition:Major Premise of Syllogism|major premise]], then [[Definition:Minor Premise of Syllogism|minor premise]], then [[Definition:Conclusion of Syllogism|conclusion]]. :$(2): \quad$ The structure of the [[Definition:Conclusion of Syllogism|conclusion]]: the [[Definition:Secondary Term of Syllogism|secondary term]] then the [[Definition:Primary Term of Syllogism|primary term]]. :$(3): \quad$ The content of the two [[Definition:Premise|premises]]: the [[Definition:Major Premise of Syllogism|major premise]] contains the [[Definition:Primary Term of Syllogism|primary term]] and the [[Definition:Middle Term of Syllogism|middle term]], while the [[Definition:Minor Premise of Syllogism|minor premise]] contains the [[Definition:Middle Term of Syllogism|middle term]] and the [[Definition:Secondary Term of Syllogism|secondary term]]. The things that can be varied are: :$(A): \quad$ The specific nature of each of the [[Definition:Categorical Statement|categorical statements]]: each can be any of four types: $\mathbf A$, $\mathbf E$, $\mathbf I$ or $\mathbf O$. :$(B): \quad$ Within the [[Definition:Major Premise of Syllogism|major]] and [[Definition:Minor Premise of Syllogism|minor premises]], the order of the two [[Definition:Term of Syllogism|terms]]: the [[Definition:Middle Term of Syllogism|middle term]] can come either first or second. The order of the [[Definition:Term of Syllogism|terms]] within the [[Definition:Premise of Syllogism|premises]] determines the [[Definition:Figure of Categorical Syllogism|figure]] of the [[Definition:Categorical Syllogism|categorical syllogism]]. For each of the two [[Definition:Premise of Syllogism|premises]] there are two options for the position of the [[Definition:Middle Term of Syllogism|middle term]]. By the [[Product Rule for Counting]] it follows that there are $2 \times 2 = 4$ [[Definition:Figure of Categorical Syllogism|figures]]. In each [[Definition:Figure of Categorical Syllogism|figure]], there are $3$ [[Definition:Categorical Statement|categorical statements]]. Each can be of any of $4$ types. Hence by the [[Product Rule for Counting]], there are $4 \times 4 \times 4 = 64$ possible [[Definition:Standard Instance of Categorical Syllogism|standard instances]] for each [[Definition:Figure of Categorical Syllogism|figure]]. For all $4$ [[Definition:Figure of Categorical Syllogism|figures]], by the [[Product Rule for Counting]], it follows that there are $4 \times 64 = 256$ [[Definition:Standard Instance of Categorical Syllogism|standard instances]] in total. {{qed}}	1
:$(1): \quad \vdash p \land q \implies p$ :$(2): \quad \vdash p \land q \implies q$	1
The [[Definition:Logical NAND|NAND]] and [[Definition:Logical NOR|NOR]] operators are each [[Definition:Functionally Complete|functionally complete]]. That is, [[Definition:Logical NAND|NAND]] and [[Definition:Logical NOR|NOR]] are [[Definition:Sheffer Operator|Sheffer operators]].	1
This is a corollary of the [[Extended Soundness Theorem for Propositional Tableaus and Boolean Interpretations]]: Let $\mathbf H$ be a [[Definition:Countable|countable]] set of [[Definition:Propositional Formula|propositional formulas]]. Let $\mathbf A$ be a [[Definition:Propositional Formula|propositional formula]]. If $\mathbf H \vdash \mathbf A$, then $\mathbf H \models \mathbf A$. In this case, we have $\mathbf H = \varnothing$. Hence the result. {{qed}}	1
Let $v$ be an arbitrary [[Definition:Boolean Interpretation|interpretation]]. Then by definition of [[Definition:Interderivable|interderivable]]: :$\map v {p \iff q}$ {{iff}} $\map v p = \map v q$ Since $v$ is arbitrary, $\map v p = \map v q$ holds in all [[Definition:Boolean Interpretation|interpretations]]. That is: :$p \dashv \vdash q$ {{qed}}	1
We see that: :$\max \left({n, m}\right) = \left({n \ \dot - \ m}\right) + m$ because: :$(1):\quad n > m \implies \left({n \ \dot - \ m}\right) + m = n - m + m = n$ :$(2):\quad n < m \implies \left({n \ \dot - \ m}\right) + m = 0 + m = m$ :$(3):\quad n = m \implies \left({n \ \dot - \ m}\right) + m = 0 + m = m = n$ Hence we see that $\max$ is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from the [[Cut-Off Subtraction is Primitive Recursive|primitive recursive function $n \ \dot - \ m$]]. Hence the result. {{qed}} [[Category:Primitive Recursive Functions]] j6mmj7vimyzj9hlemx08lzwqrqsvlsh	1
{{BeginTableau |\vdash \paren {\paren {p \lor r} \land \paren {p \implies q} \land \paren {r \implies s} } \implies \paren {q \lor s} }} {{Assumption |1|\paren {\paren {p \lor r} \land \paren {p \implies q} \land \paren {r \implies s} } }} {{Simplification|2|1|\paren {p \implies q} \land \paren {r \implies s}|1|2|Cutting corners: should use Associativity first}} {{SequentIntro |3|1|\paren {p \lor r} \implies \paren {q \lor s}|2|[[Constructive Dilemma/Formulation 1|Constructive Dilemma: Formulation 1]]}} {{Simplification|4|1|p \lor r|1|1}} {{ModusPonens |5|1|q \lor s|3|4}} {{Implication |6| |\paren {\paren {p \lor r} \land \paren {p \implies q} \land \paren {r \implies s} } \implies \paren {q \lor s}|1|5}} {{EndTableau}} {{qed}}	1
Let $\mathbf A$ be a [[Definition:WFF of Predicate Logic|WFF of predicate logic]]. Let $x \in \mathrm{VAR}$ be a [[Definition:Variable (Logic)|variable]]. Let $\tau$ be a [[Definition:Term (Predicate Logic)|term of predicate logic]] which is [[Definition:Freely Substitutable|freely substitutable]] for $x$ in $\mathbf A$. Let $\mathbf A \left({x \gets \tau}\right)$ be the [[Definition:Substitution Instance of Well-Formed Formula|substitution instance of $\mathbf A$ substituting $\tau$ for $x$]]. Let $\mathcal A$ be a [[Definition:Structure for Predicate Logic|structure for predicate logic]]. Let $\sigma$ be an [[Definition:Assignment for Structure|assignment]] for $\mathbf A$ and $\tau$. Suppose that: :$\mathop{ \operatorname{val}_{\mathcal A} \left({\tau}\right) } \left[{\sigma}\right] = a$ where $\mathop{ \operatorname{val}_{\mathcal A} \left({\tau}\right) } \left[{\sigma}\right]$ is the [[Definition:Value of Term under Assignment|value of $\tau$ under $\sigma$]]. Then: :$\mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A \left({x \gets \tau}\right) }\right) } \left[{\sigma}\right] = \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\sigma + \left({x / a}\right)}\right]$ where $\sigma + \left({x / a}\right)$ is the [[Definition:Extension of Assignment|extension of $\sigma$ by mapping $x$ to $a$]].	1
Let the [[Definition:Function|function]] $p: \N \to \N$ be the [[Definition:Prime Enumeration Function|prime enumeration function]], defined as: :$p \left({n}\right) = \begin{cases} 1 & : n = 0 \\ \mbox{the } n \mbox{th prime number} & : n > 0 \end{cases}$ Then $p$ is [[Definition:Primitive Recursive Function|primitive recursive]].	1
Every [[Definition:Recursive Function|recursive function]] is [[Definition:URM Computability|URM computable]].	1
Let $\mathcal A$ be a [[Definition:Structure for Predicate Logic|structure for predicate logic]]. Let $\mathbf B$ be any [[Definition:Universal Closure of Well-Formed Formula|universal closure]] of $\mathbf A$. Then $\mathbf B$ is a [[Definition:Sentence|sentence]] of the form: :$\forall x_1: \cdots \forall x_n: \mathbf A$ By definition of the [[Definition:Model of Sentence (Predicate Logic)|models relation]]: :$\mathcal A \models_{\mathrm{PL}} \mathbf B$ [[Definition:Iff|iff]] $\operatorname{val}_{\mathcal A} \left({\mathbf B}\right) = T$ Hence, recursively applying the [[Definition:Value of Formula under Assignment|definition of $\mathop{ \operatorname{val}_{\mathcal A} \left({\cdot}\right) } \left[{\sigma}\right]$]], we see: :$\mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf B}\right) } \left[{\varnothing}\right] = T$ [[Definition:Iff|iff]] $\forall a_1, \ldots, a_n \in A: \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\frac{x_1} {a_1} + \ldots + \frac{x_n} {a_n} }\right] = T$ where $\frac{x_1} {a_1} + \ldots + \frac{x_n} {a_n}$ denotes the iterated [[Definition:Extension of Assignment|extension of an assignment]]. By [[Value of Formula under Assignment Determined by Free Variables]] $\mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\frac{x_1} {a_1} + \ldots + \frac{x_n} {a_n} }\right]$ only depends on the $a_i$ for the [[Definition:Free Variable|free variables]] $x_i$ in $\mathbf A$. Because we check all possible $a_i \in A$ and all [[Definition:Free Variable|free variables]] $x_i$ in $\mathbf A$ are quantified over in $\mathbf B$, it follows that: :$\forall a_1, \ldots, a_n \in A: \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\frac{x_1} {a_1} + \ldots + \frac{x_n} {a_n} }\right] = T$ [[Definition:Iff|iff]]: :$\forall a_1, \ldots, a_k \in A: \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\frac{x_1} {a_1} + \ldots + \frac{x_k} {a_k} }\right] = T$ where $x_1, \ldots, x_k$ are the [[Definition:Free Variable|free variables]] of $\mathbf A$. But this last condition does not depend on $\mathbf B$ beyond that it be a [[Definition:Universal Closure of Well-Formed Formula|universal closure]]. Hence, for any two [[Definition:Universal Closure of Well-Formed Formula|universal closures]] $\mathbf B, \mathbf B'$ of $\mathbf A$: :$\mathcal A \models_{\mathrm{PL}} \mathbf B$ [[Definition:Iff|iff]] $\mathcal A \models_{\mathrm{PL}} \mathbf B$ The result follows by definition of [[Definition:Semantic Equivalence (Predicate Logic)|semantic equivalence]]. {{qed}}	1
The [[Definition:Factorial|factorial function]] $\operatorname{fac}: \N \to \N$ defined as: :$\operatorname{fac} \left({n}\right) = n!$ is [[Definition:Primitive Recursive Function|primitive recursive]].	1
{{BeginTableau|\vdash \paren {\paren {p \implies q} \implies p} \implies p}} {{Assumption|1|\paren {p \implies q} \implies p}} {{SequentIntro|2|1|p|1|[[Peirce's Law/Formulation 1|Peirce's Law: Formulation 1]]: $\paren {p \implies q} \implies p \vdash p$}} {{Implication|3||\paren {\paren {p \implies q} \implies p} \implies p|1|2}} {{EndTableau}} {{qed}}	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|cccc||cccccccc|} \hline \neg & (p & \iff & q) & (p & \lor & q) & \land & \neg & (p & \land & q) \\ \hline F & F & T & F & F & F & F & F & T & F & F & F \\ T & F & F & T & F & T & T & T & T & F & F & T \\ T & T & F & F & T & T & F & T & T & T & F & F \\ F & T & T & T & T & T & T & F & F & T & T & T \\ \hline \end{array}$ {{qed}}	1
:$\neg p \lor q \vdash p \implies q$	1
{{BeginTableau|\neg \left({p \land \neg q}\right) \vdash p \implies q}} {{Premise|1|\neg \left({p \land \neg q}\right)}} {{DeMorgan|2|1|\neg p \lor \neg \neg q|1|Disjunction of Negations}} {{SequentIntro|3|1|p \implies \neg \neg q|2|[[Rule of Material Implication]]}} {{Assumption|4|p}} {{ModusPonens|5|1, 4|\neg \neg q|3|4}} {{DoubleNegElimination|6|1, 4|q|5}} {{Implication|7|1|p \implies q|4|6}} {{EndTableau}} {{qed}} {{LEM|Double Negation Elimination}}	1
The [[Definition:Unlimited Register Machine#Null Program|null URM program]] computes the '''[[Definition:Identity Mapping|identity function]]''' $I_\N: \N \to \N$, defined as: :$\forall n \in \N: \map {I_\N} n = n$	1
:$p \vdash p$	1
The [[Definition:Game|game]] of [[Definition:Card Game with Bluffing|cards with bluffing]] is a [[Definition:Completely Mixed Game|completely mixed game]].	1
The [[Semantic Tableau Algorithm]] is a [[Definition:Decision Procedure for Tautologies|decision procedure for tautologies]].	1
Let $\struct {R, +, \circ, \le}$ be an [[Definition:Ordered Ring|ordered ring]]. Let $x, y \in R$. Let $n \in \N_{>0}$ be a [[Definition:Strictly Positive Integer|strictly positive integer]]. Let $0 < x < y$. Then: :$0 < \map {\circ^n} x < \map {\circ^n} y$	1
This follows immediately from: * a relation is [[Definition:Primitive Recursive Relation|primitive recursive]] if its [[Definition:Characteristic Function of Relation|characteristic function]] is a [[Definition:Primitive Recursive Function|primitive recursive]] * the fact that every [[Primitive Recursive Function is URM Computable]]. {{qed}}	1
Let $\N$ be the [[Definition:Natural Numbers|0-based natural numbers]]: :$\N = \left\{{0, 1, 2, \ldots}\right\}$ Let $s: \N \to \N: \map s n = n + 1$ be the [[Definition:Successor Function|successor function]]. Then: :$\forall n \in \N \setminus \set 0 \paren {\exists m \in \N: \map s m = n }$	1
:$p \land \left({p \lor q}\right) \vdash p$	1
Let $P \left({x}\right)$ denote a [[Definition:Well-Formed Formula|Well-Formed Formula]] which contains $x$ as a [[Definition:Free Variable|free variable]]. Then the following are [[Definition:Tautology|tautologies]]: :$\forall x: \left({P \left({ x }\right) \iff \exists y: \left({y = x \land P \left({y}\right)}\right)}\right)$ :$\forall x: \left({P \left({ x }\right) \iff \forall y: \left({y = x \implies P \left({y}\right)}\right)}\right)$ Note that when $y$ is substituted for $x$ in either formula, it is false in general; compare [[Confusion of Bound Variables]].	1
Since the [[Union of Primitive Recursive Sets]] is itself [[Definition:Primitive Recursive Set|primitive recursive]], all we need to do is show that each of $\operatorname{Zinstr}$, $\operatorname{Sinstr}$, $\operatorname{Cinstr}$ and $\operatorname{Jinstr}$ are [[Definition:Primitive Recursive Set|primitive recursive]]. First we consider $\operatorname{Zinstr}$. :$\operatorname{Zinstr} = \left\{{\beta \left({Z \left({n}\right)}\right): n \in \N^*}\right\} = \left\{{6 n - 3: n \in \N^*}\right\}$. So $\operatorname{Zinstr}$ is the set of [[Definition:Natural Numbers|natural numbers]] which are [[Definition:Divisor of Integer|divisible]] by $3$ but not $6$. Thus its [[Definition:Characteristic Function of Set|characteristic function]] is given by: :$\chi_{\operatorname{Zinstr}} \left({k}\right) = \operatorname{div} \left({k, 3}\right) \times \overline{\operatorname{sgn}}\left({\operatorname{div} \left({k, 6}\right)}\right)$ where: : [[Divisor Relation is Primitive Recursive|$\operatorname{div}$ is primitive recursive]] : [[Signum Function is Primitive Recursive|$\overline{\operatorname{sgn}}$ is primitive recursive]] : [[Multiplication is Primitive Recursive]] : [[Constant Function is Primitive Recursive|$3$ and $6$ are constants]] Hence $\operatorname{Zinstr}$ is [[Definition:Primitive Recursive Set|primitive recursive]]. Next we consider $\operatorname{Sinstr}$. :$\operatorname{Sinstr} = \left\{{\beta \left({S \left({n}\right)}\right): n \in \N^*}\right\} = \left\{{6 n: n \in \N^*}\right\}$. So $\operatorname{Sinstr}$ is the set of [[Definition:Natural Numbers|natural numbers]] which are [[Definition:Divisor of Integer|divisible]] by $6$. Thus its [[Definition:Characteristic Function of Set|characteristic function]] is given by: :$\chi_{\operatorname{Sinstr}} \left({k}\right) = \operatorname{sgn} \left({k}\right) \times \operatorname{div} \left({k, 6}\right)$ where: : [[Divisor Relation is Primitive Recursive|$\operatorname{div}$ is primitive recursive]] : [[Signum Function is Primitive Recursive|$\operatorname{sgn}$ is primitive recursive]] : [[Multiplication is Primitive Recursive]] : [[Constant Function is Primitive Recursive|$6$ is constant]] Hence $\operatorname{Sinstr}$ is [[Definition:Primitive Recursive Set|primitive recursive]]. Next we consider $\operatorname{Cinstr}$. We have that $\beta \left({C \left({n, m}\right)}\right) = 2^m 3^n + 1$. Hence $k \in \operatorname{Cinstr}$ iff $k \equiv 1 \pmod 3$ and $k - 1$ [[Definition:Sequence Coding|codes]] a pair of [[Definition:Positive Integer|positive integers]]. That is: {{begin-eqn}} {{eqn | l = k \in \operatorname{Cinstr} | o = \iff | r = \operatorname{rem} \left({k, 3}\right) = 1 | c = }} {{eqn | o = \land | r = \chi_{\operatorname{Seq} } \left({k \, \dot - \, 1}\right) = 1 | c = }} {{eqn | o = \land | r = \operatorname{len} \left({k \, \dot - \, 1}\right) = 2 | c = }} {{end-eqn}} We can introduce two properties: : $P \left({k}\right) \iff \operatorname{eq} \left({\operatorname{rem} \left({k, 3}\right), 1}\right)$ : $Q \left({k}\right) \iff \operatorname{eq} \left({\operatorname{len} \left({k \, \dot - \, 1}\right), 2}\right)$ $\chi_{P}$ is [[Definition:Primitive Recursive Function|primitive recursive]] since it is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from: : [[Equality Relation is Primitive Recursive|$\operatorname{eq}$ is primitive recursive]] : [[Remainder is Primitive Recursive|$\operatorname{rem}$ is primitive recursive]] : [[Constant Function is Primitive Recursive|$3$ and $1$ are constants]] $\chi_{Q}$ is [[Definition:Primitive Recursive Function|primitive recursive]] since it is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from: : [[Equality Relation is Primitive Recursive|$\operatorname{eq}$ is primitive recursive]] : [[Length Function is Primitive Recursive|$\operatorname{len}$ is primitive recursive]] : [[Cut-Off Subtraction is Primitive Recursive|$k \, \dot - \, 1$ is primitive recursive]] : [[Constant Function is Primitive Recursive|$2$ and $1$ are constants]] Thus the [[Definition:Characteristic Function of Set|characteristic function]] of $\operatorname{Cinstr}$ is given by: :$\chi_{\operatorname{Cinstr}} = \chi_{P} \left({k}\right) \chi_{Q} \left({k}\right) \chi_{\operatorname{Seq}} \left({k \, \dot - \, 1}\right)$ where: : $\chi_{P}$ is [[Definition:Primitive Recursive Function|primitive recursive]] : $\chi_{Q}$ is [[Definition:Primitive Recursive Function|primitive recursive]] : [[Multiplication is Primitive Recursive]] : [[Set of Sequence Codes is Primitive Recursive|$\chi_{\operatorname{Seq}}$ is primitive recursive]] : [[Cut-Off Subtraction is Primitive Recursive|$k \, \dot - \, 1$ is primitive recursive]] : [[Constant Function is Primitive Recursive|$1$ is constant]] Hence $\operatorname{Cinstr}$ is [[Definition:Primitive Recursive Set|primitive recursive]]. Finally we consider $\operatorname{Jinstr}$. We have that $\beta \left({J \left({n, m, q}\right)}\right) = 2^m 3^n 5^n + 2$. Hence $k \in \operatorname{Jinstr}$ iff $k \equiv 2 \pmod 3$ and $k - 1$ [[Definition:Sequence Coding|codes]] a triad of [[Definition:Positive Integer|positive integers]]. That is: {{begin-eqn}} {{eqn | l = k \in \operatorname{Jinstr} | o = \iff | r = \operatorname{rem} \left({k, 3}\right) = 2 | c = }} {{eqn | o = \land | r = \chi_{\operatorname{Seq} } \left({k \, \dot - \, 2}\right) = 1 | c = }} {{eqn | o = \land | r = \operatorname{len} \left({k \, \dot - \, 2}\right) = 3 | c = }} {{end-eqn}} We can introduce two properties: : $R \left({k}\right) \iff \operatorname{eq} \left({\operatorname{rem} \left({k, 3}\right), 2}\right)$ : $S \left({k}\right) \iff \operatorname{eq} \left({\operatorname{len} \left({k \, \dot - \, 2}\right), 3}\right)$ $\chi_R$ is [[Definition:Primitive Recursive Function|primitive recursive]] since it is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from: : [[Equality Relation is Primitive Recursive|$\operatorname{eq}$ is primitive recursive]] : [[Remainder is Primitive Recursive|$\operatorname{rem}$ is primitive recursive]] : [[Constant Function is Primitive Recursive|$3$ and $2$ are constants]] $\chi_S$ is [[Definition:Primitive Recursive Function|primitive recursive]] since it is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from: : [[Equality Relation is Primitive Recursive|$\operatorname{eq}$ is primitive recursive]] : [[Length Function is Primitive Recursive|$\operatorname{len}$ is primitive recursive]] : [[Cut-Off Subtraction is Primitive Recursive|$k \, \dot - \, 2$ is primitive recursive]] : [[Constant Function is Primitive Recursive|$2$ and $3$ are constants]] Thus the [[Definition:Characteristic Function of Set|characteristic function]] of $\operatorname{Jinstr}$ is given by: :$\chi_{\operatorname{Jinstr}} = \chi_R \left({k}\right) \chi_S \left({k}\right) \chi_{\operatorname{Seq}} \left({k \, \dot - \, 2}\right)$ where: : $\chi_R$ is [[Definition:Primitive Recursive Function|primitive recursive]] : $\chi_S$ is [[Definition:Primitive Recursive Function|primitive recursive]] : [[Multiplication is Primitive Recursive]] : [[Set of Sequence Codes is Primitive Recursive|$\chi_{\operatorname{Seq}}$ is primitive recursive]] : [[Cut-Off Subtraction is Primitive Recursive|$k \, \dot - \, 2$ is primitive recursive]] : [[Constant Function is Primitive Recursive|$2$ is constant]] Hence $\operatorname{Jinstr}$ is [[Definition:Primitive Recursive Set|primitive recursive]]. The result follows. {{qed}} [[Category:URM Programs]] [[Category:Primitive Recursive Functions]] lx6sqfd2svyrgvh97vgzh6pvnffq772	1
{{BeginTableau|\vdash p \iff p}} {{TheoremIntro|1|p \implies p|[[Law of Identity/Formulation 2|Law of Identity: Formulation 2]]}} {{BiconditionalIntro|2||p \iff p|1|1}} {{EndTableau|qed}}	1
{{BeginTableau |\vdash \paren {\paren {p \implies q} \implies \paren {p \implies r} } \implies \paren {p \implies \paren {q \implies r} } }} {{Assumption |1|\paren {p \implies q} \implies \paren {p \implies r} }} {{SequentIntro |2|1|p \implies \paren {q \implies r}|1|[[Self-Distributive Law for Conditional/Reverse Implication/Formulation 1|Self-Distributive Law for Conditional: Formulation 1]]}} {{Implication |3||\paren {\paren {p \implies q} \implies \paren {p \implies r} } \implies \paren {p \implies \paren {q \implies r} }|1|2}} {{EndTableau}} {{Qed}}	1
: $\vdash \left({p \implies q}\right) \implies \left({\left({p \land r}\right) \implies \left ({q \land r}\right)}\right)$	1
In a particular branch of [[Definition:Logic|logic]], certain concepts are at such a basic level of simplicity they can not be broken down into anything simpler. Those concepts are called '''atoms''' or described as '''atomic'''. Different branches of logic admit different '''atoms'''. === Propositional Logic === In [[Definition:Propositional Logic|propositional logic]], the '''atoms''' are [[Definition:Statement|statements]].	1
Using a [[Definition:Tableau Proof (Formal Systems)|tableau proof]] for [[Definition:Hilbert Proof System/Instance 1|instance 1 of a Hilbert proof system]]: {{BeginTableau|\vdash \paren {p \implies \paren {q \implies r} } \implies \paren {q \implies \paren {p \implies r} } |nohead = 1}} {{Assumption|1|p}} {{Assumption|2|p \implies \paren {q \implies r} }} {{ModusPonens|3|1, 2|q \implies r|1|2}} {{Assumption|4|q}} {{ModusPonens|5|1, 2, 4|r|3|4}} {{TableauLine|n = 6 | pool = 2, 4 | f = p \implies r | rlnk = Definition:Deduction Rule | rtxt = Deduction Rule | dep = 5 }} {{TableauLine|n = 7 | pool = 2 | f = q \implies \paren {p \implies r} | rlnk = Definition:Deduction Rule | rtxt = Deduction Rule | dep = 6 }} {{TableauLine|n = 8 | f = \paren {p \implies \paren {q \implies r} } \implies \paren {q \implies \paren {p \implies r} } | rlnk = Definition:Deduction Rule | rtxt = Deduction Rule | dep = 7 }} {{EndTableau}} {{qed}}	1
{{BeginTableau|\neg p \implies \neg \paren {p \land q} }} {{Assumption|1|\neg p}} {{Assumption|2|p \land q}} {{Simplification|3|2|p|2|1}} {{NonContradiction|4|1, 2|3|1}} {{Contradiction|5|1|\neg \paren {p \land q}|2|4}} {{Implication|6||\neg p \implies \neg \paren {p \land q}|1|5}} {{EndTableau}} {{qed}}	1
:$p \vdash p \lor q$	1
Let $\left({T, \mathbf H, \Phi}\right)$ be a [[Definition:Tableau Confutation|tableau confutation]] of $\mathbf H$. Suppose that $v$ were a [[Definition:Boolean Interpretation|boolean interpretation]] [[Definition:Model (Boolean Interpretations)|model]] for $\mathbf H$, i.e.: :$v \models_{\mathrm{BI}} \mathbf H$ By [[Model of Root of Propositional Tableau is Model of Branch]], it follows that: :$v \models_{\mathrm{BI}} \Phi \left[{\Gamma}\right]$ for some [[Definition:Branch (Graph Theory)|branch]] $\Gamma$ of $T$. Since $T$ is a [[Definition:Tableau Confutation|tableau confutation]], there is some [[Definition:WFF of Propositional Logic|WFF]] $\mathbf A$ such that: :$\mathbf A, \neg\mathbf A \in \Phi \left[{\Gamma}\right]$ Hence $v \models_{\mathrm{BI}} \mathbf A$, i.e.: :$v \left({\mathbf A}\right) = T$ But by the [[Definition:Logical Not/Truth Table|truth table for $\neg$]], this means: :$v \left({\neg\mathbf A}\right) = F$ which contradicts that $v \models_{\mathrm{BI}} \neg\mathbf A$. Hence, no such [[Definition:Boolean Interpretation|boolean interpretation]] can exist. That is, $\mathbf H$ is [[Definition:Unsatisfiable|unsatisfiable]] for [[Definition:Boolean Interpretation|boolean interpretations]]. {{qed}}	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|cccc||cccc|} \hline \neg & (p & \iff & q) & (p & \iff & \neg & q) \\ \hline F & F & T & F & T & F & T & F \\ T & F & F & T & T & T & F & T \\ T & T & F & F & F & T & T & F \\ F & T & T & T & F & F & F & T \\ \hline \end{array}$ {{qed}}	1
:$p \land q \dashv \vdash \paren {p \uparrow q} \uparrow \paren {p \uparrow q}$ where $\land$ denotes [[Definition:Conjunction|logical conjunction]] and $\uparrow$ denotes [[Definition:Logical NAND|logical NAND]].	1
{{BeginTableau |\vdash \paren {p \implies q} \implies \paren {\neg q \implies \neg p} }} {{Assumption |1|p \implies q}} {{Assumption |2|\neg q}} {{ModusTollens |3|1, 2|\neg p|1|2}} {{Implication |4|1|\neg q \implies \neg p|2|3}} {{Implication |5||\paren {p \implies q} \implies \paren {\neg q \implies \neg p}|1|4}} {{EndTableau}} {{Qed}}	1
: $\neg \left ({p \iff q}\right) \vdash \left({\neg p \land q}\right) \lor \left({p \land \neg q}\right)$	1
{{BeginTableau|\vdash \left({p \implies q}\right) \implies \left({\left({r \lor p}\right) \implies \left ({r \lor q}\right)}\right)}} {{Assumption|1|p \implies q}} {{SequentIntro|2|1|\left({\left({r \lor p}\right) \implies \left ({r \lor q}\right)}\right)|1 |[[Factor Principles/Disjunction on Left/Formulation 1|Factor Principles: Disjunction on Left: Formulation 1]]}} {{Implication|3|1|\left({p \implies q}\right) \implies \left({\left({r \lor p}\right) \implies \left ({r \lor q}\right)}\right)|1|2}} {{EndTableau}} {{qed}}	1
:$p \implies \paren {q \implies r} \dashv \vdash q \implies \paren {p \implies r}$	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth value]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] is [[Definition:True|true]] for all [[Definition:Boolean Interpretation|boolean interpretations]]. :$\begin{array}{|cccc|c|c|} \hline (\neg & p & \implies & p) & \implies & p \\ \hline T & F & F & F & T & F \\ F & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
: $\vdash \left({\neg q \implies p}\right) \implies \left({\neg p \implies q}\right)$	1
:$\vdash \neg \paren {p \implies q} \implies p$	1
{{BeginTableau|p \implies q \vdash \neg q \implies \neg p}} {{Premise|1|p \implies q}} {{Assumption|2|\neg q}} {{ModusTollens|3|1, 2|\neg p|1|2}} {{Implication|4|1|\neg q \implies \neg p|2|3}} {{EndTableau}} {{Qed}}	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc||ccccccccc|} \hline p & \oplus & q & (p & \lor & q) & \land & (\neg & p & \lor & \neg & q) \\ \hline F & F & F & F & F & F & F & T & F & T & T & F \\ F & T & T & F & T & T & T & T & F & T & F & T \\ T & T & F & T & T & F & T & F & T & T & T & F \\ T & F & T & T & T & T & F & F & T & F & F & T \\ \hline \end{array}$ {{qed}}	1
Let $L_n$ denote the $n$th [[Definition:Lucas Number|Lucas number]]. Then: :$L_n < \paren {\dfrac 7 4}^n$	1
{{BeginTableau|p \implies q, r \implies s \vdash p \lor r \implies q \lor s}} {{Premise|1|p \implies q}} {{Premise|2|r \implies s}} {{Assumption|3|p \lor r}} {{Assumption|4|p}} {{ModusPonens|5|1, 4|q|1|4}} {{Addition|6|1, 4|q \lor s|5|1}} {{Assumption|7|r}} {{ModusPonens|8|2, 7|s|2|7}} {{Addition|9|2, 7|q \lor s|8|2}} {{ProofByCases|10|1, 2, 3|q \lor s|3|4|6|7|9}} {{Implication|11|1, 2|p \lor r \implies q \lor s|3|10}} {{EndTableau}} {{qed}}	1
{{BeginTableau|\paren {p \implies q} \iff \paren {\neg p \lor q} }} {{Assumption|1|p \implies q}} {{SequentIntro|2|1|\neg p \lor q|1|[[Rule of Material Implication/Formulation 1/Forward Implication|Rule of Material Implication: Formulation 1]]}} {{Implication|3||\paren {p \implies q} \implies \paren {\neg p \lor q}|1|2}} {{Assumption|4|\neg p \lor q}} {{SequentIntro|5|4|p \implies q|4|[[Rule of Material Implication/Formulation 1/Reverse Implication|Rule of Material Implication: Formulation 1]]}} {{Implication|6||\paren {\neg p \lor q} \implies \paren {p \implies q}|4|5}} {{BiconditionalIntro|7||\paren {p \implies q} \iff \paren {\neg p \lor q}|3|6}} {{EndTableau|qed}} {{LEM|Rule of Material Implication/Formulation 1/Forward Implication|3}}	1
=== Necessary Condition === Let $\mathbf A \left({S, P}\right)$ and $\mathbf E \left({S, P}\right)$ both be [[Definition:False|false]]. {{begin-eqn}} {{eqn | n = 1 | o = | r = \neg \mathbf A \left({S, P}\right) \land \neg \mathbf E \left({S, P}\right) }} {{eqn | n = 2 | o = \leadsto | r = \neg \mathbf A \left({S, P}\right) | c = [[Rule of Simplification]]: from $(1)$ }} {{eqn | n = 3 | o = \leadsto | r = \mathbf O \left({S, P}\right) | c = [[Universal Affirmative and Particular Negative are Contradictory]]: from $(2)$ }} {{eqn | n = 4 | o = \leadsto | r = \neg \mathbf E \left({S, P}\right) | c = [[Rule of Simplification]]: from $(1)$ }} {{eqn | n = 5 | o = \leadsto | r = \mathbf I \left({S, P}\right) | c = [[Particular Affirmative and Universal Negative are Contradictory]]: from $(4)$ }} {{eqn | n = 6 | o = \leadsto | r = \mathbf I \left({S, P}\right) \land \mathbf O \left({S, P}\right) | c = [[Rule of Conjunction/Proof Rule|Rule of Conjunction]]: from $(5)$ and $(3)$ }} {{end-eqn}} Hence $\mathbf I \left({S, P}\right)$ and $\mathbf O \left({S, P}\right)$ are both [[Definition:True|true]]. {{qed|lemma}} === Sufficient Condition === Let $\mathbf I \left({S, P}\right)$ and $\mathbf O \left({S, P}\right)$ both be [[Definition:True|true]]. {{begin-eqn}} {{eqn | n = 1 | o = | r = \mathbf I \left({S, P}\right) \land \mathbf O \left({S, P}\right) }} {{eqn | n = 2 | o = \leadsto | r = \mathbf I \left({S, P}\right) | c = [[Rule of Simplification]]: from $(1)$ }} {{eqn | n = 3 | o = \leadsto | r = \neg \mathbf E \left({S, P}\right) | c = [[Particular Affirmative and Universal Negative are Contradictory]]: from $(2)$ }} {{eqn | n = 4 | o = \leadsto | r = \mathbf O \left({S, P}\right) | c = [[Rule of Simplification]]: from $(1)$ }} {{eqn | n = 5 | o = \leadsto | r = \neg \mathbf A \left({S, P}\right) | c = [[Universal Affirmative and Particular Negative are Contradictory]]: from $(4)$ }} {{eqn | n = 6 | o = \leadsto | r = \neg \mathbf A \left({S, P}\right) \land \neg \mathbf E \left({S, P}\right) | c = [[Rule of Conjunction/Proof Rule|Rule of Conjunction]]: from $(5)$ and $(3)$ }} {{end-eqn}} Hence $\mathbf A \left({S, P}\right)$ and $\mathbf E \left({S, P}\right)$ are both [[Definition:False|false]]. {{qed}}	1
Let us assume that the '''[[Principle of Finite Induction|PFI]]''' is true. Let $S \subseteq \N$ which satisfy: :$(A): \quad 0 \in S$ :$(B): \quad \set {0, 1, \ldots, n} \subseteq S \implies n + 1 \in S$. We want to show that $S = \N$, that is, the '''[[Principle of Complete Finite Induction|PCI]]''' is true. Let $P \paren n$ be the [[Definition:Propositional Function|propositional function]]: :$P \paren n \iff \set {0, 1, \ldots, n} \subseteq S$ We define the set $S'$ as: :$S' = \set {n \in \N: P \paren n \text { is true} }$ $P \paren 0$ is true by $(A)$, so $0 \in S'$. Assume $P \paren k$ is true where $k \ge 0$. So $k \in S'$, and by hypothesis: :$\set {0, 1, \ldots, k} \subseteq S$ So by $(B)$: :$k + 1 \in S$ Thus: :$\set {0, 1, \ldots, k, k + 1} \subseteq S$. That last statement means $P \paren {k + 1}$ is true. This means $k + 1 \in S'$. Thus we have satisfied the conditions: :$0 \in S'$ :$n \in S' \implies n + 1 \in S'$ That is, $S' = \N$, and $P \paren n$ holds for all $n \in \N$. Hence, by definition: :$S = \N$ So '''[[Principle of Finite Induction|PFI]]''' gives that $S = \N$. Therefore '''[[Principle of Finite Induction|PFI]]''' implies '''[[Principle of Complete Finite Induction|PCI]]'''.	1
{{BeginTableau|\vdash \paren {p \implies q} \lor \paren {q \implies r} }} {{ExcludedMiddle|1|q \lor \neg q}} {{Assumption|2|q}} {{SequentIntro|3|2|p \implies q|2|[[True Statement is implied by Every Statement]]}} {{Addition|4|2|\paren {p \implies q} \lor \paren {q \implies r}|3|1}} {{Assumption|5|\neg q}} {{SequentIntro|6|5|q \implies r|5|[[False Statement implies Every Statement]]}} {{Addition|7|5|\paren {p \implies q} \lor \paren {q \implies r}|6|2}} {{ProofByCases|8||\paren {p \implies q} \lor \paren {q \implies r}|1|2|4|5|7}} {{EndTableau|qed}} {{LEM}}	1
Suppose $\mathbf H$ does '''not''' have a [[Definition:Model (Boolean Interpretations)|model]]. By the [[Main Lemma of Propositional Tableaus]], $\mathbf H$ has a [[Definition:Tableau Confutation|tableau confutation]] $T$. By [[Tableau Confutation contains Finite Tableau Confutation]], $T$ may be assumed to be [[Definition:Finite Propositional Tableau|finite]]. Hence the set $\mathbf H'$ of all [[Definition:WFF of Propositional Logic|WFFs]] in $\mathbf H$ used somewhere in $T$ is [[Definition:Finite Set|finite]]. Now, let $T'$ be the [[Definition:Labeled Tree for Propositional Logic|labeled tree]] which is the same as $T$ but with root $\mathbf H'$ instead of $\mathbf H$. Then $T'$ is a [[Definition:Tableau Confutation|tableau confutation]] of $\mathbf H'$. By the [[Tableau Confutation implies Unsatisfiable]], $\mathbf H'$ has no [[Definition:Model (Boolean Interpretations)|models]]. But this contradicts the assumption that all finite subsets of $\mathbf H$ have models. Hence the result. {{qed}}	1
{{BeginTableau|p \iff q \vdash \left({p \land q}\right) \lor \left({\neg p \land \neg q}\right)}} {{Premise|1|p \iff q}} {{BiconditionalElimination|2|1|p \implies q|1|1}} {{BiconditionalElimination|3|1|q \implies p|1|2}} {{ExcludedMiddle|4|p \lor \neg p}} {{Assumption|5|p}} {{ModusPonens|6|1, 5|q|2|5}} {{Conjunction|7|1, 5|p \land q|5|6}} {{Addition|8|1, 5|\left({p \land q}\right) \lor \left({\neg p \land \neg q}\right)|7|1}} {{Assumption|9|\neg p}} {{ModusTollens|10|1, 9|\neg q|3|9}} {{Conjunction|11|1, 9|\neg p \land \neg q|9|10}} {{Addition|12|1, 9|\left({p \land q}\right) \lor \left({\neg p \land \neg q}\right)|11|2}} {{ProofByCases|13|1|\left({p \land q}\right) \lor \left({\neg p \land \neg q}\right)|1|5|8|9|12}} {{EndTableau}} {{qed}} {{LEM}} [[Category:Biconditional as Disjunction of Conjunctions]] egkw4jhwu57bih1jc81ct20djsatuf4	1
:$p \lor \left ({p \land q}\right) \dashv \vdash p$	1
{{BeginTableau|\left({\neg p \lor q}\right) \implies \left({p \implies q}\right)}} {{Assumption|1|\neg p \lor q}} {{SequentIntro|2|1|p \implies q|1|[[Rule of Material Implication/Formulation 1/Reverse Implication|Rule of Material Implication: Formulation 1]]}} {{Implication|3||\left({\neg p \lor q}\right) \implies \left({p \implies q}\right)|1|2}} {{EndTableau}} {{qed}}	1
A concept is '''vague''' if borderline cases for its application occur. That is, if there are "grey areas" where it is unclear whether or not it can be applied.	1
Let $f: \N^{k+1} \to \N$ be a [[Definition:Primitive Recursive Function|primitive recursive function]]. Then $g: \N^k \to \N$ given by: :$g \left({n_1, n_2, \ldots, n_k}\right) = f \left({n_1, n_2, \ldots, n_{i-1}, a, n_i \ldots, n_k}\right)$ is [[Definition:Primitive Recursive Function|primitive recursive]].	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, in each case, the [[Definition:Truth Value|truth values]] in the appropriate columns match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c|ccc||cc|} \hline p & p & \iff & \bot & \neg & p \\ \hline F & F & T & F & T & F \\ T & T & F & F & F & T \\ \hline \end{array}$ {{qed}}	1
Using a [[Definition:Tableau Proof (Formal Systems)|tableau proof]] for [[Definition:Hilbert Proof System/Instance 1|instance 1 of a Hilbert proof system]]: {{BeginTableau|p \implies p|nohead=1}} {{TableauLine|n = 1 | f = \paren {p \implies \paren {\paren {p \implies p} \implies p} } \implies \paren {\paren {p \implies \paren {p \implies p} } \implies \paren {p \implies p} } | rtxt = Axiom 2 | c = $\mathbf A = p, \mathbf B = p \implies p, \mathbf C = p$ }} {{TableauLine|n = 2 | f = p \implies \paren {\paren {p \implies p} \implies p} | rtxt = Axiom 1 | c = $\mathbf A = p, \mathbf B = p \implies p$ }} {{ModusPonens|3||\paren {p \implies \paren {p \implies p} } \implies \paren {p \implies p}|1|2}} {{TableauLine|n = 4 | f = p \implies \paren {p \implies p} | rtxt = Axiom 1 | c = $\mathbf A = p, \mathbf B = p$ }} {{ModusPonens|5||p \implies p|3|4}} {{EndTableau}} {{qed}}	1
Let $S_n$ denote the $n$th [[Definition:Fibonacci String|Fibonacci string]]. Then for $n \ge 3$, $S_n$ has: :$F_{n - 2}$ instances of $\text a$ :$F_{n - 1}$ instances of $\text b$.	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, in each case, the [[Definition:Truth Value|truth values]] in the appropriate columns match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c|ccc||cc|} \hline p & p & \implies & \bot & \neg & p \\ \hline F & F & T & F & T & F \\ T & T & F & F & F & T \\ \hline \end{array}$ {{qed}}	1
We check all the [[Axiom:Kolmogorov Axioms|Kolmogorov axioms]] in turn: === First Axiom === Let $n$ be the number of times a certain [[Definition:Event|event]] $\omega$ is observed to happen. Let $n'$ be the number of times $\omega$ is observed not to happen. By [[Law of Excluded Middle]] and [[Principle of Non-Contradiction]], $\omega$ either happened or did not, and not both. Therefore $n + n'$ is the total number of observations. It is supposed that at least one observation is actually made, so that $n + n' \ne 0$. The [[Definition:Relative Frequency Model|relative frequency model]] says that the probability of $\omega$ occurring can be defined as: :$\map \Pr \omega = \dfrac n {n + n'}$ the [[Definition:Numerator|numerator]] and [[Definition:Denominator|denominator]] of which are [[Definition:Positive Integer|positive integers]] such that $n + n' \ge n$. If $\omega$ is observed never to happen, then $n = 0$ and $\map \Pr \omega = \dfrac 0 {0 + n'} = 0$. If $\omega$ is observed to always happen, then $n' = 0$ and $\map \Pr \omega = \dfrac n {n + 0} = 1$. Otherwise, if $n, n' \ne 0$, from [[Mediant is Between]]: :$0 = \dfrac 0 {0 + n'} < \dfrac n {n + n'} < \dfrac n {n + 0} = 1$ Thus $\Pr$ is [[Definition:Bounded Mapping|bounded]]: :$0 \le \map \Pr {\cdot} \le 1$ {{qed|lemma}} === Second Axiom === [[Definition:By Hypothesis|By hypothesis]]: :$\map \Pr \Omega = \dfrac {n + n'} {n + n'} = 1$ {{qed|lemma}} === Third Axiom === This is a proof by [[Principle of Mathematical Induction|induction]]. ==== Basis for the Induction ==== The case $j = 2$ is verified as follows: Let $A$ and $B$ be two [[Definition:Pairwise Disjoint|pairwise disjoint]] [[Definition:Event|events]]. Let $p$ and $q$ be the number of times $A$ and $B$ have been observed, respectively. Let $n$ be the total number of trials observed. By the definition of [[Definition:Pairwise Disjoint|pairwise disjoint]], $A$ and $B$ never happened at the same time. By the same reasoning as the proof for the [[Axiom:Kolmogorov Axioms#First Axiom|first axiom]], in all $n$ observations: :$A$ happened $p$ times :$B$ happened $q$ times :$A \lor B$ happened $p + q$ times. {{MissingLinks|There's a result that can be linked to so as to replace all these words. In fact, now I think of it, there's a result which allows us to replace this entire inductive argument, we just need to find it.}} By hypothesis: {{begin-eqn}} {{eqn | l = \map \Pr {A \cup B} | r = \dfrac {p + q} n }} {{eqn | l = | r = \dfrac p n + \dfrac q n }} {{eqn | l = | r = \map \Pr A + \map \Pr B }} {{end-eqn}} This is the [[Definition:Basis for the Induction|basis for the induction]]. ==== Induction Hypothesis ==== Let $A_1, A_2, \ldots, A_j$ be $j$ [[Definition:Pairwise Disjoint|pairwise disjoint]] [[Definition:Event|events]]. By the definition of the [[Definition:Relative Frequency Model|relative frequency model]], $j$ is [[Definition:Finite|finite]]. Assume: :$\displaystyle \map \Pr {\bigcup_{i \mathop = 1}^j A_i} = \map \Pr {A_1} + \map \Pr {A_2} + \cdots + \map \Pr {A_j}$ This is our [[Definition:Induction Hypothesis|induction hypothesis]]. ==== Induction Step ==== This is our [[Definition:Induction Step|induction step]]: Let $A_1, A_2, \ldots, A_j, A_{j + 1}$ be $j+1$ [[Definition:Pairwise Disjoint|pairwise disjoint]] [[Definition:Event|events]]. Define $C = A_1 \lor A_2 \lor A_3 \lor \cdots \lor A_j$. Then $C$ and $A_{j+1}$ are also pairwise disjoint. By the [[Principle of Mathematical Induction#Basis For the Induction|base case]]: :$\map \Pr {C \cup A_{j + 1} } = \map \Pr C + \map \Pr {A_{j + 1} }$ By the definition of $C$, this equation is [[Definition:Logical Equivalence|logically equivalent]] to: :$\displaystyle \map \Pr {\bigcup_{i \mathop = 1}^{j + 1} A_i} = \sum_{i \mathop = 1}^{j + 1} \map \Pr {A_i}$ By the definition of the [[Definition:Relative Frequency Model|relative frequency model]], $j + 1$ is [[Definition:Finite|finite]]. The result follows by the [[Principle of Mathematical Induction]]. {{qed}} {{LEM}}	1
Let $k \in \Z_{>0}$ be a [[Definition:Positive Integer|positive integer]]. Let $f: \Z_{>0} \to \Z_{>0}$ be the [[Definition:Mapping|mapping]] defined as: :$\forall m \in \Z_{>0}: \map f m = $ the [[Definition:Integer Addition|sum]] of the [[Definition:Cube (Algebra)|cubes]] of the [[Definition:Digit|digits]] of $n$. Let $n_0 \in \Z_{>0}$ be a [[Definition:Strictly Positive Integer|(strictly) positive integer]] which is a [[Definition:Multiple of Integer|multiple]] of $3$. Consider the sequence: :$s_n = \begin{cases} n_0 & : n = 0 \\ \map f {s_{n - 1} } & : n > 0 \end{cases}$ Then: :$\exists r \in \N_{>0}: s_r = 153$ That is, by performing $f$ repeatedly on a [[Definition:Multiple of Integer|multiple]] of $3$ eventually results in the [[Definition:Pluperfect Digital Invariant|pluperfect digital invariant]] $153$.	1
Let $\uparrow$ signify the [[Definition:Logical NAND|NAND]] operation. The following results hold:	1
:$p \implies q \dashv \vdash p \uparrow \paren {q \uparrow q}$	1
Let $\mathscr G$ be [[Definition:Gentzen Proof System/Instance 1|instance 1 of a Gentzen proof system]].	1
:$\neg \forall x: \neg \map P x \dashv \vdash \exists x: \map P x$ ::''If not everything '''is not''', there exists something that '''is'''.''	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc||cccccc|} \hline p & \lor & q & \neg & (\neg & p & \land & \neg & q) \\ \hline F & F & F & F & T & F & T & T & F \\ F & T & T & T & T & F & F & F & T \\ T & T & F & T & F & T & F & T & F \\ T & T & T & T & F & T & F & F & T \\ \hline \end{array}$ {{qed}}	1
It is sufficient to consider the case $a_n = 1$: :$\displaystyle \map P x = \prod_{k \mathop = 1}^n \paren {x - z_k}$ The proof proceeds by [[Principle of Mathematical Induction|induction]]. Let $\map {\Bbb P} n$ be the statement that the identity below holds for all sets $\set {z_1, \ldots, z_n}$. {{begin-eqn}} {{eqn | l = \prod_{j \mathop = 1}^n \paren {x - z_j} | r = x^n + \sum_{j \mathop = 1}^n \paren {-1}^{n - j + 1} e_{n - j + 1} \paren {\set {z_1, \ldots, z_n} } \, x^{j - 1} }} {{eqn | r = x^n + \paren {-1} \, e_1 \paren {\set {z_1, \ldots, z_n} } \, x^{n - 1} + \paren {-1}^2 \, e_2 \paren {\set {z_1, \ldots, z_n} } \, x^{n - 2} + \cdots + \paren {-1}^n e_n \paren {\set {z_1, \ldots, z_n} } }} {{end-eqn}} [[Definition:Basis for the Induction|Basis for the Induction]]: $\map {\Bbb P} 1$ holds because $\map {e_1} {\set {z_1} } = z_1$. [[Definition:Induction Step|Induction Step]] $\map {\Bbb P} n$ implies $\map {\Bbb P} {n + 1}$: Assume $\map {\Bbb P} n$ holds and $n \ge 1$. Let for given values $\set {z_1, \ldots, z_n, z_{n + 1} }$: :$\displaystyle \map Q x = \paren {x - z_{n + 1} } \prod_{k \mathop = 1}^n \paren {x - z_k}$ Expand the right side product above using induction hypothesis $\map {\Bbb P} n$. Then $\map Q x$ equals $x^{n + 1}$ plus terms for $x^{j - 1}$, $1 \le j \le n + 1$. If $j = 1$, then one term occurs for $x^{j - 1}$: :$\displaystyle \paren {-x_{n + 1} } \, \paren {\paren {-1}^{n - 1 + 1} \map {e_{n - 1 + 1} } {\set {z_1, \ldots, z_n} } x^{1 - 1} } = \paren {-1}^{n + 1} \map {e_n} {\set {z_1, \ldots, z_n, z_{n + 1} } }$ If $2 \le j \le n + 1$, then two terms $T_1$ and $T_2$ occur for $x^{j - 1}$: {{begin-eqn}} {{eqn | l = T_1 | r = \paren x \paren {\paren {-1}^{n - j + 2} \, \map {e_{n - j + 2} } {\set {z_1, \ldots, z_n} } x^{j - 2} } }} {{eqn | l = T_2 | r = \paren {-z_{n + 1 } } \, \paren {\paren {-1}^{n - j + 1} \, \map {e_{n - j + 1} } {\set {z_1, \ldots, z_n} } x^{j - 1} } }} {{end-eqn}} The coefficient $c$ of $x^{j - 1}$ for $2 \le j \le n + 1$ is: {{begin-eqn}} {{eqn | l = c | r = \dfrac {T_1 + T_2} {x^{j - 1} } }} {{eqn | r = \paren {-1}^m \, \map {e_m} {\set {z_1, \ldots, z_n} } + \paren {-1}^m \, \map {e_{m - 1} } {\set {z_1, \ldots, z_n} } z_{n + 1} | c = where $m = n - j + 2$. }} {{end-eqn}} Use [[Elementary Symmetric Function/Examples/Recursion|recursion identity]] to simplify the expression for $c$: {{begin-eqn}} {{eqn | l = \map {e_m} {\set {z_1, \ldots, z_n, z_{n + 1} } } | r = z_{n + 1} \, \map {e_{m - 1} } {\set {z_1, \ldots, z_n} } + \map {e_m} {\set {z_1, \ldots, z_n} } }} {{eqn | ll= \leadsto | l = c | r = \paren {-1}^{n - j + 2} \, \map {e_{n - j + 2} } {\set {z_1, \ldots, z_n, z_{n + 1} } } }} {{end-eqn}} Thus $\map {\Bbb P} {n + 1}$ holds and the induction is complete. Set equal the two identities for $\map P x$: :$\displaystyle x^n + \sum_{k \mathop = 0}^{n - 1} a_k x^k = x^n + \paren {-1} \, \map {e_1} {\set {z_1, \ldots, z_n} } x^{n - 1} + \paren {-1}^2 \, \map {e_2} {\set {z_1, \ldots, z_n} } x^{n - 2} + \cdots + \paren {-1}^n \map {e_n} {\set {z_1, \ldots, z_n} }$ Linear independence of the powers $1, x, x^2, \ldots$ implies polynomial coefficients match left and right. Hence the coefficient $a_k$ of $x^k$ on the {{LHS}} matches $\paren {-1}^{n - k} \, \map {e_{n - k} } {\set {z_1, \ldots, z_n} }$ on the {{RHS}}. {{qed}} {{proofread}}	1
This will be [[Proof by Contradiction|proven by contradiction]]. Let such an operation $\circ$ exist. Let $f^\circ: \mathbb B^2 \to \mathbb B$ be the associated [[Definition:Truth Function|truth function]]. Suppose now that $q = F$, while $p$ remains unspecified. Then: :$p \land q = f^\land \left({p, F}\right) = F$ where $f^\land$ is the [[Definition:Truth Function|truth function]] of [[Definition:Conjunction|conjunction]]. It does not matter what $p$ is, for: :$f^\land \left({T, F}\right) = f^\land \left({F, F}\right) = F$ Hence, for $\left({p \land q}\right) \circ q = p$ to hold, $f^\circ$ must satisfy: :$f^\circ \left({F, F}\right) = p$ However, because $p$ could still be either $T$ or $F$, this identity cannot always hold. Therefore, $\circ$ cannot exist. {{qed}} [[Category:Conjunction]] iz8xrrjo16at5wz9wiqbjhnuzh6k4nl	1
Let $\N^*$ be defined as $\N^* = \N \setminus \left\{{0}\right\}$. The [[Definition:Subset|subset]] $\N^* \subset \N$ is [[Definition:Primitive Recursive Set|primitive recursive]].	1
=== [[Rule of Transposition/Variant 1/Formulation 1/Forward Implication/Proof|Proof of Forward Implication]] === {{:Rule of Transposition/Variant 1/Formulation 1/Forward Implication/Proof}} === [[Rule of Transposition/Variant 1/Formulation 1/Reverse Implication/Proof|Proof of Reverse Implication]] === {{:Rule of Transposition/Variant 1/Formulation 1/Reverse Implication/Proof}}	1
This proof proceeds by structural induction. === Case $1$ === Let $R$ be the [[Definition:Empty Set|empty-set]] [[Definition:Regular Expression|regular expression]], $\varnothing$. Then: :$L \left({R}\right) = \varnothing$ Consider the [[Definition:Finite State Machine|finite state machine]] $F_\varnothing$ defined as: :$F_\varnothing = \left({S_\varnothing, A_\varnothing, I_\varnothing, \Sigma, T_\varnothing}\right)$ where: : $S_\varnothing = \left\{ { \mathsf{Rej} }\right\}$ : $A_\varnothing = \varnothing$ : $I_\varnothing = \mathsf{Rej}$ : $T_\varnothing \left({ s, \sigma }\right) = \mathsf{Rej}$ for all $s \in S_\varnothing, \sigma \in \Sigma$ This machine is always in a rejecting state and never leaves it. So no word is in $L \left({ F_\varnothing }\right)$. Therefore: :$L \left({ F_\varnothing }\right) = \varnothing = L \left({R}\right)$ {{qed|lemma}} === Case $2$ === Let $R$ be the [[Definition:Null String|empty-word]] [[Definition:Regular Expression|regular expression]], $\epsilon$. Then: :$L \left({R}\right) = \left\{ { \left[\right] }\right\}$ Consider the [[Definition:Finite State Machine|finite state machine]] $F_\epsilon$ defined as: : $F_\epsilon = \left({ S_\epsilon, A_\epsilon, I_\epsilon, \Sigma, T_\epsilon }\right)$ where: : $S_\epsilon = \left\{ { \mathsf{Acc}, \mathsf{Rej} }\right\}$ : $A_\epsilon = \left\{ { \mathsf{Acc} }\right\}$ : $I_\epsilon = \mathsf{Acc}$ : $T_\epsilon \left({ s, \sigma }\right) = \mathsf{Rej}$ for all $s \in S_\epsilon, \sigma \in \Sigma$ This machine starts out in an accepting state. So $\left[\right]$ (the [[Definition:Null String|empty word]] is in $L \left({ F_\epsilon }\right)$. Furthermore, any symbol moves the machine to a rejecting state and never back. So no other word is in $L \left({ F_\epsilon }\right)$. Therefore: :$L \left({ F_\epsilon }\right) = \left\{ { \left[\right] }\right\} = L \left({R}\right)$ {{qed|lemma}} === Case $3$ === Let $R$ be a ''literal'' $\sigma$. Then: :$L \left({R}\right) = \left\{ { \left[{\sigma}\right] }\right\}$ Consider the [[Definition:Finite State Machine|finite state machine]] $F_\sigma$ defined as: : $F_\sigma = \left({ S_\sigma, A_\sigma, I_\sigma, \Sigma, T_\sigma }\right)$ where: : $S_\sigma = \left\{ { \mathsf{Start}, \mathsf{Acc}, \mathsf{Rej} }\right\}$ : $A_\sigma = \left\{ { \mathsf{Acc} }\right\}$ : $I_\sigma = \mathsf{Start}$ : $T_\sigma \left({ \mathsf{Start}, \sigma }\right) = \mathsf{Acc}$ : $T_\sigma \left({ s', \sigma' }\right) = \mathsf{Rej}$ for all other $s' \in S_\sigma, \sigma' \in \Sigma$ This machine starts out in a rejecting state. So $\left[{}\right]$ (the [[Definition:Null String|empty word]]) is not in $L \left({ F_\sigma }\right)$. After receiving the symbol $\sigma$ at the start, this machine moves to an accepting state. So $\left[{\sigma}\right]$ is in $L \left({ F_\sigma }\right)$. Any other initial symbol, and any symbol after the initial, moves the machine to a rejecting state and never back. So no other word is in $L \left({ F_\sigma }\right)$. Therefore: :$L \left({ F_\sigma }\right) = \left\{ { \left[{\sigma}\right] }\right\} = L \left({R}\right)$ {{qed|lemma}} === Case $4$ === Let $R$ be a concatenation: :$R = R_1 R_2$ By the induction hypothesis, there exist [[Definition:Finite State Machine|finite state machine]]s: : $F_1 = \left({ S_1, A_1, I_1, \Sigma, T_1 }\right): L \left({F_1}\right) = L \left({R_1}\right)$ : $F_2 = \left({ S_2, A_2, I_2, \Sigma, T_2 }\right): L \left({F_2}\right) = L \left({R_2}\right)$ Define a new [[Definition:Finite State Machine|finite state machine]] $F_c$ as: : $F_c = \left({ S_c, A_c, I_c, \Sigma, T_c }\right) $ where: : $S_c = S_1 \times \mathcal P \left({ S_2 }\right)$ : $A_c = \left\{ { \left({ s_1, s_2 }\right) : s_1 \in S_1 \land s_2 \cap A_2 \neq \varnothing }\right\}$ : $I_c = \begin{cases} \left({ I_1, \varnothing }\right) & : I_1 \notin A_1 \\ \left({ I_1, \left\{ {I_2} \right\} }\right) & : I_1 \in A_1 \end{cases}$ : $\displaystyle T_c \left({ \left({ s_1, s_2 }\right), \sigma }\right) = \begin{cases} \left({ T_1 \left({ s_1, \sigma }\right), \bigcup_{s \in s_2} \left\{ { T_2 \left({ s, \sigma }\right) }\right\} }\right) & : T_1 \left({ s_1, \sigma }\right) \notin A_1 \\ \left({ T_1 \left({ s_1, \sigma }\right), \bigcup_{s \in s_2} \left\{ { T_2 \left({ s, \sigma }\right) }\right\} \cup \left\{ {I_2} \right\} }\right) & : T_1 \left({ s_1, \sigma }\right) \in A_1 \end{cases}$ where: : $\times$ denotes the [[Definition:Cartesian Product|Cartesian Product]] : $\mathcal P$ the [[Definition:Power Set|Power Set]]. This machine $F_c$ effectively simulates one copy of $F_1$ and any number of copies of $F_2$. Every time the simulated $F_1$ encounters an accepting state, a new copy of $F_2$ is run. The combined $F_c$ reaches an accepting state if any one of the simulated $F_2$s do. Therefore, the language accepted by this state machine is the concatenation of the accepted languages of $F_1$ and $F_2$. {{qed|lemma}} === Case $5$ === Let $R$ be an alternation: :$R = R_1 \mid R_2$ By the induction hypothesis, there exist [[Definition:Finite State Machine|finite state machine]]s: : $F_1 = \left({ S_1, A_1, I_1, \Sigma, T_1 }\right): L \left({F_1}\right) = L \left({R_1}\right)$ : $F_2 = \left({ S_2, A_2, I_2, \Sigma, T_2 }\right): L \left({F_2}\right) = L \left({R_2}\right)$ Define a new [[Definition:Finite State Machine|finite state machine]] $F_a$ as: : $F_a = \left({ S_a, A_a, I_a, \Sigma, T_a }\right)$ where: : $S_a = S_1 \times S_2$ : $A_a = \left\{ { \left({ s_1, s_2 }\right) : s_1 \in A_1 \lor s_2 \in A_2 }\right\}$ : $I_a = \left({ I_1, I_2 }\right)$ : $T_a \left({ \left({ s_1, s_2 }\right), \sigma }\right) = \left({ T_1 \left({ s_1, \sigma }\right), T_2 \left({ s_2, \sigma }\right) }\right)$ where $\times$ denotes the [[Definition:Cartesian Product|Cartesian Product]]. This machine $F_a$ effectively simulates $F_1$ and $F_2$ in parallel. $F_a$ reaches an accepting state if any one of the simulated machines do. Therefore, the language accepted by this state machine is the union of the accepted languages of $F_1$ and $F_2$. {{qed|lemma}} === Case $6$ === Let $R$ be a Kleene star: :$R = R_1^*$ By the induction hypothesis, there exists a [[Definition:Finite State Machine|finite state machine]]: : $F_1 = \left({ S_1, A_1, I_1, \Sigma, T_1 }\right): L \left({F_1}\right) = L \left({R_1}\right)$ Define a new [[Definition:Finite State Machine|finite state machine]] $F_k$ as: : $F_k = \left({ S_k, A_k, I_k, \Sigma, T_k }\right)$ where: : $S_k = \mathcal P \left({ S_1 }\right)$ : $A_k = \left\{ { S \subseteq S_k : I_1 \in S }\right\}$ : $I_k = \left\{ {I_1} \right\} $ : $\displaystyle T_k \left({ S, \sigma }\right) = \begin{cases} U_k \left({ S, \sigma }\right) & : U_k \left({ S, \sigma }\right) \cap A_1 = \varnothing \\ U_k \left({ S, \sigma }\right) \cup \left\{ {I_1} \right\} & : U_k \left({ S, \sigma }\right) \cap A_1 \neq \varnothing \end{cases}$ : $U_k \left({ S, \sigma }\right) = \bigcup_{s \in S} \left\{ { T_1 \left({ s, \sigma }\right) }\right\}$ where $\mathcal P$ denotes the [[Definition:Power Set|Power Set]]. This machine $F_k$ effectively simulates any number of copies of $F_1$ simultaneously. Every time any of the simulated machines reaches an accepting state, a new copy is run. $F_k$ reaches an accepting state whenever $I_1$ is in its state. This occurs in two situations: : at the beginning and: : when any of the simulated machines reaches an accepting state. Therefore, the language accepted by $F_k$ consists of arbitrary numbers of concatenations of strings accepted by $F_1$. By structural induction, the result follows. {{qed}} [[Category:Formal Systems]] tpfx4zb7heqe54c057iv27g1p7h5kye	1
Let $\mathcal L_3$ be the set of regular languages. {{explain|Is it a set? Does this need to be proved? Intuition would suggest that it would be a class.}} Then the following holds: $\forall L \in \mathcal L_3: \exists n_0 \in \N_0: \forall z \in L: \left|{z}\right| > n_0 \implies \exists u, v, w$ such that: :$z = u \cdot v \cdot w$ :$\left|{v}\right| > 0$ :$\left|{u v}\right| < n_0$ :$\forall i \in \N_0: u \cdot v^i \cdot w \in L$	1
Let $C$ be a [[Definition:Linear Code|linear code]]. Let $C$ have a [[Definition:Minimum Distance of Linear Code|minimum distance]] $d$. Then $C$ corrects $e$ [[Definition:Transmission Error|transmission errors]] for all $e$ such that $2 e + 1 \le d$.	1
From the [[Definition:Substitution (Mathematical Logic)|definition]]: :$h \left({n_1, n_2, \ldots, n_k}\right) = f \left({g_1 \left({n_1, n_2, \ldots, n_k}\right), g_2 \left({n_1, n_2, \ldots, n_k}\right), \ldots, g_t \left({n_1, n_2, \ldots, n_k}\right)}\right)$. Let $P, Q_1, Q_2, \ldots, Q_t$ be [[Normalized URM Program|normalized URM programs]] which [[Definition:URM Computability|compute]] $f, g_1, g_2, \ldots, g_t$ respectively. Let $u = \max \left\{{\rho \left({P}\right), \rho \left({Q_1}\right), \rho \left({Q_2}\right), \ldots, \rho \left({Q_t}\right)}\right\}$. Let $s_j = \lambda \left({Q_j}\right)$ be the [[Definition:Unlimited Register Machine#Length of Program|number of basic instructions]] in $Q_j$ for $1 \le j \le t$. Hence: * [[Definition:Unlimited Register Machine#Registers|registers]] $R_{u+1}, R_{u+2}, \ldots, R_{u+k}$ can be used to hold a copy of the [[Definition:Unlimited Register Machine#Input|input]] $\left({n_1, n_2, \ldots, n_k}\right)$ so it can be guaranteed not to be accidentally overwritten by any operations performed by any of $P, Q_1, Q_2, \ldots, Q_t$; * [[Definition:Unlimited Register Machine#Registers|registers]] $R_{u+k+1}, R_{u+k+2}, \ldots, R_{u+k+t}$ can be used to hold copies of the [[Definition:Unlimited Register Machine#Output|outputs]] of each of $Q_1, Q_2, \ldots, Q_t$ so they also can be guaranteed not to be accidentally overwritten by any operations performed by any of $P, Q_1, Q_2, \ldots, Q_t$. The following [[Definition:Algorithm|algorithm]] can be followed to create a [[Definition:URM Program|URM program]] $H$ to [[Definition:URM Computability|compute]] $h$. It is assumed that: * The [[Definition:Unlimited Register Machine#Input|input]] is in $R_1, R_2, \ldots, R_k$. * Each of $P, Q_1, Q_2, \ldots, Q_t$ are written so as to start at line $1$. {| border="1" |- ! align="right" | Step !! ! align="left" | Process ! align="left" | Notes |- | align="right" | $1$ || | align="left" | Append a [[Block Copy Program]] $C \left({1, u+1, k}\right)$ to $H$<ref>$H$, at this point, is a [[Definition:Null URM Program|null URM program]]. After this step $\lambda \left({H}\right) = k$.</ref>. | This stores the input somewhere safe so it can be accessed again later. |- | align="right" | $2$ || | align="left" | Set $i = 1$. | This counts how many times we iterate through the following loop. |- | align="right" | $3$ || | align="left" | Calculate $l = \lambda \left({H}\right)$. | This is the [[Definition:Unlimited Register Machine#Length of Program|length]] of $H$ so far. |- | align="right" | $4$ || | align="left" | Append a [[Block Copy Program]] $C \left({u+1, 1, k}\right)$ to $H$. | This restores the input that we saved in step $1$ so it will be ready for program $Q_i$<ref>The first time through $H$, this step is technically unneeded, as $R_1, R_2, \ldots, R_k$ already contains the input. However, performing this step in ''all'' cases keeps the algorithm simpler and more modular. It's a programmer thing.</ref>. |- | align="right" | $5$ || | align="left" | Increment the <tt>Jump</tt>s in $Q_i$ by $l$ lines<ref>To '''increment the <tt>Jump</tt>s by $r$''' for any [[Normalized URM Program|normalized URM program]] is done by changing all <tt>Jump</tt>s of the form $J \left({m, n, q}\right)$ to $J \left({m, n, q+r}\right)$.</ref>. Call this amended version $Q_i'$. | As $Q_i$ was written so as to start from line 1, we need to move all the <tt>Jump</tt>s so as to point to the same lines relative to the start of $Q_i'$. |- | align="right" | $6$ || | align="left" | Append $Q_i'$ to $H$. | So $\lambda \left({H}\right)$ increases by $s_i$. |- | align="right" | $7$ || | align="left" | Append the command $C \left({1, u+k+i}\right)$ to $H$. | This stores the [[Definition:Unlimited Register Machine#Output|output]] of $Q_i'$ in a safe place where it won't get overwritten by something else. |- | align="right" | $8$ || | align="left" | Add $1$ to $i$. | |- | align="right" | $9$ || | align="left" | Is $i \le t$? If so, go to step $3$. Otherwise, continue to the next step. | |- | align="right" | $10$ || | align="left" | Append the [[Block Copy Program]] $C \left({u+k+1, 1, t}\right)$ to $H$. | This copies the [[Definition:Unlimited Register Machine#Output|outputs]] of $Q_1, Q_2, \ldots, Q_t$ back into $R_1, R_2, \ldots, R_t$ ready to be the [[Definition:Unlimited Register Machine#Input|input]] to program $P$. |- | align="right" | $11$ || | align="left" | Calculate $l = \lambda \left({H}\right)$. | This is the [[Definition:Unlimited Register Machine#Length of Program|length]] of $H$ so far. |- | align="right" | $12$ || | align="left" | Increment the <tt>Jump</tt>s in $P$ by $l$ lines. Call this amended version $P'$. | |- | align="right" | $13$ || | align="left" | Append $P'$ to $H$. | At this point, $\lambda \left({H}\right) = k + \sum_{j=1}^t \left({k + s_j + 1}\right) + t + \lambda \left({P}\right)$. |} It can easily be determined that $H$ computes $h$. Hence $h$ is [[Definition:URM Computability|URM computable]]. {{qed}}	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] is [[Definition:True|true]] for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc|c|cccc|} \hline \neg & p & \land & \neg & q & \iff & \neg & (p & \lor & q) \\ \hline T & F & T & T & F & T & T & F & F & F \\ T & F & F & F & T & T & F & F & T & T \\ F & T & F & T & F & T & F & T & T & F \\ F & T & F & F & T & T & F & T & T & T \\ \hline \end{array}$ {{qed}}	1
A statement $q$ '''depends upon''' another statement $p$ if the [[Definition:Truth Value|truth value]] of $q$ is ''influenced'' (in some way) by that of $p$, but is ''not necessarily'' [[Definition:Logical Implication|implied]] by that of $p$. Some authors prefer '''rests on''' for '''depends upon'''.	1
If two [[Definition:Propositional Formula|propositional formulas]] are [[Definition:Interderivable|interderivable]], they are [[Definition:Biconditional|equivalent]]: :$\paren {p \dashv \vdash q} \dashv \vdash \paren {p \iff q}$	1
: $p \iff q \dashv \vdash \neg p \iff \neg q$	1
:$\vdash p \iff \left({p \lor q}\right) \land \left({p \lor \neg q}\right)$	1
{{BeginTableau|p \implies q \vdash \paren {r \land p} \implies \paren {r \land q}}} {{Premise|1|p \implies q}} {{Assumption|2|r \land p}} {{Simplification|3|1, 2|p|2|2}} {{ModusPonens|4|1, 2|q|1|3}} {{Simplification|5|1, 2|r|2|1}} {{Conjunction|6|1, 2|r \land q|5|4}} {{Implication|7|1|\paren {r \land p} \implies \paren {r \land q}|2|6}} {{EndTableau}} {{qed}}	1
We apply the [[Method of Truth Tables]]. $\begin{array}{|ccc||c|c|} \hline p & \land & q & p & q \\ \hline F & F & F & F & F \\ F & F & T & F & T \\ T & F & F & T & F \\ T & T & T & T & T \\ \hline \end{array}$ As can be seen, when $p \land q$ is [[Definition:True|true]] so are both $p$ and $q$. {{qed}}	1
{{:Rule of Idempotence/Disjunction/Formulation 1}}	1
Some sources refer to the [[Biconditional Elimination]] as the rule of '''Biconditional-Conditional'''.	1
If $\mathbf H$ is [[Definition:Finite Set|finite]], the result is trivial. So let $\mathbf H = \left\{{\mathbf A_n: n \in \N}\right\}$ be an [[Definition:Enumeration|enumeration]] of $\mathbf H$. Define $\mathbf H_m = \left\{{\mathbf A_n: n \le m}\right\}$. Let $T_1$ be the [[Definition:Propositional Tableau|propositional tableau]] consisting of only a [[Definition:Root Node|root node]] with [[Definition:Hypothesis Set|hypothesis set]] $\mathbf H_1$. For each $m \in \N$, construct $T_{m+1}$ from $T_m$ by applying the [[Tableau Extension Lemma]] to $\mathbf H_{m+1}$. This provides us with a [[Definition:Sequence|sequence]] $\left({T_m}\right)_{m \in \N}$ of [[Definition:Finished Propositional Tableau|finished propositional tableaus]]. The $T_m$ form an [[Definition:Exhausting Sequence of Sets|exhausting sequence of sets]] for the [[Definition:Infinite Propositional Tableau|infinite propositional tableau]] $T = \displaystyle \bigcup_{m \mathop = 1}^\infty T_m$. If $T$ has a [[Definition:Finished Branch of Propositional Tableau|finished branch]] $\Gamma$, then by [[Finished Branch Lemma/Corollary|Finished Branch Lemma: Corollary]]: :$\Phi \left[{\Gamma}\right]$ is [[Definition:Satisfiable|satisfiable]] and hence $\mathbf H$ is [[Definition:Satisfiable|satisfiable]] (since $\mathbf H \subseteq \Phi \left[{\Gamma}\right]$). Suppose $T$ has no [[Definition:Finite Branch|finite]] [[Definition:Finished Branch of Propositional Tableau|finished branches]]. Let $T'$ be the [[Definition:Subtree|subtree]] of $T$ given by: :$t \in T'$ {{iff}} $t$ is on a [[Definition:Finished Branch of Propositional Tableau|finished branch]] $\Gamma_m$ of every $T_m$ such that $t \in T_m$ Suppose the [[Definition:Root Node|root node]] $r_T$ of $T$ were not in $T'$. Then for some $T_m$, $r_T$ would not be on a [[Definition:Finished Branch of Propositional Tableau|finished branch]] of $T_m$. But since $T_m$ is [[Definition:Finished Propositional Tableau|finished]], every [[Definition:Branch (Graph Theory)|branch]] of $T_m$ is [[Definition:Finished Branch of Propositional Tableau|finished]] or [[Definition:Contradictory Branch|contradictory]]. Hence every [[Definition:Branch (Graph Theory)|branch]] of $T_m$ is [[Definition:Contradictory Branch|contradictory]]. But then $T_m$ is a [[Definition:Tableau Confutation|tableau confutation]] of $\mathbf H_m$. By [[Tableau Confutation implies Unsatisfiable]], this contradicts the assumption that $\mathbf H_m$ is [[Definition:Satisfiable|satisfiable]]. Therefore, $r_T$ is in $T'$. Suppose $T'$ were [[Definition:Finite Tree|finite]]. Let $t$ be a [[Definition:Leaf Node|leaf]] of $T'$, which exists by [[Finite Tree has Leaf Nodes]]. Suppose $t$ were a [[Definition:Leaf Node|leaf]] of $T$. Then $\Gamma_t$, the [[Definition:Branch (Graph Theory)|branch]] of $T$ identified by [[Leaf of Rooted Tree is on One Branch]], is [[Definition:Finished Branch of Propositional Tableau|finished]]. For, as any $T_m$ is a [[Definition:Subtree|subtree]] of $T$, $\Gamma_t$ is the only [[Definition:Branch (Graph Theory)|branch]] of $T_m$ such that $t \in \Gamma_t$. The conclusion follows from the definition of $T'$. But then $\Gamma_t$ would be a [[Definition:Finite Branch|finite]] [[Definition:Finished Branch of Propositional Tableau|finished branch]] of $T$, a contradiction. Therefore, $T'$ cannot be [[Definition:Finite Tree|finite]]. Hence, $T'$ is a [[Definition:Finitely Branching|finitely branching tree]]. By [[König's Tree Lemma]], $T'$ has an [[Definition:Infinite Branch|infinite branch]] $\Gamma$. By definition of $T'$, the [[Definition:Branch (Graph Theory)|branch]] $\Gamma_m := \Gamma \cap T_m$ of $T_m$ is [[Definition:Finished Branch of Propositional Tableau|finished]] for each $m \in \N$. If $\Gamma$ were [[Definition:Contradictory Branch|contradictory]], then $\mathbf A \in \Gamma$ and $\neg\mathbf A \in \Gamma$ for some [[Definition:WFF of Propositional Logic|WFF]] $\mathbf A$. But then $\mathbf A, \neg \mathbf A \in \Gamma_m$ for some $m \in \N$, contradicting that $\Gamma_m$ is [[Definition:Finished Branch of Propositional Tableau|finished]]. Also, if $\mathbf A$ [[Definition:Occurrence along Branch|occurs]] on $\Gamma$, then it occurs on some $\Gamma_m$. Since $\Gamma_m$ is [[Definition:Finished Branch of Propositional Tableau|finished]], it follows that $\mathbf A$ is [[Definition:Used WFF|used]] on $\Gamma_m$, and hence on $\Gamma$. In conclusion, $\Gamma$ is [[Definition:Finished Branch of Propositional Tableau|finished]]. As established above, it follows that $\mathbf H$ is [[Definition:Satisfiable|satisfiable]] for [[Definition:Boolean Interpretation|boolean interpretations]]. {{qed}}	1
: $\left({p \lor q}\right) \implies \left({p \land q}\right) \vdash p \iff q$	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc||ccccccccc|} \hline p & \oplus & q & (\neg & p & \land & q) & \lor & (p & \land & \neg & q) \\ \hline F & F & F & T & F & F & F & F & F & F & T & F \\ F & T & T & T & F & T & T & T & F & F & F & T \\ T & T & F & F & T & F & F & T & T & T & T & F \\ T & F & T & F & T & F & T & F & T & F & F & T \\ \hline \end{array}$ {{qed}}	1
The [[Definition:Integer Sequence|sequence]] formed from the number of ways to play the first $n$ moves in [[Definition:Chess|chess]] begins: :$20, 400, 8902, 197 \, 742, \ldots$ {{OEIS|A007545}} The count for the fourth move is already ambiguous, as it depends on whether only legal moves count, or whether all moves, legal or illegal, are included. The count as given here does include illegal moves in addition to legal ones.	1
Let $R$ be a [[Definition:Commutative Ring|commutative ring]]. Let $\MM_{m \times n}$ be the [[Definition:Set|set]] of all $m \times n$ [[Definition:Matrix|matrices]] over $R$. Then under [[Definition:Matrix Product (Conventional)|conventional matrix multiplication]]: :$\mathbf {A B} = \mathbf {B A}$ for all $\mathbf A \in \MM_{m \times n}, \; \mathbf B \in \MM_{n \times p}$ {{iff}} $p = m = n = 1$.	1
:$\vdash p \iff \neg \neg p$	1
:$\vdash \paren {\paren {p \implies q} \implies \paren {p \implies r} } \implies \paren {p \implies \paren {q \implies r} }$	1
=== [[Non-Equivalence as Disjunction of Conjunctions/Formulation 1/Forward Implication/Proof|Forward Implication: Proof]] === {{:Non-Equivalence as Disjunction of Conjunctions/Formulation 1/Forward Implication/Proof}} === [[Non-Equivalence as Disjunction of Conjunctions/Formulation 1/Reverse Implication/Proof|Reverse Implication: Proof]] === {{:Non-Equivalence as Disjunction of Conjunctions/Formulation 1/Reverse Implication/Proof}}	1
:$\paren {p \iff \neg q} \vdash \neg \paren {p \iff q}$	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for each [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c||ccc|} \hline p & p & \lor & p \\ \hline T & T & T & T \\ F & F & F & F \\ \hline \end{array}$ {{qed}}	1
:$p \dashv \vdash \neg \neg p$	1
A [[Definition:Partial Boolean Interpretation|partial boolean interpretation]] for $S$ is a [[Definition:Mapping|mapping]] from $S$ to the [[Definition:Set of Truth Values|set of truth values]] $\set {T, F}$. By [[Cardinality of Set of All Mappings]], the total number of [[Definition:Mapping|mappings]] from $S$ to $T$ is: :$\card {T^S} = \card T^{\card S}$ The result follows directly. {{qed}}	1
{{BeginTableau|p \oplus q \vdash q \oplus p}} {{Premise|1|p \oplus q}} {{SequentIntro|2|1|\left({p \lor q} \right) \land \neg \left({p \land q}\right)|1|Definition of [[Non-Equivalence|Exclusive Or]]}} {{Commutation|3|1|\left({q \lor p} \right) \land \neg \left({p \land q}\right)|2|Disjunction}} {{Commutation|4|1|\left({q \lor p} \right) \land \neg \left({q \land p}\right)|3|Conjunction}} {{SequentIntro|5|1|q \oplus p|4|Definition of [[Non-Equivalence|Exclusive Or]]}} {{EndTableau}} {{BeginTableau|q \oplus p \vdash p \oplus q}} {{Premise|1|q \oplus p}} {{SequentIntro|2|1|\left({q \lor p} \right) \land \neg \left({q \land p}\right)|1|Definition of [[Non-Equivalence|Exclusive Or]]}} {{Commutation|3|1|\left({q \lor p} \right) \land \neg \left({p \land q}\right)|2|Conjunction}} {{Commutation|4|1|\left({p \lor q} \right) \land \neg \left({p \land q}\right)|3|Disjunction}} {{SequentIntro|5|1|p \oplus q|4|Definition of [[Non-Equivalence|Exclusive Or]]}} {{EndTableau}} {{qed}}	1
:$p \land \neg q \dashv \vdash \neg \left({p \implies q}\right)$	1
We apply the [[Method of Truth Tables]] to the proposition: :$\paren {p \implies q} \iff \paren {q \implies p}$ $\begin{array}{|ccc|c|ccc|} \hline p & \implies & q) & \iff & (q & \implies & p) \\ \hline F & T & F & T & F & T & F \\ F & T & T & F & T & F & F \\ T & F & F & F & F & T & T \\ T & T & T & T & T & T & T \\ \hline \end{array}$ As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] do not match for all [[Definition:Boolean Interpretation|boolean interpretations]]. {{qed}}	1
:$p \lor \left ({p \land q}\right) \dashv \vdash p$	1
{{BeginTableau|\left({p \lor \neg p}\right) \vdash \left({\left({p \implies q}\right) \implies p}\right) \implies p}} {{Premise|1|p \lor \neg p}} {{Assumption|2|p}} {{SequentIntro|3|2|\left({\left({p \implies q}\right) \implies p}\right) \implies p|2|[[True Statement is implied by Every Statement/Formulation 1|True Statement is implied by Every Statement]]}} {{Assumption|4|\neg p}} {{SequentIntro|5|4|p \implies q|4|[[False Statement implies Every Statement/Formulation 1|False Statement implies Every Statement]]}} {{Assumption|6|\left({p \implies q}\right) \implies p}} {{ModusPonens|7|6, 5|p|6|5}} {{Implication|8|5|\left({\left({p \implies q}\right) \implies p}\right) \implies p|6|7}} {{ProofByCases|9|1|\left({\left({p \implies q}\right) \implies p}\right) \implies p|1|2|3|4|8}} {{EndTableau}}	1
:$\set {\neg, \land}$: [[Definition:Logical Not|Not]] and [[Definition:Conjunction|And]]	1
Using a [[Definition:Tableau Proof (Formal Systems)|tableau proof]] for [[Definition:Gentzen Proof System/Instance 1|instance 1 of a Gentzen proof system]]: {| border="1" |+$\vdash \left({p \lor q}\right) \implies \left({q \lor p}\right)$ |- ! Line !! ! Pool ! Formula ! Rule ! Depends upon ! Notes |- | 1 || || | $\neg p, q, p$ | Axiom || || |- | 2 || || | $\neg q, q, p$ | Axiom || || |- | 3 || || | $\neg \left({p \lor q}\right), q, p$ | [[Definition:Gentzen Proof System/Instance 1/Alpha-Rule|$\alpha$-Rule: $\alpha\lor$]] | 1, 2 || |- | 4 || || | $\neg \left({p \lor q}\right), q \lor p$ | [[Definition:Gentzen Proof System/Instance 1/Beta-Rule|$\beta$-Rule: $\beta\lor$]] | 3 || |- | 5 || || | $\left({p \lor q}\right) \implies \left({q \lor p}\right)$ | [[Definition:Gentzen Proof System/Instance 1/Beta-Rule|$\beta$-Rule: $\beta\implies$]] | 4 || |} {{qed}}	1
Let $\struct {S, \vee, \wedge, \neg}$ be a [[Definition:Boolean Algebra|Boolean algebra]]. Let $a, b, c \in S$. Let: {{begin-eqn}} {{eqn | l = a \wedge c | r = b \wedge c }} {{eqn | l = a \wedge \neg c | r = b \wedge \neg c }} {{end-eqn}} Then: : $a = b$	1
:$\displaystyle \sum_{j \mathop = 1}^n \paren {2 j - 1} = n^2$ That is, the sum of the first $n$ [[Definition:Odd Integer|odd numbers]] is the $n$th [[Definition:Square Number|square number]].	1
The [[Definition:Constant Mapping|constant function]] of $k$ variables: $f_c^k: \N^k \to \N$, defined as: :$\map {f_c^k} {n_1, n_2, \ldots, n_k} = c$ where $c \in \N$ is [[Definition:Primitive Recursive Function|primitive recursive]].	1
The [[Definition:Subset|subset]] $\left\{{0}\right\} \subset \N$ is [[Definition:Primitive Recursive Set|primitive recursive]].	1
{{BeginTableau|\neg p \implies p \vdash p}} {{Premise|1|\neg p \implies p}} {{Assumption|2|p \implies \bot}} {{SequentIntro|3|2|\neg p|2|[[Negation as Implication of Bottom]]}} {{ModusPonens|4|1,2|p|1|3}} {{Implication|5|1|(p \implies \bot) \implies p|2|4}} {{SequentIntro|6|1|p|5|[[Peirce's Law/Formulation 1|Peirce's Law]]}} {{EndTableau}} {{qed}}	1
:$\vdash \paren {p \implies q} \implies \paren {\paren {r \land p} \implies \paren {r \land q} }$	1
{{BeginTableau|p, \neg p \vdash q|[[Definition:Hilbert Proof System/Instance 2|Instance 2 of the Hilbert-style systems]]}} {{Assumption|1|p}} {{Assumption|2|\neg p}} {{TableauLine |n = 3 |f = q \implies (p \lor q) |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Axiom $A2$ }} {{TableauLine |n = 4 |f = \neg p \implies (q \lor \neg p) |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 1$ |dep = 3 |c = $\neg p \, / \, q$, $q \, / \, p$ }} {{TableauLine |n = 5 |f = q \lor \neg p |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 3$ |dep = 2, 4 }} {{TableauLine |n = 6 |f = (q \lor \neg p) \implies (\neg p \lor q) |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Axiom $A3$, Rule $RST \, 1$ |c = $\neg p \, / \, q$, $q \, / \, p$ }} {{TableauLine |n = 7 |f = \neg p \lor q |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 3$ |dep = 5, 6 }} {{TableauLine |n = 8 |f = p \implies q |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 2 \, (2)$ }} {{TableauLine |n = 9 |f = q |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 3$ |dep = 1, 8 }} {{EndTableau}} {{qed}}	1
Let $\Bbb U$ be a [[Definition:Universal Set|universal set]]. Let $\circ: S \times S \to \Bbb U$ be a [[Definition:Binary Operation|binary operation]] on $S$. Let $T \subseteq S$. Let $\left({a, b}\right) \in T \times T$. By definition of [[Definition:Ordered Pair|ordered pair]] and [[Definition:Cartesian Product|cartesian product]]: :$a \in T$ and $b \in T$ As $T \subseteq S$, it follows that: :$a \in S$ and $b \in S$ Thus: :$\left({a, b}\right) \in S \times S$ As $\circ$ is a [[Definition:Binary Operation|binary operation]] on $S$, it follows that: :$\circ \left({a, b}\right) \in \Bbb U$ But by definition of [[Definition:Restriction of Operation|restriction]] of $\circ$: :$\circ \left({a, b}\right) = \circ {\restriction}_T \left({a, b}\right)$ Thus: :$\circ {\restriction}_T \left({a, b}\right) \in \Bbb U$ As $a$ and $b$ are arbitrary elements of $T$, it follows that this holds for all $a, b \in T$. Hence the result by definition of [[Definition:Binary Operation|binary operation]]. {{qed}} [[Category:Operations]] owksju1jdr9447lowaf79mvn8kii969	1
A [[Definition:Conditional|conditional statement]]: :$p \implies q$ is not [[Definition:Logical Equivalence|logically equivalent]] to its [[Definition:Inverse Statement|inverse]]: :$\lnot p \implies \lnot q$	1
{{AimForCont}} that such a $T$ is [[Definition:Consistent (Logic)|consistent]] and [[Definition:Complete Theory|complete]]. By the [[Undecidability Theorem]], since $T$ is [[Definition:Consistent (Logic)|consistent]] and contains $Q$, it is not [[Definition:Recursive Set|recursive]]. But, by [[Complete Recursively Axiomatized Theories are Recursive]], since $T$ is [[Definition:Complete Theory|complete]] and is the set of theorems of a [[Definition:Recursive Set|recursive set]], it is [[Definition:Recursive Set|recursive]]. The result follows by [[Proof by Contradiction]]. {{qed}}	1
The [[Well-Ordering Principle]] implies the [[Principle of Finite Induction]]. That is: :[[Well-Ordering Principle]]: Every [[Definition:Non-Empty Set|non-empty]] [[Definition:Subset|subset]] of $\N$ has a [[Definition:Minimal Element|minimal element]] implies: :[[Principle of Finite Induction]]: Given a [[Definition:Subset|subset]] $S \subseteq \N$ of the [[Definition:Natural Numbers|natural numbers]] which has these properties: ::$0 \in S$ ::$n \in S \implies n + 1 \in S$ :then $S = \N$.	1
Let $k, m, n \in \N$ be [[Definition:Natural Numbers|natural numbers]] such that: * $k \ge 1$; * $\left|{m - n}\right| \ge k$. The [[Definition:URM Program|URM program]] defined as: {| |- ! align="right" | Line !! ! align="left" | Command |- | align="right" | $1$ || | align="left" | $C \left({m, n}\right)$ |- | align="right" | $2$ || | align="left" | $C \left({m+1, n+1}\right)$ |- | align="right" | $\vdots$ || | align="left" | $\vdots$ |- | align="right" | $k$ || | align="left" | $C \left({m+k-1, n+k-1}\right)$ |} is called a '''block copy program'''. It is abbreviated $C \left({m, n, k}\right)$. It has the effect of copying the contents of [[Definition:Unlimited Register Machine#Registers|registers]] $R_m, R_{m+1}, \ldots, R_{m+k-1}$ into the [[Definition:Unlimited Register Machine#Registers|registers]] $R_n, R_{n+1}, \ldots, R_{n+k-1}$ respectively. It has [[Definition:Unlimited Register Machine#Length of Program|length]] defined as $\lambda \left({C \left({m, n, k}\right)}\right) = k$.	1
Let $A \subseteq P$ be defined by: :$A := \set {n \in P: \map Q n}$ From $(1)$, $0 \in A$. From $(2)$: :$\forall n \in P: n \in A \implies \map s n \in A$ As this holds for all $n \in P$, it holds [[Definition:A Fortiori|a fortiori]] for all $n \in A$. Thus the condition: :$n \in A \implies \map s n \in A$ is satisfied. So by [[Axiom:Peano's Axioms|Axiom $(\text P 5)$ of the Peano Axioms]]: :$A = P$ That is: :$\forall n \in P: \map Q n$ {{qed}}	1
:$\vdash \paren {\paren {q \lor r} \land p} \iff \paren {\paren {q \land p} \lor \paren {r \land p} }$	1
The [[Rule of Simplification]] can be symbolised by the [[Definition:Sequent|sequents]]:	1
:$p \implies \left({q \lor r}\right) \dashv \vdash \left({p \implies q}\right) \lor \left({p \implies r}\right)$	1
=== Function Version is Reducible to Decision Version === The algorithm described below solves the [[Definition:Directed Hamilton Cycle Problem/Function Version|function version]] of the problem with $O \left({n^2}\right)$ calls of the [[Definition:Directed Hamilton Cycle Problem/Decision Version|decision version]] of the problem. ;Input: The [[Definition:Digraph|directed graph]] $G$ ;Output: Either: :A [[Definition:Hamilton Cycle|Hamilton cycle]] in $G$ if one exists or: :''no solution'' if not. ;Auxiliary Function: $f \left({G}\right) \to \left\{{0, 1}\right\}$ defined as: :$f \left({G}\right) = 1$ {{iff}} $G$ has a [[Definition:Hamilton Cycle|Hamilton cycle]] :$f \left({G}\right) = 0$ {{iff}} $G$ has no [[Definition:Hamilton Cycle|Hamilton cycle]] If $f \left({G}\right) = 0$ output ''no solution''. Pick a starting [[Definition:Vertex of Graph|vertex]]. Call it $v_0$. The solution path starts at $v_0$. While $G$ has more then one vertex: : Pick one of the edges going out of $v_0$. : Call that edge $\left({v_0, u}\right)$. : If $f \left({G - \left({v_0, u} \right)}\right) = 1$ remove $\left({v_0, u}\right)$ from $G$. : Otherwise: ::add $u$ to the end of the solution set ::remove the vertices $v_0$ and $u$ from $G$ ::replace them with a new $v_0$ where: :::$\left({v_0, w}\right)$ is in the new graph if $\left({u, w}\right)$ is in the old graph ::and: :::$\left({w, v_0}\right)$ is in the new graph if $\left({w, v_0}\right)$ is in the old graph. Finally add $v_0$ to the end of the solution path and we have our solution. Every time $f \left({G}\right)$ is calculated at least one edge is removed. Thus $f \left({G}\right)$ is called $O \left({n^2}\right)$ times. This algorithm shows the [[Definition:Directed Hamilton Cycle Problem/Function Version|functional problem]] polynomially reduces to the [[Definition:Directed Hamilton Cycle Problem/Decision Version|decision problem]]. If the output of the [[Definition:Directed Hamilton Cycle Problem/Function Version|functional problem]] is anything other than ''no solution'' then $G$ has a [[Definition:Hamilton Cycle|Hamilton cycle]]. Thus the [[Definition:Directed Hamilton Cycle Problem/Function Version|functional problem]] reduces to the the [[Definition:Directed Hamilton Cycle Problem/Decision Version|decision problem]]. {{explain|The below does not follow from the above -- where is the "mutually polynomially reducible"? We have two statements that FP reduces to DP but no indication that DP reduces to FP. Is the second of the above statements backwards?}} Because they are mutually polynomially reducible we can show that both are NP or NP-hard by showing that either of them are NP or NP-hard. {{qed|lemma}} === Directed Hamilton Cycle Problem is NP === Given a potential solution to the decision problem in the form of a sequence of vertices it is possible to determine if that sequence is a Hamilton Cycle by: : making sure every vertex appears exactly once and: : verifying that each vertex in the sequence follows is adjacent to the previous vertex. From [[NP Problem iff Solution Verifiable in Polynomial Time]], a potential solution can be verified or rejected in polynomial time. Thus the Hamilton Cycle Problem is NP. {{qed|lemma}} === Directed Hamilton Cycle Problem is NP-hard === The objective here is to polynomially reduce the Conjunctive Normal Form Satisfiability problem with $m$ variables and $l$ clauses to the decision version of the Directed Hamilton Cycle problem. Because [[CNF Satisfiability Problem is NP-Complete]] that is enough to show the Hamilton Cycle is NP-hard. Consider the following diagram of a part of a graph: :[[File:CNF_to_HAMILTONIAN_graph.jpg]] It is clear that either $\left({A, B}\right)$ or $\left({B, A}\right)$ must be included in any Hamilton Cycle. Likewise either $\left({C, D}\right)$ or $\left({D, C}\right)$ must be included. The three cases for these four vertices are: : $\left({A, B, C, D}\right)$ : $\left({A, B, E, C, D}\right)$ : $\left({D, C, B, A}\right)$ In short, the four vertices $A, B, C, D$ must be visited in order or in reverse order. Also, they can only visit the $E$ node if they are in the right order. These pieces of the graph can be concatenated by letting the $D$ node of one piece be the same as the $A$ node of the next. The final graph to be constructed takes a form similar to the following diagram: :[[File:CNF_to_HAMILTONIAN_graph2.jpg]] The boxes represent concatenations of the pieces we have just studied. In the final graph there will be one of these rows for every variable in the CNF SAT problem, each one linked to another row as shown here. This creates a circuit through the rows. A left to right path corresponds to the variable being true and a right to left path corresponds to the variable being false. In addition to these vertices there will also be one vertex for every clause in the original problem. These will take the $E$ vertex position in the first diagram. A vertex will have be attached to a pair of vertices in a row if the variable the row corresponds to appears in the clause, going: :left to right if the variable is not negated and: :right to left if it is negated. In the image the $E$ type node would contain $x_1 \lor \neg x_2$ if the first row corresponded to $x_1$, and the second to $x_2$. Clearly all the vertices could only be visited in a cycle if there was some choice of direction for each of the rows that allowed all the $E$ type vertices to be visited. That would only happen if there was some way of deciding values for the variables in the CNF SAT problem that gave each clause at least one true variable in its conjunction. And so the graph has a Hamilton Cycle iff the CNF SAT problem has a solution. The number of vertices in a given row is at most $3 l + 3$ because: :Each variable can only appear in each clause once, otherwise that clause is either internally redundant or trivially satisfied :Each additional instance of a variable only requires three additional vertices and: :there are only three nodes of overhead. The number of $E$ type vertices is $l$. Therefore the total number of vertices in the constructed graph is at most $3 l m + 3 m + l$ vertices. Because the size of the graph is bounded by a polynomial of the size of the CNF SAT problem this scheme is a polynomial reduction from CNF SAT to the directed Hamilton Cycle problem. The Directed Hamilton Cycle problem is NP-hard. Because the Directed Hamilton Cycle problem is NP and NP-hard it is NP-complete. {{qed}}	1
:$p \implies \paren {q \implies r} \dashv \vdash \paren {p \implies q} \implies \paren {p \implies r}$	1
Every [[Definition:Proposition|proposition]] entails itself:	1
A [[Definition:Conditional|conditional statement]]: :$p \implies q$ is not [[Definition:Logical Equivalence|logically equivalent]] to its [[Definition:Converse Statement|converse]]: :$q \implies p$	1
Suppose $\mathbf H$ does '''not''' have a [[Definition:Model (Boolean Interpretations)|model]]. By the [[Main Lemma of Propositional Tableaus]], $\mathbf H$ has a [[Definition:Tableau Confutation|tableau confutation]] $T$. By [[Tableau Confutation contains Finite Tableau Confutation]], $T$ may be assumed to be [[Definition:Finite Propositional Tableau|finite]]. Hence the set $\mathbf H'$ of all [[Definition:WFF of Propositional Logic|WFFs]] in $\mathbf H$ used somewhere in $T$ is [[Definition:Finite Set|finite]]. Now, let $T'$ be the [[Definition:Labeled Tree for Propositional Logic|labeled tree]] which is the same as $T$ but with root $\mathbf H'$ instead of $\mathbf H$. Then $T'$ is a [[Definition:Tableau Confutation|tableau confutation]] of $\mathbf H'$. By the [[Tableau Confutation implies Unsatisfiable]], $\mathbf H'$ has no [[Definition:Model (Boolean Interpretations)|models]]. But this contradicts the assumption that all finite subsets of $\mathbf H$ have models. Hence the result. {{qed}}	1
Let $X$ and $Y$ be [[Definition:Topological Space|topological spaces]]. Let $V$ be a [[Definition:Normed Vector Space|normed vector space]] over $\R$ or $\C$ with [[Definition:Norm on Vector Space|norm]] $\norm {\,\cdot\,}$. Let $x_0 \in X$ and $y_0 \in Y$. Let $f: X \to Y$ be a function with $\map f {x_0} = y_0$ that is [[Definition:Continuous Mapping at Point (Topology)|continuous]] at $x_0$. Let $g, h: Y \to V$ be functions. Suppose $\map g y = \map O {\map h y}$ as $y \to y_0$, where $O$ denotes [[Definition:Big-O Notation|big-O notation]]. Then $\map {\paren {g \circ f} } x = \map O {\map {\paren {h \circ f} } x}$ as $x \to x_0$.	1
By definition of [[Definition:Substring|substring]], there exists a [[Definition:String|string]] $T'$ such that: :$S = TT'$ Hence $S$ is the [[Definition:Concatenation (Formal Systems)|concatenation]] of the [[Definition:Null String|null string]], $T$, and $T'$. Thus by definition of [[Definition:Substring|substring]], $T$ is a [[Definition:Substring|substring]] of $S$. {{qed}} [[Category:Formal Systems]] brdmwx4fr7kw0ci47xvs1zgz98lmxep	1
:$\vdash \paren {p \lor \paren {q \land r} } \iff \paren {\paren {p \lor q} \land \paren {p \lor r} }$	1
: $p \implies q, r \implies s \vdash \neg q \lor \neg s \implies \neg p \lor \neg r$	1
Let $P, Q, R$ be one-variable [[Definition:URM Program|URM programs]]. Then the [[Composition of One-Variable URM Computable Functions|concatenated URM programs]] $P * \left({Q * R}\right)$ and $\left({P * Q}\right) * R$ are the same.	1
The [[Principle of Complete Induction]] implies the [[Well-Ordering Principle]]. That is: :[[Principle of Complete Induction]]: Given a [[Definition:Subset|subset]] $S \subseteq \N$ of the [[Definition:Natural Numbers|natural numbers]] which has these properties: ::$0 \in S$ ::$\set {0, 1, \ldots, n} \subseteq S \implies n + 1 \in S$ :then $S = \N$. implies: :[[Well-Ordering Principle]]: Every [[Definition:Non-Empty Set|nonempty]] [[Definition:Subset|subset]] of $\N$ has a [[Definition:Minimal Element|minimal element]].	1
Let $\uparrow$ signify the [[Definition:Logical NAND|NAND]] operation. Then, for any [[Definition:Proposition|proposition]] $p$: :$p \uparrow p \dashv \vdash \neg p$ That is, the [[Definition:Logical NAND|NAND]] of a proposition with itself corresponds to the [[Definition:Negation|negation]] operation.	1
{{:Double Negation/Double Negation Elimination/Sequent Form/Formulation 1}}	1
Let $\mathbf A$ be a [[Definition:WFF of Propositional Logic|WFF of propositional logic]]. Let $\mathbf A$ be [[Definition:Unsatisfiable (Boolean Interpretations)|unsatisfiable for boolean interpretations]]. Then every [[Definition:Completed Tableau|completed tableau]] for $\mathbf A$ is [[Definition:Closed Tableau|closed]].	1
: $p \dashv \vdash p \land p$	1
{{BeginTableau|\vdash \paren {\paren {q \land r} \lor p} \iff \paren {\paren {q \lor p} \land \paren {r \lor p} } }} {{Assumption|1|\paren {q \land r} \lor p}} {{SequentIntro|2|1|\paren {q \lor p} \land \paren {r \lor p}|1|[[Rule of Distribution/Conjunction Distributes over Disjunction/Right Distributive/Formulation 1|Conjunction is Right Distributive over Disjunction: Formulation 1]]}} {{Implication|3||\paren {\paren {q \land r} \lor p} \implies \paren {\paren {q \lor p} \land \paren {r \lor p} }|1|2}} {{Assumption|4|\paren {q \lor p} \land \paren {r \lor p} }} {{SequentIntro|5|4|\paren {q \land r} \lor p|4|[[Rule of Distribution/Conjunction Distributes over Disjunction/Right Distributive/Formulation 1|Conjunction is Right Distributive over Disjunction: Formulation 1]]}} {{Implication|6||\paren {\paren {q \lor p} \land \paren {r \lor p} } \implies \paren {\paren {q \land r} \lor p}|4|5}} {{BiconditionalIntro|7||\paren {\paren {q \land r} \lor p} \iff \paren {\paren {q \lor p} \land \paren {r \lor p} }|3|6}} {{EndTableau|qed}} [[Category:Rule of Distribution]] 7z7uuzjoo8r26oav447crim4y4t7oxm	1
{{BeginTableau|p \implies \neg p, \neg p \implies p \vdash \bot}} {{Premise|1|p \implies \neg p}} {{Premise|2|\neg p \implies p}} {{SequentIntro|3|1|\neg p|1|[[Proof by Contradiction/Variant 3|Proof by Contradiction: Variant 3]]}} {{ModusPonens|4|1, 2|p|2|3}} {{NonContradiction|5|1, 2|4|3}} {{EndTableau}} {{qed}} [[Category:Contradiction]] [[Category:Implication]] 8oh1tuksbgbdsmsmvv8c4wsanwetqw1	1
{{:De Morgan's Laws (Logic)/Disjunction of Negations}}	1
A '''propositional function''' $\map P {x_1, x_2, \ldots}$ is an [[Definition:Operation|operation]] which acts on the [[Definition:Object|objects]] denoted by the [[Definition:Object Variable|object variables]] $x_1, x_2, \ldots$ in a particular [[Definition:Universe of Discourse|universe]] to return a [[Definition:Truth Value|truth value]] which depends on: :$(1): \quad$ The [[Definition:Value of Variable|values]] of $x_1, x_2, \ldots$ :$(2): \quad$ The nature of $P$. === [[Definition:Propositional Function/Satisfaction|Satisfaction]] === {{:Definition:Propositional Function/Satisfaction}}	1
{{BeginTableau|p \oplus \top \vdash \neg p}} {{Premise|1|p \oplus \top}} {{SequentIntro|2|1|\left({p \lor \top} \right) \land \neg \left({p \land \top}\right)|1|Definition of [[Definition:Exclusive Or|Exclusive Or]]}} {{SequentIntro|3|1|\top \land \neg \left({p \land \top}\right)|1|[[Disjunction with Tautology]]}} {{SequentIntro|4|1|\neg \left({p \land \top}\right)|1|[[Conjunction with Tautology]]}} {{SequentIntro|5|1|\neg p|1|[[Conjunction with Tautology]]}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|\neg p \vdash p \oplus \top}} {{Assumption|1|\neg p}} {{TopIntro|2}} {{SequentIntro|3||p \lor \top|2|[[Disjunction with Tautology]]}} {{SequentIntro|4|1|\neg \left({p \land \top}\right)|1|[[Conjunction with Tautology]]}} {{Conjunction|5|1|\left({p \lor \top}\right) \land \neg \left({p \land \top}\right)|3|4}} {{SequentIntro|6|1|p \oplus \top|5|Definition of [[Non-Equivalence|Exclusive Or]]}} {{EndTableau}} {{qed}}	1
We proceed by [[Principle of Mathematical Induction|induction]] over $n \ge 1$. === Basis for the Induction === If $n = 1$ the result is trivially true. This establishes the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === This is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\displaystyle \prod_{i \mathop = 1}^{n - 1} p_i = \displaystyle \sum_{k \mathop \in Z} c_d X^k$ where: :$\displaystyle c_d := \sum_{k_1 + \cdots + k_{n - 1} = d} \paren {\prod_{i \mathop = 1}^{n - 1} a_{i, k_i} }$ Now we need to show that the result is true for the product $\displaystyle \prod_{i \mathop = 1}^n p_i$. === Induction Step === This is our [[Definition:Induction Step|induction step]]: Let $b_k$ be the [[Definition:Polynomial Coefficient|coefficient]] of $X^k$ in $\displaystyle \prod_{i \mathop = 1}^n p_i$. Then: {{begin-eqn}} {{eqn | l = b_k | r = \sum_{d + k_n \mathop = k} c_d a_{n, k_n} | c = {{Defof|Multiplication of Polynomial Forms}} }} {{eqn | r = \sum_{d + k_n \mathop = k}\ \sum_{k_1 + \cdots + k_{n - 1} \mathop = d} \paren {\prod_{i \mathop = 1}^{n-1} a_{i, k_i} } a_{n, k_n} | c = [[Coefficients of Polynomial Product#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \sum_{d + k_n \mathop = k}\ \sum_{k_1 + \cdots + k_{n - 1} \mathop = d} \paren {\prod_{i \mathop = 1}^n a_{i, k_i} } | c = }} {{eqn | r = \sum_{\substack {k_1 + \dotsb + k_{n - 1} \mathop = d \\ d + k_n \mathop = k} } \paren {\prod_{i \mathop = 1}^n a_{i, k_i} } | c = }} {{eqn | r = \sum_{k_1 + \cdots + k_n = k} \paren {\prod_{i \mathop = 1}^n a_{i, k_i} } | c = }} {{end-eqn}} The result follows by [[Principle of Mathematical Induction|induction]]. {{qed}} [[Category:Polynomial Theory]] [[Category:Proofs by Induction]] nzqrwdbhmmu7s566vxk03zz9gmx4ept	1
{{BeginTableau|\neg \left ({p \iff q}\right) \vdash \neg \left({p \implies q}\right) \lor \neg \left({q \implies p}\right)}} {{Premise|1|\neg \left ({p \iff q}\right)}} {{SequentIntro|2|1|\neg \left({\left ({p \implies q}\right) \land \left ({q \implies p}\right)}\right)|1 |[[Rule of Material Equivalence]]}} {{DeMorgan|3|1|\neg \left({p \implies q}\right) \lor \neg \left({q \implies p}\right)|2|Disjunction of Negations}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|\neg \left({p \implies q}\right) \lor \neg \left({q \implies p}\right) \vdash \neg \left ({p \iff q}\right)}} {{Premise|1|\neg \left({p \implies q}\right) \lor \neg \left({q \implies p}\right)}} {{DeMorgan|2|1|\neg \left({\left ({p \implies q}\right) \land \left ({q \implies p}\right)}\right)|1|Disjunction of Negations}} {{SequentIntro|3|1|\neg \left ({p \iff q}\right)|2|[[Rule of Material Equivalence]]}} {{EndTableau}} {{qed}}	1
We apply the [[Method of Truth Tables]]: :$\begin{array}{|ccccc||ccccc|} \hline p & \uparrow & (q & \uparrow & r) & (p & \uparrow & q) & \uparrow & r \\ \hline F & T & F & T & F & F & T & F & T & F \\ F & T & F & T & T & F & T & F & F & T \\ F & T & T & T & F & F & T & T & T & F \\ F & T & T & F & T & F & T & T & F & T \\ T & F & F & T & F & T & T & F & T & F \\ T & F & F & T & T & T & T & F & F & T \\ T & F & T & T & F & T & F & T & T & F \\ T & T & T & F & T & T & F & T & T & T \\ \hline \end{array}$ As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] do not match for all [[Definition:Boolean Interpretation|boolean interpretations]]. {{qed}}	1
Let $\mathcal R$ be a [[Definition:URM Computability|URM computable]] [[Definition:Relation|$k+1$-ary relation]] on $\N^{k+1}$. Let the [[Definition:Function|function]] $f: \N^{k+1} \to \N$ be a [[Definition:URM Computability|URM computable function]]. Let $g: \N^k \to \N$ be the [[Definition:Function|function]] obtained by [[Definition:Minimization|minimization]] from $f$ thus: :$g \left({n_1, n_2, \ldots, n_k}\right) \approx \mu y \mathcal R \left({n_1, n_2, \ldots, n_k, y}\right)$ Then $g$ is also [[Definition:URM Computability|URM computable]].	1
{{BeginTableau|p \implies \bot \vdash \neg p}} {{Premise|1|p \implies \bot}} {{Assumption|2|p}} {{ModusPonens|3|1, 2|\bot|1|2}} {{Contradiction|4|1|\neg p|2|3}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|\neg p \vdash p \implies \bot}} {{Premise|1|\neg p}} {{Assumption|2|p}} {{NonContradiction|3|1,2|1|2}} {{Implication|4|1|p \implies \bot|2|3}} {{EndTableau}} {{qed}}	1
: $p \iff q \vdash \neg p \iff \neg q$	1
Consider [[Definition:Proper Fraction|proper fractions]] of the form $\dfrac 3 n$ expressed in [[Definition:Canonical Form of Rational Number|canonical form]]. Let [[Fibonacci's Greedy Algorithm]] be used to generate a [[Definition:Sequence|sequence]] $S$ of [[Definition:Egyptian Fraction|Egyptian fractions]] for $\dfrac 3 n$. The smallest $n$ for which $S$ consists of $3$ [[Definition:Term of Sequence|terms]], where $2$ would be sufficient, is $25$.	1
The [[Definition:Game|game]] of [[Definition:Matching Pennies|matching pennies]] is a [[Definition:Completely Mixed Game|completely mixed game]].	1
=== Sufficient Condition === Let $\exists x: \map S x$. Let $\map {\mathbf E} {S, P}$ be [[Definition:True|true]]. As $\map {\mathbf E} {S, P}$ is [[Definition:True|true]], then by [[Modus Ponendo Ponens]]: :$\neg \map P x$ From the [[Rule of Conjunction/Proof Rule|Rule of Conjunction]]: :$\map S x \land \neg \map P x$ Thus $\map {\mathbf O} {S, P}$ holds. So by the [[Rule of Implication]]: :$\map {\mathbf E} {S, P} \implies \map {\mathbf O} {S, P}$ {{qed|lemma}} === Necessary Condition === Let $\map {\mathbf E} {S, P} \implies \map {\mathbf O} {S, P}$. {{AimForCont}}: :$\neg \exists x: \map S x$ that is, $\map S x$ is [[Definition:Vacuous Truth|vacuous]]. From [[Denial of Existence|De Morgan's Laws: Denial of Existence]]: :$\forall x: \neg \map S x \dashv \vdash \neg \exists x: \map S x$ it follows that $\forall x: \map S x$ is [[Definition:False|false]]. From [[False Statement implies Every Statement]]: :$\forall x: \map S x \implies \neg \map P x$ is [[Definition:True|true]]. So $\map {\mathbf E} {S, P}$ holds. Again, $\neg \exists x: \map S x$. Then by the [[Rule of Conjunction/Proof Rule|Rule of Conjunction]]: :$\neg \paren {\exists x: \map S x \land \neg \map P x}$ That is, $\map {\mathbf O} {S, P}$ does not hold. So $\map {\mathbf E} {S, P}$ is [[Definition:True|true]] and $\map {\mathbf O} {S, P}$ is [[Definition:False|false]]. This [[Proof by Contradiction|contradicts]] $\map {\mathbf E} {S, P} \implies \map {\mathbf O} {S, P}$ by definition of [[Definition:Conditional|implication]]. Thus $\exists x: \map S x$ must hold. {{qed}}	1
Let $f := \displaystyle \min_{u \mathop \in C} \map w u$. Let $\mathbf 0$ denote the [[Definition:Codeword of Linear Code|codeword]] in $\map V {n, p}$ consisting of all [[Definition:Zero Digit|zeroes]]. As $C$ is a [[Definition:Vector Subspace|subspace]] of $\map V {n, p}$, we have that $\mathbf 0 \in C$. Let $w$ be a [[Definition:Codeword of Linear Code|codeword]] with [[Definition:Weight of Linear Codeword|weight]] $f$. Then: :$\map d {w, \mathbf 0} = f$ so $f \ge \map d C$. Let $u, v \in C$ such that $\map d {u, v} = \map d C$. We have that $C$ is a [[Definition:Linear Code|linear code]]. Therefore: :$u - v \in C$ where $u - v$ denotes the [[Definition:Difference between Linear Codewords|difference]] between $u$ and $v$. But $u - v$ has [[Definition:Weight of Linear Codeword|weight]] $\map d C$. Thus: :$\map d C \le f$ and it follows that $\map d C = f$. {{qed}}	1
Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \N_{> 0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\paren {a + b}^{p^n} \equiv a^{p^n} + b^{p^n} \pmod p$ === Basis for the Induction === First from [[Power of Sum Modulo Prime]] we have that $\map P 1$ is true: :$\paren {a + b}^p \equiv a^p + b^p \pmod p$ This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\paren {a + b}^{p^k} \equiv a^{p^k} + b^{p^k} \pmod p$ Then we need to show: :$\paren {a + b}^{p^{k + 1} } \equiv a^{p^{k + 1} } + b^{p^{k + 1} } \pmod p$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \paren {a + b}^{p^k} | o = \equiv | r = a^{p^k} + b^{p^k} | rr= \pmod p | c = [[Prime Power of Sum Modulo Prime#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | ll= \leadsto | l = \paren {\paren {a + b}^{p^k} }^p | o = \equiv | r = \paren {a^{p^k} + b^{p^k} }^p | rr= \pmod p | c = [[Congruence of Powers]] }} {{eqn | ll= \leadsto | l = \paren {\paren {a + b}^{p^k} }^p | o = \equiv | r = \paren {a^{p^k} }^p + \paren {b^{p^k} }^p | rr= \pmod p | c = [[Prime Power of Sum Modulo Prime#Basis for the Induction|Basis for the Induction]] }} {{eqn | ll= \leadsto | l = \paren {a + b}^{p^{k + 1} } | o = \equiv | r = a^{p^{k + 1} } + b^{p^{k + 1} } | rr= \pmod p | c = }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\forall n \in \N_{> 0}: \paren {a + b}^{p^n} \equiv a^{p^n} + b^{p^n} \pmod p$ {{qed}}	1
A [[Definition:Statement|statement]] has a [[Definition:Truth Value|truth value]] of '''true''' {{iff}} what it says matches the way that things are.	1
Let $\mathcal M$ be an [[Definition:Structure (Formal Systems)|$\mathscr M$-structure]]. By assumption, if $\mathcal M$ is a [[Definition:Model of Set of Formulas|model]] of $\mathcal F$, it is one of $\mathcal G$ as well. But any [[Definition:Model of Set of Formulas|model]] of $\mathcal G$ is also a [[Definition:Model of Set of Formulas|model]] of $\mathcal H$. In conclusion, any [[Definition:Model of Set of Formulas|model]] of $\mathcal F$ is also a [[Definition:Model of Set of Formulas|model]] of $\mathcal H$. Hence the result, by definition of [[Definition:Semantic Consequence|semantic consequence]]. {{qed}} [[Category:Formal Semantics]] 3n79d69nwfm43gnzhstbnkng6sx70f5	1
Let $G$ be a [[Definition:Loop-Multigraph|loop-multigraph]] with $2 n$ [[Definition:Odd Vertex (Graph Theory)|odd vertices]], $n > 0$. Then $G$ has $n$ [[Definition:Edge-Disjoint Trails|edge-disjoint trails]] such that every [[Definition:Edge of Graph|edge]] of $G$ is contained in one of these [[Definition:Edge-Disjoint Trails|trails]]. Each of these trails starts and ends on an [[Definition:Odd Vertex (Graph Theory)|odd vertex]].	1
{{BeginTableau|p \vdash \paren {p \implies q} \implies q}} {{Premise|1|p}} {{Assumption|2|p \implies q}} {{ModusPonens|3|1, 2|q|2|1}} {{Implication|4|1|\paren {p \implies q} \implies q|2|3}} {{EndTableau}} {{Qed}}	1
Let $\LL_0$ be the [[Definition:Language of Propositional Logic|language of propositional logic]]. Let $v: \LL_0 \to \set {\T, \F}$ be a [[Definition:Boolean Interpretation|boolean interpretation]]. Then $v$ is [[Definition:Well-Defined Mapping|well-defined]].	1
Let $g: \N^k \to \N$ be a [[Definition:URM Computability|URM computable function]]. Then there is an [[Definition:Infinite|infinite number]] of [[Definition:URM Program|URM programs]] which compute $g$.	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] are [[Definition:True|true]] for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc|c|cccccc|} \hline (p & \lor & q) & \iff & (\neg & (\neg & p & \land & \neg & q)) \\ \hline F & F & F & T & F & T & F & T & T & F \\ F & T & T & T & T & T & F & F & F & T \\ T & T & F & T & T & F & T & F & T & F \\ T & T & T & T & T & F & T & F & F & T \\ \hline \end{array}$ {{qed}}	1
=== Sufficient Condition === Let us assume :$F$ is a [[Definition:Proper Subset|proper subset]] of $S$ and $F$ is a [[Definition:Prime Filter (Order Theory)|prime filter]] in $B$. Thus :$F$ is a [[Definition:Proper Subset|proper subset]] of $S$. Let $G$ be a [[Definition:Filter|filter]] in $B$ such that :$F \subseteq G$ and $F \ne G$. By definitions of [[Definition:Subset|subset]] and [[Definition:Set Equality|set equality]]: :$\exists x: x \in G \land x \notin F$ By definition of [[Definition:Boolean Algebra|Boolean algebra]]: :$x \vee \neg x = \top$ where $\top$ denotes the [[Definition:Top (Lattice Theory)|top]] of $B$. By [[Top in Filter]]: :$\top \in F$ By definition of [[Definition:Prime Filter (Order Theory)|prime filter]]: :$\neg x \in F$ By definition of [[Definition:Subset|subset]]: :$\neg x \in G$ By [[Filtered in Meet Semilattice]]: :$x \wedge \neg x \in G$ By definition of [[Definition:Boolean Algebra|Boolean algebra]]: :$\bot \in G$ Thus by definition of [[Definition:Subset|subset]]: :$G \subseteq S$ By definition of [[Definition:Set Equality|set equality]] it remains to prove that :$S \subseteq G$ Let $y \in S$. By definition of [[Definition:Smallest Element|smallest element]]: :$\bot \preceq y$ Thus by definition of [[Definition:Upper Set|upper set]]: :$y \in G$ {{qed|lemma}} === Necessary Condition === Let $F$ be [[Definition:Ultrafilter (Order Theory)|ultrafilter]] on $B$. Thus by definition of [[Definition:Ultrafilter (Order Theory)|ultrafilter]]: :$F$ is [[Definition:Proper Subset|proper subset]] of $S$. Let $x \in S$. Aiming for a [[Definition:Contradiction|contradiction]] suppose that :$x \notin F$ and $\neg x \notin F$ By [[Finite Infima Set and Upper Closure is Smallest Filter]]: :$F \cup \left\{ {x}\right\} \subseteq {\operatorname{fininfs}\left({F \cup \left\{ {x}\right\} }\right)}^\succeq$ By [[Set is Subset of Union]]: :$\left\{ {x}\right\} \subseteq F \cup \left\{ {x}\right\}$ and $F \subseteq F \cup \left\{ {x}\right\}$ By definition of [[Definition:Singleton|singleton]]: :$x \in \left\{ {x}\right\}$ By definition of [[Definition:Subset|subset]]: :$x \in {\operatorname{fininfs}\left({F \cup \left\{ {x}\right\} }\right)}^\succeq$ By [[Finite Infima Set and Upper Closure is Filter]]: :${\operatorname{fininfs}\left({F \cup \left\{ {x}\right\} }\right)}^\succeq$ is [[Definition:Filter|filter]] in $L$. By [[Subset Relation is Transitive]]: :$F \subseteq {\operatorname{fininfs}\left({F \cup \left\{ {x}\right\} }\right)}^\succeq$ By definition of [[Definition:Ultrafilter (Order Theory)|ultrafilter]]: :${\operatorname{fininfs}\left({F \cup \left\{ {x}\right\} }\right)}^\succeq = S$ By [[Finite Subset Bounds Element of Finite Infima Set and Upper Closure]]: :$\exists a \in S: a \in F \land \neg x \succeq a \wedge \inf \left\{ {x}\right\}$ By definition of [[Definition:Greatest Element|greatest element]]: :$a \preceq \top$ {{begin-eqn}} {{eqn | l = a | r = a \wedge \top | c = [[Preceding iff Meet equals Less Operand]] }} {{eqn | r = a \wedge \left({x \vee \neg x}\right) | c = definition of [[Definition:Boolean Algebra|Boolean algebra]] }} {{eqn | r = a \wedge x \vee a \wedge \neg x | c = definition of [[Definition:Distributive Lattice|distributive lattice]] }} {{end-eqn}} By [[Infimum of Singleton]]: :$\inf \left\{ {x}\right\} = x$ By [[Meet Precedes Operands]]: :$a \wedge \neg x \preceq \neg x$ By definition of [[Definition:Infimum of Set|infimum]]: :$a \preceq \neg x$ By definition of [[Definition:Upper Set|upper set]]: :$\neg x \in F$ This contradicts $\neg x \notin F$ Thus by [[Proof by Contradiction]]: :$F$ is a [[Definition:Prime Filter (Order Theory)|prime filter]] by [[Filter is Prime iff For Every Element Element either Negation Belongs to Filter in Boolean Lattice]]. {{qed}}	1
{{BeginTableau|p \vdash q \implies p}} {{Premise|1|p}} {{Addition|2|1|\neg q \lor p|1|2}} {{SequentIntro|3|1|q \implies p|1|[[Rule of Material Implication/Formulation 1/Reverse Implication|Rule of Material Implication]]}} {{EndTableau}} {{qed}}	1
{{BeginTableau|p \iff \top \vdash p}} {{Premise|1|p \iff \top}} {{TopIntro|2}} {{BiconditionalElimination|3|1|\top \implies p|1|2}} {{ModusPonens|4|1|p|2|3}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|p \vdash p \iff \top}} {{Premise|1|\top}} {{Assumption|2|p}} {{TopIntro|3}} {{Implication|4||p \implies \top|2|3}} {{Implication|5|2|\top \implies p|1|2}} {{BiconditionalIntro|6|2|p \iff \top|4|5}} {{EndTableau}} {{qed}}	1
We apply the [[Method of Truth Tables]]. $\begin{array}{|c||ccc|} \hline q & p & \lor & q \\ \hline F & F & F & F \\ T & F & T & T \\ F & T & T & F \\ T & T & T & T \\ \hline \end{array}$ As can be seen, when $q$ is [[Definition:True|true]] so is $p \lor q$. {{qed}}	1
Let $f: \N^k \to \N$ be a [[Definition:URM Computability#Function|URM computable function]]. Then by hypothesis there is a [[Definition:URM Program|URM program]] that computes $f$. Let $P$ be the [[Definition:URM Program|URM program]] with the smallest [[Unique Code for URM Program|code number]] that computes $f$. Let $e = \gamma \left({P}\right)$ be the [[Unique Code for URM Program|code number]] of $P$. Consider the [[Definition:Function|function]] $g: \N^k \to \N$ given by: :$g \left({n_1, n_2, \ldots, n_k}\right) \approx \mu t \left({\left({S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)}\right)_1 > \operatorname{len} \left({e}\right)}\right)$ where: * $\operatorname{len} \left({e}\right)$ is the [[Definition:Length of an Integer|length of $e$]]; * $\mu t$ is the [[Definition:Minimization|minimization operation]] on $S_k$; * $\approx$ denotes [[Definition:Partial Function Equality|partial function equality]]; * $S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)$ is the [[Unique Code for State of URM Program|state code]] at [[Definition:Unlimited Register Machine#Stage of Computation|stage]] $t$ of the computation of $P$ with input $\left({n_1, n_2, \ldots, n_k}\right)$; * the number $\left({S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)}\right)_1$ is the [[Unique Code for URM Instruction|code number]] of the instruction about to be carried out at stage $t$. So the inequality: :$\left({S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)}\right)_1 > \operatorname{len} \left({e}\right)$ expresses the fact that at stage $t$ the computation has halted. So the value of $g \left({n_1, n_2, \ldots, n_k}\right)$ is the [[Unique Code for State of URM Program|state code]] of the first stage at which computation has halted, if there is one, and undefined otherwise. Since the functions in this inequality, and the sign $>$ itself, are all [[:Category:Primitive Recursive Functions|primitive recursive]], it follows that the inequality expresses a [[Definition:Primitive Recursive Relation|primitive recursive relation]] on $e, n_1, n_2, \ldots, n_k, t$. Thus $g$ is a [[Definition:Recursive Function|recursive function]] by definition, as it can be obtained by [[Definition:Minimization|minimization]] on a [[Definition:Recursive Relation|recursive relation]]. Now consider the [[Definition:Function|function]] $h: \N^k \to \N$ given by: :$h \left({n_1, n_2, \ldots, n_k}\right) \approx S_k \left({e, n_1, n_2, \ldots, n_k, g \left({n_1, n_2, \ldots, n_k}\right)}\right)$. This is [[Definition:Recursive Function|recursive]] because it was obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from known [[Definition:Recursive Function|recursive functions]]. Now $h \left({n_1, n_2, \ldots, n_k}\right)$ is defined iff the computation [[Definition:Unlimited Register Machine#Termination|halts]], and it gives the value of the state code when it has halted. The output of this computation, which gives the value of $f$, is the number in [[Definition:Unlimited Register Machine#Registers|register]] $R_1$. But the number in $R_1$ is the [[Definition:Exponent|exponent]] of $p_2 = 3$ in the expression of the [[Unique Code for State of URM Program|state code]] $h \left({n_1, n_2, \ldots, n_k}\right)$ in the form $p_1^a p_2^{r_1} p_3^{r_2} \cdots p_{k+1}^{r_k}$. Thus the function $f$ is given by: :$f \left({n_1, n_2, \ldots, n_k}\right) \approx \left({h \left({n_1, n_2, \ldots, n_k}\right)}\right)_2$. It follows that $f$ is a [[Definition:Recursive Function|recursive function]], since it is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from known [[Definition:Recursive Function|recursive functions]]. {{qed}}	1
:$\vdash \paren {\neg p \land \neg q} \iff \paren {\neg \paren {p \lor q} }$	1
We observe that: :$\exp \left({n, 0}\right) = n^0 = 1$ and that :$\exp \left({n, m + 1}\right) = n^\left({m + 1}\right) = \left({n^m}\right) \times n = \operatorname{mult} \left({\exp \left({n, m}\right), n}\right)$. Thus $\exp$ is defined by [[Definition:Primitive Recursion|primitive recursion]] from the [[Multiplication is Primitive Recursive|primitive recursive function $\operatorname{mult}$]]. Hence the result. {{qed}} [[Category:Primitive Recursive Functions]] f7a3x2f6ck2r58nl30z8om71yn89ep0	1
To save space, we will refer to: : The [[Well-Ordering Principle]] as '''[[Well-Ordering Principle|WOP]]''' : The [[Principle of Finite Induction]] as '''[[Principle of Finite Induction|PFI]]''' : The [[Principle of Complete Finite Induction]] as '''[[Principle of Complete Finite Induction|PCI]]'''. === [[Equivalence of Well-Ordering Principle and Induction/Proof/PFI implies PCI|PFI implies PCI]] === {{:Equivalence of Well-Ordering Principle and Induction/Proof/PFI implies PCI}}{{qed|lemma}} === [[Equivalence of Well-Ordering Principle and Induction/Proof/PCI implies WOP|PCI implies WOP]] === {{:Equivalence of Well-Ordering Principle and Induction/Proof/PCI implies WOP}}{{qed|lemma}} === [[Equivalence of Well-Ordering Principle and Induction/Proof/WOP implies PFI|WOP implies PFI]] === {{:Equivalence of Well-Ordering Principle and Induction/Proof/WOP implies PFI}}{{qed|lemma}} === Final assembly === So, we have that: * [[Equivalence of Well-Ordering Principle and Induction/Proof/PFI implies PCI|PFI implies PCI]]: The [[Principle of Mathematical Induction]] implies the [[Principle of Complete Induction]] * [[Equivalence of Well-Ordering Principle and Induction/Proof/PCI implies WOP|PCI implies WOP]]: The [[Principle of Complete Induction]] implies the [[Well-Ordering Principle]] * [[Equivalence of Well-Ordering Principle and Induction/Proof/WOP implies PFI|WOP implies PFI]]: The [[Well-Ordering Principle]] implies the [[Principle of Mathematical Induction]]. This completes the result. {{Qed}}	1
:$p \implies \neg q \dashv \vdash q \implies \neg p$	1
:$p \implies q \vdash \neg q \implies \neg p$	1
: $p \implies \left({q \implies r}\right) \dashv \vdash \left({p \implies q}\right) \implies \left({p \implies r}\right)$	1
Let $f: \N^k \to \N$ and $g: \N^k \to \N$ be [[Definition:Recursive Function|recursive functions]] (not necessarily [[Definition:Total Function|total]]), where $k \ge 1$. Let $\mathcal R$ be a [[Definition:Relation|$k$-ary relation]] such that: : if $\mathcal R \left({n_1, n_2, \ldots, n_k}\right)$ holds, then $f \left({n_1, n_2, \ldots, n_k}\right)$ is defined : if $\mathcal R \left({n_1, n_2, \ldots, n_k}\right)$ does not hold, then $g \left({n_1, n_2, \ldots, n_k}\right)$ is defined. Let $h: \N^k \to \N$ be the [[Definition:Function|function]] defined as: :$h \left({n_1, n_2, \ldots, n_k}\right) = \begin{cases} f \left({n_1, n_2, \ldots, n_k}\right) & : \text{if } \mathcal R \left({n_1, n_2, \ldots, n_k}\right) \text { holds} \\ g \left({n_1, n_2, \ldots, n_k}\right) & : \text{otherwise} \end{cases}$ so that $h$ is [[Definition:Total Function|total]]. Then $h$ is [[Definition:Recursive Function|recursive]].	1
:$\forall a: a = a$	1
The [[Definition:Higher Derivative|$n$th derivative]] of $\map \ln x$ for $n \ge 1$ is: :$\dfrac {\d^n} {\d x^n} \ln x = \dfrac {\paren {n - 1}! \paren {-1}^{n - 1} } {x^n}$	1
: $\vdash \left({\left({p \lor q}\right) \land \left({p \implies r}\right) \land \left({q \implies r}\right)}\right) \implies r$	1
Let $\mathbf H$ be a collection of [[Definition:WFF of Propositional Logic|WFFs of propositional logic]]. Suppose there exists a [[Definition:Tableau Confutation|tableau confutation]] of $\mathbf H$. Then $\mathbf H$ is [[Definition:Unsatisfiable|unsatisfiable]] for [[Definition:Boolean Interpretation|boolean interpretations]].	1
{{BeginTableau|\vdash \left({p \iff q}\right) \iff \left({\left({p \lor q}\right) \implies \left({p \land q}\right)}\right)}} {{Assumption|1|p \iff q}} {{SequentIntro|2|1|\left({p \lor q}\right) \implies \left({p \land q}\right)|1|[[Biconditional iff Disjunction implies Conjunction/Formulation 1|Biconditional iff Disjunction implies Conjunction: Formulation 1]]}} {{Implication|3||\left({p \iff q}\right) \implies \left({\left({p \lor q}\right) \implies \left({p \land q}\right)}\right)|1|2}} {{Assumption|4|\left({p \lor q}\right) \implies \left({p \land q}\right)}} {{SequentIntro|5|4|p \iff q|4|[[Biconditional iff Disjunction implies Conjunction/Formulation 1|Biconditional iff Disjunction implies Conjunction: Formulation 1]]}} {{Implication|6||\left({\left({p \lor q}\right) \implies \left({p \land q}\right)}\right) \implies \left({p \iff q}\right)|4|5}} {{BiconditionalIntro|7||\left({p \iff q}\right) \iff \left({\left({p \lor q}\right) \implies \left({p \land q}\right)}\right)|3|6}} {{EndTableau}} {{qed}} [[Category:Biconditional iff Disjunction implies Conjunction]] nd5xg35tyu3oguip3lvunbq029yqv73	1
Let $Q$ be a [[Definition:Valid Argument|valid]] [[Definition:Categorical Syllogism|categorical syllogism]]. Then at least one of the [[Definition:Premise of Syllogism|premises]] of $Q$ is [[Definition:Universal Categorical Statement|universal]].	1
These [[Definition:Set|sets]] of [[Definition:Logical Connective|logical connectives]] are ''not'' [[Definition:Functionally Complete|functionally complete]].	1
: $p \iff q \vdash \left({p \land q}\right) \lor \left({\neg p \land \neg q}\right)$	1
The proof proceeds by [[Principle of Mathematical Induction|mathematical induction]]. For all $n \in \N_{> 0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\displaystyle \sum_{i \mathop = 1}^n x_i + \sum_{i \mathop = 1}^n y_i = \sum_{i \mathop = 1}^n \paren {x_i + y_i}$ === Basis for the Induction === $\map P 1$ is the case: {{begin-eqn}} {{eqn | l = \sum_{i \mathop = 1}^1 x_i + \sum_{i \mathop = 1}^1 y_i | r = x_1 + y_1 }} {{eqn | r = \sum_{i \mathop = 1}^1 \paren {x_i + y_i} }} {{end-eqn}} This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is the [[Definition:Induction Hypothesis|induction hypothesis]]: :$\displaystyle \sum_{i \mathop = 1}^k x_i + \sum_{i \mathop = 1}^k y_i = \sum_{i \mathop = 1}^k \paren {x_i + y_i}$ from which it is to be shown that: :$\displaystyle \sum_{i \mathop = 1}^{k + 1} x_i + \sum_{i \mathop = 1}^{k + 1} y_i = \sum_{i \mathop = 1}^{k + 1} \paren {x_i + y_i}$ === Induction Step === This is the [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \sum_{i \mathop = 1}^{k + 1} x_i + \sum_{i \mathop = 1}^{k + 1} y_i | r = \paren {\sum_{i \mathop = 1}^k x_i + x_{k + 1} } + \paren {\sum_{i \mathop = 1}^k y_i + y_{k + 1} } | c = {{Defof|Summation}} }} {{eqn | r = \left({\sum_{i \mathop = 1}^k x_i + \sum_{i \mathop = 1}^k y_i}\right) + \paren {x_{k + 1} + y_{k + 1} } | c = [[Commutative Law of Addition]] and [[Associative Law of Addition|Associative]] }} {{eqn | r = \sum_{i \mathop = 1}^k \paren {x_i + y_i} + \paren {x_{k + 1} + y_{k + 1} } | c = [[Summation is Linear/Sum of Summations#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \sum_{i \mathop = 1}^{k + 1} \paren {x_i + y_i} | c = {{Defof|Summation}} }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\displaystyle \forall n \in \N_{> 0}: \sum_{i \mathop = 1}^n x_i + \sum_{i \mathop = 1}^n y_i = \sum_{i \mathop = 1}^n \paren {x_i + y_i}$ {{qed}} [[Category:Numbers]] [[Category:Proofs by Induction]] ibolccjs5zc8erhwzq2a6bct6mfwewf	1
Let $\mathbf A$ be a [[Definition:WFF of Propositional Logic|WFF of propositional logic]]. Let $\mathbf S$ be an [[Definition:Initial Part|initial part]] of $\mathbf A$. Then $\mathbf S$ is not a [[Definition:WFF of Propositional Logic|WFF of propositional logic]].	1
Let $T$ be a [[Definition:Finite Propositional Tableau|finite propositional tableau]]. Let $\Gamma$ be a [[Definition:Branch (Graph Theory)|branch]] of $T$. Then $\Gamma$ is a [[Definition:Finite Branch|finite branch]].	1
A '''statement form''' is a symbolic representation of a [[Definition:Compound Statement|compound statement]]. It consists of [[Definition:Statement Variable|statement variables]] along with [[Definition:Logical Connective|logical connectives]] joining them. It is traditional, particularly in the field of [[Definition:Mathematical Logic|mathematical logic]], to use lowercase [[Symbols:Greek Alphabet|Greek]] letters to stand for general formulas (the usual ones being $\phi, \psi$ and $\chi$), but more modern treatments are starting to use ordinary lowercase letters of the English alphabet, usually $p, q, r$ etc. === [[Definition:Statement Form/Specific Form|Specific Form]] === {{:Definition:Statement Form/Specific Form}}	1
:$p \uparrow \left({q \uparrow r}\right) \not \vdash \left({p \uparrow q}\right) \uparrow r$	1
{{BeginTableau|p \implies q, \neg q \vdash \neg p}} {{Premise|1|p \implies q}} {{Premise|2|\neg q}} {{ModusTollens|3|1, 2|\neg p|1|2}} {{EndTableau}} {{Qed}}	1
Define $T$ as: :$T = \set {n \in \N : \forall k: 0 \le k \le n: k \in S}$ Since $n \le n$, it follows that $T \subseteq S$. Therefore, it will suffice to show that: :$\forall n \ge 0: n \in T$ Firstly, we have that $0 \in T$ {{iff}} the following condition holds: :$\forall k: 0 \le k \le 0 \implies k \in S$ Since $0 \in S$, it thus follows that $0 \in T$. Now suppose that $n \in T$; that is: :$\forall k: 0 \le k \le n \implies k \in S$ By $(2)$, this implies: :$n + 1 \in S$ Thus, we have: :$\forall k: 0 \le k \le n + 1 \implies k \in S$ {{MissingLinks|[[Closed Interval of Naturally Ordered Semigroup with Successor equals Union with Successor]] for $\N$}} Therefore, $n + 1 \in T$. Hence, by the [[Principle of Finite Induction]]: :$\forall n \ge 0: n \in T$ That is: :$T = \N$ and as $S \subseteq \N$ it follows that: :$S = N$ {{Qed}} [[Category:Second Principle of Finite Induction]] 4mwpf2fajzm72tpav4jdn67u9l0guw1	1
:$\vdash p \implies \paren {\neg p \implies q}$	1
If $T$ is both [[Definition:Consistent (Logic)|consistent]] and [[Definition:Complete Theory|complete]], it does not contain [[Definition:Minimal Arithmetic|minimal arithmetic]].	1
Let $T$ be the [[Definition:Set|set]] of [[Definition:Theorem of Logic|theorems]] of some [[Definition:Recursive Set|recursive set]] of [[Definition:Sentence|sentences]] in the [[Definition:Language of Arithmetic|language of arithmetic]] such that $T$ contains [[Definition:Minimal Arithmetic|minimal arithmetic]]. $T$ cannot be both [[Definition:Consistent (Logic)|consistent]] and [[Definition:Complete Theory|complete]].	1
: $\neg \left({\neg p \land \neg q}\right) \vdash p \lor q$	1
A '''formal semantics''' for $\mathcal L$ comprises: * A collection of [[Definition:Object|objects]] called '''structures'''; * A notion of '''validity''' of $\mathcal L$-[[Definition:Well-Formed Formula|WFFs]] in these structures. Often, a '''formal semantics''' provides these by using a lot of auxiliary definitions.	1
In [[Definition:Aristotelian Logic|Aristotelian logic]], a [[Definition:Statement|statement]] can be either [[Definition:True|true]] or [[Definition:False|false]], and there is no undefined, in-between value. Whether it is [[Definition:True|true]] or [[Definition:False|false]] is called its '''truth value'''. Note that a [[Definition:Statement|statement's]] '''truth value''' may change depending on circumstances. Thus, the [[Definition:Statement|statement]]: :''It is currently raining on the grass outside my window'' has the truth value [[Definition:False|false]], whereas it had the truth value [[Definition:True|true]] last week. The statement: :''I am listening to Shostakovich's 4th symphony'' is currently [[Definition:True|true]], but that will last only for the next twenty minutes or so as I type. The '''truth values''' [[Definition:True|true]] and [[Definition:False|false]] are usually represented in one of two ways: :$\T$ for [[Definition:True|true]] and $\F$ for [[Definition:False|false]]; :$1$ for [[Definition:True|true]] and $0$ for [[Definition:False|false]]. There are advantages for both notations. In particular, the second lends itself to extending the discipline of [[Definition:Logic|logic]] into that of [[Definition:Probability Theory|probability theory]].	1
We have: {{begin-eqn}} {{eqn | l = \map f {n_1, n_2, \ldots, n_l} | r = \map {g_1} {n_1, n_2, \ldots, n_l} \times \map {\chi_{\mathcal R_1} } {n_1, n_2, \ldots, n_l} | c = }} {{eqn | o = | ro= + | r = \map {g_2} {n_1, n_2, \ldots, n_l} \times \map {\chi_{\mathcal R_2} } {n_1, n_2, \ldots, n_l} | c = }} {{eqn | o = | ro= + | r = \cdots | c = }} {{eqn | o = | ro= + | r = \map {g_k} {n_1, n_2, \ldots, n_l} \times \map {\chi_{\mathcal R_k} } {n_1, n_2, \ldots, n_l} | c = }} {{end-eqn}} because if $\tuple {n_1, n_2, \ldots, n_l} \in \N^k$, there is a unique $r$ such that $\map {\mathcal R_r} {n_1, n_2, \ldots, n_l}$. Then $\map {\chi_{\mathcal R_r} } {n_1, n_2, \ldots, n_l} = 1$ and $\map {\chi_{\mathcal R_s} } {n_1, n_2, \ldots, n_l} = 0$ for $s \ne r$. Then the value of the {{RHS}} is $\map {g_r} {n_1, n_2, \ldots, n_l}$ as required. Since $\mathcal R_1, \mathcal R_2, \ldots, \mathcal R_k$ are [[Definition:Primitive Recursive Relation|primitive recursive]], the functions $\chi_{\mathcal R_1}, \chi_{\mathcal R_2}, \ldots, \chi_{\mathcal R_k}$ are [[Definition:Primitive Recursive Function|primitive recursive]] as well. Hence $f$ is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from: :the [[Addition is Primitive Recursive|primitive recursive function $\operatorname{add}$]] :the [[Definition:Primitive Recursive Function|primitive recursive functions]] $g_j$ :the [[Definition:Primitive Recursive Function|primitive recursive functions]] $\chi_{\mathcal R_j}$. Hence the result. {{Qed}} === Proof of Corollary === Immediate from the main proof and [[Set Operations on Primitive Recursive Relations]]. {{qed}} [[Category:Primitive Recursive Functions]] 0o99l3ecimzdexg51bsckelv6epgk5z	1
{{handwaving}} By the [[Definition:Definitional Abbreviation|definitional abbreviation]] for the [[Definition:Conditional|conditional]]: :$\mathbf A \implies \mathbf B =_{\text{def}} \neg \mathbf A \lor \mathbf B$ the [[Rule of Addition/Sequent Form/Formulation 2/Form 2|Rule of Addition]] can be written as: : $\neg q \lor \left({p \lor q}\right)$ This evaluates as follows: :$\begin{array}{|cc|c|ccc|} \hline \neg & q & \lor & (p & \lor & q) \\ \hline 1 & 0 & 0 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 & 0 & 1 \\ 3 & 2 & 0 & 0 & 0 & 2 \\ 0 & 3 & 0 & 0 & 0 & 3 \\ 1 & 0 & 0 & 1 & 0 & 0 \\ 0 & 1 & 0 & 1 & 1 & 1 \\ 3 & 2 & 0 & 1 & 2 & 2 \\ 0 & 3 & 0 & 1 & 3 & 3 \\ 1 & 0 & 0 & 2 & 0 & 0 \\ 0 & 1 & 0 & 2 & 2 & 1 \\ 3 & 2 & 0 & 2 & 2 & 2 \\ 0 & 3 & 0 & 2 & 0 & 3 \\ 1 & 0 & 0 & 3 & 0 & 0 \\ 0 & 1 & 0 & 3 & 3 & 1 \\ 3 & 2 & 0 & 3 & 0 & 2 \\ 0 & 3 & 0 & 3 & 3 & 3 \\ \hline \end{array}$ {{qed}} [[Category:Formal Semantics]] 9qn6oodis4tald5nfqxy6512l4cavu8	1
From the [[Rule of Conjunction/Proof Rule|Rule of Conjunction]], we note the following. Any sequent: :$P_1, P_2 \vdash Q$ can be expressed as: :$P_1 \land p_2 \vdash Q$ Also, from the [[Rule of Simplification/Proof Rule|Rule of Simplification]], any [[Definition:Sequent|sequent]]: :$P_1 \land P_2 \vdash Q$ can be expressed as: :$P_1, P_2 \vdash Q$ Consider the expression: :$P_1, P_2, P_3, \ldots, P_{n - 1}, P_n \vdash Q$ By repeated application of the above, we can arrive at: :$P_1 \land \paren {P_2 \land \paren {P_3 \land \paren {\ldots \land \paren {P_{n - 1} \land P_n} \ldots} } } \vdash Q$ For convenience, the [[Rule of Substitution]] can be used to substitute $R_1$ for: :$P_2 \land \paren {P_3 \land \paren {\ldots \land \paren {P_{n - 1} \land P_n} \ldots} }$ to get: :$P_1 \land R_1 \vdash Q$ From the [[Rule of Implication]]: :$\vdash \paren {P_1 \land R_1} \implies Q$ Using the [[Rule of Exportation]], we then get: :$\vdash P_1 \implies \paren {R_1 \implies Q}$ Substituting back for $R_1$: :$\vdash P_1 \implies \paren {\paren {P_2 \land \paren {P_3 \land \paren {\ldots \land \paren {P_{n - 1} \land P_n} \ldots} } } \implies Q}$ Making a [[Rule of Substitution|substitution]] of convenience again, substitute $R_2$ for: :$P_3 \land \paren {\ldots \land \paren {P_{n - 1} \land P_n} \ldots}$ Take the expression: :$\paren {P_2 \land R_2} \implies Q$ and express it as: :$P_2 \land R_2 \vdash Q$ and use the [[Rule of Exportation]] to get: :$P_2 \implies \paren {R_2 \implies Q}$ which, substituting back for $R_2$, gives: :$P_2 \implies \paren {\paren {P_3 \land \paren {\ldots \land \paren {P_{n - 1} \land P_n} \ldots} } \right) \implies Q}$ Similarly: :$\paren {P_3 \land \paren {\ldots \land \paren {P_{n - 1} \land P_n} \ldots} } \implies Q$ converts to: :$P_3 \implies \paren {\paren {\ldots \land \paren {P_{n - 1} \land P_n} \ldots} \implies Q}$ The pattern becomes apparent. Eventually: :$\paren {P_{n - 1} \land P_n} \implies Q$ which converts to: :$P_{n - 1} \implies \paren {P_n \implies Q}$ Substituting these back into our original expression: :$\vdash P_1 \implies \paren {P_2 \implies \paren {P_3 \implies \paren {\ldots \implies \paren {P_n \implies Q} \ldots} } }$ {{qed}}	1
By the [[Definition:Definitional Abbreviation|definitional abbreviation]] for the [[Definition:Conditional|conditional]]: :$\mathbf A \implies \mathbf B =_{\text{def}} \neg \mathbf A \lor \mathbf B$ the [[Rule of Commutation/Disjunction/Formulation 2/Forward Implication|Rule of Commutation]] can be written as: :$\neg \left({p \lor q}\right) \lor \left({q \lor p}\right)$ This evaluates as follows: :$\begin{array}{|cccc|c|ccc|} \hline \neg & (p & \lor & q) & \lor & (q & \lor & p) \\ \hline 2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 2 & 0 & 0 & 1 & 0 & 1 & 0 & 0 \\ 2 & 0 & 0 & 2 & 0 & 2 & 0 & 0 \\ 2 & 1 & 0 & 0 & 0 & 0 & 0 & 1 \\ 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\ 0 & 1 & 2 & 2 & 0 & 2 & 2 & 1 \\ 2 & 2 & 0 & 0 & 0 & 0 & 0 & 2 \\ 0 & 2 & 2 & 1 & 0 & 1 & 2 & 2 \\ 0 & 2 & 2 & 2 & 0 & 2 & 2 & 2 \\ \hline \end{array}$ {{qed}} [[Category:Formal Semantics]] 04e31w1poro9dfijnymy5oqr9occrh6	1
Consider a game of [[Definition:Fibonacci Nim|Fibonacci nim]] with $n$ counters. Let it be the turn of [[Definition:Player|player]] $\text A$. Let the maximum number of counters that can be taken by $\text A$ be $q$. Let $n$ be expressed in [[Definition:Zeckendorf Representation|Zeckendorf representation]] as: :$n = F_{k_1} + F_{k_2} + \cdots + F_{k_r}$ Then $\text A$ can force a win {{iff}}: :$F_{k_r} \le q$ and by taking those $F_{k_r}$ counters.	1
By the [[Definition:Definitional Abbreviation|definitional abbreviation]] for the [[Definition:Conditional|conditional]]: :$\mathbf A \implies \mathbf B =_{\text{def}} \neg \mathbf A \lor \mathbf B$ the [[Factor Principles/Disjunction on Left/Formulation 2|Factor Principle]] can be written as: :$\neg \left({\neg p \lor q}\right) \lor \left({\neg \left({r \lor p}\right) \lor \left ({r \lor q}\right)}\right)$ This evaluates as follows: :$\begin{array}{|ccccc|c|cccccccc|} \hline \neg & (\neg & p & \lor & q) & \lor & (\neg & (r & \lor & p) & \lor & (r & \lor & q)) \\ \hline 1 & 2 & 1 & 2 & 1 & 2 & 2 & 1 & 1 & 1 & 2 & 1 & 1 & 1 \\ 1 & 2 & 1 & 2 & 1 & 2 & 1 & 2 & 2 & 1 & 2 & 2 & 2 & 1 \\ 1 & 2 & 1 & 2 & 2 & 2 & 2 & 1 & 1 & 1 & 2 & 1 & 2 & 2 \\ 1 & 2 & 1 & 2 & 2 & 2 & 1 & 2 & 2 & 1 & 2 & 2 & 2 & 2 \\ 2 & 1 & 2 & 1 & 1 & 2 & 1 & 1 & 2 & 2 & 1 & 1 & 1 & 1 \\ 2 & 1 & 2 & 1 & 1 & 2 & 1 & 2 & 2 & 2 & 2 & 2 & 2 & 1 \\ 1 & 1 & 2 & 2 & 2 & 2 & 1 & 1 & 2 & 2 & 2 & 1 & 2 & 2 \\ 1 & 1 & 2 & 2 & 2 & 2 & 1 & 2 & 2 & 2 & 2 & 2 & 2 & 2 \\ \hline \end{array}$ {{qed}} [[Category:Formal Semantics]] g378broae9uk77f3lxwet48mpsu2f3y	1
Let $\Z_{\ge n_0}$ denote the [[Definition:Set|set]]: :$S = \set {n \in \Z: n \ge n_0}$ Let $S$ be the [[Definition:Set|set]] of [[Definition:Integer|integers]] defined as: :$S = \set {n \in \Z_{\ge n_0}: \map P n}$ That is, the set of all [[Definition:Integer|integers]] for which $n \ge n_0$ and for which $\map P n$ holds. From [[Subset of Set with Propositional Function]] we have that: :$S \subseteq \Z_{\ge n_0}$ From $(1)$ we have that $\map P {n_0}$. Hence $n_0 \in S$. Let $k \in S$. Then $\map P k$ holds. But by $(2)$, $\map P {k + 1}$ also holds. This implies $k + 1 \in S$. So as: :$S \subseteq \Z_{\ge n_0}$ and: :$S$ satisfies $(1)$ and $(2)$ it follows by the [[Principle of Finite Induction]] that $S = \Z_{\ge n_0}$. Hence for all $n \ge n_0$, $\map P n$ holds. {{qed}}	1
{{BeginTableau|p \lor \bot \vdash p}} {{Premise|1|p \lor \bot}} {{Assumption|2|p}} {{Assumption|3|\bot}} {{Explosion|4|3|p|3}} {{ProofByCases|5|1|p|1|2|2|3|4}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|p \vdash p \lor \bot}} {{Premise|1|p}} {{Addition|2|1|p \lor \bot|1|1}} {{EndTableau}} {{qed}}	1
{{BeginTableau|\vdash \paren {p \land q} \iff \paren {\neg \paren {p \implies \neg q} } }} {{Assumption|1|p \land q}} {{SequentIntro|2|1|\neg \paren {p \implies \neg q}|1|[[Conjunction Equivalent to Negation of Implication of Negative/Formulation 1/Forward Implication|Conjunction Equivalent to Negation of Implication of Negative: Formulation 1: Forward Implication]]}} {{Implication|3||\paren {p \land q} \implies \paren {\neg \paren {p \implies \neg q} }|1|2}} {{Assumption|4|\neg \paren {p \implies \neg q} }} {{SequentIntro|5|4|p \land q|4|[[Conjunction Equivalent to Negation of Implication of Negative/Formulation 1/Reverse Implication|Conjunction Equivalent to Negation of Implication of Negative: Formulation 1: Reverse Implication]]}} {{Implication|6||\paren {\neg \paren {p \implies \neg q} \implies \paren {p \land q} }|4|5}} {{BiconditionalIntro|7||\paren {p \land q} \iff \paren {\neg \paren {p \implies \neg q} }|3|6}} {{EndTableau}} {{qed}}	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, in each case, the [[Definition:Truth Value|truth values]] in the appropriate columns match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c|ccc||c|} \hline p & \bot & \implies & p & \top \\ \hline F & F & T & F & T \\ T & F & T & T & T \\ \hline \end{array}$ {{qed}}	1
By the [[Definition:Definitional Abbreviation|definitional abbreviation]] for the [[Definition:Conditional|conditional]]: :$\mathbf A \implies \mathbf B =_{\text{def}} \neg \mathbf A \lor \mathbf B$ the [[Rule of Addition/Sequent Form/Formulation 2/Form 2|Rule of Addition]] can be written as: : $\neg q \lor \left({p \lor q}\right)$ This evaluates as follows: :$\begin{array}{|cc|c|ccc|} \hline \neg & q & \lor & (p & \lor & q) \\ \hline 2 & 1 & 2 & 1 & 1 & 1 \\ 1 & 2 & 2 & 1 & 2 & 2 \\ 2 & 1 & 2 & 2 & 2 & 1 \\ 1 & 2 & 2 & 2 & 2 & 2 \\ \hline \end{array}$ {{qed}} [[Category:Formal Semantics]] rk497e2li883lwe4k6qna1aco309ty8	1
:$p \uparrow q \dashv \vdash q \uparrow p$	1
An '''ambiguity''' is a [[Definition:Statement|statement]] which has more than one [[Definition:Distinct Elements|distinct]] meaning. Thus a [[Definition:Statement|statement]] is '''ambiguous''' if, without extraneous clarification, it can be interpreted in more than one way.	1
Let $S \subseteq \N$ be a [[Definition:Subset|subset]] of the [[Definition:Natural Numbers|natural numbers]]. Suppose that: :$(1): \quad 0 \in S$ :$(2): \quad \forall n \in \N: \paren {\forall k: 0 \le k \le n \implies k \in S} \implies n + 1 \in S$ Then: :$S = \N$	1
Let $\mathscr H$ be [[Definition:Hilbert Proof System/Instance 1|instance 1 of a Hilbert proof system]]. Then the [[Definition:Deduction Rule|deduction rule]]: ::$\dfrac{U,\mathbf A \vdash \mathbf B}{U \vdash \mathbf A \implies \mathbf B}$ is a [[Definition:Derived Rule|derived rule]] for $\mathscr H$.	1
We apply the [[Method of Truth Tables]]. $\begin{array}{|c|c|ccccc|} \hline p & \implies & ((p & \implies & q) & \implies & q)\\ \hline F & T & F & T & F & F & F \\ F & T & F & T & T & T & T \\ T & T & T & F & F & T & F \\ T & T & T & T & T & T & T \\ \hline \end{array}$ As can be seen by inspection, the [[Definition:Main Connective|main connective]] is [[Definition:True|true]] throughout. {{qed}}	1
:$\paren {p \implies q} \land \paren {r \implies s} \vdash \paren {p \land r} \implies \paren {q \land s}$	1
We can immediately see that $\mathbf P$ is [[Definition:Infinite|infinite]] as the number of [[URM Instructions are Countably Infinite|URM instructions is infinite]]. From [[Unique Code for URM Program]], we see that $\gamma: \mathbf P \to \N$ is also an [[Definition:Injection|injection]]. The result follows from [[Domain of Injection to Countable Set is Countable]]. {{qed}} [[Category:URM Programs]] [[Category:Countable Sets]] tf5zjy0plb8azcrkkhzbnumrur7l5sb	1
{{BeginTableau|p \implies q, r \implies s \vdash \neg q \lor \neg s \implies \neg p \lor \neg r}} {{Premise|1|p \implies q}} {{Premise|2|r \implies s}} {{Assumption|3|\neg q \lor \neg s}} {{Assumption|4|\neg q}} {{ModusTollens|5|1, 4|\neg p|1|4}} {{Addition|6|1, 4|\neg p \lor \neg r|5|1}} {{Assumption|7|\neg s}} {{ModusTollens|8|2, 7|\neg r|2|7}} {{Addition|9|2, 7|\neg p \lor \neg r|8|2}} {{ProofByCases|10|1, 2, 3|\neg p \lor \neg r|3|4|6|7|9}} {{Implication|11|1, 2|\neg q \lor \neg s \implies \neg p \lor \neg r|3|10}} {{EndTableau}} {{qed}}	1
Let $J$ be a [[Definition:Set|set]]. Let $p_1, \ldots p_n$ be [[Definition:Polynomial Form|polynomial forms]] in the [[Definition:Indeterminate (Polynomial Theory)|indeterminates]] $\set {X_j : j \in J}$ over a [[Definition:Commutative Ring|commutative ring]] $R$. Suppose that for each $i$ with $1 \le i \le n$, we have, for appropriate $a_{i, k} \in R$: :$p_i = \displaystyle \sum_{k \mathop \in Z} a_{i, k} X^k$ where $Z$ comprises the [[Definition:Multiindex|multiindices]] of [[Definition:Natural Number|natural numbers]] over $J$. Then: :$\displaystyle \prod_{i \mathop = 1}^n p_i = \displaystyle \sum_{k \mathop \in Z} b_k X^k$ where: :$\displaystyle b_k := \sum_{k_1 + \cdots + k_n \mathop = k} \paren {\prod_{i \mathop = 1}^n a_{i, k_i} }$	1
We apply the [[Method of Truth Tables]] to the proposition: :$\left({p \implies q}\right) \iff \left({\lnot p \implies \lnot q}\right)$ $\begin{array}{|ccc|c|ccc|} \hline p & \implies & q) & \iff & (\lnot & p & \implies & \lnot & q) \\ \hline F & T & F & T & T & F & T & T & F \\ F & T & T & F & T & F & F & F & T \\ T & F & F & F & F & T & T & T & F \\ T & T & T & T & F & T & T & F & T \\ \hline \end{array}$ As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] do not match for all [[Definition:Boolean Interpretation|boolean interpretations]]. {{qed}}	1
Let $\mathcal A$ be the [[Definition:Set|set]] of finitely satisfiable extensions of $T$. By the [[Finitely Satisfiable Theory has Maximal Finitely Satisfiable Extension/Lemma|lemma]], for each element $S$ of $\mathcal A$ and each $\mathcal L$-sentence $\phi$, either $S \cup \left\{ {\phi}\right\} \in \mathcal A$ or $S \cup \left\{ {\neg \phi}\right\} \in \mathcal A$. $\mathcal A$ has [[Definition:Finite Character|finite character]], by the following argument: Let $S \in \mathcal A$. Let $F$ be a [[Definition:Finite Subset|finite subset]] of $S$. Then $S$ is satisfiable and hence finitely satisfiable. Thus in $\mathcal A$. Let $S$ be a theory on $\mathcal L$. Let every [[Definition:Finite Subset|finite subset]] of $S$ be finitely satisfiable. Then every [[Definition:Finite Subset|finite subset]] of $S$ is satisfiable. Therefore $S$ is finitely satisfiable. Thus $\mathcal A$ has finite character. By the [[Restricted Tukey-Teichmüller Theorem]], $\mathcal A$ has an element $T'$ such that: :for each $\mathcal L$-sentence $\phi$, either $\phi \in T'$ or $\neg \phi \in T'$. {{qed}}	1
Let $\map V {n, p}$ be a [[Definition:Master Code|master code]] of [[Definition:Length of Sequence|length]] $n$ modulo $p$. Then $\map V {n, p}$ forms a [[Definition:Vector Space|vector space]] over $\Z_p$ of [[Definition:Dimension of Vector Space|$n$ dimensions]].	1
The [[Definition:Successor Function|successor function]] is computed by the following [[Definition:URM Program|URM program]]: {| |- ! align="right" | Line !! ! align="left" | Command |- | align="right" | $1$ || | align="left" | $\map S 1$ |} The [[Definition:Unlimited Register Machine#Input|input]] $n$ is in $R_1$ when the program starts. The program adds $1$ to $r_1$ and then stops. The [[Definition:Unlimited Register Machine#Output|output]] $n + 1$ is in $R_1$ when the program terminates. {{qed}} [[Category:URM Programs]] [[Category:Primitive Recursive Functions]] 4uvfxbgayev57oipuc6m5u5z7apfukr	1
{{BeginTableau|\vdash p \implies \left({\left({p \implies q}\right) \implies q}\right)}} {{Assumption|1|p}} {{Assumption|2|p \implies q}} {{ModusPonens|3|1, 2|q|2|1}} {{Implication|4|1|\left({p \implies q}\right) \implies q|2|3}} {{Implication|5||p \implies \left({\left({p \implies q}\right) \implies q}\right)|1|4}} {{EndTableau}} {{Qed}}	1
:$p \land q \vdash q$	1
:$\bot \implies p \dashv \vdash \top$	1
Let $X$ be the [[Definition:Universal Statement|universal statement]]: :$\forall x \in S: \map P x$ That is: :''[[Definition:Universal Quantifier|For all]] the [[Definition:Element|elements]] $x$ of a given [[Definition:Set|set]] $S$, the [[Definition:Propositional Function|property]] $P$ holds.'' Such a statement may or may not be [[Definition:True|true]]. Let $Y$ be the [[Definition:Existential Statement|existential statement]]: :$\exists y \in S: \neg \map P y$ That is: :''[[Definition:Existential Quantifier|There exists]] at least one [[Definition:Element|element]] $y$ of the [[Definition:Set|set]] $S$ such that the [[Definition:Propositional Function|property]] $P$ does ''not'' hold.'' It follows immediately by [[De Morgan's Laws (Predicate Logic)|De Morgan's laws]] that if $Y$ is [[Definition:True|true]], then $X$ must be [[Definition:False|false]]. Such a statement $Y$ is referred to as a '''counterexample to $X$'''.	1
Let $x \in S$. Then: {{begin-eqn}} {{eqn | l = x \vee \top | r = \paren {x \vee \top} \wedge \top | c = [[Definition:Boolean Algebra/Axioms/Definition 1|Boolean Algebra: Axiom $(\text {BA}_1 3)$]]: $\top$ is the [[Definition:Identity Element|identity]] of $\wedge$ }} {{eqn | r = \paren {x \vee \top} \wedge \paren {x \vee \neg x} | c = [[Definition:Boolean Algebra/Axioms/Definition 1|Boolean Algebra: Axiom $(\text {BA}_1 4)$]]: $x \vee x' = \top$ }} {{eqn | r = x \vee \paren {\top \wedge x'} | c = [[Definition:Boolean Algebra/Axioms/Definition 1|Boolean Algebra: Axiom $(\text {BA}_1 2)$]]: both $\vee$ and $\wedge$ [[Definition:Distributive Operation|distribute]] over the other }} {{eqn | r = x \vee x' | c = [[Definition:Boolean Algebra/Axioms/Definition 1|Boolean Algebra: Axiom $(\text {BA}_1 3)$]]: $\top$ is the [[Definition:Identity Element|identity]] of $\wedge$ }} {{eqn | r = \top | c = [[Definition:Boolean Algebra/Axioms/Definition 1|Boolean Algebra: Axiom $(\text {BA}_1 4)$]] $x \vee x' = \top$ }} {{end-eqn}} So $x \vee \top = \top$. {{qed|lemma}} The result $x \wedge \bot = \bot$ follows from the [[Duality Principle (Boolean Algebras)|Duality Principle]]. {{qed}}	1
{{BeginTableau|\left({p \lor q}\right) \implies r \vdash \left({p \implies r}\right) \land \left({q \implies r}\right)}} {{Premise|1|\left({p \lor q}\right) \implies r}} {{Assumption|2|p}} {{Addition|3|2|p \lor q|2|1}} {{ModusPonens|4|1, 2|r|1|3}} {{Implication|5|1|p \implies r|2|4}} {{Assumption|6|q}} {{Addition|7|6|p \lor q|6|2}} {{ModusPonens|8|1, 6|r|1|7}} {{Implication|9|1|q \implies r|6|8}} {{Conjunction|10|1|\left({p \implies r}\right) \land \left({q \implies r}\right)|5|9}} {{EndTableau}} {{qed}} [[Category:Proof by Cases]] mmig5x5s1otdg7m1su7k3gl33tj9fq7	1
We note that if $m \ne 0$ and $n = m q + r$, we have: :$\dfrac n m = q + \frac r m$ Also note that $\dfrac n m$ and $\dfrac r m$ are [[Definition:Rational Number|rational numbers]] and not necessarily [[Definition:Natural Numbers|natural numbers]]. Indeed, we have: :$0 \le \dfrac r m < 1$ So if $m > 0$ then $\map {\operatorname {quot} } {n, m}$ is the [[Definition:Floor Function|floor]] $\floor {\dfrac n m}$ of $\dfrac n m$. So we have: :$\map {\operatorname {quot} } {n, m} = \begin{cases} 0 & : m = 0 \\ \floor {\dfrac n m} & : m \ne 0 \end{cases}$ Then we see that for $m \ne 0$: :$\floor {\dfrac {n + 1} m} = \begin {cases} \floor {\dfrac n m} + 1 & : m \divides \paren {n + 1} \\ \floor {\dfrac n m} & : \text {otherwise} \end {cases}$ So for $m \ne 0$: :$\map {\operatorname {quot} } {n + 1, m} = \begin{cases} \map {\operatorname {quot} } {n, m} + 1 & : \map \rem {n + 1, m} = 0 \\ \map {\operatorname {quot} } {n, m} & : \map \rem {n + 1, m} \ne 0 \end{cases}$ Now note that: :$\map {\overline {\sgn} } {\map \rem {n + 1, m} } = \begin{cases} 1 & : \map \rem {n + 1, m} = 0 \\ 0 & : \map \rem {n + 1, m} \ne 0 \end{cases}$ So the $\operatorname {quot}$ is defined as: :$\map {\operatorname {quot} } {0, m} = 0$ :$\map {\operatorname {quot} } {n + 1, m} = \map \sgn m \map {\operatorname {quot} } {n, m} + \map {\overline {\sgn} } {\map \rem {n + 1, m} }$ (note that the factor $\map \sgn m$ is needed to cover the case where $m = 0$). Thus $\operatorname {quot}$ is obtained by [[Definition:Primitive Recursion|primitive recursion]] (over the first variable, which is allowed by [[Permutation of Variables of Primitive Recursive Function]]) from the [[Definition:Primitive Recursive Function|primitive recursive functions]]: :[[Signum Function is Primitive Recursive|Signum function $\sgn$]] :[[Remainder is Primitive Recursive|Remainder $\rem$]] :[[Addition is Primitive Recursive|Addition]] :[[Multiplication is Primitive Recursive|Multiplication]]. So it follows that $\operatorname {quot}$ is [[Definition:Primitive Recursive Function|primitive recursive]]. {{qed}} [[Category:Primitive Recursive Functions]] mtvzwief8480pk2jxmsosxrnawnk465	1
Let $\MM, \NN$ be $\LL$-[[Definition:Structure|structures]] such that $\MM$ is a [[Definition:Substructure|substructure]] of $\NN$. {{Disambiguate|Definition:Structure}} Let $\map \phi {\bar x}$ be a [[Definition:Quantifier-Free Formula|quantifier-free $\LL$-formula]], and let $\bar a \in\MM$. Then $\MM \models \map \phi {\bar a}$ {{iff}} $\NN \models \map \phi {\bar a}$.	1
The proof proceeds by [[Principle of Mathematical Induction|induction]] on $m$. For each $m \in \N_{\ge 1}$, let $\map P m$ be the proposition: :$\displaystyle \forall n \in \N: \paren {x_1 + x_2 + \cdots + x_m}^n = \sum_{k_1 \mathop + k_2 \mathop + \mathop \cdots \mathop + k_m \mathop = n} \binom n {k_1, k_2, \ldots, k_m} {x_1}^{k_1} {x_2}^{k_2} \cdots {x_m}^{k_m}$ === Basis for the Induction === Trivially, for all $n \in \N$: {{begin-eqn}} {{eqn | l = \paren {x_1}^n | r = \sum_{k_1 \mathop = n} \frac {n!} {k_1!} {x_1}^{k_1} | c = }} {{eqn | r = \frac {n!} {n!} {x_1}^n | c = }} {{eqn | r = {x_1}^n | c = }} {{end-eqn}} and so it is seen that $\map P 1$ holds. This is the [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that, if $\map P r$ is true, where $r \ge 1$, then it logically follows that $\map P {r + 1}$ is true. So this is the [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$\displaystyle \forall n \in \N: \paren {x_1 + x_2 + \cdots + x_r}^n = \sum_{k_1 \mathop + k_2 \mathop + \mathop \cdots \mathop + k_r \mathop = n} \binom n {k_1, k_2, \ldots, k_r} {x_1}^{k_1} {x_2}^{k_2} \cdots {x_r}^{k_r}$ from which it is to be shown that: :$\displaystyle \forall n \in \N: \paren {x_1 + x_2 + \cdots + x_r + x_{r + 1} }^n = \sum_{k_1 \mathop + k_2 \mathop + \mathop \cdots \mathop + k_r \mathop + k_{r + 1} \mathop = n} \binom n {k_1, k_2, \ldots, k_r, k_{r + 1} } {x_1}^{k_1} {x_2}^{k_2} \cdots {x_r}^{k_r} {x_{r + 1} }^{k_{r + 1} }$ === Induction Step === {{begin-eqn}} {{eqn | o = | r = \paren {x_1 + x_2 + \cdots + x_r + x_{r + 1} }^n }} {{eqn | r = \paren {\paren {x_1 + x_2 + \cdots + x_r} + x_{r + 1} }^n }} {{eqn | r = \sum_{j \mathop = 0}^n \binom n j {x_{r + 1} }^j \paren {x_1 + x_2 + \cdots + x_r}^{n - j} | c = [[Binomial Theorem]] }} {{eqn | r = \sum_{j \mathop = 0}^n \binom n j {x_{r + 1} }^j \sum_{k_1 + k_2 + \cdots + k_r \mathop = n - j} \binom {n - j} {k_1, k_2, \ldots, k_r} {x_1}^{k_1} {x_2}^{k_2} \cdots {x_r}^{k_r} | c = [[Multinomial Theorem#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \sum_{j \mathop = 0}^n \paren {\sum_{k_1 + k_2 + \cdots + k_r \mathop = n - j} \binom n j \binom {n - j} {k_1, k_2, \ldots, k_r} {x_1}^{k_1} {x_2}^{k_2} \cdots {x_r}^{k_r} {x_{r + 1} }^j} | c = [[Summation is Linear]] }} {{eqn | r = \sum_{k_{r + 1} \mathop = 0}^n \paren {\sum_{k_1 + k_2 + \cdots + k_r \mathop = n - k_{r + 1} } \binom n {k_{r + 1} } \binom {n - k_{r + 1} } {k_1, k_2, \ldots, k_r} {x_1}^{k_1} {x_2}^{k_2} \cdots {x_r}^{k_r} {x_{r + 1} }^k_{r + 1} } | c = renaming [[Definition:Index Variable of Summation|index variable]] }} {{eqn | r = \sum_{k_1 + k_2 + \cdots + k_r + k_{r + 1} \mathop = n} \binom n {k_{r + 1} } \binom {n - k_{r + 1} } {k_1, k_2, \ldots, k_r} {x_1}^{k_1} {x_2}^{k_2} \cdots {x_r}^{k_r} {x_{r + 1} }^{k_{r + 1} } | c = collapsing the double sum }} {{end-eqn}} Now: {{begin-eqn}} {{eqn | l = \binom n {k_{r + 1} } \binom {n - k_{r + 1} } {k_1, k_2, \ldots, k_r} | r = \frac {n!} {k_{r + 1}! \paren {n - k_{r + 1} }!} \frac {\paren {n - k_{r + 1} }!} {k_1! \, k_2! \, \cdots k_r!} | c = {{Defof|Binomial Coefficient}} and {{Defof|Multinomial Coefficient}} }} {{eqn | r = \dfrac {n!} {k_1! \, k_2! \, \cdots k_r! \, k_{r + 1}!} }} {{eqn | r = \binom n {k_1, k_2, \ldots, k_r, k_{r + 1} } | c = {{Defof|Multinomial Coefficient}} }} {{end-eqn}} So $\map P r \implies \map P {r + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. {{qed}}	1
{{BeginTableau|\vdash p \implies p}} {{Premise|1|p}} {{Implication|2||p \implies p|1|1}} {{EndTableau}} {{qed}}	1
Let $\mathbf A$ be a [[Definition:WFF of Predicate Logic|WFF of predicate logic]]. Let $Q$ be an [[Definition:Occurrence (Predicate Logic)|occurrence]] of a [[Definition:Quantifier|quantifier]] in $\mathbf A$. Then there exists a unique [[Definition:Well-Formed Part|well-formed part]] of $\mathbf A$ which (omitting outermost [[Definition:Parenthesis|parentheses]]) begins with that [[Definition:Occurrence (Predicate Logic)|occurrence]] $Q$. This unique [[Definition:Well-Formed Part|well-formed part]] of $\mathbf A$ is called the [[Definition:Scope of Quantifier|scope]] of the [[Definition:Occurrence (Predicate Logic)|occurrence]] of $Q$.	1
{{handwaving}} By the [[Definition:Definitional Abbreviation|definitional abbreviation]] for the [[Definition:Conditional|conditional]]: :$\mathbf A \implies \mathbf B =_{\text{def}} \neg \mathbf A \lor \mathbf B$ the [[Factor Principles/Disjunction on Left/Formulation 2|Factor Principle]] can be written as: :$\neg \left({\neg p \lor q}\right) \lor \left({\neg \left({r \lor p}\right) \lor \left ({r \lor q}\right)}\right)$ This evaluates as follows: :$\begin{array}{|ccccc|c|cccccccc|} \hline \neg & (\neg & p & \lor & q) & \lor & (\neg & (r & \lor & p) & \lor & (r & \lor & q)) \\ \hline 0 & 2 & 0 & 0 & 0 & 0 & 2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 0 & 2 & 1 & 0 & 0 & 0 & 2 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\ 0 & 2 & 2 & 0 & 0 & 0 & 2 & 0 & 0 & 2 & 0 & 0 & 0 & 0 \\ 0 & 2 & 0 & 0 & 0 & 0 & 2 & 1 & 0 & 0 & 0 & 1 & 0 & 0 \\ 0 & 2 & 1 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 0 & 1 & 0 & 0 \\ 0 & 2 & 2 & 0 & 0 & 0 & 0 & 1 & 2 & 2 & 0 & 1 & 0 & 0 \\ 0 & 2 & 0 & 0 & 0 & 0 & 2 & 2 & 0 & 0 & 0 & 2 & 0 & 0 \\ 0 & 2 & 1 & 0 & 0 & 0 & 0 & 2 & 2 & 1 & 0 & 2 & 0 & 0 \\ 0 & 2 & 2 & 0 & 0 & 0 & 0 & 2 & 2 & 2 & 0 & 2 & 0 & 0 \\ 0 & 2 & 0 & 0 & 1 & 0 & 2 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\ 1 & 1 & 1 & 1 & 1 & 0 & 2 & 0 & 0 & 1 & 0 & 0 & 0 & 1 \\ 2 & 0 & 2 & 2 & 1 & 0 & 2 & 0 & 0 & 2 & 0 & 0 & 0 & 1 \\ 0 & 2 & 0 & 0 & 1 & 0 & 2 & 1 & 0 & 0 & 2 & 1 & 1 & 1 \\ 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\ 2 & 0 & 2 & 2 & 1 & 0 & 0 & 1 & 2 & 2 & 0 & 1 & 1 & 1 \\ 0 & 2 & 0 & 0 & 1 & 0 & 2 & 2 & 0 & 0 & 2 & 2 & 2 & 1 \\ 1 & 1 & 1 & 1 & 1 & 0 & 0 & 2 & 2 & 1 & 0 & 2 & 2 & 1 \\ 2 & 0 & 2 & 2 & 1 & 0 & 0 & 2 & 2 & 2 & 0 & 2 & 2 & 1 \\ 0 & 2 & 0 & 2 & 2 & 0 & 2 & 0 & 0 & 0 & 0 & 0 & 0 & 2 \\ 0 & 1 & 1 & 2 & 2 & 0 & 2 & 0 & 0 & 1 & 0 & 0 & 0 & 2 \\ 2 & 0 & 2 & 0 & 2 & 0 & 2 & 0 & 0 & 2 & 0 & 0 & 0 & 2 \\ 0 & 2 & 0 & 2 & 2 & 0 & 2 & 1 & 0 & 0 & 2 & 1 & 2 & 2 \\ 0 & 1 & 1 & 2 & 2 & 0 & 1 & 1 & 1 & 1 & 2 & 1 & 2 & 2 \\ 2 & 0 & 2 & 0 & 2 & 0 & 0 & 1 & 2 & 2 & 0 & 1 & 2 & 2 \\ 0 & 2 & 0 & 2 & 2 & 0 & 2 & 2 & 0 & 0 & 2 & 2 & 2 & 2 \\ 0 & 1 & 1 & 2 & 2 & 0 & 0 & 2 & 2 & 1 & 0 & 2 & 2 & 2 \\ 2 & 0 & 2 & 0 & 2 & 0 & 0 & 2 & 2 & 2 & 0 & 2 & 2 & 2 \\ \hline \end{array}$ {{qed}} {{proofread}} [[Category:Formal Semantics]] 2il6dm5w31g149leqiwrt09afiaiw9k	1
{{BeginTableau|\vdash \paren {\neg \paren {p \iff q} } \iff \paren {\paren {\neg p \land q} \lor \paren {p \land \neg q} } }} {{Assumption|1|\neg \paren {p \iff q} }} {{SequentIntro|2|1|\paren {\neg p \land q} \lor \paren {p \land \neg q}|1|[[Non-Equivalence as Disjunction of Conjunctions/Formulation 1|Non-Equivalence as Disjunction of Conjunctions: Formulation 1]]}} {{Implication|3||\paren {\neg \paren {p \iff q} } \implies \paren {\paren {\neg p \land q} \lor \paren {p \land \neg q} }|1|2}} {{Assumption|4|\paren {\neg p \land q} \lor \paren {p \land \neg q} }} {{SequentIntro|5|4|\neg \paren {p \iff q}|4|[[Non-Equivalence as Disjunction of Conjunctions/Formulation 1|Non-Equivalence as Disjunction of Conjunctions: Formulation 1]]}} {{Implication|6||\paren {\paren {\neg p \land q} \lor \paren {p \land \neg q} } \implies \paren {\neg \paren {p \iff q} }|4|5}} {{BiconditionalIntro|7||\paren {\neg \paren {p \iff q} } \iff \paren {\paren {\neg p \land q} \lor \paren {p \land \neg q} }|3|6}} {{EndTableau|qed}}	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, in each case, the [[Definition:Truth Value|truth values]] in the appropriate columns match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c|ccc||cc|} \hline p & p & \oplus & \top & \neg & p \\ \hline F & F & T & T & T & F \\ T & T & F & T & F & T \\ \hline \end{array}$ {{qed}}	1
There exist [[Definition:URM Computability#Function|URM computable functions]] which are not [[Definition:Primitive Recursive Function|primitive recursive]].	1
The following [[Definition:Categorical Syllogism|categorical syllogisms]] are valid: :$\begin{array}{rl} \text{I} & AAA \\ \text{I} & AII \\ \text{I} & EAE \\ \text{I} & EIO \\ * \text{I} & AAI \\ * \text{I} & EAO \\ \end{array} \qquad \begin{array}{rl} \text{II} & EAE \\ \text{II} & AEE \\ \text{II} & AOO \\ \text{II} & EIO \\ * \text{II} & EAO \\ * \text{II} & AEO \\ \end{array} \qquad \begin{array}{rl} \dagger \text{III} & AAI \\ \text{III} & AII \\ \text{III} & IAI \\ \dagger \text{III} & EAO \\ \text{III} & EIO \\ \text{III} & OAO \\ \end{array} \qquad \begin{array}{rl} \S \text{IV} & AAI \\ \text{IV} & AEE \\ \dagger \text{IV} & EAO \\ \text{IV} & EIO \\ \text{IV} & IAI \\ * \text{IV} & AEO \\ \end{array}$ In the above: :$\text{I}, \text{II}, \text{III}, \text{IV}$ denote the four [[Definition:Figure of Categorical Syllogism|figures]] of the [[Definition:Categorical Syllogism|categorical syllogisms]] :$A, E, I, O$ denote the [[Definition:Universal Affirmative|universal affirmative]], [[Definition:Universal Negative|universal negative]], [[Definition:Particular Affirmative|particular affirmative]] and [[Definition:Particular Negative|particular negative]] respectively: see [[Definition:Shorthand for Categorical Syllogism|Shorthand for Categorical Syllogism]] :[[Definition:Categorical Syllogism|Syllogisms]] marked $*$ require the assumption that $\exists x: \map S x$, that is, that there exists an object fulfilling the [[Definition:Secondary Term of Syllogism|secondary predicate]] :[[Definition:Categorical Syllogism|Syllogisms]] marked $\dagger$ require the assumption that $\exists x: \map M x$, that is, that there exists an object fulfilling the [[Definition:Middle Term of Syllogism|middle predicate]] :[[Definition:Categorical Syllogism|Syllogisms]] marked $\S$ require the assumption that $\exists x: \map P x$, that is, that there exists an object fulfilling the [[Definition:Primary Term of Syllogism|primary predicate]]	1
Let $\tau_1, \tau_2$ be [[Definition:Term (Predicate Logic)|terms]]. Suppose that they are [[Definition:Relative Semantic Equivalence of Terms|semantically equivalent]] with respect to the [[Definition:Empty Set|empty set]]. Then $\tau_1 = \tau_2$.	1
:$\left({p \vdash \left({q \land \neg q}\right)}\right) \vdash \neg p$	1
The [[Definition:Conditional|implication operator]] is [[Definition:Left Distributive Operation|left distributive]] over the [[Definition:Conjunction|conjunction operator]]:	1
Let $P$ be the set of axioms of [[Definition:Peano Arithmetic|Peano arithmetic]]. Let $Q = P \cup \left\{{\neg x = 0, \neg x = s0, \neg x = ss0, \ldots}\right\}$ where $x$ is a variable of the language. Then each finite subset of $Q$ is satisfied by the standard model of arithmetic Hence $Q$ is satisfiable by the [[Compactness of First-Order Logic|Compactness theorem]]. But any [[Definition:Model (Logic)|model]] satisfying $Q$ must assign $x$ to an element which cannot be obtained by iterating the successor operator on zero a finite number of times. {{qed}} {{MissingLinks}} {{disambiguate|Definition:Model (Logic)}} [[Category:Mathematical Logic]] m3vzgmfsr7waas32t1qlq8ivfn035pc	1
{{BeginTableau|\left({p \land q}\right) \lor \left({r \land s}\right) \vdash p \lor r}} {{Premise|1|\left({p \land q}\right) \lor \left({r \land s}\right)}} {{Assumption|2|p \land q}} {{Simplification|3|2|p|2|1}} {{Addition|4|2|p \lor r|3|1}} {{Assumption|5|r \land s}} {{Simplification|6|5|r|5|1}} {{Addition|7|5|p \lor r|6|2}} {{ProofByCases|8|1|p \lor r|1|2|4|5|7}} {{EndTableau}} {{qed}} [[Category:Conjunction]] [[Category:Disjunction]] d14jj00x06kg6uslpblnejcpwlls5dt	1
{{BeginTableau|\vdash \paren {p \implies \paren {q \implies r} } \implies \paren {\paren {p \land q} \implies r} }} {{Assumption|1|p \implies \paren {q \implies r} }} {{SequentIntro|2|1|\paren {p \land q} \implies r|1|[[Rule of Exportation/Reverse Implication/Formulation 1|Rule of Exportation: Reverse Implication: Formulation 1]]}} {{Implication|3||\paren {p \implies \paren {q \implies r} } \implies \paren {\paren {p \land q} \implies r}|1|2}} {{EndTableau|qed}}	1
Since $\top$ is the [[Definition:Identity Element|identity]] for $\wedge$, the second condition for $\neg \top$: :$\top \wedge \neg \top = \bot$ implies that $\neg \top = \bot$ is the only possibility. Since $\bot$ is the [[Definition:Identity Element|identity]] for $\vee$, it follows that: :$\top \vee \bot = \top$ and we conclude that: :$\neg \top = \bot$ as desired. {{qed}}	1
:$p \iff q \dashv \vdash \paren {p \lor q} \implies \paren {p \land q}$	1
The proof proceeds by [[Induction on Well-Formed Formulas]] of $P$. $P$ must be of the form: :$x \in y$ :$\left({Q \land R}\right)$ :$\neg Q$ or: :$\forall x: Q$ for some [[Definition:Proposition|propositions]] $Q$ and $R$. === Atoms === Let $P$ be of the form $x \in y$. Then: :$A = \left\{ {x, y}\right\}$ By definition of [[Definition:Standard Structure|standard structure]]: :$B \models P \iff \left({x \in y \land x \in B \land y \in B}\right)$ By definition of [[Definition:Relativisation|relativisation]]: :$\displaystyle P^B \iff x \in y$ If $A \subseteq B$, then: :$x \in B \land y \in B$ and the two statements are equivalent. === Inductive Step for $\neg$ === Let $P$ be of the form $\neg Q$ and that the statement holds for $Q$. Then the [[Definition:Free Variable|free variables]] in $Q$ are precisely those in $P$. {{begin-eqn}} {{eqn | l = A \subseteq B | o = \implies | r = \left({B \models Q \iff Q^B}\right) | c = Inductive Hypothesis }} {{eqn | o = \implies | r = \left({\neg B \models Q \iff \neg Q^B}\right) | c = }} {{eqn | o = \implies | r = \left({B \models P \iff P^B}\right) | c = Definition of $P$ }} {{end-eqn}} === Inductive Step for $\implies$ === Suppose $P$ is of the form $\left({Q \implies R}\right)$. Suppose, further, that the statement holds for $Q$ and $R$. The free variables of $Q$ and $R$ have to all be members of $A$, and thus are members of $B$ since $A \subseteq B$. {{begin-eqn}} {{eqn | l = A \subseteq B | o = \implies | r = \left({B \models Q \iff Q^B}\right) \land \left({B \models R \iff R^B}\right) | c = Inductive Hypothesis }} {{eqn | o = \implies | r = \left({\left({B \models Q \land B \models R}\right) \iff \left({Q^B \land R^B}\right)}\right) | c = }} {{eqn | o = \implies | r = \left({B \models P \iff P^B}\right) | c = Definitions of [[Definition:Standard Structure|Standard Structure]] and [[Definition:Relativisation|Relativisation]] }} {{end-eqn}} === Inductive Step for $\forall x:$ === Let $P$ be of the form: :$\forall x: Q$ Let the statement hold for $Q$. Then the free variables of $Q$ are either in $A$ or $x$. Furthermore, $x \notin A$ because: :$x \in A \implies x$ is a free variable in $\forall x: Q$ which is a contradiction. {{begin-eqn}} {{eqn | l = A \subseteq B \land x \in B | o = \implies | r = \left({B \models Q \iff Q^B}\right) | c = Inductive Hypothesis }} {{eqn | l = A \subseteq B | o = \implies | r = \left({\left({x \in B \implies B \models Q}\right) \iff \left({x \in B \implies Q^B}\right)}\right) | c = Propositional logic manipulation }} {{eqn | o = \implies | r = \left({\forall x \in B: B \models Q \iff \forall x \in B: Q^B}\right) | c = [[Universal Generalization]] }} {{eqn | o = \implies | r = \left({B \models P \iff P^B}\right) | c = Definitions of [[Definition:Standard Structure|Standard Structure]] and [[Definition:Relativisation|Relativisation]] }} {{end-eqn}} {{qed}}	1
{{BeginTableau|\left({\neg p \land q}\right) \lor \left({p \land \neg q}\right) \vdash \neg \left ({p \iff q}\right)}} {{Premise|1|\left ({\neg p \land q}\right) \lor \left ({p \land \neg q}\right)}} {{Commutation|2|1|\left ({p \land \neg q}\right) \lor \left ({\neg p \land q}\right)|1|Disjunction}} {{Commutation|3|1|\left ({p \land \neg q}\right) \lor \left ({q \land \neg p}\right)|2|Conjunction}} {{DoubleNegIntro|4|1|\left ({\neg \neg p \land \neg q}\right) \lor \left ({\neg \neg q \land \neg p}\right)|3}} {{DeMorgan|5|1|\neg \left({\neg p \lor q}\right) \lor \neg \left ({\neg q \lor p}\right)|4|Conjunction of Negations}} {{DeMorgan|6|1|\neg \left({\left ({\neg p \lor q}\right) \land \left ({\neg q \lor p}\right)}\right)|5|Disjunction of Negations}} {{SequentIntro|7|1 |\neg \left({\left ({p \implies q}\right) \land \left ({q \implies p}\right)}\right)|6 |[[Rule of Material Implication]] (twice)}} {{SequentIntro|8|1|\neg \left ({p \iff q}\right)|7|[[Rule of Material Equivalence]]}} {{EndTableau}} {{qed}}	1
A '''property''' is a concept that specifies an aspect of an [[Definition:Object|object]]. In the phrase ''living thing'', ''living'' is a property that ''thing'' has. It creates a distinction between ''things'' that are ''living'' and ''things'' that are ''not living''.	1
:$\vdash p \land q \implies q$	1
{{BeginTableau|\vdash p \lor \neg p}} {{TheoremIntro|1|\neg\neg (p \lor \neg p)|[[Negation of Excluded Middle is False/Form 2]]}} {{DoubleNegElimination|2||p \lor \neg p|1}} {{EndTableau}} {{Qed}}	1
Every [[Definition:Primitive Recursive Set|primitive recursive set]] is [[Definition:URM Computability#Set|URM computable]].	1
We apply the [[Method of Truth Tables]] (trivially) to the proposition. $\begin{array}{|c|c|} \hline p & p \\ \hline F & F \\ T & T \\ \hline \end{array}$ {{qed}}	1
The [[Definition:Relation|relation]] $\operatorname{eq} \subseteq \N^2$, defined as: :$\map {\operatorname {eq} } {n, m} \iff n = m$ is [[Definition:Primitive Recursive Relation|primitive recursive]].	1
This follows directly from: * [[Kleene's Normal Form Theorem]]; * [[Universal URM Computable Functions]]. {{qed}} [[Category:URM Programs]] 557hxwrpy6pu9y2am1yzmuwcl59xj3w	1
:$p \land q \dashv \vdash q \land p$	1
Let $p \implies q$ be a [[Definition:Conditional|conditional]]. Then the [[Definition:Inverse Statement|inverse]] of $p \implies q$ is the [[Definition:Contrapositive Statement|contrapositive]] of its [[Definition:Converse Statement|converse]].	1
{{BeginTableau|\neg \paren {p \iff q} \vdash \paren {p \iff \neg q} }} {{Premise | 1|\neg \paren {p \iff q} }} {{SequentIntro | 2|1|\neg \paren {\paren {p \implies q} \land \paren {q \implies p} }|1|[[Rule of Material Equivalence]]}} {{DeMorgan | 3|1|\neg \paren {p \implies q} \lor \neg \paren {q \implies p} |2|Disjunction of Negations}} {{Assumption | 4|p}} {{IdentityLaw | 5|4|p|4}} {{Assumption | 6|q}} {{Implication | 7|6|p \implies q|4|6}} {{DoubleNegIntro | 8|6|\neg \neg \paren {p \implies q}|7}} {{ModusTollendoPonens | 9|1, 6|\neg \paren {q \implies p}|3|8|1}} {{SequentIntro |10|1, 6|q \land \neg p|9|[[Conjunction with Negative Equivalent to Negation of Implication]]}} {{Simplification |11|1, 6|\neg p|10|2}} {{NonContradiction |12|1, 4, 6|4|11}} {{Contradiction |13|1, 4|\neg q|6|12}} {{Implication |14|1|p \implies \neg q|4|13}} {{Assumption |15|\neg q}} {{IdentityLaw |16|15|\neg q|15}} {{Assumption |17|\neg p}} {{Implication |18|17|\neg q \implies \neg p|16|17}} {{SequentIntro |19|17|p \implies q|18|[[Rule of Transposition]]}} {{ModusTollendoPonens |20|1, 17|\neg \paren {q \implies p} |3|19|1}} {{SequentIntro |21|1, 17|q \land \neg p|20|[[Conjunction with Negative Equivalent to Negation of Implication]]}} {{Simplification |22|1, 17|q|21|1}} {{NonContradiction |23|1, 15, 17|15|22}} {{Contradiction |24|1, 15|p|17|23}} {{Implication |25|1|\neg q \implies p|15|24}} {{BiconditionalIntro |26|1|\paren {p \iff \neg q}|14|25}} {{EndTableau|qed}} {{LEM||3}}	1
{{BeginTableau|\left({p \vdash q}\right) \vdash p \implies q}} {{Premise|1|p}} |- | align="right" | 2 || | align="right" | 1 | $q$ | [[Definition:By Hypothesis|By hypothesis]] | 1 | as $p \vdash q$ {{Implication|3|1|p \implies q|1|2}} {{EndTableau}} {{Qed}}	1
{{ProofWanted|Ongoing}} [[Category:ISBN-10 is Error-Correcting Code]] mwbruqai92ntf6l904fwb5runnoin1b	1
{{BeginTableau|\vdash \paren {p \implies q} \implies \paren {\paren {r \land p} \implies \paren {r \land q} } }} {{Assumption|1|p \implies q}} {{SequentIntro|2|1|\paren {\paren {r \land p} \implies \paren {r \land q} }|1 |[[Factor Principles/Conjunction on Left/Formulation 1|Factor Principles: Conjunction on Left: Formulation 1]]}} {{Implication|3|1|\paren {p \implies q} \implies \paren {\paren {r \land p} \implies \paren {r \land q} }|1|2}} {{EndTableau}} {{qed}}	1
{{BeginTableau|\left({p \implies q}\right) \implies p \vdash p}} {{Premise|1|\left({p \implies q}\right) \implies p}} {{Assumption|2|\neg p}} {{SequentIntro|3|2|p \implies q|2|[[False Statement implies Every Statement]]}} {{ModusPonens|4|1,2|p|1|3}} {{NonContradiction|5|1,2|2|4}} {{Reductio|6|1|p|2|5}} {{EndTableau}} {{qed}}	1
Apply the [[Method of Truth Tables]]: :$\begin{array}{|ccccc||ccccc|} \hline p & \downarrow & (q & \downarrow & r) & (p & \downarrow & q) & \downarrow & r \\ \hline F & F & F & T & F & F & T & F & F & F \\ F & T & F & F & T & F & T & F & F & T \\ F & T & T & F & F & F & F & T & T & F \\ F & T & T & F & T & F & F & T & F & T \\ T & F & F & T & F & T & F & F & T & F \\ T & F & F & F & T & T & F & F & F & T \\ T & F & T & F & F & T & F & T & T & F \\ T & F & T & F & T & T & F & T & F & T \\ \hline \end{array}$ As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] do not match for all [[Definition:Boolean Interpretation|boolean interpretations]]. {{qed}}	1
Let $U$ be a [[Definition:Set|set]] of [[Definition:Propositional Formula|propositional formulas]]. Let $P$ be a [[Definition:Propositional Formula|propositional formula]]. Let $U \models P$ denote that $P$ is a [[Definition:Semantic Consequence|semantic consequence]] of $U$. Then: : $U \models P$ iff: : $U \cup P \models P$	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, in each case, the [[Definition:Truth Value|truth values]] in the appropriate columns match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c|ccc||cc|} \hline p & p & \oplus & \top & \neg & p \\ \hline F & F & T & T & T & F \\ T & T & F & T & F & T \\ \hline \end{array}$ {{qed}}	1
==== [[Biconditional is Associative/Formulation 1|Formulation 1]] ==== {{:Biconditional is Associative/Formulation 1}} ==== [[Biconditional is Associative/Formulation 2|Formulation 2]] ==== {{:Biconditional is Associative/Formulation 2}}	1
: $\neg \left ({p \iff q}\right) \dashv \vdash \left({\neg p \land q}\right) \lor \left({p \land \neg q}\right)$	1
The [[Definition:Set|set]] $\mathbf P$ of all [[Definition:URM Program|URM programs]] is [[Definition:Countable|countably infinite]].	1
{{BeginTableau|\paren {p \lor r} \land \paren {q \lor \neg r} \vdash p \lor q}} {{Premise|1|\paren {p \lor r} \land \paren {q \lor \neg r} }} {{Simplification|2|1|p \lor r|1|1|The aim is to use [[Proof by Cases]] on this ...}} {{Assumption|3|p|Assume the first of the disjuncts ...}} {{Addition|4|3|p \lor q|3|1|... and demonstrate the conclusion}} {{Simplification|5|1|q \lor \neg r|1|2}} {{Commutation|6|1|\neg r \lor q|5|Disjunction}} {{SequentIntro|7|1|r \implies q|6|[[Rule of Material Implication]]}} {{Assumption|8|r| then assume the second of the disjuncts ...}} {{ModusPonens|9|1, 8|q|7|8}} {{Addition|10|1, 8|p \lor q|9|2|... and demonstrate the conclusion}} {{ProofByCases|11|1|p \lor q|2|3|4|8|10}} {{EndTableau}} {{qed}} [[Category:Conjunction]] [[Category:Disjunction]] 8415phdouelyojbky2zc0dg3vml37w2	1
{{BeginTableau|\left({p \lor p}\right) \implies p}} {{Premise|1|p \lor p}} {{Assumption|2|p}} {{ProofByCases|3|1|p|1|2|2|2|2}} {{Implication|4||\left({p \lor p}\right) \implies p|1|3}} {{EndTableau}} {{qed}}	1
: $\left({\neg p \land q}\right) \lor \left({p \land \neg q}\right) \vdash \neg \left ({p \iff q}\right)$	1
{{BeginTableau|\vdash \paren {p \implies q} \implies \paren {\paren {q \implies r} \implies \paren {p \implies r} }|[[Definition:Hilbert Proof System/Instance 1|instance 1 of a Hilbert proof system]]}} {{Assumption|1|p}} {{Assumption|2|p \implies q}} {{ModusPonens|3|1, 2|q|1|2}} {{Assumption|4|q \implies r}} {{ModusPonens|5|1, 2, 4|r|3|4}} {{TableauLine|n = 6 | pool = 2, 4 | f = p \implies r | rlnk = Definition:Deduction Rule | rtxt = Deduction Rule | dep = 5 }} {{TableauLine|n = 7 | pool = 2 | f = \paren {q \implies r} \implies \paren {p \implies r} | rlnk = Definition:Deduction Rule | rtxt = Deduction Rule | dep = 6 }} {{TableauLine|n = 8 | f = \paren {p \implies q} \implies \paren {\paren {q \implies r} \implies \paren {p \implies r} } | rlnk = Definition:Deduction Rule | rtxt = Deduction Rule | dep = 7 }} {{EndTableau}} {{qed}}	1
=== [[Principle of Commutation/Forward Implication/Formulation 2/Proof 1|Proof of Forward Implication]] === {{:Principle of Commutation/Forward Implication/Formulation 2/Proof 1}} === [[Principle of Commutation/Reverse Implication/Formulation 2/Proof|Proof of Reverse Implication]] === {{:Principle of Commutation/Reverse Implication/Formulation 2/Proof}} {{BeginTableau|\vdash \paren {p \implies \paren {q \implies r} } \iff \paren {q \implies \paren {p \implies r} } }} {{TheoremIntro|1|\paren {p \implies \paren {q \implies r} } \implies \paren {q \implies \paren {p \implies r} }|[[Principle of Commutation/Forward Implication/Formulation 2/Proof 1|Principle of Commutation: Forward Implication: Formulation 2]]}} {{TheoremIntro|2|\paren {q \implies \paren {p \implies r} } \implies \paren {p \implies \paren {q \implies r} }|[[Principle of Commutation/Reverse Implication/Formulation 2/Proof|Principle of Commutation: Reverse Implication: Formulation 2]]}} {{BiconditionalIntro|3||\paren {p \implies \paren {q \implies r} } \iff \paren {q \implies \paren {p \implies r} }|1|2}} {{EndTableau}} {{qed}}	1
Let $\mathcal L$ be a [[Definition:Logical Language|logical language]]. Let $\mathscr M$ be a [[Definition:Formal Semantics|formal semantics]] for $\mathcal L$. Let $\mathcal F$ be an [[Definition:Satisfiable Set of Formulas|$\mathscr M$-satisfiable set of formulas]] from $\mathcal L$. Let $\mathcal F'$ be a [[Definition:Subset|subset]] of $\mathcal F$. Then $\mathcal F'$ is also [[Definition:Satisfiable Set of Formulas|$\mathscr M$-satisfiable]].	1
:$\vdash \paren {p \implies \paren {q \implies r} } \implies \paren {\paren {p \land q} \implies r}$	1
No [[Definition:Categorical Syllogism|categorical syllogism]] of which both [[Definition:Premise of Syllogism|premises]] are [[Definition:Negative Categorical Statement|negative categorical statements]] is [[Definition:Valid Argument|valid]].	1
Let $v_T$ be the [[Definition:Boolean Interpretation|boolean interpretation]] that assigns $T$ to each [[Definition:Propositional Symbol|propositional symbol]]. Then it follows by the nature of the [[Definition:Truth Function|truth functions]] for $\land$ and $\lor$ that: :$\map {v_T} {\mathbf A} = T$ for each [[Definition:WFF of Propositional Logic|WFF]] $\mathbf A$ comprising only $\land$ and $\lor$. On the other hand: :$\map {v_T} {\neg p} = F$ Therefore, $\neg p$ cannot be expressed in terms of $\land$ and $\lor$. Hence, $\set {\land, \lor}$ is not [[Definition:Functionally Complete|functionally complete]]. {{qed}}	1
{{BeginTableau|\vdash \paren {p \land \paren {q \lor r} } \iff \paren {\paren {p \land q} \lor \paren {p \land r} } }} {{Assumption|1|p \land \paren {q \lor r} }} {{SequentIntro|2|1|\paren {\paren {p \land q} \lor \paren {p \land r} }|1|[[Rule of Distribution/Conjunction Distributes over Disjunction/Left Distributive/Formulation 1/Forward Implication|Conjunction is Left Distributive over Disjunction: Formulation 1]]}} {{Implication|3||\paren {p \land \paren {q \lor r} } \implies \paren {\paren {p \land q} \lor \paren {p \land r} }|1|2}} {{Assumption|4|\paren {p \land q} \lor \paren {p \land r} }} {{SequentIntro|5|4|p \land \paren {q \lor r}|4|[[Rule of Distribution/Conjunction Distributes over Disjunction/Left Distributive/Formulation 1/Reverse Implication|Conjunction is Left Distributive over Disjunction: Formulation 1]]}} {{Implication|6||\paren {\paren {p \land q} \lor \paren {p \land r} } \implies \paren {p \land \paren {q \lor r} }|4|5}} {{BiconditionalIntro|7||\paren {p \land \paren {q \lor r} } \iff \paren {\paren {p \land q} \lor \paren {p \land r} }|3|6}} {{EndTableau}} {{qed}}	1
{{BeginTableau|\vdash p \lor \neg p}} {{TheoremIntro|1|\neg\neg (p \lor \neg p)|[[Negation of Excluded Middle is False/Form 2]]}} {{DoubleNegElimination|2||p \lor \neg p|1}} {{EndTableau}} {{Qed}}	1
{{BeginTableau|\neg \left({p \land q}\right) \vdash p \implies \neg q}} {{Premise|1|\neg \left({p \land q}\right)}} {{Assumption|2|p}} {{Assumption|3|q}} {{Conjunction|4|2, 3|p \land q|2|3}} {{NonContradiction|5|1, 2, 5|4|1}} {{Contradiction|6|1, 2|\neg q|3|5}} {{Implication|7|1|p \implies \neg q|2|6}} {{EndTableau}} {{qed}} [[Category:Modus Ponendo Tollens]] onntrxn3bw34e75yrimn9eni1iididw	1
{{BeginTableau|\neg \left({ p \downarrow \left({q \downarrow r}\right) \implies \left({p \downarrow q}\right) \downarrow r }\right)}} {{Assumption|1|\neg p \land r}} {{Simplification|2|1|\neg p|1|1}} {{Simplification|3|1|r|1|2}} {{Addition|4|1|q \lor r|3|2}} {{DoubleNegIntro|5|1|\neg \neg \left({q \lor r}\right)|4}} {{SequentIntro|6|1|\neg \left({q \downarrow r}\right)|5|Definition of [[Definition:Logical NOR|Logical NOR]]}} {{Conjunction|7|1|\neg p \land \neg \left({q \downarrow r}\right)|2|6}} {{DeMorgan|8|1|\neg \left({p \lor \left({q \downarrow r}\right) }\right)|7|Conjunction of Negations}} {{SequentIntro|9|1|p \downarrow \left({q \downarrow r}\right)|8|Definition of [[Definition:Logical NOR|Logical NOR]]}} {{Addition|10|1|\left({p \downarrow q}\right) \lor r|3|2}} {{DoubleNegIntro|11|1|\neg \neg \left({\left({p \downarrow q}\right) \lor r}\right)|10}} {{SequentIntro|12|1|\neg \left({\left({p \downarrow q}\right) \downarrow r}\right)|11|Definition of [[Definition:Logical NOR|Logical NOR]]}} {{DoubleNegIntro|13|1|\neg \neg \left({p \downarrow \left({q \downarrow r}\right)}\right)|9}} {{Conjunction|14|1|\left({\neg \neg \left({p \downarrow \left({q \downarrow r}\right)}\right)}\right) \land \left({\neg \left({\left({p \downarrow q}\right) \downarrow r}\right)}\right)|13|12}} {{DeMorgan|15|1|\neg \left({\neg \left({p \downarrow \left({q \downarrow r}\right)}\right) \lor \left({\left({p \downarrow q}\right) \downarrow r}\right)}\right)|14|Conjunction of Negations}} {{SequentIntro|16|1 |\neg \left({ p \downarrow \left({q \downarrow r}\right) \implies \left({p \downarrow q}\right) \downarrow r }\right) |15 |[[Rule of Material Implication]] }} {{EndTableau}} Taking $p = \bot$ and $r = \top$, we have $\vdash \neg p \land r$, discharging the last assumption. Hence the result. {{qed}}	1
The [[Definition:Characteristic Function of Set|characteristic function]] $\chi_\N: \N \to \N$ is defined as: :$\forall n \in \N: \chi_\N \left({n}\right) = 1$. So: : $\chi_\N \left({n}\right) = f^1_1 \left({n}\right)$ The [[Constant Function is Primitive Recursive|constant function $f^1_1$ is primitive recursive]]. Hence the result. {{qed}} [[Category:Primitive Recursive Functions]] [[Category:Natural Numbers]] 10vvk2mb2nm8d17tlbp91j9l7rcdjpc	1
From [[Functionally Complete Logical Connectives/Negation and Conjunction|Functionally Complete Logical Connectives: Negation and Conjunction]], $\set {\neg, \land}$ is [[Definition:Functionally Complete|functionally complete]]. That is: any expression can be expressed in terms of $\neg$ and $\land$. From [[De Morgan's Laws (Logic)/Conjunction|De Morgan's laws: Conjunction]], we have that: :$p \land q \dashv \vdash \neg \paren {\neg p \lor \neg q}$ Thus all occurrences of $\land$ can be replaced by $\lor$ and $\neg$. Thus any expression can be expressed in terms of $\neg$ and $\lor$. That is: $\set {\neg, \lor}$ is [[Definition:Functionally Complete|functionally complete]]. {{qed}}	1
:$p \iff q \dashv \vdash \left({p \implies q}\right) \land \left({q \implies p}\right)$	1
:$\paren {q \lor r} \land p \dashv \vdash \paren {q \land p} \lor \paren {r \land p}$	1
Clearly $\map \len 0 = 0$. For $n > 0$, we have: :$\displaystyle \map \len n = \sum_{y \mathop = 1}^n \map {\operatorname {div} } {n, \map p y}$ where: :$\map {\operatorname {div} } {n, m}$ is defined as: ::$\map {\operatorname {div} } {n, y} = \begin{cases} 1 & : y \divides n \\ 0 & : y \nmid n \end{cases}$ :$\map p y$ is the $y$th [[Definition:Prime Number|prime number]]. Let $g: \N^2 \to \N$ be the [[Definition:Function|function]] defined by: :$\displaystyle \map g {n, z} = \begin{cases} 0 & : z = 0 \\ \displaystyle \sum_{y \mathop = 1}^z \map {\operatorname {div} } {n, \map p y} & : z > 0 \end{cases}$ We have that: :[[Divisor Relation is Primitive Recursive|$\operatorname{div}$ is primitive recursive]] :[[Prime Enumeration Function is Primitive Recursive|$p: \N \to \N$ is primitive recursive]] :[[Bounded Summation is Primitive Recursive]]. So it follows that $g$ is also [[Definition:Primitive Recursive Function|primitive recursive]]. Finally, as $\map \len n = \map g {n, n}$ it follows that $\len$ is [[Definition:Primitive Recursive Function|primitive recursive]]. {{qed}} [[Category:Primitive Recursive Functions]] b2iqin2w62d35didrb6ccj0hijnve70	1
Let $S$ be the [[Definition:Set|set]] defined as: :$S := \set {n \in \N_{>0}: \map P n \text { is false} }$ {{AimForCont}} $S \ne \O$. From the [[Well-Ordering Principle]] it follows that $S$ has a [[Definition:Minimal Element|minimal element]] $m$. From $(1)$ we have that $\map P 1$ holds. Hence $1 \notin S$. Therefore $m \ne 1$. Therefore $m - 1 \in \N_{>0}$. But $m$ is the [[Definition:Minimal Element|minimal element]] of $S$. So $m - 1 \notin S$. Therefore $\map P {m - 1}$ is true. Hence by $(2)$ it follows that $\map P m$. But then $m \notin S$. This contradicts our supposition that $m \in S$. Hence there can be no such $m \in S$. So $S = \O$ and the result follows. {{qed}}	1
: $p \land q \vdash \neg \left({\neg p \lor \neg q}\right)$	1
{{BeginTableau|p \land q \vdash \neg \left({\neg p \lor \neg q}\right)}} {{Premise|1|p \land q}} {{Simplification|2|1|p|1|1}} {{Simplification|3|1|q|1|2}} {{Assumption|4|\neg p \lor \neg q}} {{Assumption|5|\neg p}} {{NonContradiction|6|1, 5|2|5}} {{Assumption|7|\neg q}} {{NonContradiction|8|1, 7|3|7}} {{ProofByCases|9|1, 4|\bot|4|5|6|7|8}} {{Contradiction|10|1|\neg \left({\neg p \lor \neg q}\right)|4|9}} {{EndTableau}} {{qed}}	1
A direct application of [[Factorial Divisible by Prime Power]]. {{qed}} [[Category:Factorials]] [[Category:Binary Notation]] 8595atu12hqzf4sfr9m0dvw223wlnb3	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc||ccccc|} \hline p & \implies & q & \neg & (p & \land & \neg & q) \\ \hline F & T & F & T & F & F & T & F \\ F & T & T & T & F & F & F & T \\ T & F & F & F & T & T & T & F \\ T & T & T & T & T & F & F & T \\ \hline \end{array}$ {{qed}}	1
{{BeginTableau|\left({p \dashv \vdash q}\right) \vdash p \iff q}} {{Premise|1|p \dashv \vdash q}} {{SequentIntro|2|1|\left ({p \vdash q}\right) \land \left ({q \vdash p}\right)|1 |Definition of [[Definition:Interderivable|Interderivable]]}} {{Assumption|3|p}} {{Simplification|4|1, 3|p \vdash q|2|1}} {{Implication|5|1|p \implies q|3|4}} {{Assumption|6|q}} {{Simplification|7|1, 6|q \vdash p|2|2}} {{Implication|8|1|q \implies p|6|7}} {{BiconditionalIntro|9|1|p \iff q|5|8}} {{EndTableau}} {{Qed}} [[Category:Equivalences are Interderivable]] s1qqzy938u5n0099qdwkh50zrgg4tkc	1
A [[Definition:Primitive Recursive Function|primitive recursive function]] is a [[Definition:Total Function|total function]], which is apparent from its method of definition. As the processes for generate a [[Definition:Primitive Recursive Function|primitive recursive function]] are a subset of those to generate a [[Definition:Recursive Function|recursive function]], it follows that a [[Definition:Primitive Recursive Function|primitive recursive function]] is also a [[Definition:Recursive Function|recursive function]]. The result follows from the definition of a [[Definition:Total Recursive Function|total recursive function]]. {{qed}} [[Category:Primitive Recursive Functions]] [[Category:Recursive Functions]] 3nmvtn2sg09j3f6oztavo9f8j59t5vs	1
We prove the [[Definition:Contrapositive Statement|contrapositive]]. Let $\kappa$ be an [[Definition:Infinite Cardinal|infinite cardinal]]. Suppose that $T$ is not [[Definition:Kappa-Stable Theory|$\kappa$-stable]]. Then there exists some $\mathcal M \models T$ and $A \subseteq \mathcal M$ with $\left\vert{A}\right\vert = \kappa$ such that: :$\left\vert{ {S_n}^\mathcal M \left({A}\right)}\right\vert > \kappa$ Let $\mathcal L_A$ denote $\mathcal L \cup \left\{{a: a \in A}\right\}$, the [[Definition:Logical Language|language]] obtained from $\mathcal L$ by adding new [[Definition:Constant Symbol|constant symbols]] for each $a \in A$. For each [[Definition:Well-Formed Formula|$\mathcal L_A$-formula]] $\phi$, let $\left[{\phi}\right] = \left\{{p \in {S_n}^\mathcal M \left({A}\right): \phi \in p}\right\}$, the [[Definition:Set|set]] of [[Definition:Complete Type|complete $n$-types over $A$]] which contain $\phi$. Our goal will be to find a [[Definition:Countable Set|countable set]] $B$ in $\mathcal M$ such that: :$\left\vert{ {S_n}^\mathcal M \left({B}\right)}\right\vert = 2^{\aleph_0} \ne \aleph_0$ which will demonstrate non-[[Definition:Kappa-Stable Theory|$\omega$-stability]] of $T$. We will do this by constructing a [[Definition:Countable Set|countable]] [[Definition:Binary Tree|binary tree]] of [[Definition:Well-Formed Formula|formulas]] such that each of the $2^{\aleph_0}$ distinct [[Definition:Simple Path|simple paths]] from the [[Definition:Root of Tree|root of the tree]] out to infinity correspond to distinct [[Definition:Type|types]]. Before we can build the tree, we need the following lemma. === Lemma === Suppose $\left\vert{ \left[{\phi}\right] }\right\vert > \kappa$. We argue that we can select some $\mathcal L_A$-formula $\psi$ such that both: : $\left\vert{\left[{\phi \land \psi}\right]}\right\vert > \kappa$ and: : $\left\vert{\left[{\phi \land \neg \psi}\right]}\right\vert > \kappa$ === Proof of Lemma === The argument is a [[Proof by Contradiction]]. Suppose the proposition is not true. Let $p$ be the [[Definition:Subset|subset]]: :$\left\{ {\psi: \left\vert{\left[{\phi \land \psi}\right]}\right\vert > \kappa }\right\}$ where each $\psi$ is an $\mathcal L_A$-formula in $n$ [[Definition:Free Variable|free variables]]. We will eventually write $\left[{\phi}\right]$ as a union of $\left\{{p}\right\}$ and other sets which are "too small", so that we contradict the cardinality of $\left[{\phi}\right]$. In order to do this, we first need to show that $p$ is a type. First, note that if both $\left\vert{\left[{\phi \land \neg \psi}\right]}\right\vert \le \kappa$ and $\left\vert{\left[{\phi \land \neg \psi}\right]}\right\vert \le \kappa$, then $\left\vert{\left[{\phi}\right]}\right\vert \le \kappa$, which is not the case. {{explain|The above makes no sense -- both expressions being anded are the same. Presumably one of these should be $\left\vert{\left[{\phi \land \psi}\right]}\right\vert > \kappa$.}} Hence, for each $\psi$, either $\psi \in p$ or $\neg \psi \in p$. Next, note that by assumption, it cannot be the case that both $\psi$ and $\neg \psi$ in $p$. Let $\Delta = \left\{{\psi_1, \ldots, \psi_m}\right\} \cup \Delta'$ be a finite subset of $p \cup \operatorname{Th}_A \left({\mathcal M}\right)$, where $\Delta$ is written so that any sentences from $\operatorname{Th}_A \left({\mathcal M}\right)$ are in $\Delta'$. Suppose $\psi_1 \land \cdots \land \psi_m$ is not in $p$. Then by the above comment, $\neg \left({\psi_1 \land \cdots \land \psi_m}\right)$ is in $p$. But this means that: {{begin-eqn}} {{eqn | l = \left\vert{\left[{\phi \land \neg \left({\psi_1 \land \cdots \land \psi_m}\right)}\right]}\right\vert | r = \left\vert{\left[{\left({\phi \land \neg \psi_1}\right) \lor \cdots \lor \left({\phi \land \neg \psi_m}\right)}\right]}\right\vert | c = [[De Morgan's Laws (Logic)]] }} {{eqn | r = \left\vert{\left[{\phi \land \neg \psi_1}\right] \cup \cdots \cup \left[{\phi \land \neg \psi_m}\right]}\right\vert | c = }} {{eqn | o = > | r = \kappa | c = }} {{end-eqn}} Thus, by [[Cardinality of Infinite Union of Infinite Sets]], at least one of the $\psi_i$ must satisfy $\left\vert{\left[{\phi \land \neg \psi_i}\right]}\right\vert > \kappa$. This is impossible, since $\psi_i \in p$. So, $\psi_1 \land \cdots \land \psi_m$ is in $p$. By definition of $p$ this means: : $\left\vert{\left[{\phi \land \psi_1 \land \cdots \land \psi_m}\right]}\right\vert > \kappa$ Hence there are types containing $\psi_1 \land \cdots \land \psi_m$. So $\Delta$ is satisfiable. By the [[Compactness Theorem]], this means that $p \cup \operatorname{Th}_A \left({\mathcal M}\right)$ is satisfiable. Hence: : $p \in S_n^\mathcal M \left({A}\right)$ We have that $p$ is a type. So we can write: :$\displaystyle \left[{\phi}\right] = \left\{{p}\right\} \cup \bigcup_{\psi \notin p} \left[{\phi \land \psi}\right]$ since every type besides $p$ which contains $\phi$ must contain some $\psi \notin p$. Note the cardinalities involved in this union: Clearly, $\left\{{p}\right\}$ has cardinality $1 < \kappa$. By definition of $p$ each $\left[{\phi \land \psi}\right]$ for $\psi \notin p$ has cardinality at most $\kappa$. We have noted earlier in the main proof that there are only $\kappa$-many $\mathcal L_A$-formulas. Thus, by [[Cardinality of Infinite Union of Infinite Sets]], it is to be concluded that: :$\left\vert{\left[{\phi}\right]}\right\vert \le \kappa$ However, this contradicts our supposition. The lemma follows by [[Proof by Contradiction]]. {{qed|lemma}} Now the tree is to be built. This amounts to recursively defining formulas $\phi_\sigma$ for each finite sequence $\sigma$ over $\left\{{0, 1}\right\}$. First, the root of the tree $\phi_{()}$ is defined where the subscript is the empty sequence. The assumption is: :$\displaystyle \left\vert{\bigcup \left[{\phi}\right]}\right\vert = \left\vert{S_n^\mathcal M \left({A}\right)}\right\vert > \kappa$ where the union is taken over all $\mathcal L_A$-formulas $\phi$ But there are only $\kappa$ many such formulas. Thus by [[Cardinality of Infinite Union of Infinite Sets]] there must be some $\mathcal L_A$-formula $\phi_{()}$ such that the cardinality of $\left[{\phi_{()} }\right]$ is strictly larger than $\kappa$. Suppose $\phi_\sigma$ has been defined and that: :$\left\vert{\left[{\phi_\sigma}\right]}\right\vert > \kappa$ Let $\sigma = \left({\sigma_0, \dots, \sigma_k}\right)$. By the lemma above, we can choose an $\mathcal L_A$ formula $\psi$ such that both: :$\left\vert{\left[{\phi \land \psi}\right]}\right\vert > \kappa$ and: :$\left\vert{\left[{\phi \land \neg \psi}\right]}\right\vert > \kappa$ Define $\phi_{\left({\sigma_0, \dots, \sigma_k, 0}\right)}$ to be $\phi_\sigma \land \psi$. Define $\phi_{\left({\sigma_0, \dots, \sigma_k, 1}\right)}$ to be $\phi_\sigma \land \neg \psi$. Now, let $B$ be the set of elements of $A$ which occur as constant symbols in any of the $\phi_\sigma$. Since only countably many $\phi_\sigma$ have been defined, $B$ is countable. We will define an [[Definition:Injection|injection]] from the set of infinite sequences over $\left\{{0, 1}\right\}$ to $S_n^\mathcal M \left({B}\right)$ using our tree. This will demonstrate that our theory $T$ is not $\omega$-stable. From [[Type Space is Compact]], $S_n^\mathcal M \left({A}\right)$ is compact (when viewed as a [[Definition:Type Space|type space]]). Thus it satisfies the [[Definition:Finite Intersection Axiom|finite intersection axiom]] by [[Equivalent Definitions of Compactness]]. We have that each $\left[{\phi_\sigma}\right]$ is closed, essentially by definition of the type space topology. Also, any finite intersection $\left[{\phi_{()} }\right] \cap \left[{\phi_{(\sigma_0)} }\right] \cap \cdots \cap \left[{\phi_{\left({\sigma_0, \dots, \sigma_k}\right)} }\right]$ is equal to $\left[{\phi_{\left({\sigma_0, \dots, \sigma_k}\right)} }\right]$ by construction. Hence it is nonempty (by its cardinality) Thus, by the [[Definition:Finite Intersection Axiom|finite intersection axiom]], for each infinite sequence $\Sigma = \left({\Sigma_0, \Sigma_1, \Sigma_2, \ldots}\right)$ over $\left\{{0, 1}\right\}$, the intersection $\displaystyle \bigcap_{k \mathop \in \N} \left[{\phi_{\left({\Sigma_0, \Sigma_1, \ldots, \Sigma_k}\right)} }\right]$ is nonempty. Moreover, let $\Sigma = \left({\Sigma_0, \Sigma_1, \Sigma_2, \ldots}\right)$ and $\Sigma' = \left({\Sigma'_0, \Sigma'_1, \Sigma'_2, \ldots}\right)$ be two distinct infinite sequences over $\left\{{0, 1}\right\}$. Then there is some $k$ for which $\Sigma_i = \Sigma'_i$ for $i \le k$ and $\Sigma_{k+1} \ne \Sigma_{k+1}$. But $\phi_{\left({\Sigma_1, \ldots, \Sigma_k, 0}\right)}$ and $\phi_{\left({\Sigma_1, \ldots, \Sigma_k, 1}\right)}$ were defined to imply $\psi$ and $\neg \psi$ respectively for some $\psi$. So no type can satisfy both of them simultaneously. Thus $\displaystyle \bigcap_{k \mathop \in \N} \left[{\phi_{\left({\Sigma_0, \Sigma_1, \ldots, \Sigma_k}\right)} }\right]$ and $\displaystyle \bigcap_{k \mathop \in \N} \left[{\phi_{\left({\Sigma'_0, \Sigma'_1, \ldots, \Sigma'_k}\right)} }\right]$ cannot both contain the same type. Thus, we can define our injection by sending each infinite sequence $\Sigma$ over $\left\{{0, 1}\right\}$ to a type chosen from $\displaystyle \bigcap_{k \mathop \in \N} \left[{\phi_{\left({\Sigma_0, \Sigma_1, \ldots, \Sigma_k}\right)} }\right]$. The existence of this injection implies that the cardinality of $S_n^\mathcal M \left({B}\right)$ is at least $2^{\aleph_0}$, as this is the cardinality of the set of infinite sequences over $\left\{{0, 1}\right\}$. Hence, $T$ is not $\omega$-stable. The theorem now follows by the [[Rule of Transposition]]. {{qed}} [[Category:Model Theory]] 1peli88zcxfhadt88up612lnahav6x4	1
{{Questionable|Not only the proof is faulty, this theorem is wrong. If we have a recursively enumerable set A of axioms, then the set of theorems (and hence, the Gödel numbers of those) proven by A is recursively enumerable. Minimal arithmetic and PA are both recursively enumerable, and hence their theorems have a recursively enumerable set of Gödel numbers. Any recursively enumerable set is arithmetical with degree Sigma^0_1 in the arithmetical hierarchy. Moreover, there is already a well known provability predicate Pr(x) in the language of Peano arithmetic. Indeed, if we use the diagonal lemma on ~Pr(x) to get a sentence with T proves G iff ~Pr(G), then we will have an unprovable sentence.|Burak}} The proof is by contradiction. Let $\Theta$ be the set of [[Definition:Gödel Number|Gödel numbers]] of the theorems of $T$. Suppose it is defined in $T$ by the formula $\map \theta y$. Since $T$ contains $Q$, we may apply the [[Diagonal Lemma]] to $\neg \map \theta y$. This gives us a sentence $G$ such that :$T \vdash G \leftrightarrow \neg \map \theta {\hat G}$ where $\hat G$ is the Gödel number of $G$ (more accurately, it is the term in the language of arithmetic obtained by applying the function symbol $s$ to $0$ this many times). {{Questionable|The below argument is not correct. $T$ does not necessarily prove that $\neg \map \theta {\hat G}$ just because it does not prove $G$. PA has a provability predicate $\map \Pr x$ which satisfies the property that if PA proves G, then PA proves $\map \Pr {\hat G}$). The step used here assumes a somewhat similar property in the opposite direction that our provability predicate satisfies if T does not prove G, then T proves $\neg \map \theta {\hat G}$, which we did not have as an assumption on $\map \Theta x$. |Burak}} Suppose $G$ is not a theorem of $T$. :Then the Gödel number of $G$ is not in $\Theta$. :Since $\theta$ defines $\Theta$ in $T$, this means that: ::$T \vdash \neg \map \theta {\hat G}$ :But, by choice of $G$ (specifically, the bi-implication above), this gives us: ::$T\vdash G$ :which contradicts $G$ not being a theorem of $T$ Thus, $G$ is a theorem of $T$. :But, then the Gödel number of $G$ is in $\Theta$, and :since $\theta$ defines $\Theta$ in $T$, this means that ::$T \vdash \map \theta {\hat G}$ :But, then this gives us ::$T \vdash \neg G$ :which contradicts $G$ being a theorem of $T$, ''since $T$ is consistent''. Since assuming $\Theta$ was definable in $T$ necessarily leads to a contradiction, we conclude that it is impossible. {{qed}}	1
If an error has been made in any one of the first $9$ [[Definition:Digit|digits]], the [[Definition:Check Digit|check digit]] will be wrong.	1
Using a [[Definition:Tableau Proof (Formal Systems)|tableau proof]] for [[Definition:Gentzen Proof System/Instance 1|instance 1 of a Gentzen proof system]]: {| border="1" |+$\vdash \left({p \lor \left({q \land r}\right)}\right) \implies \left({\left({p \lor q}\right) \land \left({p \lor r}\right)}\right)$ |- ! Line !! ! Pool ! Formula ! Rule ! Depends upon ! Notes |- | 1 || || | $\neg p, p, q$ | Axiom || || |- | 2 || || | $\neg p, p \lor q$ | [[Definition:Gentzen Proof System/Instance 1/Beta-Rule|$\beta$-Rule: $\beta\lor$]] | 1 || |- | 3 || || | $\neg p, p, r$ | Axiom || || |- | 4 || || | $\neg p, p \lor r$ | [[Definition:Gentzen Proof System/Instance 1/Beta-Rule|$\beta$-Rule: $\beta\lor$]] | 3 || |- | 5 || || | $\neg p, \left({p \lor q}\right) \land \left({p \lor r}\right)$ | [[Definition:Gentzen Proof System/Instance 1/Alpha-Rule|$\alpha$-Rule: $\alpha\land$]] | 2, 4 || |- | 6 || || | $\neg q, \neg r, p, q$ | Axiom || || |- | 7 || || | $\neg q, \neg r, p \lor q$ | [[Definition:Gentzen Proof System/Instance 1/Beta-Rule|$\beta$-Rule: $\beta\lor$]] | 6 || |- | 8 || || | $\neg q, \neg r, p, r$ | Axiom || || |- | 9 || || | $\neg q, \neg r, p \lor r$ | [[Definition:Gentzen Proof System/Instance 1/Beta-Rule|$\beta$-Rule: $\beta\lor$]] | 8 || |- | 10 || || | $\neg q, \neg r, \left({p \lor q}\right) \land \left({p \lor r}\right)$ | [[Definition:Gentzen Proof System/Instance 1/Alpha-Rule|$\alpha$-Rule: $\alpha\land$]] | 7, 9 || |- | 11 || || | $\neg \left({q \land r}\right), \left({p \lor q}\right) \land \left({p \lor r}\right)$ | [[Definition:Gentzen Proof System/Instance 1/Beta-Rule|$\beta$-Rule: $\beta\land$]] | 10 || |- | 12 || || | $\neg \left({p \lor \left({q \land r}\right)}\right), \left({p \lor q}\right) \land \left({p \lor r}\right)$ | [[Definition:Gentzen Proof System/Instance 1/Alpha-Rule|$\alpha$-Rule: $\alpha\lor$]] | 5, 11 || |- | 13 || || | $\left({p \lor \left({q \land r}\right)}\right) \implies \left({ \left({p \lor q}\right) \land \left({p \lor r}\right)}\right)$ | [[Definition:Gentzen Proof System/Instance 1/Beta-Rule|$\beta$-Rule: $\beta\implies$]] | 12 || |} {{qed}}	1
Let $\left({S, \vee, \wedge, \neg}\right)$ be a [[Definition:Boolean Algebra|Boolean algebra]]. Then $\neg \bot = \top$.	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, in each case, the [[Definition:Truth Value|truth values]] in the appropriate columns match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c|ccc||c|ccc|} \hline p & p & \implies & \top & \top \\ \hline F & F & T & T & T \\ T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
We see that: $n \mathop {\dot -} \paren {m + 1} = \begin{cases} 0 & : n \mathop {\dot -} m = 0 \\ \paren {n \mathop {\dot -} m} - 1 & : n \mathop {\dot -} m > 0 \end{cases}$ Hence we can define [[Definition:Partial Subtraction|cut-off subtraction]] as: :$n \mathop {\dot -} m = \begin{cases} n & : m = 0 \\ \operatorname{pred} \paren {n \mathop {\dot -} \paren {m - 1} } & : m > 0 \end{cases}$ This is a definition by [[Definition:Primitive Recursion|primitive recursion]] from the [[Predecessor Function is Primitive Recursive|primitive recursive function $\operatorname{pred}$]]. Hence the result. {{qed}}	1
We apply the [[Method of Truth Tables]]: :$\begin{array}{|ccc||cc|} \hline p & \uparrow & p & \neg & p \\ \hline F & T & F & T & F \\ T & F & T & F & T \\ \hline \end{array}$ As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. {{qed}}	1
We apply the [[Method of Truth Tables]] to the proposition: $p \implies \left({q \implies r}\right) \dashv \vdash \left({p \implies q}\right) \implies \left({p \implies r}\right)$ As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc||ccccccc|} \hline p & \implies & (q & \implies & r) & (p & \implies & q) & \implies & (p & \implies & r) \\ \hline F & T & F & T & F & F & T & F & T & F & T & F \\ F & T & F & T & T & F & T & F & T & F & T & T \\ F & T & T & F & F & F & T & T & T & F & T & F \\ F & T & T & T & T & F & T & T & T & F & T & T \\ T & T & F & T & F & T & F & F & T & T & F & F \\ T & T & F & T & T & T & F & F & T & T & T & T \\ T & F & T & F & F & T & T & T & F & T & F & F \\ T & T & T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
{{BeginTableau|\neg p \implies \bot \vdash p}} {{Premise|1|\neg p \implies \bot}} {{Assumption|2|\neg p}} {{ModusPonens|3|1, 2|\bot|1|2}} {{Contradiction|4|1|\neg \neg p|2|3}} {{DoubleNegElimination|5|1|p|4}} {{EndTableau}} {{qed}}	1
Let $\mathbf A$ be a [[Definition:WFF of Propositional Logic|WFF of propositional logic]]. Then the [[Semantic Tableau Algorithm]] for $\mathbf A$ terminates. Each [[Definition:Leaf Node|leaf node]] of the resulting [[Definition:Semantic Tableau|semantic tableau]] is [[Definition:Marked Leaf|marked]].	1
:$\neg p \implies \paren {q \land \neg q} \vdash p$	1
[[Definition:Hilbert Proof System/Instance 2|Instance 2]] of the [[Definition:Hilbert Proof System|Hilbert proof systems]] $\mathscr H_2$ is [[Definition:Consistent Proof System|consistent]].	1
Let $\struct {R, +, \circ}$ be a [[Definition:Ring (Abstract Algebra)|ring]] whose [[Definition:Ring Zero|zero]] is $0_R$. Let $n \cdot x$ be an [[Definition:Integral Multiple|integral multiple]] of $x$: :$n \cdot x = \begin {cases} 0_R & : n = 0 \\ x & : n = 1 \\ \paren {n - 1} \cdot x + x & : n > 1 \end {cases}$ that is $n \cdot x = x + x + \cdots \paren n \cdots x$. For $n < 0$ we use: :$-n \cdot x = n \cdot \paren {-x}$ Then: :$\forall n \in \Z: \forall x \in R: \paren {n \cdot x} \circ x = n \cdot \paren {x \circ x} = x \circ \paren {n \cdot x}$	1
Let $\Gamma$ be a [[Definition:Finished Branch of Propositional Tableau|finished branch]] of a [[Definition:Propositional Tableau|propositional tableau]] $\left({T, \mathbf H, \Phi}\right)$. Let $v$ be a [[Definition:Boolean Interpretation|boolean interpretation]] such that: :$v \models_{\mathrm{BI}} \mathbf A$ for every [[Definition:Basic WFF|basic WFF]] $\mathbf A$ that [[Definition:Occurrence along Branch|occurs]] along $\Gamma$. Then: :$v \models_{\mathrm{BI}} \Phi \left[{\Gamma}\right]$ where $\Phi \left[{\Gamma}\right]$ is the [[Definition:Image of Subset under Mapping|image]] of $\Gamma$ under $\Phi$.	1
: $\vdash \neg \neg p \implies p$	1
A '''unary logical connective''' (or '''one-place connective''') is a [[Definition:Logical Connective|connective]] whose effect on its [[Definition:Compound Statement|compound statement]] is determined by the [[Definition:Truth Value|truth value]] of ''one'' [[Definition:Substatement of Compound Statement|substatement]]. In standard [[Definition:Aristotelian Logic|Aristotelian logic]], there are four of these. The only non-trivial one is [[Definition:Logical Not|logical not]], as shown on [[Unary Truth Functions]].	1
: $p \land p \vdash p$	1
{{BeginTableau|p \iff q \vdash \neg p \iff \neg q}} {{Premise|1|p \iff q}} {{BiconditionalElimination|2|1|p \implies q|1|1}} {{SequentIntro|3|1|\neg q \implies \neg p|2|[[Rule of Transposition]]}} {{BiconditionalElimination|4|1|q \implies p|1|2}} {{SequentIntro|5|1|\neg p \implies \neg q|4|[[Rule of Transposition]]}} {{BiconditionalIntro|6|1|\neg p \iff \neg q|5|3}} {{EndTableau}} {{qed}}	1
: $1:$ Suppose $\phi$ is an [[Definition:Simple Statement|atom]] $p$. Then we need to show that $p \vdash p$ and $\neg p \vdash \neg p$. These are proved in one line in the proof of the [[Law of Identity#Proof|Law of Identity]]. : $2:$ Suppose $\phi$ is of the form $\neg \phi_1$. There are two cases to consider: * Suppose $\phi$ evaluates to $T$. {{finish|More hard work. I'll come back to this once I've got some more basics done.}} [[Category:Propositional Logic]] odpu8tmuf1zc50moxxiynr9im73pl6r	1
{{BeginTableau|\top \vdash \neg \bot}} {{Premise|1|\top}} {{Assumption|2|\bot|If a contradiction were assumed ...}} {{Explosion|3|2|\neg \top|2}} {{NonContradiction|4|1, 2|1|3}} {{Contradiction|5|1|\neg \bot|2|4}} {{EndTableau|lemma}} {{BeginTableau|\neg \bot \vdash \top}} {{Premise|1|\neg \bot}} {{Assumption|2|\neg \top|To assume a non-truth ...}} {{SequentIntro|3|2|\bot|2|from above result}} {{Reductio|4|1|\top|2|3}} {{EndTableau|qed}}	1
Let $\beta, \tau$ be [[Definition:Term (Predicate Logic)|terms]]. Let $x \in \mathrm{VAR}$ be a [[Definition:Variable (Logic)|variable]]. Let $\beta \left({x \gets \tau}\right)$ be the [[Definition:Substitution Instance of Term|substitution instance of $\beta$ substituting $\tau$ for $x$]]. Let $\mathcal A$ be a [[Definition:Structure for Predicate Logic|structure for predicate logic]]. Let $\sigma$ be an [[Definition:Assignment for Term|assignment]] for $\beta$ and $\tau$. Suppose that: :$\mathop{ \operatorname{val}_{\mathcal A} \left({\tau}\right) } \left[{\sigma}\right] = a$ where $\mathop{ \operatorname{val}_{\mathcal A} \left({\tau}\right) } \left[{\sigma}\right]$ is the [[Definition:Value of Term under Assignment|value of $\tau$ under $\sigma$]]. Then: :$\mathop{ \operatorname{val}_{\mathcal A} \left({\beta \left({x \gets \tau}\right) }\right) } \left[{\sigma}\right] = \mathop{ \operatorname{val}_{\mathcal A} \left({\beta}\right) } \left[{\sigma + \left({x / a}\right)}\right]$ where $\sigma + \left({x / a}\right)$ is the [[Definition:Extension of Assignment|extension of $\sigma$ by mapping $x$ to $a$]].	1
:$\neg p \implies q \dashv \vdash \neg q \implies p$	1
{{BeginTableau|\vdash \left({p \implies q}\right) \lor \left({q \implies p}\right)}} {{ExcludedMiddle|1|p \lor \neg p}} {{Assumption|2|p}} {{SequentIntro|3|2|q \implies p|2|[[True Statement is implied by Every Statement]]}} {{Addition|4|2|\left({p \implies q}\right) \lor \left({q \implies p}\right)|2|2}} {{Assumption|5|\neg p}} {{SequentIntro|6|5|p \implies q|5|[[False Statement implies Every Statement]]}} {{Addition|7|5|\left({p \implies q}\right) \lor \left({q \implies p}\right)|7|1}} {{ProofByCases|8||\left({p \implies q}\right) \lor \left({q \implies p}\right)|1|2|4|5|7}} {{EndTableau}} {{qed}}	1
Let $S_n$ be a [[Definition:Fibonacci String|Fibonacci string]] of [[Definition:Length of String|length]] $n$. Then for $n \ge 3$, $S_n$ ends either with $\text{ba}$ or with $\text{ab}$.	1
=== Existence === First, from the [[Definition:Formal Grammar of Predicate Logic|rules of formation of predicate logic]], we have that whenever a [[Definition:Quantifier|quantifier]] is included in a [[Definition:Well-Formed Formula|WFF]], it appears in the form: :$( Q x: \mathbf B )$ where $\mathbf B$ is itself a [[Definition:WFF of Predicate Logic|WFF]]. Hence it is clear that $( Q x: \mathbf B )$ is a [[Definition:Well-Formed Part|well-formed part]] of $\mathbf A$ which begins with $Q$. {{qed|lemma}} === Uniqueness === Now we prove that this [[Definition:Well-Formed Part|well-formed part]] is unique. Suppose $\mathbf B$ and $\mathbf C$ are both [[Definition:Well-Formed Part|well-formed parts]] of $\mathbf A$ which begin with the given [[Definition:Occurrence (Predicate Logic)|occurrence]] of $Q$. Since $\mathbf B$ and $\mathbf C$ both begin with the same $Q$, neither one can be the initial part of the other, by [[Initial Part of WFF of Predicate Logic is not WFF]]. Therefore, $\mathbf B$ and $\mathbf C$ are necessarily the same. Hence the result. {{qed}}	1
: $p \uparrow q \dashv \vdash \neg p \lor \neg q$	1
Any [[Definition:Sequent|sequent]] can be expressed as a [[Definition:Theorem of Logic|theorem]]. That is: :$P_1, P_2, P_3, \ldots, P_n \vdash Q$ means the same thing as: :$\vdash P_1 \implies \paren {P_2 \implies \paren {P_3 \implies \paren {\ldots \implies \paren {P_n \implies Q} \ldots} } }$ The latter expression is known as the [[Definition:Corresponding Conditional|corresponding conditional]] of the former. Thus every [[Definition:Sequent|sequent]] containing the [[Definition:Symbol|symbol]] $\vdash$ can, if so desired, be expressed in the form of a [[Definition:Theorem of Logic|theorem]] which has $\implies$.	1
:$p, \neg p \vdash q$	1
{{BeginTableau|\vdash p \land q \implies q}} {{Assumption|1|p \land q}} {{Simplification|2|1|q|1|2}} {{Implication|3||p \land q \implies q|1|2}} {{EndTableau}} {{Qed}}	1
{{BeginTableau |p \iff \paren {p \lor p} }} {{Assumption | 1| p}} {{Addition | 2| 1|p \lor p |1|1}} {{Implication | 3| |p \implies \paren {p \lor p}|1|2}} {{Assumption | 4| p \lor p}} {{Assumption | 5| \neg p}} {{ModusTollendoPonens| 6|4, 5|p |4|5|1}} {{NonContradiction | 7|4, 5| 6|5}} {{Contradiction | 8| 5|p |5|7}} {{Implication | 9| |\paren {p \lor p} \implies p|4|8}} {{BiconditionalIntro |10| |p \iff \paren {p \lor p} |3|9}} {{EndTableau}} {{qed}}	1
{{BeginTableau|$\vdash \neg \left({p \iff \neg p}\right)$}} {{Assumption|1|p \iff \neg p}} {{BiconditionalElimination|2|1|p \implies \neg p|1|1}} {{BiconditionalElimination|3|1|\neg p \implies p|1|2}} {{SequentIntro|4|1|\bot|2,3|[[Non-Equivalence of Proposition and Negation/Formulation 1|Non-Equivalence of Proposition and Negation: Formulation 1]]}} {{Contradiction|5||\neg \left({p \iff \neg p}\right)|1|4}} {{EndTableau}} [[Category:Biconditional]] [[Category:Contradiction]] 6y8o80gajctqmhj9do2tot370fd1goa	1
Let $\map \rem {n, m} = r$. We see that as $n$ increases by $1$, then so does $r$, except when $n = m-1$ in which case increasing $n$ by $1$ makes $r$ go to $0$. We also take into account the case where $m = 0$: So we can define $\rem$ by cases: :$\map \rem {n, m} = \begin{cases} 0 & : \map \rem {n - 1, m} = m - 1 \text { or } m = 0 \text { or } n = 0\\ \map \rem {n - 1, m} + 1 & : \text {otherwise} \\ \end{cases}$ We remind ourselves of the following [[Definition:Primitive Recursive Function|primitive recursive functions]]: * [[Signum Function is Primitive Recursive|Signum function $\sgn$]] * [[Equality Relation is Primitive Recursive|Characteristic function of equality relation $\map {\chi_{\operatorname{eq} } } {n, m}$]] * [[Cut-Off Subtraction is Primitive Recursive|Cut-off subtraction $m \, \dot - \, n$]]. We have: * $\map \sgn m = 1 \iff m \ne 0$ * $\map {\overline \sgn} {\map {\chi_{\operatorname{eq} } } {\map \rem {n, m}, m \, \dot - \, 1} } = 1 \iff \map \rem {n, m} \ne m \, \dot - \, 1$. So: :$\map \sgn m \, \map {\overline \sgn} {\map {\chi_{\operatorname{eq} } } {\map \rem {n, m}, m \, \dot - \, 1} } = 1 \iff m > 0 \land \map \rem {n, m} \ne m \, \dot - \, 1$. So we see that: :$\map \rem {n + 1, m} = \paren {\map \rem {n, m} + 1} \, \map \sgn m \, \map {\overline \sgn} {\map {\chi_{\operatorname{eq} } } {\map \rem {n, m}, m \, \dot - \, 1} }$ So $\rem$ is obtained by [[Definition:Primitive Recursion|primitive recursion]] (over the first variable, which is allowed by [[Permutation of Variables of Primitive Recursive Function]]) from the [[Definition:Primitive Recursive Function|primitive recursive functions]]: * [[Signum Function is Primitive Recursive|Signum function $\sgn$]] * [[Equality Relation is Primitive Recursive|Characteristic function of equality relation $\map {\chi_{\operatorname{eq} } } {n, m}$]] * [[Cut-Off Subtraction is Primitive Recursive|Cut-off subtraction $m \, \dot - \, n$]] * [[Addition is Primitive Recursive|Addition]] * [[Multiplication is Primitive Recursive|Multiplication]]. Thus we can use [[Definition by Cases is Primitive Recursive]] and it follows that $\rem$ is [[Definition:Primitive Recursive Function|primitive recursive]]. {{qed}} [[Category:Primitive Recursive Functions]] 9zoo0k2s3rxz1h0j34qmq5ur3u5iph3	1
The [[Axiom:Comprehension Principle|comprehension principle]] leads to a [[Definition:Contradiction|contradiction]].	1
: $p \implies \left({q \land r}\right) \vdash \left({p \implies q}\right) \land \left({p \implies r}\right)$	1
:$p \uparrow p \dashv \vdash \neg p$ That is, the [[Definition:Logical NAND|NAND]] of a [[Definition:Proposition|proposition]] with itself corresponds to the [[Definition:Negation|negation]] operation.	1
:$p \lor q \dashv \vdash \neg p \implies q$	1
Proof by [[Principle of Mathematical Induction|induction]] on $n$: === Basis for the Induction === When $n = 1$, we have: :$\map f x = a x + b$ for some $a, b \in \Z_p$ and $a \ne 0$ Suppose $x_1, x_2 \in \Z_p$ are two [[Definition:Root of Polynomial|roots]] of $\map f x$. Then: {{begin-eqn}} {{eqn | l = a x_1 + b | o = \equiv | r = a x_2 + b | rr = \equiv 0 | rrr = \pmod p }} {{eqn | ll = \leadsto | l = a x_1 | o = \equiv | r = a x_2 | rrr = \pmod p }} {{eqn | ll = \leadsto | l = x_1 | o = \equiv | r = x_2 | rrr = \pmod p | c = since $a \perp p$ }} {{end-eqn}} Hence these two [[Definition:Root of Polynomial|roots]] must be the same, implying that there is at most $1$ [[Definition:Root of Polynomial|root]]. This is our [[Definition:Basis for the Induction|base case]]. === Induction Hypothesis === This is our [[Definition:Induction Hypothesis|induction hypothesis]]: :Any [[Definition:Polynomial over Field|polynomial in one variable]] of [[Definition:Degree of Polynomial|degree]] $k$ has at most $k$ [[Definition:Root of Polynomial|roots]] in $\Z_p$. It is to be demonstrated that: :Any [[Definition:Polynomial over Field|polynomial in one variable]] of [[Definition:Degree of Polynomial|degree]] $k + 1$ has at most $k + 1$ [[Definition:Root of Polynomial|roots]] in $\Z_p$. === Induction Step === This is our [[Definition:Induction Step|induction step]]: Consider $n = k + 1$, and let $f$ be a [[Definition:Polynomial over Field|polynomial in one variable]] of [[Definition:Degree of Polynomial|degree]] $k + 1$. If $f$ does not have a [[Definition:Root of Polynomial|root]] in $\Z_p$, our claim is satisfied. Hence suppose $f$ does have a root $x_0$. From [[Ring of Integers Modulo Prime is Field]], $\Z_p$ is a [[Definition:Field (Abstract Algebra)|field]]. Applying the [[Polynomial Factor Theorem]], since $\map f {x_0} = 0$: :$\map f x = \paren {x - x_0} \map Q x$ where $Q$ is a [[Definition:Polynomial over Field|polynomial]] of [[Definition:Degree of Polynomial|degree]] $k$. By [[Euclid's Lemma for Prime Divisors]]: :$\map f x = 0 \iff x - x_0 = 0$ or $\map Q x = 0$ By induction hypothesis, $Q$ has at most $k$ [[Definition:Root of Polynomial|roots]]. Hence $f$ has at most $k + 1$ [[Definition:Root of Polynomial|roots]]. By the [[Principle of Mathematical Induction]], the theorem is true for any $n$. {{qed}} {{Namedfor|Joseph Louis Lagrange}} [[Category:Number Theory]] [[Category:Polynomial Theory]] [[Category:Proofs by Induction]] 6lpsyjudkseo2swix5o3u7a4nui5874	1
An '''assumption''' is a [[Definition:Statement|statement]] which is introduced into an [[Definition:Logical Argument|argument]], whose [[Definition:Truth Value|truth value]] is (temporarily) accepted as [[Definition:True|True]]. In mathematics, the keyword '''let''' is often the indicator here that an assumption is going to be introduced. For example: :'''Let $p$''' (be true) ... can be interpreted, in [[Definition:Natural Language|natural language]], as: :'''Let us assume, for the sake of argument, that $p$ is true''' ...	1
Let us assume that the '''[[Principle of Complete Induction|PCI]]''' is true. Let $\O \subset S \subseteq \N$. We need to show that $S$ has a [[Definition:Minimal Element|minimal element]], and so demonstrate that the '''[[Well-Ordering Principle|WOP]]''' holds. {{AimForCont}} that: :$(C): \quad S$ has no [[Definition:Minimal Element|minimal element]]. Let $\map P n$ be the [[Definition:Propositional Function|propositional function]]: :$n \notin S$ Suppose $0 \in S$. We have that $0$ is a [[Definition:Lower Bound of Set|lower bound]] for $\N$. Hence by [[Lower Bound for Subset]], $0$ is also a [[Definition:Lower Bound of Set|lower bound]] for $S$. $0 \notin S$, otherwise $0$ would be the [[Definition:Minimal Element|minimal element]] of $S$. This contradicts our supposition $(C)$, namely, that $S$ does not have a [[Definition:Minimal Element|minimal element]]. So $0 \notin S$ and so $\map P 0$ holds. Suppose $\map P j$ for $0 \le j \le k$. That is: :$\forall j \in \closedint 0 k: j \notin S$ where $\closedint 0 k$ denotes the [[Definition:Closed Interval|closed interval between $0$ and $k$]]. Now if $k + 1 \in S$ it follows that $k + 1$ would then be the [[Definition:Minimal Element|minimal element]] of $S$. So then $k + 1 \notin S$ and so $\map P {k + 1}$. Thus we have proved that: :$(1): \quad \map P 0$ holds :$(2): \quad \paren {\forall j \in \closedint 0 k: \map P j} \implies \map P {k + 1}$ So we see that '''[[Principle of Complete Induction|PCI]]''' implies that $\map P n$ holds for all $n \in \N$. But this means that $S = \O$, which is a [[Definition:Contradiction|contradiction]] of the fact that $S$ is [[Definition:Non-Empty Set|non-empty]]. So, by [[Proof by Contradiction]], $S$ must have a [[Definition:Minimal Element|minimal element]]. That is, $\N$ satisfies the [[Well-Ordering Principle]]. Thus '''[[Principle of Complete Induction|PCI]]''' implies '''[[Well-Ordering Principle|WOP]]'''.	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] match for each [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc|} \hline p & \oplus & p \\ \hline F & F & F \\ T & F & T \\ \hline \end{array}$ {{qed}}	1
From [[Clavius's Law]]: :$\neg p \implies p \vdash p$ follows the [[Law of Excluded Middle]]: :$\vdash p \lor \neg p$	1
{{BeginTableau|p \implies \left({q \implies r}\right) \vdash \left({p \implies q}\right) \implies \left({p \implies r}\right)}} {{Premise|1|p \implies \left({q \implies r}\right)}} {{Assumption|2|p \implies q}} {{Assumption|3|p}} {{ModusPonens|4|1, 3|q \implies r|1|3}} {{ModusPonens|5|2, 3|q|2|3}} {{ModusPonens|6|1, 2, 3|r|4|5}} {{Implication|7|1, 2|p \implies r|3|6}} {{Implication|8|1|\left({p \implies q}\right) \implies \left({p \implies r}\right)|2|7}} {{EndTableau}} {{qed}}	1
:$p \iff q \vdash p \implies q$	1
: $\left({\neg p \land q}\right) \lor \left({p \land \neg q}\right) \vdash \neg \left ({p \iff q}\right)$	1
Let $T$ be a [[Definition:Theory (Logic)|complete $\mathcal L$-theory]]. Let $\mathfrak C$ be a [[Definition:Monster Model|monster model]] for $T$. Let $A\subseteq B$ be [[Definition:Subset|subsets]] of the universe of $\mathfrak C$. Let $\pi(\bar x)$ be an [[Definition:Type|$n$-type]] over $B$. If $\pi$ does not [[Definition:Fork|fork]] over $A$, then there is a [[Definition:Complete Type|complete $n$-type]] $p$ over $B$ such that $\pi \subseteq p$ and $p$ does not fork over $A$.	1
The set $\operatorname{Instr}$ of [[Unique Code for URM Instruction|codes of all basic URM instructions]] is [[Definition:Primitive Recursive Set|primitive recursive]].	1
Let $x$ be an [[Definition:Object Variable|object variable]] from the [[Definition:Universe of Discourse|universe]] of '''rational beings'''. Let $\map H x$ denote the [[Definition:Propositional Function|propositional function]] ''$x$ is '''human'''''. Let $\map M x$ denote the [[Definition:Propositional Function|propositional function]] ''$x$ is '''mortal'''''. Let $S$ be a [[Definition:Proper Name|proper name]] that denotes {{AuthorRef|Socrates}}. The argument can then be expressed as: {{begin-eqn}} {{eqn | n = 1 | lo= \forall x: | l = \map H x | o = \implies | r = \map M x | c = }} {{eqn | ll= \therefore | l = \map H S | o = \implies | r = \map M S | c = [[Universal Instantiation]] }} {{eqn | n = 2 | l = \map H S | o = | c = }} {{eqn | n = 3 | ll= \therefore | l = \map M S | o = | c = [[Modus Ponendo Ponens]] }} {{end-eqn}} That is: :''{{AuthorRef|Socrates}} is mortal.'' {{qed}}	1
An '''amphiboly''' is an [[Definition:Ambiguity|ambiguity]] resulting from poor [[Definition:Syntax|syntax]].	1
{{BeginTableau|\neg \paren {p \iff q} \vdash \paren {p \lor q} \land \paren {\neg p \lor \neg q} }} {{Premise |1|\neg \paren {p \iff q} }} {{SequentIntro|2|1|\paren {p \lor q} \land \neg \paren {p \land q}|1|[[Non-Equivalence as Conjunction of Disjunction with Negation of Conjunction]]}} {{DeMorgan |3|1|\paren {p \lor q} \land \paren {\neg p \lor \neg q}|2|Disjunction of Negations}} {{EndTableau}} {{BeginTableau|\paren {p \lor q} \land \paren {\neg p \lor \neg q} \vdash \neg \paren {p \iff q} }} {{Premise |1|\paren {p \lor q} \land \paren {\neg p \lor \neg q} }} {{DeMorgan |2|1|\paren {p \lor q} \land \neg \paren {p \land q}|1|Disjunction of Negations}} {{SequentIntro|3|1|\neg \paren {p \iff q}|2|[[Non-Equivalence as Conjunction of Disjunction with Negation of Conjunction]]}} {{EndTableau|qed}}	1
Let $\mathbf A$ be a [[Definition:WFF of Propositional Logic|WFF of propositional logic]]. Then $\mathbf A$ is [[Definition:Satisfiable (Boolean Interpretations)|satisfiable]] [[Definition:Iff|iff]] its [[Definition:Negation|negation]] $\neg \mathbf A$ is [[Definition:Falsifiable (Boolean Interpretations)|falsifiable]].	1
{{ProofWanted|Can be seen to be [[Definition:Logical Equivalence|logically equivalent]] to [[Conditional is not Left Self-Distributive/Formulation 1]] by application of the [[Rule of Implication]] and [[Modus Ponendo Ponens]].}}	1
=== [[Self-Distributive Law for Conditional/Forward Implication/Formulation 2/Proof 1|Proof of Forward Implication]] === {{:Self-Distributive Law for Conditional/Forward Implication/Formulation 2/Proof 1}} === [[Self-Distributive Law for Conditional/Reverse Implication/Formulation 2/Proof|Proof of Reverse Implication]] === {{:Self-Distributive Law for Conditional/Reverse Implication/Formulation 2/Proof}} {{BeginTableau|\vdash \paren {p \implies \paren {q \implies r} } \iff \paren {\paren {p \implies q} \implies \paren {p \implies r} } }} {{TheoremIntro|1|\paren {p \implies \paren {q \implies r} } \implies \paren {\paren {p \implies q} \implies \paren {p \implies r} }|[[Self-Distributive Law for Conditional/Forward Implication/Formulation 2|Self-Distributive Law for Conditional: Forward Implication: Formulation 2]]}} {{TheoremIntro|2|\paren {\paren {p \implies q} \implies \paren {p \implies r} } \implies \paren {p \implies \paren {q \implies r} }|[[Self-Distributive Law for Conditional/Reverse Implication/Formulation 2|Self-Distributive Law for Conditional: Reverse Implication: Formulation 2]]}} {{BiconditionalIntro|3||\paren {p \implies \paren {q \implies r} } \iff \paren {\paren {p \implies q} \implies \paren {p \implies r} }|1|2}} {{EndTableau}} {{qed}}	1
Since $\Gamma$ is [[Definition:Contradictory Branch|contradictory]], there is some [[Definition:WFF of Propositional Logic|WFF]] $\mathbf A$ such that both $\mathbf A$ and $\neg \mathbf A$ [[Definition:Occurrence along Branch|occur]] along $\Gamma$. Since $\Gamma'$ is an [[Definition:Extension of Branch of Propositional Tableau|extension]] of $\Gamma$, $\mathbf A$ and $\neg \mathbf A$ also [[Definition:Occurrence along Branch|occur]] along $\Gamma'$. Hence $\Gamma'$ is [[Definition:Contradictory Branch|contradictory]]. {{qed}} [[Category:Propositional Tableaus]] qma3zjj5lx66bs29ndupq530a06tdmc	1
The proof proceeds by [[Principle of Mathematical Induction|induction]]. For all $n \in \Z_{\ge 3}$, let $P \left({n}\right)$ be the [[Definition:Proposition|proposition]]: :$S_n$ ends either with $\text{ba}$ or with $\text{ab}$ We note in passing that $S_1 = \text a$ and $S_2 = \text b$, so neither of these ends either with $\text{ba}$ or with $\text{ab}$. === Basis for the Induction === $P \left({3}\right)$ is the case: :$S_3 = \text{ba}$ Thus $P \left({3}\right)$ is seen to hold. $P \left({4}\right)$ is the case: :$S_4 = \text{bab}$ Thus $P \left({4}\right)$ is seen to hold. This is the [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that, if $P \left({k}\right)$ is true, where $k \ge 3$, then it logically follows that $P \left({k + 1}\right)$ is true. So this is the [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$S_k$ ends either with $\text{ba}$ or with $\text{ab}$ and: :$S_{k - 1}$ ends either with $\text{ba}$ or with $\text{ab}$ from which it is to be shown that: :$S_{k + 1}$ ends either with $\text{ba}$ or with $\text{ab}$ === Induction Step === This is the [[Principle of Mathematical Induction#Induction Step|induction step]]: By definition of [[Definition:Fibonacci String|Fibonacci string]]: :$S_{k + 1} = S_k S_{k - 1}$ [[Definition:Concatenation (Formal Systems)|concatenated]]. So $S_{k + 1}$ end with $S_{k - 1}$. By the [[Fibonacci String Begins with ba#Induction Hypothesis|induction hypothesis]], $S_k$ ends either with $\text{ba}$ or with $\text{ab}$. Thus $S_{k + 1}$ likewise ends either with $\text{ba}$ or with $\text{ab}$. So $P \left({k}\right) \implies P \left({k + 1}\right)$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :for all $n \in \Z$ such that $n \ge 3$, $S_n$ends either with $\text{ba}$ or with $\text{ab}$. [[Category:Fibonacci Strings]] fa27blmnmughxk5hw6jd7wiavesx2th	1
We observe that: :$\map \Mult {n, 0} = n \times 0 = 0$ and that :$\map \Mult {n, m + 1} = n \times \paren {m + 1} = \paren {n \times m} + n = \map \Add {\map \Mult {n, m}, n}$. We are to show that $\Mult$ is obtained by [[Definition:Primitive Recursion|primitive recursion]] from known [[Definition:Primitive Recursive Function|primitive recursive functions]]. First we note that: :$\map \Mult {n, 0} = 0 = \map \Zero n$ where $\map \Zero n$ is the [[Definition:Zero Function|zero function]], which is [[Definition:Basic Primitive Recursive Function|basic primitive recursive]]. Next we need to find a [[Definition:Primitive Recursive Function|primitive recursive function]] $g: \N^3 \to \N$ such that: :$\map \Mult {n, m + 1} = \map g {n, m, \map \Mult {n, m} }$ Because $\map \Mult {n, m + 1} = \map \Add {\map \Mult {n, m}, n}$, we see that a suitable function for $g$ is: :$\map g {n_1, n_2, n_3} = \map \Add {n_3, n_1}$ Using [[Definition:Projection Function|projection functions]], we can write this as: :$\map g {n_1, n_2, n_3} = \map \Add {\map {\pr_3^3} {n_1, n_2, n_3}, \map {\pr_1^3} {n_1, n_2, n_3} }$. This shows that $g$ is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from [[Addition is Primitive Recursive |$\Add$, which is primitive recursive]], and the [[Definition:Basic Primitive Recursive Function|basic primitive recursive functions]] $\pr_3^3$ and $\pr_1^3$. So $g$ is [[Definition:Primitive Recursive Function|primitive recursive]]. So $\Mult$ is obtained by [[Definition:Primitive Recursion|primitive recursion]] from the [[Definition:Primitive Recursive Function|primitive recursive functions]] $g$ and $\Zero$, and so is [[Definition:Primitive Recursive Function|primitive recursive]]. {{qed}} [[Category:Primitive Recursive Functions]] nuewcnrlqmjys1fme8euz4utktjtlv1	1
While this holds: :$\paren {p \implies q} \implies r \vdash \paren {p \implies r} \implies \paren {q \implies r}$ its converse does not: :$\paren {p \implies r} \implies \paren {q \implies r} \not \vdash \paren {p \implies q} \implies r$	1
: $\left({p \implies q}\right) \dashv \vdash \left({p \vdash q}\right)$ That is, the [[Definition:Conditional|conditional]] is [[Definition:Logical Equivalence|logically equivalent]] to [[Definition:Logical Implication|logical implication]].	1
Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \N_{>1}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\dfrac {\d^n} {\d x^n} \ln x = \dfrac {\paren {n - 1}! \paren {-1}^{n - 1} } {x^n}$ === Basis for the Induction === $\map P 1$ is true, as this just says: :$\dfrac \d {\d x} \ln x = \dfrac 1 x$ This follows by [[Derivative of Natural Logarithm Function]] This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\dfrac {\d^k} {\d x^k} \ln x = \dfrac {\paren {k - 1}! \paren {-1}^{k - 1} } {x^k}$ Then we need to show: :$\dfrac {\d^{k + 1} } {\d x^{k + 1} } \ln x = \dfrac {k! \paren {-1}^k} {x^{k + 1} }$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \frac {\d^{k + 1} } {\d x^{k + 1} } \ln x | r = \map {\frac \d {\d x} } {\frac {\d^k} {\d x^k} \ln x} | c = }} {{eqn | r = \map {\frac \d {\d x} } {\paren {k - 1}! \paren {-1}^{k - 1} x^{-k} } | c = [[Nth Derivative of Natural Logarithm#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \paren {k - 1}! \paren {-1}^{k - 1} \map {\frac \d {\d x} } {x^{-k} } | c = [[Derivative of Constant Multiple]] }} {{eqn | r = \paren {k - 1}! \paren {-1}^{k - 1} \paren {k x^{-k - 1} } | c = [[Power Rule for Derivatives]] }} {{eqn | r = k! \paren {-1}^k x^{-\paren {k + 1} } | c = {{Defof|Factorial}} }} {{eqn | r = \frac {k! \paren {-1}^k} {x^{k + 1} } | c = }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\dfrac {\d^n} {\d x^n} \ln x = \dfrac {\paren {n - 1}! \paren {-1}^{n - 1} } {x^n}$ {{Qed}} [[Category:Derivatives]] [[Category:Natural Logarithms]] [[Category:Proofs by Induction]] 4kn1vgarampqz7xu9rh0ek5g1vjhroe	1
Let $\LL$ be a [[Definition:Logical Language|logical language]]. Let $\mathscr M$ be a [[Definition:Formal Semantics|formal semantics]] for $\LL$. Let $\FF$ be a [[Definition:Set|set]] of [[Definition:Logical Formula|logical formulas]] from $\LL$. Let $\phi$ be an [[Definition:Semantic Consequence|$\mathscr M$-semantic consequence]] of $\FF$. Let $\FF'$ be another [[Definition:Set|set]] of [[Definition:Logical Formula|logical formulas]]. Then: :$\FF \cup \FF' \models_{\mathscr M} \phi$ that is, $\phi$ is also a [[Definition:Semantic Consequence|semantic consequence]] of $\FF \cup \FF'$.	1
{{Disambiguate|Definition:Model|I suspect model of a first-order theory $\LL$, which is more specific than what is linked to now}} Let $T$ be an $\LL$-theory with an infinite [[Definition:Model (Logic)|model]]. Then for each infinite cardinal $\kappa \ge \card \LL$, there exists a [[Definition:Model (Logic)|model]] of $T$ with cardinality $\kappa$.	1
A '''tautology''' is a [[Definition:Statement|statement]] which is ''always [[Definition:True|true]]'', independently of any relevant circumstances that could theoretically influence its [[Definition:Truth Value|truth value]]. It is epitomised by the form: :$p \implies p$ that is: :'''if $p$ is [[Definition:True|true]] [[Definition:Conditional|then]] $p$ is [[Definition:True|true]].''' An example of a "relevant circumstance" here is the [[Definition:Truth Value|truth value]] of $p$. The archetypal '''tautology''' is symbolised by $\top$, and referred to as [[Definition:Top (Logic)|Top]].	1
The proof proceeds by [[Principle of Mathematical Induction|induction]]. By definition, $\Gamma$ is a [[Definition:Finite Sequence|finite sequence]] of [[Definition:Elementary Column Operation|elementary column operations]] on $\mathbf A$. Let $\sequence e_k$ denote a [[Definition:Finite Sequence|finite sequence]] of [[Definition:Elementary Column Operation|elementary column operations]] $\tuple {e_1, e_2, \ldots, e_k}$ applied on $\mathbf A$ in order: first $e_1$, then $e_2$, then $\ldots$, then $e_k$. Let $\Gamma_k$ be the [[Definition:Column Operation|column operation]] which consists of $\sequence e_k$. Let $\mathbf E_k$ denote the [[Definition:Elementary Column Matrix|elementary column matrix]] of [[Definition:Order of Square Matrix|order]] $n$ formed by applying $e_k$ to the [[Definition:Unit Matrix|unit matrix]] $I_n$. For all $r \in \Z_{>0}$, let $\map P r$ be the [[Definition:Proposition|proposition]]: :For all $\Gamma_r$, there exists a [[Definition:Unique|unique]] [[Definition:Invertible Matrix|invertible]] [[Definition:Square Matrix|square matrix]] $\mathbf K_r$ of [[Definition:Order of Square Matrix|order $n$]] such that: ::$\mathbf A \mathbf K_r = \mathbf B_r$ :where: ::$\Gamma_r$ is a [[Definition:Column Operation|column operation]] which transforms $\mathbf A$ to a new [[Definition:Matrix|matrix]] $\mathbf B_r \in \map \MM {m, n}$. ::$\mathbf K_r$ is the [[Definition:Matrix Product (Conventional)|product]] of the [[Definition:Finite Sequence|finite sequence]] of [[Definition:Elementary Column Matrix|elementary column matrices]]: :::$\mathbf K_r = \mathbf E_1 \mathbf E_2 \dotsb \mathbf E_{r - 1} \mathbf E_r$ === Basis for the Induction === $\map P 1$ is the case where $\Gamma_1$ is a single-[[Definition:Term of Sequence|term]] [[Definition:Finite Sequence|sequence]] consisting of one [[Definition:Elementary Column Operation|elementary column operation]] $e_1$. Let $e_1$ be an [[Definition:Elementary Column Operation|elementary column operation]] operating on $\mathbf A$, which transforms $\mathbf A$ into $\mathbf B_1$. By definition, there exists [[Definition:Unique|exactly one]] [[Definition:Elementary Column Matrix|elementary column matrix]] $\mathbf E_1$ of [[Definition:Order of Square Matrix|order $m$]] such that $\mathbf E_1$ is the result of applying $e_1$ to the [[Definition:Unit Matrix|unit matrix]] $\mathbf I$ of [[Definition:Order of Square Matrix|order $n$]]. From the [[Elementary Column Operations as Matrix Multiplications/Corollary|corollary to Elementary Column Operations as Matrix Multiplications]]: :$\mathbf A \mathbf E_1 = \mathbf B_1$ By [[Elementary Column Matrix is Invertible]], $E_1$ is [[Definition:Invertible Matrix|invertible]]. Thus $\map P 1$ is seen to hold. This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is the [[Definition:Induction Hypothesis|induction hypothesis]]: :For all $\Gamma_k$, there exists a [[Definition:Unique|unique]] [[Definition:Invertible Matrix|invertible]] [[Definition:Square Matrix|square matrix]] $\mathbf K_k$ of [[Definition:Order of Square Matrix|order $n$]] such that: ::$\mathbf A \mathbf K_k = \mathbf B_k$ from which it is to be shown that: :For all $\Gamma_{k + 1}$, there exists a [[Definition:Unique|unique]] [[Definition:Invertible Matrix|invertible]] [[Definition:Square Matrix|square matrix]] $\mathbf K_{k + 1}$ of [[Definition:Order of Square Matrix|order $n$]] such that: ::$\mathbf A \mathbf K_{k + 1} = \mathbf B_{k + 1}$ === Induction Step === This is the [[Definition:Induction Step|induction step]]: By definition, $\Gamma_{k + 1}$ is a [[Definition:Column Operation|column operation]] consisting of a [[Definition:Finite Sequence|finite sequence]] of [[Definition:Elementary Column Operation|elementary column operations]] $\tuple {e_1, e_2, \ldots, e_k, e_{k + 1} }$ applied on $\mathbf A$ in order. Thus $\Gamma_{k + 1}$ consists of the [[Definition:Finite Sequence|finite sequence]] of [[Definition:Elementary Column Operation|elementary column operations]] $\tuple {e_1, e_2, \ldots, e_k}$ applied on $\mathbf A$ in order, followed by a further [[Definition:Elementary Column Operation|elementary column operation]] $e_{k + 1}$. By the [[Column Operation is Equivalent to Post-Multiplication by Product of Elementary Matrices#Induction Hypothesis|induction hypothesis]], there exists a [[Definition:Unique|unique]] [[Definition:Invertible Matrix|invertible]] [[Definition:Square Matrix|square matrix]] $\mathbf K_k$ of [[Definition:Order of Square Matrix|order $m$]] such that: :$\mathbf A \mathbf K_k = \mathbf B_k$ where $\mathbf B_k \in \map \MM {m, n}$ is the result of applying $\sequence e_k$ to $\mathbf A$ in order. Let $e_{k + 1}$ be applied to $\mathbf B_k$. By definition, there exists [[Definition:Unique|exactly one]] [[Definition:Elementary Column Matrix|elementary column matrix]] $\mathbf E_{k + 1}$ of [[Definition:Order of Square Matrix|order $m$]] such that $\mathbf E_{k + 1}$ is the result of applying $e_{k + 1}$ to the [[Definition:Unit Matrix|unit matrix]] $\mathbf I$ of [[Definition:Order of Square Matrix|order $m$]]. Then: {{begin-eqn}} {{eqn | l = \mathbf B_{k + 1} | r = \mathbf B_k \mathbf E_{k + 1} | c = [[Elementary Column Operations as Matrix Multiplications/Corollary|Corollary to Elementary Column Operations as Matrix Multiplications]] }} {{eqn | r = \paren {\mathbf A \mathbf K_k} \mathbf E_{k + 1} | c = }} {{eqn | r = \mathbf A \paren {\mathbf K_k \mathbf E_{k + 1} } | c = [[Matrix Multiplication is Associative]] }} {{end-eqn}} By [[Product of Matrices is Invertible iff Matrices are Invertible]], $\mathbf K_k \mathbf E_{k + 1}$ is [[Definition:Invertible Matrix|invertible]]. We have that $\mathbf K_k$ is the [[Definition:Unique|unique]] [[Definition:Invertible Matrix|invertible]] [[Definition:Square Matrix|square matrix]] resulting from the application of $\sequence e_k$ on $\mathbf I_m$. Thus $\mathbf K_k \mathbf E_{k + 1}$ is the [[Definition:Unique|unique]] [[Definition:Invertible Matrix|invertible]] [[Definition:Square Matrix|square matrix]] resulting from the application of $\sequence e_{k + 1}$ on $\mathbf I_m$. So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore, for every [[Definition:Column Operation|column operation]] $\Gamma$ which transforms $\mathbf A$ to a new [[Definition:Matrix|matrix]] $\mathbf B \in \map \MM {m, n}$, there exists a [[Definition:Unique|unique]] [[Definition:Invertible Matrix|invertible]] [[Definition:Square Matrix|square matrix]] $\mathbf R$ of [[Definition:Order of Square Matrix|order $m$]] such that: :$\mathbf A \mathbf K = \mathbf B$ where: :$\mathbf K$ is the [[Definition:Matrix Product (Conventional)|product]] of a [[Definition:Finite Sequence|finite sequence]] of [[Definition:Elementary Column Matrix|elementary column matrices]]. {{qed}}	1
:$\displaystyle \sum_{j \mathop = 1}^n \paren {2 j - 1}^3 = 1^3 + 3^3 + 5^3 + \dotsb + \paren {2 n − 1}^3 = n^2 \paren {2 n^2 − 1}$	1
The [[Definition:Zero Function|zero function]] is computed by the following [[Definition:URM Program|URM program]]: {| |- ! align="right" | Line !! ! align="left" | Command |- | align="right" | $1$ || | align="left" | $\map Z 1$ |} This sets the value $0$ into $R_1$ and then stops. The [[Definition:Unlimited Register Machine#Output|output]] $0$ is in $R_1$ when the program terminates. {{qed}} [[Category:URM Programs]] [[Category:Primitive Recursive Functions]] j8wnk5c37v24jr0wfwo7ehgessgcfj2	1
Let $\mathbf H$ be a [[Definition:Countable Set|countable set]] of [[Definition:WFF of Propositional Logic|WFFs of propositional logic]]. Suppose $\mathbf H$ is [[Definition:Finitely Satisfiable|finitely satisfiable]] for [[Definition:Boolean Interpretation|boolean interpretations]]. That is, suppose that every [[Definition:Finite Set|finite]] [[Definition:Subset|subset]] $\mathbf H' \subseteq \mathbf H$ is [[Definition:Satisfiable (Boolean Interpretations)|satisfiable]] for [[Definition:Boolean Interpretation|boolean interpretations]]. Then $\mathbf H$ has a [[Definition:Model (Boolean Interpretations)|model]].	1
Let $f: \N^{k+1} \to \N$ be a [[Definition:URM Computability|URM computable function]]. Let $P$ be a [[Definition:URM Program|URM program]] which computes $f$. Let $u = \rho \left({P}\right)$ be the [[Definition:Unlimited Register Machine#Number of Registers Used|number of registers used]] by $P$. We can use: * the [[Definition:Unlimited Register Machine#Registers|registers]] $R_{u+1}, R_{u+2}, \ldots, R_{u+k}$ to store the [[Definition:Unlimited Register Machine#Input|input]] $\left({n_1, n_2, \ldots, n_k}\right)$; * the [[Definition:Unlimited Register Machine#Registers|register]] $R_{u+k+1}$ to store the current value of the recursion variable $y$. We check whether or not $f \left({n_1, n_2, \ldots, n_k}\right) = 0$ by comparing the output from running $P$ (appearing in [[Definition:Unlimited Register Machine#Registers|register]] $1$ at the end of the running of $P$) with the number in [[Definition:Unlimited Register Machine#Registers|register]] $R_{u+k+2}$, which remains at $0$ throughout. The following [[Definition:Algorithm|algorithm]] can be followed to create a [[Definition:URM Program|URM program]] $H$ to [[Definition:URM Computability|compute]] $h$. We assume that the [[Definition:Unlimited Register Machine#Input|input]] is $\left({n_1, n_2, \ldots, n_k}\right)$, which is held in $R_1, R_2, \ldots, R_k$. We are to use the following registers: * $R_{u+1}, R_{u+2}, \ldots, R_{u+k}$ will be used to store the input $\left({n_1, n_2, \ldots, n_k}\right)$ so it does not get overwritten. * $R_{u+k+1}$ will hold the value of $y$. * $R_{u+k+2}$ will hold the $0$ throughout. When $r_{u+k+2} = r_{u+k+1}$, the computation will have ended. We also define $v = \lambda \left({H}\right)$ to be the [[Definition:Unlimited Register Machine#Length of Program|number of basic instructions]] in $H$. {| border="1" |- ! align="right" | Step !! ! align="left" | Process ! align="left" | Notes ! align="left" | $\lambda \left({H}\right)$ |- | align="right" | $1$ || | align="left" | Append a [[Block Copy Program]] $C \left({1, u, k}\right)$ to $H$<ref>$H$, at this point, is a [[Definition:Null URM Program|null URM program]].</ref>. | This stores the input somewhere safe so it can be accessed again later. | $k$ |- | align="right" | $2$ || | align="left" | Increment the <tt>Jump</tt>s in $P$ by $k$ lines<ref>To '''increment the <tt>Jump</tt>s by $r$''' for any [[Normalized URM Program|normalized URM program]] is done by changing all <tt>Jump</tt>s of the form $J \left({m, n, q}\right)$ to $J \left({m, n, q+r}\right)$.</ref>. Call this amended version $P'$. | As $P$ was written so as to start from line 1, we need to move all the <tt>Jump</tt>s so as to point to the same lines relative to the start of $P'$. |- | align="right" | $3$ || | align="left" | Append $P'$ to $H$. | This will compute $f \left({n_1, n_2, \ldots, n_k, y}\right)$. | $k + s$ |- | align="right" | $4$ || | align="left" | Append the command $J \left({1, u+k+2, v}\right)$ to $H$. | This <tt>Jump</tt>s $H$ to the end of the program if the output of $P$ is zero. | $k + s + 1$ |- | align="right" | $5$ || | align="left" | Append the command $S \left({u + k + 1}\right)$ to $H$. | Increment $y$. | $k + s + 2$ |- | align="right" | $6$ || | align="left" | Append a [[Block Copy Program]] $C \left({u+k+1, 1, k+1}\right)$ to $H$. | Recall the input values, and put $y$ in $R_{k+1}$. | $2 k + s + 3$ |- | align="right" | $8$ || | align="left" | Append the command $J \left({1, 1, k + 1}\right)$ to $H$. | This makes the program jump back to the start of $P'$. | $2 k + s + 4$ |- | align="right" | $7$ || | align="left" | Append the command $C \left({1, k+2}\right)$ to $H$. | This copies the [[Definition:Unlimited Register Machine#Output|output]] of $P'$ into the last input location for function $g$, that is, the output from $h \left({n_1, n_2, \ldots, n_k, i-1}\right)$. | $2 k + s + 5$ |- | align="right" | $8$ || | align="left" | Append the command $C \left({u+k+1, 1}\right)$ to $H$. | Put $y$ into the output register. | $v = 2 k + s + 6$ |} It can easily be determined that $H$ computes $g$. Hence $g$ is [[Definition:URM Computability|URM computable]]. {{qed}} {{proofread}}	1
{{BeginTableau|p \implies \paren {q \implies r} \vdash q \implies \paren {p \implies r} }} {{Premise|1|p \implies \paren {q \implies r} }} {{Assumption|2|q}} {{Assumption|3|p}} {{ModusPonens|4|1, 3|q \implies r|1|3}} {{ModusPonens|5|1, 2, 3|r|2|4}} {{Implication|6|1, 2|p \implies r|3|5}} {{Implication|7|1|q \implies \paren {p \implies r}|2|6}} {{EndTableau|qed}}	1
The rule of '''biconditional elimination''' is a [[Definition:Valid Argument|valid]] deduction [[Definition:Sequent|sequent]] in [[Definition:Propositional Logic|propositional logic]].	1
[[Definition:Axiom (Formal Systems)|Axiom]] $(A2)$ is [[Definition:Independent Axiom|independent]] from $(A1)$, $(A3)$, $(A4)$.	1
Let $\map P n$ be a [[Definition:Propositional Function|propositional function]] depending on $n \in \N$. If: :$(1): \quad \map P n$ is true for all $n \le d$ for some $d \in \N$ :$(2): \quad \forall m \in \N: \paren {\forall k \in \N, m \le k < m + d: \map P k} \implies \map P {m + d}$ then $\map P n$ is true for all $n \in \N$.	1
Let $\mathcal P_0$ be the [[Definition:Vocabulary of Propositional Logic|vocabulary]] of [[Definition:Language of Propositional Logic|language of propositional logic]]. Let $S \subseteq \mathcal P_0$ be a [[Definition:Finite Set|finite set]] of $n$ [[Definition:Letter|letters]] from $\mathcal P_0$. Then there are $2^n$ different [[Definition:Partial Boolean Interpretation|partial boolean interpretations]] for $S$.	1
For each [[Definition:Term of Sequence|term]] of a [[Definition:Finite Sequence|sequence]] in $\map V {n, p}$ there are $p$ possible values. There are $n$ such [[Definition:Term of Sequence|terms]]. Hence there are $\underbrace {p \times p \times \cdots \times p}_{n \text { times} } = p^n$ different possible [[Definition:Finite Sequence|sequences]] in $\map V {n, p}$. {{qed}}	1
: $p \vdash p \lor p$	1
:$\vdash \paren {p \implies q} \implies \paren {\paren {q \implies r} \implies \paren {p \implies r} }$	1
We apply the [[Method of Truth Tables]] to the proposition. $\begin{array}{|ccc|cc||c|} \hline p & \lor & q & \neg & p & q\\ \hline F & F & F & T & F & F \\ F & T & T & T & F & T \\ T & T & F & F & T & F \\ T & T & T & F & T & T \\ \hline \end{array}$ As can be seen, when $p \lor q$ is [[Definition:True|true]], and so is $\neg p$, then $q$ is also [[Definition:True|true]]. {{qed}}	1
By definition of [[Definition:Bottom-Up Grammar|bottom-up grammar]], the [[Definition:Well-Formed Formula|well-formed formulas]] of $\mathcal F$ comprise: :[[Definition:Letter|letters]] of $\mathcal F$; :expressions resulting from [[Definition:Rule of Formation|rules of formation]]. Either case is dealt with by the assumptions on $\Phi$. Hence the result, from [[Proof by Cases]]. {{qed}} [[Category:Formal Systems]] 130mstbdlgv4psjvlwcp6wj7c3bb7t1	1
Let $P$ denote the [[Definition:Simple Statement|simple statement]] ''{{AuthorRef|Socrates}} is a man.''. Let $Q$ denote the [[Definition:Simple Statement|simple statement]] ''{{AuthorRef|Socrates}} is mortal.''. The argument can then be expressed as: {{begin-eqn}} {{eqn | n = 1 | l = P | o = \implies | r = Q | c = }} {{eqn | n = 2 | l = P | o = | c = }} {{eqn | n = 3 | ll= \therefore | l = Q | o = | c = [[Modus Ponendo Ponens]] }} {{end-eqn}} That is: :''{{AuthorRef|Socrates}} is mortal.'' {{qed}}	1
'''Argumentum ad verecundiam''', or '''argument from authority''', is a [[Definition:Logical Argument|logical argument]] that infers something is [[Definition:True|true]] on the basis that a knowledgeable and well-reputed person has said it. An '''argument from authority''' may be [[Definition:Valid Argument|valid]] or [[Definition:Invalid Argument|invalid]], depending on the circumstances. If the trustworthy person is also an expert in the field, and is free to speak their mind about the matter, then the [[Definition:Logical Argument|argument]] has some validity. Otherwise, it generally does not. That said, '''argumentum ad verecundiam''' can never serve as a (mathematical) [[Definition:Proof|proof]], since no authority could ever be infallible. Thus, in the context of {{ProofWiki}}, such an [[Definition:Logical Argument|argument]] should be considered [[Definition:Fallacy|fallacious]].	1
Let $\mathcal L$ be a [[Definition:Logical Language|logical language]]. Let $\mathscr M$ be a [[Definition:Formal Semantics|formal semantics]] for $\mathcal L$. Let $\mathcal F$ be an [[Definition:Unsatisfiable Set of Formulas|$\mathscr M$-unsatisfiable set of formulas]] from $\mathcal L$. Let $\phi \in \mathcal F$ be a [[Definition:Tautology (Formal Semantics)|tautology]]. Then $\mathcal F \setminus \set {\phi}$ is also [[Definition:Unsatisfiable Set of Formulas|$\mathscr M$-unsatisfiable]].	1
=== [[Rule of Transposition/Variant 1/Formulation 2/Forward Implication/Proof|Proof of Forward Implication]] === {{:Rule of Transposition/Variant 1/Formulation 2/Forward Implication/Proof}} === [[Rule of Transposition/Variant 1/Formulation 2/Reverse Implication/Proof|Proof of Reverse Implication]] === {{:Rule of Transposition/Variant 1/Formulation 2/Reverse Implication/Proof}} {{BeginTableau|\vdash \paren {p \implies \neg q} \iff \paren {q \implies \neg p} }} {{TheoremIntro|1|\paren {p \implies \neg q} \implies \paren {q \implies \neg p}|[[Rule of Transposition/Variant 1/Formulation 2/Forward Implication|Rule of Transposition: Forward Implication]]}} {{TheoremIntro|2|\paren {q \implies \neg p} \implies \paren {p \implies \neg q}|[[Rule of Transposition/Variant 1/Formulation 2/Reverse Implication|Rule of Transposition: Reverse Implication]]}} {{BiconditionalIntro|3||\paren {p \implies \neg q} \iff \paren {q \implies \neg p}|1|2}} {{EndTableau}} {{qed}}	1
{{ProofWanted|Awaiting a reliable definition of inefficient Nash equilibrium}}	1
{{BeginTableau|\paren {p \implies \paren {q \implies r} } \implies \paren {\paren {p \implies q} \implies \paren {p \implies r} } }} {{Assumption |1|p \implies \paren {q \implies r} }} {{SequentIntro|2|1|\paren {p \implies q} \implies \paren {p \implies r}|1|[[Self-Distributive Law for Conditional/Forward Implication/Formulation 1|Self-Distributive Law for Conditional: Formulation 1]]}} {{Implication |3||\paren {p \implies \paren {q \implies r} } \implies \paren {\paren {p \implies q} \implies \paren {p \implies r} }|1|2}} {{EndTableau}} {{Qed}}	1
Let $\Phi_k: \N^{k+1} \to \N$ be given by: :$\Phi_k \left({e, n_1, n_2, \ldots, n_k}\right) = U \left({\mu z \ T_k \left({e, n_1, n_2, \ldots, n_k, z}\right)}\right)$ where $T_k$ and $U$ are as in [[Kleene's Normal Form Theorem]]. Thus we have reinterpreted [[Kleene's Normal Form Theorem]] as being about [[Definition:URM Computability#Function|URM computable functions]]. This is legitimate, as a [[URM Computable Function is Recursive]] and [[Recursive Function is URM Computable|vice versa]]. {{qed}}	1
=== Basis for the Induction === For $n = 0$ we have: :$\displaystyle \paren {x + y}^0 = 1 = \binom 0 0 x^{0 - 0} y^0 = \sum_{k \mathop = 0}^0 \binom 0 k x^{0 - k} y^k$ This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === This is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\displaystyle \paren {x + y}^n = \sum_{k \mathop = 0}^n \binom n k x^{n - k} y^k$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \paren {x + y}^{n + 1} | r = \paren {x + y} \paren {x + y}^n | c = }} {{eqn | r = x \sum_{k \mathop = 0}^n \binom n k x^{n - k}y^k + y \sum_{k \mathop = 0}^n \binom n k x^{n - k} y^k | c = [[Binomial Theorem/Integral Index#Inductive Hypothesis|Inductive Hypothesis]] }} {{eqn | r = \sum_{k \mathop = 0}^n \binom n k x^{n + 1 - k} y^k + \sum_{k \mathop = 0}^n \binom n k x^{n - k} y^{k + 1} | c = }} {{eqn | r = \binom n 0 x^{n + 1} + \sum_{k \mathop = 1}^n \binom n k x^{n + 1 - k} y^k + \binom n n y^{n + 1} + \sum_{k \mathop = 0}^{n - 1} \binom n k x^{n - k} y^{k + 1} | c = }} {{eqn | r = x^{n + 1} + y^{n + 1} + \sum_{k \mathop = 1}^n \binom n k x^{n + 1 - k} y^k + \sum_{k \mathop = 0}^{n - 1} \binom n k x^{n - k} y^{k + 1} | c = }} {{eqn | r = \binom {n + 1} 0 x^{n + 1} + \binom {n + 1} {n + 1} y^{n + 1} + \sum_{k \mathop = 1}^n \binom n k x^{n + 1 - k} y^k + \sum_{k \mathop = 1}^n \binom n {k - 1} x^{n + 1 - k} y^k | c = }} {{eqn | r = \binom {n + 1} 0 x^{n + 1} + \binom {n + 1} {n + 1} y^{n + 1} + \sum_{k \mathop = 1}^n \paren {\binom n k + \binom n {k - 1} } x^{n + 1 - k} y^k | c = }} {{eqn | r = \binom {n + 1} 0 x^{n + 1} + \binom {n + 1} {n + 1} y^{n + 1} + \sum_{k \mathop = 1}^n \binom {n + 1} k x^{n + 1 - k} y^k | c = [[Pascal's Rule]] }} {{eqn | r = \sum_{k \mathop = 0}^{n + 1} \binom {n + 1} k x^{n + 1 - k} y^k | c = }} {{end-eqn}} The result follows by the [[Principle of Mathematical Induction]]. {{qed}}	1
Let $n \in \N$ be a [[Definition:Natural Numbers|natural number]]. Let $\left({n, j}\right): \N^2 \to \N$ be defined as: :$\left({n, j}\right) = \left({n}\right)_j$ where $\left({n}\right)_j$ is the [[Definition:Prime Exponent Function|prime exponent function]]. Then $\left({n, j}\right)$ is [[Definition:Primitive Recursive Function|primitive recursive]].	1
{{begin-eqn}} {{eqn | l = p \oplus q | o = \dashv \vdash | r = \neg \left ({p \iff q}\right) | c = [[Exclusive Or is Negation of Biconditional]] }} {{eqn | o = \dashv \vdash | r = \left({\neg p \land q}\right) \lor \left({p \land \neg q}\right) | c = [[Non-Equivalence as Disjunction of Conjunctions/Formulation 1|Non-Equivalence as Disjunction of Conjunctions]] }} {{end-eqn}} {{qed}}	1
{{:Rule of Idempotence/Conjunction/Formulation 1}}	1
: $p \lor \top \dashv \vdash \top$	1
By the [[Definition:Definitional Abbreviation|definitional abbreviation]] for the [[Definition:Conditional|conditional]]: :$\mathbf A \implies \mathbf B =_{\text{def}} \neg \mathbf A \lor \mathbf B$ the [[Rule of Idempotence/Disjunction/Formulation 2/Reverse Implication|Rule of Idempotence]] can be written as: : $\neg \left({p \lor p}\right) \lor p$ This evaluates as follows: :$\begin{array}{|cccc|c|c|} \hline \neg & (p & \lor & p) & \lor & p \\ \hline 1 & 0 & 0 & 0 & 0 & 0 \\ 0 & 1 & 1 & 1 & 0 & 1 \\ 3 & 2 & 2 & 2 & 0 & 2 \\ 0 & 3 & 3 & 3 & 0 & 3 \\ \hline \end{array}$ {{qed}} [[Category:Formal Semantics]] 5wfsgwvosz5m5ujv2gjtoogcqm6423d	1
We apply the [[Principle of Structural Induction]] on the following [[Definition:Statement|statement]] $\map P \phi$: :The definition is specified for $\phi$ The given hypotheses verify the conditions for the [[Principle of Structural Induction]]. It follows that $\map D \phi$ is specified for each [[Definition:Well-Formed Formula|WFF]] $\phi$. Moreover, by virtue of the [[Definition:Unique Parsability|unique parsability]], it is ensured that each [[Definition:Well-Formed Formula|WFF]] $\phi$ has a [[Definition:Unique|unique]] definition $\map D \phi$. {{qed}} [[Category:Formal Systems]] 9trc12ncmpr7m2cvo2w8qth75d0tt7m	1
: $p \implies \left({q \land r}\right) \dashv \vdash \left({p \implies q}\right) \land \left({p \implies r}\right)$	1
:$\vdash \paren {\paren {p \implies q} \land \paren {q \implies r} } \implies \paren {p \implies r}$	1
:$\vdash \paren {p \iff \paren {q \iff r} } \iff \paren {\paren {p \iff q} \iff r}$	1
Let $\mathcal L$ be a [[Definition:Logical Language|logical language]]. Let $\mathscr M$ be a [[Definition:Formal Semantics|formal semantics]] for $\mathcal L$. Let $\mathcal F$ be a [[Definition:Set|set]] of [[Definition:Logical Formula|logical formulas]] from $\mathcal L$. Let $\phi$ be an [[Definition:Semantic Consequence|$\mathscr M$-semantic consequence]] of $\mathcal F$. Let $\psi \in \mathcal F$ be a [[Definition:Tautology|tautology]]. Then: :$\mathcal F \setminus \left\{{\psi}\right\} \models_{\mathscr M} \phi$ that is, $\phi$ is also a [[Definition:Semantic Consequence|semantic consequence]] of $\mathcal F \setminus \left\{{\psi}\right\}$.	1
{{BeginTableau|p \lor q, \neg q \vdash p}} {{Premise|1|p \lor q}} {{Premise|2|\neg q}} {{Assumption|3|q}} {{SequentIntro|4|2|q \implies p|2|[[False Statement implies Every Statement/Formulation 1|False Statement implies Every Statement]]}} {{ModusPonens|5|2, 3|p|4|3}} {{Assumption|6|p}} {{ProofByCases|7|1, 2|p|1|3|5|6|6}} {{EndTableau}} {{qed}}	1
=== [[Implication is Left Distributive over Conjunction/Forward Implication/Formulation 1/Proof|Proof of Forward Implication]] === {{:Implication is Left Distributive over Conjunction/Forward Implication/Formulation 1/Proof}} === [[Implication is Left Distributive over Conjunction/Reverse Implication/Formulation 1/Proof|Proof of Reverse Implication]] === {{:Implication is Left Distributive over Conjunction/Reverse Implication/Formulation 1/Proof}}	1
:$\paren {p \iff q} \iff q \dashv \vdash p$ where $\iff$ denotes the [[Definition:Biconditional|biconditional operator]].	1
{{BeginTableau|\neg q \implies \neg p \vdash p \implies q}} {{Premise|1|\neg q \implies \neg p}} {{Assumption|2|p}} {{DoubleNegIntro|3|2|\neg \neg p|2}} {{ModusTollens|4|1, 2|\neg \neg q|1|3}} {{DoubleNegElimination|5|1, 2|q|4}} {{Implication|6|1|p \implies q|2|5}} {{EndTableau|Qed}}	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] are [[Definition:True|true]] for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc|c|c|} \hline ((p & \implies & q) & \land & p) & \implies & q \\ \hline F & T & F & F & F & T & F \\ F & T & T & F & F & T & T \\ T & F & F & F & T & T & F \\ T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
=== $(1)$ iff $(2)$ === From [[Theory of Algebraically Closed Fields of Characteristic p is Complete|Theory of Algebraically Closed Fields of Characteristic $p$ is Complete]]: the theory $ACF_p$ of algebraically closed fields of characteristic $p$ is complete. That is, all such fields satisfy the exact same $\LL_r$ sentences. {{qed|lemma}} === $(2)$ implies $(4)$ === Let $\phi$ be true in some such field. Then: :$ACF_0 \models \phi$ By [[Gödel's Completeness Theorem]] and the finiteness of proofs, it follows that there is a finite subset $\Delta$ of $ACF_0$ such that $\Delta \models \phi$. Such a $\Delta$ can only make finitely many assertions about the character of its models. Hence, as long as $p$ is selected sufficiently large, an algebraically closed field of characteristic $p$ will satisfy $\phi$. {{qed|lemma}} === $(4)$ implies $(3)$ === We have that all sufficiently large $p$ work. Hence it follows that it is always possible to find arbitrarily large $p$ that work. {{qed|lemma}} === $(3)$ implies $(2)$ === We prove this by [[Proof by Contraposition|contraposition]]. Suppose there is no algebraically closed field of characteristic $0$ where $\phi$ is true. Then $\phi$ is false in algebraically closed fields of characteristic $0$ Since $ACF_0$ is complete, this means that $ACF_0 \models \neg \phi$. Similarly to the case of $(2)$ implies $(4)$, there must then be a finite subset $\Delta$ of $ACF_0$ such that $\Delta \models \neg \phi$. But then, for all sufficiently large $p$, we have that $\phi$ is false in the algebraically closed fields of characteristic $p$. Hence, it cannot be true for arbitrarily large $p$. By [[Rule of Transposition]], $\phi$ is true in algebraically closed fields for arbitrarily large primes $p$ implies there exists an algebraically closed field of characteristic $0$ where $\phi$ is true. {{qed}} {{Namedfor|Solomon Lefschetz|cat = Lefschetz}} [[Category:Algebraic Geometry]] [[Category:Field Theory]] [[Category:Model Theory]] [[Category:Mathematical Logic]] [[Category:Proofs by Contraposition]] 2ztr54llb9zkvlktqc9933kmxbwp44x	1
Let $\map \MM {m, n}$ be a [[Definition:Metric Space|metric space]] of [[Definition:Order of Matrix|order]] $m \times n$ over a [[Definition:Field (Abstract Algebra)|field]] $K$. Let $\mathbf A \in \map \MM {m, n}$ be a [[Definition:Matrix|matrix]]. Let $\Gamma$ be a [[Definition:Column Operation|column operation]] which transforms $\mathbf A$ to a new [[Definition:Matrix|matrix]] $\mathbf B \in \map \MM {m, n}$. Then there exists a [[Definition:Unique|unique]] [[Definition:Invertible Matrix|invertible]] [[Definition:Square Matrix|square matrix]] $\mathbf K$ of [[Definition:Order of Square Matrix|order $n$]] such that: :$\mathbf A \mathbf K = \mathbf B$ where $\mathbf K$ is the [[Definition:Matrix Product (Conventional)|product]] of a [[Definition:Finite Sequence|finite sequence]] of [[Definition:Elementary Column Matrix|elementary column matrices]].	1
:$p \lor q \vdash \neg p \implies q$	1
We are to show that: :$\left({x + y}\right) \times z = \left({x \times z}\right) + \left({y \times z}\right)$ for all $x, y, z \in \N$. From the definition of [[Definition:Natural Number Multiplication|natural number multiplication]], we have by definition that: {{begin-eqn}} {{eqn | ll= \forall m, n \in \N: | l = m \times 0 | r = 0 }} {{eqn | l = m \times n^+ | r = \left({m \times n}\right) + m }} {{end-eqn}} Let $x, y \in \N$ be arbitrary. For all $z \in \N$, let $P \left({z}\right)$ be the [[Definition:Proposition|proposition]]: :$\forall x, y \in \N: \left({x + y}\right) \times z = \left({x \times z}\right) + \left({y \times z}\right)$ === Basis for the Induction === $P \left({0}\right)$ is the case: {{begin-eqn}} {{eqn | l = \left({x + y}\right) \times 0 | r = 0 | c = Definition of [[Definition:Natural Number Multiplication|Natural Number Multiplication]] }} {{eqn | r = 0 + 0 | c = Definition of [[Definition:Natural Number Addition|Natural Number Addition]] }} {{eqn | r = x \times 0 + y \times 0 | c = Definition of [[Definition:Natural Number Multiplication|Natural Number Multiplication]] }} {{end-eqn}} and so $P \left({0}\right)$ holds. This is our [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $P \left({k}\right)$ is true, where $k \ge 0$, then it logically follows that $P \left({k^+}\right)$ is true. So this is our [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$\forall x, y \in \N: \left({x + y}\right) \times k = \left({x \times k}\right) + \left({y \times k}\right)$ Then we need to show: :$\forall x, y \in \N: \left({x + y}\right) \times k^+ = \left({x \times k^+}\right) + \left({y \times k^+}\right)$ === Induction Step === This is our [[Principle of Mathematical Induction#Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \left({x + y}\right) \times k^+ | r = \left({x + y}\right) \times k + \left({x + y}\right) | c = Definition of [[Definition:Natural Number Multiplication|Natural Number Multiplication]] }} {{eqn | r = \left({x \times k}\right) + \left({y \times k}\right) + \left({x + y}\right) | c = [[Natural Number Multiplication Distributes over Addition/Proof 2#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \left({\left({x \times k}\right) + x}\right) + \left({\left({y \times k}\right) + y}\right) | c = [[Natural Number Addition is Commutative/Proof 2|Natural Number Addition is Commutative]] and [[Natural Number Addition is Associative/Proof 2|Associative]] }} {{eqn | r = \left({x \times k^+}\right) + \left({y \times k^+}\right) | c = Definition of [[Definition:Natural Number Multiplication|Natural Number Multiplication]] }} {{end-eqn}} So $P \left({k}\right) \implies P \left({k^+}\right)$ and the result follows by the [[Principle of Mathematical Induction]]: :$\forall x, y, z \in \N: \left({x + y}\right) \times n = \left({x \times z}\right) + \left({y \times z}\right)$ {{qed|lemma}} Next we need to show that: :$z \times \left({x + y}\right) = \left({z \times x}\right) + \left({z \times y}\right)$ for all $x, y, z \in \N$. So: {{begin-eqn}} {{eqn | l = z \times \left({x + y}\right) | r = \left({x + y}\right) \times z | c = [[Natural Number Multiplication is Commutative]] }} {{eqn | r = \left({x \times z}\right) + \left({y \times z}\right) | c = from above }} {{eqn | r = \left({z \times x}\right) + \left({z \times y}\right) | c = [[Natural Number Multiplication is Commutative]] }} {{end-eqn}} Thus we have proved: :$\forall x, y, z \in \N: z \times \left({x + y}\right) = \left({z \times x}\right) + \left({z \times y}\right)$ {{qed}}	1
Let $\ZZ$ be the standard structure $\struct {\Z, +, \cdot, s, <, 0}$ for the [[Definition:Language of Arithmetic|language of arithmetic]]. Let $\operatorname {Th}_\ZZ$ be the [[Definition:Sentence|sentences]] which are [[Definition:Satisfiable|true]] in $\ZZ$. Let $\Theta$ be the set of [[Definition:Gödel Number|Gödel numbers]] of those sentences in $\operatorname {Th}_\ZZ$. $\Theta$ is not [[Definition:Definable#Definable Set|definable]] in $\operatorname {Th}_\ZZ$.	1
Consider the statement: :'''Socrates is a man.''' This means: :'''The [[Definition:Object|object]] named Socrates has the [[Definition:Property|property]] of being a man.''' Thus we see that '''is''' here means '''has the property of being'''. In this context, '''is''' here is called '''the ''is'' of predication'''.	1
{{BeginTableau|\vdash \paren {p \land \neg q} \iff \paren {\neg \paren {p \implies q} } }} {{Assumption|1|p \land \neg q}} {{SequentIntro|2|1|\neg \paren {p \implies q}|1|[[Conjunction with Negative Equivalent to Negation of Implication/Formulation 1/Forward Implication|Conjunction with Negative Equivalent to Negation of Implication: Formulation 1]]}} {{Implication|3||\paren {p \land \neg q} \implies \paren {\neg \paren {p \implies q} }|1|2}} {{Assumption|4|\neg \paren {p \implies q} }} {{SequentIntro|5|4|p \land \neg q|4|[[Conjunction with Negative Equivalent to Negation of Implication/Formulation 1/Reverse Implication|Conjunction with Negative Equivalent to Negation of Implication: Formulation 1]]}} {{Implication|6||\paren {\neg \paren {p \implies q} } \implies \paren {p \land \neg q}|4|5}} {{BiconditionalIntro|7||\paren {p \land \neg q} \iff \paren {\neg \paren {p \implies q} }|3|6}} {{EndTableau|qed}}	1
Consider the [[Definition:Categorical Statement|categorical statements]]: :$\map {\mathbf A} {S, P}: \quad$ The [[Definition:Universal Affirmative|universal affirmative]]: $\forall x: \map S x \implies \map P x$ :$\map {\mathbf I} {P, S}: \quad$ The [[Definition:Particular Affirmative|particular affirmative]]: $\exists x: \map P x \land \map S x$ Then: :$\map {\mathbf A} {S, P} \implies \map {\mathbf I} {P, S}$ {{iff}}: :$\exists x: \map S x$ Using the [[Definition:Symbolic Logic|symbology]] of [[Definition:Predicate Logic|predicate logic:]] :$\exists x: \map S x \iff \paren {\paren {\forall x: \map S x \implies \map P x} \implies \paren {\exists x: \map P x \land \map S x} }$ This law has the traditional name '''conversion per accidens of $\mathbf A$'''. Thus the $\mathbf A$ form '''converts per accidens''' to the $\mathbf I$ form.	1
:$\vdash \paren {\paren {p \implies q} \land p} \implies q$	1
Let $T$ be a [[Definition:Finite Propositional Tableau|finite propositional tableau]]. Let its [[Definition:Hypothesis Set|hypothesis set]] $\mathbf H$ be [[Definition:Finite Set|finite]]. {{:Tableau Extension Lemma/General Statement}}	1
From [[Sum Less Maximum is Minimum]] we have that: :$\min \left({n, m}\right) = n + m - \max \left({n, m}\right)$. As $n + m \ge \max \left({n, m}\right)$, we have that: :$\min \left({n, m}\right) = n + m \ \dot - \ \max \left({n, m}\right)$ Hence we see that $\min$ is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from: * the [[Cut-Off Subtraction is Primitive Recursive|primitive recursive function $n \ \dot - \ m$]] * the [[Maximum Function is Primitive Recursive|primitive recursive function $\max \left({n, m}\right)$]]. Hence the result. {{qed}} [[Category:Primitive Recursive Functions]] ls9kaltnxfkakt319rjmj8ioumz3th8	1
Let $\epsilon > 0$. Then by definition of [[Definition:Little-O Notation for Sequences|little-o notation]]: :$\exists n_1 \in \N: \paren {n \ge n_1 \implies \size {a_n} \le \epsilon \cdot \size {b_n}}$ :$\exists n_2 \in \N: \paren {n \ge n_2 \implies \size {c_n} \le \epsilon \cdot \size {d_n}}$ For $n \ge \max \set {n_1, n_2}$: {{begin-eqn}} {{eqn | l = \size {a_n + c_n} | o = \le | r = \size {a_n} + \size {c_n} | c = [[Triangle Inequality]] }} {{eqn | o = \le | r = \epsilon \cdot \size {b_n} + \epsilon \cdot \size {d_n} }} {{eqn | r = \epsilon \cdot \size {\size {b_n} + \size {d_n} } | c = [[Definition:Absolute Value|Absolute value]] is [[Definition:Positive Real Number|positive]] }} {{end-eqn}} Hence by definition of [[Definition:Little-O Notation for Sequences|little-o notation]]: :$a_n + c_n = \map o {\size {b_n} + \size {d_n} }$ {{qed}} [[Category:Asymptotic Notation]] kospwasornr8yzsr5oo9di0ssd1ev2u	1
Suppose that at least one person is in the pub. Then there is a person $x$ in the pub with the property that if $x$ is drinking, then everyone in the pub is drinking.	1
This proof depends on [[Axiom:Leibniz's Law|Leibniz's law]]: :$x = y \dashv \vdash \map P x \iff \map P y$ We are trying to prove $a = a$. Our assertion, then, is: :$a = a \dashv \vdash \map P a \iff \map P a$ From [[Law of Identity]], $\map P a \iff \map P a$ is a [[Definition:Tautology|tautology]]. Thus $a = a$ is also tautologous, and the theorem holds. {{qed}}	1
'''Logical inference''' is the process used in [[Definition:Natural Deduction|natural deduction]] to deduce the validity of [[Definition:Statement Form|statement forms]] from other statement forms by use of [[Definition:Proof Rule|proof rules]]. Given a set of [[Definition:Logical Formula|logical formulae]] and the [[Definition:Proof Rule|proof rules]], we '''(logically) infer''' other formulas.	1
{{AimForCont}} that $T \ne S$. From [[Set Difference is Subset]], $S \setminus T \subset S$. From [[Set Difference with Proper Subset]], $S \setminus T \ne \O$. By the definition of a [[Definition:Well-Ordered Set|well-ordered set]], [[Definition:Existential Quantifier|there exists]] a [[Definition:Smallest Element|smallest element]] $s$ of $S \setminus T$. As $s \in S$, it follows from the definition of $T$ that: :$\forall t \in S: t \prec s \implies t \in T$ But then $s \in T$ [[Definition:By Hypothesis|by hypothesis]], contradicting the definition of $s$. Hence the result, by [[Proof by Contradiction]]. {{qed}}	1
Let $n \in \Z_{>1}$. Let $S_n$ denote the $n$th [[Definition:Fibonacci String|Fibonacci string]]. Let $m \in \Z$ such that $1 < m \le n$. Let $F_m$ denote the $m$th [[Definition:Fibonacci Number|Fibonacci number]]. The [[Definition:Initial Part|initial part]] of $S_n$ of [[Definition:Length of String|length]] $F_m$ is the [[Definition:Fibonacci String|Fibonacci string]] $S_m$.	1
Let $C$ be a [[Definition:Linear Code|linear code]] whose [[Definition:Master Code|master code]] is $V$. Let $c \in C$ be a [[Definition:Transmitted Codeword|transmitted codeword]]. Let $v$ be the [[Definition:Received Word|received word]] from $c$. By definition, $v$ is an [[Definition:Element|element]] of $V$. Let $v$ have a [[Definition:Distance between Linear Codewords|distance]] $f$ from $c$, where $f \le d - 1$. Thus there have been $f$ [[Definition:Transmission Error|transmission errors]]. As $d$ is the [[Definition:Minimum Distance of Linear Code|minimum distance]] it is clear that $v$ cannot be a [[Definition:Codeword of Linear Code|codeword]] of $C$. Hence it can be understood that $C$ has detected that $v$ has as many as $d - 1$ [[Definition:Transmission Error|transmission errors]]. {{Qed}}	1
Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \N_{> 0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$0 < \map {\circ^n} x < \map {\circ^n} y$ === Basis for the Induction === $\map P 1$ is the case: :$0 < \map {\circ^1} x < \map {\circ^1} y$ which is just: :$0 < x < y$ Thus $\map P 1$ is seen to hold. This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is the [[Definition:Induction Hypothesis|induction hypothesis]]: :$0 < \map {\circ^k} x < \map {\circ^k} y$ from which it is to be shown that: :$0 < \map {\circ^{k + 1}} x < \map {\circ^{k + 1}} y$ === Induction Step === This is the [[Definition:Induction Step|induction step]]: We have: :$0 < x < y$ :$0 < \map {\circ^k} x < \map {\circ^k} y$ By [[Ring Product preserves Inequalities on Positive Elements]]: :$0 < \map {\circ^k} x \circ x < \map {\circ^k} y \circ y$ Hence: :$0 < \map {\circ^{k + 1}} x < \map {\circ^{k + 1}} y$ So $\map P k \implies \map P {k + 1}$ and thus it follows by the [[Principle of Mathematical Induction]] that: :$\forall n \in \N_{> 0}: 0 < \map {\circ^n} x < \map {\circ^n} y$ {{qed}}	1
A '''deductive argument''' is one whose [[Definition:Conclusion|conclusion]] follows unshakeable from the [[Definition:Premise|premises]].	1
Let $\sequence {a_n}, \sequence {b_n}, \sequence {c_n}, \sequence {d_n}$ be [[Definition:Sequence|sequences]] of [[Definition:Real Number|real]] or [[Definition:Complex Number|complex numbers]]. Let: :$a_n = \map \OO {b_n}$ :$c_n = \map \OO {d_n}$ where $\OO$ denotes [[Definition:Big-O Notation|big-O notation]]. Then: :$a_n c_n = \map \OO {b_n d_n}$	1
:$\paren {p \implies q} \land \paren {r \implies s}, \neg q \lor \neg s \vdash \neg p \lor \neg r$	1
Let $\left({S, \vee, \wedge}\right)$ be a [[Definition:Boolean Algebra|Boolean algebra]]. Then for all $a \in S$, there is a [[Definition:Unique|unique]] $b \in S$ such that: :$a \wedge b = \bot, a \vee b = \top$ i.e., a valid choice for $\neg a$ as in axiom $(BA \ 4)$ for [[Definition:Boolean Algebra|Boolean algebras]].	1
{{BeginTableau|p \implies q, p \implies \neg q \vdash \neg p}} {{Premise|1|p \implies q}} {{Premise|2|p \implies \neg q}} {{Assumption|3|p}} {{ModusPonens|4|1, 3|q|1|3}} {{ModusPonens|5|2, 3|\neg q|2|3}} {{NonContradiction|6|1, 2, 3|4|5}} {{Contradiction|7|1, 2|\neg p|3|6}} {{EndTableau}} {{Qed}}	1
Let $\mathcal A$ be a [[Definition:Structure for Predicate Logic|structure for predicate logic]]. Let $\sigma$ be an [[Definition:Assignment for Formula|assignment]] for $\mathbf A \iff \mathbf B$ in $\mathcal A$. Then the [[Definition:Value of Formula under Assignment|value of $\mathbf A \iff \mathbf B$ under $\sigma$]] is given by: :$f^\leftrightarrow \left({ \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\sigma}\right], \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf B}\right) } \left[{\sigma}\right] }\right)$ and from the [[Definition:Biconditional/Truth Function|definition of $f^\leftrightarrow$]] we see that $\mathcal A, \sigma \models_{\mathrm{PL_A}} \mathbf A \iff \mathbf B$ [[Definition:Iff|iff]]: :$\mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\sigma}\right] = \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf B}\right) } \left[{\sigma}\right]$ Because the possible values are just $T$ and $F$, this is equivalent to: :$\mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\sigma}\right] = T$ [[Definition:Iff|iff]] $\mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf B}\right) } \left[{\sigma}\right] = T$ which by definition of $\mathrm{PL_A}$-[[Definition:Model of Formula (Predicate Logic)|model]] amounts to: :$\mathcal A, \sigma \models_{\mathrm{PL_A}} \mathbf A$ [[Definition:Iff|iff]] $\mathcal A, \sigma \models_{\mathrm{PL_A}} \mathbf B$ Because $\mathcal A$ and $\sigma$ were arbitrary, the above equivalence holds for all such $\mathcal A$ and $\sigma$. The result follows by definition of [[Definition:Tautology (Predicate Logic)|tautology]]. {{qed}} [[Category:Predicate Logic]] c1t9ipnxtcw46n3dqnc3gnf56vucb8l	1
: $\neg p \lor \neg q \vdash \neg \left({p \land q}\right)$	1
{{BeginTableau|\left ({p \land q}\right) \implies r \vdash p \implies \left ({q \implies r}\right)}} {{Premise|1|\left ({p \land q}\right) \implies r}} {{Assumption|2|p}} {{Assumption|3|q}} {{Conjunction|4|2, 3|p \land q|2|3}} {{ModusPonens|5|1, 2, 3|r|1|4}} {{Implication|6|1, 2|q \implies r|3|5}} {{Implication|7|1|p \implies \left ({q \implies r}\right)|2|6}} {{EndTableau}} {{qed}}	1
:$\neg \paren {a \vee b} = \neg a \wedge \neg b$ :$\neg \paren {a \wedge b} = \neg a \vee \neg b$	1
Consider the [[Definition:Categorical Statement|categorical statements]]: :$\mathbf A: \quad$ The [[Definition:Universal Affirmative|universal affirmative]]: $\forall x: \map S x \implies \map P x$ :$\mathbf O: \quad$ The [[Definition:Particular Negative|particular negative]]: $\exists x: \map S x \land \neg \map P x$ Then $\mathbf A$ and $\mathbf O$ are [[Definition:Contradictory Statements|contradictory]]. Using the [[Definition:Symbolic Logic|symbology]] of [[Definition:Predicate Logic|predicate logic:]] :$\neg \paren {\paren {\forall x: \map S x \implies \map P x} \iff \paren {\exists x: \map S x \land \neg \map P x} }$	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc|c|ccccc|} \hline p & \implies & q) & \iff & (\neg & q & \implies & \neg & p) \\ \hline F & T & F & T & T & F & T & T & F \\ F & T & T & T & F & T & T & T & F \\ T & F & F & T & T & F & F & F & T \\ T & T & T & T & F & T & T & F & T \\ \hline \end{array}$ {{qed}}	1
[[Definition:Exclusive Or|Exclusive or]] is [[Definition:Associative|associative]]: : $p \oplus \left({q \oplus r}\right) \dashv \vdash \left({p \oplus q}\right) \oplus r$	1
Let $P$ and $Q$ be [[Definition:Propositional Function|propositional functions]]. Let $S$ and $T$ be [[Definition:Subset|subsets]] of a [[Definition:Universal Set|universe]] $\Bbb U$ such that: :$S = \set {x \in \Bbb U: \map P x}$ :$T = \set {x \in \Bbb U: \map Q x}$ By the following definitions: {{begin-axiom}} {{axiom | n = 1 | lc= [[Definition:Set Intersection|Intersection]]: | ml= S \cap T | mo= := | mr= \set {x \in \Bbb U: \map P x \land \map Q x} }} {{axiom | n = 2 | lc= [[Definition:Set Union|Union]]: | ml= S \cup T | mo= := | mr= \set {x \in \Bbb U: \map P x \lor \map Q x} }} {{axiom | n = 3 | lc= [[Definition:Subset|Subset]]: | ml= S \subseteq T | mo= := | mr= \forall x \in \Bbb U: \map P x \implies \map Q x }} {{axiom | n = 4 | lc= [[Definition:Symmetric Difference|Symmetric Difference]]: | ml= S * T | mo= = | mr= \set {x \in \Bbb U: \map P x \oplus \map Q x} }} {{axiom | n = 5 | lc= [[Definition:Set Complement|Complement]]: | ml= \relcomp {} S | mo= := | mr= \set {x \in \Bbb U: \lnot \map P x} }} {{axiom | n = 6 | lc= [[Definition:Set Equality|Set Equality]]: | ml= S = T | mo= := | mr= \forall x \in \Bbb U: \map P x \iff \map Q x }} {{end-axiom}} {{qed}}	1
{{BeginTableau|\bot \implies p \vdash \top}} {{Premise|1|\bot \implies p}} {{TopIntro|2}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|\top \vdash \bot \implies p}} {{Assumption|1|\bot}} {{Premise|2|\top}} {{Explosion|3|1|p|1}} {{Implication|4||\bot \implies p|1|3}} {{EndTableau}} {{qed}}	1
Let $\phi$ be a [[Definition:Logical Formula|$\mathcal L$-formula]]. Suppose that $T \left({\mathcal F}\right) \models_{\mathscr M} \phi$. By definition of $T \left({\mathcal F}\right)$: :$\mathcal F \models_{\mathscr M} \psi$ for every $\psi \in T \left({\mathcal F}\right)$. Hence by definition of [[Definition:Semantic Consequence|semantic consequence]]: :$\mathcal F \models_{\mathscr M} T \left({\mathcal F}\right)$ By [[Semantic Consequence is Transitive]], it follows that: :$\mathcal F \models_{\mathscr M} \phi$ Finally, by definition of $T \left({\mathcal F}\right)$: :$\phi \in T \left({\mathcal F}\right)$. Since $\phi$ was arbitrary, the result follows. {{qed}}	1
==== [[Rule of Distribution/Disjunction Distributes over Conjunction/Left Distributive/Formulation 1|Formulation 1]] ==== {{:Rule of Distribution/Disjunction Distributes over Conjunction/Left Distributive/Formulation 1}} ==== [[Rule of Distribution/Disjunction Distributes over Conjunction/Left Distributive/Formulation 2|Formulation 2]] ==== {{:Rule of Distribution/Disjunction Distributes over Conjunction/Left Distributive/Formulation 2}}	1
==== [[Biconditional iff Disjunction implies Conjunction/Formulation 1|Formulation 1]] ==== {{:Biconditional iff Disjunction implies Conjunction/Formulation 1}} ==== [[Biconditional iff Disjunction implies Conjunction/Formulation 2|Formulation 2]] ==== {{:Biconditional iff Disjunction implies Conjunction/Formulation 2}}	1
:$\neg \left({p \implies q}\right) \vdash p \land \neg q$	1
Denote with $\mathscr H_2 - (A1)$ the [[Definition:Proof System|proof system]] resulting from $\mathscr H_2$ by removing [[Definition:Axiom (Formal Systems)|axiom]] $(A1)$. Consider $\mathscr C_2$, [[Definition:Constructed Semantics/Instance 2|Instance 2]] of [[Definition:Constructed Semantics|constructed semantics]]. We will prove that: * $\mathscr H_2 - (A1)$ is [[Definition:Sound Proof System|sound]] for $\mathscr C_2$; * [[Definition:Axiom (Formal Systems)|Axiom]] $(A1)$ is not a [[Definition:Tautology (Formal Semantics)|tautology]] in $\mathscr C_2$ which leads to the conclusion that $(A1)$ is not a [[Definition:Theorem (Formal Systems)|theorem]] of $\mathscr H_2 - (A1)$. === Soundness of $\mathscr H_2 - (A1)$ for $\mathscr C_2$ === Starting with the [[Definition:Axiom (Formal Systems)|axioms]]: {{begin-axiom}} {{axiom|n = A2 |lc = [[Rule of Addition/Sequent Form/Formulation 2/Form 2|Rule of Addition]] |m = q \implies (p \lor q) |rc = [[Definition:Constructed Semantics/Instance 2/Rule of Addition|Proof of Tautology]] }} {{axiom|n = A3 |lc = [[Rule of Commutation/Disjunction/Formulation 2/Forward Implication|Rule of Commutation]] |m = (p \lor q) \implies (q \lor p) |rc = [[Definition:Constructed Semantics/Instance 2/Rule of Commutation|Proof of Tautology]] }} {{axiom|n = A4 |lc = [[Factor Principles/Disjunction on Left/Formulation 2|Factor Principle]] |m = (q \implies r) \implies \left({ (p \lor q) \implies (p \lor r)}\right) |rc = [[Definition:Constructed Semantics/Instance 2/Factor Principle|Proof of Tautology]] }} {{end-axiom}} Next it needs to be shown that the [[Definition:Hilbert Proof System/Instance 2|rules of inference of $\mathscr H_2$]] preserve $\mathscr C_2$-[[Definition:Tautology (Formal Semantics)|tautologies]]. ==== Rule $RST \, 1$: Rule of Uniform Substitution ==== By definition, any [[Definition:WFF of Propositional Logic|WFF]] is assigned a value $0$, $1$ or $2$. Thus, in applying [[Definition:Hilbert Proof System/Instance 2|Rule $RST \, 1$]], we are introducing $0$, $1$ or $2$ in the position of a [[Definition:Propositional Variable|propositional variable]]. But all possibilities of assignments of $0$s, $1$s and $2$s to such [[Definition:Propositional Variable|propositional variables]] were shown not to affect the resulting value $0$ of the axioms. Hence [[Definition:Hilbert Proof System/Instance 2|Rule $RST \, 1$]] preserves $\mathscr C_2$-[[Definition:Tautology (Formal Semantics)|tautologies]]. ==== Rule $RST \, 2$: Rule of Substitution by Definition ==== Because the definition of $\mathscr C_2$ was given in terms of [[Definition:Hilbert Proof System/Instance 2|Rule $RST \, 2$]], it cannot affect any of its results. ==== Rule $RST \, 3$: Rule of Detachment ==== Suppose $\mathbf A$ and $\mathbf A \implies \mathbf B$ both take value $0$. Then using [[Definition:Hilbert Proof System/Instance 2|Rule $RST \, 2$]], definition $(2)$, we get: :$\neg \mathbf A \lor \mathbf B$ taking value $0$ by assumption. But $\neg \mathbf A$ takes value $1$ by definition of $\neg$. So from the definition of $\lor$ it must be that $\mathbf B$ takes value $0$. Hence [[Definition:Hilbert Proof System/Instance 2|Rule $RST \, 3$]] also produces only [[Definition:WFF of Propositional Logic|WFFs]] of value $0$. ==== Rule $RST \, 4$: Rule of Adjunction ==== Suppose $\mathbf A$ and $\mathbf B$ take value $0$. Then: {{begin-eqn}} {{eqn|l = \mathbf A \land \mathbf B |r = 0 \land 0 }} {{eqn|r = \neg ( \neg 0 \lor \neg 0 ) |c = [[Definition:Hilbert Proof System/Instance 2|Rule $RST \, 2 \, (1)$]] }} {{eqn|r = \neg ( 1 \lor 1 ) }} {{eqn|r = \neg 1 }} {{eqn|r = 0 }} {{end-eqn}} proving that [[Definition:Hilbert Proof System/Instance 2|Rule $RST \, 4$]] also produces only $0$s from $0$s. Hence $\mathscr H_2 - (A1)$ is [[Definition:Sound Proof System|sound]] for $\mathscr C_2$. === $(A1)$ is not a $\mathscr C_2$-tautology === Recall [[Definition:Axiom (Formal Systems)|axiom]] $(A1)$, the [[Rule of Idempotence/Disjunction/Formulation 2/Reverse Implication|Rule of Idempotence]]: :$(p \lor p) \implies p$ Under $\mathscr C_2$, we apply a single definitional abbreviation and have the following: :$\begin{array}{|cccc|c|c|} \hline \neg & (p & \lor & p) & \lor & p \\ \hline 1 & 0 & 0 & 0 & 0 & 0 \\ 0 & 1 & 1 & 1 & 0 & 1 \\ 1 & 2 & 0 & 2 & 2 & 2 \\ \hline \end{array}$ Hence according to the definition of $\mathscr C_2$, $(A1)$ is not a [[Definition:Tautology (Formal Semantics)|tautology]]. Therefore $(A1)$ is independent from $(A2)$, $(A3)$, $(A4)$. {{qed}}	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc||ccccc|} \hline (p & \land & q) & \implies & r & p & \implies & (q & \implies & r) \\ \hline F & F & F & T & F & F & T & F & T & F \\ F & F & F & T & T & F & T & F & T & T \\ F & F & T & T & F & F & T & T & F & F \\ F & F & T & T & T & F & T & T & T & T \\ T & F & F & T & F & T & T & F & T & F \\ T & F & F & T & T & T & T & F & T & T \\ T & T & T & F & F & T & F & T & F & F \\ T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
:$p \implies q := \neg p \lor q$	1
[[Definition:Axiom (Formal Systems)|Axiom]] $(\text A 4)$ is [[Definition:Independent Axiom|independent]] from $(\text A 1)$, $(\text A 2)$, $(\text A 3)$.	1
Let $K_n$ denote the [[Definition:Complete Graph|complete graph]] of [[Definition:Order of Graph|order]] $n$ where $n \ge 0$. The [[Definition:Size of Graph|size]] of $K_n$ is given by: :$\size {K_n} = \dfrac {n \paren {n - 1} } 2$	1
We have that $\mathcal R \left({n_1, n_2, \ldots, n_k, y}\right)$ holds {{iff}} $\chi_\mathcal R \left({n_1, n_2, \ldots, n_k, y}\right) = 1$, from the definition of the [[Definition:Characteristic Function of Relation|characteristic function of a relation]]. This in turn holds {{iff}} $\overline{\operatorname{sgn}} \left({\chi_\mathcal R \left({n_1, n_2, \ldots, n_k, y}\right)}\right) = 0$, where $\overline{\operatorname{sgn}}$ is the [[Definition:Signum Complement|signum-bar function]]. Hence we have: :$\mu y \ \mathcal R \left({n_1, n_2, \ldots, n_k, y}\right) \iff \mu y \left({\overline{\operatorname{sgn}} \left({\chi_\mathcal R \left({n_1, n_2, \ldots, n_k, y}\right)}\right) = 0}\right)$. Since $\overline{\operatorname{sgn}}$ and $\chi_\mathcal R$ are [[Definition:Total Function|total functions]], then so is $\overline{\operatorname{sgn}} \circ \chi_\mathcal R$. {{qed}} [[Category:Primitive Recursive Functions]] [[Category:Recursive Functions]] 89fayxzoz09fprbh3cc7y6arzi48t04	1
:$\vdash \left({\neg p \implies p}\right) \implies p$	1
Let $\mathcal F$ be a [[Definition:Finite Set|finite set]] of [[Definition:WFF of Propositional Logic|WFFs of propositional logic]]. Let $\mathbf A$ be another [[Definition:WFF of Propositional Logic|WFF]]. Then the following are [[Definition:Logical Equivalence|equivalent]]: {{begin-eqn}} {{eqn|l = \mathcal F |o = \models_{\mathrm{BI} } |r = \mathbf A }} {{eqn|o = \models_{\mathrm{BI} } |r = \bigwedge \mathcal F \implies \mathbf A }} {{end-eqn}} that is, $\mathbf A$ is a [[Definition:Semantic Consequence (Boolean Interpretations)|semantic consequence]] of $\mathcal F$ [[Definition:Iff|iff]] $\displaystyle \bigwedge \mathcal F \implies \mathbf A$ is a [[Definition:Tautology (Boolean Interpretations)|tautology]]. Here, $\displaystyle \bigwedge \mathcal F$ is the [[Definition:Conjunction of Set|conjunction of $\mathcal F$]].	1
By definition of [[Definition:Tableau Confutation|tableau confutation]], every [[Definition:Branch (Graph Theory)|branch]] of $T$ is [[Definition:Contradictory Branch|contradictory]]. The result follows by definition of [[Definition:Finished Propositional Tableau|finished propositional tableau]]. {{qed}}	1
{{BeginTableau|p \implies q, r \implies s \vdash \neg q \lor \neg s \implies \neg p \lor \neg r}} {{Premise|1|p \implies q}} {{Premise|2|r \implies s}} {{SequentIntro|3|1, 2|\paren {p \land r} \implies \paren {q \land s}|1, 2|[[Praeclarum Theorema]]}} {{Assumption|4|\neg q \lor \neg s}} {{DeMorgan|5|4|\neg \paren {q \land s}|4|Disjunction of Negations}} {{ModusTollens|6|1, 2, 4|\neg \paren {p \land r}|3|5}} {{DeMorgan|7|1, 2|\neg p \lor \neg r|6|Disjunction of Negations}} {{Implication|8|1, 2|\neg q \lor \neg s \implies \neg p \lor \neg r|4|7}} {{EndTableau}} {{qed}}	1
[[Definition:By Hypothesis|By hypothesis]], the [[Definition:Characteristic Function of Relation|characteristic functions]] $\chi_{\RR_1}, \chi_{\RR_2}$ of $\RR_1$ and $\RR_2$ are [[Definition:Primitive Recursive Function|primitive recursive]]. Then we have that the [[Definition:Characteristic Function of Relation|characteristic functions]] of $\TT, \UU, \VV$ are given by: :$\chi_\TT = \map {\overline \sgn} {\chi_{\RR_1} }$ :$\chi_\UU = \chi_{\RR_1} \times \chi_{\RR_2}$ :$\chi_\VV = \map {\overline \sgn} {\chi_{\RR_1} + \chi_{\RR_2} }$ Compare [[Complement of Primitive Recursive Set]], [[Intersection of Primitive Recursive Sets]] and [[Union of Primitive Recursive Sets]]. Hence the result. {{qed}} [[Category:Primitive Recursive Functions]] rcvbteaj8kbg1m207heg755ubhc6ssg	1
An '''argumentum ad passiones''' is a [[Definition:Logical Argument|logical argument]] that, rather than [[Definition:Proof|prove]] or present evidence for a claim, attempts to generate support for an idea by instilling either: : an emotional attachment to the argument being presented : a feeling of embarrassment at holding a [[Definition:Philosophical Position|position]] which is subject to ridicule or : a feeling of distaste for the argument being refuted. Such arguments are commonly seen along with [[Definition:Argumentum ad Hominem|argumentum ad hominem]].	1
We will prove inductively the following claim for every [[Definition:Node (Graph Theory)|node]] $t$ of $T$: :If all [[Definition:Leaf Node|leaves]] that are [[Definition:Descendant Node|descendants]] of $t$ are [[Definition:Marked Closed Leaf|marked closed]], then $U \left({t}\right)$ is [[Definition:Unsatisfiable (Boolean Interpretations)|unsatisfiable]]. By the [[Semantic Tableau Algorithm]], we know this statement to hold for the [[Definition:Leaf Node|leaf nodes]] themselves. For, a [[Definition:Leaf Node|leaf]] $t$ is [[Definition:Marked Closed Leaf|marked closed]] [[Definition:Iff|iff]] $U \left({t}\right)$ contains a [[Definition:Complementary Pair|complementary pair]]. The assertion follows from [[Set of Literals Satisfiable iff No Complementary Pairs]]. Inductively, suppose that all [[Definition:Child Node|children]] of a [[Definition:Node (Graph Theory)|node]] $t$ satisfy the mentioned condition. If all [[Definition:Descendant Node|descendant]] [[Definition:Leaf Node|leaf nodes]] of $t$ are [[Definition:Marked Closed Leaf|marked closed]], this evidently holds for the [[Definition:Child Node|children]] $t',t''$ of $t$ as well. Hence by hypothesis, $U \left({t'}\right)$ and $U \left({t''}\right)$ are [[Definition:Unsatisfiable (Boolean Interpretations)|unsatisfiable]]. Let $\mathbf B$ be the [[Definition:WFF of Propositional Logic|WFF]] used by the [[Semantic Tableau Algorithm]] at $t$. Let $\mathbf B_1, \mathbf B_2$ be the formulas added to $t'$ and $t''$. First, the case that $\mathbf B$ is an [[Definition:Alpha-Formula|$\alpha$-formula]]. Then $t' = t''$, and $\mathbf B$ is [[Definition:Semantic Equivalence (Boolean Interpretations)|semantically equivalent]] to $\mathbf B_1 \land \mathbf B_2$. It follows that if: :$v \models_{\mathrm{BI}} U \left({t}\right)$ for some [[Definition:Boolean Interpretation|boolean interpretation]] $v$, then also: :$v \models_{\mathrm{BI}} U \left({t'}\right)$ which contradicts our hypothesis. Thus, $U \left({t}\right)$ is [[Definition:Unsatisfiable (Boolean Interpretations)|unsatisfiable]]. Next, the case that $\mathbf B$ is a [[Definition:Beta-Formula|$\beta$-formula]]. Then $\mathbf B$ is [[Definition:Semantic Equivalence (Boolean Interpretations)|semantically equivalent]] to $\mathbf B_1 \lor \mathbf B_2$. It follows that if: :$v \models_{\mathrm{BI}} U \left({t}\right)$ for some [[Definition:Boolean Interpretation|boolean interpretation]] $v$, then also one of the following must hold: :$v \models_{\mathrm{BI}} U \left({t'}\right)$ :$v \models_{\mathrm{BI}} U \left({t''}\right)$ which contradicts our hypothesis. Thus, $U \left({t}\right)$ is [[Definition:Unsatisfiable (Boolean Interpretations)|unsatisfiable]]. {{handwaving|"It follows", is obvious, and is tedious to write down}} This proves our claim: :If all [[Definition:Leaf Node|leaves]] that are [[Definition:Descendant Node|descendants]] of $t$ are [[Definition:Marked Closed Leaf|marked closed]], then $U \left({t}\right)$ is [[Definition:Unsatisfiable (Boolean Interpretations)|unsatisfiable]]. Applying this claim to the [[Definition:Root Node|root node]] of $T$, we obtain the desired result. {{qed}}	1
The '''semantics''' of a language (either [[Definition:Natural Language|natural]] or [[Definition:Formal Language|formal]]) is its '''meaning''' in a linguistic sense.	1
:$p \iff \bot \dashv \vdash \neg p$	1
:$p \land q \dashv \vdash \neg \left({p \implies \neg q}\right)$	1
Let $k \in \N^*$. Let $e = \gamma \left({P}\right)$ be the [[Unique Code for URM Program|code number]] of a [[Definition:URM Program|URM program]] $P$. Let $\left({n_1, n_2, \ldots, n_k}\right)$ be the [[Definition:Unlimited Register Machine#Input|input]] of $P$. Let $S_k: \N^{k+2} \to \N$ be the [[Definition:Function|function]] defined as: :$S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)$ is the [[Unique Code for State of URM Program|state code]] for $P$ at [[Definition:Unlimited Register Machine#Stage of Computation|stage $t$ of computation]] of $P$. If $e$ [[Unique Code for URM Program#Does Not Code|does not code a URM Program]] then $S_k = 0$. Also, if $P$ [[Definition:Unlimited Register Machine#Termination|terminates]] at stage $t_0$, then we put: :$\forall t > t_0: S_k \left({e, n_1, n_2, \ldots, n_k, t}\right) = S_k \left({e, n_1, n_2, \ldots, n_k, t_0}\right)$. Then for all $k \ge 1$, the function $S_k$ is [[Definition:Primitive Recursive Function|primitive recursive]].	1
It is useful to first state the [[Definition:Cayley Table|Cayley tables]] for the three logical operations $\lor$, $\land$ and $\neg$: :$\begin{array}{c|cc} \lor & \bot & \top \\ \hline \bot & \bot & \top \\ \top & \top & \top \end{array} \qquad \begin{array}{c|cc} \land & \bot & \top \\ \hline \bot & \bot & \bot \\ \top & \bot & \top \end{array} \qquad \begin{array}{c|cc} & \bot & \top \\ \hline \neg & \top & \bot \end{array}$ Let us now verify the axioms for a [[Definition:Boolean Algebra|Boolean algebra]] in turn. === $(BA \ 0)$: Closure === It is immediate from the [[Definition:Cayley Table|Cayley tables]] that $S$ is [[Definition:Closed Algebraic System|closed]] under $\lor$, $\land$ and $\neg$. {{qed|lemma}} === $(BA \ 1)$: Commutativity === Follows from the [[Rule of Commutation]]. {{qed|lemma}} === $(BA \ 2)$: Distributivity === Follows from the [[Rule of Distribution]] {{qed|lemma}} === $(BA \ 3)$: Identities === Follows from [[Conjunction with Tautology]] and [[Disjunction with Contradiction]]. {{qed|lemma}} === $(BA \ 4)$: Complements === Follows from [[Contradiction is Negation of Tautology]] and [[Tautology is Negation of Contradiction]]. {{qed|lemma}} Having verified all axioms, we conclude $\mathbf 2$ is a [[Definition:Boolean Algebra|Boolean algebra]]. {{qed}}	1
Every [[Definition:Non-Empty Set|non-empty]] [[Definition:Subset|subset]] of $\N$ has a [[Definition:Smallest Element|smallest (or '''first''') element]]. This is called the '''well-ordering principle'''. The '''well-ordering principle''' also holds for $\N_{\ne 0}$.	1
Let $\mathcal L$ be a [[Definition:Countable|countable]] [[Definition:First-Order (Logic)|first-order]] [[Definition:Logical Language|language]]. Let $T$ be an $\mathcal L$-[[Definition:Theory (Logic)|theory]] which [[Definition:Axiomatize (Logic)|axiomatizes]] some version of [[Definition:Axiomatic Set Theory|set theory]] (for example, [[Definition:ZFC|ZFC]]). There is a countable model of $T$.	1
There are $256$ [[Definition:Distinct Elements|distinct]] [[Definition:Standard Instance of Categorical Syllogism|standard instances]] of the [[Definition:Categorical Syllogism|categorical syllogism]].	1
Let $P$ be a [[Definition:WFF of Propositional Logic|WFF of propositional logic]]. Suppose $\mathcal P$ is of [[Definition:Finite Set|finite size]] such that it contains $n$ different [[Definition:Letter|letters]]. Then a [[Definition:Truth Table|truth table]] constructed to express $P$ will contain $2^n$ [[Definition:Row of Truth Table|rows]].	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] are [[Definition:True|true]] for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccccc|c|ccccc|} \hline ((p & \implies & r) & \land & (q & \implies & r)) & \implies & ((p & \lor & q) & \implies & r) \\ \hline F & T & F & T & F & T & F & T & F & F & F & T & F \\ F & T & T & T & F & T & T & T & F & F & F & T & T \\ F & T & F & F & T & F & F & T & F & T & T & F & F \\ F & T & T & T & T & T & T & T & F & T & T & T & T \\ T & F & F & F & F & T & F & T & T & T & F & F & F \\ T & T & T & T & F & T & T & T & T & T & F & T & T \\ T & F & F & F & T & F & F & T & T & T & T & F & F \\ T & T & T & T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
The [[Definition:Disk|unit ball]] $\mathbb D^3 \subset \R^3$ is [[Definition:Equidecomposable|equidecomposable]] to the union of two unit balls.	1
Consider [[Definition:Fourth Figure of Categorical Syllogism|Figure $\text {IV}$]]: {{:Definition:Figure of Categorical Syllogism/IV}} Let the [[Definition:Major Premise of Syllogism|major premise]] of $Q$ be denoted $\text{Maj}$. Let the [[Definition:Minor Premise of Syllogism|minor premise]] of $Q$ be denoted $\text{Min}$. Let the [[Definition:Conclusion of Syllogism|conclusion]] of $Q$ be denoted $\text{C}$. $M$ is: : the [[Definition:Predicate of Categorical Statement|predicate]] of $\text{Maj}$ : the [[Definition:Subject of Categorical Statement|subject]] of $\text{Min}$. We have: :[[Middle Term of Valid Categorical Syllogism is Distributed at least Once]]. So, in order for $M$ to be [[Definition:Distributed Term of Categorical Syllogism|distributed]], either: : From [[Definition:Distributed Term of Categorical Syllogism/Predicate|Negative Categorical Statement Distributes its Predicate]]: $\text{Maj}$ must be [[Definition:Negative Categorical Statement|negative]] or: : From [[Definition:Distributed Term of Categorical Syllogism/Subject|Universal Categorical Statement Distributes its Subject]]: $\text{Min}$ must be [[Definition:Universal Categorical Statement|universal]]. Both may be the case. Thus $(1)$ is seen to hold. {{qed|lemma}} Let $\text{C}$ be a [[Definition:Negative Categorical Statement|negative categorical statement]]. From [[Definition:Distributed Term of Categorical Syllogism/Predicate|Negative Categorical Statement Distributes its Predicate]]: : $P$ is [[Definition:Distributed Term of Categorical Syllogism|distributed]] in $\text{C}$. From [[Distributed Term of Conclusion of Valid Categorical Syllogism is Distributed in Premise]]: : $P$ is [[Definition:Distributed Term of Categorical Syllogism|distributed]] in $\text{Maj}$. So from [[Definition:Distributed Term of Categorical Syllogism/Subject|Universal Categorical Statement Distributes its Subject]]: : $\text{Maj}$ is a [[Definition:Universal Categorical Statement|universal categorical statement]]. Thus $(2)$ is seen to hold. {{qed|lemma}} Let $\text{C}$ be a [[Definition:Universal Categorical Statement|universal categorical statement]]. From [[Definition:Distributed Term of Categorical Syllogism/Subject|Universal Categorical Statement Distributes its Subject]]: : $S$ is [[Definition:Distributed Term of Categorical Syllogism|distributed]] in $\text{C}$. From [[Distributed Term of Conclusion of Valid Categorical Syllogism is Distributed in Premise]]: : $S$ is [[Definition:Distributed Term of Categorical Syllogism|distributed]] in $\text{Min}$. From [[Definition:Distributed Term of Categorical Syllogism/Predicate|Negative Categorical Statement Distributes its Predicate]]: : $S$ is a [[Definition:Negative Categorical Statement|negative categorical statement]]. Thus $(3)$ is seen to hold. {{qed}}	1
{{BeginTableau|p \iff q \vdash q \iff p}} {{Premise|1|p \iff q}} {{BiconditionalElimination|2|1|p \implies q|1|1}} {{BiconditionalElimination|3|1|q \implies p|1|2}} {{BiconditionalIntro|4|1|q \iff p|3|2}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|q \iff p \vdash p \iff q}} {{Premise|1|q \iff p}} {{BiconditionalElimination|2|1|q \implies p|1|1}} {{BiconditionalElimination|3|1|p \implies q|1|2}} {{BiconditionalIntro|4|1|p \iff q|3|2}} {{EndTableau}} {{qed}}	1
: $\vdash \left({\left({p \implies q}\right) \land \left({r \implies s}\right)}\right) \implies \left({\left({p \land r}\right) \implies \left({q \land s}\right)}\right)$	1
{{BeginTableau|\neg \paren {p \iff q} \vdash \paren {p \lor q} \land \paren {\neg p \lor \neg q} }} {{Premise |1|\neg \paren {p \iff q} }} {{SequentIntro|2|1|\paren {p \lor q} \land \neg \paren {p \land q}|1|[[Non-Equivalence as Conjunction of Disjunction with Negation of Conjunction]]}} {{DeMorgan |3|1|\paren {p \lor q} \land \paren {\neg p \lor \neg q}|2|Disjunction of Negations}} {{EndTableau}} {{BeginTableau|\paren {p \lor q} \land \paren {\neg p \lor \neg q} \vdash \neg \paren {p \iff q} }} {{Premise |1|\paren {p \lor q} \land \paren {\neg p \lor \neg q} }} {{DeMorgan |2|1|\paren {p \lor q} \land \neg \paren {p \land q}|1|Disjunction of Negations}} {{SequentIntro|3|1|\neg \paren {p \iff q}|2|[[Non-Equivalence as Conjunction of Disjunction with Negation of Conjunction]]}} {{EndTableau|qed}}	1
The [[Rule of Idempotence/Disjunction/Formulation 2/Reverse Implication|Rule of Idempotence]]: :$(p \lor p) \implies p$ is a [[Definition:Tautology (Formal Semantics)|tautology]] in [[Definition:Constructed Semantics/Instance 4|Instance 4]] of [[Definition:Constructed Semantics|constructed semantics]].	1
:$p \implies \paren {q \lor r} \vdash \paren {p \implies q} \lor \paren {p \implies r}$	1
The proof proceeds by [[Second Principle of Mathematical Induction|complete induction]]. For all $n \in \Z_{\ge 1}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$L_n < \paren {\dfrac 7 4}^n$ $\map P 1$ is the case: {{begin-eqn}} {{eqn | l = L_1 | r = 1 | c = }} {{eqn | o = < | r = \dfrac 7 4 | c = }} {{end-eqn}} Thus $\map P 1$ is seen to hold. === Basis for the Induction === $\map P 2$ is the case: {{begin-eqn}} {{eqn | l = L_2 | r = 3 | c = }} {{eqn | r = \dfrac {48} {16} | c = }} {{eqn | o = < | r = \dfrac {49} {16} | c = }} {{eqn | r = \paren {\dfrac 7 4}^2 | c = }} {{end-eqn}} Thus $\map P 2$ is seen to hold. This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that if $\map P j$ is true, for all $j$ such that $0 \le j \le k$, then it logically follows that $\map P {k + 1}$ is true. This is the [[Definition:Induction Hypothesis|induction hypothesis]]: :$L_k < \paren {\dfrac 7 4}^k$ from which it is to be shown that: :$L_{k + 1} < \paren {\dfrac 7 4}^{k + 1}$ === Induction Step === This is the [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = L_{k + 1} | r = L_k + L_{k - 1} | c = }} {{eqn | o = < | r = \paren {\dfrac 7 4}^k + \paren {\dfrac 7 4}^{k - 1} | c = [[Upper Bound for Lucas Number#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \paren {\dfrac 7 4}^{k - 1} \paren {1 + \dfrac 7 4} | c = }} {{eqn | r = \paren {\dfrac 7 4}^{k - 1} \paren {\dfrac {11} 4} | c = }} {{eqn | o = < | r = \paren {\dfrac 7 4}^{k - 1} \paren {\dfrac 7 4}^2 | c = }} {{eqn | r = \paren {\dfrac 7 4}^{k + 1} | c = }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Second Principle of Mathematical Induction]]. Therefore: :$\forall n \in \Z_{\ge 1}: L_n < \paren {\dfrac 7 4}^n$ {{qed}}	1
{{BeginTableau|\vdash p \lor \neg p|[[Definition:Hilbert Proof System/Instance 2|Instance 2 of the Hilbert-style systems]]}} {{TheoremIntro|1|\left({q \implies r}\right) \implies \left({\left({p \implies q}\right) \implies \left({p \implies r}\right)}\right)|[[Hypothetical Syllogism/Formulation 5/Proof 2|Hypothetical Syllogism]]}} {{TableauLine |n = 2 |f = \left({\left({p \lor p}\right) \implies p}\right) \implies \left({\left({p \implies \left({p \lor p}\right)}\right) \implies \left({p \implies p}\right)}\right) |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 1$ |dep = 1 |c = $p \lor p \, / \, q$, $p \, / \, r$ }} {{TableauLine |n = 3 |f = (p \lor p) \implies p |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Axiom $A1$ }} {{TableauLine |n = 4 |f = \left({p \implies \left({p \lor p}\right)}\right) \implies \left({p \implies p}\right) |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 3$ |dep = 2, 3 }} {{TableauLine |n = 5 |f = p \implies (p \lor p) |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Axiom $A2$, Rule $RST \, 1$ |c = $p \, / \, q$ }} {{TableauLine |n = 6 |f = p \implies p |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 3$ |dep = 4, 5 }} {{TableauLine |n = 7 |f = \neg p \lor p |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 2 \, (2)$ |dep = 6 }} {{TableauLine |n = 8 |f = (p \lor q) \implies (q \lor p) |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Axiom $A3$ }} {{TableauLine |n = 9 |f = (\neg p \lor p) \implies (p \lor \neg p) |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 1$ |dep = 8 |c = $p \, / \, q$, $\neg p \, / \, p$ }} {{TableauLine |n = 10 |f = p \lor \neg p |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 3$ |dep = 7, 9 }} {{EndTableau}} {{Qed}}	1
A '''contradiction''' is a [[Definition:Statement|statement]] which is ''always [[Definition:False|false]]'', independently of any relevant circumstances that could theoretically influence its [[Definition:Truth Value|truth value]]. This has the form: :$p \land \neg p$ or, equivalently: :$\neg p \land p$ that is: :'''$p$ is [[Definition:True|true]] [[Definition:Conjunction|and, at the same time]], $p$ is [[Definition:False|not true]].'''	1
: $p \implies q \vdash \left({p \land r}\right) \implies \left ({q \land r}\right)$	1
A [[Definition:Propositional Variable|propositional variable]] is already trivially in [[Definition:Negation Normal Form|negation normal form (NNF)]]. So we consider the general [[Definition:Propositional Formula|propositional formula]] $S$. In the following, $P$ and $Q$ are to stand for general [[Definition:Propositional Formula|propositional formulas]]. First, from [[Functionally Complete Logical Connectives/Conjunction, Negation and Disjunction|Functionally Complete Logical Connectives: Conjunction, Negation and Disjunction]] we have that: :$\left\{{\neg, \land, \lor}\right\}$ forms a [[Definition:Functionally Complete|functionally complete]] set of [[Definition:Logical Connective|logical connectives]]. So we can convert $S$ so that: * By the definition of the [[Definition:Biconditional|biconditional]], instances of $P \iff Q$ can be converted into $\left({P \implies Q}\right) \land \left({Q \implies P}\right)$; * By the [[Rule of Material Implication]], instances of $P \implies Q$ can be converted into $\neg P \lor Q$. Other connectives can likewise be treated appropriately. Thus $S$ will contain nothing but connectives from $\left\{{\neg, \land, \lor}\right\}$. Next we can replace: * Instances of $\neg \left({P \land Q}\right)$ with $\neg P \lor \neg Q$, by [[De Morgan's Laws (Logic)/Disjunction of Negations|De Morgan's Laws: Disjunction of Negations]]; * Instances of $\neg \left({P \lor Q}\right)$ with $\neg P \land \neg Q$, by [[De Morgan's Laws (Logic)/Conjunction of Negations|De Morgan's Laws: Conjunction of Negations]]; * Instances of $\neg \neg P$ with $P$ by [[Double Negation Elimination]]. At any stage where a negation appears before a [[Definition:Parenthesis|parenthesis]], it will then appear before the statements inside the [[Definition:Parenthesis|parenthesis]]. Thus the negation signs gradually move inwards or are eliminated. Eventually all remaining negation signs will appear next to simple statements. Hence the result. {{qed}} [[Category:Propositional Logic]] gzz56iayclxe1zjof26y760kwdu7lbx	1
This is an extension of [[Proof by Cases]]. The [[Definition:Propositional Expansion|propositional expansion]] of $\exists x: P \left({x}\right)$ is: :$P \left({\mathbf X_1}\right) \lor P \left({\mathbf X_2}\right) \lor P \left({\mathbf X_3}\right) \lor \ldots$ We know that any arbitrarily selected $\mathbf a$ with the property $P$ implies $y$. From this we can infer that ''all'' such $\mathbf a$ which have that property imply $y$. This is equivalent to the step in [[Proof by Cases]] in which we need to prove that both disjuncts lead to the same conclusion. The fact that we only need one of them in fact to ''be'' true is quite enough to draw the conclusion that $y$ is true. In this context, we are assured by the statement $\exists x: P \left({x}\right)$ that at least one such disjunct in the above propositional expansion is true. Thus the conclusion follows, and the result is proved. {{qed}}	1
{{BeginTableau|\neg p \lor q \vdash p \implies q}} {{Premise|1|\neg p \lor q}} {{Assumption|2|\neg p|Pick the first of the disjuncts ...}} {{Assumption|3|p|Assume its negation ...}} {{NonContradiction|4|2, 3|3|2| ... and demonstrate a contradiction}} {{Explosion|5|2, 3|q|4| ... from a falsehood, ''any'' statement can be derived - pick $q$}} {{Implication|6|2|p \implies q|3|5}} {{Assumption|7|q|Pick the second of the disjuncts ...}} {{Assumption|8|p|... again assume $p$ ...}} {{IdentityLaw|9|7|q|7|The truth of $q$ still holds}} {{Implication|10|7|p \implies q|8|9}} {{ProofByCases|11|1|p \implies q|1|2|6|7|10}} {{EndTableau}} {{qed}}	1
: $\neg \neg p \vdash p$	1
From the [[Definition:Stronger Statement|stronger]] results: :[[Functionally Complete Logical Connectives/Negation and Disjunction|Functionally Complete Logical Connectives: Negation and Disjunction]]: ::the [[Definition:Set|set]] of [[Definition:Logical Connective|logical connectives]]: $\set {\neg, \lor}$ is [[Definition:Functionally Complete|functionally complete]] :[[Functionally Complete Logical Connectives/Negation and Conjunction|Functionally Complete Logical Connectives: Negation and Conjunction]]: ::the [[Definition:Set|set]] of [[Definition:Logical Connective|logical connectives]]: $\set {\neg, \land}$ is [[Definition:Functionally Complete|functionally complete]] it follows directly that $\set {\neg, \land, \lor}$ is likewise [[Definition:Functionally Complete|functionally complete]]. {{qed}} [[Category:Functional Completeness]] eh8et9jrx7lv8b1gvg1ipjzycdrvr03	1
:$\vdash \neg \paren {p \land \neg p}$	1
{{BeginTableau|\neg \left ({p \iff q}\right) \vdash \neg \left({p \implies q}\right) \lor \neg \left({q \implies p}\right)}} {{Premise|1|\neg \left ({p \iff q}\right)}} {{SequentIntro|2|1|\neg \left({\left ({p \implies q}\right) \land \left ({q \implies p}\right)}\right)|1 |[[Rule of Material Equivalence]]}} {{DeMorgan|3|1|\neg \left({p \implies q}\right) \lor \neg \left({q \implies p}\right)|2|Disjunction of Negations}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|\neg \left({p \implies q}\right) \lor \neg \left({q \implies p}\right) \vdash \neg \left ({p \iff q}\right)}} {{Premise|1|\neg \left({p \implies q}\right) \lor \neg \left({q \implies p}\right)}} {{DeMorgan|2|1|\neg \left({\left ({p \implies q}\right) \land \left ({q \implies p}\right)}\right)|1|Disjunction of Negations}} {{SequentIntro|3|1|\neg \left ({p \iff q}\right)|2|[[Rule of Material Equivalence]]}} {{EndTableau}} {{qed}}	1
:$\vdash p \implies \left({p \lor q}\right)$	1
The [[Rule of Commutation/Disjunction/Formulation 2/Forward Implication|Rule of Commutation]]: :$\left({p \lor q}\right) \implies \left({q \lor p}\right)$ is a [[Definition:Tautology (Formal Semantics)|tautology]] in [[Definition:Constructed Semantics/Instance 3|Instance 3]] of [[Definition:Constructed Semantics|constructed semantics]].	1
Let $T$ be the set of [[Definition:Theorem of Logic|theorems]] of some [[Definition:Consistent (Logic)|consistent theory]] in the [[Definition:Language of Arithmetic|language of arithmetic]] which contains [[Definition:Minimal Arithmetic|minimal arithmetic]]. The set of [[Definition:Gödel Number|Gödel numbers]] of the theorems of $T$ is not [[Definition:Definable#Definable Set|definable]] in $T$.	1
{{BeginTableau|\neg \left({\neg p \lor \neg q}\right) \vdash p \land q}} {{Premise|1|\neg \left({\neg p \lor \neg q}\right)}} {{Assumption|2|\neg \left ({p \land q}\right)}} {{DeMorgan|3|2|\neg p \lor \neg q|2|Disjunction of Negations}} {{NonContradiction|4|1, 2|3|1}} {{Reductio|5|1|p \land q|2|4}} |} {{qed}} {{LEM|Reductio ad Absurdum}}	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen for all [[Definition:Boolean Interpretation|boolean interpretations]] by inspection, where the [[Definition:Truth Value|truth value]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] on the {{LHS}} is $T$, that under the one on the {{RHS}} is also $T$: : $\begin{array}{|ccccccc||ccccccccccc|} \hline (p & \implies & q) & \land & (r & \implies & s) & (\neg & q & \lor & \neg & s) & \implies & (\neg & p & \lor & \neg & r) \\ \hline F & T & F & T & F & T & F & T & F & T & T & F & T & T & F & T & T & F \\ F & T & F & T & F & T & T & T & F & T & F & T & T & T & F & T & T & F \\ F & T & F & F & T & F & F & T & F & T & T & F & T & T & F & T & F & T \\ F & T & F & T & T & T & T & T & F & T & F & T & T & T & F & T & F & T \\ F & T & T & T & F & T & F & F & T & T & T & F & T & T & F & T & T & F \\ F & T & T & T & F & T & T & F & T & F & F & T & T & T & F & T & T & F \\ F & T & T & F & T & F & F & F & T & T & T & F & T & T & F & T & F & T \\ F & T & T & T & T & T & T & F & T & F & F & T & T & T & F & T & F & T \\ T & F & F & F & F & T & F & T & F & T & T & F & T & F & T & T & T & F \\ T & F & F & F & F & T & T & T & F & T & F & T & T & F & T & T & T & F \\ T & F & F & F & T & F & F & T & F & T & T & F & F & F & T & F & F & T \\ T & F & F & F & T & T & T & T & F & T & F & T & F & F & T & F & F & T \\ T & T & T & T & F & T & F & F & T & T & T & F & T & F & T & T & T & F \\ T & T & T & T & F & T & T & F & T & F & F & T & T & F & T & T & T & F \\ T & T & T & F & T & F & F & F & T & T & T & F & F & F & T & F & F & T \\ T & T & T & T & T & T & T & F & T & F & F & T & T & F & T & F & F & T \\ \hline \end{array}$ Hence the result. {{qed}} Note that the two [[Definition:Propositional Formula|formulas]] are not [[Definition:Logical Equivalence|equivalent]], as the relevant columns do not match exactly.	1
Let $p \implies q$ be a [[Definition:Conditional|conditional]]. Then the [[Definition:Converse Statement|converse]] of $p \implies q$ is the [[Definition:Contrapositive Statement|contrapositive]] of its [[Definition:Inverse Statement|inverse]].	1
The proof proceeds by [[Principle of Mathematical Induction|induction]]. For all $n \in \Z_{\ge 0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\size {D_n} = n \paren {n - 1}$ === Basis for the Induction === $\map P 1$ is the case: {{begin-eqn}} {{eqn | l = \size {D_n} | r = 0 | c = as $D_n$ has no [[Definition:Arc of Digraph|arcs]] }} {{eqn | r = 1 \times \paren {1 - 1} | c = }} {{end-eqn}} Thus $\map P 1$ is seen to hold. This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is the [[Definition:Induction Hypothesis|induction hypothesis]]: :$\size {D_k} = k \paren {k - 1}$ from which it is to be shown that: :$\size {D_{k + 1} } = \paren {k + 1} k$ === Induction Step === This is the [[Definition:Induction Step|induction step]]: Let $D_{k + 1}$ be constructed by adding a new [[Definition:Vertex of Graph|vertex]] $v_{k + 1}$ to $D_k$. To do so, it is necessary to add $2$ [[Definition:Arc of Digraph|arcs]] to [[Definition:Join (Graph Theory)|join]] $v_{k + 1}$ to every [[Definition:Vertex of Graph|vertex]] of $D_k$. Thus there are a total of $2 k$ [[Definition:Arc of Digraph|arcs]] more in $D_{k + 1}$ than there are in $D_k$. So: {{begin-eqn}} {{eqn | l = \size {D_{k + 1} } | r = \size {D_k} + 2 k | c = from the above analysis }} {{eqn | r = k \paren {k - 1} + 2 k | c = [[Maximum Number of Arcs in Digraph#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = k^2 - k + 2 k | c = }} {{eqn | r = k^2 + k | c = }} {{eqn | r = \paren {k + 1} k | c = }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\forall n \in \Z_{\ge 0}: \size {D_n} = n \paren {n - 1}$ {{qed}}	1
:$q \vdash p \lor q$	1
We use the [[Principle of Mathematical Induction]] on the [[Definition:Cardinality|cardinality]] of $I$. === Basis for the Induction === Let $\left\vert{I}\right\vert = 1$. Let $j \in I$. Then $I = \left\{{j}\right\}$. By the definition of a [[Definition:Non-Empty Set|non-empty set]], there exists an $x \in S_j$. Hence, there exists a [[Definition:Mapping|mapping]] $f: I \to S_j$ such that $f \left({j}\right) = x$. Since $\forall i \in I: i = j$, the result follows. === Induction Hypothesis === Assume that the theorem holds for all $I$ with $\left\vert{I}\right\vert = n$. This is the [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]. === Induction Step === Now, suppose that $\left\vert{I}\right\vert = n + 1$. Let $j \in I$. Let $J = I \setminus \left\{{j}\right\}$. By [[Cardinality Less One]], $\left\vert{J}\right\vert = n$. By the [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]], there exists a [[Definition:Mapping|mapping]]: :$\displaystyle g: J \to \bigcup_{i \mathop \in J} S_i$ such that: :$\forall i \in J: g \left({i}\right) \in S_i$ By the definition of a [[Definition:Non-Empty Set|non-empty set]], there exists a $y \in S_j$. Hence, there exists a [[Definition:Mapping|mapping]]: :$\displaystyle f: I \to \bigcup_{i \mathop \in I} S_i$ such that: :$\displaystyle \forall i \in I: f \left({i}\right) = \begin{cases} g \left({i}\right) & : i \ne j \\ y & : i = j \end{cases}$ Then: :$\forall i \in I: f \left({i}\right) \in S_i$ as desired. {{qed}}	1
Let $\downarrow$ signify the [[Definition:Logical NOR|NOR]] operation. Then there exist [[Definition:Proposition|propositions]] $p,q,r$ such that: :$p \downarrow \left({q \downarrow r}\right) \not \vdash \left({p \downarrow q}\right) \downarrow r$ That is, [[Definition:Logical NOR|NOR]] is not [[Definition:Associative|associative]].	1
Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \Z_{\ge 0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\displaystyle \sum_{j \mathop = 0}^n F_j = F_{n + 2} - 1$ $\map P 0$ is the case: {{begin-eqn}} {{eqn | l = F_0 | r = 0 | c = }} {{eqn | r = 1 - 1 | c = }} {{eqn | r = F_2 - 1 | c = }} {{end-eqn}} which is seen to hold. === Basis for the Induction === $\map P 1$ is the case: {{begin-eqn}} {{eqn | l = F_1 | r = 1 | c = }} {{eqn | r = 2 - 1 | c = }} {{eqn | r = F_3 - 1 | c = }} {{end-eqn}} which is seen to hold. This is our [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 2$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$\displaystyle \sum_{j \mathop = 1}^k F_j = F_{k + 2} - 1$ Then we need to show: :$\displaystyle \sum_{j \mathop = 1}^{k + 1} F_j = F_{k + 3} - 1$ === Induction Step === This is our [[Principle of Mathematical Induction#Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \sum_{j \mathop = 1}^{k + 1} F_j | r = \sum_{j \mathop = 1}^k F_j + F_{k + 1} | c = }} {{eqn | r = F_{k + 2} - 1 + F_{k + 1} | c = [[Sum of Sequence of Fibonacci Numbers#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = F_{k + 3} - 1 | c = {{Defof|Fibonacci Number}} }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\displaystyle \forall n \in \Z_{\ge 0}: \sum_{j \mathop = 0}^n F_j = F_{n + 2} - 1$ {{qed}}	1
:$p \implies \top \dashv \vdash \top$	1
: $p \lor \bot \dashv \vdash p$	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc||cccc|} \hline p & \implies & q & \neg & p & \lor & q \\ \hline F & T & F & T & F & T & F \\ F & T & T & T & F & T & T \\ T & F & F & F & T & F & F \\ T & T & T & F & T & T & T \\ \hline \end{array}$ {{qed}}	1
Every [[Definition:Primitive Recursive Relation|primitive recursive relation]] is [[Definition:URM Computability#Set|URM computable]].	1
{{BeginTableau|\vdash \paren {p \land \paren {q \land r} } \iff \paren {\paren {p \land q} \land r} }} {{Assumption |1|p \land \paren {q \land r} }} {{SequentIntro|2|1|\paren {p \land q} \land r|1|[[Rule of Association/Conjunction/Formulation 1|Rule of Association: Formulation 1]]}} {{Implication |3||\paren {p \land \paren {q \land r} } \implies \paren {\paren {p \land q} \land r}|1|2}} {{Assumption |4|\paren {p \land q} \land r}} {{SequentIntro|5|4|p \land \paren {q \land r}|4|[[Rule of Association/Conjunction/Formulation 1|Rule of Association: Formulation 1]]}} {{Implication |6||\paren {\paren {p \land q} \land r} \implies \paren {p \land \paren {q \land r} }|4|5}} {{BiconditionalIntro|7||\paren {p \land \paren {q \land r} } \iff \paren {\paren {p \land q} \land r}|3|6}} {{EndTableau}} {{qed}}	1
Let $\overline S$ be the set of all elements of $D_{> 0_D}$ that are not in $S$: :$\overline S = D_{> 0_D} \setminus S$ {{AimForCont}} $\overline S$ is not [[Definition:Empty Set|empty]]. Then as $D$ is [[Definition:Well-Ordered Integral Domain|well-ordered]], it follows that $\overline S$ has a [[Definition:Minimal Element|minimal element]], which we will call $m$. Then $m - 1 \notin \overline S$. But $1 < m$ as $1 \in S$, and from [[One Succeeds Zero in Well-Ordered Integral Domain]], $1$ is the minimal positive element of $D$. So $0 < m - 1$ and so $m - 1$ is [[Definition:Strictly Positive|strictly positive]]. Because $m - 1 \notin \overline S$, it follows that $m - 1 \in S$. By construction of $S$ it follows that $m \in S$. So $m \in S$ and $m \in \overline S$, that is: :$m \notin S$ From this [[Definition:Contradiction|contradiction]] we deduced that there can therefore be no such $m$. Hence: :$D_{\ge 0_D} \setminus S = \O$. From [[Set Difference with Superset is Empty Set]] it follows that $D_{\ge 0_D} \subseteq S$. {{qed}}	1
{{BeginTableau|\vdash p \iff \paren {p \land q} \lor \paren {p \land \neg q} }} {{Assumption|1|p}} {{ExcludedMiddle|2|q \lor \neg q}} {{Assumption|3|q}} {{Conjunction|4|1, 3|p \land q|1|2}} {{Addition|5|1, 3|\paren {p \land q} \lor \paren {p \land \neg q}|4|1}} {{Assumption|6|\neg q}} {{Conjunction|7|1, 6|p \land \neg q|1|6}} {{Addition|8|1, 6|\paren {p \land q} \lor \paren {p \land \neg q}|7|2}} {{ProofByCases|9|1|\paren {p \land q} \lor \paren {p \land \neg q}|2|3|5|6|8}} {{Implication|10||p \implies \paren {p \land q} \lor \paren {p \land \neg q}|1|9}} {{Assumption|11|\paren {p \land q} \lor \paren {p \land \neg q} }} {{SequentIntro|12|11|p \land \paren {q \lor \neg q}|11|[[Conjunction Distributes over Disjunction]]}} {{Simplification|13|11|p|11|2}} {{Implication|14||\paren {p \land q} \lor \paren {p \land \neg q} \implies p|11|13}} {{BiconditionalIntro|15||p \iff \paren {p \land q} \lor \paren {p \land \neg q}|12|14}} {{EndTableau}} {{qed}}	1
{{BeginTableau|\vdash \paren {p \implies q} \iff \paren {\neg \paren {p \land \neg q} } }} {{Assumption|1|p \implies q}} {{Assumption|2|p \land \neg q}} {{Simplification|3|2|p|2|1}} {{ModusPonens|4|1, 2|q|1|3}} {{Simplification|5|2|\neg q|2|2}} {{NonContradiction|6|1, 2|4|5}} {{Contradiction|7|1|\neg \paren {p \land \neg q}|2|6}} {{Implication|8||\paren {p \implies q} \implies \paren {\neg \paren {p \land \neg q} }|1|7}} {{Assumption|9|\neg \paren {p \land \neg q} }} {{Assumption|10|p}} {{Assumption|11|\neg q}} {{Conjunction|12|10, 11|p \land \neg q|10|11}} {{NonContradiction|13|9, 10, 11|12|9}} {{Reductio|14|9, 10|q|11|12}} {{Implication|15|9|p \implies q|10|14}} {{Implication|16||\paren {\neg \paren {p \land \neg q} } \implies \paren {p \implies q}|9|15}} {{BiconditionalIntro|17||\paren {p \implies q} \iff \paren {\neg \paren {p \land \neg q} }|8|16}} {{EndTableau|qed}} {{LEM|Reductio ad Absurdum}}	1
The [[Definition:Biconditional|biconditional operator]] is [[Definition:Transitive Relation|transitive]]:	1
:$\neg p \implies p \vdash p$	1
Consider the [[Definition:Categorical Statement|categorical statements]]: :$\mathbf A: \quad$ The [[Definition:Universal Affirmative|universal affirmative]]: $\forall x: \map S x \implies \map P x$ :$\mathbf E: \quad$ The [[Definition:Universal Negative|universal negative]]: $\forall x: \map S x \implies \neg \map P x$ Then: :$\mathbf A$ and $\mathbf E$ are [[Definition:Contrary Statements|contrary]] {{iff}}: :$\exists x: \map S x$ Using the [[Definition:Symbolic Logic|symbology]] of [[Definition:Predicate Logic|predicate logic:]] :$\exists x: \map S x \iff \neg \paren {\paren {\forall x: \map S x \implies \map P x} \land \paren {\forall x: \map S x \implies \neg \map P x} }$	1
The '''scope''' of a [[Definition:Logical Connective|logical connective]] is defined as the [[Definition:Statement|statements]] that it connects, whether this be [[Definition:Simple Statement|simple]] or [[Definition:Compound Statement|compound]]. In the case of a [[Definition:Unary Logical Connective|unary connective]], there will be only one such statement. === [[Definition:Scope (Logic)/Connective|Connective of Propositional Logic]] === {{:Definition:Scope (Logic)/Connective}} === [[Definition:Scope (Logic)/Quantifier|Quantifier of Predicate Logic]] === {{:Definition:Scope (Logic)/Quantifier}}	1
{{BeginTableau|\vdash \neg \left({p \implies q}\right) \implies \neg q}} {{Assumption|1|\neg \left({p \implies q}\right)}} {{SequentIntro|2|1|p \land \neg q|1|[[Conjunction with Negative Equivalent to Negation of Implication]]}} {{Simplification|3|1|\neg q|2|2}} {{Implication|4||\neg \left({p \implies q}\right) \implies \neg q|1|3}} {{EndTableau}} {{Qed}}	1
{{BeginTableau|\left({p \vdash \left({q \land \neg q}\right)}\right) \vdash \neg p}} {{Premise|1|p \vdash \left({q \land \neg q}\right)}} {{Assumption|2|p}} {{SequentIntro|3|1, 2|q \land \neg q|1, 2|[[Definition:By Hypothesis|by hypothesis]]}} {{Simplification|4|1, 2|q|3|1}} {{Simplification|5|1, 2|\neg q|3|2}} {{NonContradiction|6|1, 2|4|5}} {{Contradiction|7|1|\neg p|2|6}} {{EndTableau}} {{Qed}}	1
Let $P$ be a [[Definition:Polynomial over Ring|polynomial]] of [[Definition:Degree of Polynomial|degree]] $n$ with [[Definition:Real Number|real]] or [[Definition:Complex Number|complex]] coefficients: {{begin-eqn}} {{eqn | l = \map P x | r = \sum_{i \mathop = 0}^n a_i x^i }} {{eqn | r = a_n x^n + a_{n - 1} x^{n - 1} + \dotsb + a_1 x + a_0 }} {{end-eqn}} where $a_n \ne 0$. Let $z_1, \ldots, z_k$ be [[Definition:Real Number|real]] or [[Definition:Complex Number|complex]] [[Definition:Root of Polynomial|roots]] of $P$, not assumed [[Definition:Distinct Objects|distinct]]. Let $P$ be expressible in the form: :$\displaystyle \map P x = a_n \prod_{k \mathop = 1}^n \paren {x - z_k}$ Then: {{begin-eqn}} {{eqn | l = \paren {-1}^k \dfrac {a_{n - k} } {a_n} | r = e_k \paren {\set {z_1, \ldots, z_n} } | c = that is, the [[Definition:Elementary Symmetric Function|elementary symmetric function]] on $\set {z_1, \ldots, z_n}$ }} {{eqn | r = \sum_{1 \mathop \le i_1 \mathop < \dotsb \mathop < i_k \mathop \le n} z_{i_1} \dotsm z_{i_k} | c = for $k = 1, 2, \ldots, n$. }} {{end-eqn}}	1
: $\vdash \paren {\paren {p \lor r} \land \paren {p \implies q} \land \paren {r \implies s} } \implies \paren {q \lor s}$	1
Every [[Definition:Unlimited Register Machine#State|state]] of a [[Definition:URM Program|URM program]] can be assigned a unique '''code number'''. This code number is called the '''state code''' (or '''situation code''').	1
Let $\mathbf A$ be a [[Definition:WFF of Predicate Logic|WFF of predicate logic]]. Let $\tau$ be a [[Definition:Term (Predicate Logic)|term of predicate logic]]. Let $x \in \mathrm{VAR}$ be a [[Definition:Variable (Logic)|variable]]. Let $\mathbf A \left({x \gets \tau}\right)$ be the [[Definition:Substitution Instance of Well-Formed Formula|substitution instance of $\mathbf A$ substituting $\tau$ for $x$]]. Then $\mathbf A \left({x \gets \tau}\right)$ is a [[Definition:WFF of Predicate Logic|WFF]].	1
For each $n \in \N_{>0}$, let $\map {P'} n$ be defined as: :$\map {P'} n := \map P 1 \land \dots \land \map P n$ It suffices to show that $\map {P'} n$ is true for all $n \in \N_{>0}$. It is immediate from the assumption $\map P 1$ that $\map {P'} 1$ is [[Definition:True|true]]. Now suppose that $\map {P'} n$ holds. By $(2)$, this implies that $\map P {n + 1}$ holds as well. Consequently, $\map {P'} n \land \map P {n + 1} = \map {P'} {n + 1}$ holds. Thus by the [[Principle of Mathematical Induction]]: :$\map {P'} n$ holds for all $n \in \N_{>0}$ as desired. {{Qed}}	1
A '''paradox''' is a [[Definition:Statement|statement]] or group of statements that leads to one of the following: * a [[Definition:Contradiction|contradiction]] * a situation which defies intuition * a result that is merely "puzzling".	1
If two [[Definition:Statement|statements]] $p$ and $q$ are such that: :$p \vdash q$, that is: $p$ [[Definition:Therefore|therefore]] $q$ :$q \vdash p$, that is: $q$ [[Definition:Therefore|therefore]] $p$ then $p$ and $q$ are said to be '''(logically) equivalent'''. That is: :$p \dashv \vdash q$ means: :$p \vdash q$ and $q \vdash p$. Note that because the [[Definition:Conclusion|conclusion]] of an [[Definition:Logical Argument|argument]] is a single [[Definition:Statement|statement]], there can be only one statement on either side of the $\dashv \vdash$ sign. In [[Definition:Symbolic Logic|symbolic logic]], the notion of '''logical equivalence''' occurs in the form of [[Definition:Provable Equivalence|provable equivalence]] and [[Definition:Semantic Equivalence|semantic equivalence]]. === [[Definition:Provable Equivalence|Provable Equivalence]] === {{:Definition:Provable Equivalence}} === [[Definition:Semantic Equivalence|Semantic Equivalence]] === {{:Definition:Semantic Equivalence}}	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, in each case, the [[Definition:Truth Value|truth values]] in the appropriate columns match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c|ccc||c|ccc|} \hline \bot & p & p & \lor & \bot \\ \hline F & F & F & F & F \\ F & T & T & T & F \\ \hline \end{array}$ {{qed}}	1
Let $\operatorname{sgn}: \N \to \N$ be defined as the [[Definition:Signum Function/Natural Numbers|signum function]]. Then: : $\operatorname{sgn}$ is [[Definition:Primitive Recursive Set|primitive recursive]]. : $\overline {\operatorname{sgn}}$ is [[Definition:Primitive Recursive Set|primitive recursive]].	1
Let $\mathcal L$ be a [[Definition:Formal Language|formal language]]. Let $\mathcal T$ be a [[Definition:Top-Down Grammar|top-down grammar]] for $\mathcal L$. Let $\mathcal B$ be the [[Definition:Bottom-Up Form of Top-Down Grammar|bottom-up form]] of $\mathcal T$. Then $\mathcal B$ is also a [[Definition:Formal Grammar|formal grammar]] for $\mathcal L$.	1
From the definition of the [[Definition:Factorial|factorial]], we have that: :$\operatorname{fac} \left({n}\right) = \begin{cases} 1 & : n = 0 \\ \operatorname{mult} \left({n, \operatorname{fac} \left({n - 1}\right)}\right) & : n > 0 \end{cases}$ Thus $\operatorname{fac}$ is obtained by [[Definition:Primitive Recursion|primitive recursion]] from the [[Constant Function is Primitive Recursive|constant]] $1$ and the [[Multiplication is Primitive Recursive|primitive recursive function $\operatorname{mult}$]]. Hence $\operatorname{fac}$ is [[Definition:Primitive Recursive Function|primitive recursive]]. {{qed}} [[Category:Primitive Recursive Functions]] hsvytfvlncsrbxuwe7stbguh1m2jp0s	1
Apply the [[Method of Truth Tables]]: :$\begin{array}{|ccc||cc|} \hline p & \downarrow & p & \neg & p \\ \hline F & T & F & T & F \\ T & F & T & F & T \\ \hline \end{array}$ As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. {{qed}}	1
'''Temporal logic''' is a subcategory of [[Definition:Modal Logic|modal logic]] which introduces [[Definition:Time|time]], by defining the concepts: :[[Definition:Sometimes|sometimes]] :[[Definition:Always|always]].	1
: $\neg p \implies \bot \vdash p$	1
Proof by [[Principle of Mathematical Induction|induction]] on $m$, the number of [[Definition:Elementary Row Operation|elementary row operations]] in the [[Definition:Finite Sequence|sequence]] $\hat o_1, \ldots, \hat o_m$. === Basis for the Induction === Suppose $m = 1$, so there is only one [[Definition:Elementary Row Operation|elementary row operation]] $\hat o$ in the [[Definition:Finite Sequence|sequence]]. Let $r_i$ denote the $i$'th [[Definition:Row of Matrix|row]] of $\mathbf A$. Suppose that $\hat o$ is of the type $r_i \to a r_i$, where $a \in R$ and $i \in \set {1, \ldots, n}$. From [[Effect of Elementary Row Operations on Determinant]], it follows that: :$\map \det {\mathbf A} = a \map \det {\mathbf A'}$ Suppose that $\hat o$ is of the type $r_i \to r_i + ar_j$, where $a \in R$ and $i, j \in \set {1, \ldots, n}, i \ne j$. From [[Effect of Elementary Row Operations on Determinant]], it follows that :$\map \det {\mathbf A} = \map \det {\mathbf A'} = 1_R \map \det {\mathbf A'}$ where $1_R$ denotes the [[Definition:Identity Element|identity element]] of $\struct {R, \circ}$. Suppose that $\hat o$ is of the type $r_i \leftrightarrow r_j$. From [[Effect of Elementary Row Operations on Determinant]], it follows that :$\map \det {\mathbf A} = -\map \det {\mathbf A'} = -1_R \map \det {\mathbf A'}$ where the last equality follows from [[Product with Ring Negative/Corollary|Product with Ring Negative: Corollary]]. This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === For $m \in \N$, let $\hat o_1, \ldots, \hat o_m$ be a [[Definition:Finite Sequence|finite sequence]] of [[Definition:Elementary Row Operation|elementary row operations]]. This is the [[Definition:Induction Hypothesis|induction hypothesis]]: There exists $c \in R$ such that for all [[Definition:Square Matrix|matrices]] of [[Definition:Order of Square Matrix|order $n$]] $\mathbf A$: :$\map \det {\mathbf A} = c \map \det {\mathbf A'}$ where $\mathbf A'$ is the [[Definition:Square Matrix|matrix]] of [[Definition:Order of Square Matrix|order $n$]] that results from using the [[Definition:Elementary Row Operation|elementary row operations]] $\hat o_1, \ldots, \hat o_m$ on $\mathbf A$. === Induction Step === This is the [[Definition:Induction Step|induction step]]: Let $\hat o_1, \ldots, \hat o_m, \hat o_{m + 1}$ be a [[Definition:Finite Sequence|finite sequence]] of [[Definition:Elementary Row Operation|elementary row operations]]. Let $r_i$ denote the $i$'th [[Definition:Row of Matrix|row]] of $\mathbf A'$. Let $\mathbf A''$ denote the [[Definition:Square Matrix|matrix]] of [[Definition:Order of Square Matrix|order $n$]] that results from using the [[Definition:Elementary Row Operation|elementary row operation]] $\hat o_{m + 1}$ on $A'$. Then $\mathbf A''$ is equal to the [[Definition:Square Matrix|matrix]] that results from using the [[Definition:Elementary Row Operation|elementary row operations]] $\hat o_1, \ldots, \hat o_m, \hat o_{m + 1}$ on $A$. Suppose that $\hat o_{m + 1}$ is of the type $r_i \to ar_i$, where $a \in R$ and $i \in \set {1, \ldots, n}$. Then: {{begin-eqn}} {{eqn | l = \map \det {\mathbf A} | r = c \map \det {\mathbf A'} | c = by the [[Effect of Sequence of Elementary Row Operations on Determinant#Induction Hypothesis|induction hypothesis]] }} {{eqn | r = \paren {c a} \map \det {\mathbf A''} | c = [[Effect of Elementary Row Operations on Determinant]] }} {{end-eqn}} Suppose that $\hat o_{m + 1}$ is of the type $r_i \to r_i + a r_j$, where $a \in R$ and $i, j \in \set {1, \ldots, n}, i \ne j$. Then: {{begin-eqn}} {{eqn | l = \map \det {\mathbf A} | r = c \map \det {\mathbf A'} | c = by the [[Effect of Sequence of Elementary Row Operations on Determinant#Induction Hypothesis|induction hypothesis]] }} {{eqn | r = c 1_R \map \det {\mathbf A''} | c = [[Effect of Elementary Row Operations on Determinant]] }} {{eqn | r = c \map \det {\mathbf A''} | c = {{Defof|Identity Element}}, since $R$ is [[Definition:Commutative Ring|commutative]] }} {{end-eqn}} Suppose that $\hat o_{m + 1}$ is of the type $r_i \leftrightarrow r_j$. Then: {{begin-eqn}} {{eqn | l = \map \det {\mathbf A} | r = c \map \det {\mathbf A'} | c = by the [[Effect of Sequence of Elementary Row Operations on Determinant#Induction Hypothesis|induction hypothesis]] }} {{eqn | r = c \paren {-1_R} \map \det {\mathbf A''} | c = [[Effect of Elementary Row Operations on Determinant]] }} {{eqn | r = \paren {-c} \map \det {\mathbf A''} | c = [[Product with Ring Negative/Corollary|Product with Ring Negative: Corollary]] }} {{end-eqn}} Then the [[Definition:Induction Step|induction step]] is proved for all three types of [[Definition:Elementary Row Operation|elementary row operations]]. {{qed}} [[Category:Determinants]] [[Category:Elementary Row Operations]] [[Category:Proofs by Induction]] lxp6dfv6nef3s6nkzxs4nrdn7e7j5vo	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen for all [[Definition:Boolean Interpretation|boolean interpretations]] by inspection, where the [[Definition:Truth Value|truth value]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] on the {{LHS}} is $T$, that under the one on the {{RHS}} is also $T$: $\begin{array}{|cccccc||cc|} \hline (p & \implies & q) & \land & \neg & q & \neg & p \\ \hline F & T & F & T & T & F & T & F \\ F & T & T & F & F & T & T & F \\ T & F & F & F & T & F & F & T \\ T & T & T & F & F & T & F & T \\ \hline \end{array}$ Hence the result. {{qed}} Note that the two [[Definition:Propositional Formula|formulas]] are not [[Definition:Logical Equivalence|equivalent]], as the relevant columns do not match exactly.	1
{{begin-eqn}} {{eqn | lo= \forall n \ge 1: | l = \sum_{j \mathop = 1}^n F_{2 j - 1} | r = F_1 + F_3 + F_5 + \cdots + F_{2 n - 1} | c = }} {{eqn | r = F_{2 n} | c = }} {{end-eqn}}	1
{{BeginTableau|\vdash q \implies \paren {\paren {p \implies q} \land \paren {\neg p \implies q} } }} {{Assumption|1|q|}} {{SequentIntro|2|1|\paren {p \implies q} \land \paren {\neg p \implies q}|1|[[Principle of Dilemma/Formulation 1/Reverse Implication|Principle of Dilemma: Formulation 1: Reverse Implication]]}} {{Implication|3||q \implies \paren {\paren {p \implies q} \land \paren {\neg p \implies q} }|1|2}} {{EndTableau}} {{qed}} [[Category:Principle of Dilemma]] d9q4uvsexr57d799yi2aupfipflfpf2	1
Let $\sequence {a_n}, \sequence {b_n}, \sequence {c_n}, \sequence {d_n}$ be [[Definition:Sequence|sequences]] of [[Definition:Real Number|real]] or [[Definition:Complex Number|complex numbers]]. Let: :$a_n = \map \OO {b_n}$ :$c_n = \map o {d_n}$ where: :$\OO$ denotes [[Definition:Big-O Notation|big-O notation]] :$o$ denotes [[Definition:Little-O Notation|little-o notation]]. Then: :$a_n c_n = \map o {b_n d_n}$	1
Let $T$ be a [[Definition:Complete Theory|complete $\mathcal L$-theory]] whose [[Definition:Logical Language|language]] $\mathcal L$ is [[Definition:Countable Language|countable]]. If $T$ is [[Definition:Kappa-Stable Theory|$\omega$-stable]], then $T$ is [[Definition:Kappa-Stable Theory|$\kappa$-stable]] for all [[Definition:Infinite Cardinal|infinite $\kappa$]].	1
{{BeginTableau|p \iff q \vdash q \iff p}} {{Premise|1|p \iff q}} {{SequentIntro|2|1|\left({p \implies q}\right) \land \left({q \implies p}\right)|1|[[Rule of Material Equivalence]]}} {{Commutation|3|1|\left({q \implies p}\right) \land \left({p \implies q}\right)|2|Conjunction}} {{SequentIntro|4|1|q \iff p|3|[[Rule of Material Equivalence]]}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|q \iff p \vdash p \iff q}} {{Premise|1|q \iff p}} {{SequentIntro|2|1|\left({q \implies p}\right) \land \left({p \implies q}\right)|1|[[Rule of Material Equivalence]]}} {{Commutation|3|1|\left({p \implies q}\right) \land \left({q \implies p}\right)|2|Conjunction}} {{SequentIntro|4|1|p \iff q|3|[[Rule of Material Equivalence]]}} {{EndTableau}} {{qed}}	1
Let $T$ be a [[Definition:Theory (Logic)|complete $\mathcal{L}$-theory]]. Let $\mathfrak{C}$ be a [[Definition:Monster Model|monster model]] for $T$. Let $A\subseteq B$ be [[Definition:Subset|subsets]] of the universe of $\mathfrak{C}$. Let $\pi(\bar x)$ be an [[Definition:Type|$n$-type]] over $B$. If $\pi$ does not [[Definition:Fork|fork]] over $A$, then for any formula $\phi(\bar x, \bar b)$, either $\pi \cup \{\phi\}$ or $\pi \cup \{\neg\phi\}$ does not fork over $A$.	1
Taking the criteria for [[Definition:Boolean Algebra/Definition 1|definition 1 of a Boolean algebra]] in turn: === $(\text {BA} 0):$ Closure === $\powerset S$ is [[Definition:Closed Algebraic Structure|closed]] under both $\cup$ and $\cap$: :[[Power Set is Closed under Intersection]] :[[Power Set is Closed under Union]] :[[Power Set is Closed under Complement]] {{qed|lemma}} === $(\text {BA} 1):$ Commutativity === Both $\cup$ and $\cap$ are [[Definition:Commutative Operation|commutative]] from [[Intersection is Commutative]] and [[Union is Commutative]]. {{qed|lemma}} === $(\text {BA} 2):$ Distributivity === Both $\cup$ and $\cap$ [[Definition:Distributive Operation|distribute]] over the other, from [[Union Distributes over Intersection]] and [[Intersection Distributes over Union]]. {{qed|lemma}} === $(\text {BA} 3):$ Identity Elements === Both $\cup$ and $\cap$ have [[Definition:Identity Element|identities]]: From [[Power Set with Intersection is Monoid]], $S$ is the [[Definition:Identity Element|identity]] for $\cap$. From [[Power Set with Union is Monoid]], $\O$ is the [[Definition:Identity Element|identity]] for $\cup$. {{qed|lemma}} === $(\text {BA} 4):$ Complements === From [[Union with Complement]]: :$\forall A \in S: A \cup \map \complement A = S$ which is the [[Definition:Identity Element|identity]] for $\cap$. From [[Intersection with Complement]]: :$\forall A \in S: A \cap \map \complement A = \O$ which is the [[Definition:Identity Element|identity]] for $\cup$. {{qed|lemma}} All the criteria for a [[Definition:Boolean Algebra/Definition 1|Boolean algebra]] are therefore fulfilled. {{qed}}	1
We have that: :$\forall j: 1 \le j \le k: n_{\sigma \left({j}\right)} = \operatorname{pr}^k_{\sigma \left({j}\right)}$. Thus $h$ is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from $f$ and the [[Definition:Basic Primitive Recursive Function/Projection Function|projection functions]] $\operatorname{pr}^k_{\sigma \left({j}\right)}$. The result follows. {{qed}} It follows that if a [[Definition:Function|function]] $h$ can be obtained from known [[Definition:Primitive Recursive Function|primitive recursive functions]] by [[Definition:Primitive Recursion|primitive recursion]] where a variable other than the last one is taken as the recursion variable, then $h$ is [[Definition:Primitive Recursive Function|primitive recursive]]. [[Category:Primitive Recursive Functions]] pxm8bkuciiztzv4ivz1shvcb1041jz0	1
Each <tt>Jump</tt> of the form $\map J {m, n, q}$ where $q > l$ leads to a line which does not contain an instruction. The line $\map J {m, n, l + 1}$ likewise contains no instructions, by definition. Therefore, when jumping to $\map J {m, n, l + 1}$ the program behaves in exactly the same way: that is, it stops when the instruction $\map J {m, n, l + 1}$ causes the program to jump to line $l + 1$. After the [[Definition:URM Program|URM program]] has [[Definition:Unlimited Register Machine#Termination|terminated]], its [[Definition:Unlimited Register Machine#Output|output]] sits in $R_1$ by convention. Once the [[Definition:URM Program|URM program]] reaches line $l + 1$ it has by definition [[Definition:Unlimited Register Machine#Termination|terminated]], and because of the modifications to the <tt>Jump</tt>s as defined above, there is no other way that it ''can'' terminate. Any further instructions that are added to a [[Definition:URM Program|URM program]] that are placed at line $l + 1$ and those following will therefore be executed in order (as long as none of them are <tt>Jump</tt>s) and the program will then ''really'' terminate. By adding the [[Clear Registers Program]] $\map Z {2, u}$ to the end of $P$, the only effect this will have on the operation of the program is to clear all the registers to $0$ except the one the [[Definition:Unlimited Register Machine#Output|output]] is in. {{qed}} [[Category:URM Programs]] 2ia7tx3ry8qzafgkt88e310ng2i3l4f	1
'''Absurd''' is a word used mainly in logic meaning either '''meaningless''', '''contradictory''' or '''internally inconsistent'''.	1
{{begin-eqn}} {{eqn | l = a_n | o = \text {is} | r = \text {bounded} }} {{eqn | ll = \leadstoandfrom | lo = \exists k \in \R: | l = \size {a_n} | o = \le | r = k | c = {{Defof|Bounded Sequence}} }} {{eqn | ll = \leadstoandfrom | lo = \exists k \in \R: | l = \size {a_n} | o = \le | r = k \cdot \size 1 }} {{eqn | ll = \leadstoandfrom | l = a_n | r = \map \OO 1 | c = {{Defof|O Notation|subdef = Big-O Notation/Sequence|Big-$\OO$ Notation}} }} {{end-eqn}} {{qed}} [[Category:Asymptotic Notation]] t642smig8dem4j9rdauopt8o0pzunlx	1
:$\vdash \paren {\paren {p \implies q} \implies p} \iff p$	1
Let $v$ be a [[Definition:Boolean Interpretation|boolean interpretation]]. Let $\mathbf A$ be a [[Definition:WFF of Propositional Logic|WFF of propositional logic]]. Then $v$ can not [[Definition:Model (Boolean Interpretations)|model]] both $\mathbf A$ and $\neg \mathbf A$.	1
The proof proceeds by [[Second Principle of Mathematical Induction|strong induction]]. For all $n \in \Z_{>0}$, let $P \left({n}\right)$ be the [[Definition:Proposition|proposition]]: :$\len \left({S_n}\right) = F_n$ === Basis for the Induction === $P \left({1}\right)$ is the case: {{begin-eqn}} {{eqn | l = \len \left({S_1}\right) | r = \len \left({\text a}\right) | c = {{Defof|Fibonacci String}} }} {{eqn | r = 1 | c = {{Defof|Length of String}} }} {{eqn | r = F_1 | c = {{Defof|Fibonacci Number}}: $F_1 = 1$ }} {{end-eqn}} Thus $P \left({1}\right)$ is seen to hold. $P \left({2}\right)$ is the case: {{begin-eqn}} {{eqn | l = \len \left({S_2}\right) | r = \len \left({\text b}\right) | c = {{Defof|Fibonacci String}} }} {{eqn | r = 1 | c = {{Defof|Length of String}} }} {{eqn | r = F_2 | c = {{Defof|Fibonacci Number}}: $F_2 = 1$ }} {{end-eqn}} Thus $P \left({2}\right)$ is seen to hold. This is the [[Second Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that, if $P \left({j}\right)$ is true, for all $j$ such that $1 \le j \le k$, then it logically follows that $P \left({k + 1}\right)$ is true. This is the [[Second Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$\len \left({S_k}\right) = F_k$ and: :$\len \left({S_{k - 1} }\right) = F_{k - 1}$ from which it is to be shown that: :$\len \left({S_{k + 1} }\right) = F_{k + 1}$ === Induction Step === This is the [[Second Principle of Mathematical Induction#Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \len \left({S_{k + 1} }\right) | r = \len \left({S_k S_{k - 1} }\right) | c = {{Defof|Fibonacci String}} }} {{eqn | r = \len \left({S_k}\right) + \len \left({S_{k - 1} }\right) | c = {{Defof|Length of String}} }} {{eqn | r = F_k + F_{k - 1} | c = [[Length of Fibonacci String is Fibonacci Number#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = F_{k + 1} | c = {{Defof|Fibonacci Number}} }} {{end-eqn}} So $P \left({k}\right) \implies P \left({k + 1}\right)$ and the result follows by the [[Second Principle of Mathematical Induction]]. Therefore: :$\forall n \in \Z_{>0}: \len \left({S_n}\right) = F_n$ {{qed}}	1
The set $\operatorname{Tot}$ of [[Definition:Natural Numbers|natural numbers]] which [[Unique Code for URM Program|code]] [[Definition:URM Program|URM programs]] which compute [[Definition:Total Function|total functions]] of one variable is not [[Definition:Recursive Set|recursive]].	1
:$\vdash \paren {p \implies q} \iff \paren {\neg q \implies \neg p}$	1
: $\neg \left ({p \iff q}\right) \dashv \vdash \left({\neg p \land q}\right) \lor \left({p \land \neg q}\right)$	1
:$p \implies q, q \implies r \vdash p \implies r$	1
:$\neg \paren {p \land q} \dashv \vdash p \implies \neg q$	1
Let $\mathcal L, \mathcal L'$ be [[Definition:Signature for Predicate Logic|signatures]] for the [[Definition:Language of Predicate Logic|language of predicate logic]]. Let $\mathcal L'$ be a [[Definition:Supersignature|supersignature]] of $\mathcal L$. Let $\mathbf A$ be an [[Definition:Sentence|$\mathcal L$-sentence]]. Let $\Sigma$ be a [[Definition:Set|set]] of [[Definition:Sentence|$\mathcal L$-sentences]]. Then the following are [[Definition:Logically Equivalent|equivalent]]: :$\mathcal A \models_{\mathrm{PL}} \mathbf A$ for all [[Definition:Structure for Predicate Logic|$\mathcal L$-structure]] $\mathcal A$ for which $\mathcal A \models_{\mathrm{PL}} \Sigma$ :$\mathcal A' \models_{\mathrm{PL}} \mathbf A$ for all [[Definition:Structure for Predicate Logic|$\mathcal L'$-structure]] $\mathcal A'$ for which $\mathcal A' \models_{\mathrm{PL}} \Sigma$ where $\models_{\mathrm{PL}}$ denotes the [[Definition:Model (Predicate Logic)|models]] relation. That is to say, the notion of [[Definition:Semantic Consequence (Predicate Logic)|semantic consequence]] is preserved in passing to a [[Definition:Supersignature|supersignature]].	1
:$P \left({\mathbf a}\right) \vdash \exists x: P \left({x}\right)$ Suppose we have the following: : We can find an arbitrary [[Definition:Object|object]] $\mathbf a$ in our [[Definition:Universe of Discourse|universe of discourse]] which has the [[Definition:Property|property]] $P$. Then we may infer that: : there exists in that universe ''at least one'' object $x$ which has that property $P$. This is called the '''Rule of Existential Generalisation''' and often appears in a proof with its abbreviation '''EG'''.	1
Let $T$ be a satisfiable $\mathcal L$-theory with no finite models. Let $T$ be $\kappa$-[[Definition:Categorical (Model Theory)|categorical]] for some infinite cardinal $\kappa \ge \left|{\mathcal L}\right|$. Then $T$ is complete.	1
:$p \implies \neg q \vdash q \implies \neg p$	1
Let $\Z_{\ge n_0}$ denote the [[Definition:Set|set]]: :$S = \set {n \in \Z: n \ge n_0}$ Let $S$ be the [[Definition:Set|set]] of [[Definition:Integer|integers]] defined as: :$S = \set {n \in \Z_{\ge n_0}: \map P n}$ That is, the set of all [[Definition:Integer|integers]] for which $n \ge n_0$ and for which $\map P n$ holds. From [[Subset of Set with Propositional Function]] we have that: :$S \subseteq \Z_{\ge n_0}$ From $(1)$ we have that $\map P {n_0}$. Hence $n_0 \in S$. Let $k \in S$. Then $\map P k$ holds. But by $(2)$, $\map P {k + 1}$ also holds. This implies $k + 1 \in S$. So as: :$S \subseteq \Z_{\ge n_0}$ and: :$S$ satisfies $(1)$ and $(2)$ it follows by the [[Principle of Finite Induction]] that $S = \Z_{\ge n_0}$. Hence for all $n \ge n_0$, $\map P n$ holds. {{qed}}	1
From [[Count of Truth Functions]] there are $2^{\paren {2^2} } = 16$ distinct [[Definition:Truth Function|truth functions]] on $2$ variables. These can be depicted in a [[Definition:Truth Table|truth table]] as follows: $\begin{array}{|r|cccc|} \hline p & \T & \T & \F & \F \\ q & \T & \F & \T & \F \\ \hline \map {f_\T} {p, q} & \T & \T & \T & \T \\ p \lor q & \T & \T & \T & \F \\ p \impliedby q & \T & \T & \F & \T \\ \map {\pr_1} {p, q} & \T & \T & \F & \F \\ p \implies q & \T & \F & \T & \T \\ \map {\pr_2} {p, q} & \T & \F & \T & \F \\ p \iff q & \T & \F & \F & \T \\ p \land q & \T & \F & \F & \F \\ p \uparrow q & \F & \T & \T & \T \\ \map \neg {p \iff q} & \F & \T & \T & \F \\ \map {\overline {\pr_2} } {p, q} & \F & \T & \F & \T \\ \map \neg {p \implies q} & \F & \T & \F & \F \\ \map {\overline {\pr_1} } {p, q} & \F & \F & \T & \T \\ \map \neg {p \impliedby q} & \F & \F & \T & \F \\ p \downarrow q & \F & \F & \F & \T \\ \map {f_\F} {p, q} & \F & \F & \F & \F \\ \hline \end{array}$ That accounts for all $16$ of them. {{qed}}	1
First of all, we need to prove === Lemma === Following the definitions on [[Definition:Ultraproduct]] :$\left(m_{k, i}\right)_\mathcal U = \left(m'_{k, i}\right)_\mathcal U$, $k = 1, \dotsc, n$ {{iff}} :$\left\{ i : \left({m_{1, i}, \dots, m_{n, i} }\right) = \left({m'_{1, i}, \dots, m'_{n, i} }\right) \right \} \in \mathcal U$ === Proof === Let :$I_k := \left\{ i \in I : m_{k, i} = m'_{k, i} \right\}$ :$I^* := \left\{ i : \left({m_{1, i}, \dots, m_{n, i} }\right) = \left({m'_{1, i}, \dots, m'_{n, i} }\right) \right \}= \displaystyle \bigcap^n_{k = 1} I_k $ Suppose :$\left(m_{k, i}\right)_\mathcal U = \left(m'_{k, i}\right)_\mathcal U$ for $k = 1, \dotsc, n$ we have :$I_k \in \mathcal U$ for $k = 1, \dotsc, n$ Since $\mathcal U$ is closed under [[Definition:Set Intersection|intersection]] :$I^* \in \mathcal U$ On the other hand, suppose :$I^* \in \mathcal U$ Since $\mathcal U$ is [[Definition:Upper Set|upward-closed]] :$I_k \in \mathcal U$ for $k = 1, \dotsc, n$ Therefore :$\left(m_{k, i}\right)_\mathcal U = \left(m'_{k, i}\right)_\mathcal U$ {{qed}} === Proposition 1 === ''The definition of $f^\mathcal M$ is consistent.'' i.e. for $\left(m_{k, i}\right)_\mathcal U = \left(m'_{k, i}\right)_\mathcal U$, $k = 1, \dotsc, n$ :$\left(f^{\mathcal M_i}\left(m_{1, i}, \dots, m_{n, i}\right)\right)_\mathcal U = \left(f^{\mathcal M_i}\left(m'_{1, i}, \dots, m'_{n, i}\right)\right)_\mathcal U$ === Proof === Firstly note that: :$\{i : f^{\mathcal M_i}\left(m_{1, i}, \dots, m_{n, i}\right) = f^{\mathcal M_i}\left(m'_{1, i}, \dots, m'_{n, i}\right) \} \supseteq \{i : \left(m_{1, i}, \dots, m_{n, i}\right) = \left(m'_{1, i}, \dots, m'_{n, i}\right) \} $ and by $\mathcal U$ is an [[Definition:Ultrafilter_on_Set|ultrafilter]] on $I$, we have :$\{i : \left(m_{1, i}, \dots, m_{n, i}\right) = \left(m'_{1, i}, \dots, m'_{n, i}\right) \} \in \mathcal U$ implies :$\{i : f^{\mathcal M_i}\left(m_{1, i}, \dots, m_{n, i}\right) = f^{\mathcal M_i}\left(m'_{1, i}, \dots, m'_{n, i}\right) \} \in \mathcal U$ Therefore, :$\left(m_{k, i}\right)_\mathcal U = \left(m'_{k, i}\right)_\mathcal U$, $k = 1, \dotsc, n$, by [[#Lemma]], which is equvalent to $\{i : \left(m_{1, i}, \dots, m_{n, i}\right) = \left(m'_{1, i}, \dots, m'_{n, i}\right) \} \in \mathcal U$ implies :$\left(f^{\mathcal M_i}\left(m_{1, i}, \dots, m_{n, i}\right)\right)_\mathcal U = \left(f^{\mathcal M_i}\left(m'_{1, i}, \dots, m'_{n, i}\right)\right)_\mathcal U$ {{qed}} === Proposition 2 === ''The definition of $R^\mathcal M$ is consistent.'' i.e. for $\left(m_{k, i}\right)_\mathcal U = \left(m'_{k, i}\right)_\mathcal U$, $k = 1, \dotsc, n$ :$\left\{i \in I: \left({m_{1, i}, \dots, m_{n, i} }\right) \in R^\mathcal M_i\right\} \in \mathcal U$ {{iff}} :$\left\{i \in I: \left({m'_{1, i}, \dots, m'_{n, i} }\right) \in R^\mathcal M_i\right\} \in \mathcal U$ === Proof === Let :$S := \left\{i \in I: \left({m_{1, i}, \dots, m_{n, i} }\right) \in R^\mathcal M_i\right\}$ :$S' := \left\{i \in I: \left({m'_{1, i}, \dots, m'_{n, i} }\right) \in R^\mathcal M_i\right\}$ :$I^* := \left\{ i : \left({m_{1, i}, \dots, m_{n, i} }\right) = \left({m'_{1, i}, \dots, m'_{n, i} }\right) \right \}$ :$T := I^* \cap S$ :$T' := I^* \cap S'$ As [[#Lemma]] implies :$I^* \in \mathcal U$ therefore :$S \in \mathcal U$ implies $T \in \mathcal U$ Note that :$\left({m_{1, i}, \dots, m_{n, i} }\right) = \left({m'_{1, i}, \dots, m'_{n, i} }\right)$ for $i \in I^*$ we have :$T = T'$ Hence :$T' \in \mathcal U$ and :$S' \in \mathcal U$ since $S' \supseteq T'$ So far we have proved :$S \in \mathcal U$ implies $S' \in \mathcal U$ By symmetry, :$S' \in \mathcal U$ implies $S \in \mathcal U$ {{qed}} [[Category:Model Theory]] pxaqnmgw5qct26nsoe4koay2w3aghan	1
Let $S_n$ denote the $n$th [[Definition:Fibonacci String|Fibonacci string]]. Let $\len \left({S_n}\right)$ denote the [[Definition:Length of String|length]] of $S_n$. Then: :$\len \left({S_n}\right) = F_n$ where $F_n$ denotes the $n$th [[Definition:Fibonacci Number|Fibonacci number]].	1
{{BeginTableau|p \implies \bot \vdash \neg p}} {{Premise|1|p \implies \bot}} {{Assumption|2|p}} {{ModusPonens|3|1, 2|\bot|1|2}} {{Contradiction|4|1|\neg p|2|3}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|\neg p \vdash p \implies \bot}} {{Premise|1|\neg p}} {{Assumption|2|p}} {{NonContradiction|3|1,2|1|2}} {{Implication|4|1|p \implies \bot|2|3}} {{EndTableau}} {{qed}}	1
:$\paren {p \implies q} \implies \paren {p \implies r} \vdash p \implies \paren {q \implies r}$	1
Let $\sequence {a_n}$ and $\sequence {b_n}$ be [[Definition:Sequence|sequences]] of [[Definition:Real Number|real]] or [[Definition:Complex Number|complex numbers]]. Let $a_n = \map o {b_n}$ where $o$ denotes [[Definition:Little-O Notation|little-O notation]]. Then $a_n = \map \OO {b_n}$ where $\OO$ denotes [[Definition:Big-O Notation|big-$\OO$ notation]].	1
{{begin-eqn}} {{eqn | l = p \oplus q | o = \dashv \vdash | r = \neg \left ({p \iff q}\right) | c = [[Exclusive Or is Negation of Biconditional]] }} {{eqn | o = \dashv \vdash | r = \left({\neg p \land q}\right) \lor \left({p \land \neg q}\right) | c = [[Non-Equivalence as Disjunction of Conjunctions/Formulation 1|Non-Equivalence as Disjunction of Conjunctions]] }} {{end-eqn}} {{qed}}	1
There are $64$ patterns of [[Definition:Categorical Syllogism|categorical syllogism]] per [[Definition:Figure of Categorical Syllogism|figure]]: :$\begin{array}{cccc} AAA & AAE & AAI & AAO \\ AEA & AEE & AEI & AEO \\ AIA & AIE & AII & AIO \\ AOA & AOE & AOI & AOO \\ \end{array} \qquad \begin{array}{cccc} EAA & EAE & EAI & EAO \\ EEA & EEE & EEI & EEO \\ EIA & EIE & EII & EIO \\ EOA & EOE & EOI & EOO \\ \end{array}$ :$\begin{array}{cccc} IAA & IAE & IAI & IAO \\ IEA & IEE & IEI & IEO \\ IIA & IIE & III & IIO \\ IOA & IOE & IOI & IOO \\ \end{array} \qquad \begin{array}{cccc} OAA & OAE & OAI & OAO \\ OEA & OEE & OEI & OEO \\ OIA & OIE & OII & OIO \\ OOA & OOE & OOI & OOO \\ \end{array}$ From [[No Valid Categorical Syllogism contains two Negative Premises]], all those whose patterns start $EE$, $EO$, $OE$ and $OO$ can be eliminated: :$\begin{array}{cccc} AAA & AAE & AAI & AAO \\ AEA & AEE & AEI & AEO \\ AIA & AIE & AII & AIO \\ AOA & AOE & AOI & AOO \\ \end{array} \qquad \begin{array}{cccc} EAA & EAE & EAI & EAO \\ & & & \\ EIA & EIE & EII & EIO \\ & & & \\ \end{array}$ :$\begin{array}{cccc} IAA & IAE & IAI & IAO \\ IEA & IEE & IEI & IEO \\ IIA & IIE & III & IIO \\ IOA & IOE & IOI & IOO \\ \end{array} \qquad \begin{array}{cccc} OAA & OAE & OAI & OAO \\ & & & \\ OIA & OIE & OII & OIO \\ & & & \\ \end{array}$ From [[No Valid Categorical Syllogism contains two Particular Premises]], all those whose patterns start $II$, $IO$ and $OI$ and $OO$ can be eliminated: :$\begin{array}{cccc} AAA & AAE & AAI & AAO \\ AEA & AEE & AEI & AEO \\ AIA & AIE & AII & AIO \\ AOA & AOE & AOI & AOO \\ \end{array} \qquad \begin{array}{cccc} EAA & EAE & EAI & EAO \\ & & & \\ EIA & EIE & EII & EIO \\ \end{array}$ :$\begin{array}{cccc} IAA & IAE & IAI & IAO \\ IEA & IEE & IEI & IEO \\ \end{array} \qquad \begin{array}{cccc} OAA & OAE & OAI & OAO \\ \end{array}$ From [[Conclusion of Valid Categorical Syllogism is Negative iff one Premise is Negative]], further patterns can be eliminated: :$\begin{array}{cccc} AAA & & AAI & \\ & AEE & & AEO \\ AIA & & AII & \\ & AOE & & AOO \\ \end{array} \qquad \begin{array}{cccc} & EAE & & EAO \\ & & & \\ & EIE & & EIO \\ \end{array}$ :$\begin{array}{cccc} IAA & & IAI & \\ & IEE & & IEO \\ \end{array} \qquad \begin{array}{cccc} & OAE & & OAO \\ \end{array}$ From [[No Valid Categorical Syllogism with Particular Premise has Universal Conclusion]], all those whose patterns match that condition can be eliminated: :$\begin{array}{cccc} AAA & & AAI & \\ & AEE & & AEO \\ & & AII & \\ & & & AOO \\ \end{array} \qquad \begin{array}{cccc} & EAE & & EAO \\ & & & \\ & & & EIO \\ \end{array}$ :$\begin{array}{cccc} & & IAI & \\ & & & IEO \\ \end{array} \qquad \begin{array}{cccc} & & & OAO \\ \end{array}$ Thus there are $12$ patterns remaining. Each one may apply to any one of the $4$ [[Definition:Figure of Categorical Syllogism|figures]] Thus there are no more than $48$ [[Definition:Valid Argument|valid]] patterns of [[Definition:Categorical Syllogism|categorical syllogism]]. {{qed}}	1
The [[Rule of Implication]] can be symbolised by the [[Definition:Sequent|sequent]]: :$\left({p \vdash q}\right) \vdash p \implies q$	1
Consider the [[Definition:Categorical Statement|categorical statements]]: {{begin-axiom}} {{axiom | q = \mathbf A \left({S, P}\right) | lc= The [[Definition:Universal Affirmative|universal affirmative]]: | ml= \forall x: S \left({x}\right) | mo= \implies | mr= P \left({x}\right) }} {{axiom | q = \mathbf E \left({S, P}\right) | lc= The [[Definition:Universal Negative|universal negative]]: | ml= \forall x: S \left({x}\right) | mo= \implies | mr= \neg P \left({x}\right) }} {{axiom | q = \mathbf I \left({S, P}\right) | lc= The [[Definition:Particular Affirmative|particular affirmative]]: | ml= \exists x: S \left({x}\right) | mo= \land | mr= P \left({x}\right) }} {{axiom | q = \mathbf O \left({S, P}\right) | lc= The [[Definition:Particular Negative|particular negative]]: | ml= \exists x: S \left({x}\right) | mo= \land | mr= \neg P \left({x}\right) }} {{end-axiom}} Then: :$\mathbf A \left({S, P}\right)$ and $\mathbf E \left({S, P}\right)$ are both [[Definition:False|false]] {{iff}}: :$\mathbf I \left({S, P}\right)$ and $\mathbf O \left({S, P}\right)$ are both [[Definition:True|true]].	1
It is to be demonstrated that $d$ satisfies all the [[Definition:Metric Space Axioms|metric space axioms]]. Let $u, v, w \in \map V {n, p}$ be arbitrary. === Proof of $(\text M 1)$ === By definition of [[Definition:Distance between Linear Codewords|distance]]: :$\map d {u, u} = 0$ So [[Definition:Metric Space Axioms|axiom $(\text M 1)$]] holds for $d$. {{qed|lemma}} === Proof of $(\text M 2)$ === Consider $\map d {u, v} + \map d {v, w}$. Let $\map d {u, w} \ne 0$. Then at each [[Definition:Term of Sequence|term]] at which $u$ and $w$ are different, those corresponding terms in either $u$ and $v$ or $v$ and $w$ must be different. So every contribution to the value of $\map d {u, w}$ is present in either $\map d {u, v}$ or $\map d {v, w}$. It follows that $\map d {u, v} + \map d {v, w} \ge \map d {u, w}$. So [[Definition:Metric Space Axioms|axiom $(\text M 2)$]] holds for $d$. {{qed|lemma}} === Proof of $(\text M 3)$ === $\map d {u, v} = \map d {v, u}$ by definition of [[Definition:Distance between Linear Codewords|distance]]. So [[Definition:Metric Space Axioms|axiom $(\text M 3)$]] holds for $d$. {{qed|lemma}} === Proof of $(\text M 4)$ === {{begin-eqn}} {{eqn | l = u | o = \ne | r = v | c = }} {{eqn | ll= \leadsto | l = \map d {u, v} | o = > | r = 0 | c = {{Defof|Distance between Linear Codewords}} }} {{end-eqn}} So [[Definition:Metric Space Axioms|axiom $(\text M 4)$]] holds for $d$. {{qed|lemma}} Thus $d$ satisfies all the [[Definition:Metric Space Axioms|metric space axioms]] and so is a [[Definition:Metric|metric]]. {{qed}}	1
{{ProofWanted|Straightforward but boring exercise in combinatorics}}	1
Let $a_1, a_2, \ldots, a_n, b_1, b_2, \ldots, b_n, c_1, c_2, \ldots, c_n, d_1, d_2, \ldots, d_n$ be [[Definition:Integer|integers]]. Then: : $\displaystyle \exists w, x, y, z \in \Z: \prod_{j \mathop = 1}^n \left({a_j^2 + b_j^2 + c_j^2 + d_j^2}\right) = w^2 + x^2 + y^2 + z^2$ That is, the [[Definition:Integer Multiplication|product]] of any number of [[Definition:Integer Addition|sums]] of four [[Definition:Square Number|squares]] is also a sum of four squares.	1
:$p \oplus \bot \dashv \vdash p$	1
By the definition of a [[Definition:Primitive Recursive Set|primitive recursive set]], it is sufficient to show that the [[Definition:Characteristic Function of Set|characteristic function]] $\chi_{\operatorname{Seq}}$ of $\operatorname{Seq}$ is [[Definition:Primitive Recursive Function|primitive recursive]]. Let $p: \N \to \N$ be the [[Definition:Prime Enumeration Function|prime enumeration function]]. Let $\operatorname{len} \left({n}\right)$ be the [[Definition:Length of Integer|length]] of $n$. We note that $\chi_{\operatorname{Seq}} \left({n}\right) = 1$ [[Definition:Iff|iff]] $p \left({y}\right)$ [[Definition:Divisor of Integer|divides]] $n$ for $1 \le y \le \operatorname{len} \left({n}\right)$. That is, [[Definition:Iff|iff]] $\operatorname{div} \left({n, p \left({y}\right)}\right) = 1$ for $1 \le y \le \operatorname{len} \left({n}\right)$, where $\operatorname{div}$ is the [[Divisor Relation is Primitive Recursive|divisor relation]]. We then see that $\operatorname{div} \left({n, p \left({y}\right)}\right) = 1$ for $1 \le y \le \operatorname{len} \left({n}\right)$ iff their product equals $1$. So we can define $\chi_{\operatorname{Seq}}$ by: :$\displaystyle \chi_{\operatorname{Seq}} \left({n}\right) = \begin{cases} \prod_{y \mathop = 1}^{\operatorname{len} \left({n}\right)} \operatorname{div} \left({n, p \left({y}\right)}\right) & : n > 1 \\ 0 & : \text{otherwise} \end{cases}$ Then we define $g: \N^2 \to \N$ as: :$\displaystyle g \left({n, z}\right) = \begin{cases} 1 & : z = 0 \\ \prod_{y \mathop = 1}^z \operatorname{div} \left({n, p \left({y}\right)}\right) & : z \ne 0 \end{cases}$ We then apply [[Bounded Product is Primitive Recursive]] to the [[Divisor Relation is Primitive Recursive|primitive recursive function]] $\operatorname{div} \left({n, p \left({y}\right)}\right)$, and see that $g$ is [[Divisor Relation is Primitive Recursive|primitive recursive]]. Finally, we have that: :$\chi_{\operatorname{Seq}} \left({n}\right) = \begin{cases} g \left({n, \operatorname{len} \left({n}\right)}\right) & : n > 1 \\ 0 & : \text{otherwise} \end{cases}$ is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from: * the [[Length Function is Primitive Recursive|primitive recursive function $\operatorname{len}$]] * the [[Definition:Primitive Recursive Function|primitive recursive function]] $g$ * the [[Ordering Relations are Primitive Recursive|primitive recursive relation $>$]] * the [[Constant Function is Primitive Recursive|constant $1$]] So $\chi_{\operatorname{Seq}}$ is [[Definition:Primitive Recursive Function|primitive recursive]]. Hence the result. {{qed}} [[Category:Primitive Recursive Functions]] d39jvc3slqqjbbrclhx85h9ewrxkazp	1
Let $H_f$ be a [[Definition:Set|set]] defined as follows: :$H_f = \set {\tuple {\sqbrk M, x}: \text {$M$ accepts $x$ in $\map f {\size x}$ steps} }$ where: :$M$ is a [[Definition:Turing Machine|(deterministic) Turing machine]] :$x$ is its input (the initial contents of its tape) :$\sqbrk M$ denotes an input that encodes the Turing machine $M$ Let $m$ be the size of $\tuple {\sqbrk M, x}$. We know that we can decide membership of $H_f$ by way of a [[Definition:Turing Machine|(deterministic) Turing machine]] that: :$(1): \quad$ calculates $f \left({\size x}\right)$ :$(2): \quad$ writes out a row of $0$s of that length :$(3): \quad$ uses this row of $0$s as a counter to simulate $M$ for at most that many steps. At each step, the simulating [[Definition:Turing Machine|machine]] needs to look through the definition of $M$ to decide what the next action would be. It is safe to say that this takes at most $\map f m^3$ operations, so: :$ H_f \in \map {\mathsf{DTIME} } {\map f m^3}$ {{handwaving|"We know that ...", "It is safe to say ..."}} {{AimForCont}}: :$H_f \in \map {\mathsf{DTIME} } {\map f {\floor {\dfrac m 2} } }$ Then we can construct some [[Definition:Turing Machine|machine]] $K$ which: :given some [[Definition:Turing Machine|machine]] description $\sqbrk {M_K}$ and input $x$ :decides within $\map {\mathsf{DTIME} } {\map f {\floor {\dfrac m 2} } }$ whether $\tuple {\sqbrk {M_K}, x} \in H_f$. Construct another [[Definition:Turing Machine|machine]] $N$ which: :takes a machine description $\sqbrk {M_N}$ :runs $K$ on $\left({ \sqbrk {M_N}, \sqbrk {M_N} }\right)$ :accepts only if $K$ rejects, and rejects if $K$ accepts. Let $m_n$ be the length of $\sqbrk {M_N}$. Then $m$ (the length of the input to $K$) is twice $m_n$ plus some delimiter symbol, so: :$m = 2m_n + 1$ $N$'s running time is thus: {{begin-eqn}} {{eqn | l = \map {\mathsf{DTIME} } {\map f {\floor {\frac m 2} } } | r = \map {\mathsf{DTIME} } {\map f {\floor {\frac {2 m_n + 1} 2} } } | c = }} {{eqn | r = \map {\mathsf{DTIME} } {\map f {m_n} } | c = }} {{end-eqn}} Now consider the case $M_N = N$. That is we feed $\sqbrk N$ as input into $N$ itself). In this case $m_n$ is the length of $\sqbrk N$. * If $N$ '''accepts''' $\sqbrk N$ (which we know it does in at most $\map f {m_n}$ operations): ** By the definition of $N$, $K$ '''rejects''' $\tuple {\sqbrk N, \sqbrk N}$ ** Therefore, by the definition of $K$, $\tuple {\sqbrk N, \sqbrk N} \notin H_f$ ** Therefore, by the definition of $H_f$, $N$ does not accept $\sqbrk N$ in $\map f {m_n}$ steps -- a [[Definition:Contradiction|contradiction]]. * If $N$ '''rejects''' $\sqbrk N$ (which we know it does in at most $\map f {m_n}$ operations): ** By the definition of $N$, $K$ '''accepts''' $\tuple {\sqbrk N, \sqbrk N}$ ** Therefore, by the definition of $K$, $\tuple {\sqbrk N, \sqbrk N} \in H_f$ ** Therefore, by the definition of $H_f$, $N$ '''does''' accept $\sqbrk N$ in $\map f {m_n}$ steps -- a [[Definition:Contradiction|contradiction]]. Therefore, $K$ does not exist. So, by [[Proof by Contradiction]]: :$H_f \notin \map {\mathsf{DTIME} } {\map f {\floor {\dfrac m 2} } }$ Substituting $2 n + 1$ for $m$, we get: :$H_f \notin \map {\mathsf{DTIME} } {\map f n}$ and, from the earlier result: :$H_f \in \map {\mathsf{DTIME} } {\map f {2 n + 1}^3}$ {{qed}} [[Category:Complexity Theory]] [[Category:Computer Science]] [[Category:Named Theorems]] 23hffzr83e7hv17hpn8s4dsqf0rrlhl	1
Let $D$ be a [[Definition:Minimal (Model Theory)|strongly minimal]] set in $\mathcal M$. Let $A$ be a [[Definition:Subset|subset]] of $D$. Let $b, c \in D$. If $b$ is [[Definition:Algebraic (Model Theory)|algebraic]] over $A \cup \left\{ {c}\right\}$ but not over $A$, then $c$ is [[Definition:Algebraic (Model Theory)|algebraic]] over $A \cup \left\{ {b}\right\}$.	1
{{ProofWanted}} [[Category:Formal Systems]] [[Category:Propositional Logic]] 9t09z7qppb0chm01ypqc1qfkngt4pzz	1
Let $X = \mathbb C$. There are two cases to consider: either $n$ is [[Definition:Non-Negative Integer|not negative]], or it is [[Definition:Negative Integer|negative]]. Since the [[Natural Numbers are Non-Negative Integers]], the case where $n \ge 0$ will be proved using [[Principle of Mathematical Induction|induction]]. === Case 1 === ==== Basis for the Induction ==== The case for which $n = 0$ is trivial, because: :$x + 0 \cdot L = x$ ==== Induction Hypothesis ==== For some $n \in \Z_{\ge 0}$, suppose that: :$\map f x = \map f {x + n L}$ ==== Induction Step ==== For the [[Definition:Induction Step|induction step]], let $n \to n + 1$. Then: {{begin-eqn}} {{eqn | l = \map f {x + \paren {n + 1} L} | r = \map f {x + \paren {L + n L} } }} {{eqn | r = \map f {\paren {x + L} + n L} | c = [[Complex Addition is Associative]] }} {{eqn | r = \map f {x + L} | c = [[General Periodicity Property#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \map f x | c = [[General Periodicity Property#Basis for the Induction|Basis for the Induction]] }} {{end-eqn}} === Case 2 === If $n < 0$, then: {{begin-eqn}} {{eqn | l = \map f {x + n L} | r = \map f {\paren {x + n L} - n L} | c = [[Negative of Negative Number is Positive/Integer|Negative of Negative Number is Positive]] and '''Case 1''' }} {{eqn | r = \map f {x + \paren {n L - n L} } | c = [[Complex Addition is Associative]] }} {{eqn | r = \map f x }} {{end-eqn}} Combining the results above, it is seen that for all $n \in \Z$: :$\map f x = \map f {x + n L}$ The proof for when $X = \R$ is nearly identical to the above proof. {{qed}} [[Category:Periodic Functions]] [[Category:Proofs by Induction]] o64awygd6l6v02r6a726zr6opspieft	1
We prove the contrapositive. Suppose both $\pi \cup \{\phi\}$ and $\pi \cup \{\neg\phi\}$ fork over $A$. By definition of forking, :$\pi\cup\{\phi\}$ implies $\phi_1 (\bar x, \bar c_1) \vee \cdots \vee \phi_k (\bar x, \bar c_k)$ and :$\pi\cup\{\neg\phi\}$ implies $\psi_1 (\bar x, \bar d_1) \vee \cdots \vee \psi_k (\bar x, \bar d_h)$, where each $\phi_i$ and $\psi_j$ [[Definition:Divide (Model Theory)|divide]] over $A$. Then $\pi$ implies the disjunction :$\bigvee_i \phi(\bar x, \bar c_i) \vee \bigvee_j \psi(\bar x, \bar d_i)$ with each component formula dividing over $A$. By definition, this means that $\pi$ forks over $A$. {{qed}} [[Category:Model Theory]] fuwj2wm9i715zb7ksuzsg8h7w6n2czx	1
The [[Definition:Eluding Game|eluding game]] has no [[Definition:Saddle Point (Game Theory)|saddle point]].	1
:$p \lor \paren {q \land r} \dashv \vdash \paren {p \lor q} \land \paren {p \lor r}$	1
{{BeginTableau|\vdash \neg \left ({p \iff q}\right) \iff \left({p \iff \neg q}\right)}} {{Assumption|1|\neg \left ({p \iff q}\right)}} {{SequentIntro|2|1|p \iff \neg q|1|[[Non-Equivalence as Equivalence with Negation/Formulation 1|Non-Equivalence as Equivalence with Negation: Formulation 1]]}} {{Implication|3||\left({\neg \left ({p \iff q}\right)}\right) \implies \left({p \iff \neg q}\right)|1|2}} {{Assumption|4|p \iff \neg q}} {{SequentIntro|5|4|\neg \left ({p \iff q}\right)|4|[[Non-Equivalence as Equivalence with Negation/Formulation 1|Non-Equivalence as Equivalence with Negation: Formulation 1]]}} {{Implication|6||\left({p \iff \neg q}\right) \implies \left({\neg \left ({p \iff q}\right)}\right)|4|5}} {{BiconditionalIntro|7||\left({\neg \left ({p \iff q}\right)}\right) \iff \left({p \iff \neg q}\right)|3|6}} {{EndTableau}} {{qed}}	1
A [[Definition:Statement|statement]] has a [[Definition:Truth Value|truth value]] of '''false''' {{iff}} what it says does not match the way that things are.	1
{{begin-eqn}} {{eqn | l = p \implies q | o = \dashv \vdash | r = \neg \paren {p \land \neg q} | c = [[Implication Equivalent to Negation of Conjunction with Negative]] }} {{eqn | o = \dashv \vdash | r = p \uparrow \neg q | c = Definition of [[Definition:Logical NAND|NAND]] }} {{eqn | o = \dashv \vdash | r = p \uparrow \paren {q \uparrow q} | c = [[NAND with Equal Arguments]] }} {{end-eqn}} {{qed}}	1
Define $0$ as the [[Non-Successor Element of Peano Structure is Unique|only]] element in the set $P \setminus s \left({P}\right)$, where: :$P$ is the [[Definition:Peano Structure|Peano Structure]] :$s \left({P}\right)$ is the [[Definition:Image of Mapping|image of the mapping]] $s$ defined in [[Definition:Peano Structure|Peano structure]] : $\setminus$ denotes the [[Definition:Set Difference|set difference]]. The theorem to be proven is: :$1 + 1 = 2$ where: :$1 := s \left({0}\right)$ :$2 := s \left({1}\right) = s \left({s \left({0}\right)}\right)$ :$+$ denotes [[Definition:Addition/Peano Structure|addition]] :$=$ denotes [[Definition:Equals|equality]] :$s \left({n}\right)$ denotes [[Definition:Successor Mapping|the successor function as defined by Peano]]	1
Since $\bot$ is the [[Definition:Identity Element|identity]] for $\vee$, the first condition for $\neg \bot$: :$\bot \vee \neg \bot = \top$ implies that $\neg \bot = \top$ is the only possibility. Since $\top$ is the [[Definition:Identity Element|identity]] for $\wedge$, it follows that: :$\bot \wedge \top = \bot$ and we conclude that: :$\neg \bot = \top$ as desired. {{qed}}	1
: $p \land q \dashv \vdash \neg \left({\neg p \lor \neg q}\right)$	1
{{BeginTableau|\top \implies p \vdash p}} {{Premise|1|\top \implies p}} {{TopIntro|2}} {{ModusPonens|3|1|p|1|2}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|p \vdash \top \implies p}} {{Premise|1|p}} {{Assumption|2|\top}} {{Implication|3|1|\top \implies p|2|1}} {{EndTableau}} {{qed}}	1
Let $T$ be a [[Definition:Finite Propositional Tableau|finite propositional tableau]]. Let its [[Definition:Hypothesis Set|hypothesis set]] $\mathbf H$ be [[Definition:Finite Set|finite]]. {{:Tableau Extension Lemma/General Statement}}	1
By the [[Definition:Definitional Abbreviation|definitional abbreviation]] for the [[Definition:Conditional|conditional]]: :$\mathbf A \implies \mathbf B =_{\text{def}} \neg \mathbf A \lor \mathbf B$ the [[Rule of Idempotence/Disjunction/Formulation 2/Reverse Implication|Rule of Idempotence]] can be written as: : $\neg \left({p \lor p}\right) \lor p$ This evaluates as follows: :$\begin{array}{|cccc|c|c|} \hline \neg & (p & \lor & p) & \lor & p \\ \hline 2 & 2 & 1 & 1 & 2 & 1 \\ 1 & 2 & 2 & 2 & 2 & 2 \\ \hline \end{array}$ {{qed}} [[Category:Formal Semantics]] r07evkbzlhssv5d3yrb3yass8oq8v9l	1
The [[Definition:Set|set]] $\Bbb I$ of all [[Definition:Unlimited Register Machine|basic URM instructions]] is [[Definition:Countable|countably infinite]].	1
{{BeginTableau|\neg \paren {\paren {p \uparrow q} \uparrow r \implies p \uparrow \paren {q \uparrow r} } }} {{Assumption|1|\paren {p \uparrow q} \uparrow r \implies p \uparrow \paren {q \uparrow r} }} {{Assumption|2|p \land \neg r}} {{Simplification|3|2|p|2|1}} {{Simplification|4|2|\neg r|2|2}} {{Addition|5|2|\paren {\neg q} \lor \paren {\neg r}|4|2}} {{DeMorgan|6|2|\neg \paren {q \land r}|5|Disjunction of Negations}} {{SequentIntro|7|2|q \uparrow r|6 |Definition of [[Definition:Logical NAND|Logical NAND]]}} {{Conjunction|8|2|p \land \paren {q \uparrow r}|3|7}} {{DoubleNegIntro|9|2|\neg \neg \paren {p \land \paren {q \uparrow r} }|8}} {{SequentIntro|10|2|\neg \paren {p \uparrow \paren {q \uparrow r} }|9 |Definition of [[Definition:Logical NAND|Logical NAND]]}} {{Addition|11|2|\paren {\neg \paren {p \uparrow q} } \lor \paren {\neg r}|4|2}} {{DeMorgan|12|2|\neg \paren {\paren {p \uparrow q} \land r}|11|Disjunction of Negations}} {{SequentIntro|13|2|\paren {p \uparrow q} \uparrow r|12 |Definition of [[Definition:Logical NAND|Logical NAND]]}} {{DoubleNegIntro|14|2|\neg \neg \paren {\paren {p \uparrow q} \uparrow r}|13}} {{Conjunction|15|2|\neg \neg \paren {\paren {p \uparrow q} \uparrow r} \land \neg \paren {p \uparrow \paren {q \uparrow r} }|13|10}} {{DeMorgan|16|2|\neg \paren {\neg \paren {\paren {p \uparrow q} \uparrow r} \lor \paren {p \uparrow \paren {q \uparrow r} } }|15|Conjunction of Negations}} {{SequentIntro|17|2 |\neg \paren {\paren {p \uparrow q} \uparrow r \implies p \uparrow \paren {q \uparrow r} } |16 |[[Disjunction and Implication]] }} {{NonContradiction|18|1, 2|1|17}} {{EndTableau}} Taking $p = \top$, $r = \bot$, we find $\vdash p \land \neg r$, and conclude our initial assumption was false. {{qed}}	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, in each case, the [[Definition:Truth Value|truth values]] in the appropriate columns match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c|ccc||c|} \hline p & \bot & \implies & p & \top \\ \hline F & F & T & F & T \\ T & F & T & T & T \\ \hline \end{array}$ {{qed}}	1
'''Modal logic''' is a branch of [[Definition:Logic|logic]] in which [[Definition:Truth Value|truth values]] are more complex than being merely [[Definition:True|true]] or [[Definition:False|false]], and which distinguishes between different "modes" of truth.	1
Let $C$ be a [[Definition:Linear Code|linear code]] whose [[Definition:Master Code|master code]] is $V$. Let $c \in C$ be a [[Definition:Transmitted Codeword|transmitted codeword]]. Let $v$ be the [[Definition:Received Word|received word]] from $c$. By definition, $v$ is an [[Definition:Element|element]] of $V$. Let $v$ have a [[Definition:Distance between Linear Codewords|distance]] $e$ from $c$, where $2 e + 1 \le d$. Thus there have been $e$ [[Definition:Transmission Error|transmission errors]]. {{AimForCont}} $c_1$ is a [[Definition:Codeword of Linear Code|codeword]] of $C$, [[Definition:Distinct Objects|distinct]] from $c$, such that $\map d {v, c_1} \le e$. Then: {{begin-eqn}} {{eqn | l = \map d {c, c_1} | o = \le | r = \map d {c, v} + \map d {v, c_1} | c = }} {{eqn | o = \le | r = e + e | c = }} {{eqn | o = < | r = d | c = }} {{end-eqn}} So $c_1$ has a [[Definition:Distance between Linear Codewords|distance]] from $c$ less than $d$. But $C$ has a [[Definition:Minimum Distance of Linear Code|minimum distance]] $d$. Thus $c_1$ cannot be a [[Definition:Codeword of Linear Code|codeword]] of $C$. From this [[Proof by Contradiction|contradiction]] it follows that there is no [[Definition:Codeword of Linear Code|codeword]] of $C$ closer to $v$ than $c$. Hence there is a [[Definition:Unique|unique]] [[Definition:Codeword of Linear Code|codeword]] of $C$ which has the smallest [[Definition:Distance between Linear Codewords|distance]] from $v$. Hence it can be understood that $C$ has corrected the [[Definition:Transmission Error|transmission errors]] of $v$. {{Qed}}	1
: $\vdash p \iff p$	1
{{BeginTableau|\neg (p \lor \neg p) \vdash \bot}} {{Assumption|1|\neg (p \lor \neg p)}} {{SequentIntro|2|1|\neg p \land \neg \neg p|1|[[De Morgan's Laws (Logic)/Conjunction of Negations/Formulation 1/Reverse Implication|De Morgan's Laws]]}} {{Simplification|3|1|\neg p|2|1}} {{Simplification|4|1|\neg\neg p|2|2}} {{NonContradiction|5|1|3|4}} {{EndTableau}} {{qed}}	1
We apply the [[Method of Truth Tables]]: :$\begin{array}{|ccccc||ccccc|} \hline p & \uparrow & (q & \uparrow & r) & (p & \uparrow & q) & \uparrow & r \\ \hline F & T & F & T & F & F & T & F & T & F \\ F & T & F & T & T & F & T & F & F & T \\ F & T & T & T & F & F & T & T & T & F \\ F & T & T & F & T & F & T & T & F & T \\ T & F & F & T & F & T & T & F & T & F \\ T & F & F & T & T & T & T & F & F & T \\ T & F & T & T & F & T & F & T & T & F \\ T & T & T & F & T & T & F & T & T & T \\ \hline \end{array}$ As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] do not match for all [[Definition:Boolean Interpretation|boolean interpretations]]. {{qed}}	1
Let $\mathcal M, \mathcal N$ be [[Definition:Structure|$\mathcal L$-structures]] such that $\mathcal M$ is a [[Definition:Substructure|substructure]] of $\mathcal N$. {{wtd|The page [[Definition:Structure]] is a disambiguation page, in which the form in which it is used here may not be included. The level of clarity in this page generally needs improving. Hence the invocation of the Disambiguate template.}} {{Disambiguate|Definition:Structure}} Then $\mathcal M$ is an [[Definition:Elementary Substructure|elementary substructure]] of $\mathcal N$ {{iff}}: :for every [[Definition:Logical Formula|$\mathcal L$-formula]] $\phi \left({x, \bar v}\right)$ and for every $\bar a$ in $\mathcal M$: ::if there exists an $n$ in $\mathcal N$ such that $\mathcal N \models \phi \left({n, \bar a}\right)$ ::then there exists an $m$ in $\mathcal M$ such that $\mathcal N \models \phi \left({m, \bar a}\right)$. {{wtd|Before sense can be made of this page, [[Definition:Substructure]] and [[Definition:Elementary Substructure]] need to be written.}} {{Disambiguate|Definition:Logical Formula}} The condition on the right side of the {{iff}} statement above can be rephrased as: :Every existential statement with parameters from $\mathcal M$ which is satisfied in $\mathcal N$ can be witnessed by an element from the substructure $\mathcal M$.	1
From [[Universal Affirmative implies Particular Affirmative iff First Predicate is not Vacuous]]: :$\exists x: \map S x \iff \paren {\paren {\forall x: \map S x \implies \map P x} \implies \paren {\exists x: \map S x \land \map P x} }$ From [[Law of Simple Conversion of I]]: :$\paren {\exists x: \map S x \land \map P x} \implies \paren {\exists x: \map P x \land \map S x}$ Hence the result. {{qed}}	1
{{BeginTableau|\neg\neg (p \lor \neg p)}} {{Assumption|1|\neg (p \lor \neg p)}} {{SequentIntro|2|1|\bot|1|[[Negation of Excluded Middle is False/Form 1|Negation of Excluded Middle is False: Form 1]]}} {{Implication|3||\neg (p \lor \neg p) \implies \bot|1|2}} {{SequentIntro|4||\neg \neg (p \lor \neg p)|3|[[Negation as Implication of Bottom]]}} {{EndTableau}} {{qed}} [[Category:Propositional Logic]] 9inhesbm7f2swudqcr1zrzyh8j4zygg	1
:$\neg p \iff \neg q \vdash p \iff q$	1
: $\neg \left ({p \iff q}\right) \dashv \vdash \left({\neg p \land q}\right) \lor \left({p \land \neg q}\right)$	1
: $\vdash p \implies p$	1
The only [[Definition:Binary Logical Connective|binary logical connectives]] that form [[Definition:Singleton|singleton sets]] which are [[Definition:Functionally Complete|functionally complete]] are [[Definition:Logical NAND|NAND]] and [[Definition:Logical NOR|NOR]].	1
Let us use the following abbreviations {{begin-eqn}} {{eqn | l = \phi | o = \text{ for } | r = p \implies q }} {{eqn | l = \psi | o = \text{ for } | r = q \implies r }} {{eqn | l = \chi | o = \text{ for } | r = p \implies r }} {{end-eqn}} {{BeginTableau|\left({p \implies q}\right) \implies \left({\left({q \implies r}\right) \implies \left({p \implies r}\right)}\right)}} {{TheoremIntro|1|\left({\phi \land \psi}\right) \implies \chi|[[Hypothetical Syllogism/Formulation 3|Hypothetical Syllogism: Formulation 3]]}} {{SequentIntro|2||\phi \implies \left({\psi \implies \chi}\right)|1|[[Rule of Exportation]]}} {{EndTableau}} Expanding the abbreviations leads us back to: : $\vdash \left({p \implies q}\right) \implies \left({\left({q \implies r}\right) \implies \left({p \implies r}\right)}\right)$ {{qed}}	1
From [[Functionally Complete Logical Connectives/Negation and Conjunction|Functionally Complete Logical Connectives: Negation and Conjunction]], any boolean expression can be expressed in terms of $\land$ and $\neg$. From [[NAND with Equal Arguments]]: :$\neg p \dashv \vdash p \uparrow p$ From [[Conjunction in terms of NAND]]: :$p \land q \dashv \vdash \paren {p \uparrow q} \uparrow \paren {p \uparrow q}$ demonstrating that $p \land q$ is expressed solely in terms of $\uparrow$. Thus any boolean expression can be represented solely in terms of $\uparrow$. That is, $\set {\uparrow}$ is [[Definition:Functionally Complete|functionally complete]]. {{qed}}	1
{{BeginTableau |\neg p \lor q \vdash p \implies q}} {{Premise |1|\neg p \lor q}} {{DeMorgan |2|1|\neg \paren {\neg \neg p \land \neg q}|1|Disjunction}} {{SequentIntro |3|1 |\neg \neg p \implies q |2 |[[Implication Equivalent to Negation of Conjunction with Negative/Formulation 1/Forward Implication|Implication Equivalent to Negation of Conjunction with Negative: $\neg \paren {p \land \neg q} \vdash p \implies q$]] }} {{Assumption |4|p}} {{DoubleNegIntro |5|4|\neg \neg p|4}} {{ModusPonens |6|1, 4|q|3|5}} {{Implication |7|1|p \implies q|4|6}} {{EndTableau}} {{qed}}	1
For all $n \in \N_{> 0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\displaystyle \sum_{j \mathop = 0}^{n - 1} x^j = \frac {x^n - 1} {x - 1}$ === Basis for the Induction === $\map P 1$ is the case: {{begin-eqn}} {{eqn | l = \dfrac {x^1 - 1} {x - 1} | r = 1 | c = }} {{eqn | r = 2^0 | c = }} {{eqn | r = \sum_{j \mathop = 0}^{1 - 1} x^j | c = }} {{end-eqn}} so $\map P 1$ holds. This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\displaystyle \sum_{j \mathop = 0}^{k - 1} x^j = \frac {x^k - 1} {x - 1}$ Then we need to show: :$\displaystyle \sum_{j \mathop = 0}^k x^j = \frac {x^{k + 1} - 1} {x - 1}$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \sum_{j \mathop = 0}^k x^j | r = \sum_{j \mathop = 0}^{k - 1} x^j + x^k | c = }} {{eqn | r = \frac {x^k - 1} {x - 1} + x^k | c = }} {{eqn | r = \frac {x^k - 1 + \paren {x - 1} x^k} {x - 1} | c = }} {{eqn | r = \frac {x^k - 1 + x^{k + 1} - x^k} {x - 1} | c = }} {{eqn | r = \frac {x^{k + 1} - 1} {x - 1} | c = }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\displaystyle \forall n \in \N_{> 0}: \sum_{j \mathop = 0}^{n - 1} x^j = \frac {x^n - 1} {x - 1}$ {{qed}}	1
:$\exists x: P \left({x}\right), P \left({\mathbf a}\right) \implies y \vdash y$ Suppose we have the following: : From our [[Definition:Universe of Discourse|universe of discourse]], ''any'' arbitrarily selected [[Definition:Object|object]] $\mathbf a$ which has the [[Definition:Property|property]] $P$ implies a conclusion $y$ : $\mathbf a$ is not [[Definition:Free Variable|free]] in $y$ : It is known that there ''does'' actually exists an object that has $P$. Then we may infer $y$. This is called the '''Rule of Existential Instantiation''' and often appears in a proof with its abbreviation '''EI'''. When using this rule of existential instantiation: :$\exists x: P \left({x}\right), P \left({\mathbf a}\right) \implies y \vdash y$ the instance of $P \left({\mathbf a}\right)$ is referred to as the '''typical disjunct'''.	1
For ease of analysis, let us assume that: * Each of $P$ and $Q$ have already had the appropriate [[Clear Registers Program]] $Z \left({2, \rho \left({P}\right)}\right)$ and $Z \left({2, \rho \left({Q}\right)}\right)$ appended to them; * Each of $P$ and $Q$ have already had the appropriate amendments made to their [[Definition:Unlimited Register Machine#Termination|exit jumps]] so as to lead to the first line of the appropriate [[Clear Registers Program]]. (Note that if the latter is a [[Definition:Unlimited Register Machine#Null Program|null URM program]], this will be the line immediately following the end of the program). Thus we can discuss $P$ and $Q$ without reference to these technical details. When [[Composition of One-Variable URM Computable Functions#Concatenation of two URM Programs|concatenating programs]], the only amendments made to the programs themselves are to the contents of the <tt>Jump</tt>. So it is clear that the number, type and order of the [[Definition:Unlimited Register Machine#Basic Instructions|basic instructions]] of both programs are the same. All we have to consider are the amendments to the <tt>Jump</tt>s. Suppose the [[Definition:Unlimited Register Machine#Length of Program|lengths]] of $P$ and $Q$ are as follows: * $\lambda \left({P}\right) = t$; * $\lambda \left({Q}\right) = s$. First we look at the <tt>Jump</tt>s of $R$. When we form $\left({Q * R}\right)$, every <tt>Jump</tt> of $R$ of the form $J \left({m, n, q}\right)$ is replaced by $J \left({m, n, q + s}\right)$. Then when forming $P * \left({Q * R}\right)$ the <tt>Jump</tt> $J \left({m, n, q + s}\right)$ is replaced by $J \left({m, n, q + s + t}\right)$. On the other hand, when we form $\left({P * Q}\right) * R$, every <tt>Jump</tt> of $R$ of the form $J \left({m, n, q}\right)$ is replaced directly by $J \left({m, n, q + \left({s + t}\right)}\right)$. Thus the <tt>Jump</tt>s of $R$ have been replaced by the same instructions in each of $\left({P * Q}\right) * R$ and $P * \left({Q * R}\right)$. Now we look at the <tt>Jump</tt>s of $Q$. When forming $\left({Q * R}\right)$, we have already ensured that every <tt>Jump</tt> of $Q$ of the form $J \left({m, n, q}\right)$ where $q > s$ has been replaced by $J \left({m, n, s + 1}\right)$. So when forming $P * \left({Q * R}\right)$ the <tt>Jump</tt> $J \left({m, n, s + 1}\right)$ is replaced by $J \left({m, n, s + t + 1}\right)$. On the other hand, when forming $\left({P * Q}\right)$, every <tt>Jump</tt> of $Q$ of the form $J \left({m, n, q}\right)$ is replaced by $J \left({m, n, q + t}\right)$. We have that $\left({P * Q}\right)$ has $s + t$ instructions. When $q > s$, we take account of the fact that $q + t > s + t$. So in $\left({P * Q}\right) * R$, <tt>Jump</tt>s of the form $J \left({m, n, s + 1}\right)$ are replaced by $J \left({m, n, s + t + 1}\right)$. This agrees with the corresponding <tt>Jump</tt>s in $P * \left({Q * R}\right)$. Similarly, we can show that all other <tt>Jump</tt>s of $Q$, and all <tt>Jump</tt>s of $P$, are amended in exactly the same way in each of $\left({P * Q}\right) * R$ and $P * \left({Q * R}\right)$. Hence the result. {{qed}} [[Category:URM Programs]] 1pn5stq6phjehkuuq9jwon8qf6t8qeh	1
Each [[Definition:Unlimited Register Machine|basic URM instruction]] is of one of the following forms: {| border="1" |- | <tt>Zero</tt> | $Z \left({n}\right)$ |- | <tt>Successor</tt> | $S \left({n}\right)$ |- | <tt>Copy</tt> | $C \left({m, n}\right)$ |- | <tt>Jump</tt> | $J \left({m, n, q}\right)$ |} Let $\Bbb I$ be the [[Definition:Set|set]] of all [[Definition:Unlimited Register Machine|basic URM instructions]]. We define the mapping $\beta: \Bbb I \to \N$ as follows: * $\beta \left({Z \left({n}\right)}\right) = 6 n - 3$ * $\beta \left({S \left({n}\right)}\right) = 6 n$ * $\beta \left({C \left({m, n}\right)}\right) = 2^m 3^n + 1$ * $\beta \left({J \left({m, n, q}\right)}\right) = 2^m 3^n 5^q + 2$ We note that: * $\beta \left({Z \left({n}\right)}\right) \equiv 3 \pmod 6$ * $\beta \left({S \left({n}\right)}\right) \equiv 0 \pmod 6$ * $\beta \left({C \left({m, n}\right)}\right) \equiv 1 \pmod 3$ * $\beta \left({J \left({m, n, q}\right)}\right) \equiv 2 \pmod 3$ So, if $\beta \left({I_1}\right) = \beta \left({I_2}\right)$, then both instructions must be of the same type. Hence it follows from the [[Fundamental Theorem of Arithmetic]] that $\beta$ is uniquely specified for any given [[Definition:Unlimited Register Machine|basic URM instruction]]. Thus $\beta$ is an [[Definition:Injection|injection]]. {{qed}}	1
Consider $p \ne m$. Then $\mathbf {AB}$ is defined, but $\mathbf {BA}$ is not. So: :$p \ne m \implies \mathbf {AB} \ne \mathbf {BA}$ Now consider $p = m$, and $m \ne n$. Then $\mathbf {A B}$ is an $m \times m$ matrix, while $\mathbf {BA}$ is an $n \times n$ matrix. $p \ne m \implies \mathbf {AB} \ne \mathbf {BA}$ regardless of whether $m = n$ is true or not. Hence: :$p \ne m \lor m \ne n \implies \mathbf {AB} \ne \mathbf {BA}$ Now consider $p = m$, $m = n$, and $n \ne 1$. It remains to be proved that: :$\mathbf {AB} \ne \mathbf {BA}$ This is demonstrated in [[Matrix Multiplication is not Commutative]]. Hence we have that $p \ne m \lor m \ne n \implies \mathbf {AB} \ne \mathbf {BA}$ regardless of whether $n = 1$ is true or not, so it is easily seen that: :$p \ne m \lor m \ne n \lor n \ne 1 \implies \exists \mathbf A \in \MM_{m \times n}, \mathbf B \in \MM_{n \times p}: \mathbf {AB} \ne \mathbf {BA} \dashv \vdash \\ \left(\forall \mathbf A \in \MM_{m \times n}, \mathbf B \in \MM_{n \times p}: \mathbf {AB} = \mathbf {BA}\right) \implies \lnot \left({p \ne m \lor m \ne n \lor n \ne 1}\right)$ by [[Rule of Transposition]]. The [[Definition:Existential Quantifier|existential quantifier]] is needed here because there exist [[Definition:Square Matrix|square matrices]] that commute under [[Definition:Matrix Product (Conventional)|matrix multiplication]], for example the [[Definition:Unit Matrix|unit matrix]]. :$\lnot \left({p \ne m \lor m \ne n \lor n \ne 1}\right) \dashv \vdash p = m \land m = n \land n = 1$ by a generalization of [[De Morgan's Laws (Logic)|De Morgan's Law]]. Finally, by the properties of an [[Definition:Equivalence Relation|equivalence relation]]: :$(1): \quad \paren {\forall \mathbf A \in \MM_{m \times n}, \mathbf B \in \MM_{n \times p}: \mathbf {AB} = \mathbf {BA} } \implies p = m = n = 1$ Now to prove the converse: Let $\mathbf A \in \MM_{m \times n}$, $\mathbf B \in \MM_{n \times p}$, and suppose that $p = m = n = 1$, then because $R$ is a [[Definition:Commutative Ring|commutative ring]]: :$\mathbf {AB} = A_{11} B_{11} = B_{11} A_{11} = \mathbf {BA}$ and so: :$(2): \quad p = m = n = 1 \implies \paren {\forall \mathbf A \in \MM_{m \times n}, \mathbf B \in \MM_{n \times p}: \mathbf {AB} = \mathbf {BA} }$ Combining $(1)$ and $(2)$ yields the result. {{qed}} [[Category:Conventional Matrix Multiplication]] [[Category:Commutativity]] [[Category:Proofs by Induction]] 55e8727xfy0op1ydlh1pgqwl9tzoc1f	1
{{BeginTableau|p \implies q, q \implies r, p \vdash r}} {{Premise|1|p \implies q}} {{Premise|2|q \implies r}} {{Premise|3|p}} {{ModusPonens|4|1, 3|q|1|3}} {{ModusPonens|5|1, 2, 3|r|2|4}} {{EndTableau}} {{qed}}	1
It can easily be seen that $S_k$ is a [[Definition:Total Function|total function]]. Suppose $e = \gamma \left({P}\right)$ for some [[Definition:URM Program|URM program]] $P$. At stage $0$, we are about to carry out [[Definition:Unlimited Register Machine#Basic Instructions|instruction]] $1$ with the [[Definition:Unlimited Register Machine#Input|input]] $\left({n_1, n_2, \ldots, n_k}\right)$. So we have: :$S_k \left({e, n_1, n_2, \ldots, n_k, 0}\right) = \begin{cases} 2^1 3^{n_1} 5^{n_2} \cdots p_{k+1}^{n_k} & : e \in \operatorname{Prog} \\ 0 & : \text{otherwise} \end{cases}$ where $\operatorname{Prog}$ is the set of code numbers of all [[Definition:URM Program|URM programs]]. We see that $S_k \left({e, n_1, n_2, \ldots, n_k, 0}\right)$ does not actually depend upon the actual program being run, beyond the fact that it matters whether it actually ''is'' a program or not. Now [[Set of Codes for URM Programs is Primitive Recursive|$\operatorname{Prog}$ is a primitive recursive set]]. So from [[:Category:Primitive Recursive Functions|results about primitive recursive functions]], the relations defining the cases are primitive recursive. We can also deduce from various [[:Category:Primitive Recursive Functions|results about primitive recursive functions]] that the functions given by the formulas $2^1 3^{n_1} 5^{n_2} \cdots p_{k+1}^{n_k}$ and $0$ are [[Definition:Primitive Recursive Function|primitive recursive]]. In particular, we use the results: * [[Multiplication is Primitive Recursive]]; * [[Exponentiation is Primitive Recursive]]; * [[Prime Enumeration Function is Primitive Recursive]]. So from [[Definition by Cases is Primitive Recursive]], $S_k \left({e, n_1, n_2, \ldots, n_k, 0}\right)$ is [[Definition:Primitive Recursive Function|primitive recursive]]. Now we want to be able to express $S_k \left({e, n_1, n_2, \ldots, n_k, t+1}\right)$ in terms of $e, \left({n_1, n_2, \ldots, n_k}\right), t$ and $S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)$ using known [[Definition:Primitive Recursive Function|primitive recursive functions]]. We need to consider a number of cases: #$e$ does not code a URM program; #$e = \gamma \left({P}\right)$ and the computation halts at stage $t$ or earlier; #$e = \gamma \left({P}\right)$ and the instruction to be carried out at stage $t$ is a <tt>Zero</tt> instruction; #$e = \gamma \left({P}\right)$ and the instruction to be carried out at stage $t$ is a <tt>Successor</tt> instruction; #$e = \gamma \left({P}\right)$ and the instruction to be carried out at stage $t$ is a <tt>Copy</tt> instruction; #$e = \gamma \left({P}\right)$ and the instruction to be carried out at stage $t$ is a <tt>Jump</tt> instruction. These cases are clearly mutually exclusive and exhaustive. First we need to check that each case corresponds to a [[Definition:Primitive Recursive Relation|primitive recursive relation]]. * The set $\operatorname{Prog}$ is primitive recursive so its [[Complement of Primitive Recursive Set|complement is also primitive recursive]]. So 1. is a [[Definition:Primitive Recursive Relation|primitive recursive relation]]. * So we have that $e$ codes a URM program. Call that program $P$. From the definition of [[Unique Code for State of URM Program|state code]], we see that if a computation halts at stage $t$ or earlier, then the number of the instruction to be carried out at stage $t$ is greater than the number of instructions in $P$. From the definition of the [[Unique Code for URM Program|code number]] of $P$, the number of instructions in $P$ is $\operatorname{len} \left({e}\right)$ where $\operatorname{len} \left({e}\right)$ is the [[Definition:Length of an Integer|length of $e$]], which is [[Length Function is Primitive Recursive|primitive recursive]]. Now let $r = S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)$. Let $\left({r}\right)_j$ be defined as the [[Definition:Prime Exponent Function|prime exponent function]]. By the definition of the [[Unique Code for State of URM Program|state code]], the number of the instruction to be carried out at stage $t$ is $\left({r}\right)_1$, which is [[Prime Exponent Function is Primitive Recursive|primitive recursive]]. So 2. can be expressed as: :$e \in \operatorname{Prog} \text { and } \left({S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)}\right)_1 > \operatorname{len} \left({e}\right)$ Both $\operatorname{Prog}$ and $\left({r}\right)_1$ are primitive recursive, so from [[Set Operations on Primitive Recursive Relations]], 2. is a [[Definition:Primitive Recursive Relation|primitive recursive relation]]. * So, let the number of the instruction to be carried out at stage $t$ be $a = \left({S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)}\right)_1$. From the definition of the [[Unique Code for URM Program|code number]] of $P$, the [[Unique Code for URM Instruction|code number of this instruction]] is $\left({e}\right)_a$. Now from [[Set of Codes for URM Instructions is Primitive Recursive]], each of the sets $\operatorname{Zinstr}$, $\operatorname{Sinstr}$, $\operatorname{Cinstr}$ and $\operatorname{Jinstr}$ are [[Definition:Primitive Recursive Set|primitive recursive]]. So each of 3. to 6. above can be expressed as: :$e \in \operatorname{Prog} \text { and } a \le \operatorname{len} \left({e}\right) \text { and } \left({e}\right)_a \in \operatorname{Instr}$ and is a [[Definition:Primitive Recursive Relation|primitive recursive relation]]. So relations 1. to 6. are all [[Definition:Primitive Recursive Relation|primitive recursive]]. Now we need to show how, in each case, $S_k \left({e, n_1, n_2, \ldots, n_k, t+1}\right)$ can be obtained from $e, \left({n_1, n_2, \ldots, n_k}\right), t$ and $S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)$ using known [[Definition:Primitive Recursive Function|primitive recursive functions]]. First, if $e$ does not code a URM program then $S_k \left({e, n_1, n_2, \ldots, n_k, t+1}\right) = 0$, which is primitive recursive. Second, we have adopted the convention that if $P$ has halted, then $S_k$ does not change. So if $P$ halts at or before stage $t$, we have that $S_k \left({e, n_1, n_2, \ldots, n_k, t+1}\right) = S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)$ Next, we look at the individual commands. As an example we will investigate the <tt>Successor</tt> command. The others are treated similarly. Suppose the instruction to be carried out at stage $t$ is a <tt>Successor</tt> command. We know that the [[Unique Code for URM Instruction|code number]] $c$ is given by $c = \left({e}\right)_a$ where $a = \left({S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)}\right)_1$. Suppose the instruction is $S \left({n}\right)$. Then $c = 6 n$. So $n = \operatorname{quot} \left({6, n}\right)$ which is recursive from [[Quotient is Primitive Recursive]]. This instruction adds $1$ to the number in $R_n$. This increases the exponent $p_{n+1}$ in the state code by $1$. This is achieved by multiplying $S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)$ by $p \left({n+1}\right)$, where $p \left({n+1}\right)$ is the [[Definition:Prime Enumeration Function|prime enumeration function]] which is [[Prime Enumeration Function is Primitive Recursive|primitive recursive]]. Since the instruction to be carried out at stage $t$ is a <tt>Successor</tt> the instruction number at stage $t+1$ is $a+1$ so the factor $2^a$ in $S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)$ is replaced by $2^{a+1}$. So: :$S_k \left({e, n_1, n_2, \ldots, n_k, t+1}\right) = 2 \times p_{n+1} \times S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)$ where $n = \operatorname{quot} \left({6, n}\right)$, $c = \left({e}\right)_a$ and $a = \left({S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)}\right)_1$. This is the required expression for $S_k \left({e, n_1, n_2, \ldots, n_k, t+1}\right)$ obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from [[Definition:Primitive Recursive Function|primitive recursive functions]]. The proofs for $\operatorname{Zinstr}$, $\operatorname{Cinstr}$ and $\operatorname{Jinstr}$ are along the same lines. In each case, the value of $S_k \left({e, n_1, n_2, \ldots, n_k, t+1}\right)$ can be obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from [[Definition:Primitive Recursive Function|primitive recursive functions]] (but I'd hate to have to do the calculations on my fingers). Thus by [[Definition by Cases is Primitive Recursive]], $S_k \left({e, n_1, n_2, \ldots, n_k, t+1}\right)$ is [[Definition:Primitive Recursive Function|primitive recursive]]. Hence $S_k$ is defined by [[Definition:Primitive Recursion|primitive recursion]] from functions known to be primitive recursive. Hence the result. {{qed}}	1
==== [[Rule of Distribution/Conjunction Distributes over Disjunction/Left Distributive/Formulation 1|Formulation 1]] ==== {{:Rule of Distribution/Conjunction Distributes over Disjunction/Left Distributive/Formulation 1}} ==== [[Rule of Distribution/Conjunction Distributes over Disjunction/Left Distributive/Formulation 2|Formulation 2]] ==== {{:Rule of Distribution/Conjunction Distributes over Disjunction/Left Distributive/Formulation 2}}	1
Let the [[Definition:Function|function]] $f: \N^{k+1} \to \N$ be [[Definition:Primitive Recursive Function|primitive recursive]]. Then so is the function $g: \N^{k+1} \to \N$ defined as: :$\displaystyle g \left({n_1, n_2, \ldots, n_k, z}\right) = \begin{cases} 0 & : z = 0 \\ \sum_{y \mathop = 1}^z f \left({n_1, n_2, \ldots, n_k, y}\right) & : z > 0 \end{cases}$	1
'''Symbolic logic''' is the study of [[Definition:Logic|logic]] in which the logical form of [[Definition:Statement|statements]] is analyzed by using [[Definition:Symbol|symbols]] as tools. Instead of explicit [[Definition:Statement|statements]], [[Definition:Logical Formula|logical formulas]] are investigated, which are symbolic representations of [[Definition:Statement|statements]], and [[Definition:Compound Statement|compound statements]] in particular. In '''symbolic logic''', the rules of reasoning and logic are investigated by means of [[Definition:Formal System|formal systems]], which form a good foundation for the symbolic manipulations performed in this field.	1
Not every [[Definition:Two-Person Zero-Sum Game|two-person zero-sum game]] has a [[Definition:Saddle Point (Game Theory)|saddle point]].	1
:$\paren {p \implies q} \land \paren {\neg p \implies q} \dashv \vdash q$	1
=== Definition 1 implies Definition 2 === Let $\mathbf A, \mathbf B$ be [[Definition:Semantic Equivalence/Boolean Interpretations/Definition 1|equivalent]] according to definition 1. Let $v$ be a [[Definition:Boolean Interpretation|boolean interpretation]]. By definition. either $v \left({\mathbf A}\right) = T$ or $v \left({\mathbf A}\right) = F$. In the first case, it follows by hypothesis that $v \left({\mathbf B}\right) = T$. In particular, then: :$v \left({\mathbf A}\right) = v \left({\mathbf B}\right)$ In the second case, it must be that $v \left({\mathbf B}\right) \ne T$. That is, $v \left({\mathbf B}\right) = F$, so that: :$v \left({\mathbf A}\right) = v \left({\mathbf B}\right)$ Hence $\mathbf A$ and $\mathbf B$ are also [[Definition:Semantic Equivalence/Boolean Interpretations/Definition 2|equivalent]] in the sense of definition 2. {{qed|lemma}} === Definition 2 implies Definition 3 === Let $\mathbf A, \mathbf B$ be [[Definition:Semantic Equivalence/Boolean Interpretations/Definition 2|equivalent]] according to definition 2. By definition of the [[Definition:Biconditional/Boolean Interpretation|boolean interpretation of $\iff$]]: :$v \left({\mathbf A \iff \mathbf B}\right)= T$ {{iff}} $v \left({\mathbf A}\right) = v \left({\mathbf B}\right)$ Therefore, by hypothesis and definition of [[Definition:Tautology for Boolean Interpretations|tautology]]: :$\mathbf A \iff \mathbf B$ is a [[Definition:Tautology for Boolean Interpretations|tautology]]. {{qed|lemma}} === Definition 3 implies Definition 1 === Let $\mathbf A, \mathbf B$ be [[Definition:Semantic Equivalence/Boolean Interpretations/Definition 3|equivalent]] according to definition 3. That is, let $\mathbf A \iff \mathbf B$ be a [[Definition:Tautology for Boolean Interpretations|tautology]]. From the [[Definition:Biconditional/Boolean Interpretation|boolean interpretation of $\iff$]], we have: :$v \left({\mathbf A}\right) = v \left({\mathbf B}\right)$ for every [[Definition:Boolean Interpretation|boolean interpretation]] $v$. Therefore it immediately follows that: :$v \left({\mathbf A}\right) = T$ {{iff}} $v \left({\mathbf B}\right) = T$ i.e. $\mathbf A$ and $\mathbf B$ are [[Definition:Semantic Equivalence/Boolean Interpretations/Definition 1|equivalent]] in the sense of definition 1. {{qed}}	1
This is an immediate consequence of: * [[Provable by Gentzen Proof System iff Negation has Closed Tableau]] * [[Soundness and Completeness of Semantic Tableaus]] {{qed}}	1
We will construct the claimed model using the [[Compactness Theorem]]. Let $LL^*$ be the language obtained by adding constant symbols $c_i$ to $\LL$ for each $i \in I$. Let $T^*$ be the $\LL^*$-theory obtained by adding to $T$ the $\LL^*$-sentences: :$c_i \ne c_j$ for each $i \ne j$ in $I$ and: :$\map \phi {c_{i_1}, \dotsc, c_{i_n} } \leftrightarrow \map \phi {c_{j_1}, \dotsc, c_{j_n} }$ for each $n \in \N$, each $\LL$-formula $\phi$ with $n$ [[Definition:Free Variable|free variables]], and each pair of [[Definition:Chain (Set Theory)|chains]] $i_1 < \cdots < i_n$ and $j_1 < \cdots < j_n$ in $I$. For future reference, we will refer to these last sentences using as those which '''assert indiscernibility with respect to $\phi$'''. If we can find a model of $T^*$, then its interpretations of the constants $c_i$ for $i\in I$ will be order indiscernibles. Suppose $\Delta$ is a finite subset of $T^*$. {{refactor|Extract this section as a lemma}} :We will show that there is a model of $\Delta$ using the [[Infinite Ramsey's Theorem]]. :Let $I_\Delta$ be the finite subset of $I$ containing those $i$ for which $c_i$ occurs in some sentence in $\Delta$. :Let $\psi_1, \dots, \psi_k$ be the finitely many $\LL$-formulas in $\Delta$ which assert indiscernibility with respect to $\phi_1, \dots, \phi_k$. :Let $m$ be the maximum number of free variables in the formulas $\phi_1, \dots, \phi_k$. :Let $\MM$ be an infinite model of $T$ (which exists by assumption). :Let $X$ be any infinite subset of the universe of $\MM$ such that $X$ is linearly ordered by some relation $\prec$. :Define a [[Definition:Set Partition|partition]] $P$ of $X^{\paren m} = \set {X' \subseteq X: \card {X'} = m}$ into $2^k$ components $S_A$ for each $A \subseteq \set {1, 2, \dotsc, k}$ by: ::$\set {x_1, \dots, x_m} \in S_A \iff x_1 \prec \cdots \prec x_m \text { and } A = \set {i: \MM \models \map {\phi_i} {x_1, \dotsc, x_m} }$ :By [[Infinite Ramsey's Theorem]], there is an infinite subset $Y\subseteq X$ such that each element of $Y^{\paren m} = \set {Y' \subseteq Y: \card {Y'} = m}$ is in the same component $S_A$ of $P$. :Note that $Y$ is indexed by some infinite subset $J_Y$ of $J$ and hence still linearly ordered by $\prec$. :We now show that the constants $c_i$ for $i \in I_\Delta$ can be interpreted as elements of $Y$ in $\MM$, and that the sentences $\psi_1, \dots, \psi_k$ will be satisfied using this interpretation. :Since $I_\Delta$ is finite and linearly ordered, and $J_Y$ is infinite and linearly ordered, there is clearly an [[Definition:Increasing|increasing]] function $f:I_\Delta \to J_Y$. :For each $h = 1, \dotsc, k$ and any pair of chains $i_1 < \cdots < i_n$ and $j_1 < \cdots < j_n$ in $I_\Delta$, we thus have: ::$\MM \models \map {\phi_h} {y_{\map f {i_1} }, \dotsc, y_{\map f {i_n} } }$ {{iff}} $h \in A$ {{iff}} $\MM \models \map {\phi_h} {y_{\map f {j_1} }, \dotsc, y_{\map f {j_n} } }$ :and hence: ::$\MM \models \map {\phi_h} {y_{\map f {i_1} }, \dotsc, y_{\map f {i_n} } } \iff \map {\phi_h} {y_{\map f {j_1} }, \dotsc, y_{\map f {j_n} } }$ :So, if we interpret each $c_i$ for $i \in I_\Delta$ as $y_{\map f i}$, we will have $\MM \models \psi_h$ for each $h = 1, \dotsc, k$. :Thus, we have shown that $\MM$ can be extended to an $\LL^*$-structure which models $\Delta$. Hence all finite subsets $\Delta$ of $T^*$ are satisfiable. By the [[Compactness Theorem]], we have that $T^*$ is satisfiable. Let $\NN$ be any model of $T^*$. Let $n_i$ be the interpretation of $c_i$ in $\NN$ for each $i \in I$. Then $\set {n_i: i \in I}$ is easily seen to be an order indiscernible set, since $T^*$ was defined to include sentences guaranteeing such. {{qed}} [[Category:Model Theory]] desk4iksvybgz4e4huhqre1dhkqymuh	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc||ccccccccc|} \hline p & \oplus & q & (\neg & p & \land & q) & \lor & (p & \land & \neg & q) \\ \hline F & F & F & T & F & F & F & F & F & F & T & F \\ F & T & T & T & F & T & T & T & F & F & F & T \\ T & T & F & F & T & F & F & T & T & T & T & F \\ T & F & T & F & T & F & T & F & T & F & F & T \\ \hline \end{array}$ {{qed}}	1
This is an immediate consequence of [[Semantic Consequence of Superset]]. {{qed}}	1
:$\set {\downarrow}$: [[Definition:Logical NOR|NOR]]	1
Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \N$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\paren {m \cdot x} \circ \paren {n \cdot x} = \paren {m n} \cdot \paren {x \circ x}$ In what follows, we make extensive use of [[Powers of Ring Elements]]: :$\forall n \in \Z: \forall x \in R: \paren {m \cdot x} \circ x = m \cdot \paren {x \circ x} = x \circ \paren {m \cdot x}$ First we verify $\map P 0$. When $n = 0$, we have: {{begin-eqn}} {{eqn | l = \paren {m \cdot x} \circ \paren {0 \cdot x} | r = \paren {m \cdot x} \circ 0_R | c = }} {{eqn | r = 0_R | c = }} {{eqn | r = 0 \cdot \paren {x \circ x} | c = }} {{eqn | r = \paren {m 0} \cdot \paren {x \circ x} | c = }} {{end-eqn}} So $\map P 0$ holds. === Basis for the Induction === Next we verify $\map P 1$. When $n = 1$, we have: {{begin-eqn}} {{eqn | l = \paren {m \cdot x} \circ \paren {1 \cdot x} | r = \paren {m \cdot x} \circ x | c = }} {{eqn | r = m \cdot \paren {x \circ x} | c = }} {{eqn | r = \paren {m 1} \cdot \paren {x \circ x} | c = }} {{end-eqn}} So $\map P 1$ holds. This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\paren {m \cdot x} \circ \paren {k \cdot x} = \paren {m k} \cdot \paren {x \circ x}$ Then we need to show: :$\paren {m \cdot x} \circ \paren {\paren {k + 1} \cdot x} = \paren {m \paren {k + 1} } \cdot \paren {x \circ x}$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \paren {m \cdot x} \circ \paren {\paren {k + 1} \cdot x} | r = \paren {m \cdot x} \circ \paren {k \cdot x + x} | c = }} {{eqn | r = \paren {m \cdot x} \circ \paren {k \cdot x} + \paren {m \cdot x} \circ x | c = {{Ring-axiom|D}} }} {{eqn | r = \paren {m k} \cdot \paren {x \circ x} + m \cdot \paren {x \circ x} | c = [[Powers of Ring Elements/General Result#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \paren {m k + k} \cdot \paren {x \circ x} | c = {{Ring-axiom|D}} }} {{eqn | r = \paren {m \paren {k + 1} } \cdot \paren {x \circ x} | c = }} {{end-eqn}} So $\map P K \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\forall m \in \Z: \forall n \in \N: \paren {m \cdot x} \circ \paren {n \cdot x} = \paren {m n} \cdot \paren {x \circ x}$ {{qed|lemma}} The result for $n < 0$ follows directly from [[Powers of Group Elements]]. {{qed}} [[Category:Ring Theory]] [[Category:Proofs by Induction]] nh2n0mqnbv15b7l1leixn5etc5jip76	1
{{AimForCont}} that $T \subsetneq S$. That is, $T$ is a [[Definition:Proper Subset|proper subset]] of $S$: : $T \ne S$ Let $T' = S \setminus T$. Then by [[Set Difference with Proper Subset]]: :$T' \ne \O$ By [[Definition:Naturally Ordered Semigroup Axioms|axiom $NO1$]], $S$ is [[Definition:Well-Ordered Set|well-ordered]]. By definition of [[Definition:Well-Ordered Set|well-ordered set]], it follows that $T'$ has a [[Definition:Smallest Element|smallest element]] $x$. By definition of $T$: :$0 \in T$ and so by definition of $T'$: :$0 \notin T'$ so: :$0 \prec x$ By [[Sum with One is Immediate Successor in Naturally Ordered Semigroup]]: :$1 \preceq x$ By the definition of a [[Definition:Naturally Ordered Semigroup|naturally ordered semigroup]]: :$\exists y \in S: y \circ 1 = x$ Again by [[Sum with One is Immediate Successor in Naturally Ordered Semigroup]]: :$y \prec x$ We have that $x$ is the [[Definition:Smallest Element|smallest element]] of $T'$ and $y \prec x$. Therefore: :$y \notin T'$ and so :$y \in T$ But from the definition of $T$: :$y \in T \implies y \circ 1 = x \in T$ But then by the definition of $T'$: :$x \in T' \implies x \notin T$ From this [[Definition:Contradiction|contradiction]], it follows that: :$T = S$ {{qed}}	1
A '''natural language''' is one of the conventional, everyday languages in which people usually communicate. Although there are many natural languages in the world, we are not generally going to distinguish between them, merely lumping them all into the one concept. When '''natural language''' is referred to on {{ProofWiki}}, it will usually mean English.	1
Let $T$ be the set of [[Definition:Theorem of Logic|theorems]] of some [[Definition:Consistent (Logic)|consistent theory]] in the [[Definition:Language of Arithmetic|language of arithmetic]] which contains [[Definition:Minimal Arithmetic|minimal arithmetic]] $Q$. $T$ is not [[Definition:Recursive Set|recursive]].	1
{{BeginTableau|p \lor \neg p}} {{Assumption |1|\neg \paren {p \lor \neg p}|Assume the contrary}} {{Assumption |2|p|Assume one disjunct}} {{Addition |3|2|p \lor \neg p|2|1}} {{NonContradiction |4|1, 2|3|1}} {{Contradiction |5|1|\neg p|2|4|demonstrating a contradiction}} {{Addition |6|1|p \lor \neg p|5|2}} {{NonContradiction |7|1|6|1|also demonstrating a contradiction}} {{Contradiction |8||\neg \neg \paren {p \lor \neg p}|1|7}} {{DoubleNegElimination |9||p \lor \neg p|8}} {{EndTableau}} {{Qed}}	1
:$p \lor q, \neg p \vdash q$	1
Apart from the programs given, the only other single-instruction programs are of the form: {| |- ! align="right" | Line !! ! align="left" | Command |- | align="right" | $1$ || | align="left" | $J \left({m, n, q}\right)$ |} The convention is that, at the start of the program, $R_1$ contains the [[Definition:Unlimited Register Machine#Input|input]], and all other [[Definition:Unlimited Register Machine#Registers|registers]] contain $0$. Suppose $q > 1$. Then whatever $m$ or $n$ are, the program either jumps to $q$ (a location outside the program) or steps one instruction. In either case the program stops without changing what is in $R_1$. Hence this is another way of computing the [[Single Instruction URM Programs/Identity Function|identity function]] $I_\N$. Suppose $q = 1$. If $m = n$, then whatever is held in the [[Definition:Unlimited Register Machine#Registers|registers]], $r_m = r_n$ and the program will go back to execute step 1 again. Thus the program will loop round and do step 1 endlessly, and [[Definition:Unlimited Register Machine#Termination|never terminate]]. If $m \ne n$, then the program's behaviour depends on the contents of $R_n$ and $R_m$. If $m = 1$ and $n \ne 1$, then the program will compare the [[Definition:Unlimited Register Machine#Input|input]] against the contents of $r_n$. If $r_1 = 0$ the program will go into an endless loop, and never [[Definition:Unlimited Register Machine#Termination|terminate]]. Otherwise, i.e. if $r_1 \ne 0$, the program will [[Definition:Unlimited Register Machine#Termination|never terminate]] with $r_1$ unchanged. If $m \ne 1$ and $n \ne 1$ then the program will once more [[Definition:Unlimited Register Machine#Termination|never terminate]], as $r_m = r_n = 0$ at the start of the program. So the program: {| |- ! align="right" | Line !! ! align="left" | Command |- | align="right" | $1$ || | align="left" | $J \left({m, n, 1}\right)$ |} does ''not'' specify a [[Definition:URM Computability|URM computable]] function, as: * when $m = n$ the program will [[Definition:Unlimited Register Machine#Termination|never terminate]] for any input; * when $m \ne n, m = 1$ the program will [[Definition:Unlimited Register Machine#Termination|never terminate]] on input $0$; * when $m \ne n, n = 1$ the program similarly will [[Definition:Unlimited Register Machine#Termination|never terminate]] on input $0$; * when $m \ne n, m \ne 1, n \ne 1$ the program will [[Definition:Unlimited Register Machine#Termination|never terminate]] for any input. In all cases there is at least one input for which the program will [[Definition:Unlimited Register Machine#Termination|never terminate]]. The result follows from the definition of [[Definition:URM Computability|URM computability]]. {{qed}} [[Category:URM Programs]] [[Category:Primitive Recursive Functions]] 1hwd2h1sy1wfp6cs5zq3tnfc9rlrkpe	1
Let $C$ be a [[Definition:Linear Code|linear $\tuple {n, k}$-code]] whose [[Definition:Master Code|master code]] is $\map V {n, p}$. Let $\map d C$ denote the [[Definition:Minimum Distance of Linear Code|minimum distance]] of $C$. Then: :$\map d C = \displaystyle \min_{u \mathop \in C} \map w u$ where $\map w u$ denotes the [[Definition:Weight of Linear Codeword|weight of $u$]].	1
=== [[Rule of Addition/Sequent Form/Proof 1/Form 1|Form 1]] === {{:Rule of Addition/Sequent Form/Proof 1/Form 1}} === [[Rule of Addition/Sequent Form/Proof 1/Form 2|Form 2]] === {{:Rule of Addition/Sequent Form/Proof 1/Form 2}}	1
{{begin-eqn}} {{eqn | o = | r = \map {\mathbf I} {S, P} | c = }} {{eqn | ll= \leadsto | o = | r = \exists x: \map S x \land \map P x | c = {{Defof|Particular Affirmative}} }} {{eqn | ll= \leadsto | o = | r = \exists x: \map P x \land \map S x | c = [[Conjunction is Commutative]] }} {{eqn | ll= \leadsto | o = | r = \map {\mathbf I} {P, S} | c = {{Defof|Particular Affirmative}} }} {{end-eqn}} {{qed}}	1
Let $v$ be an arbitrary [[Definition:Boolean Interpretation|boolean interpretation]]. Then $v \left({\mathbf A}\right) = v \left({\mathbf A'}\right)$. It is to be shown that $v \left({\mathbf B}\right) = v \left({\mathbf B'}\right)$. We proceed by [[Second Principle of Mathematical Induction|induction]]. Let $n \left({\mathbf B}\right)$ be the number of [[Definition:WFF of Propositional Logic|WFFs]] $\mathbf C$ such that: :$\mathbf A$ is a [[Definition:Subformula|subformula]] of $\mathbf C$, and $\mathbf C$ is a [[Definition:Subformula|subformula]] of $\mathbf B$. Note that $n \left({\mathbf B}\right) \ne 0$, for $\mathbf C = \mathbf A$ is a valid choice. Suppose now that $n \left({\mathbf B}\right) = 1$. Because we have the valid choices $\mathbf C = \mathbf A$ and $\mathbf C = \mathbf B$, it follows that these choices must be identical, i.e. $\mathbf A = \mathbf B$. Hence $\mathbf B' = \mathbf A'$, and so: :$v \left({\mathbf B}\right) = v \left({\mathbf B'}\right)$ Suppose now that the assertion is true for all $\mathbf B$ with $n \left({\mathbf B}\right) \le n$. Let $n \left({\mathbf B}\right) = n + 1$. Suppose $\mathbf B = \neg \mathbf B_1$. Then obviously $n \left({\mathbf B_1}\right) = n$, so by hypothesis: :$v \left({\mathbf B_1}\right) = v \left({\mathbf B_1 \left({\mathbf A \,//\, \mathbf A'}\right)}\right)$ Also, by definition of [[Definition:Substitution for Well-Formed Part|substitution]]: :$\mathbf B' = \neg \mathbf B_1 \left({\mathbf A \,//\, \mathbf A'}\right)$ Now, by definition of [[Definition:Boolean Interpretation|boolean interpretation]]: {{begin-eqn}} {{eqn|l = v \left({\mathbf B}\right) |r = f^\neg \left({v \left({\mathbf B_1}\right)}\right) }} {{eqn|r = f^\neg \left({v \left({\mathbf B_1 \left({\mathbf A \,//\, \mathbf A'}\right)}\right)}\right) }} {{eqn|r = v \left({\neg \mathbf B_1 \left({\mathbf A \,//\, \mathbf A'}\right)}\right) }} {{eqn|r = v \left({\mathbf B'}\right) }} {{end-eqn}} Suppose now that $\mathbf B = \mathbf B_1 \mathbin{\mathsf B} \mathbf B_2$ for a [[Definition:Binary Logical Connective|binary connective]] $\mathsf B$. Then $n \left({\mathbf B_1}\right), n \left({\mathbf B_2}\right) \le n$, so: :$v \left({\mathbf B_1}\right) = v \left({\mathbf B_1 \left({\mathbf A \,//\, \mathbf A'}\right)}\right)$ :$v \left({\mathbf B_2}\right) = v \left({\mathbf B_2 \left({\mathbf A \,//\, \mathbf A'}\right)}\right)$ This follows by either the induction hypothesis, or when $\mathbf A$ is not a [[Definition:Subformula|subformula]] of $\mathbf B_1$ or $\mathbf B_2$, is entirely trivial, considering the [[Definition:Substitution for Well-Formed Part|substitution]] does not change anything. Also, by definition of [[Definition:Substitution for Well-Formed Part|substitution]]: :$\mathbf B' = \mathbf B_1 \left({\mathbf A \,//\, \mathbf A'}\right) \mathbin{\mathsf B} \mathbf B_2 \left({\mathbf A \,//\, \mathbf A'}\right)$ Now, by definition of [[Definition:Boolean Interpretation|boolean interpretation]]: {{begin-eqn}} {{eqn|l = v \left({\mathbf B}\right) |r = f^{\mathsf B} \left({v \left({\mathbf B_1}\right), v \left({\mathbf B_2}\right)}\right) }} {{eqn|r = f^{\mathsf B} \left({v \left({\mathbf B_1 \left({\mathbf A \,//\, \mathbf A'}\right)}\right), v \left({\mathbf B_2 \left({\mathbf A \,//\, \mathbf A'}\right)}\right)}\right) }} {{eqn|r = v \left({\mathbf B_1 \left({\mathbf A \,//\, \mathbf A'}\right) \mathbin{\mathsf B} \mathbf B_2 \left({\mathbf A \,//\, \mathbf A'}\right)}\right) }} {{eqn|r = v \left({\mathbf B'}\right) }} {{end-eqn}} By definition of the [[Definition:Language of Propositional Logic|language of propositional logic]], $\mathbf B$ must have either of the above forms. Hence the result, from the [[Second Principle of Mathematical Induction]]. {{qed}}	1
This is a corollary of the [[Extended Completeness Theorem for Propositional Tableaus and Boolean Interpretations]]. Namely, it is the special case $\mathbf H = \varnothing$. Hence the result. {{qed}}	1
Two [[Definition:Statement|statements]] $p$ and $q$ are said to be '''contradictory''' [[Definition:Iff|iff]]: : whenever $p$ is [[Definition:True|true]], $q$ is [[Definition:False|false]]. and: : whenever $q$ is [[Definition:True|true]], $p$ is [[Definition:False|false]].	1
==== [[False Statement implies Every Statement/Formulation 1|Formulation 1]] ==== {{:False Statement implies Every Statement/Formulation 1}} ==== [[False Statement implies Every Statement/Formulation 2|Formulation 2]] ==== {{:False Statement implies Every Statement/Formulation 2}}	1
For each $n \ge n_0$, let $\map {P'} n$ be defined as: :$\map {P'} n := \map P {n_0} \land \dots \land \map P n$ It suffices to show that $\map {P'} n$ is true for all $n \ge n_0$. It is immediate from the assumption $\map P {n_0}$ that $\map {P'} {n_0}$ is [[Definition:True|true]]. Now suppose that $\map {P'} n$ holds. By $(2)$, this implies that $\map P {n + 1}$ holds as well. Consequently, $\map {P'} n \land \map P {n + 1} = \map {P'} {n + 1}$ holds. Thus by the [[Principle of Mathematical Induction]]: :$\map {P'} n$ holds for all $n \ge n_0$ as desired. {{Qed}}	1
{{begin-eqn}} {{eqn | l=p \lor \left({p \land q}\right) | r=\left({p \land \top}\right) \lor \left({p \land q}\right) | c=[[Conjunction with Tautology]] }} {{eqn | r=p \land \left({\top \lor q}\right) | c=[[Conjunction is Left Distributive over Disjunction]] }} {{eqn | r=p \land \top | c=[[Disjunction with Tautology]] }} {{eqn | r=p | c=[[Conjunction with Tautology]] }} {{end-eqn}} {{qed}}	1
<section notitle="True" name="definition"> === {{ProofRuleLink|Rule of Assumption}} === {{:Rule of Assumption/Proof Rule}} === {{ProofRuleLink|Rule of Conjunction}} === {{:Rule of Conjunction/Proof Rule}} === {{ProofRuleLink|Rule of Simplification}} === {{:Rule of Simplification/Proof Rule}} === {{ProofRuleLink|Rule of Addition}} === {{:Rule of Addition/Proof Rule}} === {{ProofRuleLink|Proof by Cases}} === {{:Proof by Cases/Proof Rule}} === {{ProofRuleLink|Modus Ponendo Ponens}} === {{:Modus Ponendo Ponens/Proof Rule}} === {{ProofRuleLink|Rule of Implication}} === {{:Rule of Implication/Proof Rule}} === {{ProofRuleLink|Principle of Non-Contradiction}} === {{:Principle of Non-Contradiction/Proof Rule}} === {{ProofRuleLink|Proof by Contradiction}} === {{:Proof by Contradiction/Proof Rule}}</section> [[Category:Definitions/Logic]] s4y8qrmlgh7w08v92x9jgby2l9opidt	1
: $\vdash \left({p \implies q}\right) \implies \left({\left({p \lor r}\right) \implies \left ({q \lor r}\right)}\right)$	1
:$\paren {p \implies \paren {q \implies r} } \implies \paren {\paren {p \implies q} \implies \paren {p \implies r} }$	1
: $\vdash \left({q \implies \left({p \implies r}\right)}\right) \implies \left({p \implies \left({q \implies r}\right)}\right)$	1
For $k \ge 1$, let $f_c^k$ be the [[Definition:Constant Mapping|constant function]] of $k$ variables with value $c$. We know from [[Constant Function is Primitive Recursive]] that $f_c^1$ is [[Definition:Primitive Recursive Function|primitive recursive]]. Now: :$\map {f_c^k} {n_1, n_2, \ldots, n_k} = \map {f_c^1} {n_1} = \map {f_c^1} {\map {\pr_1^k} {n_1, n_2, \ldots, n_k} }$ where $\pr_1^k$ is a [[Definition:Projection Function|projection function]] which is [[Definition:Basic Primitive Recursive Function|basic primitive recursive]]. So $f_c^k$ is obtained from the [[Definition:Primitive Recursive Function|primitive recursive function]] $f_c^1$ and the [[Definition:Basic Primitive Recursive Function|basic primitive recursive function]] $\pr_1^k$ by [[Definition:Substitution (Mathematical Logic)|substitution]]. Hence by definition, $f_c^k$ is [[Definition:Primitive Recursive Function|primitive recursive]]. {{qed}} [[Category:Primitive Recursive Functions]] [[Category:Constant Mappings]] p7103pmh89wjmd8e0mfrg551rg2r1jz	1
: $\neg p \implies q \vdash \neg q \implies p$	1
If $\mathbf H$ is [[Definition:Finite Set|finite]], the result is trivial. So let $\mathbf H = \left\{{\mathbf A_n: n \in \N}\right\}$ be an [[Definition:Enumeration|enumeration]] of $\mathbf H$. Define $\mathbf H_m = \left\{{\mathbf A_n: n \le m}\right\}$. Let $T_1$ be the [[Definition:Propositional Tableau|propositional tableau]] consisting of only a [[Definition:Root Node|root node]] with [[Definition:Hypothesis Set|hypothesis set]] $\mathbf H_1$. For each $m \in \N$, construct $T_{m+1}$ from $T_m$ by applying the [[Tableau Extension Lemma]] to $\mathbf H_{m+1}$. This provides us with a [[Definition:Sequence|sequence]] $\left({T_m}\right)_{m \in \N}$ of [[Definition:Finished Propositional Tableau|finished propositional tableaus]]. The $T_m$ form an [[Definition:Exhausting Sequence of Sets|exhausting sequence of sets]] for the [[Definition:Infinite Propositional Tableau|infinite propositional tableau]] $T = \displaystyle \bigcup_{m \mathop = 1}^\infty T_m$. If $T$ has a [[Definition:Finished Branch of Propositional Tableau|finished branch]] $\Gamma$, then by [[Finished Branch Lemma/Corollary|Finished Branch Lemma: Corollary]]: :$\Phi \left[{\Gamma}\right]$ is [[Definition:Satisfiable|satisfiable]] and hence $\mathbf H$ is [[Definition:Satisfiable|satisfiable]] (since $\mathbf H \subseteq \Phi \left[{\Gamma}\right]$). Suppose $T$ has no [[Definition:Finite Branch|finite]] [[Definition:Finished Branch of Propositional Tableau|finished branches]]. Let $T'$ be the [[Definition:Subtree|subtree]] of $T$ given by: :$t \in T'$ {{iff}} $t$ is on a [[Definition:Finished Branch of Propositional Tableau|finished branch]] $\Gamma_m$ of every $T_m$ such that $t \in T_m$ Suppose the [[Definition:Root Node|root node]] $r_T$ of $T$ were not in $T'$. Then for some $T_m$, $r_T$ would not be on a [[Definition:Finished Branch of Propositional Tableau|finished branch]] of $T_m$. But since $T_m$ is [[Definition:Finished Propositional Tableau|finished]], every [[Definition:Branch (Graph Theory)|branch]] of $T_m$ is [[Definition:Finished Branch of Propositional Tableau|finished]] or [[Definition:Contradictory Branch|contradictory]]. Hence every [[Definition:Branch (Graph Theory)|branch]] of $T_m$ is [[Definition:Contradictory Branch|contradictory]]. But then $T_m$ is a [[Definition:Tableau Confutation|tableau confutation]] of $\mathbf H_m$. By [[Tableau Confutation implies Unsatisfiable]], this contradicts the assumption that $\mathbf H_m$ is [[Definition:Satisfiable|satisfiable]]. Therefore, $r_T$ is in $T'$. Suppose $T'$ were [[Definition:Finite Tree|finite]]. Let $t$ be a [[Definition:Leaf Node|leaf]] of $T'$, which exists by [[Finite Tree has Leaf Nodes]]. Suppose $t$ were a [[Definition:Leaf Node|leaf]] of $T$. Then $\Gamma_t$, the [[Definition:Branch (Graph Theory)|branch]] of $T$ identified by [[Leaf of Rooted Tree is on One Branch]], is [[Definition:Finished Branch of Propositional Tableau|finished]]. For, as any $T_m$ is a [[Definition:Subtree|subtree]] of $T$, $\Gamma_t$ is the only [[Definition:Branch (Graph Theory)|branch]] of $T_m$ such that $t \in \Gamma_t$. The conclusion follows from the definition of $T'$. But then $\Gamma_t$ would be a [[Definition:Finite Branch|finite]] [[Definition:Finished Branch of Propositional Tableau|finished branch]] of $T$, a contradiction. Therefore, $T'$ cannot be [[Definition:Finite Tree|finite]]. Hence, $T'$ is a [[Definition:Finitely Branching|finitely branching tree]]. By [[König's Tree Lemma]], $T'$ has an [[Definition:Infinite Branch|infinite branch]] $\Gamma$. By definition of $T'$, the [[Definition:Branch (Graph Theory)|branch]] $\Gamma_m := \Gamma \cap T_m$ of $T_m$ is [[Definition:Finished Branch of Propositional Tableau|finished]] for each $m \in \N$. If $\Gamma$ were [[Definition:Contradictory Branch|contradictory]], then $\mathbf A \in \Gamma$ and $\neg\mathbf A \in \Gamma$ for some [[Definition:WFF of Propositional Logic|WFF]] $\mathbf A$. But then $\mathbf A, \neg \mathbf A \in \Gamma_m$ for some $m \in \N$, contradicting that $\Gamma_m$ is [[Definition:Finished Branch of Propositional Tableau|finished]]. Also, if $\mathbf A$ [[Definition:Occurrence along Branch|occurs]] on $\Gamma$, then it occurs on some $\Gamma_m$. Since $\Gamma_m$ is [[Definition:Finished Branch of Propositional Tableau|finished]], it follows that $\mathbf A$ is [[Definition:Used WFF|used]] on $\Gamma_m$, and hence on $\Gamma$. In conclusion, $\Gamma$ is [[Definition:Finished Branch of Propositional Tableau|finished]]. As established above, it follows that $\mathbf H$ is [[Definition:Satisfiable|satisfiable]] for [[Definition:Boolean Interpretation|boolean interpretations]]. {{qed}}	1
:$q \implies \neg p \vdash \neg p \implies q$	1
:$p \implies \neg p, \neg p \implies p \vdash \bot$	1
This is to be done by [[Second Principle of Mathematical Induction|strong induction]] on the [[Definition:Length of String|length]] of [[Definition:WFF of Propositional Logic|WFFs]]. By definition of $v$ being a [[Definition:Boolean Interpretation|boolean interpretation]], $\map v p$ is well-defined for all $p \in \PP_0$, the [[Definition:Vocabulary of Propositional Logic|vocabulary]] of $\LL_0$. A [[Definition:WFF of Propositional Logic|WFF]] of [[Definition:Length of String|length]] $1$ has (trivially) a unique [[Definition:Parsing Sequence|parsing sequence]]. Consequently, only a single defining rule for $v$ as a [[Definition:Boolean Interpretation|boolean interpretation]] applies. So the result holds for all [[Definition:WFF of Propositional Logic|WFFs]] of [[Definition:Length of String|length]] $1$. Now, suppose the result is true for all [[Definition:WFF of Propositional Logic|WFFs]] of [[Definition:Length of String|length]] $k$ or less. Let $\mathbf A$ be a [[Definition:WFF of Propositional Logic|WFF]] of length $k+1$. There are two possibilities: Suppose $\mathbf A = \neg \mathbf B$ for some [[Definition:WFF of Propositional Logic|WFF]] $\mathbf B$. Then $\mathbf B$ is of length $k$, so by the induction hypothesis has a unique value $v (\mathbf B)$ no matter what parsing sequence is used. So as $\map v {\mathbf A} = \map {f^\neg} {\map v {\mathbf B} }$, it follows that $\mathbf A$ likewise has a unique value. Hence the result holds for $k + 1$ in this situation. Suppose $\mathbf A = \paren {\mathbf B * \mathbf C}$ for some [[Definition:WFF of Propositional Logic|WFFs]] $\mathbf B$ and $\mathbf C$ and some connective $*$. By [[Language of Propositional Logic has Unique Parsability]], $*$ must be the unique [[Definition:Main Connective (Propositional Logic)|main connective]]. So $\mathbf B$ and $\mathbf C$ are both [[Definition:WFF of Propositional Logic|WFFs]] shorter than $k + 1$ and therefore by the induction hypothesis have unique values $\map v {\mathbf B}$ and $\map v {\mathbf C}$. Since $\mathbf A = \paren {\mathbf B * \mathbf C}$ for a unique [[Definition:Main Connective (Propositional Logic)|main connective]] $*$, it follows that: :$\map v {\mathbf A} = \map {f^*} {\map v {\mathbf B}, \map v {\mathbf C} }$ is well-defined. Hence the result holds for $k + 1$ in this situation. So the result follows by the [[Second Principle of Mathematical Induction]]. {{qed}}	1
Let $S$ be a [[Definition:Non-Empty Set|non-empty]] [[Definition:Subset|subset]] of the [[Definition:Natural Numbers|set of natural numbers]] $\N$. We take as [[Definition:Axiom|axiomatic]] that $\N$ is itself a [[Definition:Subset|subset]] of the [[Definition:Real Number|set of real numbers]] $\R$. Thus $S \subseteq \R$. By definition: :$\forall n \in \N: n \ge 0$ and so: :$\forall n \in S: n \ge 0$ Hence $0$ is a [[Definition:Lower Bound of Subset of Real Numbers|lower bound]] of $S$. This establishes the fact that $S$ is [[Definition:Bounded Below Subset of Real Numbers|bounded below]]. By the [[Continuum Property]], we have that $S$ admits an [[Definition:Infimum of Subset of Real Numbers|infimum]]. Hence let $b = \inf S$. Because $b$ is the [[Definition:Infimum of Subset of Real Numbers|infimum]] of $S$, it follows that $b + 1$ is not a [[Definition:Lower Bound of Subset of Real Numbers|lower bound]] of $S$. So, for some $n \in S$: :$n < b + 1$ {{AimForCont}} $n$ is not the [[Definition:Smallest Element|smallest element]] of $S$. Then there exists $m \in S$ such that: :$b \le m < n < b + 1$ from which it follows that: :$0 < n - m < 1$ But there exist no [[Definition:Natural Number|natural numbers]] $k$ such that $0 < k < 1$. Hence $n = b$ is the [[Definition:Smallest Element|smallest element]] of $S$. {{qed}}	1
{{BeginTableau|p \downarrow q \vdash q \downarrow p}} {{Premise|1|p \downarrow q}} {{SequentIntro|2|1|\neg \paren {p \lor q}|1|{{Defof|Logical NOR}} }} {{Commutation|3|1|\neg \paren {q \lor p}|2|Disjunction}} {{SequentIntro|4|1|q \uparrow p|3|{{Defof|Logical NOR}} }} {{EndTableau}} {{qed|lemma}} {{BeginTableau|q \downarrow p \vdash p \uparrow q}} {{Premise|1|q \downarrow p}} {{SequentIntro|2|1|\neg \paren {q \lor p}|1|{{Defof|Logical NOR}} }} {{Commutation|3|1|\neg \paren {p \lor q}|2|Disjunction}} {{SequentIntro|4|1|p \downarrow q|3|{{Defof|Logical NOR}} }} {{EndTableau}} {{qed}}	1
The [[Law of Excluded Middle]] can be symbolised by the [[Definition:Sequent|sequent]]: :$\vdash p \lor \neg p$	1
The [[Definition:Golay Ternary Code|Golay ternary code]] has a [[Definition:Minimum Distance of Linear Code|minimum distance]] of $5$.	1
:$\vdash \left({\neg \left({p \land \neg q}\right)}\right) \implies \left({p \implies q}\right)$	1
Let $P$ be a [[Definition:Well-Formed Formula|well-formed formula]]. Let $A$ be a finite set such that $x \in A$ {{iff}} $x$ is a [[Definition:Free Variable|free variable]] in $P$. Then: :$\displaystyle A \subseteq B \implies \left({B \models P \iff P^B}\right)$ {{explain|Definition of $P^B$}}	1
By the [[Definition:Definitional Abbreviation|definitional abbreviation]] for the [[Definition:Conditional|conditional]]: :$\mathbf A \implies \mathbf B =_{\text{def}} \neg \mathbf A \lor \mathbf B$ the [[Rule of Commutation/Disjunction/Formulation 2/Forward Implication|Rule of Commutation]] can be written as: :$\neg \left({p \lor q}\right) \lor \left({q \lor p}\right)$ This evaluates as follows: :$\begin{array}{|cccc|c|ccc|} \hline \neg & (p & \lor & q) & \lor & (q & \lor & p) \\ \hline 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 \\ 1 & 0 & 0 & 2 & 0 & 2 & 0 & 0 \\ 1 & 0 & 0 & 3 & 0 & 3 & 0 & 0 \\ 1 & 1 & 0 & 0 & 0 & 0 & 0 & 1 \\ 0 & 1 & 1 & 1 & 0 & 1 & 1 & 1 \\ 3 & 1 & 2 & 2 & 0 & 2 & 2 & 1 \\ 0 & 1 & 3 & 3 & 0 & 3 & 3 & 1 \\ 1 & 2 & 0 & 0 & 0 & 0 & 0 & 2 \\ 3 & 2 & 2 & 1 & 0 & 1 & 2 & 2 \\ 3 & 2 & 2 & 2 & 0 & 2 & 2 & 2 \\ 1 & 2 & 0 & 3 & 0 & 3 & 0 & 2 \\ 1 & 3 & 0 & 0 & 0 & 0 & 0 & 3 \\ 0 & 3 & 3 & 1 & 0 & 1 & 3 & 3 \\ 1 & 3 & 0 & 2 & 0 & 2 & 0 & 3 \\ 0 & 3 & 3 & 3 & 0 & 3 & 3 & 3 \\ \hline \end{array}$ {{qed}} [[Category:Formal Semantics]] emlja2kbsygf1qleayueqncwq850mjn	1
Let $G = \paren {\begin{array} {c|c} \mathbf I & \mathbf A \end{array} }$. Let $c \in \map V {n, p}$. Then, by definition of $G$, $c$ is a [[Definition:Codeword of Linear Code|codeword]] of $C$ {{iff}} $c$ is of the form $u G$, where $u \in \map V {k, p}$. Thus $c \in C$ {{iff}}: {{begin-eqn}} {{eqn | l = c | r = u G | c = }} {{eqn | r = u \paren {\begin{array} {c {{!}} c} \mathbf I & \mathbf A \end{array} } | c = }} {{eqn | r = \paren {\begin{array} {c {{!}} c} u & v \end{array} } | c = }} {{end-eqn}} where: :$v = u \mathbf A$ :$\paren {\begin{array} {c|c} u & v \end{array} }$ denotes the $1 \times n$ [[Definition:Matrix|matrix]] formed from the $k$ elements of $u$ and the $n - k$ elements of $v$. Let $w \in \map V {n, p}$. $w$ can be expressed in the form: :$w = \paren {\begin{array} {c|c} u_1 & v_1 \end{array} }$ where $u_1 \in \map V {k, p}$. The [[Definition:Syndrome|syndrome]] of $v$ is then calculated as: {{begin-eqn}} {{eqn | l = \map S v | r = \paren {\begin{array} {c {{!}} c} -\mathbf A^\intercal & \mathbf I \end{array} } w^\intercal | c = }} {{eqn | r = \paren {\begin{array} {c {{!}} c} -\mathbf A^\intercal & \mathbf I \end{array} } \paren {\begin{array} {c {{!}} c} u_1^\intercal & v_1^\intercal \end{array} } | c = }} {{eqn | r = -\mathbf A^\intercal u_1^\intercal + v_1^\intercal | c = }} {{end-eqn}} It follows that the [[Definition:Syndrome|syndrome]] of $w$ is [[Definition:Zero Codeword|zero]] {{iff}} $w$ is the [[Definition:Concatenation of Matrices|concatenation]] of $u_1$ and $v_1$, where: :$v_1^\intercal = \mathbf A^\intercal u_1^\intercal = \paren {u_1 \mathbf A}^\intercal$ Thus the [[Definition:Syndrome|syndrome]] of $w$ is [[Definition:Zero Codeword|zero]] {{iff}} $w$ is a [[Definition:Codeword of Linear Code|codeword]] of $C$. {{qed}}	1
The '''predicate''' of a [[Definition:Simple Statement|simple statement]] in [[Definition:Logic|logic]] is the part of the statement which defines ''what is being said'' about the [[Definition:Subject|subject]]. It is a word or phrase which, when combined with one or more names of [[Definition:Object|objects]], turns into a meaningful sentence. The predicates of simple statements are [[Definition:Atom (Logic)|atomic]] in [[Definition:Predicate Logic|predicate logic]]. The subject and predicate of a simple statement are referred to as its [[Definition:Logical Term|terms]].	1
A '''switching circuit''' is a mechanical, electronic or electromechanical system for controlling the route of information or resources. The study of '''switching circuits''' can be considered a field of applied [[Definition:Logic|logic]].	1
{{BeginTableau|p \implies q, \neg q \vdash \neg p}} {{Premise|1|p \implies q}} {{Premise|2|\neg q}} {{Assumption|3|p|Assume $p$ ...}} {{ModusPonens|4|1, 3|q|1|3|... and derive $q$ ...}} {{NonContradiction|5|1, 2, 3|4|2| ... demonstrating a contradiction}} {{Contradiction|6|1, 2|\neg p|3|5}} {{EndTableau}} {{Qed}}	1
Consider $\N$ defined as a [[Definition:Naturally Ordered Semigroup|naturally ordered semigroup]]. The result follows directly from [[Principle of Mathematical Induction for Naturally Ordered Semigroup/General Result|Principle of Mathematical Induction for Naturally Ordered Semigroup: General Result]]. {{qed}}	1
: $\vdash \left({p \implies q}\right) \iff \left({\neg q \implies \neg p}\right)$	1
Let $\struct {S, \preceq}$ be a [[Definition:Well-Ordered Set|well-ordered set]]. Let $T \subseteq S$ be a [[Definition:Subset|subset]] of $S$ such that: :$\forall s \in S: \paren {\forall t \in S: t \prec s \implies t \in T} \implies s \in T$ Then $T = S$.	1
Let $p \left({j}\right)$ be the [[Definition:Prime Enumeration Function|prime enumeration function]]. For $n \ne 0$ and $j \ne 0$, we see that $\left({n}\right)_j$ is the largest value of $k$ for which $p \left({j}\right)^k$ is a [[Definition:Divisor of Integer|divisor]] of $n$. Thus $\left({n}\right)_j$ is the ''smallest'' value of $k$ for which $p \left({j}\right)^{k+1}$ is ''not'' a [[Definition:Divisor of Integer|divisor]] of $n$. We note that if $r \ge n$ and $j \ne 0$, we have $p \left({j}\right)^r \ge 2^r \ge 2^n> n$. Thus $n$ is a (generous) [[Definition:Upper Bound of Mapping|upper bound]] of $\left({n}\right)_j$. The condition that $p \left({j}\right)^{k+1}$ is not a [[Definition:Divisor of Integer|divisor]] of $n$ can be expressed as: :$\operatorname{div} \left({n, p \left({j}\right)^{k+1}}\right) = 0$ where: : [[Divisor Relation is Primitive Recursive|$\operatorname{div}$ is primitive recursive]] : The [[Equality Relation is Primitive Recursive]] : [[Prime Enumeration Function is Primitive Recursive|$p \left({j}\right)$ is primitive recursive]] : [[Exponentiation is Primitive Recursive]] : [[Addition is Primitive Recursive]]. So we see that the relation: :$\mathcal R \left({n, j, k}\right) \iff \operatorname{div} \left({n, p \left({j}\right)^{k+1}}\right) = 0$ is [[Definition:Primitive Recursive Relation|primitive recursive]]. From [[Bounded Minimization is Primitive Recursive]], we also see that: :$\left({n}\right)_j = \begin{cases} \mu k \le n \mathcal R \left({n, j, k}\right) & : n \ne 0 \land j \ne 0 \\ 0 & : \text{otherwise} \end{cases}$ is [[Definition:Primitive Recursive Function|primitive recursive]]. The result follows. {{qed}} [[Category:Primitive Recursive Functions]] r4rtulcl7hz4vjh4k8lh3amsarwife2	1
{{begin-eqn}} {{eqn | l = p \iff q | o = \dashv \vdash | r = \neg \paren {p \oplus q} | c = [[Exclusive Or is Negation of Biconditional]] }} {{eqn | o = \dashv \vdash | r = \neg \paren {\paren {p \lor q} \land \neg \paren {p \land q} } | c = {{Defof|Exclusive Or}} }} {{eqn | o = \dashv \vdash | r = \neg \paren {\paren {p \lor q} \land \paren {p \uparrow q} } | c = {{Defof|Logical NAND}} }} {{eqn | o = \dashv \vdash | r = \neg \paren {\paren {\paren {p \uparrow p} \uparrow \paren {q \uparrow q} } \land \paren {p \uparrow q} } | c = [[Disjunction in terms of NAND]] }} {{eqn | o = \dashv \vdash | r = \paren {\paren {p \uparrow p} \uparrow \paren {q \uparrow q} } \uparrow \paren {p \uparrow q} | c = {{Defof|Logical NAND}} }} {{end-eqn}} {{qed}}	1
Firstly, we will prove that $\displaystyle \frac {\sin z} z = \paren {\frac {2^n} z} \sin \frac z {2^n} \prod_{i \mathop = 1}^n \cos \frac z {2^i}$, where $n \in \N$. Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \N$, let $\map P n$ be the [[Definition:Proposition|proposition]]: : $\displaystyle \frac {\sin z} z = \paren {\frac {2^n} z} \sin \frac z {2^n} \prod_{i \mathop = 1}^n \cos \frac z {2^i}$ === Basis for the Induction === $\map P 1$ is true, as this says $\displaystyle \frac {\sin z} z = \frac {\sin z} z$. This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 0$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\displaystyle \frac {\sin z} z = \paren {\frac {2^k} z} \sin \frac z {2^k} \prod_{i \mathop = 1}^k \cos \frac z {2^i}$ Then we need to show: :$\displaystyle \frac {\sin z} z = \paren {\frac {2^{k + 1} } z} \sin \frac z {2^{k + 1} } \prod_{i \mathop = 1}^{k + 1} \cos \frac z {2^i}$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \frac {\sin z} z | r = \paren {\frac {2^k} z} \sin \frac z {2^k} \prod_{i \mathop = 1}^k \cos \frac z {2^i} | c = [[Sine of X over X as Infinite Product#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \paren {\frac {2^k} z} \paren {2 \sin \frac z {2^{k + 1} } \cos \frac z {2^{k + 1} } } \prod_{i \mathop = 1}^k \cos \frac z {2^i} | c = [[Double Angle Formulas/Sine|Double Angle Formula for Sine]] }} {{eqn | r = \paren {\frac {2^{k + 1} } z} \sin \frac z {2^{k + 1} } \cos \frac z {2^{k + 1} } \prod_{i \mathop = 1}^k \cos \frac z {2^i} | c = }} {{eqn | r = \paren {\frac {2^{k + 1} } z} \sin \frac z {2^{k + 1} } \prod_{i \mathop = 1}^{k + 1} \cos \frac z {2^i} | c = }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\displaystyle \frac {\sin z} z = \paren {\frac {2^n} z} \sin \frac z {2^n} \prod_{i \mathop = 1}^n \cos \frac z {2^i}$ And then: {{begin-eqn}} {{eqn | l = \frac {\sin z} z | r = \lim_{n \mathop \to \infty} \paren {\frac {2^n} z} \paren {\sin \frac z {2^n} } \prod_{i \mathop = 1}^n \cos \frac z {2^i} | c = }} {{eqn | r = \paren {\lim_{n \mathop \to \infty} \paren {\frac {2^n} z} \paren {\sin \frac z {2^n} } } \prod_{i \mathop = 1}^{\infty} \cos \frac z {2^i} | c = }} {{eqn | r = \paren 1 \prod_{i \mathop = 1}^\infty \cos \frac z {2^i} | c = [[Limit of Sine of X over X]] }} {{eqn | r = \prod_{i \mathop = 1}^\infty \cos \frac z {2^i} | c = }} {{end-eqn}} {{qed}}	1
These [[Definition:Set|sets]] of [[Definition:Logical Connective|logical connectives]] are [[Definition:Functionally Complete|functionally complete]]:	1
:$p \iff \top \dashv \vdash p$	1
Let $C$ be a [[Definition:Linear Code|linear code]]. Let $C$ have a [[Definition:Minimum Distance of Linear Code|minimum distance]] $d$. Then $C$ detects $d - 1$ or fewer [[Definition:Transmission Error|transmission errors]].	1
The [[Definition:Unlimited Register Machine#State|state]] of a [[Definition:URM Program|URM program]] at a particular point in time is defined as: : the value of the [[Definition:Unlimited Register Machine#Instruction Pointer|instruction pointer]] : the value, at that point, of each of the [[Definition:Unlimited Register Machine#Registers|registers]] that are used by the program. Let $P$ be a [[Definition:URM Program|URM program]]. Suppose that, at a given [[Definition:Unlimited Register Machine#Stage of Computation|stage of computation]]: : the value of the [[Definition:Unlimited Register Machine#Instruction Pointer|instruction pointer]] is $a$; : the value of [[Definition:Unlimited Register Machine#Registers|register]] $R_k$ is $r_k$. Let $b = \rho \left({P}\right)$ be the [[Definition:Unlimited Register Machine#Number of Registers Used|number of registers used]] by $P$. Then we can define the '''state code''' $s$ as: :$s = p_1^a p_2^{r_1} p_3^{r_2} \cdots p_{b+1}^{r_b}$ where $p_j = p \left({j}\right)$ is defined as the [[Definition:Prime Enumeration Function|$j$th prime number]]. Hence it follows from the [[Fundamental Theorem of Arithmetic]] that $s$ is uniquely specified for any given [[Definition:Unlimited Register Machine#State|state]]. {{qed}}	1
Let $\mathbf A$ be a [[Definition:WFF of Predicate Logic|WFF of predicate logic]]. Let $\mathbf B, \mathbf B'$ be [[Definition:Universal Closure of Well-Formed Formula|universal closures]] of $\mathbf A$. Then $\mathbf B$ and $\mathbf B'$ are [[Definition:Semantic Equivalence (Predicate Logic)|semantically equivalent]].	1
Let $p$ be a [[Definition:Propositional Formula|propositional formula]]. Let $v$ be an arbitrary [[Definition:Boolean Interpretation|boolean interpretation]] of $p$. Then: :$\map v p = T \iff \map v {\neg p} = F$ by the definition of the [[Definition:Logical Not|logical not]]. Since $v$ is arbitrary, $p$ is [[Definition:True|true]] in all [[Definition:Boolean Interpretation|interpretations]] {{iff}} $\neg p$ is [[Definition:False|false]] in all [[Definition:Boolean Interpretation|interpretations]]. Hence: :$\top \dashv \vdash \neg \bot$ {{qed}}	1
The proof proceeds by [[Principle of Mathematical Induction|induction]]. For all $n \in \Z_{\ge 0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\size {K_n} = \dfrac {n \paren {n - 1} } 2$ First we explore the [[Definition:Degenerate Case|degenerate case]] $\map P 0$: {{begin-eqn}} {{eqn | l = \size {K_0} | r = 0 | c = as $K_0$ is the [[Definition:Null Graph|null graph]] }} {{eqn | r = \dfrac {0 \paren {0 - 1} } 2 | c = }} {{end-eqn}} Thus $\map P 0$ is seen to hold. === Basis for the Induction === $\map P 1$ is the case: {{begin-eqn}} {{eqn | l = \size {K_1} | r = 0 | c = [[Complete Graph of Order 1 is Edgeless]] }} {{eqn | r = \dfrac {1 \paren {1 - 1} } 2 | c = }} {{end-eqn}} Thus $\map P 1$ is seen to hold. This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is the [[Definition:Induction Hypothesis|induction hypothesis]]: :$\size {K_k} = \dfrac {k \paren {k - 1} } 2$ from which it is to be shown that: :$\size {K_{k + 1} } = \dfrac {\paren {k + 1} k} 2$ === Induction Step === This is the [[Definition:Induction Step|induction step]]: Let $K_{k + 1}$ be constructed by adding a new [[Definition:Vertex of Graph|vertex]] $v_{k + 1}$ to the [[Definition:Complete Graph|complete graph]] $K_k$. To do so, it is necessary to add an [[Definition:Edge of Graph|edge]] to [[Definition:Join (Graph Theory)|join]] $v_{k + 1}$ to every [[Definition:Vertex of Graph|vertex]] of $K_k$. Thus there are a total of $k$ [[Definition:Edge of Graph|edges]] more in $K_{k + 1}$ than there are in $K_k$. So: {{begin-eqn}} {{eqn | l = \size {K_{k + 1} } | r = \size {K_k} + k | c = from the above analysis }} {{eqn | r = \dfrac {k \paren {k - 1} } 2 + k | c = [[Size of Complete Graph#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \dfrac {k^2 - k + 2 k} 2 | c = }} {{eqn | r = \dfrac {k^2 + k} 2 | c = }} {{eqn | r = \dfrac {\paren {k + 1} k} 2 | c = }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\forall n \in \Z_{\ge 0}: \size {K_n} = \dfrac {n \paren {n - 1} } 2$ {{qed}} [[Category:Complete Graphs]] [[Category:Proofs by Induction]] 4tr8m4mditkjcw3gxkmd1g28qg49b7o	1
For each $n$, let $\mathbf A_n$ be the formula: :$\exists x_1 \exists x_2 \ldots \exists x_n: \left({x_1 \ne x_2 \land x_1 \ne x_3 \land \ldots \land x_{n-1} \ne x_n }\right)$ Then $\mathbf A_i$ is true in a [[Definition:First-Order Structure|structure]] $\mathcal A$ {{iff}} $\mathcal A$ has at least $n$ elements. Take: : $\displaystyle \Gamma := A \cup \bigcup_{i \mathop = 1}^\infty A_i$ Since $F$ has [[Definition:Model (Predicate Logic)|models]] of arbitrarily large size, every [[Definition:Finite Set|finite]] [[Definition:Subset|subset]] of $\Gamma$ is [[Definition:Satisfiable Set of Formulas|satisfiable]]. From the [[Compactness Theorem]], $\Gamma$ is satisfiable in some [[Definition:Model (Predicate Logic)|model]] $\mathcal M$. But since $\mathcal M \models A_i$ for each $i$, $\mathcal M$ must be infinite. So $A$ has an [[Definition:Infinite|infinite]] [[Definition:Model (Predicate Logic)|model]]. {{qed}}	1
: $\left ({p \dashv \vdash q}\right) \vdash \left ({p \iff q}\right)$	1
Let $n = \left({n_1, n_2, \ldots, n_{i-1}, n_i \ldots, n_k}\right)$. We see that: :$g \left({n_1, n_2, \ldots, n_k}\right) = f \left({\operatorname{pr}^k_1 \left({n}\right), \operatorname{pr}^k_2 \left({n}\right), \ldots, \operatorname{pr}^k_{i-1} \left({n}\right), f_a \left({n}\right), \operatorname{pr}^k_i \left({n}\right), \ldots, \operatorname{pr}^k_k \left({n}\right)}\right)$ We have that: * $\operatorname{pr}^k_j$ is a [[Definition:Basic Primitive Recursive Function/Projection Function|basic primitive recursive function]] for all $j$ such that $1 \ne j \le k$ * [[Constant Function is Primitive Recursive|$f_a$ is a primitive recursive function]]. So $g$ is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from [[Definition:Primitive Recursive Function|primitive recursive functions]] and so is [[Definition:Primitive Recursive Function|primitive recursive]]. {{qed}} [[Category:Primitive Recursive Functions]] d9j44atmv91ffg8o7430zpvybkrx5pk	1
{{BeginTableau|\vdash \paren {\paren {p \implies q} \land p} \implies q}} {{Assumption|1|\paren {p \implies q} \land p}} {{Simplification|2|1|p \implies q|1|1}} {{Simplification|3|1|p|1|2}} {{ModusPonens|4|1|q|2|3}} {{Implication|5||\paren {\paren {p \implies q} \land p} \implies q|1|4}} {{EndTableau}} {{Qed}}	1
{{BeginTableau|\vdash \left({\neg \left({p \implies q}\right)}\right) \implies \left({p \land \neg q}\right)}} {{Assumption|1|\neg \left({p \implies q}\right)}} {{SequentIntro|2|1|p \land \neg q|1|[[Conjunction with Negative Equivalent to Negation of Implication/Formulation 1/Reverse Implication|Conjunction with Negative Equivalent to Negation of Implication: Formulation 1]]}} {{Implication|3||\left({\neg \left({p \implies q}\right)}\right) \implies \left({p \land \neg q}\right)|1|2}} {{EndTableau}} {{qed}} {{LEM|Conjunction with Negative Equivalent to Negation of Implication/Formulation 1/Reverse Implication}} [[Category:Conjunction with Negative Equivalent to Negation of Implication]] sbryqpjb0wps953pi6kun8dd03dtd07	1
: $\neg p \vdash p \implies q$	1
Let $Q$ be a [[Definition:Valid Argument|valid]] [[Definition:Categorical Syllogism|categorical syllogism]]. Let one of the [[Definition:Premise of Syllogism|premises]] of $Q$ be [[Definition:Particular Categorical Statement|particular]]. Then the [[Definition:Conclusion of Syllogism|conclusion]] of $Q$ is also [[Definition:Particular Categorical Statement|particular]].	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|cccc||ccccccccc|} \hline \neg & (p & \iff & q) & (p & \lor & q) & \land & (\neg & p & \lor & \neg & q) \\ \hline F & F & T & F & F & F & F & F & T & F & T & T & F \\ T & F & F & T & F & T & T & T & T & F & T & F & T \\ T & T & F & F & T & T & F & T & F & T & T & T & F \\ F & T & T & T & T & T & T & F & F & T & F & F & T \\ \hline \end{array}$ {{qed}}	1
:$p \implies q \vdash \paren {p \lor r} \implies \paren {q \lor r}$	1
Let $\Z_{\ge n_0} := \set {n \in \Z: n \ge n_0}$. {{AimForCont}} $S \ne \Z_{\ge n_0}$. Let $S' = \Z_{\ge n_0} \setminus S$. Because $S \ne \Z_{\ge n_0}$ and $S \subseteq \Z_{\ge n_0}$, we have that $S' \ne \O$. By definition, $\Z_{\ge n_0}$ is [[Definition:Bounded Below Set|bounded below]] by $n_0$. From [[Set of Integers Bounded Below by Integer has Smallest Element]], $S'$ has a [[Definition:Minimal Element|minimal element]]. Let $k$ be this [[Definition:Minimal Element|minimal element]] of $S'$. By $(1)$ we have that: :$n_0 \in S$ and so: :$n_0 \notin S'$ Hence: :$k \ne n_0$ and so: :$k > n_0$ It follows that: :$k - 1 \le n_0$ Because $k$ is the [[Definition:Minimal Element|minimal element]] of $S'$: :$k - 1 \notin S'$ and so: :$k - 1 \in S$ But by $(2)$: :$\paren {k - 1} + 1 = k \in S$ So we have: :$k \in S$ and: :$k \notin S$ Hence by [[Proof by Contradiction]] $S = \Z_{\ge n_0}$. {{qed}}	1
An '''[[Definition:Axiom|axiom]]''' is also known as a '''[[Definition:Postulate|postulate]]'''. Among ancient Greek philosophers, the term '''axiom''' was used for a general truth that was common to everybody (see [[Axiom:Euclid's Common Notions|Euclid's "common notions"]]), while '''postulate''' had a specific application to the subject under discussion. For most authors, the distinction is no longer used, and the terms are generally used interchangeably. This is the position of {{ProofWiki}}. However, some believe there is a difference significant enough to matter: :''... we shall use "postulate" instead of "axiom" hereafter, as "axiom" has a pernicious historical association of "self-evident, necessary truth", which "postulate" does not have; a postulate is an arbitrary assumption laid down by the mathematician himself and not by God Almighty.'' :::: -- {{BookReference|Men of Mathematics|1937|Eric Temple Bell}}: Chapter $\text{II}$: Modern Minds in Ancient Bodies	1
{{questionable|This only takes on board a subset of $\N$, where we need a subset of $\Z$}} Consider $\N$ defined as a [[Definition:Naturally Ordered Semigroup|naturally ordered semigroup]]. The result follows directly from [[Principle of Mathematical Induction for Naturally Ordered Semigroup/General Result|Principle of Mathematical Induction for Naturally Ordered Semigroup: General Result]]. {{qed}}	1
Let $\mathscr M$ be a [[Definition:Formal Semantics|formal semantics]] for a [[Definition:Formal Language|formal language]] $\mathcal L$. Let $\phi, \psi$ be $\mathcal L$-[[Definition:Well-Formed Formula|WFFs]]. Then $\phi$ and $\psi$ are $\mathscr M$-'''semantically equivalent''' {{iff}}: :$\phi \models_{\mathscr M} \psi$ and $\psi \models_{\mathscr M} \phi$ that is, [[Definition:Iff|iff]] they are $\mathscr M$-[[Definition:Semantic Consequence|semantic consequences]] of one another.	1
: $\left({p \implies q}\right) \land \left({p \implies r}\right) \vdash p \implies \left({q \land r}\right)$	1
:$\left({\left({p \implies r}\right) \lor \left({q \implies r}\right)}\right) \iff \left({\left({p \land q}\right) \implies r}\right)$	1
{{BeginTableau|\bot \vdash \neg \top}} {{Premise|1|\bot}} {{Assumption|2|\top}} {{Explosion|3|1|\neg \top|1|Any statement we want}} {{Contradiction|4|1|\bot|2|3}} {{Explosion|5|1|\neg \top|4}} {{EndTableau|lemma}} {{BeginTableau|\neg \top \vdash \bot}} {{Premise|1|\neg \top}} {{ExcludedMiddle|2|p \lor \neg p|From the Law of Excluded Middle ...}} {{ExcludedMiddle|3|\top|... we deduce that truth ...}} {{NonContradiction|4|1|1|3| ... is contrary to the assumption of non-truth, which must therefore be false}} {{EndTableau|qed}}	1
=== [[Biconditional Elimination/Sequent Form/Proof 1/Form 1|Form 1]] === {{:Biconditional Elimination/Sequent Form/Proof 1/Form 1}} === [[Biconditional Elimination/Sequent Form/Proof 1/Form 2|Form 2]] === {{:Biconditional Elimination/Sequent Form/Proof 1/Form 2}}	1
:$F_{m n + 1} \equiv \paren {\begin{cases} F_1 & : m \bmod 4 = 0 \\ F_{n - 1} & : m \bmod 4 = 1 \\ \paren {-1}^n F_1 & : m \bmod 4 = 2 \\ \paren {-1}^n F_{n - 1} & : m \bmod 4 = 3 \end{cases} } \pmod {F_n}$	1
{{begin-eqn}} {{eqn | l = a | r = a \vee \bot | c = $\bot$ is the [[Definition:Identity Element|identity]] for $\vee$ }} {{eqn | r = a \vee \left({c \wedge \neg c}\right) | c = [[Definition:Boolean Algebra/Axioms/Definition 1|Boolean Algebra: Axiom $(BA_1 \ 4)$]] }} {{eqn | r = \left({a \vee c}\right) \wedge \left({a \vee \neg c}\right) | c = $\vee$ [[Definition:Distributive Operation|distributes]] over $\wedge$ }} {{eqn | r = \left({b \vee c}\right) \wedge \left({b \vee \neg c}\right) | c = by hypothesis }} {{eqn | r = b \vee \left({c \wedge \neg c}\right) | c = $\vee$ [[Definition:Distributive Operation|distributes]] over $\wedge$ }} {{eqn | r = b \vee \bot | c = [[Definition:Boolean Algebra/Axioms/Definition 1|Boolean Algebra: Axiom $(BA_1 \ 4)$]] }} {{eqn | r = b | c = $\bot$ is the [[Definition:Identity Element|identity]] for $\vee$ }} {{end-eqn}} Hence the result. {{qed}}	1
{{BeginTableau|\neg \left ({p \iff q}\right) \vdash \neg \left({p \implies q}\right) \lor \neg \left({q \implies p}\right)}} {{Premise|1|\neg \left ({p \iff q}\right)}} {{SequentIntro|2|1|\neg \left({\left ({p \implies q}\right) \land \left ({q \implies p}\right)}\right)|1 |[[Rule of Material Equivalence]]}} {{DeMorgan|3|1|\neg \left({p \implies q}\right) \lor \neg \left({q \implies p}\right)|2|Disjunction of Negations}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|\neg \left({p \implies q}\right) \lor \neg \left({q \implies p}\right) \vdash \neg \left ({p \iff q}\right)}} {{Premise|1|\neg \left({p \implies q}\right) \lor \neg \left({q \implies p}\right)}} {{DeMorgan|2|1|\neg \left({\left ({p \implies q}\right) \land \left ({q \implies p}\right)}\right)|1|Disjunction of Negations}} {{SequentIntro|3|1|\neg \left ({p \iff q}\right)|2|[[Rule of Material Equivalence]]}} {{EndTableau}} {{qed}}	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, in each case, the [[Definition:Truth Value|truth values]] in the appropriate columns match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c|ccc||c|ccc|} \hline \bot & p & p & \lor & \bot \\ \hline F & F & F & F & F \\ F & T & T & T & F \\ \hline \end{array}$ {{qed}}	1
{{handwaving}} By the [[Definition:Definitional Abbreviation|definitional abbreviation]] for the [[Definition:Conditional|conditional]]: :$\mathbf A \implies \mathbf B =_{\text{def}} \neg \mathbf A \lor \mathbf B$ the [[Rule of Commutation/Disjunction/Formulation 2/Forward Implication|Rule of Commutation]] can be written as: :$\neg \left({p \lor q}\right) \lor \left({q \lor p}\right)$ This evaluates as follows: :$\begin{array}{|cccc|c|ccc|} \hline \neg & (p & \lor & q) & \lor & (q & \lor & p) \\ \hline 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 \\ 1 & 0 & 0 & 2 & 0 & 2 & 0 & 0 \\ 1 & 1 & 0 & 0 & 0 & 0 & 0 & 1 \\ 0 & 1 & 1 & 1 & 0 & 1 & 1 & 1 \\ 2 & 1 & 2 & 2 & 0 & 2 & 2 & 1 \\ 1 & 2 & 0 & 0 & 0 & 0 & 0 & 2 \\ 2 & 2 & 2 & 1 & 0 & 1 & 2 & 2 \\ 1 & 2 & 0 & 2 & 0 & 2 & 0 & 2 \\ \hline \end{array}$ {{qed}}	1
{{BeginTableau| \vdash ((p \land q) \lor (\lnot p \land q)) \lor ( (p \land \lnot q) \lor (\lnot p \land \lnot q)) }} {{ExcludedMiddle|1|p \lor \lnot p}} {{ExcludedMiddle|2|q \lor \lnot q}} {{Conjunction|3||(p \lor \lnot p) \land (q \lor \lnot q)|1|2}} {{SequentIntro|4||((p \lor \lnot p) \land q) \lor ((p \lor \lnot p) \land \lnot q)|3|[[Rule of Distribution/Conjunction Distributes over Disjunction/Left Distributive/Formulation 1|Conjunction Distributes over Disjunction]]}} {{Assumption|5|(p \lor \lnot p) \land q}} {{SequentIntro|6|5|(p \land q) \lor (\lnot p \land q)|5|[[Rule of Distribution/Conjunction Distributes over Disjunction/Right Distributive/Formulation 1|Conjunction Distributes over Disjunction]]}} {{Implication|7||(p \lor \lnot p) \land q \implies (p \land q) \lor (\lnot p \land q)|5|6 }} {{Assumption|8|(p \lor \lnot p) \land \lnot q}} {{SequentIntro|9|8| (p \land \lnot q) \lor (\lnot p \land \lnot q)|8| [[Rule of Distribution/Conjunction Distributes over Disjunction/Right Distributive/Formulation 1|Conjunction Distributes over Disjunction]] }} {{Implication|10|| (p \lor \lnot p) \land \lnot q \implies (p \land \lnot q) \lor (\lnot p \land \lnot q)|8|9}} {{SequentIntro|11|| ((p \lor \lnot p) \land q) \lor ((p \lor \lnot p) \land \lnot q) \implies ((p \land q) \lor (\lnot p \land q)) \lor ( (p \land \lnot q) \lor (\lnot p \land \lnot q))|7,10|[[Constructive Dilemma/Formulation 1|Constructive Dilemma]]}} {{ModusPonens|12|| ((p \land q) \lor (\lnot p \land q)) \lor ( (p \land \lnot q) \lor (\lnot p \land \lnot q))|11|4 }} {{EndTableau}} {{qed}} {{LEM}} [[Category:Propositional Logic]] 48jjx3jhedwa77osqylwqo68vmo427a	1
Let $\struct {S, \vee, \wedge, \neg}$ be a [[Definition:Boolean Algebra/Definition 1|Boolean algebra, defined as in Definition 1]]. Then: :$\forall a, b, c \in S: \paren {a \wedge b} \wedge c = a \wedge \paren {b \wedge c}$ :$\forall a, b, c \in S: \paren {a \vee b} \vee c = a \vee \paren {b \vee c}$ That is, both $\vee$ and $\wedge$ are [[Definition:Associative Operation|associative operations]].	1
: $\left\{{\neg, \land, \lor, \implies}\right\}$: [[Definition:Logical Not|Not]], [[Definition:Conjunction|And]], [[Definition:Disjunction|Or]] and [[Definition:Conditional|Implies]]	1
Let $\mathbf H'$ be another [[Definition:Finite Set|finite set]] of [[Definition:WFF of Propositional Logic|WFFs]]. Then there exists a [[Definition:Finished Propositional Tableau|finished]] [[Definition:Finite Propositional Tableau|finite propositional tableau]] $T'$ such that: $(1):\quad$ the [[Definition:Root of Propositional Tableau|root]] of $T'$ is $\mathbf H \cup \mathbf H'$; $(2):\quad$ $T$ is a [[Definition:Rooted Subtree|rooted subtree]] of $T'$.	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, the [[Definition:Truth Value|truth values]] in the appropriate columns match. $\begin{array}{|c||cc|} \hline \bot & \neg & \top \\ \hline F & F & T \\ \hline \end{array}$ {{qed}}	1
The [[Definition:Projection Function|projection functions]] are computed by the following [[Definition:URM Program|URM program]]: {| |- ! align="right" | Line !! ! align="left" | Command |- | align="right" | $1$ || | align="left" | $\map C {j, 1}$ |} The [[Definition:Unlimited Register Machine#Input|input]] $\tuple {n_1, n_2, \ldots, n_j, \ldots, n_k}$ is in $R_1, R_2, \ldots, R_j, \ldots, R_k$ when the program starts. The program copies $r_j$ to $r_1$ and then stops. The [[Definition:Unlimited Register Machine#Output|output]] $n_j$ is in $R_1$ when the program terminates. {{qed}} [[Category:URM Programs]] [[Category:Primitive Recursive Functions]] d2vaqix20wd0djv8t6s5w14bb7z4trw	1
We note that: :$1 \mathop {\dot -} n = \begin{cases} 1 & : n = 0 \\ 0 & : n > 0 \end{cases}$ and so the [[Definition:Characteristic Function of Set|characteristic function]] $\chi_{\left\{{0}\right\}}$ is given by $\chi_{\left\{{0}\right\}} \left({n}\right) = 1 \mathop {\dot -} n$. So $\chi_{\left\{{0}\right\}}$ is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from the [[Cut-Off Subtraction is Primitive Recursive|primitive recursive function $1 \mathop {\dot -} n$]] using [[Constant Function is Primitive Recursive|constants, which are primitive recursive]]. Hence the result. {{qed}} [[Category:Primitive Recursive Functions]] 89z90wvo7yu203urczj8d1365qzgprg	1
Let $P$ be a [[Definition:Propositional Function|propositional function]] on the [[Definition:Natural Numbers|natural numbers]] $\N$. Suppose that: :$(1): \quad \forall n \in \N: \map P {2^n}$ holds. :$(2): \quad \map P n \implies \map P {n - 1}$. Then $\map P n$ holds for all $\forall n \in \N$. The proof technique based on this result is called '''backwards induction'''.	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] is [[Definition:True|true]] for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc|c|ccccccc|} \hline (p & \implies & (q & \land & r)) & \iff & ((p & \implies & q) & \land & (p & \implies & r)) \\ \hline F & T & F & F & F & T & F & T & F & T & F & T & F \\ F & T & F & F & T & T & F & T & F & T & F & T & T \\ F & T & T & F & F & T & F & T & T & T & F & T & F \\ F & T & T & T & T & T & F & T & T & T & F & T & T \\ T & F & F & F & F & T & T & F & F & F & T & F & F \\ T & F & F & F & T & T & T & F & F & F & T & T & T \\ T & F & T & F & F & T & T & T & T & F & T & F & F \\ T & T & T & T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
Let $\LL$ be the [[Definition:Language of Predicate Logic|language of predicate logic]]. Let $T$ be a set of $\LL$-[[Definition:Sentence|sentences]]. Then $T$ is [[Definition:Satisfiable Set of Formulas|satisfiable]] {{iff}} $T$ is [[Definition:Finitely Satisfiable|finitely satisfiable]].	1
By calculation: {{begin-eqn}} {{eqn | l=p \land \left({p \lor q}\right) | r=\left({p \lor \bot}\right) \land \left({p \lor q}\right) | c=[[Disjunction with Contradiction]] }} {{eqn | r=p \lor \left({\bot \land q}\right) | c=[[Disjunction is Left Distributive over Conjunction]] }} {{eqn | r=p \lor \bot | c=[[Conjunction with Contradiction]] }} {{eqn | r=p | c=[[Disjunction with Contradiction]] }} {{end-eqn}} {{qed}}	1
{{BeginTableau|\left({p \implies q}\right) \land \left({p \implies r}\right) \vdash p \implies \left({q \land r}\right)}} {{Premise|1|\left({p \implies q}\right) \land \left({p \implies r}\right)}} {{SequentIntro|2|1|\left({p \land p}\right) \implies \left({q \land r}\right)|1|[[Praeclarum Theorema]]}} {{Assumption|3|p}} {{Idempotence|4|3|p \land p|3|Conjunction}} {{ModusPonens|5|1, 3|q \land r|2|4}} {{Implication|6|1|p \implies \left({q \land r}\right)|3|5}} {{EndTableau}} {{qed}}	1
{{BeginTableau|\bot \vdash \neg \top}} {{Premise|1|\bot}} {{Assumption|2|\top}} {{Explosion|3|1|\neg \top|1|Any statement we want}} {{Contradiction|4|1|\bot|2|3}} {{Explosion|5|1|\neg \top|4}} {{EndTableau|lemma}} {{BeginTableau|\neg \top \vdash \bot}} {{Premise|1|\neg \top}} {{ExcludedMiddle|2|p \lor \neg p|From the Law of Excluded Middle ...}} {{ExcludedMiddle|3|\top|... we deduce that truth ...}} {{NonContradiction|4|1|1|3| ... is contrary to the assumption of non-truth, which must therefore be false}} {{EndTableau|qed}}	1
:$\vdash p \land q \implies p$	1
{{BeginTableau|\vdash \paren {p \iff q} \iff \paren {\paren {p \land q} \lor \paren {\neg p \land \neg q} } }} {{Assumption |1|p \iff q}} {{SequentIntro |2|1|\paren {p \land q} \lor \paren {\neg p \land \neg q}|1|[[Biconditional as Disjunction of Conjunctions/Formulation 1|Biconditional as Disjunction of Conjunctions: Formulation 1]]}} {{Implication |3| |\paren {p \iff q} \implies \paren {\paren {p \land q} \lor \paren {\neg p \land \neg q} }|1|2}} {{Assumption |4|\paren {p \land q} \lor \paren {\neg p \land \neg q} }} {{SequentIntro |5|4|p \iff q|4|[[Biconditional as Disjunction of Conjunctions/Formulation 1|Biconditional as Disjunction of Conjunctions: Formulation 1]]}} {{Implication |6| |\paren {\paren {p \land q} \lor \paren {\neg p \land \neg q} } \implies \paren {p \iff q}|4|5}} {{BiconditionalIntro|7| |\paren {p \iff q} \iff \paren {\paren {p \land q} \lor \paren {\neg p \land \neg q} }|3|6}} {{EndTableau}} {{qed}}	1
Let $T$ be an $\LL$-[[Definition:Theory (Logic)|theory]]. Let $\kappa$ be an [[Definition:Infinite|infinite]] [[Definition:Cardinal|cardinal]]. If $\MM$ and $\NN$ are [[Definition:Saturated Model|saturated models]] of $T$ and the [[Definition:Cardinality|cardinality]] of the universes of $\MM$ and $\NN$ are both $\kappa$, then $\MM$ and $\NN$ are [[Definition:Isomorphism (Model Theory)|isomorphic]].	1
==== [[Conjunction with Negative Equivalent to Negation of Implication/Formulation 1|Formulation 1]] ==== {{:Conjunction with Negative Equivalent to Negation of Implication/Formulation 1}} ==== [[Conjunction with Negative Equivalent to Negation of Implication/Formulation 2|Formulation 2]] ==== {{:Conjunction with Negative Equivalent to Negation of Implication/Formulation 2}}	1
{{BeginTableau|\neg \left({ p \downarrow \left({q \downarrow r}\right) \implies \left({p \downarrow q}\right) \downarrow r }\right)}} {{Assumption|1|\neg p \land r}} {{Simplification|2|1|\neg p|1|1}} {{Simplification|3|1|r|1|2}} {{Addition|4|1|q \lor r|3|2}} {{DoubleNegIntro|5|1|\neg \neg \left({q \lor r}\right)|4}} {{SequentIntro|6|1|\neg \left({q \downarrow r}\right)|5|Definition of [[Definition:Logical NOR|Logical NOR]]}} {{Conjunction|7|1|\neg p \land \neg \left({q \downarrow r}\right)|2|6}} {{DeMorgan|8|1|\neg \left({p \lor \left({q \downarrow r}\right) }\right)|7|Conjunction of Negations}} {{SequentIntro|9|1|p \downarrow \left({q \downarrow r}\right)|8|Definition of [[Definition:Logical NOR|Logical NOR]]}} {{Addition|10|1|\left({p \downarrow q}\right) \lor r|3|2}} {{DoubleNegIntro|11|1|\neg \neg \left({\left({p \downarrow q}\right) \lor r}\right)|10}} {{SequentIntro|12|1|\neg \left({\left({p \downarrow q}\right) \downarrow r}\right)|11|Definition of [[Definition:Logical NOR|Logical NOR]]}} {{DoubleNegIntro|13|1|\neg \neg \left({p \downarrow \left({q \downarrow r}\right)}\right)|9}} {{Conjunction|14|1|\left({\neg \neg \left({p \downarrow \left({q \downarrow r}\right)}\right)}\right) \land \left({\neg \left({\left({p \downarrow q}\right) \downarrow r}\right)}\right)|13|12}} {{DeMorgan|15|1|\neg \left({\neg \left({p \downarrow \left({q \downarrow r}\right)}\right) \lor \left({\left({p \downarrow q}\right) \downarrow r}\right)}\right)|14|Conjunction of Negations}} {{SequentIntro|16|1 |\neg \left({ p \downarrow \left({q \downarrow r}\right) \implies \left({p \downarrow q}\right) \downarrow r }\right) |15 |[[Rule of Material Implication]] }} {{EndTableau}} Taking $p = \bot$ and $r = \top$, we have $\vdash \neg p \land r$, discharging the last assumption. Hence the result. {{qed}}	1
:$p \lor q \dashv \vdash \paren {p \uparrow p} \uparrow \paren {q \uparrow q}$ where $\lor$ denotes [[Definition:Disjunction|logical disjunction]] and $\uparrow$ denotes [[Definition:Logical NAND|logical NAND]].	1
{{BeginTableau|p \implies \left({p \lor q}\right)|[[Definition:Hilbert Proof System/Instance 2|Instance 2 of the Hilbert-style systems]]}} {{TableauLine |n = 1 |f = q \implies \paren{ p \lor q } |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Axiom $A2$ }} {{TableauLine |n = 2 |f = p \implies \paren{ q \lor p } |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 1$ |dep = 1 |c = $p \,/\, q, q \,/\, p$ }} {{TableauLine |n = 3 |f = \paren{ p \lor q } \implies \paren{ q \lor p } |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Axiom $A3$ }} {{TableauLine |n = 4 |f = \paren{ q \lor p } \implies \paren{ p \lor q } |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 1$ |dep = 3 |c = $p \,/\, q, q \,/\, p$ }} {{TableauLine |n = 5 |f = p \implies \paren{ p \lor q } |rlnk = Hypothetical Syllogism/Formulation 1/Proof 3 |rtxt = Hypothetical Syllogism |dep = 2,4 }} {{EndTableau}} {{Qed}}	1
Let $F$ be a [[Definition:Field (Abstract Algebra)|field]]. Let $\tuple {a_0, a_1, \ldots, a_n}$ be a [[Definition:Finite Continued Fraction|finite continued fraction]] of [[Definition:Length of Continued Fraction|length]] $n \ge 0$. Let $p_n$ and $q_n$ be its $n$th [[Definition:Numerator and Denominator of Continued Fraction|numerator and denominator]]. Then the [[Definition:Value of Continued Fraction|value]] $\sqbrk {a_0, a_1, \ldots, a_n}$ equals $\dfrac {p_n} {q_n}$.	1
The '''(rule of the) hypothetical syllogism''' is a [[Definition:Valid Argument|valid]] deduction [[Definition:Sequent|sequent]] in [[Definition:Propositional Logic|propositional logic]]: :If we can conclude that $p$ implies $q$, and if we can also conclude that $q$ implies $r$, then we may infer that $p$ implies $r$.	1
Let the [[Definition:Function|function]] $f: \N^{k+1} \to \N$ be a [[Definition:URM Computability|URM computable function]]. Let $g: \N^k \to \N$ be the [[Definition:Function|function]] obtained by [[Definition:Minimization|minimization]] from $f$ thus: :$g \left({n_1, n_2, \ldots, n_k}\right) \approx \mu y \left({f \left({n_1, n_2, \ldots, n_k}\right) = 0}\right)$. Then $g$ is also [[Definition:URM Computability|URM computable]].	1
Let $p \implies q$ be a [[Definition:Conditional|conditional]]. Then the [[Definition:Converse Statement|converse]] of $p \implies q$ is the [[Definition:Inverse Statement|inverse]] of its [[Definition:Contrapositive Statement|contrapositive]].	1
Because $f = \map \OO g$ and $g = \map \OO h$, there exist [[Definition:Neighborhood of Point in Topological Space|neighborhoods]] $U$ and $V$ of $x_0$ and [[Definition:Real Number|real numbers]] $c, d \ge 0$ such that: :$\norm {\map f x} \le c \cdot \norm {\map g x}$ for all $x \in U$ :$\norm {\map g x} \le d \cdot \norm {\map h x}$ for all $x \in V$. By [[Intersection of Neighborhoods in Topological Space is Neighborhood]], $U\cap V$ is a [[Definition:Neighborhood of Point in Topological Space|neighborhood]] of $x_0$. For $x \in U \cap V$, we have: :$\norm {\map f x} \le c \cdot \norm {\map g x} \le c d \cdot \norm {\map h x}$ Thus $f = \map \OO h$ for $x \to x_0$. {{qed}} [[Category:Asymptotic Notation]] 2q0vllwo8bhm4dwet2s8v688obgsd8e	1
First we note that, from the [[Law of Identity]]: : $P \models P$ Suppose $U \models P$. So we have: * $U \models P$ * $P \models P$ So by definition of [[Definition:Model (Logic)|model]]: : $U \cup P \models P$ It also follows that if $U \cup P \models P$, then: * $U \models P$ * $P \models P$ Thus we have shown that $U \models P$ iff $U \cup P \models P$. {{qed}} [[Category:Propositional Logic]] 18u0q1g3rrl1c1ypn3yirbp7dytwi45	1
Let $T_{\mathbf H'}$ be the [[Definition:Finite Propositional Tableau|finite propositional tableau]] obtained by replacing the [[Definition:Hypothesis Set|hypothesis set]] $\mathbf H$ of $T$ with $\mathbf H \cup \mathbf H'$. By the [[Tableau Extension Lemma]], $T_{\mathbf H'}$ has a [[Definition:Finished Propositional Tableau|finished]] [[Definition:Extension of Propositional Tableau|extension]] $T'$. By definition of [[Definition:Extension of Propositional Tableau|extension]], $T_{\mathbf H'}$ is a [[Definition:Rooted Subtree|rooted subtree]] of $T'$. But $T_{\mathbf H'}$ and $T$ are equal when considered as [[Definition:Rooted Tree|rooted trees]]. The result follows. {{qed}}	1
:$p \implies q, q \implies p \vdash p \iff q$	1
Let $\mathscr H$ be [[Definition:Hilbert Proof System/Instance 1|instance 1 of a Hilbert proof system]]. Let $\mathrm{BI}$ be the [[Definition:Formal Semantics of Boolean Interpretations|formal semantics of boolean interpretations]]. Then $\mathscr H$ is a [[Definition:Sound Proof System|sound proof system]] for $\mathrm{BI}$: :Every [[Definition:Theorem (Formal Systems)|$\mathscr H$-theorem]] is a [[Definition:Tautology (Boolean Interpretations)|tautology]].	1
:$p \implies \paren {q \implies r} \vdash \paren {p \land q} \implies r$	1
==== [[Rule of Transposition/Variant 2/Formulation 1|Formulation 1]] ==== {{:Rule of Transposition/Variant 2/Formulation 1}} ==== [[Rule of Transposition/Variant 2/Formulation 2|Formulation 2]] ==== {{:Rule of Transposition/Variant 2/Formulation 2}}	1
{{TFAE|def = Semantic Equivalence for Boolean Interpretations}} Let $\mathbf A, \mathbf B$ be [[Definition:WFF of Propositional Logic|WFFs of propositional logic]].	1
: $p \vdash p$	1
{{BeginTableau|\vdash \left({p \implies q}\right) \implies \left({\left({p \land r}\right) \implies \left ({q \land r}\right)}\right)}} {{Assumption|1|p \implies q}} {{SequentIntro|2|1|\left({p \land r}\right) \implies \left ({q \land r}\right)|1 |[[Factor Principles/Conjunction on Right/Formulation 1|Factor Principles: Conjunction on Right: Formulation 1]]}} {{Implication|3|1|\left({p \implies q}\right) \implies \left({\left({p \land r}\right) \implies \left ({q \land r}\right)}\right)|1|2}} {{EndTableau}} {{qed}}	1
:$\paren {q \land r} \lor p \dashv \vdash \paren {q \lor p} \land \paren {r \lor p}$	1
: $p \implies \left({q \implies r}\right) \vdash \left({p \implies q}\right) \implies \left({p \implies r}\right)$	1
Let us use the following abbreviations {{begin-eqn}} {{eqn | l=\phi | o=\text{ for } | r=\left({p \implies q}\right) \land \left({p \implies r}\right) | c= }} {{eqn | l=\psi | o=\text{ for } | r=p \implies \left({q \land r}\right) | c= }} {{end-eqn}} {{BeginTableau|\left({\left({p \implies q}\right) \land \left({p \implies r}\right)}\right) \implies \left({p \implies \left({q \land r}\right)}\right)}} {{Assumption|1|\phi}} {{SequentIntro|2|1|\psi|1|[[Implication is Left Distributive over Conjunction/Reverse Implication/Formulation 1|Implication is Left Distributive over Conjunction: Formulation 1]]}} {{Implication|3||\phi \implies \psi|1|2}} {{EndTableau}} Expanding the abbreviations leads us back to: : $\left({\left({p \implies q}\right) \land \left({p \implies r}\right)}\right) \implies \left({p \implies \left({q \land r}\right)}\right)$ {{qed}}	1
Since [[Inverse of Identity Element is Itself|$e$ is invertible]], the [[Definition:Power of Element of Monoid|power of $e$]] is defined for all $n \in \Z$. We prove the case $n \ge 0$ by [[Principle of Mathematical Induction|induction]]. === Basis for the Induction === By definition of [[Definition:Power of Element of Monoid|power of monoid element]]: :$e^0 = e$ so the theorem holds for $n = 0$. This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Our [[Definition:Induction Hypothesis|induction hypothesis]] is that the theorem is true for $n = k$: :$e^k = e$ === Induction Step === In the [[Definition:Induction Step|induction step]], we prove that the theorem is true for $n = k + 1$. We have: {{begin-eqn}} {{eqn | l = e^{k + 1} | r = e^k \circ e | c = {{Defof|Power of Element of Monoid}} }} {{eqn | r = e^k | c = {{Defof|Identity Element}} }} {{eqn | r = e | c = [[Power of Identity is Identity#Induction Hypothesis|Induction Hypothesis]] }} {{end-eqn}} Therefore, by [[Principle of Mathematical Induction]]: :$\forall n \in \Z_{\ge 0} : e^n = e$ {{qed|lemma}} Now we prove the case $n < 0$. We have: {{begin-eqn}} {{eqn | l = e^n | r = \paren {e^{-n} }^{-1} | c = {{Defof|Power of Element of Monoid}} }} {{eqn | r = e^{-1} | c = since $-n > 0$ }} {{eqn | r = e | c = [[Inverse of Identity Element is Itself]] }} {{end-eqn}} Thus: :$\forall n \in \Z : e^n = e$ {{qed}}	1
:$\neg q \implies \neg \left({p \land q}\right)$	1
=== Necessary Condition === Let $\mathbf A$ be [[Definition:Satisfiable (Boolean Interpretations)|satisfiable]]. Then there exists a [[Definition:Boolean Interpretation|boolean interpretation]] $v$ of $\mathbf A$ such that: :$v \left({\mathbf A}\right) = T$ Hence, by definition of the [[Definition:Logical Not/Boolean Interpretation|boolean interpretation of negation]]: :$v \left({\neg \mathbf A}\right) = F$ It follows that $\neg \mathbf A$ is [[Definition:Falsifiable (Boolean Interpretations)|falsifiable]]. {{qed|lemma}} === Sufficient Condition === Let $\neg \mathbf A$ be [[Definition:Falsifiable (Boolean Interpretations)|falsifiable]]. Then there exists a [[Definition:Boolean Interpretation|boolean interpretation]] $v$ of $\neg \mathbf A$ such that: :$v \left({\neg \mathbf A}\right) = F$ Hence, by definition of the [[Definition:Logical Not/Boolean Interpretation|boolean interpretation of negation]]: :$v \left({\mathbf A}\right) = T$ It follows that $\mathbf A$ is [[Definition:Satisfiable (Boolean Interpretations)|satisfiable]]. {{qed}}	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, appropriate [[Definition:Truth Value|truth values]] match for both [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c||ccc|} \hline p & \neg & \neg & p \\ \hline F & F & T & F \\ T & T & F & T \\ \hline \end{array}$ Hence $p \dashv \vdash \neg \neg p$. {{qed}}	1
Let $\struct {T, \mathbf H, \Phi}$ be a [[Definition:Finished Propositional Tableau|finished]] [[Definition:Propositional Tableau|propositional tableau]]. Then one of the following holds: :$T$ has a [[Definition:Finished Branch of Propositional Tableau|finished branch]] :$T$ is a [[Definition:Tableau Confutation|tableau confutation]].	1
{{BeginTableau|p \vdash p \land \left({p \lor q}\right)}} {{Premise|1|p}} {{Addition|2|1|p \lor q|1|1}} {{Conjunction|3|1|p \land \left({p \lor q}\right)|1|2}} {{EndTableau}} {{qed}}	1
{{ProofWanted|This is going to be fun}}	1
A [[Definition:Cooperative Game|cooperative game]] is one where [[Definition:Player|players]] form [[Definition:Coalition|coalitions]] against the other [[Definition:Player|players]]. If the [[Definition:Player|players]] in a [[Definition:Two-Person Zero-Sum Game|two-person zero-sum game]] were to form a [[Definition:Coalition|coalition]], there would be no other [[Definition:Player|players]] to form it against. Further, as the total [[Definition:Payoff|payoff]] is [[Definition:Zero (Number)|zero]], there would be no benefit in collaborating on using one [[Definition:Strategy|strategy]] over another, as when they pool their [[Definition:Payoff|payoffs]] they are back where they started. {{qed}}	1
For each [[Definition:Integer|integer]] $k \ge 1$, there exists: * a [[Definition:Primitive Recursive Relation|primitive recursive $k+1$-ary relation]] $T_k$; * a [[Definition:Primitive Recursive Function|primitive recursive function]] $U: \N \to \N$ such that a [[Definition:Partial Function|partial function]] $f: \N^k \to \N$ is [[Definition:Recursive Function|recursive]] iff, for some $e \in \N$ and all $\left({n_1, n_2, \ldots, n_k}\right) \in \N^k$: :$f \left({n_1, n_2, \ldots, n_k}\right) \approx U \left({\mu z \ T_k \left({e, n_1, n_2, \ldots, n_k, z}\right)}\right)$	1
=== Sufficient Condition === Let $F$ be [[Definition:Prime Filter (Order Theory)|prime]]. Let $x \in S$. By definition of [[Definition:Boolean Lattice|Boolean lattice]]: :$x \vee \neg x = \top$ where $\top$ denotes the [[Definition:Top (Lattice Theory)|top]] of $B$. By definition of [[Definition:Non-Empty Set|non-empty set]]: :$\exists y: y \in F$ By definition of [[Definition:Greatest Element|greatest element]]: :$y \preceq \top$ By definition of [[Definition:Upper Set|upper set]]: :$\top \in F$ Thus by definition of [[Definition:Prime Filter (Order Theory)|prime filter]]: :$x \in F$ or $\neg x \in F$ {{qed|lemma}} === Necessary Condition === Assume that :$\forall x \in S: x \in F \lor \left({\neg x}\right) \in F$ Let $a, b \in S$ such that :$a \vee b \in F$ Aiming for a [[Definition:Contradiction|contradiction]] suppose that :$a \notin F$ and $b \notin F$ By assumption: :$\neg a \in F$ and $\neg b \in F$ By [[Filtered in Meet Semilattice]]: :$\left({\neg a}\right) \wedge \left({\neg b}\right) \in F$ By [[De Morgan's Laws (Boolean Algebras)]]: :$\neg\left({a \vee b}\right) \in F$ By [[Filtered in Meet Semilattice]]: :$\left({a \vee b}\right) \wedge \neg\left({a \vee b}\right) \in F$ By definition of [[Definition:Boolean Lattice|Boolean lattice]]: :$\bot \in F$ where $\bot$ denotes the [[Definition:Bottom (Lattice Theory)|bottom]] of $B$. By definition of [[Definition:Smallest Element|smallest element]]: :$\bot \preceq a$ By definition of [[Definition:Upper Set|upper set]]: :$a \in F$ This contradicts $a \notin F$ Thus by [[Proof by Contradiction]] :the result holds. {{qed}}	1
: $\vdash \left({p \iff q}\right) \iff \left({\left({p \land q}\right) \lor \left({\neg p \land \neg q}\right)}\right)$	1
A [[Definition:Prime Number|prime number]] is defined as an element of $\N$ with '''exactly two''' positive [[Definition:Divisor of Integer|divisors]]. So, we have that $n > 0$ is [[Definition:Prime Number|prime]] {{iff}} $\map \tau n = 2$, where $\tau: \N \to \N$ is the [[Definition:Divisor Counting Function|divisor counting function]]. Thus we can define the [[Definition:Characteristic Function of Set|characteristic function]] of the set of [[Definition:Prime Number|prime numbers]] $\Bbb P$ as: :$\forall n > 0: \map {\chi_\Bbb P} n := \map {\chi_{\operatorname {eq} } } {\map \tau n, 2}$ Now we let $g: \N^2 \to \N$ be the [[Definition:Function|function]] given by: :$\displaystyle \map g {n, z} = \begin{cases} 0 & : z = 0 \\ \displaystyle \sum_{y \mathop = 1}^z \map {\operatorname {div} } {n, y} & : z > 0 \end{cases}$ As: :[[Divisor Relation is Primitive Recursive|$\operatorname {div}$ is primitive recursive]] :[[Bounded Summation is Primitive Recursive|$\displaystyle \sum_{y \mathop = 1}^z$ is primitive recursive]] it follows that $g$ is [[Definition:Primitive Recursive Function|primitive recursive]]. Then for $n > 0$: :$\displaystyle \map g {n, n} = \sum_{y \mathop = 1}^n \map {\operatorname {div} } {n, y} = \map \tau n$ and from [[Divisor Counting Function is Primitive Recursive]] we have that $g$ is [[Definition:Primitive Recursive Function|primitive recursive]]. Then let $h: \N \to \N$ be the function defined as: :$\map h n = \map g {n, n}$ which is also [[Definition:Primitive Recursive Function|primitive recursive]]. So we have, for all $n \in \N$: :$\map {\chi_\Bbb P} n = \map {\chi_{\operatorname {eq} } } {\map h n, 2}$ Hence the result. {{qed}} [[Category:Primitive Recursive Functions]] k1a4wt3d0sgg3ejb08p2yslykgh1m52	1
Let $\map V {n, p}$ be a [[Definition:Master Code|master code]] of [[Definition:Length of Sequence|length]] $n$ modulo $p$. Then there are $p^n$ [[Definition:Element|elements]] of $\map V {n, p}$.	1
Both versions of the Traveling Salesman Problem are NP-complete.	1
:$\neg p \vdash p \implies q$	1
{{proof wanted|Stated without proof, or even an explanatory comment on its scope of applicability, in Davis. This work is too vague to be useful. I am going to have to use a different work.}}	1
We apply the [[Method of Truth Tables]] to the proposition $\vdash p \lor \neg p$. As can be seen by inspection, the [[Definition:Truth Value|truth value]] of the [[Definition:Main Connective (Propositional Logic)|main connective]], that is $\lor$, is $T$ for each [[Definition:Boolean Interpretation|boolean interpretation]] for $p$. $\begin{array}{|cccc|} \hline p & \lor & \neg & p \\ \hline F & T & T & F \\ T & T & F & T \\ \hline \end{array}$ {{qed}}	1
Let $\struct {S, \vee, \wedge, \neg}$ be a [[Definition:Boolean Algebra/Definition 1|Boolean algebra, defined as in Definition 1]]. Let the [[Definition:Identity Element|identity]] for $\vee$ be $\bot$ and the [[Definition:Identity Element|identity]] for $\wedge$ be $\top$. Then: :$(1): \quad \forall x \in S: x \vee \top = \top$ :$(2): \quad \forall x \in S: x \wedge \bot = \bot$ That is, $\bot$ is a [[Definition:Zero Element|zero element]] for $\wedge$, and $\top$ is a [[Definition:Zero Element|zero element]] for $\vee$.	1
Consider the [[Definition:Particular Affirmative|particular affirmative]] [[Definition:Categorical Statement|categorical statement]] ''Some $S$ is $P$'': :$\map {\mathbf I} {S, P}: \exists x: \map S x \land \map P x$ Then ''Some $P$ is $S$'': :$\map {\mathbf I} {P, S}$	1
:$p \land q \implies r \dashv \vdash \paren {p \implies q} \implies \paren {p \implies r}$	1
The '''Principle of Non-Contradiction''' is a [[Definition:Valid Argument|valid]] deduction [[Definition:Sequent|sequent]] in [[Definition:Propositional Logic|propositional logic]].	1
{{BeginTableau|p \lor \top \vdash \top}} {{Premise|1|p \lor \top}} {{Assumption|2|\top}} {{Assumption|3|p}} {{Addition|4|3|p \lor \neg p|3|1}} {{TableauLine | n = 5 | pool = 3 | f = \top | rlnk = Law of Excluded Middle/Proof Rule | rtxt = Law of Excluded Middle | dep = 4 | c = }} {{ProofByCases|6|1|\top|1|2|2|3|5}} {{EndTableau}} {{qed|lemma}} {{questionable|The above needs to be reviewed}} {{BeginTableau|\top \vdash p \lor \top}} {{Premise|1|\top}} {{Addition|2|1|p \lor \top|1|2}} {{EndTableau}} {{qed}}	1
:$\vdash \left({p \land \left({q \lor r}\right)}\right) \iff \left({\left({p \land q}\right) \lor \left({p \land r}\right)}\right)$	1
{{TFAE|def = Consistent (Logic)/Proof System/Propositional Logic|view = Consistent Proof System for Propositional Logic}} Let $\LL_0$ be the [[Definition:Language of Propositional Logic|language of propositional logic]]. Let $\mathscr P$ be a [[Definition:Proof System|proof system]] for $\LL_0$. Let $\FF$ be a collection of [[Definition:Logical Formula|logical formulas]].	1
The set of all [[Definition:Finitely Satisfiable|finitely satisfiable]] [[Definition:Mathematical Theory|$\mathcal L$-theories]] containing $T$ forms an [[Definition:Ordered Set|ordered set]] using [[Definition:Subset|subset inclusion]] as the [[Definition:Ordering|ordering]]. {{explain|Link to "subset is ordering"}} Let $C$ be a [[Definition:Non-Empty Set|nonempty]] [[Definition:Chain (Set Theory)|chain]] in this ordered set. Let $\displaystyle T_C = \bigcup_{\Sigma \mathop \in C} \Sigma$. Let $\Delta$ be a [[Definition:Finite Subset|finite subset]] of $T_C$. Then there exists a single $\Sigma$ in $C$ which contains $\Delta$. Since this $\Sigma$ is finitely satisfiable by definition, this means that $\Delta$ is satisfiable. Hence $T_C$ is finitely satisfiable. Since each $\Sigma \in C$ is contained in $T_C$, this means that $T_C$ is an upper bound for $C$ in the ordered set. Thus, by [[Zorn's Lemma]], there is a finitely satisfiable $\mathcal L$-theory $T'$ containing $T$ such that $T'$ contains all other such theories. Let $\phi$ be an $\mathcal L$-sentence. Let $\phi \nsubseteq T'$. Aiming for a contradiction, suppose $T' \cup \left\{ {\phi}\right\}$ were finitely satisfiable. Then by definition of $T'$, $T'$ would contain $T' \cup \left\{ {\phi}\right\}$ as a subset. This would mean that $T'$ contains $\phi$, which contradicts the assumption. Thus $T' \cup \left\{ {\phi}\right\}$ is not finitely satisfiable. By the [[Finitely Satisfiable Theory has Maximal Finitely Satisfiable Extension/Lemma|lemma]], $T' \cup \left\{ {\neg \phi}\right\}$ is finitely satisfiable. Thus, by definition of $T'$, $T'$ contains $T' \cup \left\{{\neg \phi}\right\}$ as a [[Definition:Subset|subset]]. Hence $T'$ contains $\neg \phi$. {{qed}}	1
:$p \land q \dashv \vdash \neg \left({p \implies \neg q}\right)$	1
The idea is to work in a language with constant symbols for all elements of $\mathcal M$ and show that the union of $p$ and the [[Definition:Elementary Diagram|elementary diagram]] of $\mathcal M$ is satisfiable. Since $\mathcal M$ naturally embeds into any model of such a theory, this will prove the theorem. Let $\mathcal L_\mathcal M$ be the language obtained by adding to $\mathcal L$ constant symbols for each element of $\mathcal M$. Denote by $\operatorname {Diag}_{\mathrm {el}} \left({\mathcal M}\right)$ the elementary diagram of $\mathcal M$. Let $T$ be $p \cup \operatorname {Diag}_{\mathrm{el}} \left({\mathcal M}\right)$. We will show that $T$ is finitely satisfiable. It will follow by the [[Compactness Theorem]] that $T$ is satisfiable. To this end, let $\Delta$ be a finite subset of $T$. We have that $\Delta$ is finite. Thus it consists of: :finitely many $\mathcal L_A$-sentences $\phi_0, \dotsc, \phi_n$ from $p$ (which are $\mathcal L_\mathcal M$ sentences since $A \subseteq \mathcal M$) along with: :finitely many $\mathcal L_\mathcal M$-sentences $\psi_0,\dots,\psi_k$ from $\operatorname{Diag}_{\mathrm{el}} \left({\mathcal M}\right)$. By definition, $p$ is satisfiable by some $\mathcal L_A$-structure $\mathcal N$ such that: :$\mathcal N \models p \cup \operatorname{Th}_A \left({\mathcal M}\right)$ Thus, since $\phi_0, \dotsc, \phi_n \in p$: :$\mathcal N$ satisfies $\phi_0, \dotsc, \phi_n$. We will show that the same $\mathcal N$ also satisfies $\psi_0, \dotsc, \psi_k$. The obstacle to overcome is that the $\psi_i$ are $\mathcal L_\mathcal M$-formulas, and we only know $\mathcal N$ as an $\mathcal L_A$-structure which satisfies sentences with parameters from $A$. The $\psi_i$ may have parameters from $\mathcal M$ outside of $A$. The idea is to quantify away the excess parameters and appropriately select the interpretation of new symbols so that $\mathcal N$ is a good $\mathcal L_\mathcal M$-structure. Explicitly: Let $\psi$ be the conjunction $\psi_0 \wedge \cdots \wedge \psi_k$. Note that since $\psi$ is an $\mathcal L_\mathcal M$-sentence, it can be written as an $\mathcal L_A$-formula $\psi \left({\bar b}\right)$, where $\bar b$ is a tuple of parameters from $\mathcal M$ not in $A$. By existentially quantifying away the tuple $\bar b$, we obtain an $\mathcal L_A$-sentence $\exists \bar x \psi \left({\bar x}\right)$. Now, since $\mathcal M \models \psi \left({\bar b}\right)$, we have: : $\mathcal M \models \exists \bar x: \psi \left({\bar x}\right)$ Hence $\exists \bar x: \psi \left({\bar x}\right)$ is in $\operatorname{Th}_\mathcal A \left({\mathcal M}\right)$. By choice of $\mathcal N$, it follows that: :$\mathcal N \models \exists \bar x: \psi \left({\bar x}\right)$ and thus there must be some tuple $\bar c$ of elements from $\mathcal N$ such that: :$\mathcal N \models \psi \left({\bar c}\right)$ Now, by interpreting the $\mathcal L_\mathcal M$-symbols $\bar b$ as the elements $\bar c$, we can view $\mathcal N$ as an $\mathcal L_\mathcal M$-structure which satisfies: :$\phi_0 \wedge \cdots \wedge \phi_n \wedge \psi_0 \wedge \cdots \wedge \psi_k$. Thus $\mathcal N$ satisfies all of $\Delta$. This demonstrates that $T$ is finitely satisfiable and hence satisfiable by the [[Compactness Theorem]]. This means that there is an $\mathcal L_\mathcal M$-structure $\mathcal M^*$ which satisfies: :$p \cup \operatorname{Diag}_{\mathrm {el} } \left({\mathcal M}\right)$ Since $\mathcal M^*$ interprets a symbol for each element of $\mathcal M$, there is an obvious embedding of $\mathcal M$ into $\mathcal M^*$. This embedding is [[Definition:Elementary Map (Model Theory)|elementary]] since $\mathcal M^*$ satisfies the elementary diagram of $\mathcal M$. Thus $\mathcal M^*$ is an elementary extension of $\mathcal M$. Finally, since $\mathcal M^*$ satisfies $p$, there must be a tuple of elements $\bar{d}$ such that $\mathcal M^* \models \phi \left({d}\right)$ for each $\phi \left({\bar v}\right) \in p$. Thus $\mathcal M^*$ realizes $p$. {{qed}} [[Category:Model Theory]] i06sa9qyaa7xhjubk1uegxek51ty53e	1
[[Proof by Cases]] can be symbolised by the [[Definition:Sequent|sequent]]: :$p \lor q, \paren {p \vdash r}, \paren {q \vdash r} \vdash r$	1
{{BeginTableau|\left({p \implies q}\right) \implies \left({\neg p \lor q}\right)}} {{Assumption|1|p \implies q}} {{SequentIntro|2|1|\neg p \lor q|1|[[Rule of Material Implication/Formulation 1/Forward Implication|Rule of Material Implication: Formulation 1]]}} {{Implication|3||\left({p \implies q}\right) \implies \left({\neg p \lor q}\right)|1|2}} {{EndTableau}} {{qed}} {{LEM|Rule of Material Implication/Formulation 1/Forward Implication|3}}	1
{{:De Morgan's Laws (Logic)/Conjunction/Formulation 1}}	1
{{BeginTableau|\neg \left({p \implies q}\right) \vdash p \land \neg q}} {{Premise|1|\neg \left({p \implies q}\right)}} {{Assumption|2|\neg \left({p \land \neg q}\right)}} {{SequentIntro|3|2|p \implies q|2|[[Implication Equivalent to Negation of Conjunction with Negative]]}} {{NonContradiction|4|1, 2|3|1}} {{Reductio|5|1|p \land \neg q|2|4}} {{EndTableau}} {{qed}} {{LEM|Reductio ad Absurdum}} [[Category:Conjunction with Negative Equivalent to Negation of Implication]] 74vn9lygaw57ac3s1upxd6d0jrjstff	1
{{BeginTableau|\forall x: \neg \map P x \vdash \neg \exists x: \map P x}} {{Premise|1|\forall x: \neg \map P x}} {{Assumption|2|\exists x: \map P x}} {{TableauLine|n = 3|pool = 2|f = \map P {\mathbf a}|rlnk = Existential Instantiation|rtxt = Existential Instantiation|dep = 2|c = for an arbitrary $\mathbf a$}} {{TableauLine|n = 4|pool = 1|f = \neg \map P {\mathbf a}|rlnk = Universal Instantiation|rtxt = Universal Instantiation|dep = 3}} {{NonContradiction|5|1, 2|3|4}} {{Contradiction|6|1|\neg \exists x: \map P x|2|5}} {{EndTableau|lemma}} {{BeginTableau|\neg \exists x: \map P x \vdash \forall x: \neg \map P x}} {{Premise|1|\neg \exists x: \map P x}} {{Assumption|2|\map P {\mathbf a}|for some arbitrary $\mathbf a$}} {{TableauLine|n = 3|pool = 2|f = \exists x: \map P x|rlnk = Existential Generalisation|rtxt = Existential Generalisation|dep = 2}} {{NonContradiction|4|1, 2|1|3}} {{Contradiction|5|1|\neg \map P {\mathbf a}|2|4}} {{TableauLine|n = 6|pool = 1|f = \forall x: \neg \map P x|rlnk = Universal Generalisation|rtxt = Universal Generalisation|dep = 5|c = as $\mathbf a$ was arbitrary}} {{EndTableau|qed}} {{Namedfor|Augustus De Morgan|cat = De Morgan}}	1
Let $f: \C^n \to \C^n$ be a [[Definition:Polynomial Map|polynomial map]]. Let $f$ be [[Definition:Injection|injective]]. Then $f$ is [[Definition:Surjection|surjective]].	1
: $\vdash \left({\neg p \implies q}\right) \iff \left({\neg q \implies p}\right)$	1
{{BeginTableau|\paren {p \implies r} \lor \paren {q \implies r} \vdash \paren {p \land q} \implies r}} {{Premise | 1 | \paren {p \implies r} \lor \paren {q \implies r} }} {{Assumption | 2 | p \implies r}} {{Assumption | 3 | p \land q}} {{Simplification | 4 | 3 | p | 3 | 1}} {{ModusPonens | 5 | 2, 3 | r | 2 | 4}} {{Implication | 6 | 2 | \paren {p \land q} \implies r | 3 | 5}} {{Assumption | 7 | q \implies r}} {{Assumption | 8 | p \land q}} {{Simplification | 9 | 8 | q | 8 | 2}} {{ModusPonens | 10 | 7, 8 | r | 7 | 9}} {{Implication | 11 | 7 | \paren {p \land q} \implies r | 8 | 10}} {{ProofByCases | 12 | 1 | \paren {p \land q} \implies r | 1 | 2 | 6 | 7 | 11}} {{EndTableau}} {{qed}} [[Category:Principle of Composition]] s0zw4mvifgwuf9geznf0ccfqcepe05p	1
:$\vdash \left({\neg \left({p \implies q}\right)}\right) \implies \left({p \land \neg q}\right)$	1
:$\paren {\paren {p \implies q} \implies p} \dashv \vdash p$	1
Let $X$ be a [[Definition:Topological Space|topological space]]. Let $V$ be a [[Definition:Normed Vector Space|normed vector space]] over $\R$ or $\C$ with [[Definition:Norm on Vector Space|norm]] $\norm {\,\cdot\,}$ Let $f, g: X \to V$ be [[Definition:Mapping|mappings]]. Let $x_0 \in X$. Let $f = \map o g$ as $x \to x_0$, where $o$ denotes [[Definition:Little-O|little-O notation]]. Then $f = \map \OO g$ as $x \to x_0$, where $\OO$ denotes [[Definition:Big-O|big-$\OO$ notation]].	1
{{BeginTableau|p \lor \top \vdash \top}} {{Premise|1|p \lor \top}} {{Assumption|2|\top}} {{Assumption|3|p}} {{Addition|4|3|p \lor \neg p|3|1}} {{TableauLine | n = 5 | pool = 3 | f = \top | rlnk = Law of Excluded Middle/Proof Rule | rtxt = Law of Excluded Middle | dep = 4 | c = }} {{ProofByCases|6|1|\top|1|2|2|3|5}} {{EndTableau}} {{qed|lemma}} {{questionable|The above needs to be reviewed}} {{BeginTableau|\top \vdash p \lor \top}} {{Premise|1|\top}} {{Addition|2|1|p \lor \top|1|2}} {{EndTableau}} {{qed}}	1
: $p \iff q \vdash \left({p \lor q}\right) \implies \left({p \land q}\right)$	1
{{begin-eqn}} {{eqn | l = p \uparrow q | o = \dashv \vdash | r = \neg \left({p \land q}\right) | c = Definition of [[Definition:Logical NAND|Logical NAND]] }} {{eqn | o = \dashv \vdash | r = \neg p \lor \neg q | c = [[De Morgan's Laws (Logic)/Disjunction of Negations|De Morgan's Laws: Disjunction of Negations]] }} {{end-eqn}} {{qed}}	1
Every [[Definition:Finite Group|finite]] [[Definition:Abelian Group|abelian group]] is an [[Definition:Internal Group Direct Product|internal group direct product]] of [[Definition:Cyclic Group|cyclic groups]] whose [[Definition:Order of Group|orders]] are [[Definition:Prime Power|prime powers]]. The number of terms in the [[Definition:Internal Group Direct Product|product]] and the [[Definition:Order of Group|orders]] of the [[Definition:Cyclic Group|cyclic groups]] are [[Definition:Unique|uniquely determined]] by the group.	1
Follows directly from [[Complement in Boolean Algebra is Unique]]. {{qed}}	1
{{BeginTableau|p \land \left({q \land r}\right) \vdash \left({p \land q}\right) \land r}} {{Premise|1|p \land \left({q \land r}\right)}} {{Simplification|2|1|p|1|1}} {{Simplification|3|1|q \land r|1|2}} {{Simplification|4|1|q|3|1}} {{Simplification|5|1|r|3|2}} {{Conjunction|6|1|p \land q|2|4}} {{Conjunction|7|1|\left({p \land q}\right) \land r|6|5}} {{EndTableau}} {{BeginTableau|\left({p \land q}\right) \land r \vdash p \land \left({q \land r}\right)}} {{Premise|1|\left({p \land q}\right) \land r}} {{Simplification|2|1|p \land q|1|1}} {{Simplification|3|1|r|1|2}} {{Simplification|4|1|p|2|1}} {{Simplification|5|1|q|2|2}} {{Conjunction|6|1|q \land r|5|3}} {{Conjunction|7|1|p \land \left({q \land r}\right)|4|6}} {{EndTableau}} {{qed}}	1
The [[Definition:Divisor Counting Function|divisor counting ($\tau$) function]] is [[Definition:Primitive Recursive Function|primitive recursive]].	1
The [[Definition:Function|function]] $\exp: \N^2 \to \N$, defined as: :$\exp \left({n, m}\right) = n^m$ is [[Definition:Primitive Recursive Function|primitive recursive]].	1
Let $\uparrow$ and $\downarrow$ denote [[Definition:Logical NAND|NAND]] and [[Definition:Logical NOR|NOR]] respectively. From: : [[NAND is Functionally Complete]] and : [[NOR is Functionally Complete]] the [[Definition:Singleton|singleton sets]] $\left\{{\uparrow}\right\}$ and $\left\{{\downarrow}\right\}$ are [[Definition:Functionally Complete|functionally complete]]. Suppose $\circ$ is a [[Definition:Binary Logical Connective|binary logical connective]] such that $\left\{{\circ}\right\}$ is a [[Definition:Functionally Complete|functionally complete set]]. The [[Definition:Unary Logical Connective|unary logical connective]] $\neg$ has to be equivalent to some formula: : $\cdots \circ \left({p \circ p}\right) \circ \cdots$ Suppose some [[Definition:Boolean Interpretation|interpretation]] $v$ assigns $T$ to $p$. Then $v \left({\neg p}\right) = F$ So: : $v \left({\cdots \circ \left({p \circ p}\right) \circ \cdots}\right) = F$ So it has to be true that $T \circ T = F$, otherwise: : $v \left({\cdots \circ \left({T \circ T}\right) \circ \cdots}\right) = v \left({\cdots \circ \left({T}\right) \circ \cdots}\right) = T$ Similarly: :$F \circ F = T$ Now consider $T \circ F$ and $F \circ T$. Suppose $T \circ F = F$. If $F \circ T = T$, then we have the function defined by this [[Definition:Truth Table|truth table]]: {| border="1" cellpadding="4" cellspacing="1" style="text-align:center;" |- ! $v \left({p}\right)$ ! $v \left({q}\right)$ ! $v \left({p \circ q}\right)$ |- | $F$ || $F$ || $T$ |- | $F$ || $T$ || $T$ |- | $T$ || $F$ || $F$ |- | $T$ || $T$ || $F$ |} which is $\neg p$, and hence only negation would be definable. So if $T \circ F = F$ we need $F \circ T = F$. This gives the [[Definition:Truth Table|truth table]] for the [[Definition:Logical NOR|NOR]] function: {| border="1" cellpadding="4" cellspacing="1" style="text-align:center;" |- ! $v \left({p}\right)$ ! $v \left({q}\right)$ ! $v \left({p \circ q}\right)$ |- | $F$ || $F$ || $T$ |- | $F$ || $T$ || $F$ |- | $T$ || $F$ || $F$ |- | $T$ || $T$ || $F$ |} ... which we have seen is [[Definition:Functionally Complete|functionally complete]]. Similarly, Suppose $T \circ F = T$. If $F \circ T = F$, then we have the function defined by this [[Definition:Truth Table|truth table]]: {| border="1" cellpadding="4" cellspacing="1" style="text-align:center;" |- ! $v \left({p}\right)$ ! $v \left({q}\right)$ ! $v \left({p \circ q}\right)$ |- | $F$ || $F$ || $T$ |- | $F$ || $T$ || $F$ |- | $T$ || $F$ || $T$ |- | $T$ || $T$ || $F$ |} which is $\neg q$, and hence only negation would be definable. So if $T \circ F = T$ we need $F \circ T = T$. This gives the [[Definition:Truth Table|truth table]] for the [[Definition:Logical NAND|NAND]] function: {| border="1" cellpadding="4" cellspacing="1" style="text-align:center;" |- ! $v \left({p}\right)$ ! $v \left({q}\right)$ ! $v \left({p \circ q}\right)$ |- | $F$ || $F$ || $T$ |- | $F$ || $T$ || $T$ |- | $T$ || $F$ || $T$ |- | $T$ || $T$ || $F$ |} ... which we have seen is [[Definition:Functionally Complete|functionally complete]]. Thus it follows that there can be no [[Definition:Functionally Complete|functionally complete]] [[Definition:Binary Logical Connective|binary logical connectives]] apart from [[Definition:Logical NAND|NAND]] and [[Definition:Logical NOR|NOR]]. {{qed}}	1
This is an immediate consequence of [[Subset of Satisfiable Set is Satisfiable]]. {{qed}}	1
{{BeginTableau|p \lor p \vdash p}} {{Premise|1|p \lor p}} {{Assumption|2|p}} {{ProofByCases|3|1|p|1|2|2|2|2}} {{EndTableau}} {{qed}}	1
=== [[Double Negation/Double Negation Introduction/Sequent Form/Formulation 1/Proof|Double Negation Introduction]] === {{:Double Negation/Double Negation Introduction/Sequent Form/Formulation 1/Proof}} === [[Double Negation/Double Negation Elimination/Sequent Form/Formulation 1/Proof|Double Negation Elimination]] === {{:Double Negation/Double Negation Elimination/Sequent Form/Formulation 1/Proof}}	1
'''Mathematical logic''' is a sub-branch of [[Definition:Symbolic Logic|symbolic logic]] in which the foundations of the assumptions upon which rest mathematics itself are investigated and made rigorous.	1
{{BeginTableau|\vdash p \iff p}} {{TheoremIntro|1|p \implies p|[[Law of Identity/Formulation 2|Law of Identity: Formulation 2]]}} {{BiconditionalIntro|2||p \iff p|1|1}} {{EndTableau|qed}}	1
[[Definition:Tableau Proof (Propositional Tableaus)|Tableau proofs]] (in terms of [[Definition:Propositional Tableau|propositional tableaus]]) are a [[Definition:Complete Proof System|complete proof system]] for [[Definition:Boolean Interpretation|boolean interpretations]]. That is, for every [[Definition:WFF of Propositional Logic|WFF]] $\mathbf A$: :$\models_{\mathrm{BI}} \mathbf A$ implies $\vdash_{\mathrm{PT}} \mathbf A$	1
{{BeginTableau|p \vdash \neg \neg p}} {{Premise|1|p}} {{Assumption|2|\neg p}} {{NonContradiction|3|1, 2|1|2}} {{Contradiction|4|1|\neg \neg p|2|3}} {{EndTableau}} {{Qed}}	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, in each case, the [[Definition:Truth Value|truth values]] in the appropriate columns match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c|ccc||c|ccc|} \hline p & p & \iff & \top & p \\ \hline F & F & F & T & F \\ T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
:$p \land q \vdash \left({p \land r}\right) \lor \left({q \land \neg r}\right)$	1
The proof proceeds by [[Second Principle of Mathematical Induction|strong induction]]. For all $n \in \Z_{\ge 3}$, let $P \left({n}\right)$ be the [[Definition:Proposition|proposition]]: :for all $m \in \Z$ such that $1 < m \le n$, the [[Definition:Initial Part|initial part]] of $S_n$ of [[Definition:Length of String|length]] $F_m$ is $S_m$. === Basis for the Induction === $P \left({3}\right)$ is the case: :$S_3 = \text{ba}$ For $m = 2$, $S_3$ starts with $S_2 = \text{b}$, which is the [[Definition:Initial Part|initial part]] of $S_3$ of [[Definition:Length of String|length]] $F_2 = 1$. Thus $P \left({3}\right)$ is seen to hold. $P \left({4}\right)$ is the case: :$S_4 = \text{bab}$ For $m = 2$, $S_4$ starts with $S_2 = \text{b}$, which is the [[Definition:Initial Part|initial part]] of $S_4$ of [[Definition:Length of String|length]] $F_2 = 1$. For $m = 3$, $S_4$ starts with $S_3 = \text{ba}$, which is the [[Definition:Initial Part|initial part]] of $S_4$ of [[Definition:Length of String|length]] $F_3 = 2$. Thus $P \left({4}\right)$ is seen to hold. This is the [[Second Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that, if $P \left({j}\right)$ is true, for all $j$ such that $4 \le j \le k$, then it logically follows that $P \left({k + 1}\right)$ is true. This is the [[Second Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :for all $m \in \Z$ such that $1 < m \le k$, the [[Definition:Initial Part|initial part]] of $S_k$ of [[Definition:Length of String|length]] $F_m$ is $S_m$. from which it is to be shown that: :for all $m \in \Z$ such that $1 < m \le k + 1$, the [[Definition:Initial Part|initial part]] of $S_{k + 1}$ of [[Definition:Length of String|length]] $F_m$ is $S_m$. === Induction Step === This is the [[Second Principle of Mathematical Induction#Induction Step|induction step]]: By definition of [[Definition:Fibonacci String|Fibonacci string]]: :$S_{k + 1} = S_k S_{k - 1}$ [[Definition:Concatenation (Formal Systems)|concatenated]]. Thus the [[Definition:Initial Part|initial part]] of $S_{k + 1}$ of length $F_k$ is $S_k$. By the [[Initial Part of Fibonacci String#Induction Hypothesis|induction hypothesis]], for all $m \in \Z$ such that $1 < m < k - 1$, the [[Definition:Initial Part|initial part]] of $S_k$ of [[Definition:Length of String|length]] $F_m$ is $S_m$. But we also have that the [[Definition:Initial Part|initial part]] of $S_{k + 1}$ of [[Definition:Length of String|length]] $F_k$ is $S_k$. So $P \left({k}\right) \implies P \left({k + 1}\right)$ and the result follows by the [[Second Principle of Mathematical Induction]]. Therefore: :for all $m \in \Z$ such that $1 < m \le n$, the [[Definition:Initial Part|initial part]] of $S_n$ of [[Definition:Length of String|length]] $F_m$ is $S_m$. {{qed}}	1
{{BeginTableau|\forall x: \map P x \vdash \neg \exists x: \neg \map P x}} {{Premise|1|\forall x: \map P x}} {{Assumption|2|\exists x: \neg \map P x}} {{TableauLine|n = 3|pool = 2|f = \neg \map P {\mathbf a}|rlnk = Existential Instantiation|rtxt = Existential Instantiation|dep = 2|c = for some arbitrary $\mathbf a$}} {{TableauLine|n = 4|pool = 1|f = \map P {\mathbf a}|rlnk = Universal Instantiation|rtxt = Universal Instantiation|dep = 1}} {{NonContradiction|5|1, 2|3|4}} {{Contradiction|6|1|\neg \exists x: \neg \map P x|2|5}} {{EndTableau|lemma}} {{BeginTableau|\neg \exists x: \neg \map P x \vdash \forall x: \map P x}} {{Premise|1|\neg \exists x: \neg \map P x}} {{Assumption|2|\neg \forall x: \map P x}} {{SequentIntro|3|2|\exists x: \neg \map P x|2|[[Denial of Universality]]}} {{NonContradiction|4|1, 2|1|3}} {{Reductio|5|1|\forall x: \map P x|2|4}} {{EndTableau|qed}} {{LEM|Reductio ad Absurdum}} {{Namedfor|Augustus De Morgan|cat = De Morgan}}	1
Proof by [[Principle of Mathematical Induction|induction]]: === Basis for the Induction === $n = 1$ holds trivially. Just to make sure, we try $n = 2$: :$1 + 2 + 1 = 4$ Likewise $n^2 = 2^2 = 4$. So shown for [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === This is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$1 + 2 + \cdots + k + \paren {k - 1} + \cdots + 1 = k^2$ Now we need to show true for $n = k + 1$: :$1 + 2 + \cdots + \paren {k + 1} + k + \paren {k - 1} + \cdots + 1 = \paren {k + 1}^2$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | o = | r = 1 + 2 + \cdots + \paren {k + 1} + k + \paren {k - 1} + \cdots + 1 | c = }} {{eqn | r = \paren {1 + 2 + \cdots + k + \paren {k - 1} + \cdots + 1} + k + \paren {k + 1} | c = }} {{eqn | r = k^2 + k + \paren {k + 1} | c = from [[1+2+...+n+(n-1)+...+1 = n^2/Proof 3#Induction Hypothesis|induction hypothesis]] }} {{eqn | r = k^2 + 2k + 1 | c = }} {{eqn | r = \paren {k + 1}^2 | c = }} {{end-eqn}} The result follows by [[Principle of Mathematical Induction|induction]]. {{qed}}	1
Suppose both [[Definition:Premise of Syllogism|premises]] of $Q$ are [[Definition:Particular Categorical Statement|particular]]. Then the pattern of $Q$ is one of $\text{II}x$, $\text{IO}x$, $\text{OI}x$ or $\text{OO}x$, where $x$ is the [[Definition:Conclusion of Syllogism|conclusion]]. $\text{I}$ is neither [[Definition:Universal Categorical Statement|universal]] nor [[Definition:Negative Categorical Statement|negative]]. Thus the $\text{II}x$ pattern does not [[Definition:Distributed Term of Categorical Syllogism|distribute]] the [[Definition:Middle Term of Syllogism|middle term]] of $Q$. So $\text{II}x$ violates the rule [[Middle Term of Valid Categorical Syllogism is Distributed at least Once]]. $\text{O}$ is [[Definition:Negative Categorical Statement|negative]]. Thus $\text{OO}x$ violates the rule [[No Valid Categorical Syllogism contains two Negative Premises]]. It remains to investigate $\text{IO}x$ and $\text{OI}x$. By [[Conclusion of Valid Categorical Syllogism is Negative iff one Premise is Negative]], the [[Definition:Conclusion of Syllogism|conclusion]] of $Q$ is [[Definition:Negative Categorical Statement|negative]], either $\text{E}$ or $\text{O}$. By the definition of [[Definition:Distributed Predicate of Categorical Syllogism|Distributed Predicate of Categorical Syllogism]], the [[Definition:Predicate of Categorical Statement|predicate]] of the [[Definition:Conclusion of Syllogism|conclusion]] of $Q$ is [[Definition:Distributed Term of Categorical Syllogism|distributed]]. Thus, by construction, the [[Definition:Primary Term of Syllogism|primary term]] $P$ of $Q$ is [[Definition:Distributed Term of Categorical Syllogism|distributed]]. By [[Distributed Term of Conclusion of Valid Categorical Syllogism is Distributed in Premise]], it follows that $P$ is [[Definition:Distributed Term of Categorical Syllogism|distributed]] in the [[Definition:Major Premise of Syllogism|major premise]] of $Q$. This eliminates $\text{IO}x$ as the [[Definition:Particular Affirmative|particular affirmative]] $\text{I}$ [[Definition:Distributed Term of Categorical Syllogism|distributes]] neither its [[Definition:Subject of Categorical Statement|subject]] nor its [[Definition:Predicate of Categorical Statement|predicate]]. The final pattern to be investigated is $\text{OI}x$. By definition, $\text{O}$ [[Definition:Distributed Term of Categorical Syllogism|distributes]] only its [[Definition:Predicate of Categorical Statement|predicate]]. As $\text{O}$ needs to [[Definition:Distributed Term of Categorical Syllogism|distribute]] the [[Definition:Primary Term of Syllogism|primary term]] $P$, it cannot also [[Definition:Distributed Term of Categorical Syllogism|distribute]] the [[Definition:Middle Term of Syllogism|middle term]] $M$ of $Q$. But the [[Definition:Particular Affirmative|particular affirmative]] $\text{I}$ (as has been seen above) also does not [[Definition:Distributed Term of Categorical Syllogism|distribute]] $M$. Thus $M$ remains [[Definition:Undistributed Term of Categorical Syllogism|undistributed]], so violating the rule [[Middle Term of Valid Categorical Syllogism is Distributed at least Once]]. This eliminates $\text{OI}x$. {{qed}}	1
{{BeginTableau|\vdash \left({p \implies q}\right) \implies \left({\left({p \lor r}\right) \implies \left ({q \lor r}\right)}\right)}} {{Assumption|1|p \implies q}} {{SequentIntro|2|1|\left({p \lor r}\right) \implies \left ({q \lor r}\right)|1 |[[Factor Principles/Disjunction on Right/Formulation 1|Factor Principles: Disjunction on Right: Formulation 1]]}} {{Implication|3|1|\left({p \implies q}\right) \implies \left({\left({p \lor r}\right) \implies \left ({q \lor r}\right)}\right)|1|2}} {{EndTableau}} {{qed}}	1
{{finish|Use formulation 1 + Modus Ponens}}	1
[[Definition:ISBN-10|ISBN-$10$]] is an [[Definition:Error-Correcting Code|error-correcting code]] in the following sense:	1
:$\vdash \paren {p \land q} \implies \paren {p \lor q}$	1
{{BeginTableau|\vdash \paren {p \lor \paren {q \lor r} } \iff \paren {\paren {p \lor q} \lor r}|[[Definition:Hilbert Proof System/Instance 2|Instance 2 of the Hilbert-style systems]]}} {{TableauLine | n = 1 | f = \paren {p \lor \paren {q \lor r} } \implies \paren {\paren {p \lor q} \lor r} | rlnk = Rule of Association/Disjunction/Formulation 2/Forward Implication | rtxt = Rule of Association: Forward Implication }} {{TableauLine | n = 2 | f = \paren {\paren {p \lor q} \lor r} \implies \paren {p \lor \paren {q \lor r} } | rlnk = Rule of Association/Disjunction/Formulation 2/Reverse Implication | rtxt = Rule of Association: Reverse Implication }} {{TableauLine | n = 3 | f = \paren {\paren {p \lor \paren {q \lor r} } \implies \paren {\paren {p \lor q} \lor r} } \land \paren {\paren {\paren {p \lor q} \lor r} \implies \paren {p \lor \paren {q \lor r} } } | rlnk = Definition:Hilbert Proof System/Instance 2 | rtxt = Rule $RST \, 4$ | dep = 1,2 }} {{TableauLine | n = 4 | f = \paren {p \lor \paren {q \lor r} } \iff \paren {\paren {p \lor q} \lor r} | rlnk = Definition:Hilbert Proof System/Instance 2 | rtxt = Rule $RST \, 2 (3)$ | dep = 3 }} {{EndTableau}} {{qed}}	1
:$\neg p \implies q \vdash \neg q \implies p$	1
By definition of [[Definition:Tableau Proof (Propositional Tableaus)|tableau proof]], $\mathbf H \vdash_{\mathrm{PT}} \mathbf A$ means: :There exists a [[Definition:Tableau Confutation|tableau confutation]] of $\mathbf H \cup \set {\neg\mathbf A}$. By [[Tableau Confutation implies Unsatisfiable]], it follows that $\mathbf H \cup \set {\neg\mathbf A}$ is [[Definition:Unsatisfiable|unsatisfiable]] for [[Definition:Boolean Interpretation|boolean interpretations]]. Therefore, if some [[Definition:Boolean Interpretation|boolean interpretation]] $v$ [[Definition:Model (Boolean Interpretations)|models]] $\mathbf H$: :$v \models_{\mathrm{BI}} \mathbf H$ then since $\mathbf H \cup \set {\neg\mathbf A}$ is [[Definition:Unsatisfiable|unsatisfiable]]: :$v \not\models_{\mathrm{BI}} \neg\mathbf H$ Now by definition of [[Definition:Model (Boolean Interpretations)|the relation $\models_{\mathrm{BI}}$]], it must be that: :$\map v {\neg \mathbf A} = F$ By the [[Definition:Logical Not/Truth Table|truth table for $\neg$]], this implies: :$\map v {\mathbf A} = T$ which is to say $v \models_{\mathrm{BI}} \mathbf A$. Hence: :$v \models_{\mathrm{BI}} \mathbf H$ implies $v \models_{\mathrm{BI}} \mathbf A$ that is, $\mathbf A$ is a $\mathrm{BI}$-[[Definition:Semantic Consequence|semantic consequence]] of $\mathbf H$: :$\mathbf H \models_{\mathrm{BI}} \mathbf A$ which was to be shown. {{qed}}	1
{{BeginTableau|p \uparrow p \vdash \neg p}} {{Premise|1|p \uparrow p}} {{SequentIntro|2|1|\neg \left({p \land p}\right)|1|Definition of [[Definition:Logical NAND|Logical NAND]]}} {{Idempotence|3|1|\neg p|2|Conjunction}} {{EndTableau}} {{BeginTableau|\neg p \vdash p \uparrow p}} {{Premise|1|\neg p}} {{Idempotence|2|1|\neg \left({p \land p}\right)|1|Conjunction}} {{SequentIntro|3|1|p \uparrow p|2|Definition of [[Definition:Logical NAND|Logical NAND]]}} {{EndTableau}} {{qed}}	1
A '''theorem''' in [[Definition:Logic|logic]] is a [[Definition:Statement|statement]] which can be shown to be the [[Definition:Conclusion|conclusion]] of a [[Definition:Logical Argument|logical argument]] which [[Definition:Depend|depends]] on ''no'' [[Definition:Premise|premises]] except [[Definition:Axiom|axioms]]. A [[Definition:Sequent|sequent]] which denotes a theorem $\phi$ is written $\vdash \phi$, indicating that there are no premises. In this context, $\vdash$ is read as: :'''It is a theorem that ...'''	1
A '''(logical) fallacy''' is a [[Definition:Mistake|mistake]] caused by an application of an [[Definition:Invalid Argument|invalid argument]]. '''[[Definition:Fallacy|Logical fallacies]]''' abound. Most of the documented '''[[Definition:Fallacy|fallacies]]''' that can be found in the literature arise from linguistic imprecision or deliberately misleading statements, or both. Frequently the commission of '''[[Definition:Fallacy|fallacies]]''' is as deliberate as the telling of lies.	1
[[Definition:Axiom (Formal Systems)|Axiom]] $(A3)$ is [[Definition:Independent Axiom|independent]] from $(A1)$, $(A2)$, $(A4)$.	1
{{begin-eqn}} {{eqn | o = | r = \mathbf E \left({S, P}\right) | c = }} {{eqn | o = \implies | r = \forall x: S \left({x}\right) \implies \neg P \left({x}\right) | c = Definition of [[Definition:Universal Negative|Universal Negative]] }} {{eqn | o = \implies | r = \forall x: \neg \left({S \left({x}\right) \land P \left({x}\right)}\right) | c = [[Modus Ponendo Tollens/Variant|Modus Ponendo Tollens]] }} {{eqn | o = \implies | r = \forall x: \neg \left({P \left({x}\right) \land S \left({x}\right)}\right) | c = [[Conjunction is Commutative]] }} {{eqn | o = \implies | r = \forall x: P \left({x}\right) \implies \neg S \left({x}\right) | c = [[Modus Ponendo Tollens/Variant|Modus Ponendo Tollens]] }} {{eqn | o = \implies | r = \mathbf E \left({P, S}\right) | c = Definition of [[Definition:Universal Negative|Universal Negative]] }} {{end-eqn}} {{qed}}	1
Consider the [[Definition:Categorical Statement|categorical statements]]: :$\mathbf I: \quad$ The [[Definition:Particular Affirmative|particular affirmative]]: $\exists x: \map S x \land \map P x$ :$\mathbf E: \quad$ The [[Definition:Universal Negative|universal negative]]: $\forall x: \map S x \implies \neg \map P x$ Then $\mathbf I$ and $\mathbf E$ are [[Definition:Contradictory Statements|contradictory]]. Using the [[Definition:Symbolic Logic|symbology]] of [[Definition:Predicate Logic|predicate logic:]] :$\neg \paren {\paren {\exists x: \map S x \land \map P x} \iff \paren {\forall x: \map S x \implies \neg \map P x} }$	1
Let $\downarrow$ signify the [[Definition:Logical NOR|NOR]] operation. Then, for any two [[Definition:Proposition|propositions]] $p$ and $q$: :$p \downarrow q \dashv \vdash q \downarrow p$ That is, [[Definition:Logical NOR|NOR]] is [[Definition:Commutative Operation|commutative]].	1
From the [[Rule of Exportation]]: :$\paren {p \land q} \implies r \dashv \vdash p \implies \paren {q \implies r}$ Then by [[Self-Distributive Law for Conditional]]: :$p \implies \paren {q \implies r} \dashv \vdash \paren {p \implies q} \implies \paren {p \implies r}$ {{qed}} [[Category:Implication]] [[Category:Conjunction]] oc5bpk4w3hco5d9sobteg96jn3b38gs	1
The [[Factor Principles/Disjunction on Left/Formulation 2|Factor Principle]]: :$\left({p \implies q}\right) \implies \left({\left({r \lor p}\right) \implies \left ({r \lor q}\right)}\right)$ is a [[Definition:Tautology (Formal Semantics)|tautology]] in [[Definition:Constructed Semantics/Instance 1|Instance 1]] of [[Definition:Constructed Semantics|constructed semantics]].	1
Let $\mathcal P$ be a [[Definition:Proof System|proof system]] for a [[Definition:Formal Language|formal language]] $\mathcal L$. Let $\mathcal F$ be a collection of [[Definition:Theorem (Formal Systems)|theorems]] of $\mathcal P$. Denote with $\mathscr P \left({\mathcal F}\right)$ the [[Definition:Proof System|proof system]] obtained from $\mathscr P$ by adding all the [[Definition:Well-Formed Formula|WFFs]] from $\mathcal F$ as [[Definition:Axiom (Formal Systems)|axioms]]. Let $\phi$ be a [[Definition:Provable Consequence|provable consequence]] of $\mathcal F$: :$\vdash_{\mathscr P} \mathcal F$ :$\mathcal F \vdash_{\mathscr P} \phi$ Then $\phi$ is also a [[Definition:Theorem (Formal Systems)|theorem]] of $\mathscr P$: :$\vdash_{\mathscr P} \phi$	1
:$p \iff q \dashv \vdash \left({p \implies q}\right) \land \left({q \implies p}\right)$	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] are $T$ for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc|c|c||c|c|} \hline p & \land & q & p & q & p \land q \implies p & p \land q \implies q \\ \hline F & F & F & F & F & T & T \\ F & F & T & F & T & T & T \\ T & F & F & T & F & T & T \\ T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
{{BeginTableau|p \iff \top \vdash p}} {{Premise|1|p \iff \top}} {{TopIntro|2}} {{BiconditionalElimination|3|1|\top \implies p|1|2}} {{ModusPonens|4|1|p|2|3}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|p \vdash p \iff \top}} {{Premise|1|\top}} {{Assumption|2|p}} {{TopIntro|3}} {{Implication|4||p \implies \top|2|3}} {{Implication|5|2|\top \implies p|1|2}} {{BiconditionalIntro|6|2|p \iff \top|4|5}} {{EndTableau}} {{qed}}	1
We note that: :$n = m \iff \size {n - m} = 0$ :$n \ne m \iff \size {n - m} > 0$ So it can be seen that the [[Definition:Characteristic Function of Relation|characteristic function]] of $\operatorname{eq}$ is given by: :$\map {\chi_{\operatorname {eq} } } {n, m} = \overline {\map \sgn {\map {\operatorname {adf} } {n, m} } }$. So $\map {\chi_{\operatorname {eq} } } {n, m}$ is defined by [[Definition:Substitution (Mathematical Logic)|substitution]] from: :the [[Signum Function is Primitive Recursive|primitive recursive function $\overline \sgn$]] :the [[Absolute Difference Function is Primitive Recursive|primitive recursive function $\operatorname {adf}$]]. Thus $\chi_{\operatorname {eq} }$ is [[Definition:Primitive Recursive Function|primitive recursive]]. Hence the result. {{qed}} [[Category:Primitive Recursive Functions]] 3mhxju2w14zy60wrzqxyz4rmrvauwcf	1
The '''syntax''' of a language (either [[Definition:Natural Language|natural]] or [[Definition:Formal Language|formal]]) is its ''structure''.	1
[[Definition:Set|Sets]] have [[Definition:Element|elements]]. Some of those elements may themselves be sets. So, given two sets $S$ and $T$, we can ask the question: Is $S$ an element of $T$? The answer will either be ''yes'' or ''no''. In particular, given any set $S$, we can ask the question: Is $S$ an element of $S$? Again, the answer will either be ''yes'' or ''no''. Thus, $\map P S = S \in S$ is a [[Definition:Property|property]] on which we can use the [[Axiom:Comprehension Principle|comprehension principle]] to build this set: :$T = \set {S: S \in S}$ which is the set of all sets which contain themselves. Or we can apply the [[Axiom:Comprehension Principle|comprehension principle]] to build this set: :$R = \set {S: S \notin S}$ ($R$ for {{AuthorRef|Bertrand Russell|Russell}}, of course.) We ask the question: Is $R$ itself an element of $R$? There are two possible answers: ''yes'' or ''no''. If $R \in R$, then $R$ must satisfy the property that $R \notin R$, so from that [[Definition:Contradiction|contradiction]] we know that $R \in R$ does not hold. So the only other answer, $R \notin R$, must hold instead. But now we see that $R$ satisfies the conditions of the property that $R \in R$, so we can see that $R \notin R$ does not hold either. Thus we have generated a [[Definition:Contradiction|contradiction]] from the [[Axiom:Comprehension Principle|comprehension principle]]. {{qed}}	1
: $\vdash \left({p \implies q}\right) \implies \left({\left({r \lor p}\right) \implies \left ({r \lor q}\right)}\right)$	1
Let $P$ be a [[Definition:URM Program|URM program]]. Let $l = \map \lambda P$ be the [[Definition:Unlimited Register Machine#Length of Program|number of basic instructions]] in $P$. Let $u = \map \rho P$ be the [[Definition:Unlimited Register Machine#Number of Registers Used|number of registers used]] by $P$. Then $P$ can be modified as follows: :Every <tt>Jump</tt> of the form $\map J {m, n, q}$ where $q > l$ may be replaced by $\map J {m, n, l + 1}$ :If $u > 0$, a [[Clear Registers Program]] $\map Z {2, u}$ can be appended to the end of $P$ at lines $l + 1$ to $l + u - 1$. The new program $P'$ that results from the above modifications produces exactly the same [[Definition:Unlimited Register Machine#Output|output]] as $P$ for each [[Definition:Unlimited Register Machine#Input|input]]. Note now though that $\map \lambda {P'} = l + u - 1$. Such a program as $P'$ is called a '''normalized URM program'''. The point of doing this is so as to make programs easier to [[Definition:Concatenation of URM Programs|concatenate]]. Once the above have been done, each program has a well-defined [[Definition:Unlimited Register Machine#Termination|exit line]] which can be used as the start line of the program that immediately follows it.	1
Since $\mathcal F$ is [[Definition:Satisfiable Set of Formulas|$\mathscr M$-satisfiable]], there exists some [[Definition:Model of Set of Formulas|model]] $\mathcal M$ of $\mathcal F$: :$\mathcal M \models_{\mathscr M} \mathcal F$ Since $\psi$ is a [[Definition:Tautology (Formal Semantics)|tautology]], also: :$\mathcal M \models_{\mathscr M} \psi$ Therefore, we conclude that: :$\mathcal M \models_{\mathscr M} \mathcal F \cup \left\{{\phi}\right\}$ i.e., $\mathcal F \cup \left\{{\phi}\right\}$ is [[Definition:Satisfiable Set of Formulas|satisfiable]].	1
Let $U = \set {\phi_1, \phi_2, \ldots, \phi_m, \ldots}$ be a [[Definition:Countable|countable set]] of [[Definition:Propositional Formula|propositional formulas]]. Let $\psi$ be a [[Definition:Propositional Formula|propositional formula]]. Then $U \models \psi$ {{iff}} $U \vdash \psi$. That is, [[Definition:Semantic Consequence|semantic consequence]] is equivalent to [[Definition:Provable Consequence|provable consequence]].	1
Let $S \subseteq \N$ be a [[Definition:Subset|subset]] of the [[Definition:Natural Numbers|natural numbers]]. Suppose that: :$(1): \quad 0 \in S$ :$(2): \quad \forall n \in \N : n \in S \implies n + 1 \in S$ Then: :$S = \N$	1
Any [[Definition:Model (Logic)|model]] of $\FF \cup \FF'$ is [[Definition:A Fortiori|a fortiori]] also a [[Definition:Model (Logic)|model]] of $\FF$. By definition of [[Definition:Semantic Consequence|semantic consequence]] all [[Definition:Model (Logic)|models]] of $\FF$ are [[Definition:Model (Logic)|models]] of $\phi$. Therefore all [[Definition:Model (Logic)|models]] of $\FF \cup \FF'$ are also [[Definition:Model (Logic)|models]] of $\phi$. Hence: :$\FF \cup \FF' \models_{\mathscr M} \phi$ as desired. {{qed}} [[Category:Formal Semantics]] cowaaykdur0gx37z85obu9qhreoc7ck	1
Let $C$ be a [[Definition:Linear Code|linear $\tuple {n, k}$-code]] whose [[Definition:Master Code|master code]] is $\map V {n, p}$ Let $G$ be a [[Definition:Standard Generator Matrix for Linear Code|(standard) generator matrix]] for $C$. Let $P$ be a [[Definition:Standard Parity Check Matrix|standard parity check matrix]] for $C$. Let $w \in \map V {n, p}$. Then the [[Definition:Syndrome|syndrome]] of $w$ is [[Definition:Zero Codeword|zero]] {{iff}} $w$ is a [[Definition:Codeword of Linear Code|codeword]] of $C$.	1
An '''axiom''' in [[Definition:Logic|logic]] is a [[Definition:Statement|statement]] which is taken as '''self-evident'''. Note, however, that there has been disagreement for as long as there have been logicians and philosophers as to whether particular [[Definition:Statement|statements]] are true or not. For example, the [[Law of Excluded Middle]] is accepted as axiomatic by philosophers and logicians of the [[Definition:Aristotelian Logic|Aristotelian school]] but is denied by the [[Definition:Intuitionist School|intuitionist school]].	1
As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|cccc||c|} \hline \neg & p & \implies & \bot & p \\ \hline T & F & F & F & F \\ F & T & T & F & T \\ \hline \end{array}$ {{qed}}	1
{{BeginTableau|\top \implies p \vdash p}} {{Premise|1|\top \implies p}} {{TopIntro|2}} {{ModusPonens|3|1|p|1|2}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|p \vdash \top \implies p}} {{Premise|1|p}} {{Assumption|2|\top}} {{Implication|3|1|\top \implies p|2|1}} {{EndTableau}} {{qed}}	1
{{BeginTableau|p \uparrow q \vdash q \uparrow p}} {{Premise|1|p \uparrow q}} {{SequentIntro|2|1|\neg \left({p \land q}\right)|1||Definition of [[Definition:Logical NAND|Logical NAND]]}} {{Commutation|3|1|\neg \left({q \land p}\right)|2|Conjunction}} {{SequentIntro|4|1|q \uparrow p|3||Definition of [[Definition:Logical NAND|Logical NAND]]}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|q \uparrow p \vdash p \uparrow q}} {{Premise|1|q \uparrow p}} {{SequentIntro|2|1|\neg \left({q \land p}\right)|1||Definition of [[Definition:Logical NAND|Logical NAND]]}} {{Commutation|3|1|\neg \left({p \land q}\right)|2|Conjunction}} {{SequentIntro|4|1|p \uparrow q|3||Definition of [[Definition:Logical NAND|Logical NAND]]}} {{EndTableau}} {{qed}}	1
We are to show that: :$\left({x \times y}\right) \times n = x \times \left({y \times n}\right)$ for all $x, y, n \in \N$. From the definition of [[Definition:Natural Number Multiplication|natural number multiplication]], we have that: {{begin-eqn}} {{eqn | ll= \forall m, n \in \N: | l = m \times 0 | r = 0 | c = }} {{eqn | l = m \times \left({n + 1}\right) | r = \left({m \times n}\right) + m | c = }} {{end-eqn}} Let $x, y \in \N$ be arbitrary. For all $n \in \N$, let $P \left({n}\right)$ be the [[Definition:Proposition|proposition]]: :$\left({x \times y}\right) \times n = x \times \left({y \times n}\right)$ === Basis for the Induction === $P \left({0}\right)$ is the case: {{begin-eqn}} {{eqn | l = \left({x \times y}\right) \times 0 | r = 0 }} {{eqn | r = x \times 0 }} {{eqn | r = x \times \left({y \times 0}\right) }} {{end-eqn}} and so $P \left({0}\right)$ holds. This is our [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $P \left({k}\right)$ is true, where $k \ge 0$, then it logically follows that $P \left({k + 1}\right)$ is true. So this is our [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$\left({x \times y}\right) \times k = x \times \left({y \times k}\right)$ Then we need to show: :$\left({x \times y}\right) \times \left({k + 1 }\right) = x \times \left({y \times \left({k + 1}\right)}\right)$ === Induction Step === This is our [[Principle of Mathematical Induction#Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \left({x \times y}\right) \times \left({k + 1 }\right) | r = \left({\left({x \times y}\right) \times k}\right) + \left({x \times y}\right) | c = Definition of [[Definition:Natural Number Multiplication|Natural Number Multiplication]] }} {{eqn | r = \left({x \times \left({y \times k}\right)}\right) + \left({x \times y}\right) | c = [[Natural Number Multiplication is Associative/Proof 2#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \left({x \times y}\right) + \left({x \times \left({y \times k}\right)}\right) | c = [[Natural Number Addition is Commutative]] }} {{eqn | r = x \times \left({y + \left({y \times k}\right)}\right) | c = [[Natural Number Multiplication Distributes over Addition]] }} {{eqn | r = x \times \left({\left({y \times k}\right) + y}\right) | c = [[Natural Number Addition is Commutative]] }} {{eqn | r = x \times \left({y \times \left({k + 1 }\right)}\right) | c = Definition of [[Definition:Natural Number Multiplication|Natural Number Multiplication]] }} {{end-eqn}} So $P \left({k}\right) \implies P \left({k + 1}\right)$ and the result follows by the [[Principle of Mathematical Induction]]. {{qed}}	1
Consider the [[Definition:Matching Pennies|game of Matching Pennies]]. Recall its [[Definition:Matching Pennies/Payoff Table|payoff table]]: {{:Definition:Matching Pennies/Payoff Table}} Trivially, by inspection, this has no [[Definition:Entry in Payoff Table|entry]] which is the smallest [[Definition:Entry in Payoff Table|entry]] in its row and the largest [[Definition:Entry in Payoff Table|entry]] in its column. {{qed}}	1
Follows from [[Cancellation of Join in Boolean Algebra]] through the [[Duality Principle (Boolean Algebras)|Duality Principle]] {{qed}}	1
{{BeginTableau|p \implies q, q \implies r, p \vdash r}} {{Premise|1|p \implies q}} {{Premise|2|q \implies r}} {{Premise|3|p}} {{SequentIntro|4|1, 2|p \implies r|1, 2|[[Hypothetical Syllogism/Formulation 1|Hypothetical Syllogism: Formulation 1]]}} {{ModusPonens|5|1, 2, 3|r|4|3}} {{EndTableau}} {{qed}}	1
{{begin-eqn}} {{eqn | l = p \oplus q | o = \dashv \vdash | r = \neg \left ({p \iff q}\right) | c = [[Exclusive Or is Negation of Biconditional]] }} {{eqn | o = \dashv \vdash | r = \left({\neg p \land q}\right) \lor \left({p \land \neg q}\right) | c = [[Non-Equivalence as Disjunction of Conjunctions/Formulation 1|Non-Equivalence as Disjunction of Conjunctions]] }} {{end-eqn}} {{qed}}	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, the [[Definition:Truth Value|truth values]] in the appropriate columns match. $\begin{array}{|c||cc|} \hline \top & \neg & \bot \\ \hline T & T & F \\ \hline \end{array}$ {{qed}}	1
We prove this result by [[Principle of Mathematical Induction|induction]]: For all $n \in \N_{>0}$, let $\map P N$ be the [[Definition:Proposition|proposition]]: :if $G$ has $2 n$ [[Definition:Odd Vertex (Graph Theory)|odd vertices]], it consists entirely of $n$ [[Definition:Edge-Disjoint Trails|edge-disjoint trails]], each starting and ending on an [[Definition:Odd Vertex (Graph Theory)|odd vertex]]. First note that from the [[Handshake Lemma/Corollary|corollary to the Handshake Lemma]], no graph can have an [[Definition:Odd Integer|odd number]] of [[Definition:Odd Vertex (Graph Theory)|odd vertices]]. === Basis for the Induction === $\map P 1$ is true, as this is the [[Characteristics of Traversable Graph]]. This is our [[Definition:Basis for the Induction|basis for the induction]]. Note that, from the same result, the trail starts and ends on an [[Definition:Odd Vertex (Graph Theory)|odd vertex]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :If $G$ has $2 k$ [[Definition:Odd Vertex (Graph Theory)|odd vertices]], it consists entirely of $k$ [[Definition:Edge-Disjoint Trails|edge-disjoint trails]], each starting and ending on an [[Definition:Odd Vertex (Graph Theory)|odd vertex]]. Then we need to show: :If $G$ has $2 \paren {k + 1}$ [[Definition:Odd Vertex (Graph Theory)|odd vertices]], it consists entirely of $k + 1$ [[Definition:Edge-Disjoint Trails|edge-disjoint trails]], each starting and ending on an [[Definition:Odd Vertex (Graph Theory)|odd vertex]]. === Induction Step === This is our [[Definition:Induction Step|induction step]]: Let $G_{k + 1}$ be a [[Definition:Undirected Graph|graph]] with $2 \paren {k + 1}$ odd vertices. Let $u, v$ be any pair of odd vertices in $G_{k + 1}$. We construct the graph $G'_{k + 1}$ which consists of $G_{k + 1}$ with the [[Definition:Edge of Graph|edge]] $u v$ added. It can be seen that as $u, v$ are now [[Definition:Even Vertex (Graph Theory)|even vertices]], $G'_{k + 1}$ has $2 k$ [[Definition:Odd Vertex (Graph Theory)|odd vertices]]. By our [[Odd Vertices Determines Edge-Disjoint Trails#Induction Hypothesis|induction hypothesis]], we know that $G'_{k + 1}$ consists entirely of $k$ [[Definition:Edge-Disjoint Trails|edge-disjoint trails]]. So, let us construct these [[Definition:Edge-Disjoint Trails|trails]]: let them be $T_1, T_2, \ldots, T_k$. The [[Definition:Edge of Graph|edge]] $u v$ must be somewhere in one of the above [[Definition:Edge-Disjoint Trails|trails]]. As the $k$ [[Definition:Edge-Disjoint Trails|trails]] are all [[Definition:Edge-Disjoint Trails|edge-disjoint]], it will be in [[Definition:Unique|exactly one]]. Suppose it is in $T_j$. As $T_j$ must start and end on an [[Definition:Odd Vertex (Graph Theory)|odd vertex]], $u v$ must be neither at the start nor the end of such a [[Definition:Edge-Disjoint Trails|trail]]. Suppose $T_j = \tuple {t_1, t_2, \ldots, u, v, \ldots, t_r}$. Then it follows that $t_1$ and $t_r$ are [[Definition:Odd Vertex (Graph Theory)|odd vertices]]. Now we remove $u v$ from $G'_{k + 1}$ so as to return to $G_{k + 1}$. We see that $G_{k + 1}$ consists entirely of the [[Definition:Edge-Disjoint Trails|edge-disjoint trails]]: :$T_1, T_2, \ldots, T_{j - 1}$ :$T_{j + 1}, T_{j + 2}, \ldots, T_k$ :The two trails: $\tuple {t_1, t_2, \ldots, u}$ and $\tuple {v, \ldots, t_r}$. That makes $k + 1$ [[Definition:Edge-Disjoint Trails|edge-disjoint trails]]. Also note that as $u$ and $v$ are [[Definition:Odd Vertex (Graph Theory)|odd vertices]], both of $\tuple {t_1, t_2, \ldots, u}$ and $\tuple {v, \ldots, t_r}$ start and end on [[Definition:Odd Vertex (Graph Theory)|odd vertices]]. So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. {{qed}}	1
:$\vdash \paren {p \implies \paren {q \land r} } \iff \paren {\paren {p \implies q} \land \paren {p \implies r} }$	1
Let $\left({S, \vee, \wedge, \neg}\right)$ be a [[Definition:Boolean Algebra|Boolean algebra]]. Then for all $a \in S$: :$\neg (\neg a) = a$	1
{{BeginTableau|p \lor q \vdash \neg \left({\neg p \land \neg q}\right)}} {{Premise|1|p \lor q}} {{Assumption|2|\neg p \land \neg q}} {{Simplification|3|2|\neg p|2|1}} {{Simplification|4|2|\neg q|2|2}} {{Assumption|5|p}} {{NonContradiction|6|2, 5|5|3}} {{Assumption|7|q}} {{NonContradiction|8|2, 7|7|4}} {{ProofByCases|9|1, 2|\bot|1|5|6|7|8}} {{Contradiction|10|1|\neg \left({\neg p \land \neg q}\right)|2|9}} {{EndTableau}} {{qed}}	1
{{BeginTableau|\neg \left ({p \iff q}\right) \vdash \left({p \lor q} \right) \land \neg \left({p \land q}\right)}} {{Premise|1|\neg \left ({p \iff q}\right)}} {{SequentIntro|2|1|\left({\neg p \land q}\right) \lor \left({p \land \neg q}\right)|1 |[[Non-Equivalence as Disjunction of Conjunctions/Formulation 1|Non-Equivalence as Disjunction of Conjunctions: Formulation 1]] }} {{Commutation|3|1|\left({p \land \neg q}\right) \lor \left({\neg p \land q}\right)|2|Disjunction}} {{Commutation|4|1|\left({p \land \neg q}\right) \lor \left({q \land \neg p}\right)|3|Conjunction}} {{SequentIntro|5|1 |\left ({\left({p \lor q}\right) \land \neg q}\right) \lor \left({\left({q \lor p}\right) \land \neg p}\right) |4 |[[Conjunction of Disjunction with Negation is Conjunction with Negation]] }} {{Commutation|6|1 |\left ({\left({p \lor q}\right) \land \neg q}\right) \lor \left({\left({p \lor q}\right) \land \neg p}\right) |5|Disjunction}} {{SequentIntro|7|1|\left({p \lor q}\right) \land \left({\neg q \lor \neg p}\right)|6 |[[Conjunction Distributes over Disjunction]] }} {{Commutation|8|1|\left({p \lor q}\right) \land \left({\neg p \lor \neg q}\right)|7|Disjunction}} {{DeMorgan|9|1|\left({p \lor q}\right) \land \neg \left({\neg \neg p \land \neg \neg q}\right)|8|Disjunction}} {{DoubleNegElimination|10|1|\left({p \lor q}\right) \land \neg \left({p \land q}\right)|9}} {{EndTableau}} {{BeginTableau|\left({p \lor q} \right) \land \neg \left({p \land q}\right) \vdash \neg \left ({p \iff q}\right)}} {{Premise|1|\left({p \lor q}\right) \land \neg \left({p \land q}\right)}} {{DeMorgan|2|1|\left({p \lor q}\right) \land \left({\neg p \lor \neg q}\right)|1|Disjunction of Negations}} {{Commutation|3|1|\left({p \lor q}\right) \land \left({\neg p \lor \neg q}\right)|2|Disjunction}} {{SequentIntro|4|1 |\left ({\left({p \lor q}\right) \land \neg q}\right) \lor \left({\left({p \lor q}\right) \land \neg p}\right) |3 |[[Conjunction Distributes over Disjunction]] }} {{SequentIntro|5|1|\left({p \land \neg q}\right) \lor \left({q \land \neg p}\right)|4|[[Conjunction of Disjunction with Negation is Conjunction with Negation]]}} {{Commutation|6|1|\left({q \land \neg p}\right) \lor \left({p \land \neg q}\right)|5|Disjunction}} {{Commutation|7|1|\left({\neg p \land q}\right) \lor \left({p \land \neg q}\right)|6|Conjunction}} {{SequentIntro|8|1|\neg \left ({p \iff q}\right)|6|[[Non-Equivalence as Disjunction of Conjunctions/Formulation 1|Non-Equivalence as Disjunction of Conjunctions: Formulation 1]]}} {{EndTableau}} {{qed}}	1
The [[Well-Ordering Principle]], the [[Principle of Finite Induction]] and the [[Principle of Complete Finite Induction]] are [[Definition:Logical Equivalence|logically equivalent]]. That is: :[[Principle of Finite Induction]]: Given a [[Definition:Subset|subset]] $S \subseteq \N$ of the [[Definition:Natural Numbers|natural numbers]] which has these properties: :: $0 \in S$ :: $n \in S \implies n + 1 \in S$ :then $S = \N$. {{iff}}: :[[Principle of Complete Finite Induction]]: Given a [[Definition:Subset|subset]] $S \subseteq \N$ of the [[Definition:Natural Numbers|natural numbers]] which has these properties: :: $0 \in S$ :: $\set {0, 1, \ldots, n} \subseteq S \implies n + 1 \in S$ :then $S = \N$. {{iff}}: :[[Well-Ordering Principle]]: Every [[Definition:Non-Empty Set|non-empty]] [[Definition:Subset|subset]] of $\N$ has a [[Definition:Minimal Element|minimal element]].	1
{{BeginTableau|p \lor q \vdash q \lor p}} {{Premise|1|p \lor q}} {{Assumption|2|p}} {{Addition|3|2|q \lor p|2|2}} {{Assumption|4|p}} {{Addition|5|4|q \lor p|4|1}} {{ProofByCases|6|1|q \lor p|1|2|3|4|5}} {{EndTableau}} {{qed}} {{BeginTableau|q \lor p \vdash p \lor q}} {{Premise|1|q \lor p}} {{Assumption|2|q}} {{Addition|3|2|p \lor q|2|2}} {{Assumption|4|p}} {{Addition|5|4|p \lor q|4|1}} {{ProofByCases|6|1|p \lor q|1|2|3|4|5}} {{EndTableau}} {{qed}}	1
From [[Functional Completeness over Finite Number of Arguments]], it suffices to consider binary [[Definition:Truth Function|truth functions]]. From [[Count of Truth Functions]], there are $16$ of these. These are enumerated in [[Binary Truth Functions]], and are analysed in turn as follows. === Constant Functions === There are two [[Definition:Constant Mapping|constant functions]]: {{begin-eqn}} {{eqn | l = f_F \left({p, q}\right) | r = F }} {{eqn | l = f_T \left({p, q}\right) | r = T }} {{end-eqn}} From [[Biconditional Properties]] and [[Exclusive Or Properties]]: {{begin-eqn}} {{eqn | l = p \iff p | o = \dashv \vdash | r = \top \dashv \vdash f_T \left({p, q}\right) }} {{eqn | l = p \oplus p | o = \dashv \vdash | r = \bot \dashv \vdash f_F \left({p, q}\right) }} {{end-eqn}} where $\oplus$ and $\iff$ denote [[Definition:Exclusive Or|exclusive or]] and [[Definition:Biconditional|biconditional]] respectively. So both of the constant functions can be expressed in terms of $\oplus$ and $\iff$. {{qed|lemma}} === Equivalence and Non-Equivalence === By definition of [[Definition:Exclusive Or|exclusive or]]: : $p \oplus q \dashv \vdash \neg \left({p \iff q}\right)$. Thus $\oplus$ can be expressed in terms of $\neg$ and $\iff$. By definition of [[Definition:Biconditional|biconditional]]: : $p \iff q \dashv \vdash \left({p \implies q}\right) \land \left({q \implies p}\right)$ Thus $\iff$ can be expressed in terms of $\implies$ and $\land$. {{qed|lemma}} === Projections and Negated Projections === There are two [[Definition:Projection (Mapping Theory)|projections]]: : $\operatorname{pr}_1 \left({p, q}\right) = p$ : $\operatorname{pr}_2 \left({p, q}\right) = q$ We note that: : $p \land p \dashv \vdash p \dashv \vdash \operatorname{pr}_1 \left({p, q}\right)$ : $p \lor p \dashv \vdash p \dashv \vdash \operatorname{pr}_1 \left({p, q}\right)$ and similarly for $\operatorname{pr}_2 \left({p, q}\right)$. So the [[Definition:Projection (Mapping Theory)|projections]] can be expressed in terms of either $\land$ or $\lor$. There are two [[Definition:Logical Not|negated]] [[Definition:Projection (Mapping Theory)|projections]]: : $\overline {\operatorname{pr}_1} \left({p, q}\right) = \neg p$ : $\overline {\operatorname{pr}_2} \left({p, q}\right) = \neg q$ It immediately follows from the above that these can be expressed in terms of either: : $\neg$ and $\land$ or: : $\neg$ and $\lor$ {{qed|lemma}} === NAND and NOR === There are the [[Definition:Logical NAND|NAND]] and [[Definition:Logical NOR|NOR]] operators: : $p \uparrow q$ : $p \downarrow q$ By definition of [[Definition:Logical NAND|NAND]]: : $p \uparrow q \dashv \vdash \neg \left({p \land q}\right)$ By definition of [[Definition:Logical NOR|NOR]]: : $p \downarrow q \dashv \vdash \neg \left({p \lor q}\right)$ So: : $\uparrow$ can be expressed in terms of $\neg$ and $\land$ : $\downarrow$ can be expressed in terms of $\neg$ and $\lor$ {{qed|lemma}} === Conjunction, Disjunction, Conditional === There are the [[Definition:Conjunction|conjunction]] and [[Definition:Disjunction|disjunction]] operators: : $p \land q$ : $p \lor q$ There are two [[Definition:Conditional|conditionals]]: : $p \implies q$ : $q \implies p$ There are two [[Definition:Logical Not|negated]] [[Definition:Conditional|conditionals]]: : $\neg \left({p \implies q}\right)$ : $\neg \left({q \implies p}\right)$ All of the above are already expressed in terms of $\neg, \land, \lor, \implies$. {{qed|lemma}} Thus all sixteen of the [[Binary Truth Functions]] can be expressed in terms of: : $\neg, \land, \lor, \implies$ That is: : $\left\{{\neg, \land, \lor, \implies}\right\}$ is [[Definition:Functionally Complete|functionally complete]]. {{qed}} [[Category:Functional Completeness]] 0qv4fsb1giyp2qwmxxefz3707f3rl8b	1
{{BeginTableau|\vdash \left({\neg \left({p \lor q}\right)}\right) \implies \left({\neg p \land \neg q}\right)}} {{Assumption|1|\neg \left({p \lor q}\right)}} {{SequentIntro|2|1|\neg p \land \neg q|1|[[De Morgan's Laws (Logic)/Conjunction of Negations/Formulation 1/Reverse Implication|De Morgan's Laws (Logic): Conjunction of Negations: Formulation 1]]}} {{Implication|3||\left({\neg \left({p \lor q}\right)}\right) \implies \left({\neg p \land \neg q}\right)|1|2}} {{EndTableau}} {{qed}} [[Category:De Morgan's Laws (Logic)]] lz2c718vtnmt72duwxve8dch6pc4scd	1
{{BeginTableau|\bot \implies p \vdash \top}} {{Premise|1|\bot \implies p}} {{TopIntro|2}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|\top \vdash \bot \implies p}} {{Assumption|1|\bot}} {{Premise|2|\top}} {{Explosion|3|1|p|1}} {{Implication|4||\bot \implies p|1|3}} {{EndTableau}} {{qed}}	1
The set of all [[Definition:Finitely Satisfiable|finitely satisfiable]] [[Definition:Mathematical Theory|$\mathcal L$-theories]] containing $T$ forms an [[Definition:Ordered Set|ordered set]] using [[Definition:Subset|subset inclusion]] as the [[Definition:Ordering|ordering]]. {{explain|Link to "subset is ordering"}} Let $C$ be a [[Definition:Non-Empty Set|nonempty]] [[Definition:Chain (Set Theory)|chain]] in this ordered set. Let $\displaystyle T_C = \bigcup_{\Sigma \mathop \in C} \Sigma$. Let $\Delta$ be a [[Definition:Finite Subset|finite subset]] of $T_C$. Then there exists a single $\Sigma$ in $C$ which contains $\Delta$. Since this $\Sigma$ is finitely satisfiable by definition, this means that $\Delta$ is satisfiable. Hence $T_C$ is finitely satisfiable. Since each $\Sigma \in C$ is contained in $T_C$, this means that $T_C$ is an upper bound for $C$ in the ordered set. Thus, by [[Zorn's Lemma]], there is a finitely satisfiable $\mathcal L$-theory $T'$ containing $T$ such that $T'$ contains all other such theories. Let $\phi$ be an $\mathcal L$-sentence. Let $\phi \nsubseteq T'$. Aiming for a contradiction, suppose $T' \cup \left\{ {\phi}\right\}$ were finitely satisfiable. Then by definition of $T'$, $T'$ would contain $T' \cup \left\{ {\phi}\right\}$ as a subset. This would mean that $T'$ contains $\phi$, which contradicts the assumption. Thus $T' \cup \left\{ {\phi}\right\}$ is not finitely satisfiable. By the [[Finitely Satisfiable Theory has Maximal Finitely Satisfiable Extension/Lemma|lemma]], $T' \cup \left\{ {\neg \phi}\right\}$ is finitely satisfiable. Thus, by definition of $T'$, $T'$ contains $T' \cup \left\{{\neg \phi}\right\}$ as a [[Definition:Subset|subset]]. Hence $T'$ contains $\neg \phi$. {{qed}}	1
The proof proceeds by [[Principle of Mathematical Induction|induction]]. For all $n \in \Z_{\ge 2}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\exists \mathbf A, \mathbf B \in \map {\MM_R} n: \mathbf {A B} \ne \mathbf {B A}$ === Edge Cases === ==== $n = 1$ ==== Consider the case where $n = 1$. Then: {{begin-eqn}} {{eqn | l = \mathbf {A B} | r = a_{11} b_{11} }} {{eqn | l = \mathbf {B A} | r = b_{11} a_{11} | c = }} {{end-eqn}} and it follows that [[Definition:Matrix Product (Conventional)|(conventional) matrix multiplication]] over $\map {\MM_R} 1$ is [[Definition:Commutative Operation|commutative]] {{iff}} $R$ is a [[Definition:Commutative Ring|commutative ring]]. ==== $R$ not a [[Definition:Ring with Unity|Ring with Unity]] ==== Consider the case where $R$ is not a [[Definition:Ring with Unity|ring with unity]], and is a general [[Definition:Ring (Abstract Algebra)|ring]]. Let $R$ be the [[Definition:Trivial Ring|trivial ring]]. From [[Matrix Multiplication on Square Matrices over Trivial Ring is Commutative]]: :$\forall \mathbf A, \mathbf B \in \map {\MM_R} n: \mathbf {A B} = \mathbf {B A}$ Hence the result does not follow for all [[Definition:Ring (Abstract Algebra)|rings]]. It is not established at this point on exactly which [[Definition:Ring (Abstract Algebra)|rings]] [[Definition:Matrix Product (Conventional)|(conventional) matrix multiplication]] $\map {\MM_R} n$ [[Definition:Commutative Operation|commutes]]. However, the existence of just one such [[Definition:Ring (Abstract Algebra)|ring]] (the [[Definition:Trivial Ring|trivial ring]]) warns us that we cannot apply the main result to ''all'' [[Definition:Ring (Abstract Algebra)|rings]]. ==== Matrices are not Square ==== We note that $\mathbf A \mathbf B$ is defined when: :$\mathbf A = \sqbrk a_{m n}$ is an [[Definition:Matrix|$m \times n$ matrix]] :$\mathbf B = \sqbrk b_{n p}$ is an [[Definition:Matrix|$n \times p$ matrix]]. Hence for both $\mathbf A \mathbf B$ and $\mathbf B \mathbf A$ to be defined, it is necessary that: :$\mathbf A = \sqbrk a_{m n}$ is an [[Definition:Matrix|$m \times n$ matrix]] :$\mathbf B = \sqbrk b_{n p}$ is an [[Definition:Matrix|$n \times m$ matrix]] for some $m, n \in \Z_{>0}$. But in this situation: :$\mathbf A \mathbf B$ is an [[Definition:Matrix|$m \times m$ matrix]] while: :$\mathbf B \mathbf A$ is an [[Definition:Matrix|$n \times n$ matrix]] and so if $\mathbf A$ and $\mathbf B$ are not [[Definition:Square Matrix|square matrices]], they cannot [[Definition:Commute|commute]]. === Basis for the Induction === From [[Matrix Multiplication is not Commutative/Order 2 Square Matrices|Matrix Multiplication is not Commutative/Order 2 Square Matrices]], it is seen that there exist $2 \times 2$ matrices that don't commute under [[Definition:Matrix Product (Conventional)|matrix multiplication]], thus proving the result for $n = 2$. $\map P 2$ is the case: :$\exists \mathbf A, \mathbf B \in \map {\MM_R} 2: \mathbf {A B} \ne \mathbf {B A}$ This is demonstrated in [[Matrix Multiplication is not Commutative/Order 2 Square Matrices|Matrix Multiplication is not Commutative: Order $2$ Square Matrices]]. Thus $\map P 2$ is seen to hold. This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is the [[Definition:Induction Hypothesis|induction hypothesis]]: :$\exists \mathbf A, \mathbf B \in \map {\MM_R} k: \mathbf {A B} \ne \mathbf {B A}$ from which it is to be shown that: :$\exists \mathbf A, \mathbf B \in \map {\MM_R} {k + 1}: \mathbf {A B} \ne \mathbf {B A}$ === Induction Step === This is the [[Definition:Induction Step|induction step]]: From the [[Matrix Multiplication is not Commutative#Induction Hypothesis|induction hypothesis]], it is assumed that there exist $2$ [[Definition:Order of Square Matrix|order $k$]] [[Definition:Square Matrix|square matrices]] $\mathbf A$ and $\mathbf B$ such that $\mathbf {A B} \ne \mathbf {B A}$. For an [[Definition:Order of Square Matrix|order]] $n$ [[Definition:Square Matrix|square matrix]] $\mathbf D$, let $\mathbf {D'}$ be the [[Definition:Square Matrix|square matrix]] of [[Definition:Order of Square Matrix|order]] $n + 1$ defined as: :$d'_{i j} = \begin {cases} d_{i j} & : i < n + 1 \land j < n + 1 \\ 0 & : i = n + 1 \lor j = n + 1 \end{cases}$ Thus $\mathbf D'$ is just $\mathbf D$ with a [[Definition:Zero Row or Column|zero row]] and [[Definition:Zero Row or Column|zero column]] added at the ends. We have that $\mathbf D$ is a [[Definition:Submatrix|submatrix]] of $\mathbf D'$. Now: :$\paren {a' b'}_{i j} = \begin{cases} \displaystyle \sum_{r \mathop = 1}^{n + 1} \mathbf a'_{i r} b'_{r j} & : i < n + 1 \land j < n + 1 \\ 0 & : i = n + 1 \lor j = n + 1 \end{cases}$ But: {{begin-eqn}} {{eqn | l = \sum_{r \mathop = 1}^{n + 1} a'_{i r} b'_{r j} | r = a'_{i \paren {n + 1} } b'_{\paren {n + 1} i} + \sum_{r \mathop = 1}^n a'_{i r} b'_{r j} | c = }} {{eqn | r = \sum_{r \mathop = 1}^n a_{i r} b_{r j} | c = }} {{end-eqn}} and so: {{begin-eqn}} {{eqn | l = \mathbf A' \mathbf B' \paren {n + 1, n + 1} | r = \paren {\mathbf {A B} }' \paren {n + 1, n + 1} | c = }} {{eqn | r = \mathbf {A B} | c = }} {{eqn | o = \ne | r = \mathbf {B A} | c = }} {{eqn | r = \paren {\mathbf {B A} }' \paren {n + 1, n + 1} | c = }} {{eqn | r = \mathbf B' \mathbf A' \paren {n + 1; n + 1} | c = }} {{end-eqn}} Thus it is seen that: :$\exists \mathbf A', \mathbf B' \in \MM_{n + 1 \times n + 1}: \mathbf A' \mathbf B' \ne \mathbf B' \mathbf A'$ So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\exists \mathbf A, \mathbf B \in \map {\MM_R} n: \mathbf {A B} \ne \mathbf {B A}$ and by definition [[Definition:Matrix Product (Conventional)|(conventional) matrix multiplication]] over $\map {\MM_R} n$ is not [[Definition:Commutative Operation|commutative]]. {{qed}}	1
:$p \implies \neg p \vdash \neg p$	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the appropriate [[Definition:Truth Value|truth values]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc||ccccc|} \hline p & \implies & q & p & \iff & (p & \land & q) \\ \hline F & T & F & F & T & F & F & F \\ F & T & T & F & T & F & F & T \\ T & F & F & T & F & T & F & F \\ T & T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
Let $\tau$ be a [[Definition:Term (Predicate Logic)|term of predicate logic]]. Let $\mathcal A$ be a [[Definition:Structure for Predicate Logic|structure for predicate logic]]. Let $\sigma, \sigma'$ be [[Definition:Assignment for Formula|assignments for $\tau$ in $\mathcal A$]] such that: :For each [[Definition:Variable (Logic)|variable]] $x$ [[Definition:Occurrence (Predicate Logic)|occurring]] in $\tau$, $\sigma \left({x}\right) = \sigma' \left({x}\right)$ Then: :$\mathop{ \operatorname{val}_{\mathcal A} \left({\tau}\right) } \left[{\sigma}\right] = \mathop{ \operatorname{val}_{\mathcal A} \left({\tau}\right) } \left[{\sigma'}\right]$ where $\mathop{ \operatorname{val}_{\mathcal A} \left({\tau}\right) } \left[{\sigma}\right]$ is the [[Definition:Value of Term under Assignment|value of $\tau$ under $\sigma$]].	1
: $p \implies \left({q \implies r}\right) \dashv \vdash q \implies \left({p \implies r}\right)$	1
Let $\map f n$ be a [[Definition:Time-Constructible Function|time-constructible function]]. Then there exists a [[Definition:Decision Problem|decision problem]] which: :can be solved in [[Definition:Worst-Case Deterministic Time|worst-case deterministic time]] $\map f {2 n + 1}^3$ but: :cannot be solved in [[Definition:Worst-Case Deterministic Time|worst-case deterministic time]] $\map f n$. In other words, the [[Definition:Complexity Class|complexity class]] $\map {\mathsf {DTIME} } {\map f n} \subsetneq \map {\mathsf {DTIME} } {\map f {2 n + 1}^3}$.	1
: $\vdash p \implies \left({\left({p \implies q}\right) \implies q}\right)$	1
[[Definition:Tableau Proof (Propositional Tableaus)|Tableau proofs]] (in terms of [[Definition:Propositional Tableau|propositional tableaus]]) are a [[Definition:Strongly Complete Proof System|strongly complete proof system]] for [[Definition:Boolean Interpretation|boolean interpretations]]. More precisely, for every [[Definition:Countable Set|countable]] collection $\mathbf H$ of [[Definition:WFF of Propositional Logic|WFFs of propositional logic]] and every [[Definition:WFF of Propositional Logic|WFF]] $\mathbf A$: :$\mathbf H \models_{\mathrm{BI}} \mathbf A$ implies $\mathbf H \vdash_{\mathrm{PT}} \mathbf A$	1
: $\vdash \left({\left({p \implies q}\right) \implies p}\right) \implies p$	1
Let $\left({R, +, \odot}\right)$ be a [[Definition:Ringoid (Abstract Algebra)|ringoid]] such that $\left({R, \odot}\right)$ is a [[Definition:Commutative Semigroup|commutative semigroup]]. Let $n \in \Z: n \ge 2$. Then: :$\displaystyle \forall x, y \in R: \odot^n \left({x + y}\right) = \odot^n x + \sum_{k \mathop = 1}^{n-1} \binom n k \left({\odot^{n-k} x}\right) \odot \left({\odot^k y}\right) + \odot^n y$ where $\dbinom n k = \dfrac {n!} {k! \ \left({n - k}\right)!}$ (see [[Definition:Binomial Coefficient|Binomial Coefficient]]). If $\left({R, \odot}\right)$ has an [[Definition:Identity Element|identity element]] $e$, then: :$\displaystyle \forall x, y \in R: \odot^n \left({x + y}\right) = \sum_{k \mathop = 0}^n \binom n k \left({\odot^{n - k} x}\right) \odot \left({\odot^k y}\right)$	1
==== [[Biconditional as Disjunction of Conjunctions/Formulation 1|Formulation 1]] ==== {{:Biconditional as Disjunction of Conjunctions/Formulation 1}} ==== [[Biconditional as Disjunction of Conjunctions/Formulation 2|Formulation 2]] ==== {{:Biconditional as Disjunction of Conjunctions/Formulation 2}}	1
Every [[Definition:Recursive Function|recursive function]] can be obtained from the [[Definition:Basic Primitive Recursive Function|basic primitive recursive functions]] using: * [[Definition:Substitution (Mathematical Logic)|substitution]] * [[Definition:Primitive Recursion|primitive recursion]] * at most one [[Definition:Minimization#Function|minimization on a function]].	1
:$\forall a, b, c: \paren {a = b} \land \paren {b = c} \implies a = c$	1
Let $\map P {x_1, x_2, \ldots, x_n}$ be an [[Definition:N-Ary Operation|$n$-ary]] [[Definition:Propositional Function|propositional function]]. If $a_1, a_2, \ldots, a_n$ have [[Definition:Value of Variable|values]] which make $\map P {x_1, x_2, \ldots, x_n}$ [[Definition:True|true]], then the [[Definition:Ordered Tuple|ordered tuple]] $\tuple {a_1, a_2, \ldots, a_n}$ '''satisfies''' $\map P {x_1, x_2, \ldots, x_n}$.	1
The [[Definition:Projection Function|projection functions]] $\pr_j^k: \N^k \to \N$, defined as: :$\forall j \in \closedint 1 k: \forall \tuple {n_1, n_2, \ldots, n_k} \in \N^k: \map {\pr_j^k} {n_1, n_2, \ldots, n_k} = n_j$	1
Let $\struct {S, \vee, \wedge, \neg}$ be a [[Definition:Boolean Algebra/Definition 2|Boolean algebra, defined as in Definition 2]]. Then: :$\exists \top \in S: \forall a \in S: a \vee \neg a = \top$ where $\wedge$ denotes the [[Definition:Boolean Algebra|meet operation in $S$]]. This element $\top$ is [[Definition:Unique|unique]] for any given $S$, and is named '''top'''.	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc||cccc|} \hline p & \lor & q & \neg & p & \implies & q \\ \hline F & F & F & T & F & F & F \\ F & T & T & T & F & T & T \\ T & T & F & F & T & T & F \\ T & T & T & F & T & T & T \\ \hline \end{array}$ {{qed}}	1
'''The deductive method''' is a general term for the process of building a [[Definition:Logical Argument|logical argument]] from a (usually) limited number of [[Definition:Premise|premises]]. Thus from a small number of [[Definition:Statement|statements]] which have been accepted as [[Definition:True|true]], and a small number of [[Definition:Rule of Inference|rules of deduction]], a theoretically unlimited number of further [[Definition:Statement|statements]] are determined to be [[Definition:True|true]] as a result.	1
Let $M$ be a [[Definition:Class (Class Theory)|class]] which is [[Definition:Closed under Mapping|closed]] under a [[Definition:Progressing Mapping|progressing mapping]] $g$. Let $b$ be an [[Definition:Element of Class|element]] of $M$ such that $M$ is [[Definition:Minimally Closed Class|minimally closed under $g$ with respect to $b$]]. Let $\RR$ be a [[Definition:Relation (Class Theory)|relation]] on $M$ which satisfies: {{begin-axiom}} {{axiom | n = \text D_1 | q = \forall x \in M | m = \map \RR {x, b} }} {{axiom | n = \text D_2 | q = \forall x, y \in M | m = \map \RR {x, y} \land \map \RR {y, x} \implies \map \RR {x, \map g y} }} {{end-axiom}} Then $\map \RR {x, y}$ holds for all $x, y \in M$.	1
{{BeginTableau|p \oplus \bot \vdash p}} {{Premise|1|p \oplus \bot}} {{SequentIntro|2|1|\left({p \lor \bot} \right) \land \neg \left({p \land \bot}\right)|1| {{Defof|Exclusive Or}} }} {{SequentIntro|3|1|p \land \neg \left({p \land \bot}\right)|2|[[Disjunction with Contradiction]]}} {{SequentIntro|4|1|p \land \neg \bot|3|[[Conjunction with Contradiction]]}} {{SequentIntro|5|1|p \land \top|4|[[Tautology is Negation of Contradiction]]}} {{SequentIntro|6|1|p|5|[[Conjunction with Tautology]]}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|p \vdash p \oplus \bot}} {{Premise|1|p}} {{SequentIntro|2|1|p \land \top|1|[[Conjunction with Tautology]]}} {{SequentIntro|3|1|\left({p \lor \bot}\right) \land \top|2|[[Disjunction with Contradiction]]}} {{SequentIntro|4|1|\left({p \lor \bot}\right) \land \neg \bot|3|[[Tautology is Negation of Contradiction]]}} {{SequentIntro|5|1|\left({p \lor \bot}\right) \land \neg \left({p \land \bot}\right)|4|[[Conjunction with Contradiction]]}} {{SequentIntro|6|1|p \oplus \bot|5| {{Defof|Exclusive Or}} }} {{EndTableau}} {{qed}}	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|cccc||cccccccc|} \hline \neg & (p & \iff & q) & (p & \lor & q) & \land & \neg & (p & \land & q) \\ \hline F & F & T & F & F & F & F & F & T & F & F & F \\ T & F & F & T & F & T & T & T & T & F & F & T \\ T & T & F & F & T & T & F & T & T & T & F & F \\ F & T & T & T & T & T & T & F & F & T & T & T \\ \hline \end{array}$ {{qed}}	1
=== Necessary Condition === Let $\circ$ be a [[Definition:Binary Logical Connective|binary logical connective]] such that there exists $*$ such that: :$\paren {p \circ q} * q \dashv \vdash p$ That is, by definition (and minor abuse of notation): :$\forall p, q \in \set {\F, \T}: \paren {p \circ q} * q = p$ For reference purposes, let us list from [[Binary Truth Functions]] the complete truth table containing all of the [[Definition:Binary Logical Connective|binary logical connectives]]: $\begin{array}{|r|cccc|} \hline p & \T & \T & \F & \F \\ q & \T & \F & \T & \F \\ \hline \map {f_\T} {p, q} & \T & \T & \T & \T \\ p \lor q & \T & \T & \T & \F \\ p \impliedby q & \T & \T & \F & \T \\ \map {\pr_1} {p, q} & \T & \T & \F & \F \\ p \implies q & \T & \F & \T & \T \\ \map {\pr_2} {p, q} & \T & \F & \T & \F \\ p \iff q & \T & \F & \F & \T \\ p \land q & \T & \F & \F & \F \\ p \uparrow q & \F & \T & \T & \T \\ \map \neg {p \iff q} & \F & \T & \T & \F \\ \map {\overline {\pr_2} } {p, q} & \F & \T & \F & \T \\ \map \neg {p \implies q} & \F & \T & \F & \F \\ \map {\overline {\pr_1} } {p, q} & \F & \F & \T & \T \\ \map \neg {p \impliedby q} & \F & \F & \T & \F \\ p \downarrow q & \F & \F & \F & \T \\ \map {f_\F} {p, q} & \F & \F & \F & \F \\ \hline \end{array}$ Suppose that for some $q \in \set {\F, \T}$: :$\paren {p \circ q}_{p = \F} = \paren {p \circ q}_{p = \T}$ Then: :$\paren {\paren {p \circ q} * q}_{p = \F} = \paren {\paren {p \circ q} * q}_{p = \T}$ and so either: :$\paren {\paren {p \circ q} * q}_{p = \F} \ne p$ or: :$\paren {\paren {p \circ q} * q}_{p = \T} \ne p$ Thus for $\circ$ to have an [[Definition:Inverse Operation|inverse operation]] it is necessary for $\F \circ q \ne \T \circ q$. This eliminates: {{begin-eqn}} {{eqn | o = | r = \map {f_\T} {p, q} | c = as $p \circ q = \T$ for all values of $p$ and $q$ }} {{eqn | o = | r = p \lor q | c = as $p \circ q = \T$ for $q = \T$ }} {{eqn | o = | r = p \impliedby q | c = as $p \circ q = \T$ for $q = \F$ }} {{eqn | o = | r = p \implies q | c = as $p \circ q = \T$ for $q = \T$ }} {{eqn | o = | r = \map {\pr_2} {p, q} | c = as $p \circ q = \T$ for $q = \T$ and also $p \circ q = \F$ for $q = \F$ }} {{eqn | o = | r = p \land q | c = as $p \circ q = \F$ for $q = \F$ }} {{eqn | o = | r = p \uparrow q | c = as $p \circ q = \T$ for $q = \F$ }} {{eqn | o = | r = \map {\overline {\pr_2} } {p, q} | c = as $p \circ q = \T$ for $q = \F$ and also $p \circ q = \F$ for $q = \T$ }} {{eqn | o = | r = \map \neg {p \implies q} | c = as $p \circ q = \F$ for $q = \T$ }} {{eqn | o = | r = \map \neg {p \impliedby q} | c = as $p \circ q = \F$ for $q = \F$ }} {{eqn | o = | r = p \downarrow q | c = as $p \circ q = \F$ for $q = \T$ }} {{eqn | o = | r = \map {f_\F} {p, q} | c = as $p \circ q = \T$ for all values of $p$ and $q$ }} {{end-eqn}} The remaining [[Definition:Binary Logical Connective|connectives]] which may have [[Definition:Inverse Operation|inverses]] are: $\begin{array}{|r|cccc|} \hline p & \T & \T & \F & \F \\ q & \T & \F & \T & \F \\ \hline \map {\pr_1} {p, q} & \T & \T & \F & \F \\ p \iff q & \T & \F & \F & \T \\ \map \neg {p \iff q} & \F & \T & \T & \F \\ \map {\overline {\pr_1} } {p, q} & \F & \F & \T & \T \\ \hline \end{array}$ Suppose that for some $p \in \set {\F, \T}$: :$\paren {p \circ q}_{q = \F} = \paren {p \circ q}_{q = \T}$ Then: :$\paren {q * \paren {p \circ q} }_{q = \F} = \paren {q * \paren {p \circ q} }_{q = \T}$ and so either: :$\paren {q * \paren {p \circ q} }_{q = \F} \ne p$ or: :$\paren {q * \paren {p \circ q} }_{q = \T} \ne p$ This eliminates: {{begin-eqn}} {{eqn | o = | r = \map {\pr_1} {p, q} | c = as $p \circ q = \T$ for $p = \T$ and also $p \circ q = \F$ for $p = \F$ }} {{eqn | o = | r = \map {\overline {\pr_1} } {p, q} | c = as $p \circ q = \T$ for $p = \F$ and also $p \circ q = \F$ for $p = \T$ }} {{end-eqn}} We are left with [[Definition:Exclusive Or|exclusive or]] and the [[Definition:Biconditional|biconditional]]. The result follows from [[Exclusive Or is Self-Inverse]] and [[Biconditional is Self-Inverse]]. {{qed}} === Sufficient Condition === Let $\circ$ be the [[Definition:Exclusive Or|exclusive or operator]]. Then by [[Exclusive Or is Self-Inverse]] it follows that: :$\paren {p \circ q} \circ q \dashv \vdash p$ Thus $*$ is the [[Definition:Inverse Operation|inverse operation]] of the [[Definition:Exclusive Or|exclusive or operation]]. Similarly, let $\circ$ be the [[Definition:Biconditional|biconditional operator]]. Then by [[Biconditional is Self-Inverse]] it follows that: :$\paren {p \circ q} \circ q \dashv \vdash p$ {{qed}} [[Category:Exclusive Or]] [[Category:Biconditional]] [[Category:Propositional Logic]] kbykk6g9uanajr5qrrir9gyc2juer2k	1
{{begin-eqn}} {{eqn | lo= \forall n \in \Z_{>0}: | l = F_n | r = \sum_{k \mathop = 0}^{\floor {\frac {n - 1} 2} } \dbinom {n - k - 1} k | c = }} {{eqn | r = \binom {n - 1} 0 + \binom {n - 2} 1 + \binom {n - 3} 2 + \dotsb + \binom {n - j} {j - 1} + \binom {n - j - 1} j | c = where $j = \floor {\frac {n - 1} 2}$ }} {{end-eqn}}	1
This is apparent from inspection of the [[Definition:Proof Rule|proof rules]] themselves. The rules concern only the broad structure of the [[Definition:Propositional Formula|propositional formulas]] involved, and this structure is unaffected by substitution. By performing the substitutions systematically throughout the given [[Definition:Sequent|sequent]], all applications of [[Definition:Proof Rule|proof rules]] remain correct applications in the [[Definition:Sequent|sequent]]. {{Handwaving}}	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|cccc||cccc|} \hline p & \land & \neg & q & \neg & (p & \implies & q) \\ \hline F & F & T & F & F & F & T & F \\ F & F & F & T & F & F & T & T \\ T & T & T & F & T & T & F & F \\ T & F & F & T & F & T & T & T \\ \hline \end{array}$ {{qed}}	1
We have that the [[Definition:Characteristic Function of Set|characteristic function]] $\chi_{\left\{{0}\right\}}$ of $\left\{{0}\right\}$ is [[Set Containing Only Zero is Primitive Recursive|primitive recursive]]. We note that: * If $n = 0$ then $\chi_{\left\{{0}\right\}} \left({n}\right) = 1$ therefore $\chi_{\left\{{0}\right\}} \left({\chi_{\left\{{0}\right\}} \left({n}\right)}\right) = 0$. * If $n > 0$ then $\chi_{\left\{{0}\right\}} \left({n}\right) = 0$ therefore $\chi_{\left\{{0}\right\}} \left({\chi_{\left\{{0}\right\}} \left({n}\right)}\right) = 1$. Thus $\chi_{\left\{{0}\right\}} \left({\chi_{\left\{{0}\right\}}\left({n}\right)}\right) = \chi_{\N^*} \left({n}\right)$. So $\chi_{\N^*}$ is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from the [[Set Containing Only Zero is Primitive Recursive|primitive recursive function $\chi_{\left\{{0}\right\}}$]]. Hence the result. {{qed}} [[Category:Primitive Recursive Functions]] etnxxmg7gvuqeciionb7ged49tauysn	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] is [[Definition:True|true]] for all [[Definition:Boolean Interpretation|boolean interpretations]]. :$\begin{array}{|ccccccc|c|ccc|} \hline ((p & \implies & q) & \land & (q & \implies & r)) & \implies & (p & \implies & r) \\ \hline F & T & F & T & F & T & F & T & F & T & F \\ F & T & F & T & F & T & T & T & F & T & T \\ F & T & T & T & T & F & F & T & F & T & F \\ F & T & T & T & T & T & T & T & F & T & T \\ T & F & F & F & F & T & F & T & T & F & F \\ T & F & F & T & F & T & T & T & T & T & T \\ T & T & T & F & T & F & F & T & T & F & F \\ T & T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \N_{>0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\displaystyle \forall n \ge 1: \sum_{j \mathop = 1}^n \frac 1 {j \paren {j + 1} } = \frac n {n + 1}$ === Basis for the Induction === $\map P 1$ is true, as this just says $\dfrac 1 2 = \dfrac 1 2$. This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\displaystyle \sum_{j \mathop = 1}^k \frac 1 {j \paren {j + 1} } = \frac k {k + 1}$ Then we need to show: :$\displaystyle \sum_{j \mathop = 1}^{k + 1} \frac 1 {j \paren {j + 1} } = \frac {k + 1} {k + 2}$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \sum_{j \mathop = 1}^{k + 1} \frac 1 {j \left({j + 1}\right)} | r = \sum_{j \mathop = 1}^k \frac 1 {j \paren {j + 1} } + \frac 1 {\paren {k + 1} \paren {k + 2} } | c = }} {{eqn | r = \frac k {k + 1} + \frac 1 {\paren {k + 1} \paren {k + 2} } | c = [[Sum of Sequence of Products of Consecutive Reciprocals/Proof 1#Induction Hypothesis|Induction hypothesis]] }} {{eqn | r = \frac {k \paren {k + 2} + 1} {\paren {k + 1} \paren {k + 2} } | c = }} {{eqn | r = \frac {k^2 + 2 k + 1} {\paren {k + 1} \paren {k + 2} } | c = }} {{eqn | r = \frac {\paren {k + 1}^2} {\paren {k + 1} \paren {k + 2} } | c = }} {{eqn | r = \frac {k + 1} {k + 2} | c = }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\displaystyle \forall n \ge 1: \sum_{j \mathop = 1}^n \frac 1 {j \paren {j + 1} } = \frac n {n + 1}$ {{qed}}	1
Let $\mathbf U$ be the [[Definition:Set|set]] of all [[Definition:URM Computability|URM computable functions]]. For each $f \in \mathbf U$, let $P_f$ be a [[Definition:URM Program|URM program]] which computes $f$. Such a program is very probably not unique, so in order to be definite about it, we can pick $P_f$ to be the [[Definition:URM Program|URM program]] with the smallest [[Unique Code for URM Program|code]] $\gamma \left({P_f}\right)$. This is possible from the [[Well-Ordering Principle]]. Let us define the [[Definition:Function|function]] $h: \mathbf U \to \N$ as: :$h \left({f}\right) = \gamma \left({P_f}\right)$ Since the same [[Definition:URM Program|URM program]] can not compute two different functions of $1$ variable, it can be seen that $h$ is [[Definition:Injection|injective]]. The result follows from [[Domain of Injection to Countable Set is Countable]]. {{qed}} [[Category:URM Programs]] [[Category:Countable Sets]] ep1nq4tsj6obs9kfxfnz1ms7j0mzu5u	1
Let $\dfrac p q$ denote a [[Definition:Proper Fraction|proper fraction]] expressed in [[Definition:Canonical Form of Rational Number|canonical form]]. Let $\dfrac p q$ be expressed as the [[Definition:Integer Addition|sum]] of a [[Definition:Finite Set|finite number]] of [[Definition:Distinct Elements|distinct]] [[Definition:Unit Fraction|unit fractions]] using [[Fibonacci's Greedy Algorithm]]. Then $\dfrac p q$ is expressed using no more than $p$ [[Definition:Unit Fraction|unit fractions]].	1
:$\vdash p \implies \paren {\paren {p \implies q} \implies q}$	1
Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \Z_{\ge 1}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\displaystyle \sum_{j \mathop = 1}^n \paren {2 j - 1}^3 = n^2 \paren {2 n^2 − 1}$ === Basis for the Induction === $\map P 1$ is the case: {{begin-eqn}} {{eqn | l = \sum_{j \mathop = 1}^1 \paren {2 j - 1}^3 | r = 1^3 | c = }} {{eqn | r = 1^2 \paren {2 \times 1^2 - 1} | c = }} {{end-eqn}} and $\map P 1$ is seen to hold. This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\displaystyle \sum_{j \mathop = 1}^k \paren {2 j - 1}^3 = k^2 \paren {2 k^2 − 1}$ Then we need to show: :$\displaystyle \sum_{j \mathop = 1}^{k + 1} \paren {2 j - 1}^3 = \paren {k + 1}^2 \paren {2 \paren {k + 1}^2 − 1}$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \sum_{j \mathop = 1}^{k + 1} \paren {2 j - 1}^3 | r = \sum_{j \mathop = 1}^k \paren {2 j - 1}^3 + \paren {2 k + 1}^3 | c = }} {{eqn | r = k^2 \paren {2 k^2 − 1} + \paren {2 k + 1}^3 | c = [[Sum of Sequence of Odd Cubes#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = 2 k^4 + 8 k^3 + 11 k^2 + 6 k + 1 | c = multiplying out }} {{eqn | r = \paren {k + 1}^2 \paren {2 k^2 + 4 k + 1} | c = extracting $\paren {k + 1}^2$ as a factor }} {{eqn | r = \paren {k + 1}^2 \paren {2 \paren {k + 1}^2 - 1} | c = }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\displaystyle \forall n \in \Z_{\ge 1}: \sum_{j \mathop = 1}^n \paren {2 j - 1}^3 = n^2 \paren {2 n^2 − 1}$ {{qed}}	1
{{BeginTableau|p \implies q \vdash \paren {r \land p} \implies \paren {r \land q} }} {{Premise|1|p \implies q}} {{IdentityLaw|2||r \implies r|(None)|This is a theorem so depends on nothing}} {{Conjunction|3|1|\paren {r \implies r} \land \paren {p \implies q}|2|1}} {{SequentIntro|4|1|\paren {r \land p} \implies \paren {r \land q}|3|[[Praeclarum Theorema]]}} {{EndTableau}} {{qed}}	1
{{BeginTableau|\vdash \neg p \implies \left({p \implies q}\right)}} {{Assumption|1|\neg p}} {{SequentIntro|2|1|p \implies q|1|[[False Statement implies Every Statement/Formulation 1|False Statement implies Every Statement: Formulation 1]]}} {{Implication|3||\neg p \implies \left({p \implies q}\right)|1|2}} {{EndTableau}} {{qed}}	1
Let $C$ be a [[Definition:Linear Code|linear code]]. Let $C^+$ be the [[Definition:Subset|subset]] of $C$ consisting of all the [[Definition:Codeword of Linear Code|codewords]] of $C$ which have [[Definition:Even Integer|even]] [[Definition:Weight of Linear Codeword|weight]]. Then $C^+$ is a [[Definition:Subgroup|subgroup]] of $C$ such that either $C^+ = C$ or such that $\order {C^+} = \dfrac {\order C} 2$.	1
This proof is done by constructing a model using a method known as a Henkin construction. This results in a model all of whose elements are the interpretations of constant symbols from some language. The construction for this proof in particular is done so that the theory this model satisfies asserts that each tuple of constants fails to satisfy at least one $\phi$ from each type $p_i$. As a result, the model we construct will not realize any of the types. We will prove the theorem for the special case where we only omit one type. That is, assume $\left\{{p_i: i \in \N}\right\}$ is $\left\{{p}\right\}$ for some $p$. Comments on the general case will be made after the proof. Our goal is to eventually be able to apply [[Maximal Finitely Satisfiable Theory with Witness Property is Satisfiable]] to a suitable $\mathcal L^*$-theory $T^*$, where $\mathcal L^*$ contains $\mathcal L$ and $T^*$ contains $T$. Let $\mathcal L^*$ be $\mathcal L \cup \left\{{c_i : i \in \N}\right\}$ where each $c_i$ is a new constant symbol. Note that $\mathcal L^*$ is still countable. We will recursively construct $T^*$ by adding a sentence $\theta_k$ at each stage. In order to ensure that it has the necessary properties, we will construct it in stages, each of which has three steps. The goal of the first step of each stage is ensure that $T^*$ will be maximal upon completion of the definition. The goal of the second step of each stage is to ensure that $T^*$ will satisfy the [[Definition:Witness Property|witness property]]. The goal of the third step of each stage is to ensure that $p$ is not realized by any tuple of constants. Since $\mathcal L^*$ is countable, the set of $\mathcal L$-formulas is countable, and hence in particular, the $\mathcal L^*$-sentences can be listed as $\phi_0, \phi_1, \ldots$ Similarly, since $\mathcal L^*$ is countable, the set of $n$-tuples of its constant symbols can be listed as $\bar d_0, \bar d_1, \dots$ === Recursive definition of $T^*$ === We now recursively define sets $T_k$ whose union will be $T^*$. ==== Stage $k = 0$ ==== Let $\theta_0$ be any $\mathcal L$-sentence which is a [[Definition:Tautology|tautology]]; for example, $\forall x : x = x$. Let $T_0 = T \cup \left\{{\theta_0}\right\}$. Note that $T_0$ is satisfiable since $T$ is satisfiable, and $T \models \theta_0$ trivially. Suppose that $\theta_k$ and $T_k$ have been defined and $T_k$ is satisfiable. We now handle the three steps of the $k$-th stage as mentioned above. ==== Stage $k + 1 = 3 i + 1$ ==== In this step we ensure that $T^*$ will be maximal. If $T_k \cup \left\{{\phi_i}\right\}$ is satisfiable, let $\theta_{k+1}$ be $\phi_i$. Otherwise, since $T_k$ is satisfiable, $T_k \cup \left\{{\neg \phi_i}\right\}$ must be satisfiable. In this case we let $\theta_{k+1}$ be $\neg \phi_i$. Let $T_{k+1} = T_k \cup \left\{{\theta_{k+1} }\right\}$. ==== Stage $k + 1 = 3 i + 2$ ==== In this step we ensure that $T^*$ will have the witness property. Suppose that: :$T_k \models \phi_j$ for some set of $j \le i$ and that: :$\phi_j$ are each of the form $\exists v \psi_j \left({v}\right)$. Let $\theta_{k+1}$ be $\bigwedge \psi \left({c}\right)$ where $c$ is a new constant which doesn't appear in $T_k$. This is possible since $T_k$ only has finitely many $\mathcal L^*$-sentences which are not $\mathcal L$-sentences. Let $T_{k+1} = T_k \cup \{\theta_{k+1}\}$. Since $T_k$ is satisfiable and $T_k \models \bigwedge \exists v \psi_j \left({v}\right)$, any model $\mathcal M$ of $T_k$ has an element $a_j$ such that $\mathcal M \models \psi_j (a_j)$. By interpreting $c_j$ as $a_j$, we can view $\mathcal M$ as a model of $T_{k+1}$. Thus $T_{k+1}$ is satisfiable. If $T_k$ doesn't satisfy any existential statements $\phi_j$ for $j \le i$, let $\theta_{k+1}$ be $\theta_k$ and let $T_{k+1}$ be $T_{k}$. ==== Stage $k + 1 = 3 i + 3$ ==== In this step we ensure that $p$ will be omitted by any model of $T^*$. Let $(e_1,\dots,e_n)$ be the $i$-th $n$-tuple of constants $\bar d_i$. We will add a sentence to ensure that $\bar d_i$ fails to realize $p$. Let $\psi$ be the $\mathcal L$-formula obtained from $\theta_0 \wedge \cdots \theta_k$ by: :$(1): \quad$ replacing [[Definition:Occurrence (Predicate Logic)|occurrences]] of the constants $e_1, \dotsc, e_n$ with variables $v_1, \dotsc, v_n$ :$(2): \quad$ replacing occurrences of $c_i$ besides $e_1, \dotsc, e_n$ by variables $v_{c_i}$ other than $v_1, \dotsc, v_n$ and finally: :$(3): \quad$ adding an existential quantifier $\exists v_{c_i}$ for each of the $c_i$ that were replaced other than $e_1, \dotsc, e_n$. This results in $\psi$ being an $\mathcal L$-formula with $n$ free variables. The free variables are those that correspond to the $e_i$. Since $p$ is not isolated, there must be some $\phi\in p$ such that: :$T \not \models \forall \bar v \left({\psi \left({\bar v}\right) \to \phi \left({\bar v}\right)}\right)$ Thus: :$T \models \exists \bar v \left({\psi \left({\bar v}\right) \wedge \neg \phi \left({\bar v}\right)}\right)$ Let $\theta_{k+1}$ be $\neg \phi \left({\bar d_i}\right)$. Let $T_{k+1} = T_k \cup \left\{ {\theta_{k+1} }\right\}$. Since $T$ is satisfiable, it has a model $\mathcal M$. By the above: :$\mathcal M \models \exists \bar v \left({\psi \left({\bar v}\right) \wedge \neg \phi \left({\bar v}\right)}\right)$ Hence there is some tuple $\bar a$ in $\mathcal M$ such that: :$\mathcal M \models \psi \left({\bar a}\right) \wedge \neg \phi \left({\bar a}\right)$ Let the constants $e_1, \dotsc, e_n$ be interpreted as the constants in the tuple $\bar a$. Let the the constants $c_i$ other than $e_1, \dotsc, e_n$ be interpreted as the elements from $\mathcal M$ which satisfy the existential quantifiers in $\psi \left({\bar a}\right)$. Then we have that $\mathcal M$ can be viewed as a model of $\theta_0 \wedge \dotsb \wedge \theta_k \wedge \neg \phi \left({\bar d_i}\right)$ as well. Thus $T_{k+1}$ is satisfiable. === Verification of properties of $T^*$ === Now, let $\displaystyle T^* = \bigcup_{k \mathop \in \N} T_k$, or equivalently: :$T^* = T \cup \left\{ {\theta_k: k \in \N}\right\}$ We verify that $T^*$ is a maximal finitely satisfiable theory with the witness property. Thus we may apply [[Maximal Finitely Satisfiable Theory with Witness Property is Satisfiable]] which is the theorem that will construct our desired model. ==== $T^*$ is finitely satisfiable ==== Let $\Delta$ be a finite subset of $T^*$. Then $\Delta$ is contained in one of the $T_k$. But by construction each $T_k$ was satisfiable. Heence by the [[Compactness Theorem]] $\Delta$ is satisfiable. ==== $T^*$ is a maximal theory ==== Let $\phi$ is an $\mathcal L^*$-sentence. Then it is some $\phi_i$. Hence either $\phi$ or $\neg \phi$ is contained in $T_{3i + 1}$. ==== $T^*$ has the witness property ==== Let $\psi \left({v}\right)$ be an $\mathcal L^*$-formula with one free variable. Then $\exists v \psi \left({v}\right)$ is an $\mathcal L^*$-sentence and hence is some $\phi_j$. Suppose $T^*\models \exists v \psi \left({v}\right)$. There must be a finite subset $\Delta$ of $T^*$ such that $\Delta \models \exists v \psi \left({v}\right)$. Otherwise, by the [[Compactness Theorem]], since $\Delta \cup \left\{ {\neg \exists v \psi \left({v}\right)}\right\}$ is always satisfiable, $T^* \cup \left\{ {\neg \exists v \psi \left({v}\right)}\right\}$ is satisfiable. Since such a $\Delta$ must be contained in one of the $T_k$, there is some $T_k$ such that $T_k \models \exists v \psi \left({v}\right)$. Since each $T_k$ is contained in $T_{k+1}$, we can assume that $k = 3 i + 2$ for some $i \le j$. But, $T_{3 i + 2}$ contains $\psi \left({c}\right)$ for some constant $c$ since $j \le i$ and $T_{3i+2}\models \phi_j$. === Verification that the constructed model omits $p$ === Recall that $\mathcal L$ was assumed to be countable. Thus $\mathcal L^*$ is countable as well. Thus, by [[Maximal Finitely Satisfiable Theory with Witness Property is Satisfiable]] applied to $T^*$: :there is an $\mathcal L^*$-structure $\mathcal M$ such that $\mathcal M \models T^*$ :every element of $\mathcal M$ is the interpretation of one of the constant symbols from $\mathcal L^*$ and consequently: :$\mathcal M$ is at most countable. We verify that $\mathcal M$ omits $p$. That is, every $n$-tuple of elements in $\mathcal M$ fails some sentence in $p$. Let $\left({a_1, \dotsc, a_n}\right)$ be an $n$-tuple of elements from $\mathcal M$. Then each of $a_1, \dotsc, a_n$ is the interpretation of constant symbol $e_1, \dotsc, e_n$ respectively from $\mathcal L^*$. In turn, $\left({e_1, \dotsc, e_n}\right)$ is one of the $\bar d_i$. But $T_{3 i + 3} \models \neg \phi \left({\bar d_i}\right)$ for some $\phi \in p$. Thus $\mathcal M \models \neg \phi \left({a_1, \dots, a_n}\right)$ for some $\phi \in p$. Hence, $\mathcal M$ omits $p$. === Generalization to countable set of non-isolated types === The above proof can be generalized by extending stage $k + 1 = 3i + 3$. As it is written above, we force $\bar d_i$ to fail to satisfy some $\phi$ in a single type $p$. But suppose we list the pairs $\left\{ {\left({\bar d_\alpha, p_\beta}\right) : \alpha, \beta \in \N}\right\}$ as a set $\left\{ {\pi_i: i \in \N}\right\}$. This is possible since the set of such pairs is countable. Then at stage $3 i + 3$, where $\pi_i = \left({\bar d_\alpha, p_\beta}\right)$, we can force $\bar d_\alpha$ to fail to satisfy some $\phi$ in $p_\beta$. This is achieved analogously to how it is done in the above proof. This ensures that for each $\bar d_\alpha$ with $\alpha \in \N$, and for each $p_\beta$, eventually some $T_k$ includes a sentence $\neg \phi \left({\bar d_\alpha}\right)$ for some $\phi \in p_\beta$. That is, eventually some $T_k$ ensures that $\bar d_\alpha$ does not realize $p_\beta$. {{qed}} {{finish}} [[Category:Model Theory]] [[Category:Named Theorems]] g07qco0li1v0r7459nvaquev67uvukv	1
{{BeginTableau|p \iff \bot \vdash \neg p}} {{Premise|1|p \iff \bot}} {{BiconditionalElimination|2|1|p \implies \bot|1|1}} {{SequentIntro|3|1|\neg p|2|[[Contradictory Consequent]]}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|\neg p \vdash p \iff \bot}} {{Assumption|1|\neg p}} {{SequentIntro|2|1|p \implies \bot|1|[[Contradictory Consequent]]}} {{TopIntro|3}} {{SequentIntro|4||\bot \implies p|3|[[Contradictory Antecedent]]}} {{BiconditionalIntro|5|1|p \iff \bot|2|4}} {{EndTableau}} {{qed}}	1
{{BeginTableau|\vdash \paren {p \lor q} \iff \paren {q \lor p} }} {{Assumption|1|p \lor q}} {{Commutation|2|1|q \lor p|1|Disjunction}} {{Implication|3||\paren {p \lor q} \implies \paren {q \lor p}|1|2}} {{Assumption|4|q \lor p}} {{Commutation|5|4|p \lor q|4|Disjunction}} {{Implication|6||\paren {q \lor p} \implies \paren {p \lor q}|4|5}} {{BiconditionalIntro|7||\paren {p \lor q} \iff \paren {q \lor p}|3|6}} {{EndTableau}} {{qed}}	1
:$\vdash p \iff \paren {p \land q} \lor \paren {p \land \neg q}$	1
: $\left({\neg \left({p \lor q}\right)}\right) \implies \left({\neg p \land \neg q}\right)$	1
$\vdash \neg \neg (p \lor \neg p)$	1
Let $\map P n$ be a [[Definition:Propositional Function|propositional function]] depending on $n \in \Z$. Let $n_0 \in \Z$ be given. Suppose that: :$(1): \quad \map P {n_0}$ is [[Definition:True|true]] :$(2): \quad \forall k \in \Z: k \ge n_0: \map P {n_0} \land \map P {n_0 + 1} \land \ldots \land \map P {k - 1} \land \map P k \implies \map P {k + 1}$ Then: :$\map P n$ is [[Definition:True|true]] for all $n \ge n_0$. This process is called '''proof by (mathematical) induction'''.	1
:$\vdash \paren {p \land q} \iff \paren {q \land p}$	1
: $\vdash \left({p \implies \left({q \land r}\right)}\right) \iff \left({\left({p \implies q}\right) \land \left({p \implies r}\right)}\right)$	1
:$\vdash \paren {p \land \paren {q \land r} } \iff \paren {\paren {p \land q} \land r}$	1
The [[Rule of Idempotence/Disjunction/Formulation 2/Reverse Implication|Rule of Idempotence]]: :$(p \lor p) \implies p$ is a [[Definition:Tautology (Formal Semantics)|tautology]] in [[Definition:Constructed Semantics/Instance 3|Instance 3]] of [[Definition:Constructed Semantics|constructed semantics]].	1
:$\vdash \left({p \lor \left({q \lor r}\right)}\right) \implies \left({\left({p \lor q}\right) \lor r}\right)$	1
The concepts of [[Definition:Set Theory|set theory]] have directly corresponding concepts in [[Definition:Logic|logic]]: :{| border = "1" |- ! style="padding: 2px 10px" | Set Theory ! style="padding: 2px 10px" | Logic |- | align="left" style="padding: 2px 10px"| [[Definition:Set|Set]]: $S, T$ | align="left" style="padding: 2px 10px"| [[Definition:Statement|Statement]]: $p, q$ |- | align="left" style="padding: 2px 10px"| [[Definition:Set Union|Union]]: $S \cup T$ | align="left" style="padding: 2px 10px"| [[Definition:Disjunction|Disjunction]]: $p \lor q$ |- | align="left" style="padding: 2px 10px"| [[Definition:Set Intersection|Intersection]]: $S \cap T$ | align="left" style="padding: 2px 10px"| [[Definition:Conjunction|Conjunction]]: $p \land q$ |- | align="left" style="padding: 2px 10px"| [[Definition:Subset|Subset]]: $S \subseteq T$ | align="left" style="padding: 2px 10px"| [[Definition:Conditional|Conditional]]: $p \implies q$ |- | align="left" style="padding: 2px 10px"| [[Definition:Symmetric Difference|Symmetric Difference]]: $S * T$ | align="left" style="padding: 2px 10px"| [[Definition:Exclusive Or|Exclusive Or]]: $p \oplus q$ |- | align="left" style="padding: 2px 10px"| [[Definition:Set Complement|Complement]]: $\relcomp {} S$ | align="left" style="padding: 2px 10px"| [[Definition:Logical Not|Logical Not]]: $\lnot p$ |- | align="left" style="padding: 2px 10px"| [[Definition:Set Equality|Set Equality]]: $S = T$ | align="left" style="padding: 2px 10px"| [[Definition:Biconditional|Biconditional]]: $p \iff q$ |- | align="left" style="padding: 2px 10px"| [[Definition:Venn Diagram|Venn Diagram]] | align="left" style="padding: 2px 10px"| [[Definition:Truth Table|Truth Table]] |}	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc||c|}\hline ((p & \implies & q) & \implies & p) & p \\ \hline F & T & F & F & F & F \\ F & T & T & F & F & F \\ T & F & F & T & T & T \\ T & T & T & T & T & T \\ \hline \end{array}$ {{qed}} {{Namedfor|Charles Sanders Peirce}} [[Category:Peirce's Law]] [[Category:Truth Table Proofs]] h176q3qbxl3f7z8ak724c46xngv1otc	1
{{BeginTableau|\vdash \left({p \land \left({q \lor r}\right)}\right) \iff \left({\left({p \land q}\right) \lor \left({p \land r}\right)}\right)}} {{TheoremIntro|1|\left({p \land \left({q \lor r}\right)}\right) \implies \left({\left({p \land q}\right) \lor \left({p \land r}\right)}\right)|[[Rule of Distribution/Conjunction Distributes over Disjunction/Left Distributive/Formulation 2/Forward Implication|Conjunction Distributes over Disjunction: Forward Implication]]}} {{TheoremIntro|2|\left({\left({p \land q}\right) \lor \left({p \land r}\right)}\right) \implies \left({p \land \left({q \lor r}\right)}\right)|[[Rule of Distribution/Conjunction Distributes over Disjunction/Left Distributive/Formulation 2/Reverse Implication|Conjunction Distributes over Disjunction: Reverse Implication]]}} {{BiconditionalIntro|3||\left({p \land \left({q \lor r}\right)}\right) \iff \left({\left({p \land q}\right) \lor \left({p \land r}\right)}\right)|1|2}} {{EndTableau}} {{qed}}	1
Forming the set $\SS$ of all [[Definition:Set|sets]] leads to a [[Definition:Contradiction|contradiction]].	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc||ccccccccc|} \hline p & \oplus & q & (p & \lor & q) & \land & (\neg & p & \lor & \neg & q) \\ \hline F & F & F & F & F & F & F & T & F & T & T & F \\ F & T & T & F & T & T & T & T & F & T & F & T \\ T & T & F & T & T & F & T & F & T & T & T & F \\ T & F & T & T & T & T & F & F & T & F & F & T \\ \hline \end{array}$ {{qed}}	1
The [[Rule of Addition]] can be symbolised by the [[Definition:Sequent|sequents]]: :$(1): \quad p \vdash p \lor q$ :$(2): \quad q \vdash p \lor q$	1
{{BeginTableau|\vdash \left({p \iff q}\right) \iff \left({\left({p \implies q}\right) \land \left({q \implies p}\right)}\right)}} {{Assumption|1|p \iff q}} {{SequentIntro|2|1|\left({\left({p \implies q}\right) \land \left({q \implies p}\right)}\right)|1|[[Rule of Material Equivalence/Formulation 1|Rule of Material Equivalence: Formulation 1]]}} {{Implication|3||\left({p \iff q}\right) \implies \left({\left({p \implies q}\right) \land \left({q \implies p}\right)}\right)|1|2}} {{Assumption|4|\left({p \implies q}\right) \land \left({q \implies p}\right)}} {{SequentIntro|5|4|p \iff q|4|[[Rule of Material Equivalence/Formulation 1|Rule of Material Equivalence: Formulation 1]]}} {{Implication|6||\left({\left({p \implies q}\right) \land \left({q \implies p}\right)}\right) \implies \left({p \iff q}\right)|4|5}} {{BiconditionalIntro|7||\left({p \iff q}\right) \iff \left({\left({p \implies q}\right) \land \left({q \implies p}\right)}\right)|3|6}} {{EndTableau}} {{qed}}	1
While this holds: :$\vdash \paren {\paren {p \implies q} \implies r} \implies \paren {\paren {p \implies r} \implies \paren {q \implies r} }$ its converse does not: :$\not \vdash \paren {\paren {p \implies r} \implies \paren {q \implies r} } \implies \paren {\paren {p \implies q} \implies r}$	1
:$p \downarrow q \dashv \vdash q \downarrow p$	1
:$p \land q \vdash \neg \left({p \implies \neg q}\right)$	1
Let $M$ be a [[Definition:Class (Class Theory)|class]]. Let $g: M \to M$ be a [[Definition:Mapping (Class Theory)|mapping]] on $M$. Let $M$ be [[Definition:Minimally Inductive Class under General Mapping|minimally inductive under $g$]]. Let $P: M \to \set {\T, \F}$ be a [[Definition:Propositional Function|propositional function]] on $M$. Suppose that: :$(1): \quad \map P \O = \T$ :$(2): \quad \forall x \in M: \map P x = \T \implies \map P {\map g x} = \T$ Then: :$\forall x \in M: \map P x = \T$	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc||ccccccc|} \hline p & \lor & (q & \land & r) & (p & \lor & q) & \land & (p & \lor & r) \\ \hline F & F & F & F & F & F & F & F & F & F & F & F \\ F & F & F & F & T & F & F & F & F & F & T & T \\ F & F & T & F & F & F & T & T & F & F & F & F \\ F & T & T & T & T & F & T & T & T & F & T & T \\ T & T & F & F & F & T & T & F & T & T & T & F \\ T & T & F & F & T & T & T & F & T & T & T & T \\ T & T & T & F & F & T & T & T & T & T & T & F \\ T & T & T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
{{BeginTableau|p \land q \vdash p}} {{Premise|1|p \land q}} {{Simplification|2|1|p|1|1}} {{EndTableau}} {{Qed}}	1
Let $\left({A,\prec}\right)$ be a [[Definition:Strict Well-Ordering|strict well-ordering]]. For all $x \in A$, let the $\prec$-[[Definition:Initial Segment|initial segment]] of $x$ be a [[Definition:Small Class|small class]]. Let $B$ be a [[Definition:Class (Class Theory)|class]] such that $B \subseteq A$. Let: :$(1): \quad \forall x \in A: \left({ \left({ A \cap \prec^{-1} \left({ x }\right) }\right) \subseteq B \implies x \in B }\right)$ Then: :$A = B$ That is, if a property passes from the initial segment of $x$ to $x$, then this property is true for all $x \in A$.	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|cccc||ccccc|} \hline P & (A & B & C) & (((A & \land & \neg & B) & \land & \neg & C) & \lor & ((\neg & A & \land & B) & \land & \neg & C)) & \lor & ((\neg & A & \land & \neg & B) & \land & C) \\ \hline F & F & F & F & F & F & T & F & F & T & F & F & T & F & F & F & F & T & F & F & T & F & T & T & F & F & F \\ T & F & F & T & F & F & T & F & F & F & T & F & T & F & F & F & F & F & T & T & T & F & T & T & F & T & T \\ T & F & T & F & F & F & F & T & F & T & F & T & T & F & T & T & T & T & F & T & T & F & F & F & T & F & F \\ F & F & T & T & F & F & F & T & F & F & T & F & T & F & T & T & F & F & T & F & T & F & F & F & T & F & T \\ T & T & F & F & T & T & T & F & T & T & F & T & F & T & F & F & F & T & F & T & F & T & F & T & F & F & F \\ F & T & F & T & T & T & T & F & F & F & T & F & F & T & F & F & F & F & T & F & F & T & F & T & F & F & T \\ F & T & T & F & T & F & F & T & F & T & F & F & F & T & F & T & F & T & F & F & F & T & F & F & T & F & F \\ F & T & T & T & T & F & F & T & F & F & T & F & F & T & F & T & F & F & T & F & F & T & F & F & T & F & T \\ \hline \end{array}$ {{qed}}	1
Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \N_{>0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\displaystyle \sum_{j \mathop = 1}^n F_{2 j} = F_{2 n + 1} - 1$ === Basis for the Induction === $\map P 1$ is the case $F_2 = 1 = F_3 - 1$, which holds from the definition of [[Definition:Fibonacci Numbers|Fibonacci numbers]]. This is our [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$\displaystyle \sum_{j \mathop = 1}^k F_{2 j} = F_{2 k + 1} - 1$ Then we need to show: :$\displaystyle \sum_{j \mathop = 1}^{k + 1} F_{2 j} = F_{2 k + 3} - 1$ === Induction Step === This is our [[Principle of Mathematical Induction#Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \sum_{j \mathop = 1}^{k + 1} F_{2 j} | r = \sum_{j \mathop = 1}^k F_{2 j} + F_{2 \paren {k + 1} } | c = }} {{eqn | r = F_{2 k + 1} - 1 + F_{2 k + 2} | c = [[Sum of Sequence of Even Index Fibonacci Numbers#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = F_{2 k + 3} - 1 | c = {{Defof|Fibonacci Number}} }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: : $\displaystyle \forall n \ge 1: \sum_{j \mathop = 1}^n F_{2 j} = F_{2 n + 1} - 1$ {{qed}}	1
Let $\SS$ be the set of all sets. Then $\SS$ must be an [[Definition:Element|element]] of itself, in symbols, $\SS \owns \SS$. Thus we have an infinite descending sequence of membership: :$\SS \owns \SS \owns \SS \owns \cdots$ But by the [[Axiom:Axiom of Foundation|axiom of foundation]], no such sequence exists, a [[Definition:Contradiction|contradiction]]. {{qed}} {{questionable|This is circular: We need to demonstrate the contradiction and then demonstrate why ZF (specifically the AoF) prevents it happening.}} [[Category:Antinomies]] 87mh65z8bqgp2d2r28fe681ukov2elw	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc|ccccccc|} \hline p & \iff & q & (p & \implies & q) & \land & (q & \implies & p) \\ \hline F & T & F & F & T & F & T & F & T & F \\ F & F & T & F & T & T & F & T & F & F \\ T & F & F & T & F & F & F & F & T & T \\ T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
A [[Definition:Propositional Variable|propositional variable]] is already trivially in [[Definition:Conjunctive Normal Form|conjunctive normal form (CNF)]]. So we consider the general [[Definition:Propositional Formula|propositional formula]] $S$. First we convert to [[Definition:Negation Normal Form|negation normal form (NNF)]]. This is always possible, by [[Existence of Negation Normal Form of Statement]]. Now $S$ will be of the form: : $P_1 \land P_2 \land \cdots \land P_n$ where $P_1, P_2, \ldots, P_n$ are either: * [[Definition:Literal|Literals]]; * Statements of the form $\left({Q_1 \lor Q_2 \lor \ldots \lor Q_n}\right)$ If all the $Q_1, \ldots, Q_n$ are [[Definition:Literal|literals]] we have finished. Otherwise they will be of the form $Q_j = \left({R_1 \land R_2 \land \ldots \land R_m}\right)$ If the latter is the case, then use the [[Disjunction Distributes over Conjunction]] to convert: : $Q_1 \lor Q_2 \lor \ldots \lor \left({R_1 \land R_2 \land \ldots \land R_m}\right) \ldots \lor Q_n$ into: {{begin-eqn}} {{eqn | o = | r = \left({Q_1 \lor Q_2 \lor \ldots \lor Q_n \lor R_1}\right) | c = }} {{eqn | o = \land | r = \left({Q_1 \lor Q_2 \lor \ldots \lor Q_n \lor R_2}\right) | c = }} {{eqn | o = \land | r = \ldots | c = }} {{eqn | o = \land | r = \left({Q_1 \lor Q_2 \lor \ldots \lor Q_n \lor R_m}\right) | c = }} {{end-eqn}} It is taken for granted that [[Disjunction is Associative]] and [[Disjunction is Commutative]]. It can be seen then that each of the : $\left({Q_1 \lor Q_2 \lor \ldots \lor Q_n \lor R_k}\right)$ are terms in the [[Definition:Conjunctive Normal Form|CNF]] expression required. If any terms are still not in the correct format, then use the above operation until they are. {{qed}}	1
{{BeginTableau|\vdash \neg \left({p \land \neg p}\right)}} {{Assumption|1|p \land \neg p}} {{Simplification|2|1|p|1|1}} {{Simplification|3|1|\neg p|1|2}} {{NonContradiction|4|1|2|3}} {{Contradiction|5||\neg \left({p \land \neg p}\right)|1|4}} {{EndTableau}} {{qed}}	1
In [[NAND is Functionally Complete]] it is demonstrated that [[Definition:Logical NAND|NAND]] is [[Definition:Functionally Complete|functionally complete]]. In [[NOR is Functionally Complete]] it is demonstrated that [[Definition:Logical NOR|NOR]] is [[Definition:Functionally Complete|functionally complete]].	1
Recall the [[Definition:Eluding Game/Payoff Table|payoff table]]: {{:Definition:Eluding Game/Payoff Table}} Trivially, by inspection, this has no [[Definition:Entry in Payoff Table|entry]] which is the smallest [[Definition:Entry in Payoff Table|entry]] in its row and the largest [[Definition:Entry in Payoff Table|entry]] in its column.	1
From [[Functionally Complete Logical Connectives/Negation, Conjunction, Disjunction and Implication|Functionally Complete Logical Connectives: Negation, Conjunction, Disjunction and Implication]], all sixteen of the [[Binary Truth Functions|binary truth functions]] can be expressed in terms of $\neg, \land, \lor, \implies$. From [[Conjunction and Implication]], we have that: :$p \implies q \dashv \vdash \neg \paren {p \land \neg q}$ From [[De Morgan's Laws (Logic)/Disjunction|De Morgan's laws: Disjunction]], we have that: :$p \lor q \dashv \vdash \neg \paren {\neg p \land \neg q}$ So any instance of either $\implies$ or $\lor$ can be replaced identically with one using just $\neg$ and $\land$. It follows that $\set {\neg, \land}$ is [[Definition:Functionally Complete|functionally complete]]. {{qed}}	1
Consider [[Definition:First Figure of Categorical Syllogism|Figure $\text I$]]: {{:Definition:Figure of Categorical Syllogism/I}} Let the [[Definition:Major Premise of Syllogism|major premise]] of $Q$ be denoted $\text{Maj}$. Let the [[Definition:Minor Premise of Syllogism|minor premise]] of $Q$ be denoted $\text{Min}$. Let the [[Definition:Conclusion of Syllogism|conclusion]] of $Q$ be denoted $\text{C}$. $M$ is: : the [[Definition:Subject of Categorical Statement|subject]] of $\text{Maj}$ : the [[Definition:Predicate of Categorical Statement|predicate]] of $\text{Min}$. So, in order for $M$ to be [[Definition:Distributed Term of Categorical Syllogism|distributed]], either: : $(1): \quad$ From [[Definition:Distributed Term of Categorical Syllogism/Subject|Universal Categorical Statement Distributes its Subject]]: $\text{Maj}$ must be [[Definition:Universal Categorical Statement|universal]] or: : $(2): \quad$ From [[Definition:Distributed Term of Categorical Syllogism/Predicate|Negative Categorical Statement Distributes its Predicate]]: $\text{Min}$ must be [[Definition:Negative Categorical Statement|negative]]. Suppose $\text{Min}$ is a [[Definition:Negative Categorical Statement|negative categorical statement]]. Then by [[Conclusion of Valid Categorical Syllogism is Negative iff one Premise is Negative]]: : $\text{C}$ is a [[Definition:Negative Categorical Statement|negative categorical statement]]. From $(2)$: : $P$ is [[Definition:Distributed Term of Categorical Syllogism|distributed]] in $\text{C}$. From [[Distributed Term of Conclusion of Valid Categorical Syllogism is Distributed in Premise]]: : $P$ is [[Definition:Distributed Term of Categorical Syllogism|distributed]] in $\text{Maj}$. From [[Definition:Distributed Term of Categorical Syllogism/Predicate|Negative Categorical Statement Distributes its Predicate]]: : $\text{Maj}$ is a [[Definition:Negative Categorical Statement|negative categorical statement]]. Thus both: : $\text{Min}$ is a [[Definition:Negative Categorical Statement|negative categorical statement]] : $\text{Maj}$ is a [[Definition:Negative Categorical Statement|negative categorical statement]]. But from [[No Valid Categorical Syllogism contains two Negative Premises]], this means $Q$ is [[Definition:Invalid Argument|invalid]]. Thus $\text{Min}$ is not a [[Definition:Negative Categorical Statement|negative categorical statement]] in [[Definition:First Figure of Categorical Syllogism|Figure $\text I$]]. As $\text{Min}$ needs to be an [[Definition:Affirmative Categorical Statement|affirmative categorical statement]], $M$ is not [[Definition:Distributed Term of Categorical Syllogism|distributed]] in $\text{Min}$. From [[Middle Term of Valid Categorical Syllogism is Distributed at least Once]], this means $M$ must be [[Definition:Distributed Term of Categorical Syllogism|distributed]] in $\text{Maj}$. As $M$ is the [[Definition:Subject of Categorical Statement|subject]] of $\text{Maj}$ in [[Definition:First Figure of Categorical Syllogism|Figure $\text I$]], it follows from $(1)$ that: : $\text{Maj}$ is a [[Definition:Universal Categorical Statement|universal categorical statement]]. Hence, in order for $Q$ to be [[Definition:Valid Argument|valid]]: : $\text{Maj}$ must be a [[Definition:Universal Categorical Statement|universal categorical statement]] : $\text{Min}$ must be an [[Definition:Affirmative Categorical Statement|affirmative categorical statement]]. {{qed}}	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|cccc||ccccccccc|} \hline \neg & (p & \iff & q) & (p & \lor & q) & \land & (\neg & p & \lor & \neg & q) \\ \hline F & F & T & F & F & F & F & F & T & F & T & T & F \\ T & F & F & T & F & T & T & T & T & F & T & F & T \\ T & T & F & F & T & T & F & T & F & T & T & T & F \\ F & T & T & T & T & T & T & F & F & T & F & F & T \\ \hline \end{array}$ {{qed}}	1
:$\vdash p \implies \paren{ q \implies \paren{ p \land q } }$	1
Let $\mathscr G$ be [[Definition:Gentzen Proof System/Instance 1|instance 1 of a Gentzen proof system]]. Let $\mathrm{BI}$ be the [[Definition:Formal Semantics of Boolean Interpretations|formal semantics of boolean interpretations]]. Then $\mathscr G$ is a [[Definition:Sound Proof System|sound]] and [[Definition:Complete Proof System|complete proof system]] for $\mathrm{BI}$.	1
Let $\mathcal F$ be a [[Definition:Formal Language|formal language]] in [[Definition:Polish Notation|Polish notation]]. Let $\mathbf A$ be a [[Definition:Well-Formed Formula|well-formed formula]] of $\mathcal F$. Let $a$ be an [[Definition:Occurrence (Formal Systems)|occurrence]] in $\mathbf A$. Then $a$ has a unique [[Definition:Scope of Occurrence|scope]].	1
Let $\sequence {a_n}$ and $\sequence {b_n}$ be [[Definition:Sequence|sequences in $\R$]]. {{TFAE|def = Asymptotically Equal Sequences}}	1
Let $A = \set {n \in \N: \map P n}$. We show that $A$ is an [[Definition:Inductive Set as Subset of Real Numbers|inductive set]]. By $(1)$: :$\forall 1 \le i \le d: i \in A$ Let: :$\forall x \ge d: \set {1, 2, \dotsc, x} \subset A$ Then by definition of $A$: :$\forall k \in \N: x - \paren {d - 1} \le k < x + 1: \map P k$ Thus $\map P {x + 1} \implies x + 1 \in A$ Thus $A$ is an inductive set. Thus by the fifth axiom of Peano: :$\forall n \in \N: A = \N \implies \map P n$ {{qed}} {{Proofread}}	1
There is a primitive recursive function $\mathrm {diag}$ which is defined by: :$\map {\mathrm {diag} } n = \widehat {\map A {\hat A} }$ where: :$\map A x$ is the formula such that $\hat A = n$. :the $\hat{ }$ sign denotes the Gödel number of the contained formula (and we are not being formal about distinguishing between integers and symbols in the language). Informally, $\mathrm{diag}$ takes a Gödel number, decodes it to a formula, plugs in the Gödel number for that formula in place of a free variable, and encodes this new formula back to a new Gödel number. Since $T$ contains $Q$, by [[Recursive Sets are Definable in Arithmetic]] applied to the graph of $\mathrm {diag}$, we have that there is some formula $\map {\mathrm {Diag} } {x, y}$ which [[Definition:Definable#Definable Set|defines]] the graph of $\mathrm {diag}$ in $T$. That is: :$\map {\mathrm {diag} } n = m$ if and only if $T\vdash \map {\mathrm {Diag} } {n, m}$ Let $\map A x$ be the formula: :$\exists y \paren {\map {\mathrm {Diag} } {x, y} \land \map B y}$ Let $G$ be $\map A {\hat A}$. We then have $T \vdash \map {\mathrm {Diag} } {\hat A, \hat G}$, by checking the definitions. Let $T' = T \cup \set G$. Then: :$T' \vdash \map A {\hat A}$ Hence: :$T' \vdash \exists y \paren {\map {\mathrm {Diag} } {\hat A, y} \land \map B y}$ But since $\hat G$ is the only number such that $T \vdash \map {\mathrm {Diag} } {\hat A, \hat G}$, this gives us: :$T' \vdash \map B {\hat G}$ Thus: :$T \vdash G \rightarrow \map B {\hat G}$ Let $T' = T \cup \set {\map B {\hat G} }$. Again, we have: :$T \vdash \map {\mathrm {Diag} } {\hat A, \hat G}$ so this gives us: :$T' \vdash \map {\mathrm {Diag} } {\hat A, \hat G} \land \map B {\hat G}$ and hence: :$T' \vdash \exists y \paren {\map {\mathrm {Diag} } {\hat A, y} \land \map B y}$ But this is the same thing as: :$T' \vdash G$ Thus: :$T \vdash \map B {\hat G} \rightarrow G$ Thus $G$ is as claimed. {{qed}} {{MissingLinks|first line of proof}}	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, in each case, the [[Definition:Truth Value|truth values]] in the appropriate columns match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c|ccc||c|ccc|} \hline p & p & \implies & \top & \top \\ \hline F & F & T & T & T \\ T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
The '''predecessor function''' $\operatorname{pred}: \N \to \N$ defined as: :$\operatorname{pred} \left({n}\right) = \begin{cases} 0 & : n = 0 \\ n-1 & : n > 0 \end{cases}$ is [[Definition:Primitive Recursive Function|primitive recursive]].	1
{{BeginTableau|\vdash \paren {\paren {q \lor r} \land p} \iff \paren {\paren {q \land p} \lor \paren {r \land p} } }} {{Assumption|1|\paren {q \lor r} \land p}} {{SequentIntro|2|1|\paren {q \land p} \lor \paren {r \land p}|1|[[Rule of Distribution/Conjunction Distributes over Disjunction/Right Distributive/Formulation 1|Conjunction is Right Distributive over Disjunction: Formulation 1]]}} {{Implication|3||\paren {\paren {q \lor r} \land p} \implies \paren {\paren {q \land p} \lor \paren {r \land p} }|1|2}} {{Assumption|4|\paren {q \land p} \lor \paren {r \land p} }} {{SequentIntro|5|4|\paren {q \lor r} \land p|4|[[Rule of Distribution/Conjunction Distributes over Disjunction/Right Distributive/Formulation 1|Conjunction is Right Distributive over Disjunction: Formulation 1]]}} {{Implication|6||\paren {\paren {q \land p} \lor \paren {r \land p} } \implies \paren {\paren {q \lor r} \land p}|4|5}} {{BiconditionalIntro|7||\paren {\paren {q \lor r} \land p} \iff \paren {\paren {q \land p} \lor \paren {r \land p} }|3|6}} {{EndTableau}} {{qed} [[Category:Rule of Distribution]] 7umzufsmkl5vcnhblyr3fhdma3gi018	1
=== Proof for Function === We can define $g$ as follows: :$(1) \quad g \left({n_1, n_2, \ldots, n_k, 0}\right) = \begin{cases} 0 & : f \left({n_1, n_2, \ldots, n_k, 0}\right) = 0 \\ 1 & : \text{otherwise} \\ \end{cases}$ :$(2) \quad g \left({n_1, n_2, \ldots, n_k, z + 1}\right) = \begin{cases} g \left({n_1, n_2, \ldots, n_k, z}\right) & : g \left({n_1, n_2, \ldots, n_k, z}\right) \le z \\ z + 1 & : g \left({n_1, n_2, \ldots, n_k, z}\right) = z + 1 \text{ and } f \left({n_1, n_2, \ldots, n_k, z + 1}\right) = 0 \\ z + 2 & : \text{otherwise} \\ \end{cases}$ The fact that $(1)$ is true is clear. * The cases in $(1)$ are clearly mutually exclusive and exhaustive; * By [[Definition by Cases is Primitive Recursive#Corollary|the corollary to Definition by Cases is Primitive Recursive]], the relations defining the cases are [[Definition:Primitive Recursive Relation|primitive recursive]]; * The [[Constant Function is Primitive Recursive|constants $0$ and $1$ are primitive recursive]]. Hence by [[Definition by Cases is Primitive Recursive]], the function defined in $(1)$ is [[Definition:Primitive Recursive Function|primitive recursive]]. Now we investigate $(2)$. Note that if $g \left({n_1, n_2, \ldots, n_k, z}\right) \le z$ then the equation $f \left({n_1, n_2, \ldots, n_k, y}\right) = 0$ has a solution for some $y \le z$. Then the smallest $y \le z$ which solves this equation is also the smallest value of $y \le z + 1$ which solves this equation. So in this case, $g \left({n_1, n_2, \ldots, n_k, z + 1}\right) = g \left({n_1, n_2, \ldots, n_k, z}\right)$. Otherwise there is no such $y \le z$ that solves the equation. Then the value $g \left({n_1, n_2, \ldots, n_k, z + 1}\right)$ is $z + 1$ if $f \left({n_1, n_2, \ldots, n_k, z + 1}\right) = 0$. But if $f \left({n_1, n_2, \ldots, n_k, z + 1}\right) \ne 0$ then $g \left({n_1, n_2, \ldots, n_k, z + 1}\right) = \left({z + 1}\right) + 1 = z + 2$. Thus $g$ as defined in $(1)$ and $(2)$ are an appropriate definition of: :$g \left({n_1, n_2, \ldots, n_k, z}\right) = \mu y \le z \left({f \left({n_1, n_2, \ldots, n_k, y}\right) = 0}\right)$. Now to show that the function defined in $(2)$ is [[Definition:Primitive Recursive Function|primitive recursive]]. By [[Definition by Cases is Primitive Recursive#Corollary|the corollary to Definition by Cases is Primitive Recursive]], the relations defining the cases are [[Definition:Primitive Recursive Relation|primitive recursive]]. Then we have that $g \left({n_1, n_2, \ldots, n_k, z}\right)$, $z + 1$ and $z + 2$ are expressed in terms of: * $g \left({n_1, n_2, \ldots, n_k, z}\right)$; * the variable $z$; * the [[Addition is Primitive Recursive|primitive recursive function $\operatorname{add}$]]; * the [[Constant Function is Primitive Recursive|constants $1$ and $2$]]. So all these functions are [[Definition:Primitive Recursive Function|primitive recursive]]. Hence by [[Definition by Cases is Primitive Recursive]], the function defined in $(2)$ is [[Definition:Primitive Recursive Function|primitive recursive]]. Therefore $g$ is defined by [[Definition:Primitive Recursion|primitive recursion]] from functions which we have proved to be [[Definition:Primitive Recursive Function|primitive recursive]]. The result follows. {{qed}} === Proof for Relation === We can mimic the [[Bounded Minimization is Primitive Recursive#Proof for Function|proof for the function]]. Or we can do it this way. From the definition of the [[Definition:Characteristic Function of Relation|characteristic function]] for $\mathcal R$, we can express $\mu y \le z \mathcal R \left({n_1, n_2, \ldots, n_k, y}\right)$ as: :$\mu y \le z \left({\chi_\mathcal R \left({n_1, n_2, \ldots, n_k, y}\right) = 1}\right)$. Now we turn $\chi_\mathcal R \left({n_1, n_2, \ldots, n_k, y}\right) = 1$ into something of the form $f \left({n_1, n_2, \ldots, n_k, y}\right) = 0$. We can use [[Definition:Signum Complement|signum-bar function]]: :$\chi_\mathcal R \left({n_1, n_2, \ldots, n_k, y}\right) = 1 \iff \overline{\operatorname{sgn}} \left({\chi_\mathcal R \left({n_1, n_2, \ldots, n_k, y}\right)}\right) = 0$ Now we define $f \left({n_1, n_2, \ldots, n_k, n_{k+1}}\right) = \overline{\operatorname{sgn}} \left({\chi_\mathcal R \left({n_1, n_2, \ldots, n_k, n_{k+1}}\right)}\right)$. This is [[Definition:Primitive Recursive Function|primitive recursive]] because it is defined by [[Definition:Substitution (Mathematical Logic)|substitution]] from: * the [[Signum Function is Primitive Recursive|primitive recursive function $\overline{\operatorname{sgn}}$]]; * the primitive recursive function $\chi_\mathcal R$ (primitive recursive from definition, as $\mathcal R$ is so defined). Hence from [[Definition by Cases is Primitive Recursive]], $g$ is [[Definition:Primitive Recursive Function|primitive recursive]]. {{qed}} [[Category:Primitive Recursive Functions]] 14dw34ukycu5fmhk6hxifudzc78si4v	1
Let $T$ be a finitely satisfiable $\mathcal L$-theory. There is a finitely satisfiable $\mathcal L$-theory $T'$ which contains $T$ as a subset such that for all $\mathcal L$-sentences $\phi$, either $\phi \in T'$ or $\neg\phi \in T'$. {{explain|Does this actually mean the same as the statement of the theorem in [[Finitely Satisfiable Theory has Maximal Finitely Satisfiable Extension]]? If so, replace it. If not, then it is a different proof altogether. If the two statements are equivalent, then this needs to be demonstrated.}}	1
Let $z$ be a non-zero [[Definition:Complex Number|Complex Number]]. Then: :$\displaystyle \frac {\sin z} z = \cos \frac z 2 \cos \frac z 4 \cos \frac z 8 \cdots = \prod_{i \mathop = 1}^{\infty} \cos \frac z {2^i}$ where $\sin$ denotes the [[Definition:Complex Cosine Function|sine function]] and $\cos$ denotes the [[Definition:Complex Cosine Function|cosine function]].	1
:$\vdash \paren {p \implies q} \land \paren {\neg p \implies q} \implies q$	1
From [[Count of Truth Functions]] there are $2^{\paren {2^1} } = 4$ distinct [[Definition:Truth Function|truth functions]] on $1$ variable. These can be depicted in a [[Definition:Truth Table|truth table]] as follows: :$\begin{array}{|c|cccc|} \hline p & \circ_1 & \circ_2 & \circ_3 & \circ_4 \\ \hline \T & \T & \T & \F & \F \\ \F & \T & \F & \T & \F \\ \hline \end{array}$ $\circ_1$: Whether $p = \T$ or $p = \F$, $\map {\circ_1} p = \T$. Thus $\circ_1$ is the [[Definition:Constant Mapping|constant function]] $\map {\circ_1} p = \T$. $\circ_2$: We have: :$(1): \quad p = \T \implies \map {\circ_2} p = \T$ :$(2): \quad p = \F \implies \map {\circ_2} p = \F$ Thus $\circ_2$ is the [[Definition:Identity Mapping|identity function]] $\map {\circ_2} p = p$. $\circ_3$: We have: :$(1): \quad p = \T \implies \map {\circ_3} p = \F$ :$(2): \quad p = \F \implies \map {\circ_3} p = \T$ Thus $\circ_3$ is the [[Definition:Logical Not|logical not]] function $\map {\circ_3} p = \neg p$. $\circ_4$: Whether $p = \T$ or $p = \F$, $\map {\circ_4} p = \F$. Thus $\circ_4$ is the [[Definition:Constant Mapping|constant function]] $\map {\circ_4} p = \F$. All four have been examined, and there are no other [[Definition:Unary|unary]] [[Definition:Truth Function|truth functions]]. {{qed}}	1
=== The Boolean Satisfiability Problem is NP === Given a [[Definition:Boolean Satisfiability Problem|Boolean Satisfiability Problem]] with a set of variables $X$ and clauses $L$ and a possible solution to the problem, it is a trivial matter to evaluate all the clauses in $L$ to verify the solution in polynomial time. {{Handwaving|The above needs to be justified with a page demonstrating this.}} [[NP Problem iff Solution Verifiable in Polynomial Time|Because a potential solution can be verified or rejected in polynomial time]] it is [[Definition:NP Complexity Class|NP]]. === All NP-complete problems are polynomially reducible to the Boolean Satisfiability problem === The objective is, given a non-deterministic Turing Machine $M$ with $k$ internal states and an input $x$, to construct a set of variables and clauses that has a solution iff $M$ accepts the input $x$. From the definition of [[Definition:NP Complexity Class|NP]] we know that $M$ either accepts the input $x$ within $p \left({\left\vert{x}\right\vert}\right)$ steps, or it does not accept the input at all, where $p$ is some polynomial. From [[Turing Machine cannot use More Squares of Memory than the Number of Steps that it Runs]], we only need to concern ourselves with the first $p \left({\left\vert{x}\right\vert}\right)$ squares of memory. Let $\Sigma$ denote the finite alphabet that the machine recognizes. Let the variables for the Boolean Satisfiability Problem be given by: {| border="1" |- ! Variable ! Interpretation ! Number |- | $q_{j n}$ | $M$ is in state $j$ on step $n$ | $k * p \left({\left\vert{x}\right\vert}\right)$ |- | $T_{m \ \alpha \ n}$ | The $m$th square contains the symbol $\alpha \in \Sigma$ on step $n$ | $|\Sigma| * p \left({x}\right)^2$ |- | $H_{m \ n}$ | The $m$th square is being looked at during step $n$ | $p \left({\left\vert{x}\right\vert}\right)^2$ |} {{explain|The symbol $*$ in the above -- while it is frequently used in computer science to denote multiplication, this is a page on a mathematics website, and so a standard mathematics symbol is required.}} Let the clauses for the Boolean Satisfiability Problem be given by: {| border="1" |- ! Clause ! Interpretation ! Number ! Length |- | $q_{0 0}$ | The Machine is in the initial state $\left({q_0}\right)$ on step 0. | 1 | Constant |- | $if \ m < \left\vert{x}\right\vert \ T_{m x_m 0}$ | Let $x_m$ denote the $m$'th symbol of the input. This represents the initial state of the work tape. | $\left\vert{x}\right\vert$ | Constant |- | $H_{00}$ | The Tape is in the initial position on step 0. | 1 | Constant |- | $if \ a \ne b \ q_{a n} \implies \neg q_{b n}$ | Only one internal state at a time | $\left({k^2 - k}\right) * n$ | Constant |- | $if \ a \ne b \ T_{m \ a \ n} \implies \neg T_{m \ b \ n}$ | Only one symbol per square at a time | $\left({\left\vert{\Sigma}\right\vert^2 - \left\vert{\Sigma}\right\vert}\right) * p \left({\left\vert{x}\right\vert}\right)^2$ | Constant |- | $if \ a \ne b \ H_{a n} \implies \neg H_{b n}$ | Only one square is being looked at during any cycle. | $p \left({\left\vert{x}\right\vert}\right)^2 - p \left({\left\vert{x}\right\vert}\right)$ | Constant |- | $\neg H_{m \ n} \implies \left({T_{m \ \alpha \ n} = T_{m \ \alpha \ n+1} }\right)$ | A square that was not looked at cannot change. | $\left\vert{\Sigma}\right\vert * p \left({\left\vert{x}\right\vert}\right)^2$ | Constant |- | $q_{accept \ p \left({\left\vert{x}\right\vert}\right)}$ | $M$ is in the accepting state at the end of the computation. | 1 | Constant |- | $\left({q_{j \ n} \land T_{m \ \alpha \ n} \land H_{m \ n} }\right) \implies \bigvee \left({q_{l \ n + 1} \land T_{m \ \beta \ n + 1} \land H_{m \pm 1 \ n + 1} }\right)$ | These clauses encode the rules of $M$ into logical expressions. See the explanation below. | $k * \left\vert{\Sigma}\right\vert * p \left({\left\vert{x}\right\vert}\right)^2$ | Varies (see below) |} A production rule in a non-deterministic Turing machine can be written in the form: : $\left({q_a, \alpha}\right) \to \left({q_b, \beta, D_1}\right) \lor \left({q_c, \gamma, D_2}\right)$ meaning: :if the machine is in state $q_a$ and reading $\alpha$ on the tape, ::either: :::replace $\alpha$ with $\beta$ :::move one square in direction $D_1$ (either left or right) :::change the internal state to $q_b$ ::or: :::replace $\alpha$ with $\gamma$ :::move one square in the $D_2$ direction :::go to internal state $q_c$. If $D_1$ is left and $D_2$ is right then this rule would translate to: : $\left({q_a \land T_{m \ \alpha \ n} \land H_{m \ n} }\right) \implies \left({\left({q_b \land T_{m \ \beta \ n+1} \land H_{m-1 \ n+1} }\right) \lor \left({q_c \land T_{m \ \gamma \ n+1} \land H_{m+1 \ n+1}}\right)}\right)$ If the rule in the machine allows for more then two choices then this rule can be modified by adding more triplets to the right hand side of the implication rule. The length of this clause is determined by the number of choices that $M$ gives for a given internal state and a given input. Because this number of choices is bounded for any given machine, the total space used for this group of clauses is $O \left({p \left({\left\vert{x}\right\vert}\right)^2}\right)$. In total, the size of the the Boolean Satisfiability problem is $O \left({p \left({ \left\vert{x}\right\vert }\right)^2 }\right)$, with the constant depending on $M$. The conversion from a description of $M$ to the Boolean Satisfiability problem is straightforward and can be done in polynomial time. The problem described has a solution {{iff}} $M$ accepts $x$ as its input. All NP problems are polynomially reducible to the Boolean Satisfiability problem. Therefore the Boolean Satisfiability is [[Definition:NP-hard|NP-hard]]. The Boolean Satisfiability Problem is NP-complete. {{qed}} {{Namedfor|Stephen Arthur Cook|name2 = Leonid Anatolievich Levin|cat = Cook|cat2 = Levin}}	1
Because $a_n = \map o {b_n}$, there exists $n_0 \in \N$ such that $\size {a_n} \le 1 \cdot \size {b_n}$ for $n \ge n_0$. Thus $a_n = \map \OO {b_n}$. {{qed}} [[Category:Asymptotic Notation]] sihfpytj7955n6e5181hd2fyhtved9i	1
{{BeginTableau|\vdash \left({\neg \left({p \land q}\right)}\right) \iff \left({p \implies \neg q}\right)}} {{Assumption|1|\neg \left({p \land q}\right)}} {{SequentIntro|2|1|p \implies \neg q|1|[[Modus Ponendo Tollens/Variant/Formulation 1/Forward Implication|Modus Ponendo Tollens: Formulation 1: Forward Implication]]}} {{Implication|3||\left({\neg \left({p \land q}\right)}\right) \implies \left({p \implies \neg q}\right)|1|2}} {{Assumption|4|p \implies \neg q}} {{SequentIntro|5|4|\neg \left({p \land q}\right)|4|[[Modus Ponendo Tollens/Variant/Formulation 1/Reverse Implication|Modus Ponendo Tollens: Formulation 1: Reverse Implication]]}} {{Implication|6||\left({p \implies \neg q}\right) \implies \left({\neg \left({p \land q}\right)}\right)|4|5}} {{BiconditionalIntro|7||\left({\neg \left({p \land q}\right)}\right) \iff \left({p \implies \neg q}\right)|3|6}} {{EndTableau}} {{qed}}	1
The idea is: :to extend the language by adding $\kappa$ many new constants and: :to extend the theory by adding sentences asserting that these constants are distinct. It is shown that this new theory is finitely satisfiable using an infinite model of $T$. Compactness then implies that the new theory has a model. Some care needs to be taken to ensure that we construct a model of exactly size $\kappa$. Let $\LL^*$ be the language formed by adding new constants $\set {c_\alpha: \alpha < \kappa}$ to $\LL$. Let $T^*$ be the $\LL^*$-theory formed by adding the sentences $\set {c_\alpha \ne c_\beta: \alpha, \beta < \kappa, \ \alpha \ne \beta}$ to $T$. We show that $T^*$ is finitely satisfiable: Let $\Delta$ be a finite subset of $T^*$. Then $\Delta$ contains: :finitely many sentences from $T$ along with: :finitely many sentences of the form $c_\alpha \ne c_\beta$ for the new constant symbols. Since $T$ has an infinite model, it must have a model $\MM$ of cardinality at most $\card \LL + \aleph_0$. This model already satisfies everything in $T$. So, since we can find arbitrarily many distinct elements in it, it can also be used as a model of $\Delta$ by interpreting the finitely many new constant symbols in $\Delta$ as distinct elements of $\MM$. Since $T^*$ is finitely satisfiable, it follows by the [[Compactness Theorem]] that $T^*$ itself is satisfiable. Since $T^*$ ensures the existence of $\kappa$ many distinct elements, this means it has models of size at least $\kappa$. It can be proved separately or observed from the ultraproduct proof of the compactness theorem that $T^*$ then has a model $\MM^*$ of exactly size $\kappa$. {{explain|That proof needs to be proved, and / or a link needs to be provided to that ultraproduct proof and its implications explained.}} Since $T^*$ contains $T$, $\MM^*$ is a model of $T$ of size $\kappa$. {{qed}} {{Namedfor|Leopold Löwenheim|name2 = Thoralf Albert Skolem|cat = Löwenheim|cat2 = Skolem}}	1
Let $G$ be a [[Definition:Two-Person Zero-Sum Game|two-person zero-sum game]]. Let $G$ be represented by a [[Definition:Payoff Table|payoff table]] that is [[Definition:Skew-Symmetric|skew-symmetric]]. Then the [[Definition:Value|value]] of $G$ is zero.	1
==== [[Factor Principles/Conjunction on Left/Formulation 1|Formulation 1]] ==== {{:Factor Principles/Conjunction on Left/Formulation 1}} ==== [[Factor Principles/Conjunction on Left/Formulation 2|Formulation 2]] ==== {{:Factor Principles/Conjunction on Left/Formulation 2}}	1
{{BeginTableau|p \vdash p}} {{Premise|1|p}} {{EndTableau}} {{qed}} This is the shortest [[Definition:Tableau Proof (Formal Systems)|tableau proof]] possible.	1
It will suffice to show that every [[Definition:Open Cover|open cover]] of $S_n^{\mathcal M}(A)$ by the [[Definition:Synthetic Basis|basic open sets]] $[\phi]$ of the topology has a [[Definition:Subcover|finite subcover]]. Let $\mathcal U = \{ [\phi_i] : i\in I \}$ be a cover of $S_n^{\mathcal M}(A)$ by basic open sets. This means that every complete $n$-type over $A$ contains some $\phi_i$. We will find a finite subcover of $\mathcal U$. Let $\Gamma = \{ \neg\phi_i : i\in I \}$. Then $\operatorname{Th}_\mathcal A(M) \cup \Gamma$ cannot be [[Definition:Satisfiable|satisfied]], since if $\mathcal N \models \operatorname{Th}_\mathcal A(M) \cup \Gamma (\bar{b})$, then the [[Definition:Type|type]] $\operatorname{tp}_\mathcal N (\bar{b}/A)$ is a [[Definition:Complete Type|complete $n$-type]] in $S_n^{\mathcal M}(A)$ which does not contain any $\phi_i$. By the [[Compactness Theorem]], $\operatorname{Th}_\mathcal A(M) \cup \Gamma$ must have a finite subset $\Delta$ which is not satisfiable. Since $\Delta$ is not satisfiable but $\operatorname{Th}_\mathcal A(M)$ is, $\Delta$ must contain some of the $\neg\phi_i$ from $\Gamma$. Furthermore, we must have that every model of $\operatorname{Th}_\mathcal A(M)$ fails to satisfy at least one of these finitely many $\neg\phi_i$ in $\Delta$. We claim that the finite set $\mathcal F = \{ [\phi_i] : \neg\phi_i \in \Delta \}$ is a finite subcover of $\mathcal U$. Since $\mathcal F$ is clearly a subset of $\mathcal U$, we need only show that every $p\in S_n^{\mathcal M}(A)$ is contained in some $[\phi_i]\in\mathcal F$. That is, we must show that each $p\in S_n^{\mathcal M}(A)$ contains one of these $\phi_i$. Let $p\in S_n^{\mathcal M}(A)$. By definition, this means that $p\cup \operatorname{Th}_\mathcal A(M)$ is satisfiable by some $\mathcal N$. But, as mentioned above, since $\mathcal N\models \operatorname{Th}_\mathcal A(M)$, we have that $\mathcal N\not\models \neg\phi_i$ for some $\neg\phi_i \in \Delta$. Since $p$ is complete, it must contain either $\phi_i$ or $\neg\phi_i$. However, if $p$ contained $\neg\phi_i$, then $\mathcal N\models \neg\phi_i$, which contradicts $\mathcal N\not\models \neg\phi_i$. Thus, $p$ contains $\phi_i$. This demonstrates that $\mathcal F$ is a finite subcover for $\mathcal U$. Thus, $S_n^{\mathcal M}(A)$ is compact. {{qed}} [[Category:Model Theory]] nn84c5wfi332meprrm3tew7ig41k53n	1
Denote with $\mathscr H_2 - (\text A 4)$ the [[Definition:Proof System|proof system]] resulting from $\mathscr H_2$ by removing [[Definition:Axiom (Formal Systems)|axiom]] $(\text A 4)$. Consider $\mathscr C_5$, [[Definition:Constructed Semantics/Instance 5|Instance 5]] of [[Definition:Constructed Semantics|constructed semantics]]. We will prove that: * $\mathscr H_2 - (\text A 4)$ is [[Definition:Sound Proof System|sound]] for $\mathscr C_5$; * [[Definition:Axiom (Formal Systems)|Axiom]] $(\text A 4)$ is not a [[Definition:Tautology (Formal Semantics)|tautology]] in $\mathscr C_5$ which leads to the conclusion that $(\text A 4)$ is not a [[Definition:Theorem (Formal Systems)|theorem]] of $\mathscr H_2 - (\text A 4)$. === Soundness of $\mathscr H_2 - (\text A 4)$ for $\mathscr C_5$ === Starting with the [[Definition:Axiom (Formal Systems)|axioms]]: {{begin-axiom}} {{axiom | n = \text A 1 | lc= [[Rule of Idempotence/Disjunction/Formulation 2/Reverse Implication|Rule of Idempotence]] | m = \paren {p \lor p} \implies p | rc= [[Definition:Constructed Semantics/Instance 5/Rule of Idempotence|Proof of Tautology]] }} {{axiom | n = \text A 2 | lc= [[Rule of Addition/Sequent Form/Formulation 2/Form 2|Rule of Addition]] | m = q \implies \paren {p \lor p} | rc= [[Definition:Constructed Semantics/Instance 5/Rule of Addition|Proof of Tautology]] }} {{axiom | n = \text A 3 | lc= [[Rule of Commutation/Disjunction/Formulation 2/Forward Implication|Rule of Commutation]] | m = \paren {p \lor q} \implies \paren {q \lor p} | rc= [[Definition:Constructed Semantics/Instance 5/Rule of Commutation|Proof of Tautology]] }} {{end-axiom}} Next it needs to be shown that the [[Definition:Hilbert Proof System/Instance 2|rules of inference of $\mathscr H_2$]] preserve $\mathscr C_5$-[[Definition:Tautology (Formal Semantics)|tautologies]]. ==== Rule $\text {RST} 1$: Rule of Uniform Substitution ==== By definition, any [[Definition:WFF of Propositional Logic|WFF]] is assigned a value from $\set {0, 1, 2, 3}$. Thus, in applying [[Definition:Hilbert Proof System/Instance 2|Rule $\text {RST} 1$]], we are introducing $0$, $1$, $2$ or $3$ in the position of a [[Definition:Propositional Variable|propositional variable]]. But all possibilities of assignments to such [[Definition:Propositional Variable|propositional variables]] were shown not to affect the resulting values of the axioms. Hence [[Definition:Hilbert Proof System/Instance 2|Rule $\text {RST} 1$]] preserves $\mathscr C_5$-[[Definition:Tautology (Formal Semantics)|tautologies]]. ==== Rule $\text {RST} 2$: Rule of Substitution by Definition ==== Because the definition of $\mathscr C_5$ was given in terms of [[Definition:Hilbert Proof System/Instance 2|Rule $\text {RST} 2$]], it cannot affect any of its results. ==== Rule $\text {RST} 3$: Rule of Detachment ==== Suppose $\mathbf A$ and $\mathbf A \implies \mathbf B$ both take value $0$. Then using [[Definition:Hilbert Proof System/Instance 2|Rule $\text {RST} 2$]], definition $(2)$, we get: :$\neg \mathbf A \lor \mathbf B$ taking value $0$ by assumption. But $\neg \mathbf A$ takes value $1$ by definition of $\neg$. So from the definition of $\lor$, it must be that $\mathbf B$ takes value $0$. Hence [[Definition:Hilbert Proof System/Instance 2|Rule $\text {RST} 3$]] also produces only [[Definition:WFF of Propositional Logic|WFFs]] of value $0$. ==== Rule $\text {RST} 4$: Rule of Adjunction ==== Suppose $\mathbf A$ and $\mathbf B$ take value $0$. Then using the definitional abbreviations: :$\mathbf A \land \mathbf B =_{\text {def} } \neg \paren {\neg \mathbf A \lor \neg \mathbf B}$ We compute: {{begin-eqn}} {{eqn | l = \mathbf A \land \mathbf B | r = 0 \land 0 }} {{eqn | r = \neg \paren {\neg 0 \lor \neg 0} | c = [[Definition:Hilbert Proof System/Instance 2|Rule $\text {RST} 2 \, (1)$]] }} {{eqn | r = \neg \paren {1 \lor 1} }} {{eqn | r = \neg 1 }} {{eqn | r = 0 }} {{end-eqn}} proving that [[Definition:Hilbert Proof System/Instance 2|Rule $\text {RST} 4$]] also produces only $0$s from $0$s. Hence $\mathscr H_2 - (\text A 4)$ is [[Definition:Sound Proof System|sound]] for $\mathscr C_5$. === $(\text A 4)$ is not a $\mathscr C_5$-tautology === Recall [[Definition:Axiom (Formal Systems)|axiom]] $(\text A 4)$, the [[Factor Principles/Disjunction on Left/Formulation 2|Factor Principle]]: :$\paren {p \lor q} \implies \paren {q \lor p}$ Under $\mathscr C_5$, we can use definitional abbreviations to arrive at: :$\neg \paren {\neg p \lor q} \lor \paren {\neg \paren {r \lor p} \lor \paren {r \lor q} }$ Applying the definition of $\mathscr C_5$, we have the following: ::$\begin{array}{|ccccc|c|cccccccc|} \hline \neg & (\neg & p & \lor & q) & \lor & (\neg & (r & \lor & p) & \lor & (r & \lor & q)) \\ \hline 1 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 1 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\ 1 & 3 & 2 & 0 & 0 & 0 & 1 & 0 & 0 & 2 & 0 & 0 & 0 & 0 \\ 1 & 0 & 3 & 0 & 0 & 0 & 1 & 0 & 0 & 3 & 0 & 0 & 0 & 0 \\ 1 & 1 & 0 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 1 & 0 & 0 \\ 1 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 0 & 1 & 0 & 0 \\ 1 & 3 & 2 & 0 & 0 & 0 & 3 & 1 & 2 & 2 & 0 & 1 & 0 & 0 \\ 1 & 0 & 3 & 0 & 0 & 0 & 0 & 1 & 3 & 3 & 0 & 1 & 0 & 0 \\ 1 & 1 & 0 & 0 & 0 & 0 & 1 & 2 & 0 & 0 & 0 & 2 & 0 & 0 \\ 1 & 0 & 1 & 0 & 0 & 0 & 3 & 2 & 2 & 1 & 0 & 2 & 0 & 0 \\ 1 & 3 & 2 & 0 & 0 & 0 & 3 & 2 & 2 & 2 & 0 & 2 & 0 & 0 \\ 1 & 0 & 3 & 0 & 0 & 0 & 1 & 2 & 0 & 3 & 0 & 2 & 0 & 0 \\ 1 & 1 & 0 & 0 & 0 & 0 & 1 & 3 & 0 & 0 & 0 & 3 & 0 & 0 \\ 1 & 0 & 1 & 0 & 0 & 0 & 0 & 3 & 3 & 1 & 0 & 3 & 0 & 0 \\ 1 & 3 & 2 & 0 & 0 & 0 & 1 & 3 & 0 & 2 & 0 & 3 & 0 & 0 \\ 1 & 0 & 3 & 0 & 0 & 0 & 0 & 3 & 3 & 3 & 0 & 3 & 0 & 0 \\ 0 & 1 & 0 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\ 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 1 \\ 0 & 3 & 2 & 3 & 1 & 0 & 1 & 0 & 0 & 2 & 0 & 0 & 0 & 1 \\ 1 & 0 & 3 & 0 & 1 & 0 & 1 & 0 & 0 & 3 & 0 & 0 & 0 & 1 \\ 0 & 1 & 0 & 1 & 1 & 0 & 1 & 1 & 0 & 0 & 1 & 1 & 1 & 1 \\ 1 & 0 & 1 & 0 & 1 & 0 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 1 \\ 0 & 3 & 2 & 3 & 1 & 0 & 3 & 1 & 2 & 2 & 3 & 1 & 1 & 1 \\ 1 & 0 & 3 & 0 & 1 & 0 & 0 & 1 & 3 & 3 & 0 & 1 & 1 & 1 \\ 0 & 1 & 0 & 1 & 1 & 0 & 1 & 2 & 0 & 0 & 2 & 2 & 2 & 1 \\ 1 & 0 & 1 & 0 & 1 & 0 & 3 & 2 & 2 & 1 & 0 & 2 & 2 & 1 \\ 0 & 3 & 2 & 3 & 1 & 0 & 3 & 2 & 2 & 2 & 0 & 2 & 2 & 1 \\ 2 & 1 & 2 & 0 & 3 & 2 & 2 & 2 & 1 & 1 & 0 & 3 & 0 & 1 \\ 0 & 1 & 0 & 1 & 1 & 0 & 1 & 3 & 0 & 0 & 3 & 3 & 3 & 1 \\ 1 & 0 & 1 & 0 & 1 & 0 & 0 & 3 & 3 & 1 & 0 & 3 & 3 & 1 \\ 0 & 3 & 2 & 3 & 1 & 0 & 1 & 3 & 0 & 2 & 3 & 3 & 3 & 1 \\ 1 & 0 & 3 & 0 & 1 & 0 & 0 & 3 & 3 & 3 & 0 & 3 & 3 & 1 \\ 3 & 1 & 0 & 2 & 2 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 2 \\ 1 & 0 & 1 & 0 & 2 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 2 \\ 1 & 3 & 2 & 0 & 2 & 0 & 1 & 0 & 0 & 2 & 0 & 0 & 0 & 2 \\ 1 & 0 & 3 & 0 & 2 & 0 & 1 & 0 & 0 & 3 & 0 & 0 & 0 & 2 \\ 3 & 1 & 0 & 2 & 2 & 0 & 1 & 1 & 0 & 0 & 2 & 1 & 2 & 2 \\ 1 & 0 & 1 & 0 & 2 & 0 & 0 & 1 & 1 & 1 & 0 & 1 & 2 & 2 \\ 1 & 3 & 2 & 0 & 2 & 0 & 3 & 1 & 2 & 2 & 0 & 1 & 2 & 2 \\ 1 & 0 & 3 & 0 & 2 & 0 & 0 & 1 & 3 & 3 & 0 & 1 & 2 & 2 \\ 3 & 1 & 0 & 2 & 2 & 0 & 1 & 2 & 0 & 0 & 2 & 2 & 2 & 2 \\ 1 & 0 & 1 & 0 & 2 & 0 & 3 & 2 & 2 & 1 & 0 & 2 & 2 & 2 \\ 1 & 3 & 2 & 0 & 2 & 0 & 3 & 2 & 2 & 2 & 0 & 2 & 2 & 2 \\ 1 & 0 & 3 & 0 & 2 & 2 & 1 & 2 & 0 & 3 & 2 & 2 & 2 & 2 \\ 3 & 1 & 0 & 2 & 2 & 0 & 1 & 3 & 0 & 0 & 0 & 3 & 0 & 2 \\ 1 & 0 & 1 & 0 & 2 & 0 & 0 & 3 & 3 & 1 & 0 & 3 & 0 & 2 \\ 1 & 3 & 2 & 0 & 2 & 0 & 1 & 3 & 0 & 2 & 0 & 3 & 0 & 2 \\ 1 & 0 & 3 & 0 & 2 & 0 & 0 & 3 & 3 & 3 & 0 & 3 & 0 & 2 \\ 0 & 1 & 0 & 3 & 3 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 3 \\ 1 & 0 & 1 & 0 & 3 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 3 \\ 0 & 3 & 2 & 3 & 3 & 0 & 1 & 0 & 0 & 2 & 0 & 0 & 0 & 3 \\ 1 & 0 & 3 & 0 & 3 & 0 & 1 & 0 & 0 & 3 & 0 & 0 & 0 & 3 \\ 0 & 1 & 0 & 3 & 3 & 0 & 1 & 1 & 0 & 0 & 3 & 1 & 3 & 3 \\ 1 & 0 & 1 & 0 & 3 & 0 & 0 & 1 & 1 & 1 & 0 & 1 & 3 & 3 \\ 0 & 3 & 2 & 3 & 3 & 0 & 3 & 1 & 2 & 2 & 3 & 1 & 3 & 3 \\ 1 & 0 & 3 & 0 & 3 & 0 & 0 & 1 & 3 & 3 & 0 & 1 & 3 & 3 \\ 0 & 1 & 0 & 3 & 3 & 0 & 1 & 2 & 0 & 0 & 0 & 2 & 0 & 3 \\ 1 & 0 & 1 & 0 & 3 & 0 & 3 & 2 & 2 & 1 & 0 & 2 & 0 & 3 \\ 0 & 3 & 2 & 3 & 3 & 0 & 3 & 2 & 2 & 2 & 0 & 2 & 0 & 3 \\ 1 & 0 & 3 & 0 & 3 & 0 & 1 & 2 & 0 & 3 & 0 & 2 & 0 & 3 \\ 0 & 1 & 0 & 3 & 3 & 0 & 1 & 3 & 0 & 0 & 3 & 3 & 3 & 3 \\ 1 & 0 & 1 & 0 & 3 & 0 & 0 & 3 & 3 & 1 & 0 & 3 & 3 & 3 \\ 0 & 3 & 2 & 3 & 3 & 0 & 1 & 3 & 0 & 2 & 3 & 3 & 3 & 3 \\ 1 & 0 & 3 & 0 & 3 & 0 & 0 & 3 & 3 & 3 & 0 & 3 & 3 & 3 \\ \hline \end{array}$ Hence according to the definition of $\mathscr C_5$, $(\text A 4)$ is not a [[Definition:Tautology (Formal Semantics)|tautology]]. Therefore $(\text A 4)$ is independent from $(\text A 1)$, $(\text A 2)$, $(\text A 3)$. {{qed}}	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] is [[Definition:True|true]] for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc|c|ccccccc|} \hline p & \land & (q & \lor & r) & \iff & (p & \land & q) & \lor & (p & \land & r) \\ \hline F & F & F & F & F & T & F & F & F & F & F & F & F \\ F & F & F & T & T & T & F & F & F & F & F & F & T \\ F & F & T & T & F & T & F & F & T & F & F & F & F \\ F & F & T & T & T & T & F & F & T & F & F & F & T \\ T & F & F & F & F & T & T & F & F & F & T & F & F \\ T & T & F & T & T & T & T & F & F & T & T & T & T \\ T & T & T & T & F & T & T & T & T & T & T & F & F \\ T & T & T & T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] are [[Definition:True|true]] for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc|c|cccc|} \hline p & \lor & q & \iff & \neg & p & \implies & q \\ \hline F & F & F & T & T & F & F & F \\ F & T & T & T & T & F & T & T \\ T & T & F & T & F & T & T & F \\ T & T & T & T & F & T & T & T \\ \hline \end{array}$ {{qed}}	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, the [[Definition:Truth Value|truth values]] in the appropriate columns match. $\begin{array}{|c||cc|} \hline \bot & \neg & \top \\ \hline F & F & T \\ \hline \end{array}$ {{qed}}	1
{{BeginTableau|\paren {p \land q} \implies r \vdash \paren {p \implies r} \lor \paren {q \implies r} }} {{Premise | 1 | \paren {p \land q} \implies r}} {{SequentIntro | 2 | 1 | \neg \paren {p \lor q} \lor r | 1 | [[Rule of Material Implication/Formulation 1|Rule of Material Implication]]}} {{SequentIntro | 3 | 1 | \neg p \lor \neg q \lor r | 2 | [[De Morgan's Laws (Logic)/Disjunction of Negations|De Morgan's Laws: Disjunction of Negations]]}} {{Addition | 4 | 1 | r \lor \neg p \lor \neg q \lor r | 3 | 2}} {{Commutation | 5 | 1 | \neg p \lor r \lor \neg q \lor r | 4 | Disjunction}} {{SequentIntro | 6 | 1 | \paren {p \implies r} \lor \neg q \lor r | 5 | [[Rule of Material Implication/Formulation 1|Rule of Material Implication]]}} {{SequentIntro | 7 | 1 | \paren {p \implies r} \lor \paren {q \implies r} | 6 | [[Rule of Material Implication/Formulation 1|Rule of Material Implication]]}} {{EndTableau}} {{qed}} [[Category:Principle of Composition]] lrbsgl53wcyrryvmzb11mbkzydx5lg1	1
{{BeginTableau|\vdash p \lor \neg p}} {{TheoremIntro|1|\neg\neg (p \lor \neg p)|[[Negation of Excluded Middle is False/Form 2]]}} {{DoubleNegElimination|2||p \lor \neg p|1}} {{EndTableau}} {{Qed}}	1
Every [[Definition:Primitive Recursive Function|primitive recursive function]] is a [[Definition:Total Recursive Function|total recursive function]].	1
We are given that $M$ is a [[Definition:Minimally Inductive Class under General Mapping|minimally inductive class under $g$]]. That is, $M$ is an [[Definition:Inductive Class under General Mapping|inductive class under $g$]] with the extra property that $M$ has no [[Definition:Proper Class|proper class]] which is also [[Definition:Inductive Class under General Mapping|inductive class under $g$]]. Let $P$ be a [[Definition:Propositional Function|propositional function]] on $M$ which has the properties specified: :$(1): \quad \map P \O = \T$ :$(2): \quad \forall x \in M: \map P x = \T \implies \map P {\map g x} = \T$ Thus by definition, the [[Definition:Class|class]] $S$ of all [[Definition:Element of Class|elements]] of $M$ such that $\map P x = \T$ is an [[Definition:Inductive Class under General Mapping|inductive class under $g$]]. But because $M$ is [[Definition:Minimally Inductive Class under General Mapping|minimally inductive under $g$]], $S$ contains all [[Definition:Element of Class|elements]] of $M$. That is: :$\forall x \in M: \map P x = \T$ as we were to show. {{Qed}}	1
The two directions of this theorem are respectively addressed on: :[[Soundness Theorem for Semantic Tableaus]] :[[Completeness Theorem for Semantic Tableaus]] {{qed}}	1
{{BeginTableau|\vdash \paren {p \implies q} \land \paren {\neg p \implies q} \implies q}} {{Assumption|1|\paren {p \implies q} \land \paren {\neg p \implies q} }} {{Simplification|2|1|p \implies q|1|1}} {{Simplification|3|1|\neg p \implies q|1|2}} {{Assumption|4|\neg q}} {{ModusTollens|5|1, 4|\neg p|2|4}} {{ModusPonens|6|1, 4|q|3|5}} {{NonContradiction|7|1, 4|4|6}} {{Contradiction|8|1|\neg \neg q|4|7}} {{DoubleNegElimination|9|1|q|8}} {{Implication|10||\paren {p \implies q} \land \paren {\neg p \implies q} \implies q|1|9}} {{EndTableau|qed}}	1
: $\left ({p \iff q}\right) \vdash \left ({p \dashv \vdash q}\right)$	1
{{BeginTableau|p \implies \top \vdash \top}} {{Premise|1|p \implies \top}} {{TopIntro|2}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|\top \vdash p \implies \top}} {{Assumption|1|p}} {{Premise|2|\top}} {{Implication|3|1|p \implies \top|1|2}} {{EndTableau}} {{qed}}	1
: $p \implies q \vdash \left({r \lor p}\right) \implies \left ({r \lor q}\right)$	1
Suppose we have a [[Definition:Universal Statement|universal statement]]: :$\forall x: \map P x$ where $\forall$ is the [[Definition:Universal Quantifier|universal quantifier]] and $\map P x$ is a [[Definition:Propositional Function|propositional function]]. Then we can deduce: :$\map P {\mathbf a}$ where $\mathbf a$ is any arbitrary [[Definition:Object|object]] we care to choose in the [[Definition:Universe of Discourse|universe of discourse]]. In [[Definition:Natural Language|natural language]]: :''Suppose $P$ is true of everything in the [[Definition:Universe of Discourse|universe of discourse]].'' :''Let $\mathbf a$ be an element of the [[Definition:Universe of Discourse|universe of discourse]]." :''Then $P$ is true of $\mathbf a$.''	1
Let $\sequence {a_n}, \sequence {b_n}, \sequence {c_n}, \sequence {d_n}$ be [[Definition:Sequence|sequences]] of [[Definition:Real Number|real]] or [[Definition:Complex Number|complex numbers]]. Let: :$a_n = \map o {b_n}$ :$c_n = \map o {d_n}$ where $o$ denotes [[Definition:Little-O Notation for Sequences|little-o notation]]. Then: :$a_n + c_n = \map o {\size {b_n} + \size {d_n} }$	1
Let $a, b, c \in S$. Let: :$x = a \wedge \paren {b \wedge c}$ :$y = \paren {a \wedge b} \wedge c$ Then: {{begin-eqn}} {{eqn | l = a \vee x | r = a \vee \paren {a \wedge \paren {b \wedge c} } | c = }} {{eqn |r = \paren {a \vee a} \wedge \paren {a \vee \paren {b \wedge c} } | c = [[Definition:Boolean Algebra/Axioms/Definition 1|Boolean Algebra: Axiom $(\text {BA}_1 \ 2)$]]: both $\vee$ and $\wedge$ [[Definition:Distributive Operation|distribute]] over the other }} {{eqn | r = a \wedge \paren {a \vee \paren {b \wedge c} } | c = [[Operations of Boolean Algebra are Idempotent]] }} {{eqn | r = a | c = [[Absorption Laws (Boolean Algebras)]] }} {{end-eqn}} Similarly: {{begin-eqn}} {{eqn | l = a \vee y | r = a \vee \paren {\paren {a \wedge b} \wedge c} | c = }} {{eqn | r = \paren {a \vee \paren {a \wedge b} } \wedge \paren {a \vee c} | c = [[Definition:Boolean Algebra/Axioms/Definition 1|Boolean Algebra: Axiom $(\text {BA}_1 \ 2)$]]: both $\vee$ and $\wedge$ [[Definition:Distributive Operation|distribute]] over the other }} {{eqn | r = a \wedge \paren {a \vee c} | c = [[Absorption Laws (Boolean Algebras)]] }} {{eqn | r = a | c = [[Absorption Laws (Boolean Algebras)]] }} {{end-eqn}} Thus we see we have $a \vee x = a \vee y$. Next: {{begin-eqn}} {{eqn | l = \neg a \vee x | r = \neg a \vee \paren {a \wedge \paren {b \wedge c} } | c = }} {{eqn | r = \paren {\neg a \vee a} \wedge \paren {\neg a \vee \paren {b \wedge c} } | c = [[Definition:Boolean Algebra/Axioms/Definition 1|Boolean Algebra: Axiom $(\text {BA}_1 \ 2)$]]: both $\vee$ and $\wedge$ [[Definition:Distributive Operation|distribute]] over the other }} {{eqn | r = \top \wedge \paren {\neg a \vee \paren {b \wedge c} } | c = [[Definition:Boolean Algebra/Axioms/Definition 1|Boolean Algebra: Axiom $(\text {BA}_1 \ 4)$]]: $\neg a \vee a = \top$ }} {{eqn | r = \neg a \vee \paren {b \wedge c} | c = [[Definition:Boolean Algebra/Axioms/Definition 1|Boolean Algebra: Axiom $(\text {BA}_1 \ 3)$]]: $\top$ is the [[Definition:Identity Element|identity]] of $\wedge$ }} {{end-eqn}} Similarly: {{begin-eqn}} {{eqn | l = \neg a \vee y | r = \neg a \vee \paren {\paren {a \wedge b} \wedge c} | c = }} {{eqn | r = \paren {\neg a \vee \paren {a \wedge b} } \wedge \paren {\neg a \vee c} | c = [[Definition:Boolean Algebra/Axioms/Definition 1|Boolean Algebra: Axiom $(\text {BA}_1 \ 2)$]]: both $\vee$ and $\wedge$ [[Definition:Distributive Operation|distribute]] over the other }} {{eqn | r = \paren {\paren {\neg a \vee a} \wedge \paren {\neg a \vee b} } \wedge \paren {\neg a \vee c} | c = [[Definition:Boolean Algebra/Axioms/Definition 1|Boolean Algebra: Axiom $(\text {BA}_1 \ 2)$]]: both $\vee$ and $\wedge$ [[Definition:Distributive Operation|distribute]] over the other }} {{eqn | r = \paren {\top \wedge \paren {\neg a \vee b} } \wedge \paren {\neg a \vee c} | c = [[Definition:Boolean Algebra/Axioms/Definition 1|Boolean Algebra: Axiom $(\text {BA}_1 \ 4)$]]: $\neg a \vee a = \top$ }} {{eqn | r = \paren {\neg a \vee b} \wedge \paren {\neg a \vee c} | c = [[Definition:Boolean Algebra/Axioms/Definition 1|Boolean Algebra: Axiom $(\text {BA}_1 \ 3)$]]: $\top$ is the [[Definition:Identity Element|identity]] of $\wedge$ }} {{eqn | r = \neg a \vee \paren {b \wedge c} | c = [[Definition:Boolean Algebra/Axioms/Definition 1|Boolean Algebra: Axiom $(\text {BA}_1 \ 2)$]]: both $\vee$ and $\wedge$ [[Definition:Distributive Operation|distribute]] over the other }} {{end-eqn}} Thus we see we have $\neg a \vee x = \neg a \vee y$. In conclusion, we have: :$a \vee x = a \vee y$ :$\neg a \vee x = \neg a \vee y$ Hence $x = y$ by [[Cancellation of Join in Boolean Algebra]], that is: :$\paren {a \wedge b} \wedge c = a \wedge \paren {b \wedge c}$ {{qed|lemma}} The result: :$\paren {a \vee b} \vee c = a \vee \paren {b \vee c}$ follows from the [[Duality Principle (Boolean Algebras)|Duality Principle]]. {{qed}}	1
Let $\mathbf H$ be a [[Definition:Countable Set|countable set]] (either [[Definition:Finite Set|finite]] or [[Definition:Countably Infinite|infinite]]) of [[Definition:WFF of Propositional Logic|WFFs of propositional logic]]. The following [[Definition:Statement|statements]] are [[Definition:Logical Equivalence|logically equivalent]]: :$(1): \quad$ $\mathbf H$ has a [[Definition:Model (Boolean Interpretations)|model]]. :$(2): \quad$ $\mathbf H$ is [[Definition:Consistent Set of Formulas|consistent]] for the [[Definition:Proof System of Propositional Tableaus|proof system of propositional tableaus]]. :$(3): \quad$ $\mathbf H$ has no [[Definition:Tableau Confutation|tableau confutation]].	1
Let $\downarrow$ signify the [[Definition:Logical NOR|NOR]] operation. Then, for any two [[Definition:Proposition|propositions]] $p$ and $q$: :$p \downarrow q \dashv \vdash q \downarrow p$ That is, [[Definition:Logical NOR|NOR]] is [[Definition:Commutative Operation|commutative]].	1
{{BeginTableau|q \implies \paren {p \lor q} }} {{Premise|1|q}} {{Addition|2|1|p \lor q|1|2}} {{Implication|3||q \implies \paren {p \lor q}|1|3}} {{EndTableau}} {{Qed}}	1
:$p \implies \neg q \vdash \neg \paren {p \land q}$	1
Let $\mathbf 2$ be the [[Definition:Boolean Algebra|Boolean algebra]] [[Definition:Two (Boolean Algebra)|two]], and let $X$ be a [[Definition:Set|set]]. Let $\mathbf 2^X$ be the [[Definition:Set of All Mappings|set of all mappings]] $p: X \to \mathbf 2$. Define the operations $\vee$, $\wedge$ and $\neg$ on $\mathbf 2^X$ in [[Definition:Pointwise Operation|pointwise]] fashion thus: :$\vee: \mathbf 2^X \times \mathbf 2^X \to \mathbf 2^X, \left({p \vee q}\right) (x) := p (x) \vee q (x)$ :$\wedge: \mathbf 2^X \times \mathbf 2^X \to \mathbf 2^X, \left({p \wedge q}\right) (x) := p (x) \wedge q (x)$ :$\neg: \mathbf 2^X \to \mathbf 2^X, \left({\neg p}\right) (x) := \neg p (x)$ Furthermore, write $\bot$ and $\top$ for the [[Definition:Constant Mapping|constant mappings]] with these values, viz: :$\bot: X \to \mathbf 2, \bot (x) := \bot$ :$\top: X \to \mathbf 2, \top (x) := \top$ Then $\left({\mathbf 2^X, \vee, \wedge, \neg}\right)$ is a [[Definition:Boolean Algebra|Boolean algebra]], with $\bot$ and $\top$ as [[Definition:Identity Element|identities]] for $\vee$ and $\wedge$, respectively.	1
Let $D_n$ be a [[Definition:Digraph|digraph]] of [[Definition:Order of Graph|order]] $n$ such that $n \ge 1$. Let $D_n$ have the greatest number of [[Definition:Arc of Digraph|arcs]] of all [[Definition:Digraph|digraphs]] of [[Definition:Order of Graph|order]] $n$. The number of [[Definition:Arc of Digraph|arcs]] in $D$ is given by: :$\size {D_n} = n \paren {n - 1}$	1
:$p \iff q \vdash q \implies p$	1
Let $\map P n$ be a [[Definition:Propositional Function|propositional function]] depending on $n \in \Z$. Let $n_0 \in \Z$ be given. Suppose that: :$(1): \quad \map P {n_0}$ is [[Definition:True|true]] :$(2): \quad \forall k \in \Z: k \ge n_0 : \map P k \implies \map P {k + 1}$ Then: :$\map P n$ is [[Definition:True|true]] for all $n \in \Z$ such that $n \ge n_0$.	1
The [[Definition:Natural Numbers|set of natural numbers]] $\N$ is [[Definition:Primitive Recursive Set|primitive recursive]].	1
Let the [[Definition:Function|functions]] $f: \N^k \to \N$ and $g: \N^{k+2} \to \N$ be [[Definition:URM Computability|URM computable functions]]. Let $h: \N^{k+1} \to \N$ be obtained from $f$ and $g$ by [[Definition:Primitive Recursion|primitive recursion]]. Then $h$ is also [[Definition:URM Computability|URM computable]].	1
: $\neg \left({p \land q}\right) \dashv \vdash p \implies \neg q$	1
=== [[Self-Distributive Law for Conditional/Forward Implication/Formulation 1/Proof|Proof of Forward Implication]] === {{:Self-Distributive Law for Conditional/Forward Implication/Formulation 1/Proof}} === [[Self-Distributive Law for Conditional/Reverse Implication/Formulation 1/Proof|Proof of Reverse Implication]] === {{:Self-Distributive Law for Conditional/Reverse Implication/Formulation 1/Proof}}	1
A [[Definition:Natural Numbers|natural number]] $n$ codes a [[Definition:URM Program|URM program]] {{iff}} it [[Definition:Sequence Coding|codes a sequence]] of [[Definition:Positive Integer|positive integers]] which are the [[Unique Code for URM Instruction|code numbers of URM instructions]]. Suppose $n$ codes such a sequence. Then $\operatorname{len} \left({n}\right)$ is the number of terms in this sequence, where $\operatorname{len} \left({n}\right)$ is the [[Definition:Length of Integer|length of $n$]]. Also, for $1 \le j \le \operatorname{len} \left({n}\right)$, $\left({n}\right)_j$ is the [[Definition:Prime Exponent Function|exponent of the $j$th prime]] in the [[Definition:Prime Decomposition|prime decomposition]] of $n$. So $\left({n}\right)_j$ is the $j$th number in the [[Definition:Sequence Coding|sequence coded by $n$]]. So: :$n \in \operatorname{Prog}$ {{iff}} $\chi_{\operatorname{Seq}} \left({n}\right) = 1$ and $\left({n}\right)_j \in \operatorname{Instr}$ for $1 \le j \le \operatorname{len} \left({n}\right)$ where $\chi_{\operatorname{Seq}}$ is the [[Definition:Characteristic Function of Set|characteristic function]] of the set of [[Definition:Sequence Coding|code numbers of finite sequences of positive integers]]. Now $\left({n}\right)_j \in \operatorname{Instr} \iff \chi_{\operatorname{Instr}} \left({\left({n}\right)_j}\right) = 1$. So $\left({n}\right)_j \in \operatorname{Instr}$ for $1 \le j \le \operatorname{len} \left({n}\right)$ {{iff}} $\chi_{\operatorname{Instr}} \left({\left({n}\right)_j}\right) = 1$ for $1 \le j \le \operatorname{len} \left({n}\right)$. This is the case {{iff}}: :$\displaystyle \prod_{j \mathop = 1}^{\operatorname{len} \left({n}\right)} = 1$ Thus $n \in \operatorname{Prog}$ {{iff}}: :$\displaystyle \chi_{\operatorname{Seq}} \left({n}\right) \times \prod_{j \mathop = 1}^{\operatorname{len} \left({n}\right)} = 1$ Now we define the [[Definition:Function|function]] $g: \N^2 \to \N$ by: :$\displaystyle g \left({n, z}\right) = \begin{cases} 1 & : z = 0 \\ \displaystyle \prod_{j \mathop = 1}^z \chi_{\operatorname{Instr}} \left({\left({n}\right)_j}\right) & : \text{otherwise} \end{cases}$ We use $g$ to obtain the [[Definition:Characteristic Function of Set|characteristic function]] of the set $\operatorname{Prog}$: :$\chi_{\operatorname{Prog}} \left({n}\right) = \chi_{\operatorname{Seq}} \left({n}\right) g \left({n, \operatorname{len} \left({n}\right)}\right)$ (We need to introduce $g$ to ensure $\chi_{\operatorname{Prog}}$ is defined if $\operatorname{len} \left({n}\right) = 0$.) Now we have that: * [[Prime Exponent Function is Primitive Recursive|$\left({n}\right)_j$ is primitive recursive]]; * [[Set of Codes for URM Instructions is Primitive Recursive|$\operatorname{Instr}$ is primitive recursive]]. So $g$ is therefore [[Definition:Primitive Recursive Function|primitive recursive]], as it is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from these. Therefore $\chi_{\operatorname{Prog}}$ is [[Definition:Primitive Recursive Function|primitive recursive]] as it is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from: * [[Multiplication is Primitive Recursive|the primitive recursive function $\operatorname{mult}$]]; * [[Set of Sequence Codes is Primitive Recursive|the primitive recursive function $\chi_{\operatorname{Seq}}$]]; * the primitive recursive function $g$; * [[Length Function is Primitive Recursive|the primitive recursive function $\operatorname{len}$]]. Hence $\operatorname{Prog}$ is a [[Definition:Primitive Recursive Set|primitive recursive set]]. [[Category:URM Programs]] [[Category:Primitive Recursive Functions]] cxyyd5ymfd8c25stbprdgvsvniuwh86	1
Consider [[Definition:Second Figure of Categorical Syllogism|Figure $\text{II}$]]: {{:Definition:Figure of Categorical Syllogism/II}} Let the [[Definition:Major Premise of Syllogism|major premise]] of $Q$ be denoted $\text{Maj}$. Let the [[Definition:Minor Premise of Syllogism|minor premise]] of $Q$ be denoted $\text{Min}$. Let the [[Definition:Conclusion of Syllogism|conclusion]] of $Q$ be denoted $\text{C}$. $M$ is: : the [[Definition:Predicate of Categorical Statement|predicate]] of $\text{Maj}$ : the [[Definition:Predicate of Categorical Statement|predicate]] of $\text{Min}$. So, in order for $M$ to be [[Definition:Distributed Term of Categorical Syllogism|distributed]], either: : $(1): \quad$ From [[Definition:Distributed Term of Categorical Syllogism/Predicate|Negative Categorical Statement Distributes its Predicate]]: $\text{Maj}$ must be [[Definition:Negative Categorical Statement|negative]] or: : $(2): \quad$ From [[Definition:Distributed Term of Categorical Syllogism/Predicate|Negative Categorical Statement Distributes its Predicate]]: $\text{Min}$ must be [[Definition:Negative Categorical Statement|negative]]. Note that from [[No Valid Categorical Syllogism contains two Negative Premises]], it is not possible for both $\text{Maj}$ and $\text{Min}$ to be [[Definition:Negative Categorical Statement|negative]]. From [[Conclusion of Valid Categorical Syllogism is Negative iff one Premise is Negative]]: : $\text{C}$ is a [[Definition:Negative Categorical Statement|negative categorical statement]]. From [[Definition:Distributed Term of Categorical Syllogism/Predicate|Negative Categorical Statement Distributes its Predicate]]: : $P$ is [[Definition:Distributed Term of Categorical Syllogism|distributed]] in $\text{C}$. From [[Distributed Term of Conclusion of Valid Categorical Syllogism is Distributed in Premise]]: : $P$ is [[Definition:Distributed Term of Categorical Syllogism|distributed]] in $\text{Maj}$. From [[Definition:Distributed Term of Categorical Syllogism/Subject|Universal Categorical Statement Distributes its Subject]]: : $\text{Maj}$ is a [[Definition:Universal Categorical Statement|universal categorical statement]]. Hence, in order for $Q$ to be [[Definition:Valid Argument|valid]]: : $\text{Maj}$ must be a [[Definition:Universal Categorical Statement|universal categorical statement]] : Either $\text{Maj}$ or $\text{Min}$, and therefore $\text{C}$, must be a [[Definition:Negative Categorical Statement|negative categorical statement]]. {{qed}}	1
Let $R$ be a [[Definition:Ring with Unity|ring with unity]]. Let $n \in \Z_{>0}$ be a [[Definition:Strictly Positive Integer|(strictly) positive integer]] such that $n \ne 1$. Let $\map {\MM_R} n$ denote the [[Definition:Matrix Space|$n \times n$ matrix space]] over $R$. Then [[Definition:Matrix Product (Conventional)|(conventional) matrix multiplication]] over $\map {\MM_R} n$ is not [[Definition:Commutative Operation|commutative]]: :$\exists \mathbf A, \mathbf B \in \map {\MM_R} n: \mathbf {A B} \ne \mathbf {B A}$ If $R$ is specifically not [[Definition:Commutative Ring|commutative]], then the result holds when $n = 1$ as well.	1
We observe that: :$\map \Add {n, 0} = n + 0 = n$ and that :$\map \Add {n, m + 1} = n + \paren {m + 1} = \paren {n + m} + 1 = \map \Succ {\map \Add {n, m} }$ where $\Succ$ is the [[Definition:Successor Function|successor function]], which is a [[Definition:Basic Primitive Recursive Function|basic primitive recursive function]]. We are to show that $\Add$ is defined by [[Definition:Primitive Recursion|primitive recursion]]. So we need to find [[Definition:Primitive Recursive Function|primitive recursive functions]] $f: \N \to \N$ and $g: \N^3 \to \N$ such that: :$\map \Add {n, m} = \begin{cases} \map f n & : m = 0 \\ \map g {n, m - 1, \map \Add {n, m - 1} } & : m > 0 \end{cases}$ Because $\map \Add {n, 0} = n$, we can see that: :$\map f n = n$. That is, $f$ is the [[Definition:Basic Primitive Recursive Function|basic primitive recursive function]] $\pr_1^1: \N \to \N$. Because $\map \Add {n, m + 1} = \map \Succ {\map \Add {n, m} }$, we can see that $g$ needs to be a function which maps the [[Definition:Ordered Tuple|ordered triple]] $\tuple {n, m, \map \Add {n, m} }$ to $\map \Succ {\map \Add {n, m} }$. A suitable function is: :$g: \N^3 \to \N$ where $\map g {n_1, n_2, n_3} = \map \Succ {n_3}$ because then: :$\map g {n, m, \map \Add {n, m} } = \map \Succ {\map \Add {n, m} }$ It remains to be shown that $g$ is [[Definition:Primitive Recursive Function|primitive recursive]]. This is achieved by using the [[Definition:Projection Function|projection function]]: :$\map g {n_1, n_2, n_3} = \map \Succ {\map {\pr_3^3} {n_1, n_2, n_3} }$ Thus $g$ is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from the [[Definition:Basic Primitive Recursive Function|basic primitive recursive functions]] $\Succ$ and $\pr_3^3$ and so is [[Definition:Primitive Recursive Function|primitive recursive]]. So $\Add$ is obtained by [[Definition:Primitive Recursion|primitive recursion]] from the [[Definition:Primitive Recursive Function|primitive recursive functions]] $\pr_1^1$ and $g$, and so is [[Definition:Primitive Recursive Function|primitive recursive]]. {{qed}} [[Category:Primitive Recursive Functions]] 95nbchdnbufaaogke2kaxcs6usiyunb	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the appropriate [[Definition:Truth Value|truth values]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc||c|} \hline p & \lor & (p & \land & q) & p \\ \hline F & F & F & F & F & F \\ F & F & F & F & T & F \\ T & T & T & F & F & T \\ T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
:$p \land \left({q \lor r}\right) \dashv \vdash \left({p \land q}\right) \lor \left({p \land r}\right)$	1
It is to be demonstrated that each [[Definition:WFF of Propositional Logic|WFF]] arises by a unique [[Definition:Rule of Formation|rule of formation]] from the [[Definition:Bottom-Up Specification of Propositional Logic|bottom-up specification of propositional logic]]. The rules $\mathbf W : TF$ and $\mathbf W : \mathcal P_0$ need no further treatment. From inspection of the first character it is clear that the remaining $\mathbf W : \neg$ and $\mathbf W : Op$ cannot yield the same [[Definition:WFF of Propositional Logic|WFF]]. What remains is to establish uniqueness in applying $\mathbf W : \neg$ and $\mathbf W : Op$. For $\mathbf W : \neg$, this means to consider: :$\mathbf A = \neg \mathbf B = \neg \mathbf C$ from which it is immediate that $\mathbf B = \mathbf C$. Lastly, for $\mathbf W : Op$, we have the following lemma: === [[Language of Propositional Logic has Unique Parsability/Lemma|Lemma]] === {{:Language of Propositional Logic has Unique Parsability/Lemma}}{{qed|lemma}} Having examined all possible combinations of [[Definition:Rule of Formation|rules of formation]], we conclude that $\mathcal L_0$ has [[Definition:Unique Parsability|unique parsability]]. {{qed}}	1
Let $p$ be a [[Definition:Prime Number|prime number]]. Then: :$\forall n \in \N_{> 0}: \paren {a + b}^{p^n} \equiv a^{p^n} + b^{p^n} \pmod p$	1
The '''[[Definition:Partial Subtraction|cut-off subtraction]]''' function, defined as: :$\forall \tuple {n, m} \in \N^2: n \mathop {\dot -} m = \begin{cases} 0 & : n < m \\ n - m & : n \ge m \end{cases}$ is [[Definition:Primitive Recursive Function|primitive recursive]].	1
:$\set {\neg, \implies}$: [[Definition:Logical Not|Not]] and [[Definition:Conditional|Implies]]	1
:$(1): \quad$ ''If {{AuthorRef|Socrates}} is a man then {{AuthorRef|Socrates}} is mortal.'' :$(2): \quad$ ''{{AuthorRef|Socrates}} is a man.'' :$(3): \quad$ ''Therefore {{AuthorRef|Socrates}} is mortal.''	1
By definition, a [[Definition:Finite Propositional Tableau|finite propositional tableau]] $T$ is formed by applying the [[Definition:Tableau Extension Rules|tableau extension rules]] a finite number of times. Each [[Definition:Tableau Extension Rules|tableau extension rule]] extends $T$ finitely. Therefore $T$ is a [[Definition:Finite Tree|finite tree]]. The result follows from [[Branch of Finite Tree is Finite]]. {{qed}} [[Category:Propositional Tableaus]] gg8rbya0gos7zkbxsgvc3m619tat6y7	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] on the {{LHS}} match those for $p$ on the {{RHS}} for all [[Definition:Boolean Interpretation|boolean interpretations]]: $\begin{array}{|ccccc||c|} \hline (p & \iff & q) & \iff & q & p \\ \hline F & T & F & F & F & F \\ F & F & T & F & T & F \\ T & F & F & T & F & T \\ T & T & T & T & T & T \\ \hline \end{array}$ {{qed}} [[Category:Biconditional]] 5ybdy25cskm1eyv6h2mol5sojt7fmiv	1
:$p \land \neg q \dashv \vdash \neg \left({p \implies q}\right)$	1
Let $G$ be a [[Definition:Standard Generator Matrix for Linear Code|(standard) generator matrix]] for a [[Definition:Linear Code|linear code]]. The following methods can be used to generate a [[Definition:Linear Code|linear code]] from $G$:	1
=== [[Rule of Distribution/Conjunction Distributes over Disjunction/Left Distributive|Conjunction is Left Distributive over Disjunction]] === {{:Rule of Distribution/Conjunction Distributes over Disjunction/Left Distributive}} === [[Rule of Distribution/Conjunction Distributes over Disjunction/Right Distributive|Conjunction is Right Distributive over Disjunction]] === {{:Rule of Distribution/Conjunction Distributes over Disjunction/Right Distributive}}	1
Let $A, B \subseteq \N$ be [[Definition:Subset|subsets]] of the [[Definition:Natural Numbers|set of natural numbers]] $\N$. Let $A$ and $B$ both be [[Definition:Primitive Recursive Set|primitive recursive]]. Then $A \cup B$, the [[Definition:Set Union|union]] of $A$ and $B$, is [[Definition:Primitive Recursive Set|primitive recursive]].	1
:$p \oplus \top \dashv \vdash \neg p$	1
: $\vdash \left({\neg p \implies q}\right) \iff \left({\neg q \implies p}\right)$	1
We have that [[Natural Numbers are Non-Negative Integers]]. Then we have that [[Integers form Well-Ordered Integral Domain]]. The result follows from [[Induction on Well-Ordered Integral Domain]]. {{qed}}	1
The [[Definition:Inverse Statement|inverse]] of $p \implies q$ is: :$\neg p \implies \neg q$ The [[Definition:Contrapositive Statement|contrapositive]] of $p \implies q$ is: :$\neg q \implies \neg p$ The [[Definition:Converse Statement|converse]] of $\neg q \implies \neg p$ is: :$\neg p \implies \neg q$ The two are seen to be equal. {{qed}} [[Category:Implication]] 3evau7fkxx96gwhtt8hqi0rpefw4w1z	1
{{BeginTableau|\vdash p \iff \left({p \lor q}\right) \land \left({p \lor \neg q}\right)}} {{Assumption|1|p}} {{Addition|2|1|p \lor q|1|1}} {{Addition|3|1|p \lor \neg q|1|2}} {{Conjunction|4|1|\left({p \lor q}\right) \land \left({p \lor \neg q}\right)|2|3}} {{Implication|5||p \implies \left({p \lor q}\right) \land \left({p \lor \neg q}\right)|1|4}} {{Assumption|6|\left({p \lor q}\right) \land \left({p \lor \neg q}\right)}} {{SequentIntro|7|6|p \lor \left({q \land \neg q}\right)|6|[[Disjunction Distributes over Conjunction]]}} {{Assumption|8|p}} {{TheoremIntro|9|\neg \left({q \land \neg q}\right)|[[Principle of Non-Contradiction/Sequent Form/Formulation 2|Principle of Non-Contradiction: Formulation 2]]}} {{ModusTollendoPonens|10|6|p|7|9|2}} {{ProofByCases|11|6|p|6|8|8|9|10}} {{Implication|12||\left({p \lor q}\right) \land \left({p \lor \neg q}\right) \implies p|6|11}} {{BiconditionalIntro|13||p \iff \left({p \lor q}\right) \land \left({p \lor \neg q}\right)|5|12}} {{EndTableau}} {{qed}}	1
==== [[Non-Equivalence as Disjunction of Conjunctions/Formulation 1|Formulation 1]] ==== {{:Non-Equivalence as Disjunction of Conjunctions/Formulation 1}} ==== [[Non-Equivalence as Disjunction of Conjunctions/Formulation 2|Formulation 2]] ==== {{:Non-Equivalence as Disjunction of Conjunctions/Formulation 2}}	1
Let $S$ be a [[Definition:String|string]], and let $T$ be an [[Definition:Initial Part|initial part]] of $S$. Then $T$ is a [[Definition:Substring|substring]] of $S$.	1
=== [[Definition:Truth Value/Aristotelian Logic|Aristotelian Logic]] === {{:Definition:Truth Value/Aristotelian Logic}} {{expand|Other logic types}}	1
:$\neg p \lor \neg q \dashv \vdash \neg \paren {p \land q}$	1
{{BeginTableau|p \lor \paren {p \land q} \vdash p}} {{Premise|1|p \lor \paren {p \land q} }} {{Assumption|2|p}} {{Assumption|3|p \land q}} {{Simplification|4|3|p|3|1}} {{ProofByCases|5|1|p|1|2|2|3|4}} {{EndTableau}} {{qed}}	1
{{begin-eqn}} {{eqn | l = p \oplus q | o = \dashv \vdash | r = \paren {p \lor q} \land \neg \paren {p \land q} | c = {{Defof|Exclusive Or}} }} {{eqn | o = \dashv \vdash | r = \paren {p \lor q} \land \paren {\neg p \lor \neg q} | c = [[De Morgan's Laws (Logic)/Disjunction of Negations|De Morgan's Laws: Disjunction of Negations]] }} {{end-eqn}} {{qed}}	1
By the [[Definition:Definitional Abbreviation|definitional abbreviation]] for the [[Definition:Conditional|conditional]]: :$\mathbf A \implies \mathbf B =_{\text{def}} \neg \mathbf A \lor \mathbf B$ the [[Rule of Idempotence/Disjunction/Formulation 2/Reverse Implication|Rule of Idempotence]] can be written as: : $\neg \left({p \lor p}\right) \lor p$ This evaluates as follows: :$\begin{array}{|cccc|c|c|} \hline \neg & (p & \lor & p) & \lor & p \\ \hline 1 & 0 & 0 & 0 & 0 & 0 \\ 0 & 1 & 1 & 1 & 0 & 1 \\ 0 & 2 & 2 & 2 & 0 & 2 \\ 2 & 3 & 3 & 3 & 0 & 3 \\ \hline \end{array}$ {{qed}} [[Category:Formal Semantics]] 01yq3v78ftnoxwrey60d9xk091x9ahx	1
The proof will proceed by the [[Principle of Finite Induction]] on $\N \setminus \set 0$ === Basis for the Induction === :$\map s 0 = 1$ So 1 is the successor of 0. This is our [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]] === Induction Hypothesis === This is our [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$\exists m \in \N: \map s m = k$ Then we need to show: :$\exists m' \in \N: \map s m' = k+1$ === Induction Step === This is our [[Principle of Mathematical Induction#Induction Step|induction step]]: {{begin-eqn}} {{eqn | o = | r = \exists m \in \N: \map s m = k | c = }} {{eqn | o = \implies | r = k \in \N | c = {{PeanoAxiom|2}} }} {{eqn | o = \implies | r = \map s k = k+1 | c = }} {{eqn | o = \implies | r = \exists m' \in \N: \map s m' = k+1 }} {{end-eqn}} {{qed}} [[Category:Proofs by Induction]] [[Category:Natural Numbers]] irytocb7177a83bgadx53xcg59gkyxy	1
:$p \land \left({q \land r}\right) \dashv \vdash \left({p \land q}\right) \land r$	1
From the [[Law of Excluded Middle]] follows [[Peirce's Law]]: :$\left({p \lor \neg p}\right) \vdash \left({\left({p \implies q}\right) \implies p}\right) \implies p$	1
:$\vdash \left({\left({p \lor q}\right) \land \left({p \lor r}\right)}\right) \implies \left({p \lor \left({q \land r}\right)}\right)$	1
:$p, \neg p \vdash \bot$	1
: $q \implies \neg p \vdash p \implies \neg q$	1
Let $f$ be a [[Definition:Polynomial over Field|polynomial in one variable]] of [[Definition:Degree of Polynomial|degree]] $n$ over $\Z_p$ for some [[Definition:Prime Number|prime]] $p$. Then $f$ has at most $n$ [[Definition:Root of Polynomial|roots]] in $\Z_p$.	1
Let $Q$ be a [[Definition:Valid Argument|valid]] [[Definition:Categorical Syllogism|categorical syllogism]] in [[Definition:Third Figure of Categorical Syllogism|Figure $\text {III}$]]. Then it is a [[Definition:Necessary Condition|necessary condition]] that: :The [[Definition:Conclusion of Syllogism|conclusion]] of $Q$ be a [[Definition:Particular Categorical Statement|particular categorical statement]] and: :If the [[Definition:Conclusion of Syllogism|conclusion]] of $Q$ be a [[Definition:Negative Categorical Statement|negative categorical statement]], then so is the [[Definition:Major Premise of Syllogism|major premise]] of $Q$.	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc||ccc|} \hline p & \land & q & q & \land & p \\ \hline F & F & F & F & F & F \\ F & F & T & T & F & F \\ T & F & F & F & F & T \\ T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
{{BeginTableau|p \downarrow p \vdash \neg p}} {{Premise|1|p \downarrow p}} {{SequentIntro|2|1|\neg \left({p \lor p}\right)|1|Definition of [[Definition:Logical NOR|Logical NOR]]}} {{Idempotence|3|1|\neg p|2|Disjunction}} {{EndTableau}} {{BeginTableau|\neg p \vdash p \downarrow p}} {{Premise|1|\neg p}} {{Idempotence|2|1|\neg \left({p \lor p}\right)|1|Disjunction}} {{SequentIntro|3|1|p \downarrow p|2|Definition of [[Definition:Logical NOR|Logical NOR]]}} {{EndTableau}} {{qed}}	1
Of the $256$ different types of [[Definition:Categorical Syllogism|categorical syllogism]], all but $48$ can immediately be identified as [[Definition:Invalid Argument|invalid]] by consideration of the [[Rules of Quantity]] and the [[Rules of Quality]].	1
{{BeginTableau|\vdash \left({p \lor \left({q \lor r}\right)}\right) \implies \left({\left({p \lor q}\right) \lor r}\right)|[[Definition:Hilbert Proof System/Instance 2|Instance 2 of the Hilbert-style systems]]}} {{TableauLine |n = 1 |f = \paren{ \paren{ p \lor q } \lor r } \implies \paren{ p \lor \paren{ q \lor r } } |rlnk = Rule of Association/Disjunction/Formulation 2/Reverse Implication |rtxt = Rule of Association: Reverse Implication }} {{TableauLine |n = 2 |f = \paren{ q \lor r } \implies \paren{ r \lor q } |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Axiom $A3$ |c = $q \,/\, p, r \,/\, q$ }} {{TableauLine |n = 3 |f = \paren{ \paren{ q \lor r } \implies \paren{ r \lor q } } \implies \paren{ \paren{ p \lor \paren{ q \lor r } } \implies \paren{ p \lor \paren{ r \lor q } } } |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Axiom $A4$ |c = $\paren{ q \lor r } \,/\, q, \paren{ r \lor q } \,/\, r$ }} {{TableauLine |n = 4 |f = \paren{ p \lor \paren{ q \lor r } } \implies \paren{ p \lor \paren{ r \lor q } } |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 3$ |dep = 2,3 }} {{TableauLine |n = 5 |f = \paren{ \paren{ p \lor q } \lor r } \implies \paren{ p \lor \paren{ r \lor q } } |rlnk = Hypothetical Syllogism/Formulation 1/Proof 3 |rtxt = Hypothetical Syllogism |dep = 1,4 }} {{TableauLine |n = 6 |f = \paren{ p \lor \paren{ r \lor q } } \implies \paren{ \paren{ r \lor q } \lor p } |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Axiom $A3$ |c = $\paren{ r \lor q } \,/\, q$ }} {{TableauLine |n = 7 |f = \paren{ \paren{ p \lor q } \lor r } \implies \paren{ \paren{ r \lor q } \lor p } |rlnk = Hypothetical Syllogism/Formulation 1/Proof 3 |rtxt = Hypothetical Syllogism |dep = 5,6 }} {{TableauLine |n = 8 |f = \paren{ r \lor \paren{ p \lor q } } \implies \paren{ \paren{ p \lor q } \lor r } |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Axiom $A3$ |c = $r \,/\, p, \paren{ p \lor q } \,/\, q$ }} {{TableauLine |n = 9 |f = \paren{ r \lor \paren{ p \lor q } } \implies \paren{ \paren{ r \lor q } \lor p } |rlnk = Hypothetical Syllogism/Formulation 1/Proof 3 |rtxt = Hypothetical Syllogism |dep = 7,8 }} {{TableauLine |n = 10 |f = \paren{ q \lor p } \implies \paren{ p \lor q } |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Axiom $A3$ |c = $p/q, q/p$ }} {{TableauLine |n = 11 |f = \paren{ \paren{ q \lor p } \implies \paren{ p \lor q } } \implies \paren{ \paren{ r \lor \paren{ q \lor p } } \implies \paren{ r \lor \paren{ p \lor q } } } |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Axiom $A4$ |c = $r \,/\, p, \paren{ q \lor p } \,/\, q, \paren{ p \lor q } \,/\, r$ }} {{TableauLine |n = 12 |f = \paren{ r \lor \paren{ q \lor p } } \implies \paren{ r \lor \paren{ p \lor q } } |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 3$ |dep = 10,11 }} {{TableauLine |n = 13 |f = \paren{ r \lor \paren{ q \lor p } } \implies \paren{ \paren{ r \lor q } \lor p } |rlnk = Hypothetical Syllogism/Formulation 1/Proof 3 |rtxt = Hypothetical Syllogism |dep = 9,12 }} {{TableauLine |n = 14 |f = \paren{ p \lor \paren{ q \lor r } } \implies \paren{ \paren{ p \lor q } \lor r } |rlnk = Definition:Hilbert Proof System/Instance 2 |rtxt = Rule $RST \, 1$ |dep = 13 |c = $r/p, p/r$ }} {{EndTableau}} {{qed}}	1
Let $S_n$ denote the $n$th [[Definition:Fibonacci String|Fibonacci string]]. Let $F_n$ denote the $n$th [[Definition:Fibonacci Number|Fibonacci number]]. Let $k \in \Z$ such that $k \le F_n$. Then the $k$th letter of $S_n$ is $\text b$ {{iff}}: : $\left\lfloor{\left({k + 1}\right) \phi^{-1} }\right\rfloor - \left\lfloor{k \phi^{-1} }\right\rfloor = 1$ where: : $\left\lfloor{\, \cdot \,}\right\rfloor$ denotes the [[Definition:Floor Function|floor function]] : $\phi$ denotes the [[Definition:Golden Mean|golden mean]].	1
Denote with $\bar{\mathbf A}$ and $\bar U$ the [[Definition:Logical Complement|logical complement]] of a [[Definition:WFF of Propositional Logic|WFF]] $\mathbf A$ and [[Definition:Set|set]] $U$, respectively. === Necessary Condition === We aim to prove this result using the [[Second Principle of Mathematical Induction]], applied to the minimal length of a [[Definition:Formal Proof|formal proof]] of $U$. Suppose first that $U$ is an [[Definition:Axiom (Formal Systems)|axiom]] of $\mathscr G$. Then $U$ contains a [[Definition:Complementary Pair|complementary pair]] of [[Definition:Literal|literals]]. Hence, so does $\bar U$, by definition of [[Definition:Logical Complement|logical complement]]. Therefore, the [[Definition:Semantic Tableau|semantic tableau]] comprising only a [[Definition:Root Node|root node]] labeled $\bar U$ is [[Definition:Closed Tableau|closed]]. Next, suppose that the last step in proving $U$ was an instance of the [[Definition:Gentzen Proof System/Instance 1/Alpha-Rule|$\alpha$-rule]]. That is, for some [[Definition:Alpha-Formula|$\alpha$-formula]] $\mathbf A$ and corresponding $\mathbf A_1, \mathbf A_2$: :$U = U_1 \cup U_2 \cup \left\{{\mathbf A}\right\}$ where $U_1 \cup \left\{{\mathbf A_1}\right\}$ and $U_2 \cup \left\{{\mathbf A_2}\right\}$ are [[Definition:Theorem (Formal Systems)|$\mathscr G$-theorems]]. By induction hypothesis, the [[Definition:Logical Complement|logical complements]]: :$\bar U_1 \cup \left\{{\bar{\mathbf A}_1}\right\}$ :$\bar U_2 \cup \left\{{\bar{\mathbf A}_@}\right\}$ of these [[Definition:Theorem (Formal Systems)|theorems]] have [[Definition:Closed Tableau|closed tableaus]]. From the [[Soundness Theorem for Semantic Tableaus]], it follows that these sets are [[Definition:Unsatisfiable (Boolean Interpretations)|unsatisfiable]]. Now by [[Superset of Unsatisfiable Set is Unsatisfiable]], so are: :$\bar U' := \bar U_1 \cup \bar U_2 \cup \left\{{\bar{\mathbf A}_1}\right\}$ :$\bar U'' := \bar U_1 \cup \bar U_2 \cup \left\{{\bar{\mathbf A}_1}\right\}$ By the [[Completeness Theorem for Semantic Tableaus]], these have [[Definition:Closed Tableau|closed tableaus]]. Since $\mathbf A$ is an [[Definition:Alpha-Formula|$\alpha$-formula]], it is [[Definition:Semantic Equivalence (Boolean Interpretations)|equivalent]] to $\mathbf A_1 \land \mathbf A_2$. By [[De Morgan's Laws (Logic)/Disjunction of Negations|De Morgan's Laws]], it follows that: :$\bar{\mathbf A}$ is [[Definition:Semantic Equivalence (Boolean Interpretations)|equivalent]] to $\bar{\mathbf A}_1 \lor \bar{\mathbf A}_2$. Therefore, $\bar{\mathbf A}$ is a [[Definition:Beta-Formula|$\beta$-formula]], and $\bar{\mathbf A}_1, \bar{\mathbf A}_2$ correspond to it as in the [[Definition:Table of Beta-Formulas|table of $\beta$-formulas]]. This allows the [[Semantic Tableau Algorithm]] to expand a [[Definition:Leaf Node|leaf]] labeled $\bar U$ into two leaves labeled $\bar U'$ and $\bar U''$. Because $\bar U'$ and $\bar U''$ have [[Definition:Closed Tableau|closed tableaus]], so does $\bar U$. Finally, suppose that the last step in proving $U$ was an instance of the [[Definition:Gentzen Proof System/Instance 1/Beta-Rule|$\beta$-rule]]. That is, for some [[Definition:Beta-Formula|$\beta$-formula]] $\mathbf B$ and corresponding $\mathbf B_1, \mathbf B_2$: :$U = U_1 \cup \left\{{\mathbf B}\right\}$ where $U' := U_1 \cup \left\{{\mathbf B_1, \mathbf B_2}\right\}$ is a [[Definition:Theorem (Formal Systems)|$\mathscr G$-theorem]]. By induction hypothesis, the [[Definition:Logical Complement|logical complement]]: :$\bar U' = \bar U_1 \cup \left\{{\bar{\mathbf B}_1, \bar{\mathbf B}_2}\right\}$ of this [[Definition:Theorem (Formal Systems)|$\mathscr G$-theorem]] has a [[Definition:Closed Tableau|closed tableau]]. Since $\mathbf B$ is a [[Definition:Beta-Formula|$\beta$-formula]], it is [[Definition:Semantic Equivalence (Boolean Interpretations)|equivalent]] to $\mathbf B_1 \lor \mathbf B_2$. By [[De Morgan's Laws (Logic)/Conjunction of Negations|De Morgan's Laws]], it follows that: :$\bar{\mathbf B}$ is [[Definition:Semantic Equivalence (Boolean Interpretations)|equivalent]] to $\bar{\mathbf B}_1 \land \bar{\mathbf B}_2$. Therefore, $\bar{\mathbf B}$ is an [[Definition:Alpha-Formula|$\alpha$-formula]], and $\bar{\mathbf B}_1, \bar{\mathbf B}_2$ correspond to it as in the [[Definition:Table of Alpha-Formulas|table of $\alpha$-formulas]]. This allows the [[Semantic Tableau Algorithm]] to expand a [[Definition:Leaf Node|leaf]] labeled $\bar U$ into a leaf labeled $\bar U'$. Because $\bar U'$ has a [[Definition:Closed Tableau|closed tableau]], so does $\bar U$. The result follows by the [[Second Principle of Mathematical Induction]]. {{qed|lemma}} === Sufficient Condition === Let $T$ be a [[Definition:Closed Tableau|closed tableau]] for $\bar U$. We prove that $U$ is a [[Definition:Theorem (Formal Systems)|$\mathscr G$-theorem]] by the [[Second Principle of Mathematical Induction]], applied to the number of [[Definition:Node (Graph Theory)|nodes]] of $T$. Suppose $T$ has only one [[Definition:Node (Graph Theory)|node]]. Then $\bar U$ has to contain a [[Definition:Complementary Pair|complementary pair]] of [[Definition:Literal|literals]] for $T$ to be [[Definition:Closed Tableau|closed]]. But then $U$ also contains a [[Definition:Complementary Pair|complementary pair]]. Hence, it is an [[Definition:Axiom (Formal Systems)|axiom]] of $\mathscr G$. If $T$ has more than one [[Definition:Node (Graph Theory)|node]], the first iteration of the [[Semantic Tableau Algorithm]] must have selected either an [[Definition:Alpha-Formula|$\alpha$-formula]] $\mathbf A$ or a [[Definition:Beta-Formula|$\beta$-formula]] $\mathbf B$ from $\bar U$. First the case that an [[Definition:Alpha-Formula|$\alpha$-formula]] $\mathbf A$ was selected. Define, for convenience, $\bar U' = \bar U \setminus \left\{{\mathbf A}\right\}$. Then the rest of $T$ is a [[Definition:Semantic Tableau|semantic tableau]] for $\bar U' \cup \left\{{\mathbf A_1, \mathbf A_2}\right\}$. This [[Definition:Semantic Tableau|tableau]] has fewer [[Definition:Node (Graph Theory)|nodes]] than $T$. For $T$ to be [[Definition:Closed Tableau|closed]], this [[Definition:Subtree|subtree]] must also be a [[Definition:Closed Tableau|closed tableau]]. By induction hypothesis, this means that $U' \cup \left\{{\bar{\mathbf A}_1, \bar{\mathbf A}_2}\right\}$ is a [[Definition:Theorem (Formal Systems)|$\mathscr G$-theorem]]. Now, since $\mathbf A$ is an [[Definition:Alpha-Formula|$\alpha$-formula]], it is [[Definition:Semantic Equivalence (Boolean Interpretations)|equivalent]] to $\mathbf A_1 \land \mathbf A_2$. Hence by [[De Morgan's Laws (Logic)/Disjunction of Negations|De Morgan's Laws]], $\bar{\mathbf A}$ is [[Definition:Semantic Equivalence (Boolean Interpretations)|equivalent]] to $\bar{\mathbf A}_1 \lor \bar{\mathbf A}_2$. That is, $\bar{\mathbf A}$ is a [[Definition:Beta-Formula|$\beta$-formula]], so that the [[Definition:Gentzen Proof System/Instance 1/Beta-Rule|$\beta$-rule]] may be applied to it. Hence, $U = U' \cup \left\{{\bar{\mathbf A}}\right\}$ is a [[Definition:Theorem (Formal Systems)|$\mathscr G$-theorem]], as desired. Now the case that a [[Definition:Beta-Formula|$\beta$-formula]] $\mathbf B$ was selected. Define, for convenience, $\bar U' = \bar U \setminus \left\{{\mathbf B}\right\}$. Then the rest of our [[Definition:Closed Tableau|closed tableau]] $T$ comprises two [[Definition:Semantic Tableau|semantic tableaus]] for $\bar U' \cup \left\{{\mathbf B_1}\right\}$ and $\bar U' \cup \left\{{\mathbf B_2}\right\}$, respectively. Each of these has fewer [[Definition:Node (Graph Theory)|nodes]] than $T$. For $T$ to be [[Definition:Closed Tableau|closed]], these [[Definition:Subtree|subtrees]] must also be [[Definition:Closed Tableau|closed tableaus]]. By induction hypothesis, this means that $U' \cup \left\{{\bar{\mathbf B}_1}\right\}$ and $U' \cup \left\{{\bar{\mathbf B}_2}\right\}$ are [[Definition:Theorem (Formal Systems)|$\mathscr G$-theorems]]. Now, since $\mathbf B$ is a [[Definition:Beta-Formula|$\beta$-formula]], it is [[Definition:Semantic Equivalence (Boolean Interpretations)|equivalent]] to $\mathbf B_1 \lor \mathbf B_2$. Hence by [[De Morgan's Laws (Logic)/Conjunction of Negations|De Morgan's Laws]], $\bar{\mathbf B}$ is [[Definition:Semantic Equivalence (Boolean Interpretations)|equivalent]] to $\bar{\mathbf B}_1 \land \bar{\mathbf B}_2$. That is, $\bar{\mathbf B}$ is an [[Definition:Alpha-Formula|$\alpha$-formula]], so that the [[Definition:Gentzen Proof System/Instance 1/Alpha-Rule|$\alpha$-rule]] may be applied to it. Hence, $U = U' \cup \left\{{\bar{\mathbf B}}\right\}$ is a [[Definition:Theorem (Formal Systems)|$\mathscr G$-theorem]], as desired. The result now follows from the [[Second Principle of Mathematical Induction]]. {{qed}}	1
:$\neg \paren {p \land q}, p \vdash \neg q$	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] is [[Definition:True|true]] for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|cccc|c|cccc|} \hline p & \land & \neg & q & \iff & \neg & (p & \implies & q) \\ \hline F & F & T & F & T & F & F & T & F \\ F & F & F & T & T & F & F & T & T \\ T & T & T & F & T & T & T & F & F \\ T & F & F & T & T & F & T & T & T \\ \hline \end{array}$ {{qed}}	1
We apply the [[Method of Truth Tables]]. $\begin{array}{|c|c||ccc|} \hline p & q & p & \implies & q\\ \hline F & F & F & T & F \\ F & T & F & T & T \\ T & F & T & F & F \\ T & T & T & T & T \\ \hline \end{array}$ As can be seen by inspection, only when $p$ is [[Definition:True|true]] and $q$ is [[Definition:False|false]], then so is $p \implies q$ also [[Definition:False|false]]. {{qed}}	1
Let $\mathcal L$ be a [[Definition:Logical Language|logical language]]. Let $\mathscr M$ be a [[Definition:Formal Semantics|formal semantics]] for $\mathcal L$. Let $\mathscr P$ be a [[Definition:Proof System|proof system]] for $\mathcal L$. Suppose that $\mathscr P$ is [[Definition:Sound Proof System|sound]] for $\mathscr M$. Then $\mathscr P$ is [[Definition:Consistent Proof System|consistent]].	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, in all cases the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc||ccccccc|} \hline p & \iff & q & (p & \lor & q) & \implies & (p & \land & q) \\ \hline F & T & F & F & F & F & T & F & F & F \\ F & F & T & F & T & T & F & F & F & T \\ T & F & F & T & T & F & F & T & F & F \\ T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
There exist non-standard models of arithmetic.	1
{{begin-eqn}} {{eqn | l = a | r = b | c = }} {{eqn | ll= \vdash | l = \map P a | o = \iff | r = \map P b | c = [[Axiom:Leibniz's Law|Leibniz's law]] }} {{eqn | l = b | r = c | c = }} {{eqn | ll= \vdash | l = \map P b | o = \iff | r = \map P c | c = [[Axiom:Leibniz's Law|Leibniz's law]] }} {{eqn | ll= \vdash | l = \map P a | o = \iff | r = \map P c | c = [[Biconditional is Transitive]] }} {{eqn | ll= \vdash | l = a | r = c | c = [[Axiom:Leibniz's Law|Leibniz's law]] }} {{end-eqn}} {{qed}}	1
{{BeginTableau|\left({p \land q}\right) \lor \left({\neg p \land \neg q}\right) \vdash p \iff q}} {{Premise|1|\left({p \land q}\right) \lor \left({\neg p \land \neg q}\right)}} {{Assumption|2|p \land q}} {{Assumption|3|p}} {{Simplification|4|2|q|2|2}} {{Implication|5|2|p \implies q|3|4}} {{Assumption|6|q}} {{Simplification|7|2|p|2|1}} {{Implication|8|2|q \implies p|6|7}} {{BiconditionalIntro|9|2|p \iff q|5|8}} {{Assumption|10|\neg p \land \neg q}} {{Assumption|11|\neg p}} {{Simplification|12|10|\neg q|10|2}} {{Implication|13|10|\neg p \implies \neg q|11|12}} {{SequentIntro|14|10|q \implies p|13|[[Rule of Transposition]]}} {{Assumption|15|\neg q}} {{Simplification|16|10|\neg p|10|1}} {{Implication|17|10|\neg q \implies \neg p|15|16}} {{SequentIntro|18|10|p \implies q|17|[[Rule of Transposition]]}} {{BiconditionalIntro|19|10|p \iff q|18|14}} {{ProofByCases|20|1|p \iff q|1|2|9|10|19}} {{EndTableau}} {{qed}} [[Category:Biconditional as Disjunction of Conjunctions]] kpkzs6086yvdup4ehfnuooz56hz7783	1
:$\vdash \paren {p \land q} \iff \paren {\neg \paren {p \implies \neg q} }$	1
Let $T$ be the [[Definition:Set|set]] of all [[Definition:1-Based Natural Numbers|$1$-based natural numbers]] not in $S$: :$T = \N_{>0} \setminus S$ {{AimForCont}} $T$ is [[Definition:Non-Empty Set|non-empty]]. From the [[Well-Ordering Principle]], $T$ has a [[Definition:Smallest Element|smallest element]]. Let this [[Definition:Smallest Element|smallest element]] be denoted $a$. We have been given that $1 \in S$. So: :$a > 1$ and so: :$0 < a - 1 < a$ As $a$ is the [[Definition:Smallest Element|smallest element]] of $T$, it follows that: :$a - 1 \notin T$ That means $a - 1 \in S$. But then [[Definition:By Hypothesis|by hypothesis]]: :$\paren {a - 1} + 1 \in S$ But: :$\paren {a - 1} + 1 = a$ and so $a \notin T$. This [[Definition:Contradiction|contradicts]] our assumption that $a \in T$. It follows by [[Proof by Contradiction]] that $T$ has no such [[Definition:Smallest Element|smallest element]]. Hence it follows that $T$ can have no [[Definition:Element|elements]] at all. That is: :$\N_{>0} \setminus S = \O$ That is: :$S = \N_{>0}$	1
{{handwaving}} By the [[Definition:Definitional Abbreviation|definitional abbreviation]] for the [[Definition:Conditional|conditional]]: :$\mathbf A \implies \mathbf B =_{\text{def}} \neg \mathbf A \lor \mathbf B$ the [[Rule of Addition/Sequent Form/Formulation 2/Form 2|Rule of Addition]] can be written as: : $\neg q \lor \left({p \lor q}\right)$ This evaluates as follows: :$\begin{array}{|cc|c|ccc|} \hline \neg & q & \lor & (p & \lor & q) \\ \hline 1 & 0 & 0 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 & 0 & 1 \\ 0 & 2 & 0 & 0 & 0 & 2 \\ 2 & 3 & 0 & 0 & 0 & 3 \\ 1 & 0 & 0 & 1 & 0 & 0 \\ 0 & 1 & 0 & 1 & 1 & 1 \\ 0 & 2 & 0 & 1 & 2 & 2 \\ 2 & 3 & 0 & 1 & 3 & 3 \\ 1 & 0 & 0 & 2 & 0 & 0 \\ 0 & 1 & 0 & 2 & 2 & 1 \\ 0 & 2 & 0 & 2 & 2 & 2 \\ 2 & 3 & 0 & 2 & 0 & 3 \\ 1 & 0 & 0 & 3 & 0 & 0 \\ 0 & 1 & 0 & 3 & 3 & 1 \\ 0 & 2 & 0 & 3 & 3 & 2 \\ 2 & 3 & 0 & 3 & 3 & 3 \\ \hline \end{array}$ {{qed}} [[Category:Formal Semantics]] 5hf2kbaogy667algmc2jorctor673g1	1
We apply the [[Method of Truth Tables]]. $\begin{array}{|c|c||ccc|} \hline p & q & p & \lor & q\\ \hline F & F & F & F & F \\ F & T & F & T & T \\ T & F & T & T & F \\ T & T & T & T & T \\ \hline \end{array}$ As can be seen, whenever either $p$ or $q$ (or both) are [[Definition:True|true]], then so is $p \lor q$. {{qed}}	1
$1$ is defined as $s \left({0}\right)$ and $2$ as $s \left({s \left({0}\right)}\right)$. Therefore the statement to be proven becomes: :$s \left({0}\right) + s \left({0}\right) = s \left({s \left({0}\right)}\right)$ Thus: {{begin-eqn}} {{eqn | ll= \forall n \in P: | l = m + s \left({n}\right) | r = s \left({m + n}\right) | c = Definition of [[Definition:Addition/Peano Structure|Addition]] }} {{eqn |lll= \implies | l = m + s \left({0}\right) | r = s \left({m+0}\right) }} {{eqn |lll= \implies | ll= \forall m \in P: | l = m + s \left({0}\right) | r = s \left({m + 0}\right) }} {{eqn | n = 1 |lll= \implies | l = s \left({0}\right) + s \left({0}\right) | r = s \left({s \left({0}\right) + 0}\right) }} {{eqn | ll= \forall m \in P: | l = m + 0 | r = m | c = Definition of [[Definition:Addition/Peano Structure|Addition]] }} {{eqn | n = 2 |lll= \implies | l = s \left({0}\right) + 0 | r = s \left({0}\right) }} {{eqn | l = s \left({s \left({0}\right) + 0}\right) | r = s \left({s \left({0}\right)}\right) | c = taking the successor on both sides of $(2)$ }} {{eqn | n = 3 |lll= \implies | l = s \left({0}\right) + s \left({0}\right) | r = s \left({s \left({0}\right) + 0}\right) | c = from $(1)$ }} {{eqn | r = s \left({s \left({0}\right)}\right) | c = from $(2)$ }} {{end-eqn}} {{qed}}	1
:$\neg \left({p \land \neg q}\right) \vdash p \implies q$	1
There is no [[Definition:Algorithm|algorithm]] to determine whether a given [[Definition:Polynomial|polynomial]] [[Definition: Diophantine Equation|Diophantine equation]] with [[Definition:Integer|integer]] [[Definition:Coefficient|coefficients]] has an [[Definition:Integer|integer]] solution.	1
Let $\mathbf A$ be a [[Definition:WFF of Propositional Logic|WFF of propositional logic]]. Let $T$ be a [[Definition:Completed Tableau|completed semantic tableau]] for $\mathbf A$. Then $\mathbf A$ is [[Definition:Unsatisfiable (Boolean Interpretations)|unsatisfiable]] {{iff}} $T$ is [[Definition:Closed Tableau|closed]].	1
Because $a_n = O(b_n)$, there exists $M\geq0$ and $n_0 \in\N$ such that $|a_n| \leq M \cdot |b_n|$ for $n\geq n_0$. Because $n_k$ [[Definition:Divergent Sequence|diverges]], there exists $k_0\in\N$ such that $n_k\geq n_0$ for $k\geq k_0$. Then $|a_{n_k}| \leq M\cdot |b_{n_k}|$ for $k\geq k_0$. Thus $a_{n_k} = O(b_{n_k})$. {{qed}} [[Category:Asymptotic Notation]] q917p4cyyh16q4kjx1g18nd1hkq82oy	1
Let the [[Double Negation Elimination|Law of Double Negation Elimination]] be supposed to hold: :$\neg \neg p \vdash p$ Then the [[Law of Excluded Middle]] likewise holds: :$\vdash p \lor \neg p$	1
Any [[Definition:URM Program|URM program]] can be assigned a unique '''code number'''.	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc||ccccccc|} \hline (q & \land & r) & \lor & p & (q & \lor & p) & \land & (r & \lor & p) \\ \hline F & F & F & F & F & F & F & F & F & F & F & F \\ F & F & F & T & T & F & T & T & T & F & T & T \\ F & F & T & F & F & F & F & F & F & T & T & F \\ F & F & T & T & T & F & T & T & T & T & T & T \\ T & F & F & F & F & T & T & F & F & F & F & F \\ T & F & F & T & T & T & T & T & T & F & T & T \\ T & T & T & T & F & T & T & F & T & T & T & F \\ T & T & T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
:$\set {\neg, \lor}$: [[Definition:Logical Not|Not]] and [[Definition:Disjunction|Or]]	1
In a [[Definition:Truth Table|truth table]], one [[Definition:Row of Truth Table|row]] is needed for each [[Definition:Boolean Interpretation|boolean interpretation]] of $P$. Let $S$ be the [[Definition:Set|set]] of different [[Definition:Letter|letters]] used in $P$. The result then follows from applying [[Number of Boolean Interpretations for Finite Set of Variables]] to $S$. {{qed}}	1
Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \N_{>0}$, let $P \left({n}\right)$ be the [[Definition:Proposition|proposition]]: : $\displaystyle \exists w, x, y, z \in \Z: \prod_{j \mathop = 1}^n \left({a_j^2 + b_j^2 + c_j^2 + d_j^2}\right) = w^2 + x^2 + y^2 + z^2$ $P \left({1}\right)$ is true, as this just says: : $\exists w, x, y, z \in \Z: a^2 + b^2 + c^2 + d^2 = w^2 + x^2 + y^2 + z^2$ which is trivially true. === Basis for the Induction === $P \left({2}\right)$ is the case: : $\exists w, x, y, z \in \Z: \left({a_1^2 + b_1^2 + c_1^2 + d_1^2}\right) \left({a_2^2 + b_2^2 + c_2^2 + d_2^2}\right) = w^2 + x^2 + y^2 + z^2$ which follows from [[Product of Sums of Four Squares]]. This is our [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $P \left({k}\right)$ is true, where $k \ge 2$, then it logically follows that $P \left({k+1}\right)$ is true. So this is our [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: : $\displaystyle \exists w, x, y, z \in \Z: \prod_{j \mathop = 1}^k \left({a_j^2 + b_j^2 + c_j^2 + d_j^2}\right) = w^2 + x^2 + y^2 + z^2$ Then we need to show that it directly implies: : $\displaystyle \exists w, x, y, z \in \Z: \prod_{j \mathop = 1}^{k+1} \left({a_j^2 + b_j^2 + c_j^2 + d_j^2}\right) = w^2 + x^2 + y^2 + z^2$ === Induction Step === This is our [[Principle of Mathematical Induction#Induction Step|induction step]]: {{begin-eqn}} {{eqn | o = | r = \prod_{j \mathop = 1}^{k+1} \left({a_j^2 + b_j^2 + c_j^2 + d_j^2}\right) | c = }} {{eqn | r = \left({\prod_{j \mathop = 1}^k \left({a_j^2 + b_j^2 + c_j^2 + d_j^2}\right)}\right) \left({a_{k+1}^2 + b_{k+1}^2 + c_{k+1}^2 + d_{k+1}^2}\right) | c = }} {{eqn | r = \left({r^2 + s^2 + t^2 + u^2}\right) \left({a_{k+1}^2 + b_{k+1}^2 + c_{k+1}^2 + d_{k+1}^2}\right) | c = from the [[Product of Sums of Four Squares/Corollary#Induction Hypothesis|induction hypothesis]]: for some $r, s, t, u, \in \Z$ }} {{eqn | r = w^2 + x^2 + y^2 + z^2 | c = from the [[Product of Sums of Four Squares/Corollary#Basis for the Induction|basis for the induction]]: for some $w, x, y, z, \in \Z$ }} {{end-eqn}} So $P \left({k}\right) \implies P \left({k+1}\right)$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: : $\displaystyle \forall n \in \Z_{>0}: \exists w, x, y, z \in \Z: \prod_{j \mathop = 1}^n \left({a_j^2 + b_j^2 + c_j^2 + d_j^2}\right) = w^2 + x^2 + y^2 + z^2$ {{qed}} [[Category:Product of Sums of Four Squares]] [[Category:Proofs by Induction]] mqkxsxvflrnnxqfi8350kswpk0gnpj9	1
An '''equivocation''' is a shift in meaning of an [[Definition:Ambiguous|ambiguous]] term. If an [[Definition:Logical Argument|argument]]'s persuasive force depends on utilizing an '''equivocation''' it is [[Definition:Fallacy|fallacious]]. To make such an argument is to commit the '''fallacy of equivocation'''.	1
Let $\LL$ be a [[Definition:Language of Predicate Logic|language]]. Let $I$ be an infinite set. Let $\UU$ be an [[Definition:Ultrafilter on Set|ultrafilter]] on $I$. Let $\map \phi {v_1, \ldots, v_n}$ be an $\LL$-[[Definition:Language of Predicate Logic/Formal Grammar|formula]]. Let $\MM$ be the [[Definition:Ultraproduct|ultraproduct]]: :$\displaystyle \paren {\prod_{i \mathop \in I} \MM_i} / \UU$ where each $\MM_i$ is an $\LL$-[[Definition:Formal Semantics/Structure|structure]]. Then, for all $m_1 = \paren {m_{1, i} }_\UU, \dots, m_n = \paren {m_{n, i} }_\UU$ in $\MM$: :$\MM \models \map \phi {m_1, \ldots, m_n}$ {{iff}}: :the set $\set {i \in I: \MM_i \models \map \phi {m_{1, i}, \ldots, m_{n, i} } }$ is in $\UU$. In particular, for all $\LL$-[[Definition:Classes of WFFs/Sentence|sentences]] $\phi$, we have that: :$\MM \models \phi$ {{iff}} $\set {i \in I: \MM_i \models \phi}$ is in $\UU$.	1
: $p \implies \left({q \land r}\right) \vdash \left({p \implies q}\right) \land \left({p \implies r}\right)$	1
For each [[Definition:Integer|integer]] $k \ge 1$, there exists a [[Definition:URM Program|URM program]] $P_k$ such that: For each [[Definition:URM Program|URM program]] $P$ there exists a [[Definition:Natural Numbers|natural number]] $e$ such that: For all $\left({n_1, n_2, \ldots, n_k}\right) \in \N^k$, the computation using the program $P_k$ with [[Definition:Unlimited Register Machine#Input|input]] $\left({e, n_1, n_2, \ldots, n_k}\right)$ has the same [[Definition:Unlimited Register Machine#Output|output]] as the computation using the program $P$ with [[Definition:Unlimited Register Machine#Input|input]] $\left({n_1, n_2, \ldots, n_k}\right)$. This function $P_k$ is a '''universal program for URM computations with $k$ inputs'''.	1
Let $T$ be a finitely satisfiable $\mathcal L$-theory. Let $\phi$ be an $\mathcal L$-sentence. Then either $T \cup \left\{ {\phi}\right\}$ or $T \cup \left\{ {\neg \phi}\right\}$ is finitely satisfiable.	1
: $\vdash \left({p \implies \left({q \land r}\right)}\right) \implies \left({\left({p \implies q}\right) \land \left({p \implies r}\right)}\right)$	1
:$\left({p \vdash q}\right) \vdash p \implies q$	1
Suppose $\mathbf H$ does '''not''' have a [[Definition:Model (Boolean Interpretations)|model]]. By the [[Main Lemma of Propositional Tableaus]], $\mathbf H$ has a [[Definition:Tableau Confutation|tableau confutation]] $T$. By [[Tableau Confutation contains Finite Tableau Confutation]], $T$ may be assumed to be [[Definition:Finite Propositional Tableau|finite]]. Hence the set $\mathbf H'$ of all [[Definition:WFF of Propositional Logic|WFFs]] in $\mathbf H$ used somewhere in $T$ is [[Definition:Finite Set|finite]]. Now, let $T'$ be the [[Definition:Labeled Tree for Propositional Logic|labeled tree]] which is the same as $T$ but with root $\mathbf H'$ instead of $\mathbf H$. Then $T'$ is a [[Definition:Tableau Confutation|tableau confutation]] of $\mathbf H'$. By the [[Tableau Confutation implies Unsatisfiable]], $\mathbf H'$ has no [[Definition:Model (Boolean Interpretations)|models]]. But this contradicts the assumption that all finite subsets of $\mathbf H$ have models. Hence the result. {{qed}}	1
:$\paren {p \land q} \implies r \dashv \vdash p \implies \paren {q \implies r}$	1
Let $S \subseteq \N_{>0}$ be a [[Definition:Subset|subset]] of the [[Definition:1-Based Natural Numbers|$1$-based natural numbers]]. Suppose that: :$(1): \quad 1 \in S$ :$(2): \quad \forall n \in \N_{>0} : n \in S \implies n + 1 \in S$ Then: :$S = \N_{>0}$	1
: $\left({p \implies r}\right) \land \left({q \implies r}\right) \vdash \left({p \lor q}\right) \implies r$	1
==== [[Rule of Material Equivalence/Formulation 1|Formulation 1]] ==== {{:Rule of Material Equivalence/Formulation 1}} ==== [[Rule of Material Equivalence/Formulation 2|Formulation 2]] ==== {{:Rule of Material Equivalence/Formulation 2}}	1
$\neg (p \lor \neg p) \vdash \bot$	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, in each case, the [[Definition:Truth Value|truth values]] in the appropriate columns match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c|ccc||cc|} \hline p & p & \implies & \bot & \neg & p \\ \hline F & F & T & F & T & F \\ T & T & F & F & F & T \\ \hline \end{array}$ {{qed}}	1
By the [[Łoś-Vaught Test]], it suffices to show that $ACF_p$ is satisfiable, has no finite models, and is [[Definition:Categorical (Model Theory)|$\kappa$-categorical]] for some [[Definition:Uncountable Set|uncountable]] $\kappa$. === Satisfiability === $\C$ is an [[Definition:Algebraically Closed Field|algebraically closed field]] of [[Definition:Characteristic of Field|characteristic]] $0$. If $p$ is a [[Definition:Prime Number|prime]], then the [[Definition:Algebraic Closure|algebraic closure]] of $\Z / \Z_p$ is an [[Definition:Algebraically Closed Field|algebraically closed field]] of [[Definition:Characteristic of Field|characteristic]] $p$. Thus $ACF_p$ is satisfiable. {{explain|Needs to be made clear why what is above leads to that statement.}} {{qed|lemma}} === No Finite Models === From [[Algebraically Closed Field is Infinite]]: $ACF_p$ has no finite models {{qed|lemma}} === $\kappa$-Categorical === From: : [[Field of Uncountable Cardinality K has Transcendence Degree K|Field of Uncountable Cardinality $\kappa$ has Transcendence Degree $\kappa$]] and: : [[Algebraically Closed Fields are Isomorphic iff they have the same Characteristic and Transcendence Degree]] it follows that: : $ACF_p$ is $\kappa$-categorical for all uncountable $\kappa$ Hence: : $ACF_p$ is $\kappa$-categorical for some uncountable $\kappa$ as was to be proved. {{qed}} [[Category:Model Theory]] [[Category:Mathematical Logic]] q2tolc8ek8jowx6j72tpmdgmhgs5lmj	1
The proof proceeds by the [[Principle of Mathematical Induction]]. === Base Case === First we note that $f_0: \N \to \N$ is the [[Definition:Zero Function|zero function]], which is a [[Definition:Basic Primitive Recursive Function|basic primitive recursive function]]. This is our [[Principle of Mathematical Induction#Basis for the Induction|base case]]. === Induction Hypothesis === This is our [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$f_k: \N \to \N$ is [[Definition:Primitive Recursive Function|primitive recursive]] for some given $k \in \N$. Then we need to show: :$f_{k + 1}: \N \to \N$ is [[Definition:Primitive Recursive Function|primitive recursive]]. === Induction Step === This is our [[Principle of Mathematical Induction#Induction Step|induction step]]: :$\map {f_{k + 1} } n = k + 1 = \map \Succ k = \map \Succ {\map {f_k} n}$ Now $\map {f_k} n$ is [[Definition:Primitive Recursive Function|primitive recursive]] from our [[Constant Function is Primitive Recursive#Induction Hypothesis|induction hypothesis]]. Thus $\map {f_{k + 1} } n$ is obtained from the [[Definition:Basic Primitive Recursive Function|basic primitive recursive function]] $\Succ$ and $\map {f_k} n$ by [[Definition:Substitution (Mathematical Logic)|substitution]]. The result follows by the [[Principle of Mathematical Induction]]. {{qed}} [[Category:Primitive Recursive Functions]] [[Category:Constant Mappings]] d9lze0g0094p4jharia6vybbweoagps	1
{{BeginTableau|p \implies \left ({q \implies r}\right) \vdash \left ({p \land q}\right) \implies r}} {{Premise|1|p \implies \left ({q \implies r}\right)}} {{Assumption|2|p \land q}} {{Simplification|3|2|p|2|1}} {{Simplification|4|2|q|2|2}} {{ModusPonens|5|1, 2|q \implies r|1|3}} {{ModusPonens|6|1, 2|r|5|4}} {{Implication|7|1|\left ({p \land q}\right) \implies r|2|6}} {{EndTableau}} {{Qed}}	1
: $p \implies q, r \implies s \vdash p \lor r \implies q \lor s$	1
{{BeginTableau|\vdash \paren {\neg p \implies p} \implies p}} {{Premise|1|\neg p \implies p}} {{SequentIntro|2|1|p|1|[[Clavius's Law/Formulation 1|Clavius's Law: Formulation 1]]}} {{Implication|3||\paren {\neg p \implies p} \implies p|1|2}} {{EndTableau|qed}}	1
: $p \vdash \neg \neg p$	1
Let $\mathbf P$ be the [[Definition:Set|set]] of all [[Definition:URM Program|URM programs]]. Let $P \in \mathbf P$ be a [[Definition:URM Program|URM program]] with $k$ [[Definition:Unlimited Register Machine#Basic Instruction|basic instructions]]: {| |- ! align="right" | Line !! ! align="left" | Command !! |- | align="right" | $1$ || | align="left" | $I_1$ || |- | align="right" | $2$ || | align="left" | $I_2$ || |- | align="right" | $\vdots$ || | align="left" | $\vdots$ || |- | align="right" | $k$ || | align="left" | $I_k$ || |} We define the mapping $\gamma: \mathbf P \to \N$ as follows: :$\displaystyle \gamma \left({P}\right) = \prod_{i=1}^k p_i^{\beta \left({I_i}\right)}$ where: * $p_i$ is the $i$th [[Definition:Prime Number|prime number]]; * $\beta \left({I_i}\right)$ is the [[Unique Code for URM Instruction|unique code for instruction $i$]]. Hence it follows from the [[Fundamental Theorem of Arithmetic]] that $\gamma$ is uniquely specified for any given [[Definition:URM Program|URM program]]. Thus $\gamma$ is an [[Definition:Injection|injection]]. {{qed}} For a given $P$, the number $\gamma \left({P}\right)$ is referred to as the '''code number of $P$'''.	1
:$\vdash p \land q \implies q$	1
An '''argument form''' is a [[Definition:Collation|collation]] of [[Definition:Symbol|symbols]] which contains [[Definition:Statement Variable|statement variables]] such that: : when [[Definition:Statement|statements]] are used to replace [[Definition:Statement Variable|statement variables]] (the same [[Definition:Statement|statement]] replacing the same [[Definition:Statement Variable|statement variable]] throughout), the result is a [[Definition:Logical Argument|logical argument]]. === [[Definition:Argument Form/Specific Form|Specific Form]] === {{:Definition:Argument Form/Specific Form}}	1
:$\vdash \paren {p \land q} \iff \paren {\neg \paren {\neg p \lor \neg q} }$	1
:$\vdash \paren {\paren {p \implies r} \land \paren {q \implies r} } \iff \paren {\paren {p \lor q} \implies r}$	1
This page gathers together some useful results that can be used in the derivation of [[Definition:Tableau Proof (Propositional Tableaus)|proofs by propositional tableau]]. Let $\mathcal M$ be a [[Definition:Model (Boolean Interpretations)|model for propositional logic]], and let $\mathbf A$ and $\mathbf B$ be [[Definition:WFF of Propositional Logic|WFFs of propositional logic]]. Then the following results hold. The symbol $\models$ is used throughout to denote [[Definition:Semantic Consequence|semantic consequence]].	1
The set $\Bbb P$ of [[Definition:Prime Number|prime numbers]] is [[Definition:Primitive Recursive Set|primitive recursive]].	1
:$\neg \left({p \land q}\right), q \vdash \neg p$	1
Let $\struct {S, \vee, \wedge}$ be a [[Definition:Boolean Algebra|Boolean algebra]]. Then any theorem in $\struct {S, \vee, \wedge}$ remains valid if both $\vee$ and $\wedge$ are interchanged, and also $\bot$ and $\top$ are interchanged throughout the whole theorem.	1
Let $\AA$ be a [[Definition:Structure for Predicate Logic|structure]] on a [[Definition:Set|set]] $A$, and let $\sigma$ be an [[Definition:Assignment for Formula|assignment]] for $\forall x: \map {\mathbf A} x \implies \map {\mathbf A} \tau$. Define: :$a_\tau := \mathop{ \operatorname{val}_\AA \left({\tau}\right) } \sqbrk \sigma$ the [[Definition:Value of Term under Assignment|value]] of $\tau$ under $\sigma$. From the definition of [[Definition:Value of Formula under Assignment|value]] under $\sigma$: :$\map {\mathrm {val}_\AA} {\forall x: \map {\mathbf A} x \implies \map {\mathbf A} \tau} \sqbrk \sigma = \map {f^\to} {\map {\mathrm {val}_\AA} {\forall x: \map {\mathbf A} x} \sqbrk \sigma, \map {\mathrm {val}_\AA} {\map {\mathbf A} \tau} \sqbrk \sigma}$ where $f^\to$ is the [[Definition:Conditional/Truth Function|truth function]] of $\implies$. We thus need to ascertain that if: :$\map {\mathrm {val}_\AA} {\forall x: \map {\mathbf A} x} \sqbrk \sigma = T$ then also: :$\map {\mathrm {val}_\AA} {\map {\mathbf A} \tau} \sqbrk \sigma = T$ By definition of [[Definition:Value of Formula under Assignment|value]] under $\sigma$, the former amounts to: :$\map {\mathrm {val}_\AA} {\map {\mathbf A} x} \sqbrk {\sigma + \paren {x / a} } = T$ for all $a \in A$. By the [[Substitution Theorem for Well-Formed Formulas]]: :$\map {\mathrm {val}_\AA} {\map {\mathbf A} \tau} \sqbrk \sigma = \map {\mathrm {val}_\AA} {\mathbf A} \sqbrk {\sigma + \paren {x / a_\tau} }$ Since $a_\tau \in A$, the conclusion follows, and $\forall x: \map {\mathbf A} x \implies \map {\mathbf A} \tau$ is a [[Definition:Tautology (Predicate Logic)|tautology]]. {{qed}}	1
See the proof of [[URM Computable Function is Recursive]] for an explanation of the symbols used here. === Necessary Condition === Suppose $e = \gamma \left({P}\right)$ codes a [[Definition:URM Program|URM program]] $P$ which computes $f$. Suppose the computation using $P$ with input $\left({n_1, n_2, \ldots, n_k}\right)$ [[Definition:Unlimited Register Machine#Termination|halts]] at [[Definition:Unlimited Register Machine#Stage of Computation|stage]] $t_0$ with [[Definition:Unlimited Register Machine#Output|output]] $q$. Let $t > t_0$, that is, we "wait till after $P$ has finished". Then $f \left({n_1, n_2, \ldots, n_k}\right) = q$. Since $P$ has [[Definition:Unlimited Register Machine#Termination|halted]] at [[Definition:Unlimited Register Machine#Stage of Computation|stage]] $t_0$: :$\left({S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)}\right)_1 > \operatorname{len} \left({e}\right)$ where: * $S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)$ is the [[Unique Code for State of URM Program|state code]] at [[Definition:Unlimited Register Machine#Stage of Computation|stage]] $t$ of the computation of $P$ with input $\left({n_1, n_2, \ldots, n_k}\right)$ * $\operatorname{len} \left({e}\right)$ is the [[Definition:Length of an Integer|length of $e$]] * the number $\left({S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)}\right)_1$ is the value of the [[Definition:Unlimited Register Machine#Instruction Pointer|instruction pointer]] to the [[Definition:Unlimited Register Machine#Basic Instructions|instruction]] about to be carried out at stage $t$ * $\left({z}\right)_j$ is the [[Definition:Prime Exponent Function|prime exponent function]]. Since the [[Definition:Unlimited Register Machine#Output|output]] is $q$: :$\left({S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)}\right)_2 = q$ Let us put $z_0 = 2^q 3^{t_0}$. Then: :$\left({z_0}\right)_2 = t_0$ and $\left({z_0}\right)_1 = q$ Thus: :$\left({S_k \left({e, n_1, n_2, \ldots, n_k, \left({z_0}\right)_2}\right)}\right)_1 > \operatorname{len} \left({e}\right)$ and :$\left({z_0}\right)_1 = \left({S_k \left({e, n_1, n_2, \ldots, n_k, \left({z}\right)_2}\right)}\right)_2$ Now $z_0$ is the smallest integer with these properties, because $\left({z_0}\right)_2 = t_0$ is the [[Definition:Unlimited Register Machine#Stage of Computation|stage]] at which $P$ [[Definition:Unlimited Register Machine#Termination|halts]]. Thus we have: :$f \left({n_1, n_2, \ldots, n_k}\right) = q = \left({z_0}\right)_1$. Now we let $T_k \left({e, n_1, n_2, \ldots, n_k, z}\right)$ be the relation defined as: {{begin-eqn}} {{eqn | l=T_k \left({e, n_1, n_2, \ldots, n_k, z}\right) | o=\iff | r=\left({S_k \left({e, n_1, n_2, \ldots, n_k, t}\right)}\right)_1 > \operatorname{len} \left({e}\right) | c= }} {{eqn | o=\text { and } | r=\left({z}\right)_1 = \left({S_k \left({e, n_1, n_2, \ldots, n_k, \left({z}\right)_2}\right)}\right)_2 | c= }} {{end-eqn}} Then $T_k$ is a [[Definition:Primitive Recursive Relation|primitive recursive $k+1$-ary relation]]. Also, we can take $U: \N \to \N$ to be the [[Definition:Primitive Recursive Function|primitive recursive function]] given by $U \left({z}\right) = \left({z}\right)_1$. {{qed|lemma}} === Sufficient Condition === Now let $f$ be a [[Definition:Recursive Function|recursive function]]. Then by [[Recursive Function is URM Computable]], there exists some [[Definition:URM Program|URM program]] which computes $f$. Let $P$ be the [[Definition:URM Program|URM program]] with the smallest [[Unique Code for URM Program|code number]] that computes $f$. Let $e = \gamma \left({P}\right)$ be the [[Unique Code for URM Program|code number]] of $P$. Suppose $f \left({n_1, n_2, \ldots, n_k}\right)$ is defined. Then from the above, we deduce that $\mu z \ T_k \left({e, n_1, n_2, \ldots, n_k, z}\right)$ is defined. Let $z_0 = \mu z \ T_k \left({e, n_1, n_2, \ldots, n_k, z}\right)$. Then $\left({z_0}\right)_1 = f \left({n_1, n_2, \ldots, n_k}\right)$. That is, $U \left({z_0}\right) = f \left({n_1, n_2, \ldots, n_k}\right)$. Hence $f \left({n_1, n_2, \ldots, n_k}\right) = U \left({\mu z \ T_k \left({e, n_1, n_2, \ldots, n_k, z}\right)}\right)$ as required. On the other hand, suppose $f \left({n_1, n_2, \ldots, n_k}\right)$ is undefined. Then the computation using $P$ with [[Definition:Unlimited Register Machine#Input|input]] $\left({n_1, n_2, \ldots, n_k}\right)$ does not halt. So there is no $z$ such that $T_k \left({e, n_1, n_2, \ldots, n_k, z}\right)$. So $U \left({\mu z \ T_k \left({e, n_1, n_2, \ldots, n_k, z}\right)}\right)$ is undefined. Thus: :$f \left({n_1, n_2, \ldots, n_k}\right) \approx U \left({\mu z \ T_k \left({e, n_1, n_2, \ldots, n_k, z}\right)}\right)$ as defined in [[Definition:Partial Function Equality|partial function equality]]. {{qed}} {{namedfor|Stephen Cole Kleene|cat=Kleene}} [[Category:Recursion Theory]] 5y05vgiz6wiiu27wodfhk3mwwgt3pt6	1
Proceed by the [[Principle of Structural Induction]] applied to the [[Definition:Bottom-Up Specification of Predicate Logic|bottom-up specification of predicate logic]]. If $\mathbf A = p \left({\tau_1, \ldots, \tau_n}\right)$, then: :$\mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\sigma}\right] = p_{\mathcal A} \left({ \mathop{ \operatorname{val}_{\mathcal A} \left({\tau_1}\right) } \left[{\sigma}\right], \ldots, \mathop{ \operatorname{val}_{\mathcal A} \left({\tau_n}\right) } \left[{\sigma}\right] }\right)$ Because $\mathbf A$ contains no [[Definition:Quantifier|quantifiers]], all its variables are [[Definition:Free Variable|free]], and hence are in the [[Definition:Domain of Mapping|domain]] of $\sigma, \sigma'$ as [[Definition:Assignment for Formula|assignments]]. Thus $\sigma, \sigma'$ are [[Definition:Assignment for Term|assignments]] for each $\tau_i$, and by [[Value of Term under Assignment Determined by Variables]]: :$\mathop{ \operatorname{val}_{\mathcal A} \left({\tau_i}\right) } \left[{\sigma}\right] = \mathop{ \operatorname{val}_{\mathcal A} \left({\tau_i}\right) } \left[{\sigma'}\right]$ for each $\tau_i$. It is immediate that: :$\mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\sigma}\right] = \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\sigma'}\right]$ If $\mathbf A = \neg \mathbf B$ and the induction hypothesis applies to $\mathbf B$, then: {{begin-eqn}} {{eqn|l = \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\sigma}\right] |r = f^\neg \left({ \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf B}\right) } \left[{\sigma}\right] }\right) |c = Definition of [[Definition:Value of Formula under Assignment|value under $\sigma$]] }} {{eqn|r = f^\neg \left({ \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf B}\right) } \left[{\sigma'}\right] }\right) |c = Induction Hypothesis }} {{eqn|r = \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\sigma'}\right] |c = Definition of [[Definition:Value of Formula under Assignment|value under $\sigma'$]] }} {{end-eqn}} If $\mathbf A = \mathbf B \circ \mathbf B'$ for $\circ$ one of $\land, \lor, \implies, \iff$ and the induction hypothesis applies to $\mathbf B, \mathbf B'$: {{begin-eqn}} {{eqn|l = \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\sigma}\right] |r = f^\circ \left({ \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf B}\right) } \left[{\sigma}\right], \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf B'}\right) } \left[{\sigma}\right] }\right) |c = Definition of [[Definition:Value of Formula under Assignment|value under $\sigma$]] }} {{eqn|r = f^\circ \left({ \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf B}\right) } \left[{\sigma'}\right], \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf B'}\right) } \left[{\sigma'}\right] }\right) |c = Induction Hypothesis }} {{eqn|r = \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\sigma'}\right] |c = Definition of [[Definition:Value of Formula under Assignment|value under $\sigma'$]] }} {{end-eqn}} If $\mathbf A = \exists x: \mathbf B$ or $\mathbf A = \forall x : \mathbf B$, and the induction hypothesis applies to $\mathbf B$, then from the definition of [[Definition:Value of Formula under Assignment|value under $\sigma$]]: :$\mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\sigma}\right]$ is determined by the [[Definition:Value of Formula under Assignment|values]]: :$\mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf B}\right) } \left[{\sigma + \left({x / a}\right)}\right]$ where $a$ ranges over $\mathcal A$, and $\sigma + \left({x / a}\right)$ is the [[Definition:Extension of Assignment|extension]] of $\sigma$ mapping $x$ to $a$. Now, for a [[Definition:Free Variable|free variable]] $y$ of $\mathbf B$: {{begin-eqn}} {{eqn|l = \left({\sigma + \left({x / a}\right)}\right) \left({y}\right) |r = \begin{cases} a &: \text{if $y = x$} \\ \sigma \left({y}\right) &: \text{otherwise} \end{cases} |c = Definition of [[Definition:Extension of Assignment|Extension]] }} {{eqn|r = \begin{cases} a &: \text{if $y = x$} \\ \sigma' \left({y}\right) &: \text{otherwise} \end{cases} |c = Assumption on $\sigma, \sigma'$ }} {{eqn|r = \left({\sigma' + \left({x / a}\right)}\right) \left({y}\right) |c = Definition of [[Definition:Extension of Assignment|Extension]] }} {{end-eqn}} Hence, by the induction hypothesis: :$\mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf B}\right) } \left[{\sigma + \left({x / a}\right)}\right] = \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf B}\right) } \left[{\sigma' + \left({x / a}\right)}\right]$ It follows that: :$\mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\sigma}\right] = \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\sigma'}\right]$ The result follows from the [[Principle of Structural Induction]]. {{qed}} [[Category:Predicate Logic]] 72pyybgluhk8a7ghrccyz86nqc2qh1q	1
Let $m, n \in \N$ be [[Definition:Natural Numbers|natural numbers]]. Let us define the [[Definition:Function|function]] $\operatorname{rem}: \N^2 \to \N$: :$\map \rem {n, m} = \begin{cases} \text{the remainder when } n \text{ is divided by } m & : m \ne 0 \\ 0 & : m = 0 \end{cases}$ where the $\text{remainder}$ is as defined in the [[Division Theorem]]: :If $n = m q + r$, where $0 \le r < m$, then $r$ is the [[Definition:Remainder|remainder]]. Then $\rem$ is [[Definition:Primitive Recursive Function|primitive recursive]].	1
The [[Rule of Idempotence/Disjunction/Formulation 2/Reverse Implication|Rule of Idempotence]]: :$(p \lor p) \implies p$ is a [[Definition:Tautology (Formal Semantics)|tautology]] in [[Definition:Constructed Semantics/Instance 1|Instance 1]] of [[Definition:Constructed Semantics|constructed semantics]].	1
{{begin-eqn}} {{eqn | l = p \implies q | o = \dashv \vdash | r = \neg \paren {p \land \neg q} | c = [[Implication Equivalent to Negation of Conjunction with Negative]] }} {{eqn | o = \dashv \vdash | r = p \uparrow \neg q | c = Definition of [[Definition:Logical NAND|NAND]] }} {{eqn | o = \dashv \vdash | r = p \uparrow \paren {q \uparrow q} | c = [[NAND with Equal Arguments]] }} {{end-eqn}} {{qed}}	1
: $\vdash p \iff \paren {p \lor p}$	1
: $\vdash \left({\left({p \lor q}\right) \implies r}\right) \implies \left({\left({p \implies r}\right) \land \left({q \implies r}\right)}\right)$	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] are [[Definition:True|true]] for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc|c|ccccc|} \hline ((p & \land & q) & \implies & r) & \implies & (p & \implies & (q & \implies & r)) \\ \hline F & F & F & T & F & T & F & T & F & T & F \\ F & F & F & T & T & T & F & T & F & T & T \\ F & F & T & T & F & T & F & T & T & F & F \\ F & F & T & T & T & T & F & T & T & T & T \\ T & F & F & T & F & T & T & T & F & T & F \\ T & F & F & T & T & T & T & T & F & T & T \\ T & T & T & F & F & T & T & F & T & F & F \\ T & T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
{{BeginTableau|p \land \top \vdash p}} {{Premise|1|p \land \top}} {{Simplification|2|1|p|1|1}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|p \vdash p \land \top}} {{Premise|1|p}} {{ExcludedMiddle|2|q \lor \neg q}} {{ExcludedMiddle|3|\top}} {{Conjunction|4|1|p \land \top|1|3}} {{EndTableau}} {{qed}}	1
If any two of the first $9$ [[Definition:Digit|digits]] are transposed, the [[Definition:Check Digit|check digit]] will be wrong.	1
Let $S_n$ denote the $n$th [[Definition:Fibonacci String|Fibonacci string]]. Let $F_n$ denote the $n$th [[Definition:Fibonacci Number|Fibonacci number]]. Let $m \in \Z$ such that $m \le F_n$. Let $m - 1$ be expressed in [[Definition:Zeckendorf Representation|Zeckendorf representation]] as $Z_{m - 1}$. Then the $m$th letter of $S_n$ is $\text a$ {{iff}}: : $k_r = 2$ where $k_r$ denotes the final [[Definition:Digit|digit]] of $Z_{m - 1}$.	1
Let $\mathcal L$ be a [[Definition:Logical Language|logical language]]. Let $\mathscr M$ be a [[Definition:Formal Semantics|formal semantics]] for $\mathcal L$. Let $\mathcal F$ be a [[Definition:Set|set]] of [[Definition:Logical Formula|$\mathcal L$-formulas]]. Let $T \left({\mathcal F}\right)$ be the [[Definition:Theory of Set of Formulas|$\mathcal L$-theory]] of $\mathcal F$. Then $T \left({\mathcal F}\right)$ is a [[Definition:Theory|theory]].	1
: $\vdash \left({p \implies \left({q \land r}\right)}\right) \implies \left({\left({p \implies q}\right) \land \left({p \implies r}\right)}\right)$	1
{{BeginTableau|p \land \left({p \lor q}\right) \vdash p}} {{Premise|1|p \land \left({p \lor q}\right)}} {{Simplification|2|1|p|1|1}} {{EndTableau}} {{qed}}	1
: $p \implies \left({q \land r}\right) \dashv \vdash \left({p \implies q}\right) \land \left({p \implies r}\right)$	1
: $\vdash \left({\left({p \implies q}\right) \land \left({p \implies r}\right)}\right) \implies \left({p \implies \left({q \land r}\right)}\right)$	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] is [[Definition:True|true]] for all [[Definition:Boolean Interpretation|boolean interpretations]], proving a [[Definition:Tautology (Boolean Interpretations)|tautology]]. $\begin{array}{|ccccccc|} \hline (p & \implies & q) & \lor & (q & \implies & p) \\ \hline F & T & F & T & F & T & F \\ F & T & T & T & T & F & F \\ T & F & F & T & F & T & T \\ T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc||ccccc|} \hline p & \oplus & (q & \oplus & r) & (p & \oplus & q) & \oplus & r \\ \hline F & F & F & F & F & F & F & F & F & F \\ F & T & F & T & T & F & F & F & T & T \\ F & T & T & T & F & F & T & T & T & F \\ F & F & T & F & T & F & T & T & F & T \\ T & T & F & F & F & T & T & F & T & F \\ T & F & F & T & T & T & T & F & F & T \\ T & F & T & T & F & T & F & T & F & F \\ T & T & T & F & T & T & F & T & T & T \\ \hline \end{array}$ {{qed}}	1
{{TFAE|def = Consistent (Logic)/Proof System/Propositional Logic|view = Consistent Proof System for Propositional Logic}} Let $\LL_0$ be the [[Definition:Language of Propositional Logic|language of propositional logic]]. Let $\mathscr P$ be a [[Definition:Proof System|proof system]] for $\LL_0$.	1
We apply the [[Method of Truth Tables]] to the proposition $\neg \left({p \land \neg p}\right)$. As can be seen by inspection, the [[Definition:Truth Value|truth value]] of the [[Definition:Main Connective (Propositional Logic)|main connective]], that is $\neg$, is $T$ for each [[Definition:Boolean Interpretation|boolean interpretation]] for $p$. $\begin{array}{|ccccc|} \hline \neg & (p & \land & \neg & p)\\ \hline T & F & F & T & F \\ T & T & F & F & T \\ \hline \end{array}$ {{qed}}	1
: $q \vdash \left({p \implies q}\right) \land \left({\neg p \implies q}\right)$	1
:$\paren {p \iff q} \iff q \dashv \vdash p$	1
We perform a proof by [[Cantor's Diagonal Argument]]. {{AimForCont}} $H$ is [[Definition:Recursive Function|recursive]]. Consider the [[Universal URM Computable Functions|universal URM computable function]] $\Phi_1: \N^2 \to \N$. Let $f: \N \to \N$ be the [[Definition:Function|function]] given by: :$\map f n = \begin{cases} \map {\Phi_1} {n, n} & : \map H {n, n} = 1 \\ 0 & : \text{otherwise} \end{cases}$ As $H$ is [[Definition:Recursive Function|recursive]], the relation $\map H {n, n} = 1$ is also [[Definition:Recursive Relation|recursive]]. The [[Universal URM Computable Functions|universal function]] is [[Definition:Recursive Function|recursive]] as all [[URM Computable Function is Recursive|URM computable functions are recursive]]. Also, $\map {\Phi_1} {n, n}$ is defined when $\map H {n, n} = 1$. The [[Constant Function is Primitive Recursive|constant $0$ is (primitive) recursive]] and always defined. So $f$ is [[Definition:Total Function|total]], and by [[Combination of Recursive Functions]] it is also [[Definition:Recursive Function|recursive]]. It follows immediately that the function $g: \N \to \N$ given by: :$\map g n = \map f n + 1$ is also [[Definition:Recursive Function|recursive]]. So by [[Universal URM Computable Functions]] there exists some $e \in \N$ such that: :$\forall n: \map g n = \map {\Phi_1} {e, n}$ that is, the [[Unique Code for URM Program|URM program coded by $e$]] computes $g$. Hence: :$\map g e = \map {\Phi_1} {e, e}$ But since $e$ codes a [[Definition:URM Program|URM program]] which [[Definition:Unlimited Register Machine#Termination|halts]] with [[Definition:Unlimited Register Machine#Input|input]] $e$, we have: :$\map H {e, e} = 1$ and so: :$\map f e = \map {\Phi_1} {e, e}$ Therefore, by definition of $g$, we have: :$\map g e = \map {\Phi_1} {e, e} + 1$ This [[Definition:Contradiction|contradiction]] arose because we assumed that $H$ is [[Definition:Recursive Function|recursive]]. Hence the result. {{Qed}} [[Category:URM Programs]] [[Category:Recursion Theory]] nqsyvfw3b9n34ir7ld2nu0la3udzsf9	1
{{BeginTableau|\neg \left({\neg p \land \neg q}\right) \vdash p \lor q}} {{Premise|1|\neg \left({\neg p \land \neg q}\right)}} {{Assumption|2|\neg \left ({p \lor q}\right)}} {{DeMorgan|3|2|\neg p \land \neg q|2|Conjunction of Negations}} {{NonContradiction|4|1, 2|3|1}} {{Reductio|5|1|p \lor q|2|4}} {{EndTableau}} {{qed}} {{LEM|Reductio ad Absurdum}}	1
'''Multi-value logic''' is a branch of [[Definition:Logic|logic]] in which it is admissible for a [[Definition:Statement|statements]] to have a [[Definition:Truth Value|truth value]] other than just [[Definition:True|true]] or [[Definition:False|false]].	1
Let $X$ be a [[Definition:Topological Space|topological space]]. Let $V$ be a [[Definition:Normed Vector Space|normed vector space]] over $\R$ or $\C$ with [[Definition:Norm on Vector Space|norm]] $\norm {\,\cdot\,}$. Let $f, g, h: X \to V$ be functions. Let $x_0 \in X$. Let $f = \map \OO g$ and $g = \map \OO h$ as $x \to x_0$, where $\OO$ denotes [[Definition:Big-O Notation|big-O notation]]. Then $f = \map \OO h$ as $x \to x_0$.	1
{{BeginTableau|p \iff q \vdash \left({p \vdash q}\right)}} {{Premise|1|p \iff q}} {{BiconditionalElimination|3|1|p \implies q|1|1}} {{Assumption|3|p}} {{ModusPonens|4|1, 3|q|2|3}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|p \iff q \vdash \left({q \vdash p}\right)}} {{Premise|1|p \iff q}} {{BiconditionalElimination|3|1|p \implies q|1|2}} {{Assumption|3|q}} {{ModusPonens|4|1, 3|p|2|3}} {{EndTableau}} {{qed}} [[Category:Equivalences are Interderivable]] mdne6teoypnkvrjoq2gr6rw5bg536yu	1
Suppose $\pi$ does not fork over $A$. We will use [[Zorn's Lemma]] to find a candidate for the needed complete type. Consider the collection $\Pi$ of all non-forking sets $\pi'$ of $\mathcal L$-formulas with parameters from $B$ such that $\pi'$ contains $\pi$. Order $\Pi$ by subset inclusion. Since [[Forking is Local|a set forks iff a finite subset forks]], the union over any [[Definition:Chain (Set Theory)|chain]] is still a non-forking set, and hence is an upper bound for the chain. Thus, by [[Zorn's Lemma]], there is a maximal (with respect to subset inclusion) $p$ in $\Pi$. Suppose $p$ is not complete. :By definition, for some $\phi(\bar x, \bar b)$, $p$ contains neither $\phi(\bar x, \bar b)$ nor $\neg\phi(\bar x, \bar b)$. :Since $p$ is non-forking, by [[Formula and its Negation Cannot Both Cause Forking]], at least one of $p\cup\phi(\bar x, \bar b)$ or $p\cup\neg\phi(\bar x, \bar b)$ is non-forking as well. :Hence $p$ is not maximal in $\Pi$, contradicting the choice of $p$. Thus $p$ is complete. {{qed}} {{AoC|Zorn's Lemma}} [[Category:Model Theory]] ppskkx54i644iki7i51u3hpdka104hw	1
Because of the [[Definition:Unique Readability|unique readability]] of $ST$, we can determine for each [[Definition:Symbol|symbol]] $s$ that is part of $ST$, whether: :$s$ is part of $S$ :$s$ is part of $T$ and furthermore, precisely one of these options occurs. There are $\left\vert{S}\right\vert$ [[Definition:Symbol|symbols]] in $S$, and $\left\vert{T}\right\vert$ [[Definition:Symbol|symbols]] in $T$. In total, then, $ST$ is seen to consist of $\left\vert{S}\right\vert + \left\vert{T}\right\vert$ [[Definition:Symbol|symbols]]. {{qed}} [[Category:Formal Systems]] d0o1ugpai8p0eyecwjkg0ghq30mujzo	1
Let $T$ be the [[Definition:Set|set]] of [[Definition:Theorem of Logic|theorems]] of some [[Definition:Recursive Set|recursive set]] of [[Definition:Sentence|sentences]] in the [[Definition:Language of Arithmetic|language of arithmetic]] such that $T$ contains [[Definition:Minimal Arithmetic|minimal arithmetic]]. Let $\map {\mathrm {Cons} } T$ be the [[Definition:Propositional Function|propositional function]] which states that $T$ is [[Definition:Consistent (Logic)|consistent]]. Then it is not possible to prove $\map {\mathrm {Cons} } T$ by means of formal statements within $T$ itself.	1
For all $n \in \N_{> 0}$, let $P \left({n}\right)$ be the [[Definition:Proposition|proposition]]: :$\displaystyle \lambda \sum_{i \mathop = 1}^n x_i = \sum_{i \mathop = 1}^n \lambda x_i$ === Basis for the Induction === $P \left({1}\right)$ is the case: {{begin-eqn}} {{eqn | l = \lambda \sum_{i \mathop = 1}^1 x_i | r = \lambda x_1 }} {{eqn | r = \sum_{i \mathop = 1}^1 \lambda x_i }} {{end-eqn}} This is the [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that, if $P \left({k}\right)$ is true, where $k \ge 2$, then it logically follows that $P \left({k + 1}\right)$ is true. So this is the [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$\displaystyle \lambda \sum_{i \mathop = 1}^k x_i = \sum_{i \mathop = 1}^k \lambda x_i$ from which it is to be shown that: :$\displaystyle \lambda \sum_{i \mathop = 1}^{k + 1} x_i = \sum_{i \mathop = 1}^{k + 1} \lambda x_i$ === Induction Step === This is the [[Principle of Mathematical Induction#Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \lambda \sum_{i \mathop = 1}^{k + 1} x_i | r = \lambda \left({\sum_{i \mathop = 1}^k x_i + x_{k + 1} }\right) | c = Definition of [[Definition:Summation|Summation]] }} {{eqn | r = \lambda \sum_{i \mathop = 1}^k x_i + \lambda x_{k + 1} | c = [[Multiplication of Numbers Distributes over Addition]] }} {{eqn | r = \sum_{i \mathop = 1}^k \lambda x_i + \lambda x_{k + 1} | c = [[Summation is Linear/Scaling of Summations#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \sum_{i \mathop = 1}^{k + 1} \lambda x_i | c = Definition of [[Definition:Summation|Summation]] }} {{end-eqn}} So $P \left({k}\right) \implies P \left({k + 1}\right)$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\displaystyle \forall n \in \N_{> 0}: \lambda \sum_{i \mathop = 1}^n x_i = \sum_{i \mathop = 1}^n \lambda x_i$ {{qed}} [[Category:Numbers]] [[Category:Proofs by Induction]] s6gnp5lzhthp0s5hmwo7dcinjytg7f9	1
Recall the statement of $RST \, 4$: :If $\mathbf A$ and $\mathbf B$ are [[Definition:Theorem (Formal Systems)|theorems]] of $\mathscr H_2$, then so is $\mathbf A \land \mathbf B$. Suppose that $\mathbf A$ and $\mathbf B$ are [[Definition:Theorem (Formal Systems)|theorems]] of $\mathscr H_2$. From [[Rule of Conjunction/Sequent Form/Formulation 2]], we have as a [[Definition:Theorem (Formal Systems)|theorem]]: :$p \implies \paren{ q \implies \paren{ p \land q } }$ which can be recursively checked to not have used $RST \, 4$ anywhere in a proof. Applying $RST \, 1$, this becomes: :$\mathbf A \implies \paren{ \mathbf B \implies \paren{ \mathbf A \land \mathbf B } }$ Using $RST \, 3$ twice, the result follows. {{qed}}	1
:$p \lor \left ({p \land q}\right) \dashv \vdash p$	1
The [[Definition:Min Operation|minimum function]] $\min: \N^2 \to \N$, defined as: :$\min \left({n, m}\right) = \begin{cases} n: & n \le m \\ m: & m \le n \end{cases}$ is [[Definition:Primitive Recursive Function|primitive recursive]].	1
This is to be done by [[Second Principle of Mathematical Induction|strong induction]] on the [[Definition:Length of String|length]] of [[Definition:WFF of Propositional Logic|WFFs]]. By definition of $v$ being a [[Definition:Boolean Interpretation|boolean interpretation]], $\map v p$ is well-defined for all $p \in \PP_0$, the [[Definition:Vocabulary of Propositional Logic|vocabulary]] of $\LL_0$. A [[Definition:WFF of Propositional Logic|WFF]] of [[Definition:Length of String|length]] $1$ has (trivially) a unique [[Definition:Parsing Sequence|parsing sequence]]. Consequently, only a single defining rule for $v$ as a [[Definition:Boolean Interpretation|boolean interpretation]] applies. So the result holds for all [[Definition:WFF of Propositional Logic|WFFs]] of [[Definition:Length of String|length]] $1$. Now, suppose the result is true for all [[Definition:WFF of Propositional Logic|WFFs]] of [[Definition:Length of String|length]] $k$ or less. Let $\mathbf A$ be a [[Definition:WFF of Propositional Logic|WFF]] of length $k+1$. There are two possibilities: Suppose $\mathbf A = \neg \mathbf B$ for some [[Definition:WFF of Propositional Logic|WFF]] $\mathbf B$. Then $\mathbf B$ is of length $k$, so by the induction hypothesis has a unique value $v (\mathbf B)$ no matter what parsing sequence is used. So as $\map v {\mathbf A} = \map {f^\neg} {\map v {\mathbf B} }$, it follows that $\mathbf A$ likewise has a unique value. Hence the result holds for $k + 1$ in this situation. Suppose $\mathbf A = \paren {\mathbf B * \mathbf C}$ for some [[Definition:WFF of Propositional Logic|WFFs]] $\mathbf B$ and $\mathbf C$ and some connective $*$. By [[Language of Propositional Logic has Unique Parsability]], $*$ must be the unique [[Definition:Main Connective (Propositional Logic)|main connective]]. So $\mathbf B$ and $\mathbf C$ are both [[Definition:WFF of Propositional Logic|WFFs]] shorter than $k + 1$ and therefore by the induction hypothesis have unique values $\map v {\mathbf B}$ and $\map v {\mathbf C}$. Since $\mathbf A = \paren {\mathbf B * \mathbf C}$ for a unique [[Definition:Main Connective (Propositional Logic)|main connective]] $*$, it follows that: :$\map v {\mathbf A} = \map {f^*} {\map v {\mathbf B}, \map v {\mathbf C} }$ is well-defined. Hence the result holds for $k + 1$ in this situation. So the result follows by the [[Second Principle of Mathematical Induction]]. {{qed}}	1
: $\neg q \implies p \vdash \neg p \implies q$	1
Let $X$ be a [[Definition:Set|set]]. Let $w$ be a [[Definition:Group Word on Set|group word]] on $X$. Then $w$ has a [[Definition:Unique|unique]] [[Definition:Reduced Form of Group Word|reduced form]].	1
In all contexts, the definition of the term '''axiom''' is by and large the same. That is, an '''axiom''' is a [[Definition:Statement|statement]] which is ''accepted'' as being [[Definition:True|true]]. A [[Definition:Statement|statement]] that is considered an '''axiom''' can be described as being '''axiomatic'''.	1
{{BeginTableau|\left({p \implies q}\right) \land \left({\neg p \implies q}\right) \vdash q}} {{Premise|1|\left({p \implies q}\right) \land \left({\neg p \implies q}\right)}} {{Simplification|2|1|p \implies q|1|1}} {{Simplification|3|1|\neg p \implies q|1|2}} {{SequentIntro|4|1|p \lor \neg p \implies q \lor q|2, 3|[[Constructive Dilemma]]}} {{ExcludedMiddle|5|p \lor \neg p}} {{ModusPonens|6|1|q \lor q|4|5}} {{Idempotence|7|1|q|6|Disjunction}} {{EndTableau}} {{Qed}}	1
Let $p$ be either $0$ or a [[Definition:Prime Number|prime number]]. Let $ACF_p$ be the [[Definition:Theory of Elementary Class|theory]] of [[Definition:Algebraically Closed Field|algebraically closed fields]] of [[Definition:Characteristic of Field|characteristic]] $p$ in the language $\mathcal L_r = \left\{ {0, 1, +, -, \cdot}\right\}$ for [[Definition:Ring (Abstract Algebra)|rings]], where: :$0, 1$ are [[Definition:Constant|constants]] and: :$+, -, \cdot$ are [[Definition:Binary Operation|binary functions]]. Then $ACF_p$ is [[Definition:Complete Theory|complete]].	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] are $T$ for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc|c|c|}\hline ((p & \implies & q) & \implies & p) & \implies & p \\ \hline F & T & F & F & F & T & F \\ F & T & T & F & F & T & F \\ T & F & F & T & T & T & T \\ T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|cccc||cccc|} \hline p & \implies & \neg & q & q & \implies & \neg & p \\ \hline F & T & T & F & F & T & T & F \\ F & T & F & T & T & T & T & F \\ T & F & T & F & F & F & F & T \\ T & T & F & T & T & T & F & T \\ \hline \end{array}$ {{qed}}	1
{{BeginTableau|\left({p \implies q}\right) \lor \left({p \implies r}\right) \vdash p \implies \left({q \lor r}\right)}} {{Assumption|1|\left({p \implies q}\right) \lor \left({p \implies r}\right)}} {{Assumption|2|p \implies q}} {{Assumption|3|p}} {{ModusPonens|4|2, 3|q|2|3}} {{Addition|5|2, 3|q \lor r|4|1}} {{Implication|6|2|p \implies \left({q \lor r}\right)|3|5}} {{Assumption|7|p \implies r}} {{Assumption|8|p}} {{ModusPonens|9|7, 8|r|7|8}} {{Addition|10|7, 8|q \lor r|9|2}} {{Implication|11|7|p \implies \left({q \lor r}\right)|8|10}} {{ProofByCases|12|1|p \implies \left({q \lor r}\right)|1|2|6|7|11}} {{EndTableau}} {{qed}} [[Category:Implication is Left Distributive over Disjunction]] 9y3zqxzh2wtz8svinjz0k93zt6o6bxt	1
=== [[Rule of Exportation/Forward Implication/Formulation 1/Proof|Proof of Forward Implication]] === {{:Rule of Exportation/Forward Implication/Formulation 1/Proof}} === [[Rule of Exportation/Reverse Implication/Formulation 1/Proof|Proof of Reverse Implication]] === {{:Rule of Exportation/Reverse Implication/Formulation 1/Proof}}	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc||ccccc|} \hline p & \land & (q & \land & r) & (p & \land & q) & \land & r \\ \hline F & F & F & F & F & F & F & F & F & F \\ F & F & F & F & T & F & F & F & F & T \\ F & F & T & F & F & F & F & T & F & F \\ F & F & T & T & T & F & F & T & F & T \\ T & F & F & F & F & T & F & F & F & F \\ T & F & F & F & T & T & F & F & F & T \\ T & F & T & F & F & T & T & T & F & F \\ T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
{{BeginTableau|\neg p \vdash p \implies q}} {{Premise|1|\neg p}} {{Addition|2|1|\neg p \lor q|1|1}} {{SequentIntro|3|1|p \implies q|2|[[Rule of Material Implication/Formulation 1/Reverse Implication|Rule of Material Implication]]}} {{EndTableau}} {{qed}}	1
{{BeginTableau|\neg p \iff \neg q \vdash p \iff q}} {{Premise|1|\neg p \iff \neg q}} {{BiconditionalElimination|2|1|\neg p \implies \neg q|1|1}} {{SequentIntro|3|1|\neg \neg q \implies \neg \neg p|2|[[Rule of Transposition]]}} {{DoubleNegElimination|4|1|q \implies p|3|(twice)}} {{BiconditionalElimination|5|1|\neg q \implies \neg p|1|2}} {{SequentIntro|6|1|\neg \neg p \implies \neg \neg q|5|[[Rule of Transposition]]}} {{DoubleNegElimination|7|1|p \implies q|3|(twice)}} {{BiconditionalIntro|8|1|p \iff q|7|4}} {{EndTableau|qed}} {{LEM|Double Negation Elimination}}	1
The proof proceeds by [[Principle of Mathematical Induction|induction]]. For all $n \in \Z_{\ge 3}$, let $P \left({n}\right)$ be the [[Definition:Proposition|proposition]]: :$S_n$ begins with $\text{ba}$ We note in passing that $S_1 = \text a$ and $S_2 = \text b$, so neither of these begin with $\text{ba}$. === Basis for the Induction === $P \left({3}\right)$ is the case: :$S_3 = \text{ba}$ Thus $P \left({3}\right)$ is seen to hold. This is the [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that, if $P \left({k}\right)$ is true, where $k \ge 3$, then it logically follows that $P \left({k + 1}\right)$ is true. So this is the [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$S_k$ begins with $\text{ba}$ from which it is to be shown that: :$S_{k + 1}$ begins with $\text{ba}$ === Induction Step === This is the [[Principle of Mathematical Induction#Induction Step|induction step]]: By definition of [[Definition:Fibonacci String|Fibonacci string]]: :$S_{k + 1} = S_k S_{k - 1}$ [[Definition:Concatenation (Formal Systems)|concatenated]]. So $S_{k + 1}$ begins with $S_k$. By the [[Fibonacci String Begins with ba#Induction Hypothesis|induction hypothesis]], $S_k$ begins with $\text{ba}$. Thus $S_{k + 1}$ likewise begins with $\text{ba}$. So $P \left({k}\right) \implies P \left({k + 1}\right)$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :for all $n \in \Z$ such that $n \ge 3$, $S_n$ begins with $\text{ba}$. [[Category:Fibonacci Strings]] m1amfujyneiyn3x1ok7in380usedwui	1
{{BeginTableau|\neg p \lor \neg q \vdash \neg \left({p \land q}\right)}} {{Premise|1|\neg p \lor \neg q}} {{Assumption|2|p \land q}} {{Simplification|3|2|p|2|1}} {{Simplification|4|2|q|2|2}} {{Assumption|5|\neg p}} {{NonContradiction|6|2, 5|3|5}} {{Assumption|7|\neg q}} {{NonContradiction|8|2, 7|4|7}} {{ProofByCases|9|1, 2|\bot|1|5|6|7|8}} {{Contradiction|10|1|\neg \left({p \land q}\right)|2|9}} {{EndTableau}} {{qed}}	1
Not all [[Definition:Function|functions]] $f: \N \to \N$ are [[Definition:Primitive Recursive Function|primitive recursive]].	1
{{BeginTableau|p \oplus \bot \vdash p}} {{Premise|1|p \oplus \bot}} {{SequentIntro|2|1|\left({p \lor \bot} \right) \land \neg \left({p \land \bot}\right)|1| {{Defof|Exclusive Or}} }} {{SequentIntro|3|1|p \land \neg \left({p \land \bot}\right)|2|[[Disjunction with Contradiction]]}} {{SequentIntro|4|1|p \land \neg \bot|3|[[Conjunction with Contradiction]]}} {{SequentIntro|5|1|p \land \top|4|[[Tautology is Negation of Contradiction]]}} {{SequentIntro|6|1|p|5|[[Conjunction with Tautology]]}} {{EndTableau}} {{qed|lemma}} {{BeginTableau|p \vdash p \oplus \bot}} {{Premise|1|p}} {{SequentIntro|2|1|p \land \top|1|[[Conjunction with Tautology]]}} {{SequentIntro|3|1|\left({p \lor \bot}\right) \land \top|2|[[Disjunction with Contradiction]]}} {{SequentIntro|4|1|\left({p \lor \bot}\right) \land \neg \bot|3|[[Tautology is Negation of Contradiction]]}} {{SequentIntro|5|1|\left({p \lor \bot}\right) \land \neg \left({p \land \bot}\right)|4|[[Conjunction with Contradiction]]}} {{SequentIntro|6|1|p \oplus \bot|5| {{Defof|Exclusive Or}} }} {{EndTableau}} {{qed}}	1
Let $\mathcal L$ be a [[Definition:Logical Language|logical language]]. Let $\mathscr M$ be a [[Definition:Formal Semantics|formal semantics]] for $\mathcal L$. Let $\mathcal F$ be an [[Definition:Satisfiable Set of Formulas|$\mathscr M$-satisfiable set of formulas]] from $\mathcal L$. Let $\phi \in \mathcal F$. Then $\mathcal F \setminus \left\{{\phi}\right\}$ is also [[Definition:Satisfiable Set of Formulas|$\mathscr M$-satisfiable]].	1
Suppose $T$ has no [[Definition:Finished Branch of Propositional Tableau|finished branch]]. Then since $T$ is [[Definition:Finished Propositional Tableau|finished]], every [[Definition:Branch (Graph Theory)|branch]] of $T$ is [[Definition:Contradictory Branch|contradictory]]. Hence $T$ is a [[Definition:Tableau Confutation|tableau confutation]]. {{qed}}	1
{{BeginTableau|p \implies q \vdash \left({p \land r}\right) \implies \left ({q \land r}\right)}} {{Premise|1|p \implies q}} {{IdentityLaw|2||r \implies r|(None)|This is a theorem so depends on nothing}} {{Conjunction|3|1|\left({p \implies q}\right) \land \left({r \implies r}\right)|1|2}} {{SequentIntro|4|1|\left({p \land r}\right) \implies \left ({q \land r}\right)|3|[[Praeclarum Theorema]]}} {{EndTableau}} {{qed}}	1
{{BeginTableau|p, \neg p \vdash \bot}} {{Premise|1|p}} {{Premise|2|\neg p}} {{NonContradiction|3|1, 2|1|2}} {{EndTableau}} {{Qed}}	1
{{BeginTableau|p \lor q, \neg p \vdash q}} {{Premise|1|p \lor q}} {{Premise|2|\neg p}} {{Assumption|3|p}} {{SequentIntro|4|2|p \implies q|2|[[False Statement implies Every Statement/Formulation 1|False Statement implies Every Statement]]}} {{ModusPonens|5|2, 3|q|4|3}} {{Assumption|6|q}} {{ProofByCases|7|1, 2|q|1|3|5|6|6}} {{EndTableau}} {{qed}}	1
Let the [[Definition:Function|function]] $f: \N^{k+1} \to \N$ be [[Definition:Primitive Recursive Function|primitive recursive]]. Then so is the function $g: \N^{k+1} \to \N$ defined as: :$\displaystyle g \left({n_1, n_2, \ldots, n_k, z}\right) = \begin{cases} 1 & : z = 0 \\ \prod_{y=1}^z f \left({n_1, n_2, \ldots, n_k, y}\right) & : z > 0 \end{cases}$	1
We verify by brute force: :Starting on $n_0 \le 2916 = 4 \times 9^3$, we will end on $153$. {{qed|lemma}} First we prove that if $3 \divides n_0$, then $3 \divides \map f {n_0}$. From [[Divisibility by 3]]: The [[Definition:Integer Addition|sum]] of [[Definition:Digit|digits]] of $n_0$ is [[Definition:Divisor of Integer|divisible]] by $3$. By [[Fermat's Little Theorem]]: :$\forall x \in \Z: x^3 \equiv x \pmod 3$ Therefore [[Definition:Integer Addition|sum]] of the [[Definition:Cube|cubes]] of the [[Definition:Digit|digits]] of $n_0$ is also [[Definition:Divisor of Integer|divisible]] by $3$. That is the definition of $\map f {n_0}$. Thus $3 \divides \map f {n_0}$. {{qed|lemma}} It remains to be shown that for every $n_0 > 2916$, $\map f {n_0} < n_0$. For $n_0 \le 9999$: :$\map f {n_0} \le 9^3 + 9^3 + 9^3 + 9^3 = 2916 < n_0$ Now suppose $n_0$ is a $k$-[[Definition:Digit|digit]] number, where $k \ge 5$. Then: {{begin-eqn}} {{eqn | l = n_0 | o = > | r = 10^{k - 1} | c = the smallest $k$-[[Definition:Digit|digit]] number }} {{eqn | r = 10^4 \times 10^{k - 5} }} {{eqn | o = \ge | r = 10^4 \paren {1 + 9 \paren {k - 5} } | c = [[Bernoulli's Inequality]] }} {{eqn | o = > | r = 10 \times 9^3 \paren {9 k - 44} | c = $10 > 9$ }} {{eqn | o = > | r = 9^3 \paren {90 k - 440} }} {{eqn | o = \ge | r = 9^3 \paren {k + 445 - 440} | c = $k \ge 5$ }} {{eqn | o = > | r = 9^3 \times k }} {{eqn | o = \ge | r = \map f {n_0} }} {{end-eqn}} This shows that $\map f {n_0} < n_0$ for all $n_0 > 2916$. Thus for any $n_0 > 2916$, $s_n$ is eventually less than $2916$. Therefore we will eventually reach $153$. {{qed}}	1
From [[Master Code forms Vector Space]], $\map V {n, p}$ is a [[Definition:Vector Space|vector space]]. By definition, $\tuple {n, k}$ is a [[Definition:Vector Subspace|subspace]] of $\map V {n, p}$. The result follows by the fact that a [[Definition:Vector Subspace|subspace]] is itself a [[Definition:Vector Space|vector space]]. {{finish|I lose patience with the fine detail.}}	1
: $\left({p \implies q}\right) \land \left({\neg p \implies q}\right) \vdash q$	1
:$p \lor \paren {q \land r} \vdash \paren {p \lor q} \land \paren {p \lor r}$	1
We apply the [[Method of Truth Tables]]. As can be seen for all [[Definition:Boolean Interpretation|boolean interpretations]] by inspection, where the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] on the {{LHS}} is $T$, that under the one on the {{RHS}} is also $T$: $\begin{array}{|ccccccc||ccc|} \hline (p & \iff & q) & \land & (q & \iff & r) & p & \iff & r \\ \hline F & T & F & T & F & T & F & F & T & F \\ F & T & F & F & F & F & T & F & F & T \\ F & F & T & F & T & F & F & F & T & F \\ F & F & T & F & T & T & T & F & F & T \\ T & F & F & F & F & T & F & T & F & F \\ T & F & F & F & F & F & T & T & T & T \\ T & T & T & F & T & F & F & T & F & F \\ T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ Hence the result. {{qed}}	1
{{BeginTableau | \paren {p \iff \neg q} \vdash \neg \paren {p \iff q} }} {{Premise | 1 | p \iff \neg q}} {{SequentIntro | 2 | 1 |\neg \paren {p \iff \neg \neg q} | 1 | [[Non-Equivalence as Equivalence with Negation/Formulation 1/Forward Implication|Non-Equivalence as Equivalence with Negation: Forward Implication]]}} {{TheoremIntro | 3 | \neg \neg q \iff q | [[Double Negation]]}} {{SequentIntro | 4 | 1 |\neg \paren {p \iff q} |2, 3| [[Biconditional is Transitive]]}} {{EndTableau}}	1
Let $\mathcal L, \mathcal L'$ be [[Definition:Signature for Predicate Logic|signatures]] for the [[Definition:Language of Predicate Logic|language of predicate logic]]. Let $\mathcal L'$ be a [[Definition:Supersignature|supersignature]] of $\mathcal L$. Let $\Sigma$ be a [[Definition:Set|set]] of [[Definition:Sentence|$\mathcal L$-sentences]]. Then the following are [[Definition:Logically Equivalent|equivalent]]: :$\mathcal A \models_{\mathrm{PL}} \Sigma$ for some [[Definition:Structure for Predicate Logic|$\mathcal L$-structure]] $\mathcal A$ :$\mathcal A' \models_{\mathrm{PL}} \Sigma$ for some [[Definition:Structure for Predicate Logic|$\mathcal L'$-structure]] $\mathcal A'$ where $\models_{\mathrm{PL}}$ is the [[Definition:Model (Predicate Logic)|models]] relation. That is to say, the notion of [[Definition:Satisfiable Set of Formulas|satisfiability]] is preserved in passing to a [[Definition:Supersignature|supersignature]].	1
{{BeginTableau|p \land q \vdash \left({p \land r}\right) \lor \left({q \land \neg r}\right)}} {{Premise|1|p \land q}} {{ExcludedMiddle|2|r \lor \neg r}} {{Simplification|3|1|p|1|1}} {{Simplification|4|1|q|1|2}} {{Assumption|5|r}} {{Conjunction|6|1, 5|p \land r|1|5}} {{Addition|7|1, 5|\left({p \land r}\right) \lor \left({q \land \neg r}\right)|6|1}} {{Assumption|8|\neg r}} {{Conjunction|9|1, 8|q \land \neg r|4|8}} {{Addition|10|1, 8|\left({p \land r}\right) \lor \left({q \land \neg r}\right)|9|2}} {{ProofByCases|11|1|\left({p \land r}\right) \lor \left(q \land \neg r\right)|2|5|7|8|10}} {{EndTableau}} {{qed}} [[Category:Conjunction]] [[Category:Disjunction]] 0770tcw59m2lo3ynmatxcn9fqt8yf71	1
:$\bot \vdash \phi$	1
The '''subject''' of a [[Definition:Simple Statement|simple statement]] in [[Definition:Logic|logic]] is the part of the statement specifying the [[Definition:Object|object]] being talked about. The '''subject''' of a [[Definition:Simple Statement|simple statement]] is [[Definition:Atom (Logic)|atomic]] in [[Definition:Predicate Logic|predicate logic]]. The '''subject''' and [[Definition:Predicate|predicate]] of a [[Definition:Simple Statement|simple statement]] are referred to as its [[Definition:Logical Term|terms]].	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, in all cases the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc||ccccc|} \hline p & \iff & q & \neg & p & \iff & \neg & q \\ \hline F & T & F & T & F & T & T & F \\ F & F & T & T & F & F & F & T \\ T & F & F & F & T & F & T & F \\ T & T & T & F & T & T & F & T \\ \hline \end{array}$ {{qed}} [[Category:Biconditional Equivalent to Biconditional of Negations]] [[Category:Truth Table Proofs]] gi5u0dj3jca25l8ylyo15gtegynwcki	1
: $\neg \left ({p \iff q}\right) \dashv \vdash \left({p \lor q} \right) \land \neg \left({p \land q}\right)$	1
$A$ and $B$ are [[Definition:Primitive Recursive Set|primitive recursive]], therefore so are their [[Definition:Characteristic Function of Set|characteristic functions]] $\chi_A$ and $\chi_B$. Let $n \in \N$ be a [[Definition:Natural Numbers|natural number]]. Then $n \in A \cup B \iff \chi_A \left({n}\right) + \chi_B \left({n}\right) > 0$. So: {{begin-eqn}} {{eqn | l = \chi_{A \cup B} \left({n}\right) | r = \operatorname{sgn} \left({\chi_A \left({n}\right) + \chi_B \left({n}\right)}\right) | c = [[Signum Function is Primitive Recursive]] }} {{eqn | r = \operatorname{sgn} \left({\operatorname{add} \left({\chi_A \left({n}\right), \chi_B \left({n}\right)}\right)}\right) | c = [[Addition is Primitive Recursive]] }} {{end-eqn}} Thus $A \cup B$ is defined by [[Definition:Substitution (Mathematical Logic)|substitution]] from the [[Definition:Primitive Recursive Function|primitive recursive functions]] $\operatorname{sgn}$, $\operatorname{add}$, $\chi_A$ and $\chi_B$. Hence the result. {{qed}} [[Category:Primitive Recursive Functions]] [[Category:Set Union]] jzuuii96m9d4tlnaycoc63rmwvfejmx	1
Let $\mathcal M$ be an $\mathcal L$-[[Definition:First-Order Structure|structure]]. Let $\kappa$ be a [[Definition:Cardinal|cardinal]]. If $\mathcal M$ is $\kappa$-[[Definition:Big Model|big]], then it is $\kappa$-[[Definition:Saturated Model|saturated]].	1
Consider $\N$ defined as a [[Definition:Naturally Ordered Semigroup|naturally ordered semigroup]]. The result follows directly from [[Principle of Mathematical Induction for Naturally Ordered Semigroup]]. {{qed}}	1
We have that: {{begin-eqn}} {{eqn | l = a n + b | r = \map \Add {\map \Mult {a, n}, b} | c = }} {{eqn | r = \map \Add {\map \Mult {a, n}, \map {f_b} n} | c = }} {{eqn | r = \map \Add {\map \Mult {\map {f_a} n, \map {\pr_1^1} n}, \map {f_b} n} | c = }} {{end-eqn}} where: * [[Multiplication is Primitive Recursive|$\Mult$ is primitive recursive]] * [[Addition is Primitive Recursive|$\Add$ is primitive recursive]] * [[Constant Function is Primitive Recursive|the constant functions $f_a$ and $f_b$ are primitive recursive]] * The [[Definition:Projection Function|projection function]] $\pr_1^1$ is a [[Definition:Basic Primitive Recursive Function|basic primitive recursive function]]. Note that we need to use the [[Definition:Projection Function|projection function]] (in this case, the [[Definition:Basic Primitive Recursive Function/Identity Function|identity function]]) in order to satisfy the definition of [[Definition:Substitution (Mathematical Logic)|substitution]], even when there is only one variable. So $\Mult$ is obtained by using two levels of [[Definition:Substitution (Mathematical Logic)|substitution]] from the above [[Definition:Primitive Recursive Function|primitive recursive functions]]. {{qed}} [[Category:Primitive Recursive Functions]] 4yt2hry6ggmnj7w5vojcg1hwjv9binf	1
=== [[Implication is Left Distributive over Conjunction/Forward Implication/Formulation 2/Proof|Proof of Forward Implication]] === {{:Implication is Left Distributive over Conjunction/Forward Implication/Formulation 2/Proof}} === [[Implication is Left Distributive over Conjunction/Reverse Implication/Formulation 2/Proof|Proof of Reverse Implication]] === {{:Implication is Left Distributive over Conjunction/Reverse Implication/Formulation 2/Proof}}	1
Let $\phi$ be a [[Definition:Well-Formed Formula|WFF]] of $\LL$. Then $\phi$ is the result of applying finitely many [[Definition:Rule of Formation|rules of formation]] of $\LL$. If we can show that the result of each [[Definition:Rule of Formation|rule of formation]] satisfies $P$, we will have finished. Suppose now that for a [[Definition:Rule of Formation|rule of formation]] $\mathbf R$, all preceding rules have produced [[Definition:Well-Formed Formula|WFFs]] satisfying $P$. By the [[Definition:Bottom-Up Grammar|bottom-up]] nature of the [[Definition:Formal Grammar|formal grammar]] of $\LL$, $\mathbf R$ either: :Introduces a [[Definition:Letter|letter]] as a [[Definition:Well-Formed Formula|WFF]]; or :Constructs a new [[Definition:Well-Formed Formula|WFF]] from previously constructed ones. The two given hypotheses precisely ensure that the [[Definition:Well-Formed Formula|WFF]] resulting from $\mathbf R$ must also satisfy $P$. For the first [[Definition:Rule of Formation|rule of formation]] applied, all preceding rules have [[Definition:Vacuous Truth|vacuously]] produced [[Definition:Well-Formed Formula|WFFs]] satisfying $P$. But now we see that any subsequent [[Definition:Rule of Formation|rule of formation]] will satisfy this premise. In particular, it applies to the final [[Definition:Rule of Formation|rule of formation]], and hence $\map P \phi$ is true. {{qed}}	1
We apply the [[Method of Truth Tables]]. $\begin{array}{|ccc|ccc|ccc||c|} \hline p & \lor & q & p & \implies & r & q & \implies & r & r \\ \hline F & F & F & F & T & F & F & T & F & F \\ F & F & F & F & T & T & F & T & T & T \\ F & T & T & F & T & F & T & F & F & F \\ F & T & T & F & T & T & T & T & T & T \\ T & T & F & T & F & F & F & T & F & F \\ T & T & F & T & T & T & F & T & T & T \\ T & T & T & T & F & F & T & F & F & F \\ T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ As can be seen, when $p \lor q$, $p \implies r$ and $q \implies r$ are all [[Definition:True|true]], then so is $r$. {{qed}}	1
'''Predicate logic''' is a sub-branch of [[Definition:Symbolic Logic|symbolic logic]]. It is an extension of [[Definition:Propositional Logic|propositional logic]] in which the internal structure of [[Definition:Simple Statement|simple statements]] is analyzed. Thus in '''predicate logic''', simple statements are no longer [[Definition:Atom (Logic)|atomic]]. The [[Definition:Atom (Logic)|atoms]] of '''predicate logic''' are [[Definition:Subject|subjects]] and [[Definition:Predicate|predicates]] of [[Definition:Simple Statement|simple statements]]. There are various [[Definition:Formal System|formal systems]] allowing for rigid determination of the [[Definition:Theorem|theorems]] of '''predicate logic''':	1
:$\neg p \vdash p \implies q$	1
:$\forall m, n \in \Z: \forall x \in R: \paren {m \cdot x} \circ \paren {n \cdot x} = \paren {m n} \cdot \paren {x \circ x}$.	1
: $\left({\neg p \land \neg q}\right) \implies \left({\neg \left({p \lor q}\right)}\right)$	1
:$p \implies q \vdash \neg p \lor q$	1
Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \N_{>0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\displaystyle \forall n \ge 1: \sum_{j \mathop = 1}^n j \paren {j + 1} = \frac {n \paren {n + 1} \paren {n + 2} } 3$ === Basis for the Induction === $\map P 1$ is true, as this just says $1 \times 2 = 2 = \dfrac {1 \times 2 \times 3} 3$. This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\displaystyle \sum_{j \mathop = 1}^k j \paren {j + 1} = \frac {k \paren {k + 1} \paren {k + 2} } 3$ Then we need to show: :$\displaystyle \sum_{j \mathop = 1}^{k + 1} j \paren {j + 1} = \frac {\paren {k + 1} \paren {k + 2} \paren {k + 3} } 3$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \sum_{j \mathop = 1}^{k + 1} j \paren {j + 1} | r = \sum_{j \mathop = 1}^k j \paren {j + 1} + \paren {k + 1} \paren {k + 2} | c = }} {{eqn | r = \frac {k \paren {k + 1} \paren {k + 2} } 3 + \paren {k + 1} \paren {k + 2} | c = [[Sum of Sequence of Products of Consecutive Integers/Proof 1#Induction Hypothesis|Induction hypothesis]] }} {{eqn | r = \frac {k \paren {k + 1} \paren {k + 2} + 3 \paren {k + 1} \paren {k + 2} } 3 | c = }} {{eqn | r = \frac {\paren {k + 1} \paren {k + 2} \paren {k + 3} } 3 | c = }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\displaystyle \forall n \ge 1: \sum_{j \mathop = 1}^n j \paren {j + 1} = \frac {n \paren {n + 1} \paren {n + 2} } 3$ {{qed}}	1
{{BeginTableau|p \implies q \vdash \paren {p \lor r} \implies \paren {q \lor r} }} {{Premise|1|p \implies q}} {{TheoremIntro|2|r \implies r|[[Law of Identity/Formulation 2|Law of Identity: Formulation 2]]}} {{SequentIntro|3|1|\paren {p \lor r} \implies \paren {q \lor r}|1, 2|[[Constructive Dilemma/Formulation 1|Constructive Dilemma]]}} {{EndTableau}} {{qed}}	1
We apply the [[Method of Truth Tables]]. $\begin{array}{|c|ccc||c|} \hline p & p & \implies & q & q\\ \hline F & F & T & F & F \\ F & F & T & T & T \\ T & T & F & F & F \\ T & T & T & T & T \\ \hline \end{array}$ As can be seen, when $p$ is [[Definition:True|true]], and so is $p \implies q$, then $q$ is also [[Definition:True|true]]. {{qed}}	1
=== Outline === The idea of the proof is that since the models are saturated, we can define an isomorphism $f: \NN \to \MM$ by picking the image $\map f x$ of an element $x \in \NN$ as something which realizes the type that $\map f x$ would need to satisfy in $\MM$. This is done using a (transfinite) recursive construction which extends an elementary map at each step. The proof is very similar to that of [[Saturated Implies Universal]]; in both proofs we attempt to construct a formula-preserving map. In this case, however, the map must be bijective between the universes of the models. === Body of Proof === First, since $\MM$ and $\NN$ have cardinality $\kappa$, we can denote their elements by $m_\alpha$ and $n_\alpha$ respectively for ordinals $\alpha < \kappa$. For each $\alpha < \kappa$, let $A_\alpha$ denote the domain of the $f_\alpha$ we define below. Note that we do not know in advance what the domains will be. Base case $\alpha = 0$: Define $f_0 = \O$. Note that $f_0$ is trivially an [[Definition:Elementary Embedding|elementary embedding]] from $A_0 = \O$ into $\MM$. {{qed|lemma}} [[Definition:Limit Ordinal|Limit ordinals]] $\alpha$, assuming $f_\beta: A_\beta \to \MM$ is defined and elementary, and that $\card {A_\beta} < \kappa$ for all $\beta < \alpha$: Let $\displaystyle f_\alpha = \bigcup_{\beta < \alpha} f_\beta$. If $\phi$ is an $\LL$-sentence with parameters from $A_\alpha$, then since it involves only finitely many such parameters, they must all be contained in some $A_\beta$ for $\beta < \alpha$. But $f_\alpha \restriction A_\beta = f_\beta$ is elementary, so $f_\alpha$ must be as well. Note that $\card {A_\alpha} < \kappa$ by [[Cardinality of Infinite Union of Infinite Sets]]. {{qed|lemma}} [[Definition:Successor Ordinal|Successor ordinals]] $\alpha = \beta + 1$, assuming $f_\beta: A_\beta \to \MM$ is defined and elementary, and that $\card {A_\beta} < \kappa$: We need to extend $f_\beta$ to some $f_\alpha$ so that the domain includes $n_\beta$, the image includes $m_\beta$, and so that $\LL$-formulas with parameters from $A_\alpha$ are preserved by $f_\alpha$. First we add $n_\beta$ to the domain: Consider the subset: :$p = \set {\map \phi {v, \map {f_\beta} {\bar a} }: \bar a \text { is a tuple from } A_\beta \text { and } \NN \models \map \phi {n_\beta, \bar a} }$ of the set of $\LL$-formulas with one free variable and parameters from the image $\map {f_\beta} {A_\beta}$ of $A_\beta$ under $f_\beta$. The set $p$ is a $1$-type over the image $\map {f_\beta} {A_\beta}$ in $\MM$. Since $\card {A_\beta} < \kappa$ by the inductive hypothesis and since by assumption $\MM$ is $\kappa$-saturated, this means that $p$ is realized in $\MM$ by some element $b$. Thus $f'_\alpha = f_\beta \cup \set {\tuple {n_\beta, b} }$ is an elementary embedding $A_\beta \cup \set {n_\beta} \to \MM$. Now we add $m_\beta$ to the image: This is done similarly to the above. Consider the subset: :$q = \set {\map \phi {v, \bar a}: \bar a \text { is a tuple from } A_\beta \cup \set {n_\beta} \text { and } \MM \models \map \phi {m_\beta, \map {f'_\alpha} {\bar a} } }$ of the set of $\LL$-formulas with one free variable and parameters from $A_\beta \cup \{n_\beta\}$. The set $q$ is a $1$-type over $A_\beta \cup \{n_\beta\}$ in $\NN$. Since $\card {A_\beta} < \kappa$ by the inductive hypothesis and hence $\card {A_\beta \cup \set {n_\beta} } < \kappa$ as well, and since by assumption $\NN$ is $\kappa$-saturated, this means that $q$ is realized in $\NN$ by some element $c$. Thus $f_\alpha = f'_\alpha \cup \set {\tuple {c, m_\beta} } = f_\beta \cup \set {\tuple {n_\beta, b}, \tuple {c, m_\beta} }$ is an elementary embedding $A_\beta \cup \set {n_\beta} \to \MM$ which includes $m_\beta$ in its range. Finally define $\displaystyle f = \bigcup_{\alpha < \kappa} f_\alpha$. The map $f$ is an elementary embedding $\NN \to \MM$ since $\displaystyle \bigcup_{\alpha < \kappa} A_\alpha = \NN$, any finite set of parameters from $\NN$ must belong to some single $A_\alpha$, and $f\restriction A_\alpha$ is elementary. $f$ is onto $\MM$ since we have constructed it so that $m_\alpha$ is in the image of $f_{\alpha + 1}$. So, $f$ is a bijection. Since elementary embeddings are by definition $\LL$-embeddings, this means that $f$ is an isomorphism by definition. {{qed}} [[Category:Model Theory]] 1mf8vzyw8ow9lnqwkgsdn87sjxzzb2a	1
{{begin-eqn}} {{eqn | l = p \oplus q | o = \dashv \vdash | r = \paren {p \lor q} \land \neg \paren {p \land q} | c = {{Defof|Exclusive Or}} }} {{eqn | o = \dashv \vdash | r = \paren {p \lor q} \land \paren {\neg p \lor \neg q} | c = [[De Morgan's Laws (Logic)/Disjunction of Negations|De Morgan's Laws: Disjunction of Negations]] }} {{end-eqn}} {{qed}}	1
{{BeginTableau|p \vdash p \lor \paren {p \land q} }} {{Premise|1|p}} {{Addition|2|1|p \lor \paren {p \land q}|1|1}} {{EndTableau}} {{qed}}	1
Let $M$ be a [[Definition:Class (Class Theory)|class]]. Let $g: M \to M$ be a [[Definition:Mapping (Class Theory)|mapping]] on $M$. Let $b \in M$ such that $M$ is [[Definition:Minimally Closed Class|minimally closed under $g$ with respect to $b$]]. Let $P: M \to \set {\T, \F}$ be a [[Definition:Propositional Function|propositional function]] on $M$. Suppose that: :$(1): \quad \map P b = \T$ :$(2): \quad \forall x \in M: \map P x = \T \implies \map P {\map g x} = \T$ Then: :$\forall x \in M: \map P x = \T$	1
Let $\mathbf A$ be a [[Definition:WFF of Predicate Logic|WFF of predicate logic]]. Let $\mathcal A$ be a [[Definition:Structure for Predicate Logic|structure for predicate logic]]. Let $\sigma, \sigma'$ be [[Definition:Assignment for Formula|assignments for $\mathbf A$ in $\mathcal A$]] such that: :For each [[Definition:Free Variable|free variable]] $x$ of $\mathbf A$, $\sigma \left({x}\right) = \sigma' \left({x}\right)$ Then: :$\mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\sigma}\right] = \mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\sigma'}\right]$ where $\mathop{ \operatorname{val}_{\mathcal A} \left({\mathbf A}\right) } \left[{\sigma}\right]$ is the [[Definition:Value of Formula under Assignment|value of $\mathbf A$ under $\sigma$]].	1
Let $S \subseteq \Z$ be a [[Definition:Subset|subset]] of the [[Definition:Integer|integers]]. Let $n_0 \in \Z$ be given. Suppose that: :$(1): \quad n_0 \in S$ :$(2): \quad \forall n \ge n_0: \paren {\forall k: n_0 \le k \le n \implies k \in S} \implies n + 1 \in S$ Then: :$\forall n \ge n_0: n \in S$	1
Two [[Definition:Statement|statements]] are said to be '''subcontrary''' if they can both be [[Definition:True|true]], but they cannot both be [[Definition:False|false]].	1
:$p \lor q \dashv \vdash \neg p \implies q$	1
:$(1): \quad p \iff q \vdash p \implies q$ :$(2): \quad p \iff q \vdash q \implies p$	1
: $\vdash \left({p \iff q}\right) \iff \left({\left({p \lor q}\right) \implies \left({p \land q}\right)}\right)$	1
The [[Definition:Function|function]] $f: \N \to \N$, defined as: :$\map f n = a n + b$ where $a$ and $b$ are [[Definition:Constant|constants]], is [[Definition:Primitive Recursive Function|primitive recursive]].	1
A [[Definition:Linear Code|linear code]] $C$ can be obtained from $G$ by: :taking the [[Definition:Set|set]] $U$ of all [[Definition:Finite Sequence|sequences]] of [[Definition:Length of Sequence|length]] $k$ over $\Z_p$ and expressing them as $1 \times k$ [[Definition:Matrix|matrices]] :forming all possible [[Definition:Matrix Product (Conventional)|matrix products]] $u G$ for all $u \in U$.	1
Let $\downarrow$ signify the [[Definition:Logical NOR|NOR]] operation. The following results hold:	1
:$\vdash \paren {\paren {p \land q} \implies r} \iff \paren {p \implies \paren {q \implies r} }$	1
Let $\left({T, \mathbf H, \Phi}\right)$ be a [[Definition:Propositional Tableau|propositional tableau]]. Let $v: \mathcal L_0 \to \left\{{T, F}\right\}$ be a [[Definition:Boolean Interpretation|boolean interpretation]] such that: :$v \models_{\mathrm{BI}} \mathbf H$ that is, such that $v$ is a [[Definition:Model (Boolean Interpretations)|model]] for the [[Definition:Root of Propositional Tableau|root]] $\mathbf H$ of $T$. Then there exists a [[Definition:Branch (Graph Theory)|branch]] $\Gamma$ of $T$ such that: :$v \models_{\mathrm{BI}} \Phi \left[{\Gamma}\right]$ where $\Phi \left[{\Gamma}\right]$ denotes the [[Definition:Image of Subset under Mapping|image]] of $\Gamma$ under $\Phi$.	1
{{BeginTableau|p \lor q, \paren {p \vdash r}, \paren {q \vdash r} \vdash r}} {{Premise | 1 | p \lor q}} {{Assumption | 2 | p}} {{TableauLine | n = 3 | pool = 2 | f = r | rlnk = Definition:By Hypothesis | rtxt = By hypothesis | dep = 2 | c = as $p \vdash r$ }} {{Assumption | 4 | q }} {{TableauLine | n = 5 | pool = 4 | f = r | rlnk = Definition:By Hypothesis | rtxt = By hypothesis | dep = 4 | c = as $q \vdash r$ }} {{ProofByCases | 6 | 1 | r | 1 | 2 | 3 | 4 | 5}} {{EndTableau}} {{qed}}	1
We apply the [[Method of Truth Tables]] to the propositions in turn. As can be seen for all [[Definition:Boolean Interpretation|boolean interpretations]] by inspection, where the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] on the {{LHS}} (that is, the rightmost $\land$) is $T$, that under the instance of $r$ on the {{RHS}} is also $T$: $\begin{array}{|ccccccccc||c|} \hline ((p & \implies & q) & \land & (q & \implies & r)) & \land & p & r \\ \hline F & T & F & T & F & T & F & F & F & F \\ F & T & F & T & F & T & T & F & F & T \\ F & T & T & F & T & F & F & F & F & F \\ F & T & T & T & T & T & T & F & F & T \\ T & F & F & F & F & T & F & F & T & F \\ T & F & F & F & F & T & T & F & T & T \\ T & T & T & F & T & F & F & F & T & F \\ T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ Hence the result. {{qed}}	1
: $p \implies q, \neg q \vdash \neg p$	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth value]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] is [[Definition:True|true]] for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{ccccc|c|ccccccc} (p & \implies & (q & \implies & r)) & \implies & ((p & \implies & q) & \implies & (p & \implies & r)) \\ \hline F & T & F & T & F & T & F & T & F & T & F & T & F \\ F & T & F & T & T & T & F & T & F & T & F & T & T \\ F & T & T & F & F & T & F & T & T & T & F & T & F \\ F & T & T & T & T & T & F & T & T & T & F & T & T \\ T & T & F & T & F & T & T & F & F & T & T & F & F \\ T & T & F & T & T & T & T & F & F & T & T & T & T \\ T & F & T & F & F & T & T & T & T & F & T & F & F \\ T & T & T & T & T & T & T & T & T & T & T & T & T \\ \end{array}$	1
Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \N_{>0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\displaystyle \sum_{j \mathop = 1}^n F_{2 j - 1} = F_{2 n}$ === Basis for the Induction === $\map P 1$ is the case $F_1 = 1 = F_2$, which holds from the definition of [[Definition:Fibonacci Numbers|Fibonacci numbers]]. This is our [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$\displaystyle \sum_{j \mathop = 1}^k F_{2 j - 1} = F_{2 k}$ Then we need to show: :$\displaystyle \sum_{j \mathop = 1}^{k + 1} F_{2 j - 1} = F_{2 k + 2}$ === Induction Step === This is our [[Principle of Mathematical Induction#Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \sum_{j \mathop = 1}^{k + 1} F_{2 j - 1} | r = \sum_{j \mathop = 1}^k F_{2 j - 1} + F_{2 k + 1} | c = }} {{eqn | r = F_{2 k} + F_{2 k + 1} | c = [[Sum of Sequence of Odd Index Fibonacci Numbers#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = F_{2 k + 2} | c = Definition of [[Definition:Fibonacci Numbers|Fibonacci Numbers]] }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\displaystyle \forall n \ge 1: \sum_{j \mathop = 1}^n F_{2 j - 1} = F_{2 n}$ {{qed}}	1
: $\vdash \left({p \lor p}\right) \implies p$	1
[[Definition:Conjunction|Conjunction]] is [[Definition:Associative Operation|associative]]: === [[Rule of Association/Conjunction/Formulation 1|Formulation 1]] === {{:Rule of Association/Conjunction/Formulation 1}} === [[Rule of Association/Conjunction/Formulation 2|Formulation 2]] === {{:Rule of Association/Conjunction/Formulation 2}}	1
: $p \lor q \vdash \neg \left({\neg p \land \neg q}\right)$	1
Let $S \subseteq \N_{>0}$ denote the [[Definition:set|set]] of [[Definition:Strictly Positive Integer|(strictly positive)]] [[Definition:Natural Number|natural numbers]] for which $(1)$ holds. === Basis for the Induction === We have: {{begin-eqn}} {{eqn | l = 2^1 - 1 | r = 2 - 1 | c = }} {{eqn | r = 1 | c = }} {{eqn | r = 2^0 | c = }} {{eqn | r = \sum_{j \mathop = 0}^{1 - 1} 2^j | c = }} {{end-eqn}} So $1 \in S$. This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === We now show that, if $k \in S$ is true, where $k \ge 1$, then it logically follows that $k + 1 \in S$. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\displaystyle \sum_{j \mathop = 0}^{k - 1} 2^j = 2^k - 1$ Then we need to show: :$\displaystyle \sum_{j \mathop = 0}^k 2^j = 2^{k + 1} - 1$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \sum_{j \mathop = 0}^k 2^j | r = \sum_{j \mathop = 0}^{k - 1} 2^j + 2^k | c = }} {{eqn | r = 2^k - 1 + 2^k | c = [[Sum of Powers of 2/Proof 2#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = 2 \times 2^k - 1 | c = }} {{eqn | r = 2^{k + 1} - 1 | c = }} {{end-eqn}} So $k \in S \implies k + 1 \in S$. It follows by the [[Principle of Finite Induction]] that $S = \N_{>0}$. That is: :$\displaystyle \forall n \in \N_{> 0}: \sum_{j \mathop = 0}^{n - 1} 2^j = 2^n - 1$ {{qed}}	1
{{BeginTableau|\neg \left({p \land q}\right) \vdash \neg p \lor \neg q}} {{Premise|1|\neg \left({p \land q}\right)}} {{Assumption|2|\neg \left ({\neg p \lor \neg q}\right)}} {{Assumption|3|\neg p}} {{Addition|4|3|\neg p \lor \neg q|3|1}} {{NonContradiction|5|2, 3|4|2}} {{Reductio|6|2|p|3|5}} {{Assumption|7|\neg q}} {{Addition|8|7|\neg p \lor \neg q|7|2}} {{NonContradiction|9|2, 7|8|2}} {{Reductio|10|2|q|7|9}} {{Conjunction|11|2|p \land q|6|10}} {{NonContradiction|12|1, 2|11|1}} {{Reductio|13|1|\neg p \lor \neg q|2|12}} {{EndTableau}} {{qed}} {{LEM|Reductio ad Absurdum}}	1
We apply the [[Method of Truth Tables]]. $\begin{array}{|ccccccc||ccc|} \hline (p & \implies & q) & \land & (q & \implies & p) & p & \iff & q\\ \hline F & T & F & T & F & T & F & F & T & F \\ F & T & T & F & T & F & F & F & F & T \\ T & F & F & F & F & T & T & T & F & F \\ T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ As can be seen, only when both $p \implies q$ and $q \implies p$ are [[Definition:True|true]], then so is $p \iff q$. {{qed}}	1
{{ProofWanted|working on it, it's fiddly}}	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc||cccc|} \hline \neg & p & \lor & \neg & q & \neg & (p & \land & q) \\ \hline T & F & T & T & F & T & F & F & F \\ T & F & T & F & T & T & F & F & T \\ F & T & T & T & F & T & T & F & F \\ F & T & F & F & T & F & T & T & T \\ \hline \end{array}$ {{qed}}	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc||ccccc|} \hline p & \land & q & \neg & (p & \implies & \neg & q) \\ \hline F & F & F & F & F & T & T & F \\ F & F & T & F & F & T & F & T \\ T & F & F & F & T & T & T & F \\ T & T & T & T & T & F & F & T \\ \hline \end{array}$ {{qed}}	1
: $p \implies q, r \implies s \vdash p \lor r \implies q \lor s$	1
:$p \implies q \dashv \vdash p \iff \left({p \land q}\right)$	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|cccccccc||c|} \hline (p & \implies & q) & \land & (\neg & p & \implies & q) & q \\ \hline F & T & F & F & T & F & F & F & F \\ F & T & T & T & T & F & T & T & T \\ T & F & F & F & F & T & T & F & F \\ T & T & T & T & F & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
:$\vdash q \implies \left({p \lor q}\right)$	1
=== 2 iff 3 === Let $a_n - b_n = \map o {b_n}$. Let $0 < \epsilon < 1/2$. Then {{begin-eqn}} {{eqn | l = \epsilon \cdot \size {b_n} | o = \ge | r = \size {a_n - b_n} | c = For $n$ [[Definition:Sufficiently Large|sufficiently large]] }} {{eqn | r = \paren {1 - \epsilon} \size {a_n - b_n} + \epsilon \cdot \size {a_n - b_n} | c = }} {{eqn | o = \ge | r = \paren {1 - \epsilon} \size {a_n - b_n} - \epsilon \cdot \size {a_n} + \epsilon \cdot \size {b_n} | c = [[Triangle Inequality]] }} {{end-eqn}} So $\size {a_n - b_n} \le \dfrac {\epsilon \cdot \size {a_n} } {1 - \epsilon} \le 2 \epsilon \cdot \size {a_n}$. Thus $a_n - b_n = \map o {a_n}$. The other implication follows by symmetry. {{qed|lemma}} === 1 iff 2 === {{begin-eqn}} {{eqn | l = \lim_{n \to \infty} \dfrac {a_n} {b_n} | o = \to | r = 1 }} {{eqn | ll = \leadstoandfrom | l = \lim_{n \to \infty} \paren {\dfrac {a_n} {b_n} - \dfrac {b_n} {b_n} } | o = \to | r = 0 }} {{eqn | ll = \leadstoandfrom | l = \lim_{n \to \infty} \dfrac {a_n - b_n} {b_n} | o = \to | r = 0 }} {{eqn | ll = \leadstoandfrom | l = a_n - b_n | r = \map o {b_n} }} {{end-eqn}} {{qed}} [[Category:Asymptotic Notation]] d46q51xbla75ikhfwlgi0fbzo6j4d6p	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, in each case, the [[Definition:Truth Value|truth values]] in the appropriate columns match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|c|c||ccc|} \hline p & \top & p & \lor & \top \\ \hline F & T & F & T & T \\ T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
:$p \land q \dashv \vdash q \land p$	1
Let $Q$ be a [[Definition:Valid Argument|valid]] [[Definition:Categorical Syllogism|categorical syllogism]] in [[Definition:Fourth Figure of Categorical Syllogism|Figure $\text {IV}$]]. Then it is a [[Definition:Necessary Condition|necessary condition]] that: :$(1): \quad$ Either: :: the [[Definition:Major Premise of Syllogism|major premise]] of $Q$ be a [[Definition:Negative Categorical Statement|negative categorical statement]] :or: :: the [[Definition:Minor Premise of Syllogism|minor premise]] of $Q$ be a [[Definition:Universal Categorical Statement|universal categorical statement]] :or both. :$(2): \quad$ If the [[Definition:Conclusion of Syllogism|conclusion]] of $Q$ be a [[Definition:Negative Categorical Statement|negative categorical statement]], then the [[Definition:Major Premise of Syllogism|major premise]] of $Q$ be a [[Definition:Universal Categorical Statement|universal categorical statement]]. :$(3): \quad$ If the [[Definition:Conclusion of Syllogism|conclusion]] of $Q$ be a [[Definition:Universal Categorical Statement|universal categorical statement]], then the [[Definition:Minor Premise of Syllogism|minor premise]] of $Q$ be a [[Definition:Negative Categorical Statement|negative categorical statement]].	1
{{BeginTableau|\neg \paren {p \land q}, p \vdash \neg q}} {{Premise|1|\neg \paren {p \land q} }} {{Premise|2|p}} {{Assumption|3|q}} {{Conjunction|4|2, 3|p \land q|2|3}} {{NonContradiction|5|1, 2, 3|4|1}} {{Contradiction|6|1, 2|\neg q|3|5}} {{EndTableau}} {{qed}}	1
Let $S_p$ be the [[Definition:Initial Segment|set of all elements of $S$ preceding $p$]]: :$S_p = \set {x \in S: x \prec p}$ Let $T' = T \cup S_p$. Then the set $T'$ satisfies the conditions of the [[Principle of Mathematical Induction for Naturally Ordered Semigroup|Principle of Mathematical Induction for a Naturally Ordered Semigroup]]. From that result: :$T' = S$ By [[Set Difference with Union is Set Difference]]: :$S \setminus S_p = T \setminus S_p$ By [[Set Difference is Subset]]: :$T \setminus S_p \subseteq T$ completing the proof. {{qed}}	1
{{BeginTableau|\paren {p \vdash \bot} \vdash \neg p}} {{Premise |1|p \vdash \bot}} {{Assumption |2|p}} {{Contradiction|3|1|\neg p|2|2}} {{EndTableau}} {{Qed}} [[Category:Proof by Contradiction]] s213zzvegzbnzr2r7p55j1sgvbbcsk8	1
We have that: {{begin-eqn}} {{eqn | l = \frac 3 {25} | r = \frac 1 9 + \frac 2 {225} | c = as $\ceiling {25 / 3} = \ceiling {8.333\ldots} = 9$ }} {{eqn | r = \frac 1 9 + \frac 1 {113} + \frac 1 {25 \, 425} | c = as $\ceiling {225 / 2} = \ceiling {112.5} = 113$ }} {{end-eqn}} But then we have: {{begin-eqn}} {{eqn | l = \frac 3 {25} | r = \frac 6 {50} | c = }} {{eqn | r = \frac 5 {50} + \frac 1 {50} | c = }} {{eqn | r = \frac 1 {10} + \frac 1 {50} | c = }} {{end-eqn}} By [[Condition for 3 over n producing 3 Egyptian Fractions using Greedy Algorithm when 2 Sufficient]], we are to find the smallest $n$ such that: :$n \equiv 1 \pmod 6$ :$\exists d: d \divides n$ and $d \equiv 2 \pmod 3$ The first few $n \ge 4$ which satisfies $n \equiv 1 \pmod 6$ are: :$7, 13, 19, 25$ of which $7, 13, 19$ are [[Definition:Prime Number|primes]], so they do not have a [[Definition:Divisor of Integer|divisor]] of the form $d \equiv 2 \pmod 3$. We see that $5 \divides 25$ and $5 \equiv 2 \pmod 3$. Hence the result. {{qed}}	1
By definition, we have that the [[Definition:Characteristic Function of Set|characteristic function]] $\chi_{\N \mathop \setminus S} \left({n}\right) = 1$ {{iff}} $\chi_S \left({n}\right) = 0$. So: : $\chi_{\N \mathop \setminus S} \left({n}\right) = \chi_{\left\{{0}\right\}} \left({\chi_S \left({n}\right)}\right)$ Thus $\chi_{\N \mathop \setminus S}$ is obtained by [[Definition:Substitution (Mathematical Logic)|substitution]] from $\chi_{\left\{{0}\right\}}$ and $\chi_S$. The result follows from [[Set Containing Only Zero is Primitive Recursive]]. {{qed}} [[Category:Primitive Recursive Functions]] [[Category:Relative Complement]] e3bgbvgrhzig0xzivxy54xijrzynxu7	1
The proof proceeds by [[Principle of General Induction for Minimally Closed Class|general induction]]. Let $x \in M$ be [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$ Let $\map P y$ be the [[Definition:Proposition|proposition]]: :$\map \RR {x, y}$ holds. === Basis for the Induction === By condition $\text D_1$ of the definition of $\RR$: :$\map \RR {x, b}$ for all $x \in M$. Thus $\map P \O$ is seen to hold. This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that if $\map P y$ is true, where $x \in M$, then it logically follows that $\map P {\map g y}$ is true. So this is the [[Definition:Induction Hypothesis|induction hypothesis]]: :$\map \RR {x, y}$ holds from which it is to be shown that: :$\map \RR {x, \map g y}$ holds === Induction Step === This is the [[Definition:Induction Step|induction step]]: Let $\map \RR {x, y}$ hold. As $x$ is [[Definition:Right Normal Element of Relation|right normal]] with respect to $\RR$: :$\map \RR {y, x}$ holds. Thus by condition $\text D_2$ of the definition of $\RR$: :$\map \RR {x, \map g y}$ holds. So $\map P x \implies \map P {\map g x}$ and the result follows by the [[Principle of General Induction]]. Therefore: :$\forall x \in M$: if $x$ is a [[Definition:Right Normal Element of Relation|right normal element]] of $M$ with respect to $\RR$, then $x$ is a [[Definition:Left Normal Element of Relation|left normal element]] of $M$ with respect to $\RR$ {{qed}} [[Category:Double Induction Principle]] dh3hayz3877232k9wavgxn0bn5rqq4k	1
Consider the [[Definition:Natural Numbers|natural numbers]] $\N$ defined as the [[Definition:Naturally Ordered Semigroup|naturally ordered semigroup]] $\struct {S, \circ, \preceq}$. From its definition, $\struct {S, \circ, \preceq}$ is [[Definition:Well-Ordered Set|well-ordered]] by $\preceq$. The result follows. As $\N_{\ne 0} = \N \setminus \set 0$, by [[Set Difference is Subset]] $\N_{\ne 0} \subseteq \N$. As $\N$ is [[Definition:Well-Ordered Set|well-ordered]], by definition, every subset of $\N$ has a [[Definition:Smallest Element|smallest element]]. {{qed}}	1
:$\left({p \oplus q}\right) \oplus q \dashv \vdash p$	1
From the [[Definition:Primitive Recursion|definition]]: :$\forall n \in \N: h \left({n_1, n_2, \ldots, n_k, n}\right) = \begin{cases} f \left({n_1, n_2, \ldots, n_k}\right) & : n = 0 \\ g \left({n_1, n_2, \ldots, n_k, n-1, h \left({n_1, n_2, \ldots, n_k, n-1}\right)}\right) & : n > 0 \end{cases}$ Let $P$ and $Q$ be [[Normalized URM Program|normalized URM programs]] which [[Definition:URM Computability|compute]] $f$ and $g$ respectively. Let $s = \lambda \left({P}\right)$ and $t = \lambda \left({Q}\right)$ be the [[Definition:Unlimited Register Machine#Length of Program|number of basic instructions]] in $P$ and $Q$. Let $u = \max \left\{{\rho \left({P}\right), \rho \left({Q}\right), k+2}\right\}$. Thus [[Definition:Unlimited Register Machine#Registers|registers]] $R_{u+1}, R_{u+2}, \ldots$ are neither used by $P$ nor $Q$ nor for [[Definition:Unlimited Register Machine#Input|input]]. So they can be used for storing values. The following [[Definition:Algorithm|algorithm]] can be followed to create a [[Definition:URM Program|URM program]] $H$ to [[Definition:URM Computability|compute]] $h$. We assume that the [[Definition:Unlimited Register Machine#Input|input]] is $\left({n_1, n_2, \ldots, n_k, n}\right)$, which is held in $R_1, R_2, \ldots, R_k, R_{k+1}$. The plan is that the program will compute $h \left({n_1, n_2, \ldots, n_k, i}\right)$ for $i = 0, 1, 2, \ldots, n$ in order. At the end of the last iteration, $h \left({n_1, n_2, \ldots, n_k, n}\right)$ will be left in $R_1$. We are to use the following registers: * $R_{u+1}, R_{u+2}, \ldots, R_{u+k+1}$ will be used to store the input $\left({n_1, n_2, \ldots, n_k, n}\right)$ so it does not get overwritten. We note that $R_{u+k+1}$ will hold the value of $n$. * $R_{u+k+2}$ will hold the current value of the recursion variable $i$. When $r_{u+k+2} = r_{u+k+1}$, the computation will have ended. {| border="1" |- ! align="right" | Step !! ! align="left" | Process ! align="left" | Notes ! align="left" | $\lambda \left({H}\right)$ |- | align="right" | $1$ || | align="left" | Append a [[Block Copy Program]] $C \left({1, u+1, k+1}\right)$ to $H$<ref>$H$, at this point, is a [[Definition:Null URM Program|null URM program]].</ref>. | This stores the input somewhere safe so it can be accessed again later. | $k + 1$ |- | align="right" | $2$ || | align="left" | Append $Z \left({k+1}\right)$ to $H$. | This clears $R_{k+1}$ so that $R_1, R_2, \ldots, R_{k+1}$ holds the input for calculating $f$. | $k + 2$ |- | align="right" | $3$ || | align="left" | Increment the <tt>Jump</tt>s in $P$ by $k+2$ lines<ref>To '''increment the <tt>Jump</tt>s by $r$''' for any [[Normalized URM Program|normalized URM program]] is done by changing all <tt>Jump</tt>s of the form $J \left({m, n, q}\right)$ to $J \left({m, n, q+r}\right)$.</ref>. Call this amended version $P'$. | As $P$ was written so as to start from line 1, we need to move all the <tt>Jump</tt>s so as to point to the same lines relative to the start of $P'$. |- | align="right" | $4$ || | align="left" | Append $P'$ to $H$. | This will compute $h \left({n_1, n_2, \ldots, n_k, n}\right) = f \left({n_1, n_2, \ldots, n_k}\right)$. | $k + s + 2$ |- | align="right" | $5$ || | align="left" | Append the command $J \left({u+k+1, u+k+2, k+s+t+8}\right)$ to $H$. | If the iterator equals the value of $n$ that was input, this <tt>Jump</tt>s $H$ to a non-existent line to force $H$ to [[Definition:Unlimited Register Machine#Termination|terminate]]. | $k + s + 3$ |- | align="right" | $6$ || | align="left" | Append the command $C \left({1, k+2}\right)$ to $H$. | This copies the [[Definition:Unlimited Register Machine#Output|output]] of $P'$ into the last input location for function $g$, that is, the output from $h \left({n_1, n_2, \ldots, n_k, i-1}\right)$. | $k + s + 4$ |- | align="right" | $7$ || | align="left" | Append the command $C \left({u+k+2, k+1}\right)$ to $H$. | This moves the current contents of $R_{u+k+2}$, the current iteration count, into the last but one input location for function $g$, that is, $i-1$ itself. | $k + s + 5$ |- | align="right" | $8$ || | align="left" | Append a [[Block Copy Program]] $C \left({u+1, 1, k}\right)$ to $H$. | This restores the input that we saved in step $1$ so it will be ready for program $Q$. | $2 k + s + 5$ |- | align="right" | $9$ || | align="left" | Append the command $S \left({u+k+2}\right)$ to $H$. | This increments the iterator $i$. | $2 k + s + 6$ |- | align="right" | $10$ || | align="left" | Calculate $l = \lambda \left({H}\right)$. | This is the [[Definition:Unlimited Register Machine#Length of Program|length]] of $H$ so far. |- | align="right" | $11$ || | align="left" | Increment the <tt>Jump</tt>s in $Q$ by $k + l$ lines. Call this amended version $Q'$. | As $Q$ was written so as to start from line 1, we need to move all the <tt>Jump</tt>s so as to point to the same lines relative to the start of $Q'$. |- | align="right" | $12$ || | align="left" | Append $Q'$ to $H$. | This will compute $h \left({n_1, n_2, \ldots, n_k, n}\right) = f \left({n_1, n_2, \ldots, n_k}\right)$. | $2 k + s + t + 6$ |- | align="right" | $13$ || | align="left" | Append the command $J \left({1, 1, k + s + 3}\right)$ to $H$. | This makes the program jump back to the command added at step $6$. | $2 k + s + t + 7$ |} The program $H$ finally looks like this: {| |- ! align="right" | Line !! ! align="left" | Command !! ! align="left" | Comment |- | align="right" | $1$ || | align="left" | $C \left({1, u+1}\right)$ || | Start of block copy of input to store. |- | align="right" | || | align="left" | $\vdots$ || | |- | align="right" | $k+1$ || | align="left" | $C \left({k+1, u+k+1}\right)$ || | End of block copy of input to store. |- | align="right" | $k+2$ || | align="left" | $Z \left({k+1}\right)$ || | Clear the iterator to zero. |- | align="right" | $k+3$ || | align="left" | || | Start of $P'$. |- | align="right" | || | align="left" | $P'$ || | |- | align="right" | $k+s+2$ || | align="left" | || | End of $P'$. |- | align="right" | $k+s+3$ || | align="left" | $J \left({u+k+1, u+k+2, k+s+t+8}\right)$ || | If all the iterations have finished, jump to the [[Definition:Unlimited Register Machine#Termination|exit line]]. |- | align="right" | $k+s+4$ || | align="left" | $C \left({1, k+2}\right)$ || | Copy the [[Definition:Unlimited Register Machine#Output|output]] of $P'$ into input of $Q'$. |- | align="right" | $k+s+5$ || | align="left" | $C \left({u+k+2, k+1}\right)$ || | Copy the current iteration count input location for function $Q'$. |- | align="right" | $k+s+6$ || | align="left" | $C \left({u+1, 1}\right)$ || | Start of block copy of stored input back to input of $Q'$. |- | align="right" | || | align="left" | $\vdots$ || | |- | align="right" | $2k+s+5$ || | align="left" | $C \left({u+k, k}\right)$ || | End of block copy of stored input back to input of $Q'$. |- | align="right" | $2k+s+6$ || | align="left" | $S \left({u+k+2}\right)$ || | Increment the iterator. |- | align="right" | $2k+s+7$ || | align="left" | || | Start of $Q'$. |- | align="right" | || | align="left" | $Q'$ || | |- | align="right" | $2k+s+t+6$ || | align="left" | || | End of $Q'$. |- | align="right" | $2k+s+t+7$ || | align="left" | $J \left({1, 1, k + s + 3}\right)$ || | Jump back to start the next iteration through $Q'$. |- | align="right" | $2k+s+t+8$ || | align="left" | Empty || | [[Definition:Unlimited Register Machine#Termination|Exit line]]. |} It can easily be determined that $H$ computes $h$. Hence $h$ is [[Definition:URM Computability|URM computable]]. {{qed}}	1
From the definition of [[Definition:Little-O|little-O notation]]: :there exists a [[Definition:Neighborhood of Point in Topological Space|neighborhood]] $U$ of $x_0$ such that $\norm {\map f x} \le \norm {\map g x}$ for all $x \in U$. By definition of [[Definition:Big-O|big-$\OO$ notation]], $f = \map \OO g$ as $x \to x_0$. {{qed}} [[Category:Asymptotic Notation]] [[Category:Order Notation]] m96cmklqesjtl62cy9wwf2wxtn5d0wc	1
In a [[Definition:Compound Statement|compound statement]], exactly '''one''' of its [[Definition:Logical Connective|logical connectives]] has the largest [[Definition:Scope (Logic)|scope]]. That [[Definition:Logical Connective|connective]] is called the '''main connective'''. The [[Definition:Scope (Logic)|scope]] of the '''main connective''' comprises the entire [[Definition:Compound Statement|compound statement]]. {{transclude:Definition:Main Connective/Propositional Logic |section = def |title = Propositional Logic |link = true |header = 3 |increase = 1 }}	1
Let $\Theta$ be the set of [[Definition:Gödel Number|Gödel numbers]] of the theorems in $T$. We have that $T$ is a [[Definition:Consistent (Logic)|consistent]] extension of $Q$. By [[Set of Gödel Numbers of Arithmetic Theorems Not Definable in Arithmetic]], $\Theta$ is not a [[Definition:Definable#Definable Set|definable set]] in $T$. Since [[Recursive Sets are Definable in Arithmetic]], this means that $\Theta$ is not [[Definition:Recursive Set|recursive]]. {{AimForCont}} $T$ were [[Definition:Recursive Set|recursive]]. Then by [[Gödel Numbering is Recursive]], we could recursively go from $\Theta$ to $T$. Then using the recursivity of $T$, we could then recursively go back to $\Theta$. Thus $\Theta$ would be [[Definition:Recursive Set|recursive]]. This would be a [[Definition:Contradiction|contradiction]]. Thus, by [[Proof by Contradiction]], $T$ is not [[Definition:Recursive Set|recursive]]. {{qed}}	1
We apply the [[Method of Truth Tables]] to the proposition. As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connective]] are [[Definition:True|true]] for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccccc|c|ccccc|} \hline (p & \implies & (q & \implies & r)) & \implies & ((p & \land & q) & \implies & r) \\ \hline F & T & F & T & F & T & F & F & F & T & F \\ F & T & F & T & T & T & F & F & F & T & T \\ F & T & T & F & F & T & F & F & T & T & F \\ F & T & T & T & T & T & F & F & T & T & T \\ T & T & F & T & F & T & T & F & F & T & F \\ T & T & F & T & T & T & T & F & F & T & T \\ T & F & T & F & F & T & T & T & T & F & F \\ T & T & T & T & T & T & T & T & T & T & T \\ \hline \end{array}$ {{qed}}	1
Let $\mathcal M$ be an [[Definition:First-Order Structure|$\mathcal L$-structure]]. Let $A$ be a subset of the universe of $\mathcal M$. Let $p$ be an [[Definition:Type|$n$-type]] over $A$. There exists an [[Definition:Elementary Extension|elementary extension]] of $\mathcal M$ which [[Definition:Realization|realizes]] $p$.	1
A [[Definition:Contradiction|contradiction]] implies and is implied by the [[Definition:Logical Not|negation]] of a [[Definition:Tautology|tautology]]: :$\bot \dashv \vdash \neg \top$ That is, a falsehood can not be true, and a non-truth is a falsehood.	1
:$\set {\neg, \land, \lor}$: [[Definition:Logical Not|Not]], [[Definition:Conjunction|And]] and [[Definition:Disjunction|Or]]	1
{{BeginTableau|\left({p \implies q}\right) \land \left({r \implies s}\right) \vdash \left({p \land r}\right) \implies \left({q \land s}\right)}} {{Premise|1|\left({p \implies q}\right) \land \left({r \implies s}\right)}} {{Simplification|2|1|p \implies q|1|1}} {{Simplification|3|1|r \implies s|1|2}} {{Assumption|4|p \land r}} {{Simplification|5|4|p|4|1}} {{Simplification|6|4|r|4|2}} {{ModusPonens|7|1, 4|q|2|5}} {{ModusPonens|8|1, 4|s|3|6}} {{Conjunction|9|1, 4|q \land s|7|8|}} {{Implication|10|1|\left({p \land r}\right) \implies \left({q \land s}\right)|4|9}} {{EndTableau}} {{qed}}	1
Let $T$ be a [[Definition:Finitely Satisfiable|finitely satisfiable]] [[Definition:Mathematical Theory|$\mathcal L$-theory]]. Then there exists a [[Definition:Finitely Satisfiable|finitely satisfiable]] $\mathcal L$-theory $T'$ which contains $T$ as a [[Definition:Subset|subset]] such that: :for all $\mathcal L$-sentences $\phi$, either $\phi \in T'$ or $\neg \phi \in T'$.	1
:$\left({p \vdash q}\right) \vdash p \implies q$	1
Proof by [[Principle of Mathematical Induction|induction]]: === Basis for the Induction === When $n = 1$, we have: :$\displaystyle \sum_{i \mathop = 1}^1 i = 1$ Also: :$\dfrac {n \paren {n + 1} } 2 = \dfrac {1 \cdot 2} 2 = 1$ This is our [[Definition:Basis for the Induction|base case]]. === Induction Hypothesis === :$\forall k \in \N: k \ge 1: \displaystyle \sum_{i \mathop = 1}^k i = \frac {k \paren {k + 1} } 2$ This is our [[Definition:Induction Hypothesis|induction hypothesis]]. It is to be demonstrated that: :$\displaystyle \sum_{i \mathop = 1}^{k + 1} i = \frac {\paren {k + 1} \paren {k + 2} } 2$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: Consider $n = k + 1$. By the properties of [[Definition:Summation|summation]]: :$\displaystyle \sum_{i \mathop = 1}^{k + 1} i = \sum_{i \mathop = 1}^k i + k + 1$ Using the [[Closed Form for Triangular Numbers/Proof by Induction#Induction Hypothesis|induction hypothesis]] this can be simplified to: {{begin-eqn}} {{eqn | l = \frac {k \paren {k + 1} } 2 + k + 1 | r = \frac {k \paren {k + 1} + 2 k + 2} 2 | c = }} {{eqn | r = \frac {k^2 + 3 k + 2} 2 | c = }} {{eqn | r = \frac {\paren {k + 1} \paren {k + 2} } 2 | c = }} {{eqn | r = \frac {\paren {k + 1} \paren {\paren {k + 1} + 1} } 2 | c = }} {{end-eqn}} Hence the result by [[Principle of Mathematical Induction|induction]]. {{qed}}	1
: $\neg \left({p \land q}\right) \vdash \neg p \lor \neg q$	1
Let $\exists r, s \in S: r \wedge \neg r = a, \ s \wedge \neg s = b$ Then: {{begin-eqn}} {{eqn | l = a | r = r \wedge \neg r | c = [[Definition:By Hypothesis|by hypothesis]] }} {{eqn | r = \paren {s \wedge \neg s} \vee \paren {r \wedge \neg r} | c = [[Definition:Boolean Algebra/Axioms/Definition 2|Boolean Algebra: Axiom $(BA_2 \ 5)$]] }} {{eqn | r = \paren {r \wedge \neg r} \vee \paren {s \wedge \neg s} | c = [[Definition:Boolean Algebra/Axioms/Definition 2|Boolean Algebra: Axiom $(BA_2 \ 1)$]] }} {{eqn | r = s \wedge \neg s | c = [[Definition:Boolean Algebra/Axioms/Definition 2|Boolean Algebra: Axiom $(BA_2 \ 5)$]] }} {{eqn | r = b | c = [[Definition:By Hypothesis|by hypothesis]] }} {{end-eqn}} Thus, whatever $r$ and $s$ may be: : $r \wedge \neg r = s \wedge \neg s$ This [[Definition:Unique|unique]] element can be assigned the [[Definition:Symbol|symbol]] $\bot$ and named '''bottom''' as required. {{qed}}	1
The function $g$ satisfies: * $g \left({n_1, n_2, \ldots, n_k, z}\right) = 0$ * $g \left({n_1, n_2, \ldots, n_k, z+1}\right) = g \left({n_1, n_2, \ldots, n_k, z}\right) \times f \left({n_1, n_2, \ldots, n_k, z + 1}\right)$ Hence $g$ is defined by [[Definition:Primitive Recursion|primitive recursion]] from: * the [[Addition is Primitive Recursive|primitive recursive function $\operatorname{mult}$]] * $f$, which is [[Definition:Primitive Recursive Function|primitive recursive]] * and [[Constant Function is Primitive Recursive|constants, which are primitive recursive]]. Hence the result. {{Qed}}	1
{{handwaving}} By the [[Definition:Definitional Abbreviation|definitional abbreviation]] for the [[Definition:Conditional|conditional]]: :$\mathbf A \implies \mathbf B =_{\text{def}} \neg \mathbf A \lor \mathbf B$ the [[Factor Principles/Disjunction on Left/Formulation 2|Factor Principle]] can be written as: :$\neg \left({\neg p \lor q}\right) \lor \left({\neg \left({r \lor p}\right) \lor \left ({r \lor q}\right)}\right)$ This evaluates as follows: :$\begin{array}{|ccccc|c|cccccccc|} \hline \neg & (\neg & p & \lor & q) & \lor & (\neg & (r & \lor & p) & \lor & (r & \lor & q)) \\ \hline 1 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 0 & 1 & 0 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\ 2 & 1 & 0 & 2 & 2 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 2 \\ 1 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\ 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 1 \\ 1 & 0 & 1 & 0 & 2 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 2 \\ 1 & 2 & 2 & 0 & 0 & 0 & 1 & 0 & 0 & 2 & 0 & 0 & 0 & 0 \\ 2 & 2 & 2 & 2 & 1 & 0 & 1 & 0 & 0 & 2 & 0 & 0 & 0 & 1 \\ 1 & 2 & 2 & 0 & 2 & 0 & 1 & 0 & 0 & 2 & 0 & 0 & 0 & 2 \\ 1 & 1 & 0 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 1 & 0 & 0 \\ 0 & 1 & 0 & 1 & 1 & 0 & 1 & 1 & 0 & 0 & 1 & 1 & 1 & 1 \\ 2 & 1 & 0 & 2 & 2 & 0 & 1 & 1 & 0 & 0 & 2 & 1 & 2 & 2 \\ 1 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 0 & 1 & 0 & 0 \\ 1 & 0 & 1 & 0 & 1 & 0 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 1 \\ 1 & 0 & 1 & 0 & 2 & 0 & 0 & 1 & 1 & 1 & 0 & 1 & 2 & 2 \\ 1 & 2 & 2 & 0 & 0 & 0 & 2 & 1 & 2 & 2 & 0 & 1 & 0 & 0 \\ 2 & 2 & 2 & 2 & 1 & 0 & 2 & 1 & 2 & 2 & 2 & 1 & 1 & 1 \\ 1 & 2 & 2 & 0 & 2 & 0 & 2 & 1 & 2 & 2 & 0 & 1 & 2 & 2 \\ 1 & 1 & 0 & 0 & 0 & 0 & 1 & 2 & 0 & 0 & 0 & 2 & 0 & 0 \\ 0 & 1 & 0 & 1 & 1 & 0 & 1 & 2 & 0 & 0 & 2 & 2 & 2 & 1 \\ 2 & 1 & 0 & 2 & 2 & 0 & 1 & 2 & 0 & 0 & 0 & 2 & 0 & 2 \\ 1 & 0 & 1 & 0 & 0 & 0 & 2 & 2 & 2 & 1 & 0 & 2 & 0 & 0 \\ 1 & 0 & 1 & 0 & 1 & 0 & 2 & 2 & 2 & 1 & 0 & 2 & 2 & 1 \\ 1 & 0 & 1 & 0 & 2 & 0 & 2 & 2 & 2 & 1 & 0 & 2 & 0 & 2 \\ 1 & 2 & 2 & 0 & 0 & 0 & 1 & 2 & 0 & 2 & 0 & 2 & 0 & 0 \\ 2 & 2 & 2 & 2 & 1 & 0 & 1 & 2 & 0 & 2 & 2 & 2 & 2 & 1 \\ 1 & 2 & 2 & 0 & 2 & 0 & 1 & 2 & 0 & 2 & 0 & 2 & 0 & 2 \\ \hline \end{array}$ {{qed}}	1
Apply the [[Method of Truth Tables]]: :$\begin{array}{|ccc||cc|} \hline p & \downarrow & p & \neg & p \\ \hline F & T & F & T & F \\ T & F & T & F & T \\ \hline \end{array}$ As can be seen by inspection, the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. {{qed}}	1
Let $P_f, P_g, P_\mathcal R$ be the [[Definition:URM Program|URM programs]] computing, respectively, the functions $f$ and $g$ and the [[Definition:Characteristic Function of Relation|characteristic function]] $\chi_\mathcal R$. From [[Recursive Function is URM Computable]], these programs are guaranteed to exist. An informal algorithm for computing $h$ is as follows. # Input $\left({n_1, n_2, \ldots, n_k}\right)$. # Use $P_\mathcal R$ to determine whether $\mathcal R \left({n_1, n_2, \ldots, n_k}\right)$ holds. # If it holds, use $P_f$ to compute $f \left({n_1, n_2, \ldots, n_k}\right)$. # If it does not hold, use $P_g$ to compute $g \left({n_1, n_2, \ldots, n_k}\right)$. The result follows from [[URM Computable Function is Recursive]]. {{qed}}	1
:$\ds \sum_{j \mathop = 1}^{2 n - 1} F_j F_{j + 1} = {F_{2 n} }^2$	1
The [[Factor Principles/Disjunction on Left/Formulation 2|Factor Principle]]: :$\left({p \implies q}\right) \implies \left({\left({r \lor p}\right) \implies \left ({r \lor q}\right)}\right)$ is a [[Definition:Tautology (Formal Semantics)|tautology]] in [[Definition:Constructed Semantics/Instance 4|Instance 4]] of [[Definition:Constructed Semantics|constructed semantics]].	1
:$p \implies q, p \vdash q$	1
:$p \iff q, q \iff r \vdash p \iff r$	1
{{BeginTableau|\left({\neg p \land \neg q}\right) \implies \left({\neg \left({p \lor q}\right)}\right)}} {{Assumption|1|\neg p \land \neg q}} {{SequentIntro|2|1|\neg \left({p \lor q}\right)|1|[[De Morgan's Laws (Logic)/Conjunction of Negations/Formulation 1/Forward Implication|De Morgan's Laws (Logic): Conjunction of Negations: Formulation 1]]}} {{Implication|3||\left({\neg p \land \neg q}\right) \implies \left({\neg \left({p \lor q}\right)}\right)|1|2}} {{EndTableau}} {{qed}}	1
:$\vdash p \land q \implies p$	1
From [[Solution to Card Game with Bluffing]], the optimum [[Definition:Strategy|strategy]] for the [[Definition:Card Game with Bluffing|card game with bluffing, is: :For $A$, to use both [[Definition:Pure Strategy|pure strategies]] but favour $A_1$ by $2/3$ to $1/3$. :For $B$, to use both [[Definition:Pure Strategy|pure strategies]] but favour $B_1$ by $2/3$ to $1/3$. Hence the result by definition of [[Definition:Completely Mixed Game|completely mixed game]].	1
Consider the [[Definition:Categorical Statement|categorical statements]]: :$\mathbf I: \quad$ The [[Definition:Particular Affirmative|particular affirmative]]: $\exists x: \map S x \land \map P x$ :$\mathbf O: \quad$ The [[Definition:Particular Negative|particular negative]]: $\exists x: \map S x \land \neg \map P x$ Then: :$\mathbf I$ and $\mathbf O$ are [[Definition:Subcontrary Statements|subcontrary]] {{iff}}: :$\exists x: \map S x$ Using the [[Definition:Symbolic Logic|symbology]] of [[Definition:Predicate Logic|predicate logic:]] :$\exists x: \map S x \iff \paren {\paren {\exists x: \map S x \land \map P x} \lor \paren {\exists x: \map S x \land \neg \map P x} }$	1
{{begin-eqn}} {{eqn|l = \left({p \oplus q}\right) \oplus q |o = \dashv \vdash |r = p \oplus \left({q \oplus q}\right) |c = [[Exclusive Or is Associative]] }} {{eqn|o = \dashv \vdash |r = p \oplus \bot |c = [[Exclusive Or with Itself]] }} {{eqn|o = \dashv \vdash |r = p |c = [[Exclusive Or with Contradiction]] }} {{end-eqn}} {{qed}}	1
From [[Elimination of all but 48 Categorical Syllogisms as Invalid]] there are $12$ possible patterns of [[Definition:Categorical Syllogism|categorical syllogism]] per [[Definition:Figure of Categorical Syllogism|figure]]: :$\begin{array}{cccccc} AAA & AAI & AEE & AEO & AII & AOO \\ EAE & EAO & EIO & IAI & IEO & OAO \\ \end{array}$ === Figure $\text I$ === Consider [[Definition:First Figure of Categorical Syllogism|Figure $\text I$]]: {{:Definition:Figure of Categorical Syllogism/I}} From [[Valid Syllogism in Figure I needs Affirmative Minor Premise and Universal Major Premise]], the patterns: :$AEE$, $AEO$, $AOO$ and $IEO$ can be eliminated as they all have a [[Definition:Negative Categorical Statement|negative]] [[Definition:Minor Premise of Syllogism|minor premise]], and: :$IAI$ and $OAO$ can be eliminated as they all have a [[Definition:Particular Categorical Statement|particular]] [[Definition:Major Premise of Syllogism|major premise]]. Thus the only patterns in [[Definition:First Figure of Categorical Syllogism|Figure $\text I$]] that may be [[Definition:Valid Argument|valid]] are: :$\begin{array}{rl} \text{I} & AAA \\ \text{I} & AII \\ \text{I} & EAE \\ \text{I} & EIO \\ \text{I} & AAI \\ \text{I} & EAO \\ \end{array}$ {{qed|lemma}} === Figure $\text {II}$ === Consider [[Definition:Second Figure of Categorical Syllogism|Figure $\text {II}$]]: {{:Definition:Figure of Categorical Syllogism/II}} From [[Valid Syllogism in Figure II needs Negative Conclusion and Universal Major Premise]], the patterns: :$AAA$, $AAI$, $AII$ and $IAI$ can be eliminated as they all have an [[Definition:Affirmative Categorical Statement|affirmative]] [[Definition:Conclusion of Syllogism|conclusion]], and: :$IEO$ and $OAO$ can be eliminated as they all have a [[Definition:Particular Categorical Statement|particular]] [[Definition:Major Premise of Syllogism|major premise]]. Thus the only patterns in [[Definition:Second Figure of Categorical Syllogism|Figure $\text {II}$]] that may be [[Definition:Valid Argument|valid]] are: :$\begin{array}{rl} \text{II} & EAE \\ \text{II} & AEE \\ \text{II} & AOO \\ \text{II} & EIO \\ \text{II} & EAO \\ \text{II} & AEO \\ \end{array}$ {{qed|lemma}} === Figure $\text {III}$ === Consider [[Definition:Third Figure of Categorical Syllogism|Figure $\text {III}$]]: {{:Definition:Figure of Categorical Syllogism/III}} From [[Valid Syllogism in Figure III needs Particular Conclusion and if Negative then Negative Major Premise]], the patterns: :$AAA$, $AEE$ and $EAE$ can be eliminated as they all have a [[Definition:Universal Categorical Statement|universal]] [[Definition:Conclusion of Syllogism|conclusion]], and: :$AEO$, $AOO$ and $IEO$ can be eliminated as they all have a [[Definition:Negative Categorical Statement|negative]] [[Definition:Minor Premise of Syllogism|minor premise]]. Thus the only patterns in [[Definition:Third Figure of Categorical Syllogism|Figure $\text {III}$]] that may be [[Definition:Valid Argument|valid]] are: :$\begin{array}{rl} \text{III} & AAI \\ \text{III} & AII \\ \text{III} & IAI \\ \text{III} & EAO \\ \text{III} & EIO \\ \text{III} & OAO \\ \end{array}$ {{qed|lemma}} === Figure $\text {IV}$ === Consider [[Definition:Fourth Figure of Categorical Syllogism|Figure $\text {IV}$]]: {{:Definition:Figure of Categorical Syllogism/IV}} From [[Valid Syllogisms in Figure IV]], the patterns: :$AII$ and $EOO$ can be eliminated as they have an [[Definition:Affirmative Categorical Statement|affirmative]] [[Definition:Major Premise of Syllogism|major premise]] and a [[Definition:Particular Categorical Statement|particular]] [[Definition:Minor Premise of Syllogism|minor premise]]. :$IEO$ and $OAO$ can be eliminated as they have a [[Definition:Negative Categorical Statement|negative]] [[Definition:Conclusion of Syllogism|conclusion]] and a [[Definition:Particular Categorical Statement|particular]] [[Definition:Major Premise of Syllogism|major premise]]. :$AAA$ and $EAE$ can be eliminated as they have a [[Definition:Universal Categorical Statement|universal]] [[Definition:Conclusion of Syllogism|conclusion]] and a [[Definition:Negative Categorical Statement|negative]] [[Definition:Minor Premise of Syllogism|minor premise]]. Thus the only patterns in [[Definition:Fourth Figure of Categorical Syllogism|Figure $\text {IV}$]] that may be [[Definition:Valid Argument|valid]] are: :$\begin{array}{rl} \text{IV} & AAI \\ \text{IV} & AEE \\ \text{IV} & EAO \\ \text{IV} & EIO \\ \text{IV} & IAI \\ \text{IV} & AEO \\ \end{array}$ {{qed|lemma}} It remains to be established whether these $24$ patterns actually do represent [[Definition:Valid Argument|valid]] [[Definition:Categorical Syllogism|categorical syllogisms]]. {{qed}}	1
Let $\LL$ be a [[Definition:Logical Language|logical language]]. Let $\mathscr M$ be a [[Definition:Formal Semantics|formal semantics]] for $\LL$. Let $\FF$ be an [[Definition:Unsatisfiable Set of Formulas|$\mathscr M$-unsatisfiable set of formulas]] from $\LL$. Let $\FF'$ be a [[Definition:Superset|superset]] of $\FF$. Then $\FF'$ is also [[Definition:Unsatisfiable Set of Formulas|$\mathscr M$-unsatisfiable]].	1
==== [[True Statement is implied by Every Statement/Formulation 1|Formulation 1]] ==== {{:True Statement is implied by Every Statement/Formulation 1}} ==== [[True Statement is implied by Every Statement/Formulation 2|Formulation 2]] ==== {{:True Statement is implied by Every Statement/Formulation 2}}	1
:$\vdash \neg \left({p \iff \neg p}\right)$	1
We apply the [[Method of Truth Tables]]. $\begin{array}{|c||ccc|} \hline p & p & \lor & q \\ \hline F & F & F & F \\ F & F & T & T \\ T & T & T & F \\ T & T & T & T \\ \hline \end{array}$ As can be seen, when $p$ is [[Definition:True|true]] so is $p \lor q$. {{qed}}	1
:$(1): \quad$ If we can conclude $\phi \iff \psi$, then we may infer $\phi \implies \psi$. :$(2): \quad$ If we can conclude $\phi \iff \psi$, then we may infer $\psi \implies \phi$.	1
{{BeginTableau|\neg \forall x: \neg \map P x \vdash \exists x: \map P x}} {{Premise|1|\neg \forall x: \neg \map P x}} {{Assumption|2|\neg \exists x: \map P x}} {{SequentIntro|3|2|\forall x: \neg \map P x|2|[[Denial of Existence]]}} {{NonContradiction|4|1, 2|1|3}} {{Reductio|5|1|\exists x: \map P x|2|4}} {{EndTableau|lemma}} {{BeginTableau|\exists x: \map P x \vdash \neg \forall x: \neg \map P x}} {{Premise|1|\exists x: \map P x}} {{Assumption|2|\forall x: \neg \map P x}} {{TableauLine|n = 3|pool = 1|f = \map P {\mathbf a}|rlnk = Existential Instantiation|rtxt = Existential Instantiation|dep = 1|for some arbitrary $\mathbf a$}} {{TableauLine|n = 4|pool = 2|f = \neg \map P {\mathbf a}|rlnk = Universal Instantiation|rtxt = Universal Instantiation|dep = 2}} {{NonContradiction|5|1, 2|3|4}} {{Contradiction|6|1|\neg \forall x: \neg \map P x|2|5}} {{EndTableau|qed}} {{LEM|Reductio ad Absurdum}} {{Namedfor|Augustus De Morgan|cat = De Morgan}}	1
Let $\map P n$ be a [[Definition:Propositional Function|propositional function]] depending on $n \in \N$. Suppose that: :$(1): \quad \map P 0$ is [[Definition:True|true]] :$(2): \quad \forall k \in \N: k \ge 0 : \map P k \implies \map P {k + 1}$ Then: :$\map P n$ is [[Definition:True|true]] for all $n \in \N$.	1
We apply the [[Method of Truth Tables]]. As can be seen by inspection, in all cases the [[Definition:Truth Value|truth values]] under the [[Definition:Main Connective (Propositional Logic)|main connectives]] match for all [[Definition:Boolean Interpretation|boolean interpretations]]. $\begin{array}{|ccc||ccccccccc|} \hline p & \iff & q & (p & \land & q) & \lor & (\neg & p & \land & \neg & q) \\ \hline F & T & F & F & F & F & T & T & F & T & T & F \\ F & F & T & F & F & T & F & T & F & F & F & T \\ T & F & F & T & F & F & F & F & T & F & T & F \\ T & T & T & T & T & T & T & F & T & F & F & T \\ \hline \end{array}$ {{qed}}	1

First note that: {{begin-eqn}} {{eqn | n = 1 | l = \map {\frac {\d} {\d x} } {\sin a x - \cos a x} | r = a \paren {\cos a x + \sin a x} | c = [[Derivative of Sine of a x|Derivative of $\sin a x$]] and [[Derivative of Cosine of a x|Derivative of $\cos a x$]] }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = \int \frac {\sin a x \rd x} {\sin a x - \cos a x} | r = \int \frac {\paren {\sin a x - \cos a x + \cos a x} \rd x} {\sin a x - \cos a x} | c = }} {{eqn | r = \int \frac {\paren {\sin a x - \cos a x} \rd x} {\sin a x - \cos a x} + \int \frac {\cos a x \rd x} {\sin a x - \cos a x} | c = [[Linear Combination of Integrals]] }} {{eqn | r = \int \rd x + \int \frac {\cos a x \rd x} {\sin a x - \cos a x} | c = simplification }} {{eqn | r = \int \rd x + \int \frac {\paren {\cos a x + \sin a x - \sin a x} \rd x} {\sin a x - \cos a x} | c = }} {{eqn | r = \int \rd x + \int \frac {\paren {\cos a x + \sin a x} \rd x} {\sin a x - \cos a x} - \int \frac {\sin a x \rd x} {\sin a x - \cos a x} | c = [[Linear Combination of Integrals]] }} {{eqn | ll= \leadsto | l = 2 \int \frac {\sin a x \rd x} {\sin a x - \cos a x} | r = \int \rd x + \int \frac {\paren {\cos a x + \sin a x} \rd x} {\sin a x - \cos a x} | c = rearranging }} {{eqn | ll= \leadsto | l = \int \frac {\sin a x \rd x} {\sin a x + \cos a x} | r = \frac 1 2 \int \rd x + \frac 1 {2 a} \int \frac {a \paren {\cos a x + \sin a x} \rd x} {\sin a x - \cos a x} | c = [[Linear Combination of Integrals]] }} {{eqn | r = \frac x 2 + \frac 1 {2 a} \int \frac {a \paren {\cos a x + \sin a x} \rd x} {\sin a x - \cos a x} + C | c = [[Primitive of Constant]] }} {{Eqn-intertext|Then from $(1)$:}} {{eqn | r = \frac x 2 + \frac 1 {2 a} \ln \size {\sin a x - \cos a x} + C | c = [[Primitive of Function under its Derivative]] }} {{end-eqn}} {{qed}}	0
From [[Group Induces B-Algebra|Group Induces $B$-Algebra]], $\left({G, *}\right)$ is a [[Definition:B-Algebra|$B$-algebra]]. As in the proof [[Group Induces B-Algebra|Group Induces $B$-Algebra]], we let: :$0 := e$ Now we demonstrate $0$-commutativity. Let $x, y \in G$: {{begin-eqn}} {{eqn | l=x * \left({0 * y }\right) | r=x \circ \left({e \circ y^{-1} }\right)^{-1} | c=by definition of $*$ and $0$ }} {{eqn | r=x \circ (y^{-1})^{-1} | c=by definition of [[Definition:Identity Element|identity element]] }} {{eqn | r=x \circ y | c=[[Inverse of Group Inverse]] }} {{eqn | r=y \circ x | c=by definition of [[Definition:Abelian Group|abelian group]] }} {{eqn | r=y \circ \left({x^{-1} }\right)^{-1} | c=[[Inverse of Group Inverse]] }} {{eqn | r=y \circ \left({e \circ x^{-1} } \right)^{-1} | c=by definition of [[Definition:Identity Element|identity element]] }} {{eqn | r=y * \left({0 * x}\right) | c=by definition of $*$ and $0$ }} {{end-eqn}} Hence the result. {{qed}} [[Category:B-Algebras]] [[Category:Abelian Groups]] 9cys3fduhaj05rcakpzha68h2xkv8xm	0
By definition of [[Definition:Ordering|ordering]], the relation $\le$ is: :[[Definition:Reflexive Relation|reflexive]] :[[Definition:Transitive Relation|transitive]] :[[Definition:Antisymmetric Relation|antisymmetric]] and furthermore, every pair of elements is [[Definition:Comparable|comparable]]. The [[Definition:Ordering Compatible with Ring Structure|order is compatible with $F$]] in the sense that, for all $x, y, z, c \in F$: :$x < y \implies x + z < y + z$ :$c > 0,\ x < y \implies c x < c y$ The proof is by repeated deduction from these properties. * $(1): \quad x < 0 \iff -x > 0$: {{begin-eqn}} {{eqn | l = x | o = < | r = 0 }} {{eqn | ll= \leadsto | l = x - x | o = < | r = 0 - x }} {{eqn | ll= \leadsto | l = -x | o = > | r = 0 }} {{end-eqn}} Conversely: {{begin-eqn}} {{eqn | l = x | o = > | r = 0 }} {{eqn | ll= \leadsto | l = x - x | o = > | r = 0 - x }} {{eqn | ll= \leadsto | l = -x | o = < | r = 0 }} {{end-eqn}} * $(2): \quad x > y \iff x - y > 0$: {{begin-eqn}} {{eqn | l = x | o = > | r = y }} {{eqn | ll= \leadsto | l = x - y | o = > | r = y - y = 0 }} {{end-eqn}} Conversely: {{begin-eqn}} {{eqn | l = x - y > 0 | o = > | r = y }} {{eqn | ll= \leadsto | l = x - y + y | o = > | r = y }} {{eqn | ll= \leadsto | l = x | o = > | r = y }} {{end-eqn}} * $(3): \quad x < y \iff -x > -y$: {{begin-eqn}} {{eqn | l = x | o = < | r = y }} {{eqn | ll= \leadsto | l = x - x - y | o = < | r = y - x - y }} {{eqn | ll= \leadsto | l = -y | o = < | r = -x }} {{end-eqn}} Conversely: {{begin-eqn}} {{eqn | l = -y | o = < | r = -x }} {{eqn | ll= \leadsto | l = -y + y + x | o = < | r = -x + y + x }} {{eqn | ll= \leadsto | l = x | o = < | r = y }} {{end-eqn}} * $(4): \quad (z < 0) \land (x < y) \implies x z > y z$: By parts 1 and 3 above, if $z < 0$, $x < y$ then $-z > 0$ and $-x > -y$. Then: :$x z = \paren {-x} \paren {-z} > \paren {-y} \paren {-z} = y z$ * $(5): \quad x \ne 0 \implies x^2 > 0$: If $x > 0$, then: :$x^2 = x \cdot x > x \cdot 0 = 0$ If $x < 0$, then by 1, $-x > 0$, so: :$x^2 = \paren {-x} \cdot \paren {-x} > \paren {-x} \cdot 0 = 0$ * $(6): \quad 1 > 0$: This is immediate from $(5)$, noting that $1 = 1^2$ is a square. * $(7): \quad \Char k = 0$: By $(6)$, we have: :$0 < 1 < 1 + 1 < 1 + 1 + 1 < \cdots$ so $n \cdot 1 \ne 0$ for all $n \in \N$. * $(8): \quad x > y > 0 \iff y^{-1} > x^{-1} > 0$: First let $x > 0$, and suppose that $x^{-1} < 0$. Then by $(4)$: :$0 = 0 \cdot x^{-1} > x \cdot x^{-1} = 1$ which contradicts $(6)$, so $x^{-1} > 0$. Now let $x > y > 0$. Then: {{begin-eqn}} {{eqn | l = x^{-1} y^{-1} x | o = > | r = x^{-1} y^{-1} y > 0 }} {{eqn | ll= \leadsto | l = y^{-1} | o = > | r = x^{-1} > 0 }} {{end-eqn}} The converse follows upon interchanging $x^{-1} \leftrightarrow x$ and $y^{-1} \leftrightarrow y$. {{qed}} [[Category:Ordered Fields]] jfttok3h9u1ed8f6bf74k928uc01v1b	0
Let $a$ be [[Definition:Left Cancellable Element|left cancellable]] in $\struct {S, \circ}$. Let $x \in S$ and $y \in S$ be arbitrary. Then: {{begin-eqn}} {{eqn | l = \map \phi a * \map \phi x | r = \map \phi a * \map \phi y | c = }} {{eqn | ll= \leadsto | l = \map \phi {a \circ x} | r = \map \phi {a \circ y} | c = [[Definition:Morphism Property|Morphism Property]] }} {{eqn | ll= \leadsto | l = \map \phi x | r = \map \phi y | c = as $a$ is [[Definition:Left Cancellable Element|left cancellable]] }} {{end-eqn}} That is, $\map \phi a$ is [[Definition:Left Cancellable Element|left cancellable]] in $\struct {T, *}$. As $\phi$ is an [[Definition:Isomorphism (Abstract Algebra)|isomorphism]], then so is $\phi^{-1}$. So the same proof works in reverse in exactly the same way. {{qed}}	0
Assume $G$ is [[Definition:Finite Group|finite]]. Then: {{begin-eqn}} {{eqn | l = \index G H | r = \frac {\order G} {\order H} | c = [[Lagrange's Theorem (Group Theory)|Lagrange's Theorem]] }} {{eqn | l = \index G K | r = \frac {\order G} {\order K} | c = [[Lagrange's Theorem (Group Theory)|Lagrange's Theorem]] }} {{eqn | ll= \leadsto | l = \index G K | r = \frac {\order H} {\order K} \times \index G H | c = }} {{end-eqn}} Since $K \le H$, from [[Lagrange's Theorem (Group Theory)|Lagrange's Theorem]] we have that $\dfrac {\order H} {\order K} = \index H K$. Hence the result. {{qed}}	0
The [[Definition:Decimal Expansion|decimal expansion]] of the [[Definition:Reciprocal|reciprocal]] of $99$ is: :$\dfrac 1 {99} = 0 \cdotp \dot 0 \dot 1$ {{OEIS|A000035}}	0
Let $G$ be a [[Definition:Group|group]], and let $\iota: G \to G$ be the [[Definition:Inversion Mapping|inversion mapping]]. Then $\iota$ is an [[Definition:Involution (Mapping)|involution]]. That is: :$\forall g \in G: \map \iota {\map \iota g} = g$	0
Let $A$ be a [[Definition:Non-Trivial Ring|non-trivial]] [[Definition:Commutative Ring with Unity|commutative ring with unity]]. Then $A$ has a [[Definition:Prime Ideal of Ring|prime ideal]].	0
Let $C$ be a [[Definition:Contour (Complex Plane)|contour in $\C$]]. Let $f, g: \Img C \to \C$ be [[Definition:Continuous Complex Function|continuous complex functions]], where $\Img C$ denotes the [[Definition:Image of Contour (Complex Plane)|image]] of $C$. Let $\lambda, \mu \in \C$ be [[Definition:Complex Number|complex]] [[Definition:Constant|constants]]. Then: :$\displaystyle \int_C \paren {\lambda \map f z + \mu \map g z} \rd z = \lambda \int_C \map f z \rd z + \mu \int_C \map g z \rd z$	0
Let $R$ be a [[Definition:Commutative Ring|commutative ring]]. Let $G$ be an [[Definition:Module|$R$-module]]. Let $G^*$ be the [[Definition:Algebraic Dual|algebraic dual]] of $G$. Let $\left \langle {x, t'} \right \rangle$ be the [[Definition:Evaluation Linear Transformation|evaluation linear transformation]] from $G$ to $G^{**}$. Then the [[Definition:Mapping|mapping]] $\phi: G \times G^* \to R$ defined as $\forall \left({x, t'}\right) \in G \times G^*: \phi \left({x, t'}\right) = \left \langle {x, t'} \right \rangle$ satisfies the following properties: : $(1): \quad \forall x, y \in G: \forall t' \in G^*: \left \langle {x + y, t'} \right \rangle = \left \langle {x, t'} \right \rangle + \left \langle {y, t'} \right \rangle$ : $(2): \quad \forall x \in G: \forall s', t' \in G^*: \left \langle {x, s' + t'} \right \rangle = \left \langle {x, s'} \right \rangle + \left \langle {x, t'} \right \rangle$ : $(3): \quad \forall x \in G: \forall s', t' \in G^*: \forall \lambda \in R: \left \langle {\lambda x, t'} \right \rangle = \lambda \left \langle {x, t'} \right \rangle = \left \langle {x, \lambda t'} \right \rangle$	0
{{begin-eqn}} {{eqn | l = \paren {-a} + a | r = a + \paren {-a} | c = {{Field-axiom|A2}} }} {{eqn | r = 0_F | c = {{Field-axiom|A4}} }} {{eqn | ll= \leadsto | l = a | r = -\paren {-a} | c = {{Defof|Field Negative}} }} {{end-eqn}} {{qed}}	0
There are two versions of this result: * one for [[Definition:Complex Sequence|sequences]] in the set of [[Definition:Complex Number|complex numbers]] $\C$, and more generally for sequences in a metric space. * one for [[Definition:Real Sequence|sequences]] in the set of [[Definition:Real Number|real numbers]] $\R$, and more generally in linearly ordered spaces (which is [[Definition:Conditional/Semantics of Conditional|stronger]]). {{explain|stronger in what sense?}} === [[Squeeze Theorem/Sequences/Real Numbers|Sequences of Real Numbers]] === {{:Squeeze Theorem/Sequences/Real Numbers}} === [[Squeeze Theorem/Sequences/Complex Numbers|Sequences of Complex Numbers]] === {{:Squeeze Theorem/Sequences/Complex Numbers}} === [[Squeeze Theorem/Sequences/Linearly Ordered Space|Sequences in a Linearly Ordered Space]] === {{:Squeeze Theorem/Sequences/Linearly Ordered Space}} === [[Squeeze Theorem/Sequences/Metric Spaces|Sequences in a Metric Space]] === {{:Squeeze Theorem/Sequences/Metric Spaces}}	0
Let $\struct {R, +, \circ}$ be a [[Definition:Ring (Abstract Algebra)|ring]]. Let $J$ be an [[Definition:Ideal of Ring|ideal]] of $R$. Let $\struct {R / J, +}$ be the [[Definition:Quotient Group|quotient group]] of $\struct {R, +}$ by $\struct {J, +}$. Then each element of $\struct {R / J, +}$ is a [[Definition:Coset|coset]] of $J$ in $R$, that is, is of the form $x + J = \set {x + j: j \in J}$ for some $x \in R$. The rule of addition of these [[Definition:Coset|cosets]] is: $\paren {x + J} + \paren {y + J} = \paren {x + y} + J$. The [[Definition:Identity Element|identity]] of $\struct {R / J, +}$ is $J$ and for each $x \in R$, the [[Definition:Inverse Element|inverse]] of $x + J$ is $\paren {-x} + J$.	0
Let $S$ be a [[Definition:Set|set]]. Let $S^S$ be the [[Definition:Set of All Mappings|set of all mappings]] from $S$ to itself Let $\struct {\Gamma \paren S, \circ}$ denote the [[Definition:Symmetric Group|symmetric group on $S$]]. Let $\struct {S^S, \circ}$ be the [[Definition:Monoid|monoid]] of [[Definition:Self-Map|self-maps]] under [[Definition:Composition of Mappings|composition of mappings]]. Then $\struct {\Gamma \paren S, \circ}$ is a [[Definition:Subgroup|subgroup]] of $\struct {S^S, \circ}$.	0
Let $V$ be a [[Definition:Topological Vector Space|topological vector space]] over $\R$ or $\C$. Let $A\subset V$ be a [[Definition:Convex Set (Vector Space)|convex subset]]. Then $A$ is [[Definition:Contractible Space|contractible]].	0
Let $\struct {\R, \tau}$ denote the [[Definition:Real Number Line with Euclidean Topology|real number line with the usual (Euclidean) topology]]. Let $\openint a b$ be an [[Definition:Open Real Interval|open interval]] of $\R$. Then $\openint a b$ is [[Definition:Regular Open Set|regular open]] in $\struct {\R, \tau_d}$.	0
Let $\size x < a$. Then: {{begin-eqn}} {{eqn | l = \int \frac {\d x} {x^2 - a^2} | r = -\frac 1 a \tanh^{-1} {\frac x a} + C | c = [[Primitive of Reciprocal of a squared minus x squared/Inverse Hyperbolic Tangent Form|Primitive of $\dfrac 1 {x^2 - a^2}$: $\tanh^{-1}$ form]] }} {{eqn | r = -\frac 1 a \paren {\dfrac 1 2 \map \ln {\dfrac {a + x} {a - x} } } + C | c = [[Inverse Hyperbolic Tangent of x over a in Logarithm Form|$\tanh^{-1} \dfrac x a$ in Logarithm Form]] }} {{eqn | r = -\dfrac 1 {2 a} \map \ln {\dfrac {a + x} {a - x} } + C | c = simplifying }} {{eqn | r = \dfrac 1 {2 a} \map \ln {\dfrac {a - x} {a + x} } + C | c = [[Logarithm of Reciprocal]] }} {{end-eqn}}	0
Let $S$ be a [[Definition:Set|set]] of [[Definition:Ordered Pair|ordered pairs]]. Let $x \in S$ such that $x = \left\{{\left\{{a}\right\}, \left\{{a, b}\right\}}\right\}$ as defined in [[Kuratowski Formalization of Ordered Pair]]. Since the elements of $S$ are [[Definition:Set|sets]], we can form the [[Definition:Set Union|union]] $\mathbb S = \bigcup S$ of the sets in $S$. Since $x \in S$ it follows that the [[Definition:Element|elements]] of $x$ are elements of $\mathbb S$. Since $\left\{{a, b}\right\} \in x$ it follows that $\left\{{a, b}\right\} \in \mathbb S$. Now we can form the [[Definition:Set Union|union]] $\mathbb S' = \bigcup \mathbb S$ of the sets in $\mathbb S$. Since $\left\{{a, b}\right\} \in \mathbb S$ it follows that both $a$ and $b$ are elements of $\mathbb S' = \bigcup \bigcup S$. Thus from the [[Kuratowski Formalization of Ordered Pair]] we have that $S$ is a [[Definition:Subset|subset]] of some $A \times B$. We can at this stage take both $A$ and $B$ as being equal to $\bigcup \bigcup S$. Finally, the [[Axiom:Axiom of Specification|axiom of specification]] is applied to construct the sets: :$A = \left\{{a: \exists b: \left({a, b}\right) \in S}\right\}$ and :$B = \left\{{b: \exists a: \left({a, b}\right) \in S}\right\}$ $A$ and $B$ are seen to be the [[Definition:First Projection|first]] and [[Definition:Second Projection|second projections]] respectively of $S$. {{qed}}	0
Let $G$ be a [[Definition:Group|group]] and let $H \le G$. Consider the [[Definition:Mapping|mapping]] $\phi$ from the [[Definition:Left Coset Space|left coset space]] to the [[Definition:Right Coset Space|right coset space]] defined as: :$\forall g \in G: \map \phi {g H} = H g^{-1}$ We need to show that $\phi$ is a [[Definition:Bijection|bijection]]. First we need to show that $\phi$ is [[Definition:Well-Defined Mapping|well-defined]]. That is, that $a H = b H \implies \map \phi {a H} = \map \phi {b H}$. Suppose $a H = b H$. {{begin-eqn}} {{eqn | l = a H = b H | o = \iff | r = a^{-1} b \in H | c = [[Left Cosets are Equal iff Product with Inverse in Subgroup]] }} {{eqn | l = H a^{-1} = H b^{-1} | o = \iff | r = a^{-1} \paren {b^{-1} }^{-1} \in H | c = [[Right Cosets are Equal iff Product with Inverse in Subgroup]] }} {{end-eqn}} But $a^{-1} \paren {b^{-1} }^{-1} = a^{-1} b \in H$ as $a H = b H$. So $H a^{-1} = H b^{-1}$ and $\phi$ is [[Definition:Well-Defined Mapping|well-defined]]. Next we show that $\phi$ is [[Definition:Injection|injective]]: Suppose $\exists x, y \in G: \map \phi {x H} = \map \phi {y H}$. Then $H x^{-1} = H y^{-1}$, so $x^{-1} = e_G x^{-1} = h y^{-1}$ for some $h \in H$. Thus $h = x^{-1} y \implies h^{-1} = y^{-1} x$. As $H$ is a [[Definition:Subgroup|subgroup]], $h^{-1} \in H$. Thus: : $y^{-1} x \in H$ So by [[Left Cosets are Equal iff Product with Inverse in Subgroup]]: :$x H = y H$ Thus $\phi$ is [[Definition:Injection|injective]]. Next we show that $\phi$ is [[Definition:Surjection|surjective]]: Let $H x$ be a [[Definition:Right Coset|right coset]] of $H$ in $G$. Since $x = \paren {x^{-1} }^{-1}$, $H x = \map \phi {x^{-1} H}$ and so $\phi$ is [[Definition:Surjection|surjective]]. Thus $\phi$ constitutes a [[Definition:Bijection|bijection]] from the [[Definition:Left Coset Space|left coset space]] to the [[Definition:Right Coset Space|right coset space]], and the result follows. {{qed}}	0
Let $\map f t := \map \Si t = \displaystyle \int_0^t \dfrac {\sin u} u \rd u$. Then: :$\map f 0 = 0$ and: {{begin-eqn}} {{eqn | l = \map {f'} t | r = \dfrac {\sin t} t | c = }} {{eqn | ll= \leadsto | l = t \map {f'} t | r = \sin t | c = }} {{eqn | ll= \leadsto | l = \laptrans {t \map {f'} t} | r = \laptrans {\sin t} | c = }} {{eqn | r = \dfrac 1 {s^2 + 1} | c = [[Laplace Transform of Sine]] }} {{eqn | ll= \leadsto | l = -\dfrac \d {\d s} \laptrans {\map {f'} t} | r = \dfrac 1 {s^2 + 1} | c = [[Derivative of Laplace Transform]] }} {{eqn | ll= \leadsto | l = \map {\dfrac \d {\d s} } {s \laptrans {\map f t} - \map f 0} | r = -\dfrac 1 {s^2 + 1} | c = [[Laplace Transform of Derivative]] }} {{eqn | ll= \leadsto | l = s \laptrans {\map f t} | r = -\int \dfrac 1 {s^2 + 1} \rd s | c = $\map f 0 = 0$, and integrating both sides {{WRT|Integration}} $s$ }} {{eqn | ll= \leadsto | l = s \laptrans {\map f t} | r = -\arctan s + C | c = [[Primitive of Reciprocal of x squared plus a squared/Arctangent Form|Primitive of $\dfrac 1 {x^2 + a^2}$]] }} {{end-eqn}} By the [[Initial Value Theorem of Laplace Transform]]: :$\displaystyle \lim_{s \mathop \to \infty} s \laptrans {\map f t} = \lim_{t \mathop \to 0} \map f t = \map f 0 = 0$ which leads to: :$c = \dfrac \pi 2$ Thus: {{begin-eqn}} {{eqn | l = s \laptrans {\map f t} | r = \dfrac \pi 2 - \arctan s | c = }} {{eqn | r = \arccot s | c = [[Sum of Arctangent and Arccotangent]] }} {{eqn | r = \arctan \dfrac 1 s | c = [[Arctangent of Reciprocal equals Arccotangent]] }} {{eqn | ll= \leadsto | l = \laptrans {\map f t} | r = \dfrac 1 s \arctan \dfrac 1 s | c = }} {{end-eqn}} {{qed}}	0
This has been demonstrated by an exhaustive search. {{qed}}	0
Consider two cases: :$(1): \quad \mathbf A$ is not [[Definition:Invertible Matrix|invertible]]. :$(2): \quad \mathbf A$ is [[Definition:Invertible Matrix|invertible]]. === Proof of case $1$ === Assume $\mathbf A$ is not [[Definition:Invertible Matrix|invertible]]. Then: :$\map \det {\mathbf A} = 0$ Also if $\mathbf A$ is not [[Definition:Invertible Matrix|invertible]] then neither is $\mathbf A \mathbf B$. Indeed, if $\mathbf A \mathbf B$ has an inverse $\mathbf C$, then $\mathbf A \mathbf B \mathbf C = \mathbf I$, whereby $\mathbf B \mathbf C$ is a right inverse of $\mathbf A$. It follows by [[Left or Right Inverse of Matrix is Inverse]] that in that case $\mathbf B \mathbf C$ is the inverse of $A$. It follows that: :$\map \det {\mathbf A \mathbf B} = 0$ Thus: :$0 = 0 \cdot \map \det {\mathbf B}$ :$\map \det {\mathbf A \mathbf B} = \map \det {\mathbf A} \cdot \map \det {\mathbf B}$ {{qed|lemma}} === Proof of case $2$ === Assume $\mathbf A$ is [[Definition:Invertible Matrix|invertible]]. Then $\mathbf A$ is a product of [[[[Definition:Elementary Row Matrix|elementary row matrices]], $\mathbf E$. Let $\mathbf A = \mathbf E_k \mathbf E_{k - 1} \cdots \mathbf E_1$. So: :$\map \det {\mathbf A \mathbf B} = \map \det {\mathbf E_k \mathbf E_{k - 1} \cdots \mathbf E_1 \mathbf B}$ It remains to be shown that for any [[Definition:Square Matrix|square matrix]] $\mathbf D$ of [[Definition:Order of Square Matrix|order]] $n$: :$\map \det {\mathbf E \mathbf D} = \map \det {\mathbf E} \cdot \map \det {\mathbf D}$ Let $e_i \paren {\mathbf I} = \mathbf E_i$ for all $i \in \closedint 1 k$, then using [[Elementary Row Operations as Matrix Multiplications]] and [[Effect of Sequence of Elementary Row Operations on Determinant]] yields: :$\map \det {\mathbf E \mathbf D} = \map \det {\mathbf E_k \mathbf E_{k - 1} \dotsm \mathbf {E_1} \mathbf D} = \map \det {e_k e_{k - 1} \cdots e_1 \paren {\mathbf D} } = \alpha \map \det {\mathbf D}$ Using [[Elementary Row Operations as Matrix Multiplications]] and [[Effect of Sequence of Elementary Row Operations on Determinant]], '''and''' [[Unit Matrix is Unity of Ring of Square Matrices]]: :$\map \det {\mathbf E} = \map \det {\mathbf E_k \mathbf E_{k - 1} \cdots \mathbf {E_1} \mathbf I} = \map \det {e_k e_{k - 1} \cdots e_1 \paren {\mathbf I} } = \alpha \map \det {\mathbf I}$ From [[Determinant of Unit Matrix]]: :$\map \det {\mathbf E} = \alpha$ And so $\map \det {\mathbf E \mathbf D} = \map \det {\mathbf E} \cdot \map \det {\mathbf D}$ {{qed|lemma}} Therefore: :$\map \det {\mathbf A \mathbf B} = \map \det {\mathbf A} \map \det {\mathbf B}$ as required. {{qed}}	0
We have: {{begin-eqn}} {{eqn | l = \prod_{j \mathop = 2}^n \paren {1 - \frac 1 {j^2} } | r = \prod_{j \mathop = 2}^n \paren {\frac {\paren {j - 1} \paren {j + 1} } {j^2} } | c = [[Difference of Two Squares]] }} {{eqn | r = \paren {\prod_{j \mathop = 2}^n \paren {j - 1} } \paren {\prod_{j \mathop = 2}^n \paren {j + 1} } \paren {\prod_{j \mathop = 2}^n \frac 1 j}^2 | c = [[Product of Products]] }} {{eqn | r = \paren {\prod_{j \mathop = 1}^{n - 1} j} \paren {\prod_{j \mathop = 3}^{n + 1} j} \frac 1 {\paren {\prod_{j \mathop = 2}^n j}^2} }} {{eqn | r = \paren {n - 1}! \paren {\frac 1 2 \prod_{j \mathop = 2}^{n + 1} j} \frac 1 {\paren {n!}^2} | c = {{Defof|Factorial}} }} {{eqn | r = \frac {\paren {n - 1}! \paren {n + 1}!} {2 \times n! \times n!} | c = {{Defof|Factorial}} }} {{eqn | r = \frac {\paren {n - 1}! n! \paren {n + 1} } {2 \paren {n - 1}! \times n \times n!} | c = [[Gamma Difference Equation]] }} {{eqn | r = \frac {n + 1} {2 n} }} {{end-eqn}} {{qed}}	0
Let: : $x H$ be the [[Definition:Left Coset|left coset]] of $x$ modulo $H$. Then: : $x \in x H$	0
Let $G$ be the [[Definition:Graph of Mapping|graph]] of the [[Definition:Real Function|function]] $y = \sin \left({\dfrac 1 x}\right)$ for $x > 0$. Let $J$ be the [[Definition:Line Segment|line segment]] joining the points $\left({0, -1}\right)$ and $\left({0, 1}\right)$ in $\R^2$. Then while $G \cup J$ is [[Definition:Connected Set (Topology)|connected]], it is '''not''' [[Definition:Path-Connected Set (Topology)|path-connected]].	0
Let $\map {\operatorname {Af}_1} \R$ be the [[Definition:Affine Group of One Dimension|$1$-dimensional affine group on $\R$]]. Then $\map {\operatorname {Af}_1} \R$ is a [[Definition:Group|group]].	0
Since $\norm x = \map d {x, \mathbf 0}$, the result follows directly from [[Distance Function of Metric Space is Continuous]]. {{qed}} [[Category:Norm Theory]] [[Category:Continuous Mappings]] nwsfsr3ucq08u3e6eq3x8ugflydugc2	0
Let $R$ be a [[Definition:Ring with Unity|ring with unity]]. Let $M, N, P$ be [[Definition:Free Module|free $R$-modules]] of [[Definition:Dimension (Linear Algebra)|finite dimension]] $m, n, p > 0$ respectively. Let $\mathcal A,\mathcal B,\mathcal C$ be [[Definition:Ordered Basis (Linear Algebra)|ordered bases]] of $M, N, P$. Let $f: M \to N$ and $g : N \to P$ be [[Definition:Linear Transformation|linear transformations]], and $g \circ f$ be their [[Definition:Composition of Mappings|composition]]. Let $\mathbf M_{f, \mathcal B, \mathcal A}$ and $\mathbf M_{g, \mathcal C, \mathcal B}$ be their [[Definition:Relative Matrix|matrices relative]] to $\mathcal A, \mathcal B$ and $\mathcal B, \mathcal C$ respectively. Then the [[Definition:Matrix|matrix]] of $g \circ f$ [[Definition:Relative Matrix|relative to]] $\mathcal A$ and $\mathcal C$ is: :$\mathbf M_{g \mathop \circ f, \mathcal C, \mathcal A} = \mathbf M_{g, \mathcal C, \mathcal B}\cdot \mathbf M_{f, \mathcal B, \mathcal A}$	0
By the [[Integral Test]]: :$\displaystyle \sum_{n \mathop = 1}^\infty \frac 1 {n^x}$ [[Definition:Convergent Real Sequence|converges]] {{iff}} the [[Definition:Improper Integral|improper integral]] $\displaystyle \int_1^\infty \frac {\d t} {t^x}$ exists. The result follows from [[Integral to Infinity of Reciprocal of Power of x]]. {{qed}}	0
{{begin-eqn}} {{eqn | l = \map {\operatorname C} {-x} | r = \sqrt {\frac 2 \pi} \int_0^{-x} \cos u^2 \rd u | c = {{Defof|Fresnel Cosine Integral Function}} }} {{eqn | r = -\sqrt {\frac 2 \pi} \int_0^{-\paren {-x} } \map \cos {\paren {-u}^2} \rd u | c = [[Integration by Substitution|substituting]] $u \mapsto -u$ }} {{eqn | r = -\sqrt {\frac 2 \pi} \int_0^x \cos u^2 \rd u }} {{eqn | r = -\map {\operatorname C} x | c = {{Defof|Fresnel Cosine Integral Function}} }} {{end-eqn}} {{qed}}	0
Let $a \in A$, $b \in B$. Then: {{begin-eqn}} {{eqn | l = a \circ b | o = \preceq | r = \sup A \circ b | c = {{Defof|Supremum of Set}} }} {{eqn | o = \preceq | r = \sup A \circ \sup B | c = {{Defof|Supremum of Set}} }} {{end-eqn}} Hence $\sup A \circ \sup B$ is an [[Definition:Upper Bound of Set|upper bound]] for $A \circ_{\PP} B$. Suppose that $u$ is an [[Definition:Upper Bound of Set|upper bound]] for $A \circ_{\PP} B$. Then: {{begin-eqn}} {{eqn | lo= \forall b \in B: \forall a \in A: | l = a \circ b | o = \preceq | r = u }} {{eqn | ll= \leadsto | lo= \forall b \in B: \forall a \in A: | l = a | o = \preceq | r = u \circ b^{-1} }} {{eqn | ll= \leadsto | lo= \forall b \in B: | l = \sup A | o = \preceq | r = u \circ b^{-1} | c = {{Defof|Supremum of Set}} }} {{eqn | ll= \leadsto | lo= \forall b \in B: | l = b | o = \preceq | r = \paren {\sup A}^{-1} \circ u }} {{eqn | ll= \leadsto | l = \sup B | o = \preceq | r = \paren {\sup A}^{-1} \circ u | c = {{Defof|Supremum of Set}} }} {{eqn | ll= \leadsto | l = \sup A \circ \sup B | o = \preceq | r = u }} {{end-eqn}} Therefore: :$\sup \paren {A \circ_{\PP} B} = \sup A \circ \sup B$ {{qed}}	0
Let $\mathbf C$ be a [[Definition:Metacategory|metacategory]]. Let $C$ be an [[Definition:Object (Category Theory)|object]] of $\mathbf C$. Then $\displaystyle \prod \set C = C$, where $\displaystyle \prod$ denotes [[Definition:Product (Category Theory)/General Definition|product]].	0
Let $G$ be a [[Definition:Finite Group|finite]] [[Definition:Cyclic Group|cyclic group]]. Let the [[Definition:Order of Structure|order]] of $G$ be $2^k$ for some $k \in \Z_{>0}$. Then $G$ has $2^{n - 1}$ [[Definition:Distinct|distinct]] [[Definition:Generator of Group|generators]].	0
:$\ds \int \sec a x \rd x = \frac 1 a \ln \size {\sec a x + \tan a x} + C$ where $\sec a x + \tan a x \ne 0$.	0
{{begin-eqn}} {{eqn | l = \sec 195 \degrees | r = \map \sec {360^ \degrees - 165 \degrees} | c = }} {{eqn | r = \sec 165 \degrees | c = [[Secant of Conjugate Angle]] }} {{eqn | r = -\paren {\sqrt 6 - \sqrt 2} | c = [[Secant of 165 Degrees|Secant of $165 \degrees$]] }} {{end-eqn}} {{qed}}	0
Let $F$ be a [[Definition:Field (Abstract Algebra)|field]]. Then the [[Definition:Characteristic of Ring|characteristic]] of $F$ is either zero or a [[Definition:Prime Number|prime number]].	0
Let $a$ and $b$ be [[Definition:Set|sets]]. Let $w = \tuple {a, b}$ denote the [[Definition:Ordered Pair|ordered pair]] of $a$ and $b$. Let $\map {\pr_2} w$ denote the [[Definition:Second Projection|second projection]] on $w$. Then: :$\displaystyle \map {\pr_2} w = \begin {cases} \displaystyle \map \bigcup {\bigcup w \setminus \bigcap w} & : \displaystyle \bigcup w \ne \bigcap w \\ \displaystyle \bigcup \bigcup w & : \displaystyle \bigcup w = \bigcap w \end {cases}$ where: :$\displaystyle \bigcup$ and $\displaystyle \bigcap$ denote [[Definition:Union of Set of Sets|union]] and [[Definition:Intersection of Set of Sets|intersection]] respectively. :$\setminus$ denotes the [[Definition:Set Difference|set difference operator]].	0
Let $z \in \C$ be a [[Definition:Complex Number|complex number]]. Let $z$ be interpreted as a [[Definition:Complex Number as Vector|vector]] in the [[Definition:Complex Plane|complex plane]]. Let $w \in \C$ be the [[Definition:Complex Number|complex number]] defined as $z$ [[Definition:Complex Multiplication|multiplied]] by $-1$: :$w = \left({-1}\right) z$ Then $w$ can be interpreted as the [[Definition:Complex Number as Vector|vector]] $z$ after being [[Definition:Plane Rotation|rotated]] through two [[Definition:Right Angle|right angles]]. The direction of [[Definition:Plane Rotation|rotation]] is usually interpreted as being [[Definition:Anticlockwise|anticlockwise]], but a [[Definition:Plane Rotation|rotated]] through two [[Definition:Right Angle|right angles]] is the same whichever direction the [[Definition:Plane Rotation|rotation]] is performed.	0
Suppose $\displaystyle \lim_{n \mathop \to \infty} x_n = l$ and $\displaystyle \lim_{n \mathop \to \infty} x_n = m$. Let $\epsilon > 0$. Then, provided $n$ is [[Definition:Sufficiently Large|sufficiently large]]: {{begin-eqn}} {{eqn | l = \map d {l, m} | o = \le | r = \map d {l, x_n} + \map d {x_n, m} | c = [[Triangle Inequality]] }} {{eqn | o = < | r = \epsilon + \epsilon | c = {{Defof|Limit of Sequence (Metric Space)}} }} {{eqn | r = 2 \epsilon }} {{end-eqn}} So $0 \le \dfrac {\map d {l, m} } 2 < \epsilon$. This holds for ''any'' value of $\epsilon > 0$. Thus from [[Real Plus Epsilon]] it follows that $\dfrac {\map d {l, m} } 2 = 0$, that is, that $l = m$. {{qed}}	0
By definition of [[Definition:Reflexive Reduction|reflexive reduction]], for all $a, b \in S$: :$a \mathrel {\RR^\ne} b$ {{iff}} $a \mathrel \RR b$ but $a \ne b$. By definition of the [[Definition:Diagonal Relation|diagonal relation]] $\Delta_S$: :$a \ne b$ {{iff}} $\tuple {a, b} \notin \Delta_S$ Thus, considered as [[Definition:Subset|subsets]] of $S \times S$, we have: :$\RR^\ne = \RR \setminus \Delta_S$ By [[Diagonal Relation is Universally Compatible]], $\Delta_S$ is [[Definition:Relation Compatible with Operation|compatible]] with $\circ$. Thus by [[Set Difference of Relations Compatible with Group Operation is Compatible]], $\RR^\ne$ is [[Definition:Relation Compatible with Operation|compatible]] with $\circ$. {{qed}} [[Category:Compatible Relations]] [[Category:Reflexive Reductions]] 5bruh6rzeh2dor1v9o7f8hwoz6mv5cv	0
Let $S_n$ be the $n$th [[Definition:Partial Sum|partial sum]] of $\displaystyle \sum_{n \mathop = 1}^\infty z_n$. Let $P_n$ be the $n$th [[Definition:Partial Product|partial product]] of $\displaystyle \prod_{n \mathop = 1}^\infty \exp \left({z_n}\right)$. By [[Exponential of Sum]], $\exp \left({S_n}\right) = P_n$ for all $n \in \N$. By [[Exponential Function is Continuous]], $\displaystyle \lim_{n \mathop \to \infty} \exp \left({S_n}\right) = \exp z$. By [[Exponential of Complex Number is Nonzero]], $\exp z \ne 0$. Thus $\displaystyle \lim_{n \mathop \to \infty} P_n = \exp z \ne 0$. {{qed}}	0
:$\forall \omega \in \C: \paren {r e^{i \theta} }^\omega = r^\omega e^{i \omega \theta}$	0
Let $\displaystyle \prod_{k \mathop = 1}^n S_k$ be the [[Definition:Finite Cartesian Product|cartesian product]] of a [[Definition:Finite Sequence|(finite) sequence]] of [[Definition:Set|sets]] $\sequence {S_n}$. Then: :$\displaystyle \card {\prod_{k \mathop = 1}^n S_k} = \prod_{k \mathop = 1}^n \card {S_k}$	0
Let $\struct {R, +, \circ}$ be a [[Definition:Ring with Unity|ring with unity]]. First, let $J \subsetneq R$. By [[Ideal of Unit is Whole Ring/Corollary|Ideal of Unit is Whole Ring: Corollary]]: :$1_R \in J \implies J = R$ So $1_R \notin J$. Thus $1_R + J \ne J$, so $1_R + J \ne 0_{R/J}$. Now let $x \in R$. {{begin-eqn}} {{eqn | l = \paren {1_R + J} \circ \paren {x + J} | r = 1_R \circ x + J | c = [[Definition:Quotient Ring|Definition of $\circ$]] in $R / J$ }} {{eqn | r = x + J | c = {{Defof|Unity of Ring}} }} {{eqn | r = x \circ 1_R + J | c = {{Defof|Unity of Ring}} }} {{eqn | r = \paren {x + J} \circ \paren {1_R + J} | c = [[Definition:Quotient Ring|Definition of $\circ$]] in $R / J$ }} {{end-eqn}} Thus $R / J$ has a [[Definition:Unity of Ring|unity]], and that [[Definition:Unity of Ring|unity]] is $1_R + J$. Now suppose $J = R$. Then $1_R + J = J$ and therefore $1_R = 0_R$. The only ring to have $1_R = 0_R$ is the [[Definition:Null Ring|null ring]]. This is appropriate, because: :$R / J = R / R = \set {0_{R / R} }$ which is the [[Definition:Null Ring|null ring]]. {{Qed}}	0
From [[Cardano's Formula]], the [[Definition:Root of Polynomial|roots]] of $P$ are: :$(1): \quad x_1 = S + T - \dfrac b {3 a}$ :$(2): \quad x_2 = - \dfrac {S + T} 2 - \dfrac b {3 a} + \dfrac {i \sqrt 3} 2 \paren {S - T}$ :$(3): \quad x_3 = - \dfrac {S + T} 2 - \dfrac b {3 a} - \dfrac {i \sqrt 3} 2 \paren {S - T}$ where: :$S = \sqrt [3] {R + \sqrt {Q^3 + R^2} }$ :$T = \sqrt [3] {R - \sqrt {Q^3 + R^2} }$ Let $D = Q^3 + R^2 < 0$. Then $S^3 = R + i \sqrt {\size {Q^3 + R^2} }$. We can express this in [[Definition:Polar Form of Complex Number|polar form]]: :$S^3 = r \paren {\cos \theta + i \sin \theta}$ where: :$r = \sqrt {R^2 + \paren {\sqrt {Q^3 + R^2} }^2} = \sqrt {R^2 - \paren {Q^3 + R^2} } = \sqrt {-Q^3}$ :$\tan \theta = \dfrac {\sqrt {\size {Q^3 + R^2} } } R$ Then: :$\cos \theta = \dfrac R {\sqrt {-Q^3} }$ Similarly for $T^3$. The result: :$(1): \quad x_1 = 2 \sqrt {-Q} \, \map \cos {\dfrac \theta 3} - \dfrac b {3 a}$ :$(2): \quad x_2 = 2 \sqrt {-Q} \, \map \cos {\dfrac \theta 3 + \dfrac {2 \pi} 3} - \dfrac b {3 a}$ :$(3): \quad x_3 = 2 \sqrt {-Q} \, \map \cos {\dfrac \theta 3 + \dfrac {4 \pi} 3} - \dfrac b {3 a}$ follows after some algebra. {{qed}}	0
Let $G$ be a [[Definition:Group|group]] whose [[Definition:Identity Element|identity]] is $e$. Let $H_1, H_2$ be [[Definition:Subgroup|subgroups]] of $G$. Let $\phi: H_1 \times H_2 \to G$ be a [[Definition:Mapping|mapping]] defined by $\map \phi {h_1, h_2} = h_1 h_2$. Let $H_1$ and $H_2$ be [[Definition:Normal Subgroup|normal subgroups]] of $G$, and let $H_1 \cap H_2 = \set e$. Then $\phi$ is a [[Definition:Group Homomorphism|(group) homomorphism]].	0
By [[Idempotent Elements of Ring with No Proper Zero Divisors]], it follows that the [[Definition:Unity of Ring|unity]] of a [[Definition:Subdomain|subdomain]] is the [[Definition:Unity of Ring|unity]] of the [[Definition:Integral Domain|integral domain]] it's a [[Definition:Subdomain|subdomain]] of. {{qed}}	0
Let $a \in \R_{\ne 0}$. Let $b^2 - 4 a c < 0$. Then: :$\displaystyle \int \frac {\d x} {\sqrt {a x^2 + b x + c} } = \frac 1 {\sqrt a} \sinh^{-1} \paren {\dfrac {2 a x + b} {\sqrt {4 a c - b^2} } } + C$	0
First, to prove that $\struct {S^*, *}$ is a [[Definition:Semigroup|semigroup]]. That is, to prove $*$ is [[Definition:Associative Operation|associative]]. Let $s, s', s'' \in S^*$ be [[Definition:Finite Sequence|sequences]] of [[Definition:Length of Sequence|lengths]] $n, n', n''$, respectively. Then: {{begin-eqn}} {{eqn | l = \map {s * \paren {s' * s''} } i | r = \begin {cases} \map s i & \text {if $1 \le i \le n$} \\ \map {s' * s''} {i - n} & \text {if $n < i \le n + n' + n''$} \end {cases} }} {{eqn | r = \begin {cases} \map s i & \text {if $1 \le i \le n$} \\ \map {s'} {i - n} & \text {if $n < i \le n + n'$} \\ \map {s''} {i - n - n'} & \text {if $n + n' < i \le n + n' + n''$} \end {cases} }} {{eqn | l = \map {\paren {s * s'} * s''} i | r = \begin {cases} \map {s * s'} i & \text {if $1 \le i \le n + n'$} \\ \map {s''} {i - n - n'} & \text {if $n + n' < i \le n + n' + n''$} \end {cases} }} {{eqn | r = \begin {cases} \map s i & \text {if $1 \le i \le n$} \\ \map {s'} {i - n} & \text {if $n < i \le n + n'$} \\ \map {s''} {i - n - n'} & \text {if $n + n' < i \le n + n' + n''$} \end {cases} }} {{end-eqn}} Hence, by [[Equality of Mappings]]: :$s * \paren {s' * s''} = \paren {s * s'} * s''$ that is, $*$ is [[Definition:Associative Operation|associative]]. Now, to prove $\struct {S^*, *}$ has an [[Definition:Identity Element|identity]] $e$. It follows immediately from the [[Definition:Length of Sequence|length]] of a [[Definition:Concatenation of Ordered Tuples|concatenation]] that $e$ must have [[Definition:Length of Sequence|length]] $0$. That is, the only choice for $e$ is the [[Definition:Empty Sequence|empty sequence]]. Now, for any $s \in S^*$: :$\map {e * s} i = \begin {cases} \map e i & \text {if $1 \le i \le 0$} \\ \map s i & \text {if $0 < i < 0 + n$} \end {cases}$ from which we see that $e * s = s$. Also: :$\map {s * e} i = \begin {cases} \map s i & \text {if $1 \le i \le n$} \\ \map e i & \text {if $n < i < n + 0$} \end {cases}$ which shows $s * e = s$. So indeed the [[Definition:Empty Sequence|empty sequence]] is an [[Definition:Identity Element|identity element]] of $\struct {S^*, *}$. Hence $\struct {S^*, *}$ is a [[Definition:Monoid|monoid]]. {{qed}}	0
For each $n \in \N$, define $S_n$ to be the [[Definition:Set|set]]: :$S_n := \left\{{\dfrac m n: m \in \Z}\right\}$ By [[Integers are Countably Infinite]], each $S_n$ is [[Definition:Countably Infinite|countably infinite]]. Because each [[Definition:Rational Number|rational number]] can be written down with a [[Definition:Positive Integer|positive]] [[Definition:Denominator|denominator]], it follows that: :$\forall q \in \Q: \exists n \in \N: q \in S_n$ which is to say: :$\displaystyle \bigcup_{n \mathop \in \N} S_n = \Q$ By [[Countable Union of Countable Sets is Countable]], it follows that $\Q$ is [[Definition:Countable|countable]]. Since $\Q$ is manifestly [[Definition:Infinite Set|infinite]], it is [[Definition:Countably Infinite|countably infinite]]. {{qed}}	0
From [[Prime Power of Sum Modulo Prime]] we have: :$(1): \quad \paren {a + b}^{p^n} \equiv \paren {a^{p^n} + b^{p^n} } \pmod p$ We can write this: :$\paren {a + b}^{p^n k} = \paren {\paren {a + b}^{p^n} }^k$ By $(1)$ and [[Congruence of Powers]], we therefore have: :$\paren {a + b}^{p^n k} \equiv \paren {a^{p^n} + b^{p^n} }^k \pmod p$ The coefficient $\dbinom {p^n k} {p^n}$ is the [[Definition:Binomial Coefficient|binomial coefficient]] of $b^{p^n}$ in $\paren {a + b}^{p^n k} = \paren {\paren {a + b}^{p^n} }^k$. Expanding $\paren {a^{p^n} + b^{p^n} }^k$ using the [[Binomial Theorem]], we find that the coefficient of $b^{p^n}$, the second term, is $\dbinom k 1 = k$. So: :$\dbinom {p^n k} {p^n} \equiv k \pmod p$ {{qed}}	0
For all [[Definition:Number|numbers]] $a, b$ where $a, b$ in $\N, \Z, \Q$ or $\R$: :$\min \set {a, b} = \dfrac 1 2 \paren {a + b - \size {a - b} }$	0
{{improve}} Let $\mathcal V$ be an [[Definition:Inner Product Space|inner product space]]. {{explain|The theorem calls for a [[Definition:Hilbert Space|Hilbert space]]. What is actually required?}} Let $T: \mathcal V \to \mathcal V$ be a [[Definition:Normal Operator|normal linear operator]]. Requisite knowledge: $T^*$ is the [[Definition:Adjoint Linear Transformation|adjoint]] of $T$ and is defined by the fact that for any $u, w \in \mathcal V$, we have :$\left\langle{T u, w}\right\rangle = \left\langle{T^* w}\right\rangle$ It is important to note the existence and uniqueness of adjoint operators. {{explain|Link to the required proofs and/or definitions as given above.}} '''Claim''': We know that for $v \in \mathcal V$: :$T v = \lambda v \iff T^* v = \overline \lambda v$ This is true because for all [[Definition:Normal Operator|normal operators]], by definition: :$T^* T = T T*$ and so: {{begin-eqn}} {{eqn | l = \left\Vert{T v}\right\Vert^2 | r = \left\langle{T v, T v}\right\rangle | c = }} {{eqn | r = \left\langle{T^* T v, v}\right\rangle | c = }} {{eqn | r = \left\langle{T T^* v, v}\right\rangle | c = }} {{eqn | r = \left\langle{T^* v, T^*v}\right\rangle | c = }} {{eqn | r = \left\Vert{T^* v}\right\Vert^2 | c = }} {{end-eqn}} Since for [[Definition:Normal Operator|normal]] $T$, $\left({T - \lambda I}\right)$ is [[Definition:Normal Operator|normal]], we have: {{explain|Link to a page demonstrating the above}} {{begin-eqn}} {{eqn | l = T v | r = \lambda v | c = }} {{eqn | ll= \iff | l = \left\Vert{\left({T - \lambda I}\right) v}\right\Vert | r = 0 | c = }} {{eqn | ll= \iff | l = \left\Vert{\left({T - \lambda I}\right)^* v}\right\Vert | r = 0 | c = }} {{eqn | ll= \iff | l = \left\Vert{T^* v - \overline \lambda v}\right\Vert | r = 0 | c = }} {{eqn | ll= \iff | l = T^* v | r = \overline \lambda v | c = }} {{end-eqn}} Now, if $T v_1 = \lambda_1 v_1$ and $T v_2 = \lambda_2 v_2$, where $\lambda_1 \ne \lambda_2$ and $v_1, v_2$ are eigenvectors (i.e. $v_1, v_2 \ne \vec 0$), we have: {{begin-eqn}} {{eqn | l = \lambda_1 \left\langle{v_1, v_2}\right\rangle | r = \left\langle{\lambda_1 v_1, v_2}\right\rangle | c = }} {{eqn | r = \left\langle{T v_1, v_2}\right\rangle | c = }} {{eqn | r = \left\langle{v_1, T^* v_2}\right\rangle | c = }} {{eqn | r = \left\langle{v_1, \overline{\lambda_2} v_2}\right\rangle | c = }} {{eqn | r = \lambda_2 \left\langle{v_1, v_2}\right\rangle | c = }} {{end-eqn}} Since $\lambda_1 \ne \lambda_2$, this is only possible if $\left\langle{v_1, v_2}\right\rangle = 0$, which means the [[Definition:Eigenvector|eigenvectors]] of our [[Definition:Normal Operator|normal operator]] are [[Definition:Orthogonal (Hilbert Space)#Sets|orthogonal]]. {{qed}}	0
:$\tanh \paren {a + b i} = \dfrac {\tanh a - \tanh a \tan^2 b} {1 + \tan^2 a \tanh^2 b} + \dfrac {\tan b + \tanh^2 a \tan b} {1 + \tanh^2 a \tan^2 b} i$	0
From [[Normed Division Ring Operations are Continuous/Corollary|Corollary to Normed Division Ring Operations are Continuous]]: :$\struct {R, +, *, \tau_{_R} }$ is a [[Definition:Topological Division Ring|topological division ring]]. From [[Product Rule for Continuous Mappings to Topological Division Ring]]: :$f * g: \struct {S, \tau_{_S} } \to \struct {R, \tau_{_R} }$ is a [[Definition:Continuous Mapping on Set|continuous mapping]]. {{qed}}	0
{{begin-eqn}} {{eqn | r = \int \frac {\d x} {x \paren {a x^2 + b x + c}^{n + \frac 1 2} } | o = | c = }} {{eqn | r = \int \frac {c \rd x} {c x \paren {a x^2 + b x + c}^{n + \frac 1 2} } | c = multiplying [[Definition:Numerator|top]] and [[Definition:Denominator|bottom]] by $c$ }} {{eqn | r = \frac 1 c \int \frac {\paren {a x^2 + b x + c - a x^2 - b x} \rd x} {c x \paren {a x^2 + b x + c}^{n + \frac 1 2} } | c = }} {{eqn | r = \frac 1 c \int \frac {\paren {a x^2 + b x + c} \rd x} {x \paren {a x^2 + b x + c}^{n + \frac 1 2} } - \frac a c \int \frac {x^2 \rd x} {x \paren {a x^2 + b x + c}^{n + \frac 1 2} } - \frac b c \int \frac {x \rd x} {x \paren {a x^2 + b x + c}^{n + \frac 1 2} } | c = [[Linear Combination of Integrals]] }} {{eqn | n = 1 | r = \frac 1 c \int \frac {\d x} {x \paren {a x^2 + b x + c}^{n - \frac 1 2} } - \frac a c \int \frac {x \rd x} {\paren {a x^2 + b x + c}^{n + \frac 1 2} } - \frac b c \int \frac {\d x} {\paren {a x^2 + b x + c}^{n + \frac 1 2} } | c = simplifying }} {{end-eqn}} Now take: {{begin-eqn}} {{eqn | r = \int \frac {x \rd x} {\paren {a x^2 + b x + c}^{n + \frac 1 2} } | o = | c = }} {{eqn | r = \int \frac {2 a x \rd x} {2 a \paren {a x^2 + b x + c}^{n + \frac 1 2} } | c = multiplying [[Definition:Numerator|top]] and [[Definition:Denominator|bottom]] by $2 a$ }} {{eqn | r = \int \frac {\paren {2 a x + b - b} \rd x} {2 a \paren {a x^2 + b x + c}^{n + \frac 1 2} } | c = }} {{eqn | n = 2 | r = \frac 1 {2 a} \int \frac {\paren {2 a x + b} \rd x} {\paren {a x^2 + b x + c}^{n + \frac 1 2} } - \frac b {2 a} \int \frac {\d x} {\paren {a x^2 + b x + c}^{n + \frac 1 2} } | c = [[Linear Combination of Integrals]] }} {{end-eqn}} Let: {{begin-eqn}} {{eqn | l = z | r = a x^2 + b x + c | c = }} {{eqn | ll= \leadsto | l = \frac {\d z} {\d x} | r = 2 a x + b | c = [[Derivative of Power]] }} {{eqn | ll= \leadsto | l = \int \frac {\paren {2 a x + b} \rd x} {\paren {a x^2 + b x + c}^{n + \frac 1 2} } | r = \int z^{-n - \frac 1 2} \rd z | c = [[Integration by Substitution]] }} {{eqn | r = \frac {z^{-n + \frac 1 2} } {-n + \frac 1 2} | c = [[Primitive of Power]] }} {{eqn | n = 3 | r = \frac {-2} {\paren {2 n - 1} \paren {a x^2 + b x + c}^{n - \frac 1 2} } | c = simplifying }} {{end-eqn}} Thus: {{begin-eqn}} {{eqn | r = \int \frac {x \rd x} {\paren {a x^2 + b x + c}^{n + \frac 1 2} } | o = | c = }} {{eqn | r = \frac 1 {2 a} \int \frac {\paren {2 a x + b} \rd x} {\paren {a x^2 + b x + c}^{n + \frac 1 2} } - \frac b {2 a} \int \frac {\d x} {\paren {a x^2 + b x + c}^{n + \frac 1 2} } | c = from $(2)$ }} {{eqn | r = \frac 1 {2 a} \paren {\frac {-2} {\paren {2 n - 1} \paren {a x^2 + b x + c}^{n - \frac 1 2} } } - \frac b {2 a} \int \frac {\d x} {\paren {a x^2 + b x + c}^{n + \frac 1 2} } | c = from $(3)$ }} {{eqn | r = \frac {-1} {a \paren {2 n - 1} \paren {a x^2 + b x + c}^{n - \frac 1 2} } - \frac b {2 a} \int \frac {\d x} {\paren {a x^2 + b x + c}^{n + \frac 1 2} } | c = simplifying }} {{end-eqn}} So: {{begin-eqn}} {{eqn | r = \int \frac {\d x} {x \paren {a x^2 + b x + c}^{n + \frac 1 2} } | o = | c = }} {{eqn | r = \frac 1 c \int \frac {\d x} {x \paren {a x^2 + b x + c}^{n - \frac 1 2} } - \frac a c \int \frac {x \rd x} {\paren {a x^2 + b x + c}^{n + \frac 1 2} } - \frac b c \int \frac {\d x} {\paren {a x^2 + b x + c}^{n + \frac 1 2} } | c = from $(1)$ }} {{eqn | r = \frac 1 c \int \frac {\d x} {x \paren {a x^2 + b x + c}^{n - \frac 1 2} } | c = }} {{eqn | o = | ro= - | r = \frac a c \paren {\frac {-1} {a \paren {2 n - 1} \paren {a x^2 + b x + c}^{n - \frac 1 2} } - \frac b {2 a} \int \frac {\d x} {\paren {a x^2 + b x + c}^{n + \frac 1 2} } } | c = from $(3)$ }} {{eqn | o = | ro= - | r = \frac b c \int \frac {\d x} {\paren {a x^2 + b x + c}^{n + \frac 1 2} } | c = }} {{eqn | r = \frac 1 c \int \frac {\d x} {x \paren {a x^2 + b x + c}^{n - \frac 1 2} } | c = }} {{eqn | o = | ro= + | r = \frac 1 {\paren {2 n - 1} c \paren {a x^2 + b x + c}^{n - \frac 1 2} } + \frac b {2 c} \int \frac {\d x} {\paren {a x^2 + b x + c}^{n + \frac 1 2} } | c = simplifying }} {{eqn | o = | ro= - | r = \frac b c \int \frac {\d x} {\paren {a x^2 + b x + c}^{n + \frac 1 2} } | c = }} {{eqn | r = \frac 1 {\paren {2 n - 1} c \paren {a x^2 + b x + c}^{n - \frac 1 2} } + \frac 1 c \int \frac {\d x} {x \paren {a x^2 + b x + c}^{n - \frac 1 2} } - \frac b {2 c} \int \frac {\d x} {\paren {a x^2 + b x + c}^{n + \frac 1 2} } | c = gathering terms }} {{end-eqn}} {{qed}}	0
{{ProofWanted|This is (probably) a specialisation of a more general result on cyclic groups.}}	0
The axioms $(C1)$ to $(C3)$ are checked for a [[Definition:Metacategory|metacategory]]. Pick any two [[Definition:Morphism|morphisms]] $f : \left({A, a}\right) \to \left({B, b}\right)$ and $g : \left({B, b}\right) \to \left({C, c}\right)$ from $\mathbf{Set}_*$. By the definition of [[Definition:Composition of Morphisms|composition]] in the [[Definition:Category of Pointed Sets|category of pointed sets]]: :$\left({g \circ f}\right) \left({a}\right) = g \left({f \left({a}\right)}\right) = g \left({b}\right) = c$ whence $g \circ f$ is a [[Definition:Pointed Mapping|pointed mapping]] from $\left({A, a}\right)$ to $\left({C, c}\right)$. That composition of [[Definition:Pointed Mapping|pointed mappings]] is [[Definition:Associative|associative]] follows from [[Composition of Mappings is Associative]]. For any [[Definition:Object (Category Theory)|object]] $\left({A, a}\right)$, the [[Definition:Identity Mapping|identity mapping]] $\operatorname{id}_A$ induces a [[Definition:Pointed Mapping|pointed map]] $\operatorname{id}_{\left({A, a}\right)}: \left({A, a}\right) \to \left({A, a}\right)$, as $\operatorname{id}_A \left({a}\right) = a$. By [[Identity Mapping is Left Identity]] and [[Identity Mapping is Right Identity]], this is the [[Definition:Identity Morphism|identity morphism]] for $\left({A, a}\right)$. {{qed}} [[Category:Category Theory]] 508169qexbek7gz2m6l5hfg83j45x57	0
Let $m$ and $n$ be [[Definition:Finite Ordinal|finite ordinals]]. Let $m \ne 0$, where $0$ is the [[Definition:Zero (Ordinal)|zero ordinal]]. Let $x$ be a [[Definition:Limit Ordinal|limit ordinal]]. Then: :$m \times \left({ x + n }\right) = x + \left({ m \times n }\right)$ {{expand|Via [[Definition:Cantor Normal Form|Cantor normal form]], all ordinals are of the form $x+n$}}	0
=== [[First-Countability is Preserved under Open Continuous Surjection|Proof for First-Countability]] === {{:First-Countability is Preserved under Open Continuous Surjection}} === [[Second-Countability is Preserved under Open Continuous Surjection|Proof for Second-Countability]] === {{:Second-Countability is Preserved under Open Continuous Surjection}}	0
The [[Definition:Cartesian Product|cartesian product]] of two [[Definition:Countable Set|countable sets]] is [[Definition:Countable Set|countable]].	0
Let $R$ and $S$ be [[Definition:Commutative and Unitary Ring|commutative rings with unity]], and $\phi: R \to S$ a [[Definition:Ring Monomorphism|ring monomorphism]]. Then there is a ring $T$ [[Definition:Ring Isomorphism|isomorphic]] to $S$ that contains $R$ as a [[Definition:Subring|subring]].	0
$S^a$ is defined as $a \circ S \circ a^{-1}$ from the definition of the [[Definition:Conjugate of Group Subset|conjugate of a set]]. From the definition of [[Definition:Subset Product with Singleton|subset product with a singleton]], this can be seen to be the same thing as: :$S^a = \set a \circ S \circ \set {a^{-1} }$. Thus we can express $\paren {S^a}^b$ as $b \circ \paren {a \circ S \circ a^{-1} } \circ b^{-1}$, and understand that the {{RHS}} refers to [[Definition:Subset Product|subset products]]. From [[Subset Product within Semigroup is Associative]] (which applies because $\circ$ is [[Definition:Associative Operation|associative]]), it then follows directly that: {{begin-eqn}} {{eqn | l = \paren {S^a}^b | r = b \circ \paren {a \circ S \circ a^{-1} } \circ b^{-1} | c = from above }} {{eqn | r = \paren {b \circ a} \circ S \circ \paren {a^{-1} \circ b^{-1} } | c = [[Subset Product within Semigroup is Associative]] }} {{eqn | r = \paren {b \circ a} \circ S \circ \paren {b \circ a}^{-1} | c = [[Inverse of Group Product]] }} {{eqn | r = S^{b \circ a} | c = {{Defof|Conjugate of Group Subset}} }} {{end-eqn}} {{Qed}} === Proof for Alternative Definition === Using the same preliminary argument as above, we then follow: {{begin-eqn}} {{eqn | l = \paren {S^a}^b | r = b^{-1} \circ \paren {a^{-1} \circ S \circ a} \circ b | c = from above }} {{eqn | r = \paren {b^{-1} \circ a^{-1} } \circ S \circ \paren {a \circ b} | c = [[Subset Product within Semigroup is Associative]] }} {{eqn | r = \paren {a \circ b}^{-1} \circ S \circ \paren {a \circ b} | c = [[Inverse of Group Product]] }} {{eqn | r = S^{a \circ b} | c = {{Defof|Conjugate (Group Theory)/Subset/Also defined as|Conjugate of Group Subset}} }} {{end-eqn}} {{Qed}}	0
{{begin-eqn}} {{eqn | l = \sec i | r = \frac 1 {\cos i} | c = Definition of [[Definition:Complex Secant Function|Complex Secant]] }} {{eqn | r = \frac 1 {\frac e 2 + \frac 1 {2 e} } | c = [[Cosine of i|Cosine of $i$]] }} {{eqn | r = \frac {2 e} {e^2 + 1} | c = multiplying [[Definition:Denominator|denominator]] and [[Definition:Numerator|numerator]] by $2 e$ }} {{end-eqn}} {{qed}}	0
Let $r, s \in \Z$. Then: {{begin-eqn}} {{eqn | l = \map {f_c} {r s} | r = \paren {r s}^c | c = }} {{eqn | r = r^c s^c | c = [[Exponent Combination Laws/Product of Powers|Exponent Combination Laws: Product of Powers]] }} {{eqn | r = \map {f_c} r \map {f_c} s | c = }} {{end-eqn}} {{Qed}}	0
{{begin-eqn}} {{eqn | l = \csc 135 \degrees | r = \map \csc {180 \degrees - 45 \degrees} | c = }} {{eqn | r = \csc 45 \degrees | c = [[Cosecant of Supplementary Angle]] }} {{eqn | r = \sqrt 2 | c = [[Cosecant of 45 Degrees|Cosecant of $45 \degrees$]] }} {{end-eqn}} {{qed}}	0
Let $G \left({z}\right)$ be the [[Definition:Generating Function|generating function]] for the [[Definition:Sequence|sequence]] $\left\langle{a_n}\right\rangle$. Let $m \in \Z_{\ge 0}$ be a [[Definition:Non-Negative Integer|non-negative integer]]. Then $\dfrac 1 {z^m} \left({G \left({z}\right) - \displaystyle \sum_{k \mathop = 0}^{m - 1} a_k z^k}\right)$ is the [[Definition:Generating Function|generating function]] for the [[Definition:Sequence|sequence]] $\left\langle{a_{n + m} }\right\rangle$.	0
Let $\struct {D, +, \circ}$ be an [[Definition:Integral Domain|integral domain]]. Let $\struct {F, \oplus, \cdot}$ be a [[Definition:Field of Quotients|field of quotients]] of $D$. Then $F$ satisfies the following [[Definition:Universal Property|universal property]]: There exists a [[Definition:Ring Homomorphism|(ring) homomorphism]] $\iota : D \to F$ such that: ::for every [[Definition:Field (Abstract Algebra)|field]] $\tilde F$ and :and: ::for every [[Definition:Ring Homomorphism|(ring) homomorphism]] $\phi: D \to \tilde F$ :there exists a unique [[Definition:Field Homomorphism|field homomorphism]] $\psi: F \to \tilde F$ satisfying: :::$\psi \iota = \phi$ That is, the following diagram [[Definition:Commutative Diagram|commutes]]: :[[File:FieldFracComDiag.jpg|Universal Property]] Namely we may take: :$\psi: a / b \mapsto \map \phi a \map \phi b^{-1}$	0
First it is shown that the [[Definition:Mapping|mapping]] $\phi: D \sqbrk {X_1} \to D \sqbrk {X_2}$ given by: :$\displaystyle \map \phi {\sum_{k \mathop = 0}^n a_k \circ X_1^k} = \sum_{k \mathop = 0}^n a_k \circ X_2^k$ is a [[Definition:Bijection|bijection]]. Let $p, q \in \phi: D \sqbrk {X_1}$. Suppose $\map \phi p = \map \phi q$. Then the [[Definition:Polynomial Coefficient|coefficients]] of $\map \phi p$ and $\map \phi q$ are equal, and $p_1 = q_1$. Thus, by definition, $\phi$ is an [[Definition:Injection|injection]]. By the same argument, the [[Definition:Mapping|mapping]] $\psi: D \sqbrk {X_2} \to D \sqbrk {X_1}$ defined as: :$\displaystyle \map \psi {\sum_{k \mathop = 0}^n a_k \circ X_2^k} = \sum_{k \mathop = 0}^n a_k \circ X_1^k$ is similarly an [[Definition:Injection|injection]]. Thus by [[Injection is Bijection iff Inverse is Injection]], $\phi$ is a [[Definition:Bijection|bijection]]. It remains to show that $\phi$ is a [[Definition:Ring Homomorphism|ring homomorphism]]. Let $\displaystyle p = \sum_{k \mathop = 0}^n a_k \circ X_1^k, q = \sum_{k \mathop = 0}^n b_k \circ X_2^k \in D \sqbrk {X_1}$. For convenience we set $a_k = 0$, $k > n$ and $b_k = 0$, $k > m$. We have: {{begin-eqn}} {{eqn | l = \map \phi {p + q} | r = \map \phi {\sum_{k \mathop = 0}^\infty \paren {a_k + b_k} X_1^k} | c = {{Defof|Addition of Polynomials}} }} {{eqn | r = \sum_{k \mathop = 0}^\infty \left({a_k + b_k}\right) X_2^k | c = }} {{eqn | r = \sum_{k \mathop = 0}^m a_k X_2^k + \sum_{k \mathop = 0}^n b_k X_2^k | c = }} {{eqn | r = \map \phi p + \map \phi q | c = }} {{end-eqn}} Similarly for [[Definition:Multiplication of Polynomials|multiplication]]: {{begin-eqn}} {{eqn | l = \map \phi {p q} | r = \map \phi {\sum_{k \mathop = 0}^{m n} \sum_{i + j = k} a_i b_j X_1^k} | c = {{Defof|Multiplication of Polynomials}} }} {{eqn | r = \sum_{k \mathop = 0}^{m n} \sum_{i + j \mathop = k} a_i b_j X_2^k | c = }} {{eqn | r = \paren {\sum_{k \mathop = 0}^n a_k \circ X_1^k} \paren {\sum_{k \mathop = 0}^n b_k \circ X_2^k} | c = }} {{eqn | r = \map \phi p \, \map \phi q | c = }} {{end-eqn}} This completes the proof. {{qed}}	0
Let $x \in \operatorname{Rad} \left({\mathfrak a}\right)$. We show that $x \in \operatorname{Rad} \left({\mathfrak b}\right)$. By definition of [[Definition:Radical of Ideal of Ring|radical]], there exists $n \in \N$ such that the [[Definition:Power of Ring Element|power]] $x^n \in \mathfrak a$. Because $\mathfrak a \subseteq \mathfrak b$, also $x^n \in \mathfrak b$. Thus $x \in \operatorname{Rad} \left({\mathfrak b}\right)$. {{qed}} [[Category:Radical of Ideals]] k3nevcqozzdlobgpyk4rf16r31o9smw	0
Let $G \left({z}\right)$ be the [[Definition:Generating Function|generating function]] for the [[Definition:Sequence|sequence]] $\left\langle{a_n}\right\rangle$. Then: :$z G' \left({z}\right)$ is the [[Definition:Generating Function|generating function]] for the [[Definition:Sequence|sequence]] $\left\langle{n a_n}\right\rangle$ where $G' \left({z}\right)$ is the [[Definition:Derivative|derivative]] of $G \left({z}\right)$ {{WRT|Differentiation}} $z$.	0
Let $f: \C \to \C$ be an [[Definition:Entire Function|entire function]]. Let $\omega$ be its [[Definition:Order of Entire Function|order]]. Let $\tau$ be its [[Definition:Exponent of Convergence|exponent of convergence]]. Then $\tau \le \omega$.	0
Let $\N$ denote the [[Definition:Set|set]] of [[Definition:Natural Number|natural numbers]]. Let $\powerset \N$ denote the [[Definition:Power Set|power set]] of $\N$. Let $\card {\powerset \N}$ denote the [[Definition:Cardinality|cardinality]] of $\powerset \N$. Then $\card {\powerset \N}$ is the [[Definition:Cardinality|cardinality]] of the [[Definition:Continuum|continuum]].	0
We have [[Exponential on Real Numbers is Injection]]. Let $y \in \R_{> 0}$. Then $\exists x \in \R: x = \map \ln y$ That is: :$\exp x = y$ and so $\exp: \R \to \R_{>0}$ is a [[Definition:Surjection|surjection]]. Hence the result. {{qed}}	0
Let $B = \set {\phi_{i j}: i \in \closedint 1 n, j \in \closedint 1 m}$. Let $\displaystyle \sum_{j \mathop = 1}^m \sum_{i \mathop = 1}^n \lambda_{i j} \phi_{i j} = 0$. Then: :$\displaystyle \forall k \in \closedint 1 n: 0 = \sum_{j \mathop = 1}^m \sum_{i \mathop = 1}^n \lambda_{i j} \map {\phi_{i j} } {a_k} = \sum_{j \mathop = 1}^m \lambda_{k j} b_j$ So: :$\forall j \in \closedint 1 n: \lambda_{k j} = 0$ Hence $B$ is [[Definition:Linearly Independent Set|linearly independent]]. Now let $\phi \in \map {\LL_R} {G, H}$. Let $\tuple {\alpha_{i 1}, \alpha_{i 2}, \ldots, \alpha_{i m} }$ be the [[Definition:Sequence|sequence]] of [[Definition:Scalar (Module)|scalars]] that satisfies: :$\displaystyle \forall i \in \closedint 1 n: \map \phi {a_i} = \sum_{j \mathop = 1}^m \alpha_{i j} b_j$ Then: :$\displaystyle \forall k \in \closedint 1 n: \map \phi {a_k} = \map {\paren {\sum_{j \mathop = 1}^m \sum_{i \mathop = 1}^n \alpha_{i j} u_{i j} } } {a_k}$ by a calculation similar to the preceding. So, by [[Linear Transformation of Generated Module]]: :$\displaystyle u = \sum_{j \mathop = 1}^m \sum_{i \mathop = 1}^n \alpha_{i j} u_{i j}$ Thus $B$ is a [[Definition:Generator of Module|generator]] for $\phi \in \map {\LL_R} {G, H}$. {{Qed}}	0
Let $\left({ A_1 , \preceq_1 }\right)$ be an [[Definition:Ordered Set|ordered set]]. Let $\phi : A_1 \to A_2$ be a [[Definition:Bijection|bijection]]. Let: : $\preceq_2 \mathop{:=} \left\{ \left({\phi\left({x}\right), \phi\left({y}\right) }\right): x \in A_1 \land y \in A_1 \land x \mathop{\preceq_1} y \right\}$ Then $\phi : \left({ A_1 , \preceq_1 }\right) \to \left({ A_2 , \preceq_2 }\right)$ is an [[Definition:Order Isomorphism|order isomorphism]].	0
If you list the gaps between consecutive [[Definition:Prime Number|primes]] greater than $5$: :$2, 4, 2, 4, 2, 4, 6, 2, 6, 4, 2, 4, \ldots$ you will notice that consecutive gaps that are equal are of the form $6 x$. This is ''always'' the case. {{OEIS|A001223}}	0
Let $\displaystyle \sum_{n \mathop = 1}^\infty b_n$ be a [[Definition:Divergent Series|divergent series]] of [[Definition:Positive Real Number|positive real numbers]]. Let $\sequence {a_n}$ be a [[Definition:Sequence|sequence in $\R$]]. Let: :$\forall n \in \N_{>0}: b_n \le a_n$ Then the [[Definition:Series|series]] $\displaystyle \sum_{n \mathop = 1}^\infty a_n$ [[Definition:Divergent Series|diverges]].	0
{{begin-eqn}} {{eqn | l = \map \exp {z + 2 \pi i} | r = \map \exp z \, \map \exp {2 \pi i} | c = [[Exponential of Sum/Complex Numbers|Exponential of Sum: Complex Numbers]] }} {{eqn | r = \map \exp z \times 1 | c = [[Euler's Formula/Examples/e^2 i pi|Euler's Formula Example: $e^{2 i \pi}$]] }} {{eqn | r = \map \exp z }} {{end-eqn}} {{qed}}	0
Let $\epsilon \in \R_{>0}$. Let $a \in A$. Set $\delta = \dfrac \epsilon K$. Then: {{begin-eqn}} {{eqn | l = \map {d_1} {x, a} | o = < | r = \delta | c = }} {{eqn | ll= \leadsto | l = \map {d_2} {\map {I_A} x, \map {I_A} a} | o = \le | r = K \map {d_1} {x, a} | c = }} {{eqn | o = < | r = K \delta | c = }} {{eqn | r = \epsilon | c = }} {{end-eqn}} Hence by definition $I_A$ is [[Definition:Continuous at Point of Metric Space|continuous]] at $a$. As $a$ is arbitrary, it follows that this is true for all $a \in A$. Thus $I_A$ is [[Definition:Continuous on Metric Space|continuous]] on the whole of $M_1$. {{qed}}	0
From the definition of [[Definition:Multiplicative Inverse in Field|multiplicative inverse]], $a^{-1}$ is the [[Definition:Inverse Element|inverse element]] of the [[Definition:Multiplicative Group|multiplicative group]] $\struct {F^*, \times}$. The result follows from [[Inverse in Group is Unique]]. {{qed}}	0
By definition, a [[Definition:Topological Group|topological group]] is a [[Definition:Topological Semigroup|topological semigroup]]. Hence $\struct {G, *, \tau_{_G}}$ is a [[Definition:Topological Semigroup|topological semigroup]]. From [[Multiple Rule for Continuous Mappings to Topological Semigroup]]: :$\lambda * f, f * \lambda: \struct {S, \tau_{_S} } \to \struct {G, \tau_{_G} }$ are [[Definition:Continuous Mapping on Set|continuous mappings]]. {{qed}}	0
From [[Euclidean Space is Complete Metric Space]], a [[Definition:Euclidean Space|Euclidean space]] is a [[Definition:Metric Space|metric space]]. From [[Metric Space fulfils all Separation Axioms]] it follows that $\struct {\R \setminus \Q, \tau_d}$ is a [[Definition:Completely Normal Space|completely normal space]]. {{qed}}	0
Let $\map {J_n} x$ denote the [[Definition:Bessel Function of the First Kind|Bessel function of the first kind]] of [[Definition:Order of Bessel Function|order $n$]].	0
Let: {{begin-eqn}} {{eqn | l = z | r = x^2 }} {{eqn | ll= \leadsto | l = \frac {\d z} {\d x} | r = 2 x | c = [[Power Rule for Derivatives]] }} {{eqn | ll= \leadsto | l = \int x \sqrt {x^2 - a^2} \rd x | r = \int \frac {\sqrt z \sqrt {z - a^2} \rd z} {2 \sqrt z} | c = [[Integration by Substitution]] }} {{eqn | r = \frac 1 2 \int \sqrt {z - a^2} \rd z | c = [[Primitive of Constant Multiple of Function]] }} {{eqn | r = \frac 1 2 \frac {2 \paren {\sqrt {z - a^2} }^3} 3 + C | c = [[Primitive of Root of a x + b|Primitive of $\sqrt {a x + b}$]] }} {{eqn | r = \frac {\paren {\sqrt {x^2 - a^2} }^3} 3 + C | c = substituting for $z$ and simplifying }} {{end-eqn}} {{qed}}	0
Recall that a [[Definition:Field (Abstract Algebra)|field]] is a [[Definition:Non-Trivial Ring|non-trivial]] [[Definition:Commutative Division Ring|commutative division ring]]. The result follows from [[Non-Zero Elements of Division Ring form Group]]. {{qed}}	0
:$\displaystyle \int \frac {\d x} {x^2 - a^2} = \begin {cases} \dfrac 1 {2 a} \map \ln {\dfrac {a - x} {a + x} } + C & : \size x < a\\ & \\ \dfrac 1 {2 a} \map \ln {\dfrac {x - a} {x + a} } + C & : \size x > a \\ & \\ \text {undefined} & : \size x = a \end {cases}$	0
By hypothesis there is a [[Definition:Basis of Vector Space|basis]] $B$ of $E$ with $n$ elements. Then $H \cup B$ is a [[Definition:Generator of Module|generator]] for $E$. So by [[Vector Space has Basis Between Linearly Independent Set and Finite Spanning Set]] there exists a [[Definition:Basis of Vector Space|basis]] $C$ of $E$ such that $H \subseteq C \subseteq H \cup B$. {{Qed}}	0
Let $G \left({z}\right)$ be the [[Definition:Generating Function|generating function]] for the [[Definition:Sequence|sequence]] $\left\langle{a_n}\right\rangle$. and $H \left({z}\right)$ be the [[Definition:Generating Function|generating function]] for the [[Definition:Sequence|sequence]] $\left\langle{b_n}\right\rangle$. Then $\alpha G \left({z}\right) + \beta H \left({z}\right)$ is the [[Definition:Generating Function|generating function]] for the [[Definition:Sequence|sequence]] $\left\langle{\alpha a_n + \beta b_n}\right\rangle$.	0
We can write: {{begin-eqn}} {{eqn | l = \int_0^\infty \map \ln {\frac {e^x + 1} {e^x - 1} } \rd x | r = \int_0^\infty \map \ln {\frac {e^{x/2} \paren {e^{x/2} + e^{-x/2} } } {e^{x/2} \paren {e^{x/2} - e^{-x/2} } } } \rd x }} {{eqn | r = \int_0^\infty \map \ln {\coth \frac x 2} \rd x | c = {{Defof|Hyperbolic Cotangent}} }} {{end-eqn}} Let: :$u = \coth \dfrac x 2$ We have, by [[Derivative of Hyperbolic Cotangent Function]]: :$\dfrac {\d u} {\d x} = -\dfrac 1 2 \csch^2 \dfrac x 2$ From [[Difference of Squares of Hyperbolic Cotangent and Cosecant]], this can be written: :$\dfrac {\d u} {\d x} = \dfrac 1 2 \paren {1 - \coth^2 \dfrac x 2} = \dfrac 1 2 \paren {1 - u^2}$ From [[Limit to Infinity of Hyperbolic Cotangent Function]], we have: :as $x \to \infty$, $u \to 1$. We also have: :as $x \to 0^+$, $u \to \infty$. With this, we have: {{begin-eqn}} {{eqn | l = \int_0^\infty \map \ln {\coth \frac x 2} \rd x | r = 2 \int_\infty^1 \frac {\ln u} {1 - u^2} \rd u | c = [[Integration by Substitution|substituting]] $u = \coth \dfrac x 2$ }} {{eqn | r = -2 \int_1^\infty \frac {\ln u} {1 - u^2} \rd u | c = [[Reversal of Limits of Definite Integral]] }} {{eqn | r = -2 \int_1^0 \paren {-\frac 1 {v^2} } \frac {\map \ln {\frac 1 v} } {1 - \paren {\frac 1 {v^2} }^2} \rd v | c = [[Integration by Substitution|substituting]] $v = \dfrac 1 v$ }} {{eqn | r = -2 \int_0^1 \frac {\ln v} {1 - v^2} \rd v | c = [[Reversal of Limits of Definite Integral]] }} {{eqn | r = -2 \int_0^1 \ln v \paren {\sum_{n \mathop = 0}^\infty \paren {v^2}^n} \rd v | c = [[Sum of Geometric Sequence]] }} {{eqn | r = -2 \sum_{n \mathop = 0}^\infty \int_0^1 v^{2 n} \ln v \rd v | c = [[Fubini's Theorem]] }} {{eqn | r = 2 \sum_{n \mathop = 0}^\infty \frac {\map \Gamma 2} {\paren {2 n + 1}^2} | c = [[Definite Integral from 0 to 1 of Power of x by Power of Logarithm of x|Definite Integral from $0$ to $1$ of $x^m \paren {\ln x}^n$]] }} {{eqn | r = 2 \times 1! \times \frac {\pi^2} 8 | c = [[Gamma Function Extends Factorial]], [[Sum of Reciprocals of Squares of Odd Integers]] }} {{eqn | r = \frac {\pi^2} 4 }} {{end-eqn}} {{qed}}	0
The element $1_D$ is the [[Definition:Unity of Ring|unity]] of $\struct {D, +, \circ}$, and so: :$1_D \in D: x = 1_D \circ x$ Similarly, from [[Product of Ring Negatives]]: :$-1_D \in D: x = \paren {-1_D} \circ \paren {-x}$ The result follows from the definition of [[Definition:Divisor of Ring Element|divisor]]. {{qed}}	0
{{ProofWanted|Background needed}}	0
From [[Projection is Surjection]], $\pr_1$ and $\pr_2$ are [[Definition:Surjection|surjections]]. We now need to show they are [[Definition:Group Homomorphism|homomorphisms]]. Let $g, h \in \struct {G, \circ}$ where $g = \tuple {g_1, g_2}$ and $h = \tuple {h_1, h_2}$. Then: {{begin-eqn}} {{eqn | l = \map {\pr_1} {g \circ h} | r = \map {\pr_1} {\tuple {g_1, g_2} \circ \tuple {h_1, h_2} } | c = }} {{eqn | r = \map {\pr_1} {\tuple {g_1 \circ_1 h_1, g_2 \circ_2 h_2} } | c = }} {{eqn | r = g_1 \circ_1 h_1 | c = }} {{eqn | r = \map {\pr_1} g \circ_1 \map {\pr_1} h | c = }} {{end-eqn}} {{begin-eqn}} {{eqn | l = \map {\pr_2} {g \circ h} | r = \map {\pr_2} {\tuple {g_1, g_2} \circ \tuple {h_1, h_2} } | c = }} {{eqn | r = \map {\pr_2} {\tuple {g_1 \circ_1 h_1, g_2 \circ_2 h_2} } | c = }} {{eqn | r = g_2 \circ_2 h_2 | c = }} {{eqn | r = \map {\pr_2} g \circ_2 \map {\pr_2} h | c = }} {{end-eqn}} and thus the [[Definition:Morphism Property|morphism property]] is demonstrated for both $\pr_1$ and $\pr_2$. {{Qed}}	0
With a view to expressing the [[Definition:Primitive|primitive]] in the form: :$\displaystyle \int u \frac {\d v} {\d x} \rd x = u v - \int v \frac {\d u} {\d x} \rd x$ let: {{begin-eqn}} {{eqn | l = u | r = x | c = }} {{eqn | ll= \leadsto | l = \frac {\d u} {\d x} | r = 1 | c = [[Derivative of Identity Function]] }} {{end-eqn}} and let: {{begin-eqn}} {{eqn | l = \frac {\d v} {\d x} | r = \sin a x | c = }} {{eqn | ll= \leadsto | l = v | r = -\frac {\cos a x} a | c = [[Primitive of Sine of a x|Primitive of $\sin a x$]] }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = \int x \map \sin {a x} \rd x | r = x \paren {-\frac {\cos a x} a} - \int \paren {-\frac {\cos a x} a} \times 1 \rd x + C | c = [[Integration by Parts]] }} {{eqn | r = -\frac {x \cos a x} a + \frac 1 a \int \cos a x \rd x + C | c = [[Linear Combination of Primitives]] }} {{eqn | r = -\frac {x \cos a x} a + \frac 1 a \paren {\frac {\sin a x} a} + C | c = [[Primitive of Cosine of a x|Primitive of $\cos a x$]] }} {{eqn | r = \frac {\sin a x} {a^2} - \frac {x \cos a x} a + C | c = simplification }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \map {J_{-n} } x | r = \dfrac 1 \pi \int_0^\pi \map \cos {-n \theta - x \sin \theta} \rd \theta | c = [[Integral Representation of Bessel Function of the First Kind/Integer Order]] }} {{eqn | r = \dfrac 1 \pi \int_0^\pi \map \cos {-n \paren {\pi - \theta} - x \sin \paren {\pi - \theta} } \rd \paren {\pi - \theta} | c = substitution of $\pi - \theta$ }} {{eqn | r = -\dfrac 1 \pi \int_\pi^0 \map \cos {n \theta - x \sin \theta - n \pi} \rd \theta | c = [[Sine of Supplementary Angle]] }} {{eqn | r = \dfrac 1 \pi \int_0^\pi \map \cos {n \theta - x \sin \theta - n \pi} \rd \theta | c = [[Reversal of Limits of Definite Integral]] }} {{eqn | r = \paren {-1}^{-n} \dfrac 1 \pi \int_0^\pi \map \cos {n \theta - x \sin \theta} \rd \theta | c = [[Cosine of Angle plus Integer Multiple of Pi]] }} {{eqn | r = \paren {-1}^n \map {J_n} x | c = [[Integral Representation of Bessel Function of the First Kind/Integer Order]] }} {{end-eqn}} {{qed}}	0
Let $\left({X, d}\right)$ be a [[Definition:Metric Space|metric space]]. Let $\left \langle {x_n} \right \rangle$ be a [[Definition:Sequence|sequence]] in $\left({X, d}\right)$. Then $\left \langle {x_n} \right \rangle$ can have at most one [[Definition:Limit of Sequence (Metric Space)|limit]].	0
{{begin-eqn}} {{eqn | l = \left({R \cap T}\right) \setminus \left({S \cap T}\right) | r = \left({\left({R \cap T}\right) \setminus S}\right) \cup \left({\left({R \cap T}\right) \setminus T}\right) | c = [[De Morgan's Laws (Set Theory)/Set Difference/Difference with Intersection|De Morgan's Laws: Difference with Intersection]] }} {{eqn | r = \left({\left({R \cap T}\right) \setminus S}\right) \cup \varnothing | c = [[Set Difference of Intersection with Set is Empty Set]] }} {{eqn | r = \left({R \cap T}\right) \setminus S | c = [[Union with Empty Set]] }} {{eqn | r = \left({R \setminus S}\right) \cap T | c = [[Intersection with Set Difference is Set Difference with Intersection]] }} {{end-eqn}} {{qed|lemma}} Then: {{begin-eqn}} {{eqn | l = R \cap \left({S \setminus T}\right) | r = \left({S \setminus T}\right) \cap R | c = [[Intersection is Commutative]] }} {{eqn | r = \left({S \cap R}\right) \setminus \left({T \cap R}\right) | c = from above }} {{eqn | r = \left({R \cap S}\right) \setminus \left({R \cap T}\right) | c = [[Intersection is Commutative]] }} {{end-eqn}} {{qed}}	0
This proof depends on the [[Definition:Exponential Function/Real/Sum of Series|definition of the exponential function as the function inverse]] of the [[Definition:Natural Logarithm|natural logarithm]]. From [[Logarithm is Strictly Increasing]], $\ln$ is [[Definition:Strictly Monotone Real Function|strictly monotone]] on $\R_{>0}$. From [[Natural Logarithm Function is Continuous]], $\ln$ is [[Definition:Continuous on Interval|continuous]] on $\R_{>0}$ Thus, from the [[Continuous Inverse Theorem]], $\exp := \ln^{-1}$ is continuous. {{qed}}	0
Let $f$ be an [[Definition:Arithmetic Function|arithmetic function]]. Then $f$ is a [[Definition:Unit of Ring|unit]] in the [[Definition:Ring of Arithmetic Functions|ring of arithmetic functions]] {{iff}}: :$\map f 1 \ne 0$	0
The points in $\C$ which correspond to the [[Definition:Interior (Complex Analysis)|interior]] of $C$ can be defined by: :$\left\lvert{z - \alpha}\right\rvert < r$	0
For $n \ge 0$: {{begin-eqn}} {{eqn | l = \int_\alpha^{\alpha + n L} \map f x \d x | r = \int_\alpha^0 \map f x \d x + \sum_{k \mathop = 0}^{n - 1} \int_{k L}^{\paren {k + 1} L} \map f x \d x + \int_{n L}^{\alpha + n L} \map f x \d x | c = [[Sum of Integrals on Adjacent Intervals for Integrable Functions/Corollary]] }} {{eqn | r = \int_\alpha^0 \map f x \d x + \sum_{k \mathop = 0}^{n - 1} \int_{k L}^{\paren {k + 1} L} \map f {x - k L} \d x + \int_{n L}^{\alpha + n L} \map f {x - n L} \d x | c = [[General Periodicity Property]] }} {{eqn | r = \int_\alpha^0 \map f x \d x + \sum_{k \mathop = 0}^{n - 1} \int_0^L \map f x \d x + \int_0^\alpha \map f x \d x | c = [[Integration by Substitution]] }} {{eqn | r = n \int_0^L \map f x \d x | c = [[Reversal of Limits of Definite Integral]] }} {{end-eqn}} For $n < 0$: {{begin-eqn}} {{eqn | l = \int_\alpha^{\alpha + n L} \map f x \d x | r = -\int_{\alpha + n L}^\alpha \map f x \d x | c = [[Reversal of Limits of Definite Integral]] }} {{eqn | r = -\int_{\alpha + n L}^{\alpha + n L + \paren {-n L} } \map f x \d x }} {{eqn | r = -\paren {-n \int_0^L \map f x \d x} | c = by the above; $-n > 0$ }} {{eqn | r = n \int_0^L \map f x \d x }} {{end-eqn}} Hence the result. {{qed}} [[Category:Definite Integrals]] [[Category:Periodic Functions]] bewj8ikxf8sp0alog7mr5srk702adv3	0
Let $G$ be a [[Definition:Group|group]] with [[Definition:Identity Element|identity]] $e$. Then: :$e^1 = e$ and: :$\forall a \in G: a \ne e: a^1 = a \ne e$. Hence the result. {{qed}}	0
Let $S \subset \Z$ be a [[Definition:Non-Empty Set|non-empty]] [[Definition:Subset|subset]] of the [[Definition:Integer|set of integers]]. Let $S$ be [[Definition:Bounded Above Subset of Real Numbers|bounded above]] in the [[Definition:Real Number|set of real numbers]] $\R$. Then $S$ has a [[Definition:Greatest Element|greatest element]], and it is equal to the [[Definition:Supremum of Subset of Real Numbers|supremum]] $\sup S$.	0
Let $P = \sequence {a_j}_{0 \mathop \le j \mathop \le n}$ be a [[Definition:Geometric Sequence of Integers|geometric sequence of integers]] of [[Definition:Length of Sequence|length]] $n + 1$. Let $a_0$ be [[Definition:Coprime Integers|coprime]] to $a_n$. Then there exist [[Definition:Geometric Sequence of Integers|geometric sequences of integers]] $Q_1$ and $Q_2$ of [[Definition:Length of Sequence|length]] $n + 1$ such that: :the [[Definition:Initial Term of Geometric Sequence|initial term]] of both $Q_1$ and $Q_2$ is $1$ :the [[Definition:Final Term of Geometric Sequence|final term]] of $Q_1$ is $a_0$ :the [[Definition:Final Term of Geometric Sequence|final term]] of $Q_2$ is $a_n$. {{:Euclid:Proposition/VIII/9}}	0
Let $D: \R \to \R$ be a [[Definition:Dirichlet Function|Dirichlet function]]. In proving that the [[Dirichlet Function is Periodic]], it was shown that every [[Definition:Nonzero|non-zero]] [[Definition:Rational Number|rational number]] is a [[Definition:Periodic Element|periodic element]] of $D$. Therefore, the [[Definition:Period of Function|period]] of $D$ must be the [[Definition:Smallest Element|smallest element]] of $\Q_{> 0}$. But from [[Rational Numbers are not Well-Ordered under Conventional Ordering]] there cannot exist such an element. Hence the result. {{qed}} [[Category:Periodic Functions]] gbw385yz4t49ue86fmt3m04luu36wc7	0
Let $\left({S,\circ}\right)$ be a [[Definition:Magma|magma]]. Let $\circ_{\mathcal P}$ be the [[Definition:Subset Product|subset product]] on $\mathcal P \left({S}\right)$, the [[Definition:Power Set|power set]] of $S$. Then the [[Definition:Superset|superset]] relation $\supseteq$ is [[Definition:Relation Compatible with Operation|compatible]] with $\circ_{\mathcal P}$.	0
{{ProofWanted|By brute force, one supposes.}}	0
:[[File:Spherical-Cosine-Formula-2.png|500px]] Let $A$, $B$ and $C$ be the [[Definition:Vertex of Polygon|vertices]] of a [[Definition:Spherical Triangle|spherical triangle]] on the surface of a [[Definition:Sphere (Geometry)|sphere]] $S$. By definition of a [[Definition:Spherical Triangle|spherical triangle]], $AB$, $BC$ and $AC$ are [[Definition:Arc of Circle|arcs]] of [[Definition:Great Circle|great circles]] on $S$. By definition of a [[Definition:Great Circle|great circle]], the [[Definition:Center of Circle|center]] of each of these [[Definition:Great Circle|great circles]] is $O$. Let $O$ be joined to each of $A$, $B$ and $C$. Let $P$ be an arbitrary [[Definition:Point|point]] on $OC$. Construct $PQ$ [[Definition:Perpendicular|perpendicular]] to $OA$ meeting $OA$ at $Q$. Construct $PR$ [[Definition:Perpendicular|perpendicular]] to $OB$ meeting $OB$ at $R$. In the [[Definition:Plane|plane]] $OAB$: :construct $QS$ [[Definition:Perpendicular|perpendicular]] to $OA$ :construct $RS$ [[Definition:Perpendicular|perpendicular]] to $OB$ where $S$ is the [[Definition:Point|point]] where $QS$ and $RS$ [[Definition:Intersection (Geometry)|intersect]]. Let $OS$ and $PS$ be joined. Let [[Definition:Tangent Line|tangents]] be constructed at $A$ to the [[Definition:Arc of Circle|arcs]] of the [[Definition:Great Circle|great circles]] $AC$ and $AB$. These [[Definition:Tangent Line|tangents]] [[Definition:Containment of Angle|contain]] the [[Definition:Spherical Angle|spherical angle]] $A$. But by construction, $QS$ and $QP$ are [[Definition:Parallel Lines|parallel]] to these [[Definition:Tangent Line|tangents]] Hence $\angle PQS = \sphericalangle A$. Similarly, $\angle PRS = \sphericalangle B$. Also we have: {{begin-eqn}} {{eqn | l = \angle COB | r = a }} {{eqn | l = \angle COA | r = b }} {{eqn | l = \angle AOB | r = c }} {{end-eqn}} It is to be proved that $PS$ is [[Definition:Line Perpendicular to Plane|perpendicular]] to the [[Definition:Plane|plane]] $AOB$. By construction, $OQ$ is [[Definition:Perpendicular|perpendicular]] to both $PQ$ and $QS$. Thus $OQ$ is [[Definition:Line Perpendicular to Plane|perpendicular]] to the [[Definition:Plane|plane]] $PQS$. Similarly, $OR$ is [[Definition:Line Perpendicular to Plane|perpendicular]] to the [[Definition:Plane|plane]] $PRS$. Thus $PS$ is [[Definition:Perpendicular|perpendicular]] to both $OQ$ and $OR$. Thus $PS$ is [[Definition:Perpendicular|perpendicular]] to every [[Definition:Straight Line|line]] in the [[Definition:Plane|plane]] of $OQ$ and $OR$. That is, $PS$ is [[Definition:Line Perpendicular to Plane|perpendicular]] to the [[Definition:Plane|plane]] $OAB$. In particular, $PS$ is [[Definition:Perpendicular|perpendicular]] to $OS$, $SQ$ and $SR$ It follows that $\triangle PQS$ and $\triangle PRS$ are [[Definition:Right Triangle|right triangles]]. From the [[Definition:Right Triangle|right triangles]] $\triangle OQP$ and $\triangle ORP$, we have: {{begin-eqn}} {{eqn | n = 1 | l = PQ | r = OP \sin b }} {{eqn | n = 2 | l = PR | r = OP \sin a }} {{eqn | n = 3 | l = OQ | r = OP \cos b }} {{eqn | n = 4 | l = OR | r = OP \cos a }} {{end-eqn}} From the [[Definition:Right Triangle|right triangles]] $\triangle PQS$ and $\triangle PRS$, we have: {{begin-eqn}} {{eqn | l = PS | r = PS \sin \angle PRS }} {{eqn | r = PQ \sin A }} {{eqn | l = PS | r = PR \sin \angle PRS }} {{eqn | r = PR \sin B }} {{eqn | ll= \leadsto | l = OP \sin b \sin A | r = OP \sin a \sin B | c = from $(1)$ and $(2)$ }} {{eqn | ll= \leadsto | l = \dfrac {\sin a} {\sin A} | r = \dfrac {\sin b} {\sin B} | c = }} {{end-eqn}} The result follows by applying this technique [[Definition:Mutatis Mutandis|mutatis mutandis]] to the other [[Definition:Spherical Angle|angles]] of $ABC$. {{qed}}	0
{{begin-eqn}} {{eqn | l = \csc 165 \degrees | r = \map \csc {180 \degrees - 15 \degrees} | c = }} {{eqn | r = \csc 15 \degrees | c = [[Cosecant of Supplementary Angle]] }} {{eqn | r = \sqrt 6 + \sqrt 2 | c = [[Cosecant of 15 Degrees]] }} {{end-eqn}} {{qed}}	0
Let $G$ be a [[Definition:Group|group]] whose [[Definition:Order of Group|order]] is $15$. Then: :the number of [[Definition:Sylow p-Subgroup|Sylow $3$-subgroups]] is in the [[Definition:Set|set]] $\set {1, 4, 7, \ldots}$ :the number of [[Definition:Sylow p-Subgroup|Sylow $5$-subgroups]] is in the [[Definition:Set|set]] $\set {1, 6, 11, \ldots}$	0
By the [[Well-Ordering Principle]], $\N$ is a [[Definition:Well-Ordered Set|well-ordered set]]. The result follows from [[Max Operation on Woset is Monoid]]. {{qed}}	0
Let $\sequence {x_n}$ [[Definition:Convergent Sequence in Normed Division Ring|converge]] to $l$ in $\norm {\, \cdot \,}_1$. Let $\epsilon \in \R_{> 0}$ be given. Let $\map {B_\epsilon^2} i$ denote the [[Definition:Open Ball|open ball]] [[Definition:Center of Open Ball|centered]] on $l$ of [[Definition:Radius of Open Ball|radius]] $\epsilon$ in $\struct {R, \norm {\, \cdot \,}_2}$. By [[Open Ball of Metric Space is Open Set]] then $\map {B_\epsilon^2} l$ is [[Definition:Open Set of Metric Space|open set]] in $\struct {R, d_2}$. Since $d_1$ and $d_2$ are [[Definition:Topologically Equivalent Metrics|topologically equivalent metrics]] then $\map {B_\epsilon^2} l$ is [[Definition:Open Set of Metric Space|open set]] in $\struct {R, d_1}$. By the definition of an [[Definition:Open Set of Metric Space|open set in a metric space]] then: :$\exists \delta \in \R_{> 0}: \map {B_\delta^1} l \subseteq \map {B_\epsilon^2} l$ Hence: :$\forall x \in R: \norm {x - l}_1 < \delta \implies \norm {x - l}_2 < \epsilon$ Since $\sequence {x_n}$ [[Definition:Convergent Sequence in Normed Division Ring|converges]] to $l$ in $\norm {\, \cdot \,}_1$ then: :$\exists N \in \N: \forall n \ge N: \norm {x_n - l}_1 < \delta$ Hence: :$\exists N \in \N: \forall n \ge N: \norm {x_n - l}_2 < \epsilon$ Since $\sequence {x_n}$ and $\epsilon > 0$ were arbitrary then it has been shown that for all [[Definition:Sequence|sequences]] $\sequence {x_n}$ in $R$: :$\sequence {x_n}$ [[Definition:Convergent Sequence in Normed Division Ring|converges]] to $l$ in $\norm {\, \cdot \,}_1 \implies \sequence {x_n}$ [[Definition:Convergent Sequence in Normed Division Ring|converges]] to $l$ in $\norm {\, \cdot \,}_2$. By a similar argument it is shown that for all [[Definition:Sequence|sequences]] $\sequence {x_n}$ in $R$: :$\sequence {x_n}$ [[Definition:Convergent Sequence in Normed Division Ring|converges]] to $l$ in $\norm {\, \cdot \,}_2 \implies \sequence {x_n}$ [[Definition:Convergent Sequence in Normed Division Ring|converges]] to $l$ in $\norm {\, \cdot \,}_1$. The result follows. {{qed}}	0
Let $\struct {\Z, +}$ be the [[Definition:Additive Group of Integers|additive group of integers]]. Let $\struct {\Q, +}$ be the [[Definition:Additive Group of Rational Numbers|additive group of rational numbers]]. Then $\struct {\Z, +}$ is a [[Definition:Normal Subgroup|normal subgroup]] of $\struct {\Q, +}$.	0
Let $\struct {S, \circ}$ be a [[Definition:Commutative Semigroup|commutative semigroup]] with [[Definition:Cancellable Element|cancellable elements]] Let $\struct {C, \circ} \subseteq \struct {S, \circ}$ be the [[Definition:Subsemigroup|subsemigroup]] of all [[Definition:Cancellable Element|cancellable elements]] of $S$ Let $\struct {S', \circ'}$ be an [[Definition:Inverse Completion|inverse completion]] of $\struct {S, \circ}$ Let $\phi$ be a [[Definition:Semigroup Homomorphism|(semigroup) homomorphism]] from $\struct {S, \circ}$ into a [[Definition:Semigroup|semigroup]] $\struct {T, *}$ such that $\map \phi y$ is [[Definition:Invertible Element|invertible]] for all $y \in C$. Then: :$(1): \quad$ There is one and only one [[Definition:Homomorphism (Abstract Algebra)|homomorphism]] $\psi$ from $\struct {S', \circ'}$ into $\struct {T, *}$ [[Definition:Extension of Mapping|extending]] $\phi$ :$(2): \quad \forall x \in S, y \in C: \map \psi {x \circ' y^{-1} } = \map \phi * \paren {\map \phi y}^{-1}$ :$(3): \quad$ If $\phi$ is a [[Definition:Monomorphism (Abstract Algebra)|monomorphism]], then so is $\psi$.	0
Let $\mathcal F = \sequence {a_n}$ be a [[Definition:General Fibonacci Sequence|general Fibonacci sequence]] generated by the parameters $r, s, t, u$: :$a_n = \begin{cases} r & : n = 0 \\ s & : n = 1 \\ t a_{n - 2} + u a_{n - 1} & : n > 1 \end{cases}$ Let: :$d = \gcd \set {r, s}$ where $\gcd$ denotes [[Definition:Greatest Common Divisor of Integers|greatest common divisor]]. Then: :$\forall n \in \Z_{>0}: d \divides a_n$	0
=== Necessary Condition === Suppose that $f$ is [[Definition:Injection|injective]]. Suppose further that we have [[Definition:Mapping|mappings]] $g, h: Z \to X$ such that $g \ne h$. Then necessarily there exists some $z \in Z$ such that $g \left({z}\right) \ne h \left({z}\right)$ by [[Equality of Mappings]]. As $f$ is [[Definition:Injection|injective]], it follows that: :$f \left({g \left({z}\right)}\right) \ne f \left({h \left({z}\right)}\right)$ which, again by [[Equality of Mappings]], means that $g \circ f \ne h \circ f$. Hence $f$ is [[Definition:Monomorphism (Category Theory)|monic]], by the [[Rule of Transposition]]. {{qed|lemma}} === Sufficient Condition === Suppose that $f: X \rightarrowtail Y$ is a [[Definition:Monomorphism (Category Theory)|monomorphism]]. By definition of [[Definition:Injection|injection]], it will suffice to show that: :$x \ne x' \implies f \left({x}\right) \ne f \left({x'}\right)$ To this end, consider a [[Definition:Singleton|singleton]] $\left\{{a}\right\}$, and define: :$\bar x: \left\{{a}\right\} \to X, \bar x \left({a}\right) := x$ :$\bar x': \left\{{a}\right\} \to X, \bar x' \left({a}\right) := x'$ In particular, $\bar x \ne \bar x'$, and so, $f$ being [[Definition:Monomorphism (Category Theory)|monic]], we deduce: :$f \circ \bar x \ne f \circ \bar x'$ It follows that it must be that: {{begin-eqn}} {{eqn|l = f \left({x}\right) |r = f \left({\bar x \left({a}\right)}\right) }} {{eqn|o = \ne |r = f \left({\bar x' \left({a}\right)}\right) |c = [[Equality of Mappings]] }} {{eqn|r = f \left({x'}\right) }} {{end-eqn}} Hence $f$ is [[Definition:Injection|injective]]. {{qed}}	0
Let the given [[Definition:Ratio|ratios]] in least numbers be: :$a : b$, $c : d$, $e : f$ From {{EuclidPropLink|book = VII|prop = 34|title = Existence of Lowest Common Multiple}}, we can find: :$g = \lcm set {b, c}$ Let: :$g = r b$ :$g = s c$ Then let: :$h = r a$ :$k = s d$ Now either $e \divides k$ or $e \nmid k$. First, suppose $e \divides k$. Let $k = t e$. Then let $l = t f$. We have: :$h = r a$ :$g = r b$ thus from {{EuclidDefLink|VII|20|Proportional}}: :$a : h = b : g$ So from {{EuclidPropLink|book = VII|prop = 13|title = Proportional Numbers are Proportional Alternately}}: :$a : b = h : g$ Similarly: :$c : d = g : k$ and further: :$e : f = k : l$ Thus $h, g, k, l$ are [[Definition:Continuously Proportional|continuously proportional]]: :in the [[Definition:Ratio|ratio]] of $a : b$ :in the [[Definition:Ratio|ratio]] of $c : d$ :in the [[Definition:Ratio|ratio]] of $e : f$. It is necessary to prove that these are the least [[Definition:Natural Number|natural numbers]] with this property. Suppose $h, g, k, l$ are not the least [[Definition:Natural Number|natural numbers]] in the [[Definition:Ratio|ratios]] of $a : b$, $c : d$, $e : f$. Let these numbers be $n, o, m, p$. Then: :$a : b = n : o$ while $a$ and $b$ are least. By {{EuclidPropLink|book=VII|prop=20|title=Ratios of Fractions in Lowest Terms}}: :$b \divides o$ :$c \divides o$ and so $o$ is a [[Definition:Common Multiple|common multiple]] of $b$ and $c$. Therefore by {{EuclidPropLink|book = VII|prop = 35|title = LCM Divides Common Multiple}}: :$\lcm \set {b, c} \divides o$ But $g = \lcm \set {b, c}$ from above. Therefore $g \divides o$, the greater the less, which is impossible. Therefore there are no numbers $n, o, m, p$ less than $h, g, k, l$ which have the properties in question. {{qed|lemma}} Now suppose $e \nmid k$. Let $m = \lcm \set {e, k}$. Thus let: :$m = u k$ :$n = u h$ :$o = u g$ and: :$m = v e$ :$p = v f$ Thus from {{EuclidDefLink|VII|20|Proportional}}: :$h : n = g : o$ From {{EuclidPropLink|book = VII|prop = 13|title = Proportional Numbers are Proportional Alternately}}: :$h : g = n : o$ Similarly, let: But: :$h : g = a : b$ and so: :$a : b = n : o$ For the same reason: :$c : d = o : m$ Since: :$m = v e$ :$p = v f$ from {{EuclidDefLink|VII|20|Proportional}}: :$e : m = f : p$ and so from {{EuclidPropLink|book=VII|prop=13|title=Proportional Numbers are Proportional Alternately}}: :$e : f = m : p$ Therefore $n, o, m, p$ are [[Definition:Continuously Proportional|continuously proportional]]: :in the [[Definition:Ratio|ratio]] of $a : b$ :in the [[Definition:Ratio|ratio]] of $c : d$ :in the [[Definition:Ratio|ratio]] of $e : f$. It is necessary to prove that these are the least [[Definition:Natural Number|natural numbers]] with this property. Suppose $n, o, m, p$ are not the least [[Definition:Natural Number|natural numbers]] in the [[Definition:Ratio|ratios]] of $a : b$, $c : d$, $e : f$. Let these numbers be $n', o', m', p'$. Then: :$a : b = n' : o'$ while $a$ and $b$ are least. By {{EuclidPropLink|book=VII|prop=20|title=Ratios of Fractions in Lowest Terms}}: :$b \divides o'$ :$c \divides o'$ and so $o'$ is a [[Definition:Common Multiple|common multiple]] of $b$ and $c$. Therefore by {{EuclidPropLink|book = VII|prop = 35|title = LCM Divides Common Multiple}}: :$\lcm \set {b, c} \divides o'$ But $g = \lcm \set {b, c}$ from above. Therefore $g \divides o'$, the greater the less, which is impossible. Therefore there are no numbers $n', o', m', p'$ less than $n, o, m, p$ which have the properties in question. {{qed}} {{Euclid Note|4|VIII|It needs to be pointed out that {{AuthorRef|Euclid}} uses the term [[Definition:Continued Proportion|continued proportion]] here to mean something different from [[Definition:Geometric Sequence|geometric sequence]]; the [[Definition:Ratio|ratios]] $a : b$, $c : d$ and $e : f$ are not necessarily equal.}}	0
The [[Definition:Algebraic Structure|algebraic structure]] $\struct {\N, +}$ consisting of the [[Definition:Set|set]] of [[Definition:Natural Numbers|natural numbers]] $\N$ under [[Definition:Natural Number Addition|addition]] $+$ is not a [[Definition:Group|group]].	0
Let $a \in \N$ be an [[Definition:Even Integer|even]] [[Definition:Perfect Number|perfect number]]. Then $a$ is in the form: :$2^{n - 1} \paren {2^n - 1}$ where $2^n - 1$ is [[Definition:Prime Number|prime]].	0
:$\forall n \in \Z: \dbinom n n = \sqbrk {n \ge 0}$ where $\sqbrk {n \ge 0}$ denotes [[Definition:Iverson's Convention|Iverson's convention]]. That is: :$\forall n \in \Z_{\ge 0}: \dbinom n n = 1$ :$\forall n \in \Z_{< 0}: \dbinom n n = 0$	0
Let $\struct {G, \circ}$ be a [[Definition:Group|group]]. Let $H$ be a [[Definition:Subgroup|subgroup]] of $G$. Let $K$ be a [[Definition:Subgroup|subgroup]] of $H$. Let: :$\index G K = p$ where: :$p$ denotes a [[Definition:Prime Number|prime number]] :$\index G K$ denotes the [[Definition:Index of Subgroup|index]] of $K$ in $G$. Then either: :$H = K$ or: :$H = G$	0
Let $S \subseteq \R$. Let $\sequence {f_n}$ be a [[Definition:Sequence|sequence]] of [[Definition:Real Function|real functions]] $S \to \R$. Then the infinite series: :$\displaystyle \sum_{n \mathop = 1}^\infty f_n$ [[Definition:Uniform Convergence/Infinite Series|converges uniformly]] on $S$ {{iff}} for all $\varepsilon \in \R_{> 0}$ there exists $N \in \N$ such that: :$\displaystyle \size {\sum_{k \mathop = m + 1}^n \map {f_k} x} < \varepsilon$ for all $x \in S$ and $n > m > N$.	0
Let $\family {X_i}_{i \mathop \in I}$ be a [[Definition:Indexed Family|family]] of [[Definition:Set|sets]] where $I$ is an arbitrary [[Definition:Indexing Set|index set]]. Let $\displaystyle X = \prod_{i \mathop \in I} X_i$ be the [[Definition:Cartesian Product of Family|Cartesian product]] of $\family {X_i}_{i \mathop \in I}$. Let $z \in X$. Let $i \in I$. Let $Y_i = \set {x \in X: \forall j \in I \setminus \set i: x_j = z_j}$. Let $p_i = \pr_i {\restriction_{Y_i} }$, where $\pr_i$ is the [[Definition:Projection on Family of Sets|projection]] from $X$ to $X_i$. Then: :$p_i$ is a [[Definition:Surjection|surjection]].	0
Let $l, m, n \in \Z$ be [[Definition:Integer|integers]] such that $n \ge 0$. Then: :$\displaystyle \sum_{j, k \mathop \in \Z} \left({-1}\right)^{j + k} \dbinom {j + k} {k + l} \dbinom r j \dbinom n k \dbinom {s + n - j - k} {m - j} = \left({-1}\right)^l \dbinom {n + r} {n + l} \dbinom {s - r} {m - n - l}$	0
Let $S$ be the [[Definition:Set|set]] defined as: :$S = \set {\cos \theta + i \sin \theta: \theta \in \Q}$ Then the [[Definition:Algebraic Structure|algebraic structure]] $\struct {S, \times}$ is an [[Definition:Infinite Group|infinite]] [[Definition:Abelian Group|abelian group]].	0
Let $\struct {\Z \sqbrk i, +, \times}$ be the [[Gaussian Integers form Integral Domain|integral domain of Gaussian Integers]]. Let $\nu: \Z \sqbrk i \to \R$ be the [[Definition:Real-Valued Function|real-valued function]] defined as: :$\forall a \in \Z \sqbrk i: \map \nu a = \cmod a^2$ where $\cmod a$ is the [[Definition:Modulus of Complex Number|(complex) modulus]] of $a$. Then $\nu$ is a [[Definition:Euclidean Valuation|Euclidean valuation]] on $\Z \sqbrk i$. Hence $\struct {\Z \sqbrk i, +, \times}$ with $\nu: \Z \sqbrk i \to \Z$ forms a [[Definition:Euclidean Domain|Euclidean domain]].	0
=== [[Primitive of Reciprocal of a squared minus x squared/Logarithm Form 1/size of x less than a|Case where $\size x < a$]] === {{:Primitive of Reciprocal of a squared minus x squared/Logarithm Form 1/size of x less than a}} === [[Primitive of Reciprocal of a squared minus x squared/Logarithm Form 1/size of x greater than a|Case where $\size x > a$]] === {{:Primitive of Reciprocal of a squared minus x squared/Logarithm Form 1/size of x greater than a}}	0
Let $\struct {G, \circ}$ be a [[Definition:Group|group]]. Let $H$ be a [[Definition:Subgroup|subgroup]] of $G$ which is not [[Definition:Normal Subgroup|normal]]. Let $a, b \in G$. Then it is not necessarily the case that the [[Definition:Coset Product|coset product]]: :$\paren {a \circ H} \circ \paren {b \circ H} = \paren {a \circ b} \circ H$ is [[Definition:Well-Defined Operation|well-defined]].	0
Let $n \in \Z_{>0}$ be a [[Definition:Strictly Positive Integer|(strictly) positive integer]]. Let $B$ be the [[Definition:Binary Notation|binary representation]] of $n$. Let $r$ be the number of [[Definition:Unit (One)|unit digits]] in $B$. Let $n!$ denote the [[Definition:Factorial|factorial of $n$]]. Then $2^{n - r}$ is a [[Definition:Divisor of Integer|divisor]] of $n!$, but $2^{n - r + 1}$ is not.	0
{{begin-eqn}} {{eqn | l = \int \frac {x \ \mathrm d x} {\left({a x + b}\right)^2} | r = \int \frac {a x \ \mathrm d x} {a \left({a x + b}\right)^2} | c = multiplying [[Definition:Numerator|top]] and [[Definition:Denominator|bottom]] by $a$ }} {{eqn | r = \int \frac {\left({a x + b - b}\right) \ \mathrm d x} {a \left({a x + b}\right)^2} | c = adding and subtracting $b$ }} {{eqn | r = \frac 1 a \int \frac {\left({a x + b}\right) \ \mathrm d x} {\left({a x + b}\right)^2} - \frac b a \int \frac {\mathrm d x} {\left({a x + b}\right)^2} | c = [[Linear Combination of Integrals]] }} {{eqn | r = \frac 1 a \int \frac {\mathrm d x} {a x + b} - \frac b a \int \frac {\mathrm d x} {\left({a x + b}\right)^2} | c = simplification }} {{eqn | r = \frac 1 a \left({\frac 1 a \ln \left\vert{a x + b}\right\vert}\right) - \frac b a \int \frac {\mathrm d x} {\left({a x + b}\right)^2} + C | c = [[Primitive of Reciprocal of a x + b|Primitive of Reciprocal of $\dfrac 1 {\left({a x + b}\right)}$]] }} {{eqn | r = \frac 1 a \left({\frac 1 a \ln \left\vert{a x + b}\right\vert}\right) - \frac b a \left({-\frac 1 {a \left({a x + b}\right)} }\right) + C | c = [[Primitive of Reciprocal of a x + b squared|Primitive of Reciprocal of $\dfrac 1 {\left({a x + b}\right)^2}$]] }} {{eqn | r = \frac b {a^2 \left({a x + b}\right)} + \frac 1 {a^2} \ln \left\vert{a x + b}\right\vert + C | c = simplification }} {{end-eqn}} {{qed}}	0
Follows directly from the definition of [[Definition:Center of Ring|center]] and [[Centralizer of Ring Subset is Subring]]. {{qed}}	0
Let $M$ be a [[Definition:Infinite Line|straight line]] in [[Definition:The Plane|the plane]] passing through the [[Definition:Origin|origin]]. Then the '''reflection''' $s_M$ of $\R^2$ in $M$ is the [[Rotation of Plane about Origin is Linear Operator|rotation]] of [[Definition:The Plane|the plane]] in [[Definition:Ordinary Space|space]] through one half turn about $M$ as an [[Definition:Axis|axis]]. :$s_M \circ s_M = I_{\R^2}$ and hence: :$s_M = s_M^{-1}$ If $M$ is the [[Definition:X-Axis|$x$-axis]] then $\map {s_M} {\lambda_1, \lambda_2} = \tuple {\lambda_1, -\lambda_2}$. If $M$ is the [[Definition:Y-Axis|$y$-axis]] then $\map {s_M} {\lambda_1, \lambda_2} = \tuple {-\lambda_1, \lambda_2}$. In general, $s_M$ is a [[Definition:Linear Operator|linear operator]] for every [[Definition:Straight Line|straight line]] $M$ through the [[Definition:Origin|origin]].	0
Let $\sequence {x_n}$ be a [[Definition:Real Sequence|sequence in $\R$]]. Let $x_n \to l$ as $n \to \infty$. To show that $\sequence {x_n}$ is [[Definition:Bounded Sequence|bounded sequence]], we need to find $K$ such that: :$\forall n \in \N: \size {x_n} \le K$ Because $\sequence {x_n}$ [[Definition:Convergent Real Sequence|converges]]: :$\forall \epsilon > 0: \exists N: n > N \implies \size {x_n - l} < \epsilon$ In particular, this is true when $\epsilon = 1$. That is: :$\exists N_1: \forall n > N_1: \size {x_n - l} < 1$ By [[Backwards Form of Triangle Inequality]]: :$\forall n > N_1: \size {x_n} - \size l \le \size {x_n - l} < 1$ That is: :$\size {x_n} < \size l + 1$ So we set: :$K = \max \set {\size {x_1}, \size {x_2}, \ldots, \size {x_{N_1} }, \size l + 1}$ and the result follows. {{qed}}	0
Let $p_1$ and $p_2$ be [[Definition:Prime Number|prime numbers]] such that $p_1 \neq p_2$. Let $\norm {\,\cdot\,}_{p_1}$ and $\norm {\,\cdot\,}_{p_2}$ be the [[Definition:P-adic Norm|$p$-adic norms]] on the [[Definition:Rational Numbers|rationals $\Q$]]. Then $\norm {\,\cdot\,}_{p_1}$ and $\norm {\,\cdot\,}_{p_2}$ are not [[Definition:Equivalent Division Ring Norms|equivalent norms]]. That is, the [[Definition:Topology Induced by Division Ring Norm|topology induced]] by $\norm {\,\cdot\,}_{p_1}$ does not equal the [[Definition:Topology Induced by Division Ring Norm|topology induced]] by $\norm {\,\cdot\,}_{p_2}$.	0
Let $n \in \Z_{>0}$ be a [[Definition:Strictly Positive Integer|(strictly) positive integer]]. Then: {{begin-eqn}} {{eqn | l = x^{2 n + 1} - y^{2 n + 1} | r = \paren {x - y} \displaystyle \prod_{k \mathop = 1}^n \paren {x^2 - 2 x y \cos \dfrac {2 \pi k} {2 n + 1} + y^2} | c = }} {{eqn | r = \paren {x - y} \paren {x^2 - 2 x y \cos \dfrac {2 \pi} {2 n + 1} + y^2} \paren {x^2 - 2 x y \cos \dfrac {4 \pi} {2 n + 1} + y^2} \dotsm \paren {x^2 - 2 x y \cos \dfrac {2 n \pi} {2 n + 1} + y^2} | c = }} {{end-eqn}}	0
Let [[Definition:Real Number|real numbers]] be selected at [[Definition:Random Selection|random]] following a [[Definition:Continuous Uniform Distribution|continuous uniform distribution]] from the [[Definition:Closed Real Interval|interval]] $\closedint 0 1$ until their total sum is greater than $1$. The [[Definition:Expectation|expectation]] of the [[Definition:Integer|number]] of selections is [[Definition:Euler's Number|Euler's number $e$]].	0
Let $A_\bullet$, $B_\bullet$ be [[Definition:Complex (Homological Algebra)|chain complexes]] of abelian groups. Let $f, g: A_\bullet \to B_\bullet$ be [[Definition:Homomorphism of Complexes|chain maps]] which are [[Definition:Homotopic (Homological Algebra)|homotopic]]. Then $f$ and $g$ [[Homomorphism of Chain Complexes induces Homomorphism of Homology|induce]] equal maps on homology.	0
From [[Injection from Finite Set to Itself is Surjection]], $f$ is a [[Definition:Surjection|surjection]]. As $f$ is thus both an [[Definition:Injection|injection]] and a [[Definition:Surjection|surjection]], $f$ is a [[Definition:Bijection|bijection]] by definition. Thus as $f$ is a [[Definition:Bijection|bijection]] to itself, it is by definition a [[Definition:Permutation|permutation]]. {{qed}}	0
Let $\mathcal F$ be the [[Definition:Equivalence Class|equivalence class]] of $\mathcal A$ under the [[Definition:Relation|relation]] of [[Definition:Compatible Atlases|compatibility]]. By [[Compatibility of Atlases is Equivalence Relation]], this is indeed an [[Definition:Equivalence Relation|equivalence relation]]. By definition we have $\mathcal A \in \mathcal F$. By [[Relation Partitions Set iff Equivalence]], $\mathcal F$ is an [[Definition:Element|element]] of the [[Definition:Partition (Set Theory)|partition]] of [[Definition:Equivalence Class|equivalence classes]]. By definition, the [[Definition:Element|elements]] of a [[Definition:Partition (Set Theory)|partition]] are [[Definition:Pairwise Disjoint|pairwise disjoint]]. Therefore if $\mathcal G \ne \mathcal F$ is an [[Definition:Element|element]] of the [[Definition:Partition (Set Theory)|partition]], we must have: : $\mathcal A \notin \mathcal G$ Therefore $\mathcal A$ belongs to exactly one [[Definition:Differentiable Structure|differentiable structure]]. {{qed}} {{explain|Clarification is needed as to why this result should be categorised in [[:Category:Manifolds]].}} [[Category:Manifolds]] 1d6a163jw7q2sy421hs3o2njg2xs4ya	0
:$\displaystyle \int F \left({\operatorname{arccot} \frac x a}\right) \ \mathrm d x = -a \int F \left({u}\right) \csc^2 u \ \mathrm d u$ where $u = \operatorname{arccot} \dfrac x a$.	0
We check each of the axioms in turn. Let $k = \left \langle {k_j}\right \rangle_{j \in J}$, $\ell = \left \langle {\ell_j}\right \rangle_{j \in J}$ and $m = \left \langle {m_j}\right \rangle_{j \in J}$ be [[Definition:Multiindex|multiindices]]. === Closure === Trivially we have that: :$j \mapsto \left({ k_j + \ell_j }\right)$ is a [[Definition:Sequence|sequence]] of [[Definition:Integer|integers]] [[Definition:Indexing Set|indexed]] by $J$. We know that [[Definition:Finite|finitely many]] of the $k_j$ are non-zero, and finitely many of the $\ell_j$ are non-zero. Therefore finitely many of the $k_j + \ell_j$ are non-zero. This shows that $k + \ell$ is a [[Definition:Multiindex|multiindex]] and so $+$ is [[Definition:Closed Algebraic Structure|closed]]. {{qed|lemma}} === Associativity === For all $j \in J$, we have: {{begin-eqn}} {{eqn|l = \left(\left(\ell + k\right) + m \right)_j |r = \left(\ell + k\right)_j + m_j |c = }} {{eqn|r = \left(\ell_j + k_j\right) + m_j |c = }} {{eqn|r = \ell_j + \left(k_j + m_j\right) |c = by [[Integer Addition is Associative]] }} {{eqn|r = \ell_j + \left(k + m\right)_j |c = }} {{eqn|r = \left(\ell + \left(k + m\right) \right)_j |c = }} {{end-eqn}} Thus $+$ is shown to be [[Definition:Associative|associative]]. {{qed|lemma}} === Commutativity === For all $j \in J$, we have: {{begin-eqn}} {{eqn|l = \left(\ell + k\right)_j |r = \ell_j + k_j |c = }} {{eqn|r = k_j + \ell_j |c = By [[Integer Addition is Commutative]] }} {{eqn|r = \left(k + \ell\right)_j |c = }} {{end-eqn}} Thus $+$ is shown to be [[Definition:Commutative Operation|commutative]]. {{qed|lemma}} === Identity Element === Let $0_Z$ be the multiindex defined by: :$\left(0_Z\right)_j = 0$ for all $j \in J$. Then we have, for all $j \in J$: {{begin-eqn}} {{eqn|l = \left(0_Z + \ell\right)_j |r = 0 + \ell_j |c = }} {{eqn|r = \ell_j |c = }} {{end-eqn}} Since we have seen that $\left({Z, +}\right)$ is [[Definition:Commutative Algebraic Structure|commutative]], this shows that $0_Z$ is an [[Definition:Identity Element|identity element]] for $Z$. {{Qed}} [[Category:Polynomial Theory]] qe0w3f8egjspdnmdpiopykvs42e2a9q	0
Let $\sequence {a_n}$ be a [[Definition:Sequence|sequence in $\R$]]. If $\displaystyle \lim_{k \mathop \to \infty} a_k \ne 0$, then $\displaystyle \sum_{i \mathop = 1}^\infty a_n$ [[Definition:Divergent Series|diverges]].	0
We have: {{begin-eqn}} {{eqn | l = \laptrans {\cos a t} | r = \int_0^\infty e^{-s t} \cos a t \rd t | c = {{Defof|Laplace Transform}} }} {{eqn | n = 1 | r = \dfrac s {s^2 + a^2} | c = [[Laplace Transform of Cosine]] }} {{end-eqn}} Hence: {{begin-eqn}} {{eqn | l = \dfrac \d {\d a} \int_0^\infty e^{-s t} \cos a t \rd t | r = \int_0^\infty e^{-s t} \paren {\map {\dfrac \partial {\partial a} } {\cos a t} } \rd t | c = [[Derivative of Integral]] }} {{eqn | r = \int_0^\infty e^{-s t} \paren {-t \sin a t} \rd t | c = [[Derivative of Cosine Function]] }} {{eqn | r = -\laptrans {t \sin a t} | c = {{Defof|Laplace Transform}} }} {{eqn | r = \map {\dfrac \d {\d a} } {\dfrac s {s^2 + a^2} } | c = from $(1)$ }} {{eqn | r = -\dfrac {2 a s} {\paren {s^2 + a^2}^2} | c = [[Quotient Rule for Derivatives]] }} {{end-eqn}} and the result follows. {{qed}}	0
{{begin-eqn}} {{eqn | l = \sin 105^\circ | r = \sin \left({90^\circ + 15^\circ}\right) | c = }} {{eqn | r = \cos 15^\circ | c = [[Sine of Angle plus Right Angle]] }} {{eqn | r = \frac {\sqrt 6 + \sqrt 2} 4 | c = [[Cosine of 15 Degrees]] }} {{end-eqn}} {{qed}}	0
Let $\chi$ be a [[Definition:Dirichlet Character#Primitive Characters|primitive Dirichlet character]] to the modulus $q \geq 1$. Let $\map \Lambda {s, \chi}$ be the [[Definition:Completed Dirichlet L-Function|completed $L$-function]] for $\chi$. Let $\map \tau \chi$ denote the [[Definition:Gauss Sum|Gaussian sum]]. Then for all $s \in \C$: :$\map \Lambda {s, \chi} = i^{-\kappa} \dfrac {\map \tau \chi} {\sqrt q} \map \Lambda {1 - s, \overline \chi}$ where $\kappa = \dfrac 1 2 \paren {1 - \map \chi {-1} }$.	0
This proof assumes that $R$ is a [[Definition:Field (Abstract Algebra)|field]], which makes the triangulation process slightly quicker. By this assumptions, all [[Definition:Element of Matrix|elements]] of $\mathbf A$ have [[Definition:Inverse Element|multiplicative inverses]]. Let $\mathbf A$ be a [[Definition:Square Matrix|square matrix of order $n$]]. We proceed by induction on $n$, the number of [[Definition:Row of Matrix|rows]] of $\mathbf A$. === Basis for the Induction === For $n = 1$, we have a matrix of just one [[Definition:Element of Matrix|element]], which is trivially [[Definition:Diagonal Matrix|diagonal]], hence both upper and lower triangular. This is the [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Fix $n \in \N$, and assume all $n \times n$-matrices can be upper triangularised by [[Definition:Elementary Row Operation|elementary row operations]]. If $R$ is a [[Definition:Field (Abstract Algebra)|field]], assume all $n \times n$-matrices can be upper triangularised by elementary row operations of type 2. This forms our [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]. === Induction Step === Let $\mathbf A = \left[{a}\right]_{n + 1}$ be a [[Definition:Square Matrix|square matrix]] of order $n + 1$. When the first [[Definition:Column of Matrix|column]] of $\mathbf A$ contains only zeroes, it is upper triangularisable {{iff}} the [[Definition:Submatrix|submatrix]] $\mathbf A \left({1; 1}\right)$ is. Each [[Definition:Elementary Row Operation|elementary row operation]] used in triangularisation process of the submatrix $\mathbf A \left({1; 1}\right)$ will not change the zeros of the first column of $\mathbf A$. So when $\mathbf A \left({1; 1}\right)$ is upper triangularised, then $\mathbf A$ will also be upper triangularised. From the [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]], we conclude that $\mathbf A$ can be upper triangularised by elementary row operations. Now suppose that its first column contains a non-zero value. Suppose that $a_{11} = 0$. Let $j$ be the smallest row index such that $a_{j1} \ne 0$, and note that $j$ exists by assumption. Now apply the following operation of type 2: :$r_1 \to r_1 + r_j$ As $a_{j1} \ne 0$, this enforces $a_{11} \ne 0$, and we continue as in the case below. Suppose $a_{11} \ne 0$. We use the following operations of type 2: :$\forall j \in \left\{{2, \ldots, n+1}\right\}: r_j \to r_j - \dfrac {a_{j1}} {a_{11}} r_1$ This will put the first column to zero (except for the first element, $a_{11}$). It follows that $\mathbf A$ can be upper triangularised precisely when the [[Definition:Submatrix|submatrix]] $\mathbf A \left({1; 1}\right)$ can. Again, the [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]] renders $\mathbf A$ upper triangularisable by [[Definition:Elementary Row Operation|elementary row operations]]. This completes the case distinction, and hence the result follows by [[Principle of Mathematical Induction|induction]]. To put the matrix $\mathbf A$ into [[Definition:Lower Triangular Matrix|lower triangular form]], just do the same thing, but start with the last column and the last diagonal element $a_{n + 1 \; n + 1}$. {{qed}}	0
=== Existence === We prove this by [[Proof by Mathematical Induction|induction]] on $k$. ==== Basis for the induction ==== Let $k = 2$. Let $d = \gcd \left({n_1, n_2}\right)$. By [[Bézout's Lemma]], there exist $s, t \in \Z$ such that $d = s n_1 + t n_2$. Let $\left({q_1, r}\right)$ and $\left({q_2, r}\right)$ be the [[Division Theorem|quotient and remainder]] of $b_1$ and $b_2$ upon [[Definition:Integer Division|division]] by $d$. Then $x = q_1 s n_2 + q_2 t n_2 + r$ is a solution. ==== Induction step ==== Let $n = \lcm \left({n_2, \ldots, n_k}\right)$. By the induction hypothesis, the last $k - 1$ congruences are equivalent to a single congruence: :$x \equiv b \pmod n$ for a certain $b \in \Z$ which satisfies $b \equiv b_i \pmod {n_i}$ for all $i \in \left\{ {2, \ldots, k}\right\}$. It remains to be shown that :$\lcm \left({n, n_1}\right) = \lcm \left({n_1, \ldots, n_k}\right)$ :$b \equiv b_1 \pmod {\gcd \left({n, n_1}\right)}$ to apply the case $k = 2$ and conclude. The first statement follows from [[Lowest Common Multiple is Associative]]. From [[GCD and LCM Distribute Over Each Other]]: :$\gcd \left({n, n_1}\right) = \lcm \left({\gcd \left({n_1, n_2}\right), \ldots, \gcd \left({n_1, n_k}\right)}\right)$ For all $i \in \left\{ {2, \ldots, k}\right\}$: : $b \equiv b_i \pmod {n_i}$ and: : $b_i \equiv b_1 \pmod {\gcd \left({n_1, n_i}\right)}$ Thus: : $b \equiv b_1 \pmod {\gcd \left({n_1, n_i}\right)}$ Therefore: :$b \equiv b_1 \pmod {\lcm \left({\gcd \left({n_1, n_2}\right), \ldots, \gcd \left({n_1, n_k}\right)}\right)}$ {{qed|lemma}} === Uniqueness=== {{ProofWanted}} [[Category:Chinese Remainder Theorem]] rblaaqhqiu6lqz5u8gvqms58tp3ug1e	0
:$\cos 135 \degrees = \cos \dfrac {3 \pi} 4 = -\dfrac {\sqrt 2} 2$	0
{{begin-eqn}} {{eqn | l = a | o = \perp | r = b }} {{eqn | ll= \leadsto | l = \gcd \set {a, b} | r = 1 | c = {{Defof|Coprime Integers}} }} {{eqn | ll= \leadsto | l = \exists m, n \in \Z: m a + n b | r = 1 | c = [[Bézout's Lemma]] }} {{end-eqn}} Then we have: {{begin-eqn}} {{eqn | l = \exists m, n \in \Z: m a + n b | r = 1 | c = }} {{eqn | ll= \leadsto | l = \gcd \set {a, b} | o = \divides | r = 1 | c = [[Set of Integer Combinations equals Set of Multiples of GCD]] }} {{eqn | ll= \leadsto | l = \gcd \set {a, b} | r = 1 | c = }} {{eqn | ll= \leadsto | l = a | o = \perp | r = b | c = {{Defof|Coprime Integers}} }} {{end-eqn}} {{qed}}	0
:[[File:Scalar-product-distributes-over-vector-addition.png|400px]] Let $\mathbf a = \vec {OP}$ and $\mathbf b = \vec {PQ}$. Then: :$\vec {OQ} = \mathbf a + \mathbf b$ Let $P'$ and $Q'$ be [[Definition:Point|points]] on $OP$ and $OQ$ respectively so that: :$OP' : OP = OQ' : OQ = m$ Then $P'Q'$ is [[Definition:Parallel Lines|parallel]] to $PQ$ and $m$ times it in [[Definition:Length of Line|length]]. Thus: :$\vec {P'Q'} = m \mathbf b$ which shows that: {{begin-eqn}} {{eqn | l = m \paren {\mathbf a + \mathbf b} | r = \vec {OQ'} | c = }} {{eqn | r = \vec {OP} + \vec {OP'} | c = }} {{eqn | r = m \mathbf a + m \mathbf b | c = }} {{end-eqn}} {{qed}}	0
:$\displaystyle \tan \left({n \theta}\right) = \frac {\displaystyle \sum_{i \mathop = 0}^{\left\lfloor{\frac {n - 1} 2}\right\rfloor} \left({-1}\right)^i \binom n {2 i + 1} \tan^{2 i + 1}\theta} {\displaystyle \sum_{i \mathop = 0}^{\left\lfloor{\frac n 2}\right\rfloor} \left({-1}\right)^i \binom n {2 i} \tan^{2 i}\theta}$	0
The [[Definition:Riemann Zeta Function|Riemann zeta function]] has a [[Definition:Unique|unique]] [[Definition:Analytic Continuation|analytic continuation]] to $\{s \in \C : \Re(s) > 0\}\setminus\{1\}$, the [[Definition:Complex Half-Plane|half-plane]] $\Re(s)>0$ minus the point $s=1$.	0
:$\sec 345 \degrees = \sec \dfrac {23 \pi} {12} = \sqrt 6 - \sqrt 2$	0
By definition of the [[Definition:Unit Matrix|unit matrix]]: :$I_{a b} = \delta_{a b}$ where: :$I_{a b}$ denotes the [[Definition:Element of Matrix|element]] of $\mathbf I$ whose [[Definition:Index of Matrix Element|indices]] are $\tuple {a, b}$. By definition, $\mathbf E$ is the [[Definition:Square Matrix|square matrix]] of [[Definition:Order of Square Matrix|order $m$]] formed by applying $e$ to the [[Definition:Unit Matrix|unit matrix]] $\mathbf I$. That is, all [[Definition:Element of Matrix|elements]] of [[Definition:Column of Matrix|column]] $i$ of $\mathbf I$ are to have the corresponding [[Definition:Element of Matrix|elements]] of [[Definition:Column of Matrix|column]] $j$ added to them after the latter have been [[Definition:Ring Product|multiplied]] by $\lambda$. By definition of [[Definition:Unit Matrix|unit matrix]]: :all [[Definition:Element of Matrix|elements]] of [[Definition:Column of Matrix|column]] $i$ are $0$ except for [[Definition:Element of Matrix|element]] $I_{i i}$, which is $1$. :all [[Definition:Element of Matrix|elements]] of [[Definition:Column of Matrix|column]] $j$ are $0$ except for [[Definition:Element of Matrix|element]] $I_{j j}$, which is $1$. Thus in $\mathbf E$: :where $b \ne i$, $E_{a b} = \delta_{a b}$ :where $b = i$: ::$E_{a b} = \delta_{a b}$ where $a \ne j$ ::$E_{a b} = \delta_{a b} + \lambda \cdot 1$ where $a = j$ That is: :$E_{a b} = \delta_{a b}$ for all [[Definition:Element of Matrix|elements]] of $\mathbf E$ except where $b = i$ and $a = j$, at which [[Definition:Element of Matrix|element]]: :$E_{a b} = \delta_{a b} + \lambda$ That is: :$E_{a b} = \delta_{a b} + \lambda \cdot \delta_{b i} \cdot \delta_{j a}$ Hence the result. {{qed}}	0
From [[One Divides all Integers]]: :$1 \divides a$ and: :$1 \divides b$ where $\divides$ denotes [[Definition:Divisor of Integer|divisibility]]. The result follows by definition of [[Definition:Common Divisor of Integers|common divisor]]. {{Qed}}	0
Let $S_n$ denote the [[Definition:Symmetric Group on n Letters|symmetric group on $n$ letters]]. Let $\sigma \in S_n$. Let $\RR_\sigma$ denote the [[Definition:Equivalence Relation Induced by Mapping|equivalence]] defined in [[Permutation Induces Equivalence Relation]]. Let $i \in \N^*_{\le n}$. Then: :$i \in \Fix \sigma$ {{iff}} $\eqclass i {\RR_\sigma} = \set i$ where: :$\eqclass i {\RR_\sigma}$ denotes the [[Definition:Equivalence Class|equivalence class]] of $i$ under $\RR_\sigma$ :$\Fix \sigma$ denotes the [[Definition:Set of Fixed Elements|set of fixed elements]] of $\sigma$.	0
Let $\epsilon \in \R_{>0}$ be a [[Definition:Strictly Positive Real Number|strictly positive real number]]. For all $x \in A_1$, define: :$\map \Delta x = \set {\delta \in \R_{>0}: \forall y \in A_1: \map {d_1} {x, y} < 2 \delta \implies \map {d_2} {\map f x, \map f y} < \dfrac \epsilon 2}$ Define: :$\mathcal C = \set {\map {B_{\delta} } x: x \in A_1, \, \delta \in \map \Delta x}$ where $B_{\delta} \left({x}\right)$ denotes the [[Definition:Open Ball|open $\delta$-ball of $x$ in $M_1$]]. From the definition of [[Definition:Continuous Mapping (Metric Spaces)|continuity]], it follows that $\mathcal C$ is a [[Definition:Cover of Set|cover]] for $A_1$. From [[Open Ball of Metric Space is Open Set]], it therefore follows that $\mathcal C$ is an [[Definition:Open Cover|open cover]] for $A_1$. By the definition of a [[Definition:Compact Metric Space|compact metric space]], there exists a [[Definition:Finite Subcover|finite subcover]] $\set {\map {B_{\delta_1} } {x_1}, \map {B_{\delta_2} } {x_2}, \ldots, \map {B_{\delta_n} } {x_n} }$ of $\mathcal C$ for $A_1$. Define: :$\delta = \min \set {\delta_1, \delta_2, \ldots, \delta_n}$ Let $x, y \in A_1$ satisfy $\map {d_1} {x, y} < \delta$. By the definition of a [[Definition:Cover of Set|cover]], there exists a $k \in \set{1, 2, \ldots, n}$ such that $\map {d_1} {x, x_k} < \delta_k$. Then: {{begin-eqn}} {{eqn | l = \map {d_1} {y, x_k} | o = \le | r = \map {d_1} {y, x} + \map {d_1} {x, x_k} | c = [[Definition:Triangle Inequality|Triangle Inequality]] }} {{eqn | o = < | r = \delta + \delta_k | c = [[Definition:Metric Space Axioms|Metric Space Axiom $\paren {M3}$]] }} {{eqn | o = \le | r = 2 \delta_k }} {{end-eqn}} By the definition of $\Delta \left({x_k}\right)$, it follows that: :$\map {d_2} {\map f x, \map f {x_k} } < \dfrac \epsilon 2$ :$\map {d_2} {\map f y, \map f {x_k} } < \dfrac \epsilon 2$ Hence: {{begin-eqn}} {{eqn | l = \map {d_2} {\map f x, \map f y} | o = \le | r = \map {d_2} {\map f x, \map f {x_k} } + \map {d_2} {\map f {x_k}, \map f y} | c = [[Definition:Triangle Inequality|Triangle Inequality]] }} {{eqn | o = < | r = \frac \epsilon 2 + \frac \epsilon 2 | c = [[Definition:Metric Space Axioms|Metric Space Axiom $\paren{M3}$]] }} {{eqn|r = \epsilon }} {{end-eqn}} The result follows from the definition of [[Definition:Uniformly Continuous Mapping (Metric Spaces)|uniform continuity]]. {{qed}}	0
{{begin-eqn}} {{eqn | l = \int \tan x \rd x | r = -\ln \size {\cos x} | c = [[Primitive of Tangent Function/Cosine Form|Primitive of $\tan x$: Cosine Form]] }} {{eqn | ll= \leadsto | l = \int \tan a x \rd x | r = \frac 1 a \paren {-\ln \size {\cos a x} } + C | c = [[Primitive of Function of Constant Multiple]] }} {{eqn | r = \frac {-\ln \size {\cos a x} } a + C | c = simplifying }} {{end-eqn}} {{qed}}	0
Let $\struct {F, +, \times}$ be a [[Definition:Field (Abstract Algebra)|field]]. Let $a \in F$ and $m, n \in \Z$. Then: :$\paren {m n} \cdot a = m \cdot \paren {n \cdot a}$ where $n \cdot a$ is as defined in [[Definition:Integral Multiple|integral multiple]].	0
We have: {{begin-eqn}} {{eqn | l = \cos 4 \theta + i \sin 4 \theta | r = \paren {\cos \theta + i \sin \theta}^4 | c = [[De Moivre's Formula]] }} {{eqn | r = \paren {\cos \theta}^4 + \binom 4 1 \paren {\cos \theta}^3 \paren {i \sin \theta} + \binom 4 2 \paren {\cos \theta}^2 \paren {i \sin \theta}^2 }} {{eqn | o = | ro=+ | r = \binom 4 3 \paren {\cos \theta} \paren {i \sin \theta}^3 + \paren {i \sin \theta}^4 | c = [[Binomial Theorem]] }} {{eqn | r = \cos^4 \theta + 4 i \cos^3 \theta \sin \theta - 6 \cos^2 \theta \sin^2 \theta | c = substituting for [[Definition:Binomial Coefficient|binomial coefficients]] }} {{eqn | o = | ro=- | r = 4 i \cos \theta \sin^3 \theta + \sin^4 \theta | c = and using $i^2 = -1$ }} {{eqn | n = 1 | r = \cos^4 \theta - 6 \cos^2 \theta \sin^2 \theta + \sin^4 \theta }} {{eqn | o = | ro=+ | r = 4 i \cos^3 \theta \sin \theta - 4 i \cos \theta \sin^3 \theta | c = rearranging }} {{end-eqn}} Hence: {{begin-eqn}} {{eqn | l = \sin 4 \theta | r = 4 \cos^3 \theta \sin \theta - 4 \cos \theta \sin^3 \theta | c = equating [[Definition:Imaginary Part|imaginary parts]] in $(1)$ }} {{eqn | r = 4 \cos \theta \paren {1 - \sin^2 \theta} \sin \theta - 4 \cos \theta \sin^3 \theta | c = [[Sum of Squares of Sine and Cosine]] }} {{eqn | r = 4 \cos \theta \sin \theta - 8 \sin^3 \theta \cos \theta | c = multiplying out and gathering terms }} {{end-eqn}} {{qed}}	0
Let $S_n$ denote the [[Definition:Symmetric Group on n Letters|symmetric group on $n$ letters]]. Let $\pi, \rho \in S_n$. The [[Definition:Cycle Decomposition|cycle decomposition]] of the [[Definition:Permutation|permutation]] $\pi \rho \pi^{-1}$ can be obtained from that of $\rho$ by replacing each $i$ in the [[Definition:Cycle Decomposition|cycle decomposition]] of $\rho$ with $\map \pi i$.	0
By definition, every [[Definition:Real Polynomial Function|real polynomial function]] is a [[Definition:Linear Combination|linear combination]] of $B$. Suppose: :$\displaystyle \sum_{k \mathop = 0}^m \alpha_k I^k = 0, \alpha_m \ne 0$ Then by [[Definition:Differentiation|differentiating]] $m$ times, we obtain from [[Nth Derivative of Nth Power]]: :$m! \alpha_m = 0$ whence $\alpha_m = 0$ which is a contradiction. Hence $B$ is [[Definition:Linearly Independent Set|linearly independent]] and therefore is a [[Definition:Basis of Vector Space|basis]] for $\map P \R$. {{qed}}	0
=== [[Definition:Golden Mean/Definition 1|Definition 1]] === {{:Definition:Golden Mean/Definition 1}} === [[Definition:Golden Mean/Definition 2|Definition 2]] === {{:Definition:Golden Mean/Definition 2}}	0
:$\forall g \in G: g \circ N \circ g^{-1} = N$ :$\forall g \in G: g^{-1} \circ N \circ g = N$	0
From the definition of a [[Definition:Field (Abstract Algebra)|field]] as a [[Definition:Division Ring|division ring]], every element of $F^*$ is a [[Definition:Unit of Ring|unit]]. The result follows from [[Product Inverse in Ring is Unique]]. {{qed}}	0
{{begin-eqn}} {{eqn | l = \sin^2 x - \cos^2 x | r = \left({\sin^2 x - \cos^2 x}\right) \left({\sin^2 x + \cos^2 x}\right) | c = [[Sum of Squares of Sine and Cosine]] }} {{eqn | r = \sin^4 x - \cos^4 x | c = [[Difference of Two Squares]] }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \cos z | r = \cos \left({\dfrac {\pi} 2 + i \ln \phi}\right) | c = }} {{eqn | r = \frac {e^{i \left({\left({\pi / 2}\right) + i \ln \phi}\right)} + e^{-i \left({\left({\pi / 2}\right) + i \ln \phi}\right)} } 2 | c = [[Cosine Exponential Formulation]] }} {{eqn | r = \frac {e^{i \pi / 2} e^{-\ln \phi} + e^{-i \pi / 2} e^{\ln \phi} } 2 | c = }} {{eqn | r = \frac {e^{-\ln \phi} \left({\cos \frac \pi 2 + i \sin \frac \pi 2}\right) + e^{\ln \phi} \left({\cos \left({-\frac \pi 2}\right) + i \sin \left({-\frac \pi 2}\right)}\right)} 2 | c = [[Euler's Formula]] and [[Euler's Formula/Corollary|Corollary]] }} {{eqn | r = \frac {e^{-\ln \phi} \left({i \sin \frac \pi 2}\right) + e^{\ln \phi} \left({i \sin \left({-\frac \pi 2}\right)}\right)} 2 | c = [[Cosine of Half-Integer Multiple of Pi]] }} {{eqn | r = \frac {i e^{-\ln \phi} - i e^{\ln \phi} } 2 | c = [[Sine of Half-Integer Multiple of Pi]] and simplification }} {{eqn | r = -i \frac {\phi - \frac 1 {\phi} } 2 | c = [[Exponential of Natural Logarithm]] }} {{eqn | r = -i \frac {\phi^2 - 1} {2 \phi} | c = }} {{eqn | r = -i \frac {\phi} {2 \phi} | c = [[Square of Golden Mean equals One plus Golden Mean]] }} {{eqn | r = \frac {-i} 2 | c = }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = \sin \left({n + 1}\right) z + \sin \left({n - 1}\right) z | r = 2 \sin n z \cos z | c = [[Simpson's Formula for Sine by Cosine]] }} {{eqn | r = -i \sin n z | c = }} {{end-eqn}} {{finish|Where to from here?}}	0
Let $f: D \to \C$ be a [[Definition:Continuous Complex Function|continuous complex function]], where $D$ is a [[Definition:Connected Domain (Complex Analysis)|connected domain]]. Let $z_0 \in D$. Suppose that $\displaystyle \oint_C \map f z \rd z = 0$ for all [[Definition:Closed Contour (Complex Plane)|closed]] [[Definition:Staircase Contour|staircase contours]] $C$ in $D$. Then $f$ has a [[Definition:Complex Primitive|primitive]] $F: D \to \C$ defined by: :$\displaystyle \map F w = \int_{C_w} \map f z \rd z$ where $C_w$ is any [[Definition:Staircase Contour|staircase contour]] in $D$ with [[Definition:Start Point of Contour (Complex Plane)|start point]] $z_0$ and [[Definition:End Point of Contour (Complex Plane)|end point]] $w$.	0
Let $\epsilon > 0$. Since $\displaystyle \lim_{n \mathop \to \infty} x_n = l$, it follows from the definition of [[Definition:Limit of Sequence (Metric Space)|limit]] that: :$\exists N: \forall n > N: d \left({x_n, l}\right) < \epsilon$ Now let $R = N$. Then from [[Strictly Increasing Sequence of Natural Numbers]]: : $\forall r > R: n_r \ge r$ Thus $n_r > N$ and so: :$d \left({x_n, l}\right) < \epsilon$ The result follows. {{qed}}	0
=== Necessary Condition === Let $a \circ b = b \circ a$. By definition, all [[Definition:Element|elements]] of a [[Definition:Group|group]] are [[Definition:Invertible Element|invertible]]. Therefore the results in [[Power of Product of Commutative Elements in Monoid]] can be applied directly. {{qed|lemma}} === Sufficient Condition === If $\paren {a \circ b}^n = a^n \circ b^n$ for all $n$, then it certainly holds for $n = 2$: {{begin-eqn}} {{eqn | l = \paren {a \circ b}^2 | r = a^2 \circ b^2 | c = }} {{eqn | ll= \leadsto | l = \paren {a \circ b} \circ \paren {a \circ b} | r = \paren {a \circ a} \circ \paren {b \circ b} | c = }} {{eqn | ll= \leadsto | l = \paren {a^{-1} \circ a} \circ b \circ a \circ \paren {b \circ b^{-1} } | r = \paren {a^{-1} \circ a} \circ a \circ b \circ \paren {b \circ b^{-1} } | c = {{GroupAxiom|1}} }} {{eqn | ll= \leadsto | l = e \circ b \circ a \circ e | r = e \circ a \circ b \circ e | c = {{GroupAxiom|3}} }} {{eqn | ll= \leadsto | l = b \circ a | r = a \circ b | c = {{GroupAxiom|2}} }} {{end-eqn}} {{qed}}	0
The [[Definition:Integer Addition|sum]] of the entries in the $n$th [[Definition:Lesser Diagonal of Pascal's Triangle|lesser diagonal]] of [[Definition:Pascal's Triangle|Pascal's triangle]] equals the $n + 1$th [[Definition:Fibonacci Number|Fibonacci number]].	0
Let $A$ be a [[Definition:Commutative and Unitary Ring|commutative ring with unity]]. Let $A^\times$ be the [[Definition:Group of Units of Ring|group of units]] of $A$. Let $\map {\operatorname {Jac} } A$ be the [[Definition:Jacobson Radical|Jacobson radical]] of $A$. Then: :$\map {\operatorname {Jac} } A = \set {a \in A: 1_A - a x \in A^\times \text{ for all } x \in A}$ where $1_A$ is the [[Definition:Unity of Ring|unity]] of $A$.	0
:$\displaystyle \int \frac {\mathrm d x} {x \left({\sqrt{a x + b} }\right)^m} = \frac 2 {\left({m - 2}\right) b \left({\sqrt{a x + b} }\right)^{m - 2} } + \frac 1 b \int \frac {\mathrm d x} {x \left({\sqrt{a x + b} }\right)^{m - 2} }$	0
Consider the [[Definition:Natural Numbers|natural numbers]] defined as a [[Definition:Naturally Ordered Semigroup|naturally ordered semigroup]]. By definition, the [[Definition:Binary Operation|operation]] in a [[Definition:Naturally Ordered Semigroup|naturally ordered semigroup]] is [[Definition:Commutative Operation|commutative]]. Hence the result. {{qed}}	0
Let $M_1 = \left({A_1, d_1}\right)$ and $M_2 = \left({A_2, d_2}\right)$ be [[Definition:Metric Space|metric spaces]]. Let $f_c: A_1 \to A_2$ be the [[Definition:Constant Mapping|constant mapping]] from $A_1$ to $A_2$: :$\exists c \in A_2: \forall a \in A_1: f_c \left({a}\right) = c$ That is, every [[Definition:Element|point]] in $A_1$ maps to the same [[Definition:Element|point]] $c$ in $A_2$. Then $f_c$ is [[Definition:Continuous Mapping (Metric Spaces)|continuous throughout $A_1$ with respect to $d_1$ and $d_2$]].	0
From [[Sum of Infinite Geometric Sequence]]: :$(1): \quad \displaystyle \sum_{n \mathop = 0}^\infty \paren {-x^2}^n = \frac 1 {1 + x^2}$ for $-1 < x < 1$. From [[Power Series is Termwise Integrable within Radius of Convergence]], $(1)$ can be [[Definition:Integration|integrated]] term by term: {{begin-eqn}} {{eqn | l = \int_0^x \frac 1 {1 + t^2} \rd t | r = \sum_{n \mathop = 0}^\infty \int_0^x \paren {-t^2}^n \rd t | c = }} {{eqn | ll= \leadsto | l = \arctan x | r = \sum_{n \mathop = 0}^\infty \paren {-1}^n \frac {x^{2 n + 1} } {2 n + 1} | c = [[Primitive of Reciprocal of x squared plus a squared/Arctangent Form|Primitive of Reciprocal of $\dfrac 1 {1 + t^2}$]], [[Integral of Power]] }} {{end-eqn}} For $-1 \le x \le 1$, the [[Definition:Real Sequence|sequence]] $\sequence {\dfrac {x^{2 n + 1}} {2 n + 1} }$ is [[Definition:Decreasing Real Sequence|decreasing]] and [[Definition:Convergent Sequence (Analysis)|converges]] to zero. Therefore the series converges in the given range by the [[Alternating Series Test]]. {{qed|lemma}} Now consider the case $x \ge 1$: {{begin-eqn}} {{eqn | l = \arctan x | r = \frac \pi 2 - \map \arctan {\frac 1 x} | c = [[Sum of Arctangent and Arccotangent]] }} {{eqn | r = \frac \pi 2 - \sum_{n \mathop = 0}^\infty \paren {-1}^n \frac 1 {2 n + 1} \paren {\frac 1 x}^{2 n + 1} | c = as $x \ge 1$, $0 < \dfrac 1 x \le 1$, so may apply the above result }} {{eqn | r = \frac \pi 2 - \sum_{n \mathop = 0}^\infty \paren {-1}^n \frac 1 {\paren {2 n + 1} x^{2 n + 1} } }} {{end-eqn}} {{qed|lemma}} We also have: {{begin-eqn}} {{eqn | l = \map \arctan {-x} | r = -\arctan x | c = [[Arctangent Function is Odd]] }} {{eqn | r = -\frac \pi 2 - \sum_{n \mathop = 0}^\infty \paren {-1}^{n + 1} \frac 1 {\paren {2 n + 1} x^{2 n + 1} } | c = per above result }} {{end-eqn}} Substituting $x$ for $-x$ gives us the expansion for $x \le -1$: {{begin-eqn}} {{eqn | l = \arctan x | r = -\frac \pi 2 - \sum_{n \mathop = 0}^\infty \paren {-1}^{n + 1} \frac 1 {\paren {2 n + 1} \paren {-x}^{2 n + 1} } }} {{eqn | r = -\frac \pi 2 - \sum_{n \mathop = 0}^\infty \paren {-1}^{n + 1} \frac 1 {-\paren {2 n + 1} x^{2 n + 1} } }} {{eqn | r = -\frac \pi 2 - \sum_{n \mathop = 0}^\infty \paren {-1}^n \frac 1 {\paren {2 n + 1} x^{2 n + 1} } }} {{end-eqn}} {{qed}}	0
Let $\mathcal C$ be a smooth curve given by the vector function $\mathbf r \left({t}\right)$ for $a \le t \le b$. Let $f$ be a differentiable function of two or three variables whose gradient vector $\nabla f$ is continuous on $\mathcal C$. Then: :$\displaystyle \int_\mathcal C \nabla f \cdot d \mathbf r = f \left({\mathbf r \left({b}\right)}\right) - f \left({\mathbf r \left({a}\right)}\right)$	0
Let $\mathbf r$ be a [[Definition:Position Vector|position vector]] embedded in a [[Definition:Cartesian Plane|Cartesian plane]] $\CC$ with [[Definition:Origin|origin]] $O$. Let $\CC$ be [[Definition:Plane Rotation|rotated]] [[Definition:Anticlockwise|anticlockwise]] through an [[Definition:Angle|angle]] $\varphi$ about the [[Definition:Axis of Rotation|axis of rotation]] $O$. Let $\CC'$ denote the [[Definition:Cartesian Plane|Cartesian plane]] in its new position. Let $\mathbf r$ be kept fixed during this [[Definition:Plane Rotation|rotation]]. Let $\tuple {x, y}$ denote the [[Definition:Component of Vector|components]] of $\mathbf r$ with respect to $\CC$. Let $\tuple {x', y'}$ denote the [[Definition:Component of Vector|components]] of $\mathbf r$ with respect to $\CC'$. Then: {{begin-eqn}} {{eqn | l = x' | r = x \cos \varphi + y \sin \varphi }} {{eqn | l = y' | r = -x \sin \varphi + y \cos \varphi }} {{end-eqn}}	0
Let $\struct {S, \circ}$ be an [[Definition:Algebraic Structure|algebraic structure]] in which $\circ$ has an [[Definition:Identity Element|identity]] $e_S$. Then: :$\forall x \in S: x \circ e_S = x = e_S \circ x$ Thus: {{begin-eqn}} {{eqn | l = \map \phi x | r = \map \phi {x \circ e_S} | c = $e_S$ is an [[Definition:Identity Element|identity]] for $\circ$ }} {{eqn | r = \map \phi x * \map \phi {e_S} | c = [[Definition:Morphism Property|Morphism property]] of $\circ$ under $\phi$ }} {{end-eqn}} and: {{begin-eqn}} {{eqn | l = \map \phi x | r = \map \phi {e_S \circ x} | c = $e_S$ is an [[Definition:Identity Element|identity]] for $\circ$ }} {{eqn | r = \map \phi {e_S} * \map \phi x | c = [[Definition:Morphism Property|Morphism property]] of $\circ$ under $\phi$ }} {{end-eqn}} The result follows because every [[Definition:Element of Set|element]] $y \in T$ is of the form $\map \phi x$ with $x \in S$. {{qed}}	0
Define: :$\displaystyle \map g z = \sum_{n \mathop = 1}^\infty n a_n \paren {z - \xi}^{n - 1}$ From [[Radius of Convergence of Derivative of Complex Power Series]], it follows that $g$ has [[Definition:Radius of Convergence of Complex Power Series|radius of convergence]] $R$. Fix an $\epsilon > 0$ satisfying $\epsilon < R - \cmod {z - \xi}$. Define: :$\displaystyle M = \paren {R - \epsilon - \cmod {z - \xi} }^{-2} \sum_{n \mathop = 2}^\infty \cmod {a_n} \paren {R - \epsilon}^n$ Suppose that $\cmod h \le R - \epsilon - \cmod {z - \xi}$. Then, by the [[Binomial Theorem]] and the [[Triangle Inequality]]: {{begin-eqn}} {{eqn | l = \cmod {\dfrac {\map f {z + h} - \map f z} h - \map g z} | r = \cmod {\dfrac 1 h \paren {\sum_{n \mathop = 0}^\infty a_n \paren {z + h - \xi}^n - \sum_{n \mathop = 0}^\infty a_n \paren {z - \xi}^n} - \sum_{n \mathop = 1}^\infty n a_n \paren {z - \xi}^{n - 1} } }} {{eqn | r = \cmod {\sum_{n \mathop = 0}^\infty a_n \sum_{k \mathop = 0}^n \binom n k \paren {z - \xi}^k h^{n - k - 1} - \sum_{n \mathop = 0}^\infty \dfrac {a_n} h \paren {z - \xi}^n - \sum_{n \mathop = 1}^\infty n a_n \paren {z - \xi}^{n - 1} } | c = [[Binomial Theorem]] }} {{eqn | r = \cmod {\sum_{n \mathop = 1}^\infty a_n \paren {\sum_{k \mathop = 0}^n \binom n k \paren {z - \xi}^k h^{n - k - 1} - \dfrac 1 h \paren {z - \xi}^n - n \paren {z - \xi}^{n - 1} } } | c = [[Difference of Absolutely Convergent Series]] }} {{eqn | r = \cmod {\sum_{n \mathop = 2}^\infty a_n \sum_{k \mathop = 0}^{n - 2} \binom n k \paren {z - \xi}^k h^{n - k - 1} } | c = by algebraic manipulations }} {{eqn | o = \le | r = \cmod h \sum_{n \mathop = 2}^\infty \cmod {a_n} \sum_{k \mathop = 0}^{n - 2} \binom n k \cmod {z - \xi}^k \cmod h^{n-k-2} | c = [[Triangle Inequality]] }} {{eqn | o = \le | r = \cmod h \sum_{n \mathop = 2}^\infty \cmod {a_n} \sum_{k \mathop = 0}^{n - 2} \binom n k \cmod {z - \xi}^k \paren {R - \epsilon - \cmod {z - \xi} }^{n - k - 2} | c = by assumption }} {{eqn | o = \le | r = \cmod h \paren {R - \epsilon - \cmod {z - \xi} }^{-2} \sum_{n \mathop = 2}^\infty \cmod {a_n} \sum_{k \mathop = 0}^n \binom n k \cmod {z - \xi}^k \paren {R - \epsilon - \cmod {z - \xi} }^{n - k} }} {{eqn | r = \cmod h \paren {R - \epsilon - \cmod {z - \xi} }^{-2} \sum_{n \mathop = 2}^\infty \cmod {a_n} \paren {R - \epsilon}^n | c = by the [[Binomial Theorem|binomial theorem]] }} {{eqn | r = M \cmod h }} {{end-eqn}} Letting $h\to 0$ we see that $\map {f'} z$ exists and $\map {f'} z = \map g z$, as desired. {{qed}}	0
Let $n \in \Z_{>0}$ be a [[Definition:Integer Power|power]] of $2$. Then: :$\map \sigma n = 2 n - 1$	0
Let $\struct {R, +, *, \norm {\,\cdot\,} }$ be a [[Definition:Normed Division Ring|normed division ring]]. Let $d$ be the [[Definition:Metric Induced by Norm on Division Ring|metric induced by the norm]] $\norm {\,\cdot\,}$. Let $p \in \R_{\ge 1} \cup \set \infty$. Let $d_p$ be the [[Definition:P-Product Metric|$p$-product metric]] on $R \times R$. Let $R^* = R \setminus \set 0$ Let $d^*$ be the [[Definition:Restriction|restriction]] of $d$ to $R^*$. Then the following results hold:	0
{{begin-eqn}} {{eqn | l = \lambda_a \sqbrk T | r = \set {s \in S: \exists t \in T: s = \map {\lambda_a} t} | c = {{Defof|Image of Subset under Mapping}} }} {{eqn | r = \set {s \in S: \exists t \in T: s = a \circ t} | c = {{Defof|Left Regular Representation}} }} {{eqn | r = \set {a \circ t: t \in T} | c = }} {{eqn | r = a \circ T | c = {{Defof|Subset Product}} }} {{end-eqn}} {{qed}}	0
Let $a$ be [[Definition:Odd Integer|odd]] and $b$ be [[Definition:Even Integer|even]]. Then by definition of [[Definition:Odd Integer|odd number]]: :$\exists c \in \Z: a = 2 c + 1$ and by definition of [[Definition:Even Integer|even number]]: :$\exists d \in \Z: b = 2 d$ So: {{begin-eqn}} {{eqn | l = a - b | r = 2 c + 1 - 2 d | c = }} {{eqn | r = 2 \paren {c - d} + 1 | c = }} {{end-eqn}} Hence the result by definition of [[Definition:Odd Integer|odd number]]. {{qed}} {{Euclid Note|27|IX}}	0
The number of [[Definition:Sylow p-Subgroup|Sylow $p$-subgroups]] of a [[Definition:Finite Group|finite group]] is [[Definition:Congruence (Number Theory)|congruent]] to $1 \pmod p$.	0
Let $\struct {\R, \tau_d}$ be the [[Definition:Real Number Line with Euclidean Topology|real number line with the usual (Euclidean) topology]]. Then $\tau_d$ can be given by a [[Definition:Quasimetric|quasimetric]] defined as: :$\map d {x, y} = \begin {cases} y - x & : y \ge x \\ 2 \paren {x - y} & : y < x \end {cases}$ Thus $\struct {\R, \tau_d}$ is a [[Definition:Quasimetric Space|quasimetric space]].	0
{{begin-eqn}} {{eqn | l = 31 | r = 1 + 5 + 5^2 | c = }} {{eqn | r = 1 + 2 + 2^2 + 2^3 + 2^4 | c = }} {{end-eqn}} {{begin-eqn}} {{eqn | l = 8191 | r = 1 + 90 + 90^2 | c = }} {{eqn | r = 1 + 2 + 2^2 + 2^3 + 2^4 + 2^5 + 2^6 + 2^7 + 2^8 + 2^9 + 2^{10}+ 2^{11}+ 2^{12} | c = }} {{end-eqn}} These are the only two examples known. {{qed}}	0
With a view to expressing the problem in the form: :$\displaystyle \int u \frac {\d v} {\d x} \rd x = u v - \int v \frac {\d u} {\d x} \rd x$ let: {{begin-eqn}} {{eqn | l = u | r = \sin^{n - 1} x | c = }} {{eqn | ll= \leadsto | l = \frac {\d u} {\d x} | r = \paren {n - 1} \sin ^{n - 2} x \cos x | c = [[Chain Rule for Derivatives]], [[Derivative of Sine Function]], [[Derivative of Power]] }} {{end-eqn}} and let: {{begin-eqn}} {{eqn | l = \frac {\d v} {\d x} | r = \sin x | c = }} {{eqn | ll= \leadsto | l = v | r = -\cos x | c = [[Primitive of Sine Function]] }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = \int \sin^n x \rd x | r = \int \sin^{n - 1} x \sin x \rd x | c = }} {{eqn | r = \sin^{n - 1} x \paren {-\cos x} - \int \paren {-\cos x} \paren {\paren {n - 1} \sin^{n - 2} x \cos x} \rd x | c = [[Integration by Parts]] }} {{eqn | r = \int \paren {n - 1} \sin^{n - 2} x \cos^2 x \rd x - \sin^{n - 1} x \cos x | c = rearranging }} {{eqn | r = \int \paren {n - 1} \sin^{n - 2} x \paren {1 - \sin^2 x} \rd x - \sin^{n - 1} x \cos x | c = [[Sum of Squares of Sine and Cosine]] }} {{eqn | r = \paren {n - 1} \int \sin^{n - 2} x \rd x - \paren {n - 1} \int \sin^n x \rd x - \sin^{n - 1} x \cos x | c = [[Linear Combination of Integrals]] }} {{eqn | ll= \leadsto | l = n \int \sin^n x \rd x | r = \paren {n - 1} \int \sin^{n - 2} x \rd x - \sin^{n - 1} x \cos x | c = rearranging }} {{eqn | ll= \leadsto | l = \int \sin^n x \rd x | r = \dfrac {n - 1} n \int \sin^{n - 2} x \rd x - \dfrac {\sin^{n - 1} x \cos x} n | c = dividing both sides by $n$ }} {{end-eqn}} {{qed}}	0
We have that [[Non-Zero Real Numbers under Multiplication form Group]]. We also have that the [[Definition:Set|set]] of [[Definition:Zero (Number)|non-zero]] [[Definition:Integer|integers]] $\Z_{\ne 0}$ form a [[Definition:Subset|subset]] of $\R_{\ne 0}$. From [[Non-Zero Integers Closed under Multiplication]]: :$\forall a, b \in \Z_{\ne 0}: a \times b \in \Z_{\ne 0}$ We have that: :$\forall x \in \Z_{\ne 0}: 1 \times x= x = x \times 1$ and so $1$ is the [[Definition:Identity Element|identity]] of $\struct {\Z_{\ne 0}, \times}$. But for $x \in \Z_{\ne 0}: x \ne 1$, there exists no $y \in \Z_{\ne 0}: x \times y = 1$. Thus $\struct {\Z_{\ne 0}, \times}$ does not have [[Definition:Inverse Element|inverses]] for all $x \in \Z_{\ne 0}$. Thus, by definition, $\struct {\Z_{\ne 0}, \times}$ is not a [[Definition:Group|group]]. It follows that $\struct {\Z_{\ne 0}, \times}$ is not a [[Definition:Subgroup|subgroup]] of $\struct {\R_{\ne 0}, \times}$. {{qed}}	0
Note that by [[Subset of Finite Set is Finite]], $\operatorname{Supp} \left({f}\right)$ is indeed [[Definition:Finite Set|finite]]. The result now follows from: * [[Sum over Complement of Finite Set]] * [[Sum of Zero over Finite Set]] * [[Identity Element of Addition on Numbers]] {{qed}}	0
From the [[Definition:Numerators and Denominators of Continued Fraction|recursive definition of continued fractions]], we have: {{begin-eqn}} {{eqn | l = p_i | r = a_i p_{i - 1} + p_{i - 2} | c = }} {{eqn | l = q_i | r = a_i q_{i - 1} + q_{i - 2} | c = }} {{end-eqn}} Let: {{begin-eqn}} {{eqn | l = \sqbrk {a_0, a_1, a_2, a_3, a_4, a_5, a_6, a_7, a_8, a_9, \ldots} | r = \sqbrk {1, 0, 1, 1, 2, 1, 1, 4, 1, 1, \ldots} }} {{end-eqn}} In other words: :$a_{3 n + 1} = 2 n$ and: :$a_{3 n + 0} = a_{3 n + 2} = 1$ Then $p_i$ and $q_i$ are as follows: :$\begin{array}{r|cccccccccc} \displaystyle i & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\ \hline p_i & 1 & 1 & 2 & 3 & 8 & 11 & 19 & 87 & 106 & 193 \\ q_i & 1 & 0 & 1 & 1 & 3 & 4 & 7 & 32 & 39 & 71 \\ \hline \end{array}$ Furthermore, $p_i$ and $q_i$ satisfy the following $6$ [[Definition:Recursive Sequence|recurrence relations]]: {{begin-eqn}} {{eqn | n = 1 | l = p_{3 n + 0} | r = \paren {a_{3 n + 0} } p_{3 n - 1} + p_{3 n - 2} | rr= = p_{3 n - 1} + p_{3 n - 2} }} {{eqn | n = 2 | l = p_{3 n + 1} | r = \paren {a_{3 n + 1} } p_{3 n + 0} + p_{3 n - 1} | rr= = 2 n p_{3 n + 0} + p_{3 n - 1} }} {{eqn | n = 3 | l = p_{3 n + 2} | r = \paren {a_{3 n + 2} } p_{3 n + 1} + p_{3 n + 0} | rr= = p_{3 n + 1} + p_{3 n + 0} }} {{eqn | n = 4 | l = q_{3 n + 0} | r = \paren {a_{3 n + 0} } q_{3 n - 1} + q_{3 n - 2} | rr= = q_{3 n - 1} + q_{3 n - 2}, }} {{eqn | n = 5 | l = q_{3 n + 1} | r = \paren {a_{3 n + 1} } q_{3 n + 0} + q_{3 n - 1} | rr= = 2 n q_{3 n + 0} + q_{3 n - 1}, }} {{eqn | n = 6 | l = q_{3 n + 2} | r = \paren {a_{3 n + 2} } q_{3 n + 1} + q_{3 n + 0} | rr= = q_{3 n + 1} + q_{3 n + 0}, }} {{end-eqn}} Our ultimate aim is to prove that: :$\displaystyle \lim_{n \mathop \to \infty} \frac {p_n} {q_n} = e$ In the pursuit of that aim, let us define the [[Definition:Definite Integral|integrals]]: {{begin-eqn}} {{eqn | l = A_n | r = \int_0^1 \frac {x^n \paren {x - 1}^n} {n!} e^x \rd x }} {{eqn | l = B_n | r = \int_0^1 \frac {x^{n + 1} \paren {x - 1}^n} {n!} e^x \rd x }} {{eqn | l = C_n | r = \int_0^1 \frac {x^n \paren {x - 1}^{n + 1} } {n!} e^x \rd x }} {{end-eqn}} === [[Continued Fraction Expansion of Euler's Number/Proof 1/Lemma|Lemma]] === {{:Continued Fraction Expansion of Euler's Number/Proof 1/Lemma}}{{qed|lemma}} We assert that $A_n$, $B_n$ and $C_n$ all converge to $0$ as $n \to \infty$: {{begin-eqn}} {{eqn | l = \lim_{n \mathop \to \infty} A_n | r = \frac {\frac {x^{n + 1} \paren {x - 1}^{n + 1} } {\paren {n + 1}!} e^x} {\frac {x^n \paren {x - 1}^n } {n!} e^x} | c = [[Radius of Convergence from Limit of Sequence/Real Case|Radius of Convergence from Limit of Sequence: Real Case]] }} {{eqn | r = \frac {x \paren {x - 1} } {\paren {n + 1} } }} {{eqn | r = 0 }} {{eqn | l = \lim_{n \mathop \to \infty} B_n | r = \frac {\frac {x^{n + 2} \paren {x - 1}^{n + 1} } {\paren {n + 1}!} e^x} {\frac {x^{n + 1} \paren {x - 1}^n} {n!} e^x} | c = [[Radius of Convergence from Limit of Sequence/Real Case]] }} {{eqn | r = \frac {x \paren {x - 1} } {\paren {n + 1} } }} {{eqn | r = 0 }} {{eqn | l = \lim_{n \mathop \to \infty} C_n | r = \lim_{n \mathop \to \infty} B_n - \lim_{n \mathop \to \infty} A_n }} {{eqn | r = 0 }} {{end-eqn}} We now have: {{begin-eqn}} {{eqn | l = \lim_{n \mathop \to \infty} A_n | r = \lim_{n \mathop \to \infty} \paren {q_{3 n} e - p_{3 n} } | rr = = 0 }} {{eqn | l = \lim_{n \mathop \to \infty} B_n | r = \lim_{n \mathop \to \infty} \paren {p_{3 n + 1} - q_{3 n + 1} e} | rr = = 0 }} {{eqn | l = \lim_{n \mathop \to \infty} C_n | r = \lim_{n \mathop \to \infty} \paren {p_{3 n + 2} - q_{3 n + 2} e} | rr = = 0 }} {{end-eqn}} from which we conclude: {{begin-eqn}} {{eqn | l = \lim_{n \mathop \to \infty} \paren {p_n - q_n e} | r = 0 }} {{eqn | l = \lim_{n \mathop \to \infty} p_n | r = q_n e }} {{eqn | l = \lim_{n \mathop \to \infty} \frac {p_n} {q_n} | r = e }} {{end-eqn}} {{qed}}	0
Let $T = \struct {S, \tau}$ be a [[Definition:Hausdorff Space|Hausdorff space]] which is [[Definition:Separable Space|separable]]. Then $S$ can have a [[Definition:Cardinality|cardinality]] no greater than $2^{2^{\aleph_0} }$.	0
Let $p \in \Z$ be an [[Definition:Odd Prime|odd prime]]. Let $q \in \Z$ be an [[Definition:Odd Integer|odd integer]]. Then: :$\displaystyle \sum_{0 \mathop \le k \mathop < p / 2} \floor {\dfrac {2 k q} p}r \equiv \sum_{0 \mathop \le k \mathop < p / 2} \floor {\dfrac {k q} p} \pmod 2$	0
Let $\eqclass {a, b} {}$ and $\eqclass {c, d} {}$ be [[Definition:Integer|integers]], as defined by the [[Definition:Integer/Formal Definition|formal definition of integers]]. Then exactly one of the following holds: {{begin-eqn}} {{eqn | l = \eqclass {a, b} {} | o = < | r = \eqclass {c, d} {} | c = }} {{eqn | l = \eqclass {a, b} {} | o = = | r = \eqclass {c, d} {} | c = }} {{eqn | l = \eqclass {a, b} {} | o = > | r = \eqclass {c, d} {} | c = }} {{end-eqn}} That is, [[Definition:Strict Ordering on Integers|strict ordering]] is a [[Definition:Trichotomy|trichotomy]].	0
{{begin-eqn}} {{eqn | l = 2 \times 0^2 + 11 | r = 0 + 11 }} {{eqn | r = 11 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 2 \times 1^2 + 11 | r = 2 + 11 | c = }} {{eqn | r = 13 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 2 \times 2^2 + 11 | r = 2 \times 4 + 11 | c = }} {{eqn | r = 8 + 11 | c = }} {{eqn | r = 19 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 2 \times 3^2 + 11 | r = 2 \times 9 + 11 | c = }} {{eqn | r = 18 + 11 | c = }} {{eqn | r = 29 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 2 \times 4^2 + 11 | r = 2 \times 16 + 11 | c = }} {{eqn | r = 32 + 11 | c = }} {{eqn | r = 43 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 2 \times 5^2 + 11 | r = 2 \times 25 + 11 | c = }} {{eqn | r = 50 + 11 | c = }} {{eqn | r = 61 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 2 \times 6^2 + 11 | r = 2 \times 36 + 11 | c = }} {{eqn | r = 72 + 11 | c = }} {{eqn | r = 83 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 2 \times 7^2 + 11 | r = 2 \times 49 + 11 | c = }} {{eqn | r = 98 + 11 | c = }} {{eqn | r = 109 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 2 \times 8^2 + 11 | r = 2 \times 64 + 11 | c = }} {{eqn | r = 128 + 11 | c = }} {{eqn | r = 139 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 2 \times 9^2 + 11 | r = 2 \times 81 + 11 | c = }} {{eqn | r = 162 + 11 | c = }} {{eqn | r = 173 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 2 \times 10^2 + 11 | r = 2 \times 100 + 11 | c = }} {{eqn | r = 200 + 11 | c = }} {{eqn | r = 211 | c = which is [[Definition:Prime Number|prime]] }} {{end-eqn}}	0
Let $f$ be a [[Definition:Real Function|real function]] which is: :[[Definition:Continuous on Interval|continuous]] on the [[Definition:Closed Real Interval|closed interval]] $\closedint a b$ and: :[[Definition:Differentiable on Interval|differentiable]] on the [[Definition:Open Real Interval|open interval]] $\openint a b$. Let $\map f a = \map f b$. Then: :$\exists \xi \in \openint a b: \map {f'} \xi = 0$	0
:$\lambda \circ e = 0_R \circ x = e$	0
Let $\chi : G := \left({\Z / q \Z}\right)^\times \to \C^\times$ be a [[Definition:Dirichlet Character|Dirichlet character]] modulo $q$. {{explain|$\C^\times$}} Let $L \left({s, \chi}\right)$ be the [[Definition:Dirichlet L-function|Dirichlet $L$-function]] for $\chi$. Let $\chi$ be the [[Definition:Dirichlet Character/Trivial Character|trivial character]]. Then $L \left({s, \chi}\right)$ has an analytic continuation to $\C$ except for a [[Definition:Simple Pole|simple pole]] at $s = 1$. Let $\chi$ be non-trivial. Then $L \left({s, \chi}\right)$ is analytic on $\Re \left({s}\right) > 0$.	0
By inspection, the [[Definition:Cayley Table|Cayley table]] is constructed: :$\begin{array}{c|cccc} & e & a & b & c \\ \hline e & e & a & b & c \\ a & a & e & c & b \\ b & b & c & e & a \\ c & c & b & a & e \\ \end{array}$ Again by inspection this can be seen to be the same as the [[Klein Four-Group/Cayley Table|Cayley table for the Klein $4$-group]]. {{qed}}	0
Let $\struct {R, \norm {\,\cdot\,} }$ be a [[Definition:Normed Division Ring |normed division ring]] with [[Definition:Non-Archimedean Division Ring Norm|non-Archimedean norm]] $\norm {\,\cdot\,}$. Let $\sequence {x_n}$ be a [[Definition:Sequence|sequence]] in $R$. Then: :$\sequence {x_n}$ is a [[Definition:Cauchy Sequence (Normed Division Ring)|Cauchy sequence]] {{iff}} $\displaystyle \lim_{n \mathop \to \infty} \norm {x_{n + 1} - x_n} = 0$.	0
[[Definition:Equivalent Matrices|Matrix equivalence]] is an [[Definition:Equivalence Relation|equivalence relation]].	0
=== Necessary Condition === Let $a = \pm 1$. From [[Integer Divides Itself]] we have that $1 \divides 1$. From [[Integer Divides its Negative]] we have that $-1 \divides 1$. {{qed|lemma}} === Sufficient Condition === Let $\exists a \in \Z: a \divides 1$. Then $\exists c \in \Z: a c = 1$. From [[Absolute Value Function is Completely Multiplicative]] we have that: :$\size a \cdot \size c = \size 1$ Neither $a$ nor $c$ can be zero, from [[Integers form Integral Domain]]. So $\size a \ge 1$ and $\size c \ge 1$. But if $\size a > 1$ then: :$\size a \cdot \size c > \size c$ and so: :$\size a \cdot \size c > 1$ So: :$\size a = 1$ that is: :$a = 1$ or $a = -1$ {{qed}}	0
Let $x \in I_o$. Then by definition: :$0 < x < 1$ and so: :$0 \le x \le 1$ and so: :$x \in I_c$. Thus: :$I_o \subseteq I_c$ Consider: :$0 \in I_c$ by definition of [[Definition:Closed Real Interval|closed interval]]. But it is not the case that $0 < 0$. So $0 \notin I_o$ and so $I_c \not \subseteq I_o$. Hence the result by definition of [[Definition:Proper Subset|proper subset]]. {{qed}}	0
Let $\begin{vmatrix} a_{11} & \cdots & a_{1s} & \cdots & a_{1n} \\ \vdots & \ddots & \vdots & \ddots & \vdots \\ a_{r1} & \cdots & a_{rs} & \cdots & a_{rn} \\ \vdots & \ddots & \vdots & \ddots & \vdots \\ a_{n1} & \cdots & a_{ns} & \cdots & a_{nn} \end{vmatrix}$ be a [[Definition:Determinant of Matrix|determinant]]. Then $\begin{vmatrix} a_{11} & \cdots & a_{1s} & \cdots & a_{1n} \\ \vdots & \ddots & \vdots & \ddots & \vdots \\ a_{r1} + a'_{r1} & \cdots & a_{rs} + a'_{rs} & \cdots & a_{rn} + a'_{rn} \\ \vdots & \ddots & \vdots & \ddots & \vdots \\ a_{n1} & \cdots & a_{ns} & \cdots & a_{nn} \end{vmatrix} = \begin{vmatrix} a_{11} & \cdots & a_{1s} & \cdots & a_{1n} \\ \vdots & \ddots & \vdots & \ddots & \vdots \\ a_{r1} & \cdots & a_{rs} & \cdots & a_{rn} \\ \vdots & \ddots & \vdots & \ddots & \vdots \\ a_{n1} & \cdots & a_{ns} & \cdots & a_{nn} \end{vmatrix} + \begin{vmatrix} a_{11} & \cdots & a_{1s} & \cdots & a_{1n} \\ \vdots & \ddots & \vdots & \ddots & \vdots \\ a'_{r1} & \cdots & a'_{rs} & \cdots & a'_{rn} \\ \vdots & \ddots & \vdots & \ddots & \vdots \\ a_{n1} & \cdots & a_{ns} & \cdots & a_{nn} \end{vmatrix}$. Similarly: Then $\begin{vmatrix} a_{11} & \cdots & a_{1s} + a'_{1s} & \cdots & a_{1n} \\ \vdots & \ddots & \vdots & \ddots & \vdots \\ a_{r1} & \cdots & a_{rs} + a'_{rs} & \cdots & a_{rn} \\ \vdots & \ddots & \vdots & \ddots & \vdots \\ a_{n1} & \cdots & a_{ns} + a'_{ns} & \cdots & a_{nn} \end{vmatrix} = \begin{vmatrix} a_{11} & \cdots & a_{1s} & \cdots & a_{1n} \\ \vdots & \ddots & \vdots & \ddots & \vdots \\ a_{r1} & \cdots & a_{rs} & \cdots & a_{rn} \\ \vdots & \ddots & \vdots & \ddots & \vdots \\ a_{n1} & \cdots & a_{ns} & \cdots & a_{nn} \end{vmatrix} + \begin{vmatrix} a_{11} & \cdots & a'_{1s} & \cdots & a_{1n} \\ \vdots & \ddots & \vdots & \ddots & \vdots \\ a_{r1} & \cdots & a'_{rs} & \cdots & a_{rn} \\ \vdots & \ddots & \vdots & \ddots & \vdots \\ a_{n1} & \cdots & a'_{ns} & \cdots & a_{nn} \end{vmatrix}$.	0
{{begin-eqn}} {{eqn | l = \csc 75^\circ | r = \frac 1 {\sin 75 \degrees} | c = [[Cosecant is Reciprocal of Sine]] }} {{eqn | r = \frac 1 {\frac {\sqrt 6 + \sqrt 2} 4} | c = [[Sine of 75 Degrees|Sine of $75 \degrees$]] }} {{eqn | r = \frac 4 {\sqrt 6 + \sqrt 2} | c = multiplying top and bottom by $4$ }} {{eqn | r = \frac {4 \paren {\sqrt 6 - \sqrt 2} } {\paren {\sqrt 6 + \sqrt 2} \paren {\sqrt 6 - \sqrt 2} } | c = multiplying top and bottom by $\sqrt 6 - \sqrt 2$ }} {{eqn | r = \frac {4 \paren {\sqrt 6 - \sqrt 2} } {6 - 2} | c = [[Difference of Two Squares]] }} {{eqn | r = \sqrt 6 - \sqrt 2 | c = simplifying }} {{end-eqn}} {{qed}}	0
By definition, [[Definition:Matrix Entrywise Addition|matrix entrywise addition]] is the '''[[Definition:Hadamard Product|Hadamard product]]''' of $\mathbf A$ and $\mathbf B$ with respect to [[Definition:Ring Addition|ring addition]]. We have from {{Ring-axiom|A0}} that [[Definition:Ring Addition|ring addition]] is [[Definition:Closed Algebraic Structure|closed]]. The result then follows directly from [[Closure of Hadamard Product]]. {{qed}}	0
Let $I = \closedint a b$ be a [[Definition:Closed Real Interval|closed real interval]]. Let $\struct {\map {\CC^k} I, +, \, \cdot \,}_\R$ be the [[Space of Real-Valued k-times Differentiable on Closed Interval Functions with Pointwise Addition and Pointwise Scalar Multiplication forms Vector Space|vector space of real-valued functions, k-times differentiable on]] $I$. Let $x \in \map {\CC^k} I$ be a [[Definition:Real-Valued Function|real-valued function]] of [[Definition:Differentiability Class|differentiability class]] $k$. Let $\norm {\, \cdot \,}_{\map {C^k} I}$ be the [[Definition:C^k Norm|$C^k$ norm]] on $I$. Then $\norm {\, \cdot \,}_{\map {C^k} I}$ is a [[Definition:Norm on Vector Space|norm]] on $\struct {\map {\CC^k} I, +, \, \cdot \,}_\R$.	0
{{TFAE|def = Nilradical of Ring}} Let $A$ be a [[Definition:Commutative Ring|commutative ring]].	0
By [[Abelian Group Factored by Prime]], the [[Definition:Subgroup|subgroup]] $H_2$ defined as: :$H_2 := \set {g \in G: g^2 = e}$ has precisely two elements. One of them has to be $e$, since $e^2 = e$. The result follows. {{qed}}	0
{{begin-eqn}} {{eqn | l = \int e^{a x} \sin b x \rd x | r = \int e^{a x} \paren {\frac {e^{i b x} - e^{-i b x} } {2 i} } \rd x | c = [[Sine Exponential Formulation]] }} {{eqn | r = \frac 1 {2 i} \int e^{a x} \paren {e^{i b x} - e^{-i b x} } \rd x | c = [[Primitive of Constant Multiple of Function]] }} {{eqn | r = \frac 1 {2 i} \int \paren {e^{a x} e^{i b x} - e^{a x} e^{-i b x} } \rd x | c = }} {{eqn | r = \frac 1 {2 i} \int \paren {e^{a x + i b x} - e^{a x - i b x} } \rd x | c = [[Exponent Combination Laws/Product of Powers|Exponent Combination Laws: Product of Powers]] }} {{eqn | r = \frac 1 {2 i} \int e^{a x + i b x} \rd x - \frac 1 {2 i} \int e^{a x - i b x} \rd x | c = [[Linear Combination of Integrals]] }} {{eqn | r = \frac 1 {2 i} \int e^{\paren {a + i b} x} \rd x - \frac 1 {2 i} \int e^{\paren {a - i b} x} \rd x | c = }} {{eqn | r = \frac 1 {2 i} \frac {e^{\paren {a + i b} x} } {a + i b} - \frac 1 {2 i} \frac {e^{\paren {a - i b} x} } {a - i b} + C | c = [[Primitive of Exponential of a x|Primitive of $e^{a x}$]] }} {{eqn | r = \frac 1 {2 i} \frac {e^{a x + i b x} } {a + i b} - \frac 1 {2 i} \frac {e^{a x - i b x} } {a - i b} + C | c = }} {{eqn | r = \frac 1 {2 i} \frac {e^{a x} e^{i b x} } {a + i b} - \frac 1 {2 i} \frac {e^{a x} e^{-i b x} } {a - i b} + C | c = [[Exponent Combination Laws/Product of Powers|Exponent Combination Laws: Product of Powers]] }} {{eqn | r = \frac 1 {2 i} \frac {e^{a x} e^{i b x} \paren {a - i b} } {\paren {a + i b} \paren {a - i b} } - \frac 1 {2 i} \frac {e^{a x} e^{-i b x} \paren {a + i b} } {\paren {a - i b} \paren {a + i b} } + C | c = }} {{eqn | r = \frac {e^{a x} e^{i b x} \paren {a - i b} - e^{a x} e^{-i b x} \paren {a + i b} } {2 i \paren {a + i b} \paren {a - i b} } + C | c = }} {{eqn | r = \frac {e^{a x} e^{i b x} \paren {a - i b} - e^{a x} e^{-i b x} \paren {a + i b} } {2 i \paren {a^2 + b^2} } + C | c = [[Product of Complex Number with Conjugate]] }} {{eqn | r = \frac {a e^{a x} e^{i b x} - i b e^{a x} e^{i b x} - a e^{a x} e^{-i b x} - i b e^{a x} e^{-i b x} } {2 i \paren {a^2 + b^2} } + C | c = }} {{eqn | r = \frac {e^{a x} } {\paren {a^2 + b^2} } \paren {\frac {a e^{i b x} - i b e^{i b x} - a e^{-i b x} - i b e^{-i b x} } {2 i} } + C | c = }} {{eqn | r = \frac {e^{a x} } {\paren {a^2 + b^2} } \paren {a \frac {e^{i b x} - e^{-i b x} } {2 i} - b \frac {e^{i b x} + e^{-i b x} } 2 } + C | c = }} {{eqn | r = \frac {e^{a x} } {\paren {a^2 + b^2} } \paren {a \frac {e^{i b x} - e^{-i b x} } {2 i} - b \cos b x } + C | c = [[Cosine Exponential Formulation]] }} {{eqn | r = \frac {e^{a x} } {\paren {a^2 + b^2} } \paren {a \sin b x - b \cos b x } + C | c = [[Sine Exponential Formulation]] }} {{eqn | r = \frac {e^{a x} \paren {a \sin b x - b \cos b x} } {a^2 + b^2} + C | c = }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = x^2 | o = \equiv | r = y^2 | rr= \pmod n | c = }} {{eqn | ll= \leadsto | l = n | o = \divides | r = \paren {x^2 - y^2} | c = }} {{eqn | ll= \leadsto | l = n | o = \divides | r = \paren {x + y} \paren {x - y} | c = }} {{eqn | ll= \leadsto | l = p | o = \divides | r = \paren {x + y} \paren {x - y} | c = for all [[Definition:Prime Factor|prime divisors]] $p$ of $n$ }} {{eqn | ll= \leadsto | l = p | o = \divides | r = \paren {x - y} | c = }} {{eqn | lo= \lor | l = p | o = \divides | r = \paren {x + y} | c = }} {{end-eqn}} But since $x \not \equiv -y \pmod n$, then: :$n \nmid \paren {x + y}$ and since $x \not \equiv y \pmod n$, then: :$n \nmid \paren {x - y}$ Therefore: :$\gcd \set {x - y, n} < n$ and: :$\gcd \set {x + y, n} < n$ So if $p \divides \paren {x - y}$ then: :$1 < \gcd \set {x - y, n} < n$ and also there exists $q$ such that: :$q \divides n$ :$q \divides \paren {x + y}$ :$1 < q \le \gcd \set {x + y, n}$ Likewise if $p \divides \paren {x + y}$ then: :$1 < \gcd \set {x + y, n} < n$ and also there exists $q$ such that: :$q \divides n$ :$q \divides \paren {x - y}$ :$1 < q \le \gcd \set {x - y, n}$ {{qed}} [[Category:Greatest Common Divisor]] 2ob6v1o7np6io1f9934hko48nro0o2v	0
By definition of [[Definition:Group|group]], both $\circ_1$ and $\circ_2$ are [[Definition:Associative|associative operations]]. The result follows from [[External Direct Product Associativity]], where the [[Definition:Algebraic Structure|algebraic structures]] in question are [[Definition:Group|groups]]. {{qed}}	0
{{begin-eqn}} {{eqn | l = \arcsec x | r = \map \arccos {\frac 1 x} | c = [[Arcsecant of Reciprocal equals Arccosine]] }} {{eqn | r = -i \map \Ln {i \sqrt {1 - \paren {\frac 1 x}^2} + \frac 1 x} | c = [[Arccosine Logarithmic Formulation]] }} {{eqn | r = -i \map \Ln {i \sqrt {1 - \frac 1 {x^2} } + \frac 1 x} }} {{end-eqn}} {{qed}}	0
Let $\mathbf A_1, \mathbf A_2, \cdots, \mathbf A_n$ be [[Definition:Square Matrix|square matrices]] of [[Definition:Order of Square Matrix|order $n$]], where $n > 1$. Then: :$\map \det {\mathbf A_1 \mathbf A_2 \cdots \mathbf A_n} = \map \det {\mathbf A_1} \map \det {\mathbf A_2} \cdots \map \det {\mathbf A_n}$	0
{{begin-eqn}} {{eqn | l = \map \Gamma 1 | r = 0 \, \map \Gamma 0 | c = [[Gamma Difference Equation]] }} {{eqn | ll= \leadsto | l = \map \Gamma 0 | r = \dfrac {\map \Gamma 1} 0 | c = }} {{eqn | ll= \leadsto | l = \map \Gamma 0 | r = \dfrac 1 0 | c = [[Gamma Function Extends Factorial]] }} {{end-eqn}} But $\dfrac 1 0$ is not defined. Hence the result. {{qed}}	0
:$\displaystyle \int \frac 1 {1 + x^4} \rd x = \frac 1 {2 \sqrt 2} \paren {\map \arctan {\frac 1 {\sqrt 2} \paren {x - \frac 1 x} } + \frac 1 2 \ln \size {\frac {x^2 + \sqrt 2 x + 1} {x^2 - \sqrt 2 x + 1} } } + C$	0
=== [[Prime-Generating Quadratics of form 2 a squared plus p/3|3]] === {{:Prime-Generating Quadratics of form 2 a squared plus p/3}} === [[Prime-Generating Quadratics of form 2 a squared plus p/5|5]] === {{:Prime-Generating Quadratics of form 2 a squared plus p/5}} === [[Prime-Generating Quadratics of form 2 a squared plus p/11|11]] === {{:Prime-Generating Quadratics of form 2 a squared plus p/11}} === [[Prime-Generating Quadratics of form 2 a squared plus p/29|29]] === {{:Prime-Generating Quadratics of form 2 a squared plus p/29}} When $x = p$ we have: {{begin-eqn}} {{eqn | l = 2 p^2 + p | r = p \left({2 p + 1}\right) | c = }} {{end-eqn}} which has [[Definition:Divisor of Integer|divisors]] $p$ and $2 p + 1$ and so is not [[Definition:Prime Number|prime]]. {{qed}}	0
Let $S$ be a [[Definition:Finite Set|finite set]]. Let $0 : S \to \mathbb A$ be the [[Definition:Zero Mapping|zero mapping]]. {{explain|Presumably the above is a [[Definition:Constant Mapping|constant mapping]] on $0$ -- needs to be made explicit.}} Then the [[Definition:Summation|summation]] of $0$ over $S$ equals [[Definition:Zero of Standard Number System|zero]]: :$\displaystyle \sum_{s \mathop \in S} 0 \left({s}\right) = 0$	0
An intuition is given as follows: Suppose for some $m, n \in \N$: :$7^m = c \cdot 10^n$, where $c$ is very close to $1$. Taking [[Definition:Common Logarithm|common logarithm]]: :$m \log 7 = \log c + n$ Which leads to: :$\log 7 = \dfrac n m + \dfrac {\log c} m$ where $\dfrac {\log c} m$ is very close to $0$. To make a good approximation is to minimize $\size {\log c}$. One may calculate the [[Definition:Continued Fraction|continued fraction]] of $\log 7$. We use [[Definition:Continued Fraction|continued fractions]] because [[Convergents are Best Approximations]]. One obtains $\sqbrk {0; 1, 5, 2, 5, 6, 1, 4813, 1, 1, 2, 2, \dots}$. {{OEIS|A082571}} Let $\dfrac {p_n} {q_n}$ be the [[Definition:Convergent of Continued Fraction|convergent]] $\sqbrk {0; a_1, \dots, a_n}$. Then: {{begin-eqn}} {{eqn | l = \size {\log c} | r = q_k \size {\log 7 - \frac {p_k} {q_k} } }} {{eqn | o = < | r = q_k \paren {\frac 1 {q_k q_{k + 1} } } | c = [[Accuracy of Convergents of Continued Fraction]] }} {{eqn | r = \frac 1 {q_{k + 1} } }} {{eqn | r = \frac 1 {a_{k + 1} q_k + q_{k - 1} } | c = [[Definition:Numerators and Denominators of Continued Fraction|Recursive Definition of Denominators of Convergents]] }} {{end-eqn}} Thus, at least intuitively, the larger the value of the next $a_i$, the smaller $\size {\log c}$ is. {{finish|I am not familiar with this, this is just some justification}} $4813$ is the largest number in the expansion among at least the first $100$ numbers. Note that $\sqbrk {0; 1, 5, 2, 5, 6, 1} = \dfrac {431} {510}$ This gives the estimate $7^{510} \approx 10^{431}$. {{qed}}	0
First note that when $\theta = 0, \pm \pi, \pm 2 \pi \ldots$: :$\sin \theta = 0$ so $\dfrac {\sin 5 \theta} {\sin \theta}$ is undefined. Therefore for the rest of the proof it is assumed that $\theta \ne 0, \pm \pi, \pm 2 \pi \ldots$ {{begin-eqn}} {{eqn | l = \sin 5 \theta | r = 5 \sin \theta - 20 \sin^3 \theta + 16 \sin^5 \theta | c = [[Quintuple Angle Formula for Sine]] }} {{eqn | ll= \leadsto | l = \dfrac {\sin 5 \theta} {\sin \theta} | r = 5 - 20 \paren {1 - \cos^2 \theta} + 16 \paren {1 - \cos^2 \theta}^2 | c = [[Sum of Squares of Sine and Cosine]] }} {{eqn | r = 16 \cos^4 \theta - 12 \cos^2 \theta + 1 | c = multiplying out and gathering terms }} {{end-eqn}} {{qed}}	0
By definition of [[Definition:Central Subgroup|central subgroup]]: :$Z \subseteq \map Z G$ where $\map Z G$ denotes the [[Definition:Center of Group|center]] of $G$. From [[Image under Epimorphism of Center is Subset of Center]]: :$\theta \sqbrk {\map Z G} \subseteq \map Z H$ From [[Image of Subset under Mapping is Subset of Image]] it follows that: :$\theta \sqbrk Z \subseteq \map Z H$ The result follows. {{qed}} [[Category:Central Subgroups]] [[Category:Group Epimorphisms]] 9fdj8xamuhphxaj2xl5xszjyb657b1r	0
The case where $n = 0$ is clear: :$\order {\set e} = 1$ and $e^2 = e$. {{AimForCont}} $\order G = m \times 2^k$ for some [[Definition:Odd Integer|odd integer]] $m$. Then $m$ itself has an [[Definition:Odd Prime|odd prime]] $p$ as a [[Definition:Divisor of Integer|integer]] (which may of course equal $m$ if $m$ is itself [[Definition:Odd Prime|prime]]). Then by [[Cauchy's Lemma (Group Theory)]] there exists $g \in G$ such that $\order g = p$. Hence it is not the case that $g^2 = e$. Hence $\order G$ has no [[Definition:Prime Factor|prime factor]] which is [[Definition:Odd Integer|odd]]. The result follows. {{qed}}	0
Follows directly from the [[Definition:Rational Number|definition of rational numbers]] as the [[Definition:Field of Quotients|field of quotients]] of the [[Definition:Integral Domain|integral domain]] $\struct {\Z, +, \times}$ of [[Definition:Integer|integers]]. So $\struct {\Q, +, \times}$ is a [[Definition:Field (Abstract Algebra)|field]], and therefore [[Definition:A Priori|a priori]] $\times$ is [[Definition:Associative|associative]] on $\Q$. {{qed}}	0
Let $X$ be a [[Definition:Set|set]], and $\left({Y, \Sigma}\right)$ be a [[Definition:Measurable Space|measurable space]]. Let $f: X \to Y$ be a [[Definition:Mapping|mapping]].	0
[[Proof by Counterexample]]: We have that: :$2 + 0 i \in \Z \sqbrk i$ However there is no $z \in \Z \sqbrk i$ such that: :$x \paren {2 + 0 i} = 1 + 0 i$ So, by definition, $\Z \sqbrk i$ is not a [[Definition:Field (Abstract Algebra)|field]]. Thus $\Z \sqbrk i$ is not a [[Definition:Subfield|subfield]] of $\C$. {{qed}}	0
Let $f$ be a [[Definition:Real Function|real function]]. Let $I \subseteq \R$ be an [[Definition:Real Interval|interval of $\R$]]. Then $f$ is [[Definition:Concave Real Function|concave on $I$]] {{iff}} $-f$ is [[Definition:Convex Real Function|convex]] on $\R$.	0
Let $T = \struct {S, \tau_p}$ be a [[Definition:Particular Point Topology|particular point space]]. Let $V \subseteq S$ be [[Definition:Closed Set (Topology)|closed]] in $T$ such that $V \ne S$. Then: :$V^\circ = \O$ where $V^\circ$ denotes the [[Definition:Interior (Topology)|interior]] of $V$.	0
Let $G = \struct {V, A}$ be a [[Definition:Directed Graph|directed graph]]. Let $r \in V$. {{TFAE|def = Arborescence}}	0
{{begin-eqn}} {{eqn | l = y \in C' | o = \leadstoandfrom | r = x \text{ is path-connected to } y \text{ in } T | c = Definition of $\sim$ }} {{eqn | o = \leadstoandfrom | r = \exists B \text{ a connected set of } T, x \in B, y \in B | c = [[Points are Path-Connected iff Contained in Path-Connected Set]] }} {{eqn | o = \leadstoandfrom | r = \exists B \in \CC_x : y \in B | c = Equivalent definition }} {{eqn | o = \leadstoandfrom | r = y \in \bigcup \CC_x | c = {{Defof|Set Union|subdef = General Definition}} }} {{eqn | o = \leadstoandfrom | r = y \in C | c = Definition of $C$ }} {{end-eqn}} The result follows.	0
Let $\left({X, \Sigma}\right)$ be a [[Definition:Measurable Space|measurable space]]. Let $f: X \to \overline{\R}$ be a [[Definition:Measurable Function|$\Sigma$-measurable function]]. Then there exists a [[Definition:Sequence|sequence]] $\left({f_n}\right)_{n \in \N} \in \mathcal E \left({\Sigma}\right)$ of [[Definition:Simple Function|simple functions]], such that: :$\forall x \in X: f \left({x}\right) = \displaystyle \lim_{n \to \infty} f_n \left({x}\right)$ That is, such that $f = \displaystyle \lim_{n \to \infty} f_n$ [[Definition:Pointwise Limit|pointwise]]. The [[Definition:Sequence|sequence]] $\left({f_n}\right)_{n \in \N}$ may furthermore be taken to satisfy: :$\forall n \in \N: \left\vert{f_n}\right\vert \le \left\vert{f}\right\vert$ where $\left\vert{f}\right\vert$ denotes the [[Definition:Absolute Value of Extended Real-Valued Function|absolute value of $f$]].	0
Let $g: \Z \to \R$ be the [[Definition:Mapping|mapping]] defined as: :$(1): \quad \map g n = \map H {\dfrac 1 n, \dfrac 1 n, \dotsc, \dfrac 1 n}$ Let $k \in \Z_{>0}$. We have: {{begin-eqn}} {{eqn | l = \map g {n^k} | r = \map g {n \times n^{k - 1} } | c = }} {{eqn | r = \map g n + \map g {n^{k - 1} } | c = [[Axiom:Axioms of Uncertainty/Axiom 7|Axiom 7]] }} {{eqn | r = \map g n + \map g n + \map g {n^{k - 2} } | c = [[Axiom:Axioms of Uncertainty/Axiom 7|Axiom 7]] again }} {{eqn | r = \underbrace {\map g n + \map g n + \dotsb + \map g n}_{\text {$k - 1$ times} } + \map g {n^{k - \paren {k - 1} } } | c = after $k - 1$ applications of [[Axiom:Axioms of Uncertainty/Axiom 7|Axiom 7]] }} {{eqn | r = \underbrace {\map g n + \map g n + \dotsb + \map g n}_{\text {$k - 1$ times} } + \map g n | c = }} {{eqn | n = 2 | r = k \map g n | c = }} {{end-eqn}} Let $r, s \in \R$ and $n \in \Z_{>0}$. Let $m$ satisfy: :$(3): \quad r^m \le s^n \le r^{m + 1}$ From $(2)$ and [[Axiom:Axioms of Uncertainty/Axiom 5|Axiom 5]]: :$\map g {r^m} \le \map g {s^n} \le \map g {r^{m + 1} }$ and so: :$m \map g r \le n \map g s \le \paren {m + 1} \map g r$ Taking [[Definition:Natural Logarithm|logarithms]] of $(3)$: :$m \ln r \le n \ln s \le \paren {m + 1} \ln r$ which holds because [[Logarithm is Strictly Increasing]]. Hence: :$\size {\dfrac {\map g s} {\map g r} - \dfrac {\map \ln s} {\map \ln r} } \le \dfrac 1 n$ We have that $n$ is an arbitrary [[Definition:Positive Integer|positive integer]]. Hence the {{RHS}} of the above can be made arbitrarily small. Hence: :$\size {\dfrac {\map g s} {\map g r} - \dfrac {\map \ln s} {\map \ln r} } = 0$ and so: :$(4): \quad \dfrac {\map g s} {\map \ln s} = \dfrac {\map g r} {\map \ln r} = A$ for some [[Definition:Constant|constant]] $A$. That is: :$(5): \quad \map g s = A \map \ln s$ for $s \in \Z$. Let $p$ be a [[Definition:Rational Number|rational number]] such that $0 < p < 1$. That is: :$p = \dfrac t n$ for some [[Definition:Integer|integers]] $t$ and $n$. Thus we can set: :$q = 1 = p = \dfrac {n - t} n$ [[Axiom:Axioms of Uncertainty/Axiom 8|Axiom 8]] gives: :$\map g n = \map H {\dfrac 1 n, \dfrac 1 n, \dotsc, \dfrac 1 n} = \map H {\dfrac 1 n, \dfrac {n - t} n} + \dfrac t n \map g t + \dfrac {n - t} n \map g {n - t}$ Using $(5)$ and gathering up terms: :$\map H {\dfrac 1 n, \dfrac {n - t} n} = A \paren {\dfrac t n} \ln \dfrac t n + A \paren {\dfrac {n - t} n} \ln \dfrac {n - t} n$ which gives: :$(6): \quad \map H {p, 1 - p} = A p \ln p + A \paren {1 - p} \, \map \ln {1 - p}$ for [[Definition:Rational Number|rational]] $p$. [[Axiom:Axioms of Uncertainty/Axiom 6|Axiom 6]] gives that $H$ is [[Definition:Continuous Real-Valued Function|continuous]]. Thus $(6)$ extends to all [[Definition:Real Number|real]] $p$ such that $0 < p < 1$. It remains to be demonstrated that: :$(7): \quad \map H {p_1, p_2, \ldots, p_N} = A \displaystyle \sum_{i \mathop = 1}^N p_i \ln p_i$ where: :$0 < p_i < 1$ for all $p_i$ :$p_1 + p_2 + \dotsb + p_N$ for all $N \in \Z_{\ge 2}$. We have demonstrated that $(7)$ is true for $N = 2$. Assume the [[Definition:Induction Hypothesis|induction hypothesis]] that $(7)$ holds for $N = k$. Consider: :$\map H {p_1, p_2, \ldots, p_k, p_{k + 1} }$ Let: :$p = p_1 + p_2 + \dotsb + p_k$ :$q = p_{k + 1}$ and apply [[Axiom:Axioms of Uncertainty/Axiom 8|Axiom 8]]: {{begin-eqn}} {{eqn | l = \map H {p_1, p_2, \ldots, p_k, p_{k + 1} } | r = \map H {p, q} + p \map H {\dfrac {p_1} p, \dfrac {p_2} p, \dotsc, \dfrac {p_k} p} + q \map H 1 | c = }} {{eqn | r = A p \ln p + A q \ln q + p A \sum_{i \mathop = 1}^k \dfrac {p_i} p \ln \dfrac {p_i} p | c = from the [[Definition:Induction Hypothesis|induction hypothesis]] }} {{eqn | r = A p \ln p + A p_{k + 1} \ln p_{k + 1} + A \sum_{i \mathop = 1}^k p_i \paren {\ln p_i - \ln p} | c = [[Difference of Logarithms]] }} {{eqn | r = A p \ln p + A p_{k + 1} \ln p_{k + 1} + A \sum_{i \mathop = 1}^k p_i \ln p_i - A p \ln p | c = as $A \displaystyle \sum_{i \mathop = 1}^k p_i = p$ }} {{eqn | ll= \leadsto | l = \map H {p_1, p_2, \ldots, p_k, p_{k + 1} } | r = A \sum_{i \mathop = 1}^{k + 1} p_i \ln p_i | c = }} {{end-eqn}} Hence the result from the [[Principle of Mathematical Induction]]. {{qed}}	0
Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \N_{> 0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\displaystyle \sum_{k \mathop = 0}^{n - 1} \paren {a + k d} r^k = \frac {a \paren {1 - r^n} } {1 - r} + \frac {r d \paren {1 - n r^{n - 1} + \paren {n - 1} r^n} } {\paren {1 - r}^2}$ === Basis for the Induction === $\map P 1$ is the case: {{begin-eqn}} {{eqn | l = \sum_{k \mathop = 0}^{1 - 1} \paren {a + k d} r^k | r = \frac {a \paren {1 - r^1} } {1 - r} + \frac {r d \paren {1 - 1 r^{1 - 1} + \paren {1 - 1} r^1} } {\paren {1 - r}^2} | c = }} {{eqn | r = a + \frac {r d \paren {1 - 1 + \paren {1 - 1} } } {\paren {1 - r}^2} | c = }} {{eqn | r = a | c = }} {{end-eqn}} demonstrating that $\map P 1$ holds. This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P m$ is true, where $m \ge 1$, then it logically follows that $\map P {m + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\displaystyle \sum_{k \mathop = 0}^{m - 1} \paren {a + k d} r^k = \frac {a \paren {1 - r^m} } {1 - r} + \frac {r d \paren {1 - m r^{m - 1} + \paren {m - 1} r^m} } {\paren {1 - r}^2}$ Then we need to show: :$\displaystyle \sum_{k \mathop = 0}^m \paren {a + k d} r^k = \frac {a \paren {1 - r^{m + 1} } } {1 - r} + \frac {r d \paren {1 - \paren {m + 1} r^m + m r^{m + 1} } } {\paren {1 - r}^2}$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \sum_{k \mathop = 0}^m \paren {a + k d} r^k | r = \sum_{k \mathop = 0}^{m - 1} \paren {a + k d} r^k + \paren {a + m d} r^m | c = }} {{eqn | r = \frac {a \paren {1 - r^m} } {1 - r} + \frac {r d \paren {1 - m r^{m - 1} + \paren {m - 1} r^m} } {\paren {1 - r}^2} + \paren {a + m d} r^m | c = [[Sum of Arithmetic-Geometric Sequence#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \frac {a \paren {1 - r^m} } {1 - r} + \frac {r d \paren {1 - m r^{m - 1} + \paren {m - 1} r^m} } {\paren {1 - r}^2} | c = }} {{eqn | o = | ro= + | r = \frac {a r^m \paren {1 - r} } {1 - r} + \frac {m d r^m \paren {1 - r}^2} {\paren {1 - r}^2} | c = common [[Definition:Denominator|denominator]] (2 instances) }} {{eqn | r = \frac {a \paren {1 - r^m + r^m \paren {1 - r} } } {1 - r} | c = }} {{eqn | o = | ro= + | r = \frac {r d \paren {1 - m r^{m - 1} + \paren {m - 1} r^m} + r d \paren {m r^{m - 1} \paren {1 - r}^2} } {\paren {1 - r}^2} | c = simplifying }} {{eqn | r = \frac {a \paren {1 - r^m + r^m - r^{m + 1} } } {1 - r} | c = }} {{eqn | o = | ro= + | r = \frac {r d \paren {1 - m r^{m - 1} + m r^m - r^m + m r^{m - 1} - 2 m r^m + m r^{m + 1} } } {\paren {1 - r}^2} | c = multiplying out }} {{eqn | r = \frac {a \paren {1 - r^{m + 1} } } {1 - r} + \frac {r d \paren {1 - m r^m - r^m + m r^{m + 1} } } {\paren {1 - r}^2} | c = cancelling out terms }} {{eqn | r = \frac {a \paren {1 - r^{m + 1} } } {1 - r} + \frac {r d \paren {1 - \paren {m + 1} r^m + m r^{m + 1} } } {\paren {1 - r}^2} | c = simplification }} {{end-eqn}} So $\map P m \implies \map P {m + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\displaystyle \forall n \in \N_{> 0}: \sum_{k \mathop = 0}^{n - 1} \paren {a + k d} r^k = \frac {a \paren {1 - r^n} } {1 - r} + \frac {r d \paren {1 - n r^{n - 1} + \paren {n - 1} r^n} } {\paren {1 - r}^2}$ {{qed}}	0
Let $\ln x$ be the [[Definition:Natural Logarithm|natural logarithm function]]. Then: :$\map {\dfrac \d {\d x} } {\ln x} = \dfrac 1 x$	0
=== Necessary Condition === Let $\left \lceil{x}\right \rceil \le n$. By [[Number is between Ceiling and One Less]]: :$x \le \left \lceil{x}\right \rceil$ Hence: :$x \le n$ {{qed|lemma}} === Sufficient Condition === Let $x \le n$. {{AimForCont}} $\left \lceil{x}\right \rceil > n$. We have that: :$\forall m, n \in \Z: m < n \iff m \le n - 1$ Hence: :$\left \lceil{x}\right \rceil - 1 \ge n$ and so [[Definition:By Hypothesis|by hypothesis]]: :$\left \lceil{x}\right \rceil - 1 \ge x$ This [[Definition:Contradiction|contradicts]] the result [[Number is between Ceiling and One Less]]: :$\left \lceil{x}\right \rceil - 1 < x$ Thus by [[Proof by Contradiction]]: :$\left \lceil{x}\right \rceil \le n$ {{qed|lemma}} Hence the result: :$\left \lceil{x}\right \rceil \le n \iff x \le n$ {{qed}}	0
Let $p$ be a [[Definition:Prime Number|prime number]]. Then: :$2 \le k \le p - 1 \implies \dbinom {p + 1} k \equiv 0 \pmod p$ where $\dbinom {p + 1} k$ denotes a [[Definition:Binomial Coefficient|binomial coefficient]].	0
By definition of [[Definition:Binomial Coefficient|binomial coefficient]]: {{begin-eqn}} {{eqn | l = \dbinom {2 n} n | r = \dfrac {\paren {2 n}!} {\paren {n!}^2} | c = where $n!$ denotes the [[Definition:Factorial|factorial]] of $n$ }} {{eqn | ll= \leadsto | l = \dbinom {2 n} n \paren {n!}^2 | r = \paren {2 n}! | c = }} {{end-eqn}} Let $\mathbb P$ denote the [[Definition:Set|set]] of [[Definition:Prime Number|prime numbers]]. Let $p \in \mathbb P$ such that $n < p < 2 n$. By definition of [[Definition:Factorial|factorial]]: :$p \divides \paren {2 n}!$ That is: :$p \divides \dbinom {2 n} n \paren {n!}^2$ From [[Prime iff Coprime to all Smaller Positive Integers]]: :$p \nmid n!$ where $\nmid$ denotes non-[[Definition:Divisor of Integer|divisibility]]. and so: :$p \nmid \paren {n!}^2$ But from [[Euclid's Lemma for Prime Divisors]], $p$ is a [[Definition:Divisor of Integer|divisor]] of either $\dbinom {2 n} n$ or $\paren {n!}^2$. Hence it must be the case that: :$p \divides \dbinom {2 n} n$ {{qed}}	0
Each of the [[Definition:Row of Pascal's Triangle|rows]] of [[Definition:Pascal's Triangle|Pascal's triangle]] forms a [[Definition:Palindrome|palindromic]] [[Definition:Sequence|sequence]].	0
We know that $\bot$ is the [[Definition:Identity Element|identity]] for $\vee$. Therefore, from the condition that: :$\bot \vee a = \top$ for a [[Definition:Complement (Lattice Theory)|complement]] $a$ of $\bot$, it follows that $a = \top$ is the only possibility. Since also: :$\bot \wedge \top = \bot$ as $\top$ is the [[Definition:Identity Element|identity]] for $\wedge$, the result follows. {{qed}}	0
{{explain|generally, why the following purports to be a proof. Suggest the specific basis axioms are invoked.}} $U$ is non-empty by the [[Ultrafilter Lemma]]. The topology of the Stone space is defined as the topology generated by the [[Definition:Basis (Topology)|basis]] $Q$ consisting of all sets of the form :$\set {x \in U: b \in x}$ for some $b \in B$. We must show that $Q$ is in fact a [[Definition:Synthetic Basis|basis]]. $Q$ is trivially a subset of the power set of $U$. Suppose that $x \in U$. Then by the definition of ultrafilter, $x \ne \O$. Thus $x$ has some element $b$. Then $x \in \set {x \in U: b \in x} \in Q$. So $Q$ covers $U$. Let $P, Q \in Q$. Then for some $b, c \in B$, :$P = \set {x \in U: b \in x}$ and :$Q = \set {y \in U: c \in y}$. Let $z \in P \cap Q$. Then by the definitions of $P$ and $Q$, :$b \in z$ and $c \in z$. So $z$ is an ultrafilter on $B$ containing $b$ and $c$. Since $z$ is a filter containing $b$ and $c$, it also contains $b \wedge c$. Let $R = \set {w \in U: b \wedge c \in w}$. $R$ is clearly an element of $Q$ containing $z$. Suppose that $v \in R$. Then $b \wedge c \in v$. Since $v$ is a filter, $b \in v$ and $c \in v$. Thus $v \in P \cap Q$. Since this holds for each $v \in R$, $R \subseteq P \cap Q$ {{qed}} [[Category:Stone Spaces]] h9iz9f3u9277lm6yi1nmkt1wtydxlaq	0
The [[Definition:Set|set]] of [[Definition:Complex Number|complex numbers]] under [[Definition:Complex Multiplication|multiplication]] $\struct {\C, \times}$ forms a [[Definition:Monoid|monoid]].	0
Let $P_1$ and $P_2$ be [[Definition:Compact Topological Space|compactness properties]] and let: :$P_1 \implies P_2$ mean: :If a [[Definition:Metric Space|metric space]] $M$ satsifies property $P_1$, then $M$ also satisfies property $P_2$. Then the following sequence of implications holds: {| |- | align="center" | [[Definition:Sequentially Compact Space|Sequentially Compact]] || | align="center" | $\implies$ || | align="center" | [[Definition:Weakly Sigma-Locally Compact Space|Weakly $\sigma$-Locally Compact]] || | align="center" | $\implies$ || | align="center" | [[Definition:Weakly Locally Compact Space|Weakly Locally Compact]] || |- | align="center" | $\Big\Updownarrow$ || | align="center" | || | align="center" | $\Big\Downarrow$ || | align="center" | || | align="center" | $\Big\Updownarrow$ || |- | align="center" | [[Definition:Countably Compact Space|Countably Compact]] || | align="center" | || | align="center" | [[Definition:Sigma-Compact Space|$\sigma$-Compact]] || | align="center" | || | align="center" | [[Definition:Strongly Locally Compact Space|Strongly Locally Compact]] || |- | align="center" | $\Big\Updownarrow$ || | align="center" | || | align="center" | $\Big\Downarrow$ || |- | align="center" | [[Definition:Compact Topological Space|Compact]] || | align="center" | || | align="center" | [[Definition:Separable Space|Separable]] || |- | align="center" | $\Big\Updownarrow$ || | align="center" | || | align="center" | $\Big\Updownarrow$ || |- | align="center" | [[Definition:Weakly Countably Compact Space|Weakly Countably Compact]] || | align="center" | || | align="center" | [[Definition:Lindelöf Space|Lindelöf]] || |- | align="center" | || | align="center" | || | align="center" | $\Big\Updownarrow$ || |- | align="center" | || | align="center" | || | align="center" | [[Definition:Second-Countable Space|Second-Countable]] || |}	0
Let $\sequence {x_n}$ be a [[Definition:Real Sequence|sequence in $\R$]]. Let $\sequence {x_n}$ be [[Definition:Convergent Real Sequence|convergent]] to the [[Definition:Limit of Real Sequence|limit]] $l$. That is, let $\displaystyle \lim_{n \mathop \to \infty} x_n = l$. Suppose $l > 0$. Then: : $\exists N: \forall n > N: x_n > \dfrac l 2$ Similarly, suppose $l < 0$. Then: : $\exists N: \forall n > N: x_n < \dfrac l 2$	0
:$\displaystyle \int \cot x \rd x = \ln \size {\sin x} + C$ where $\sin x \ne 0$.	0
{{begin-eqn}} {{eqn | l = \dfrac 1 a \map {\coth^{-1} } {\frac x a} | r = \dfrac 1 a \cdot \dfrac 1 2 \map \ln {\dfrac {\frac x a + 1} {\frac x a - 1} } | c = {{Defof|Inverse Hyperbolic Cotangent|subdef = Real|index = 2}} }} {{eqn | r = \dfrac 1 {2 a} \map \ln {\dfrac {x + a} {x - a} } | c = multiplying [[Definition:Numerator|top]] and [[Definition:Denominator|bottom]] of argument by $a$ }} {{eqn | ll= \leadsto | l = \map {\dfrac \d {\d x} } {\dfrac 1 {2 a} \map \ln {\dfrac {x + a} {x - a} } } | r = \map {\dfrac \d {\d x} } {\dfrac 1 a \map {\coth^{-1} } {\frac x a} } | c = }} {{eqn | r = \dfrac 1 a \cdot \dfrac {-a} {x^2 - a^2} | c = [[Derivative of Inverse Hyperbolic Cotangent of x over a]] }} {{eqn | r = \dfrac 1 {a^2 - x^2} | c = simplifying }} {{end-eqn}} {{qed}}	0
Let $P = \sequence {a_j}_{0 \mathop \le j \mathop \le n}$ be a [[Definition:Geometric Sequence of Integers|geometric sequence of integers]] of [[Definition:Length of Sequence|length]] $n$. Let $r$ be the [[Definition:Common Ratio|common ratio]] of $P$. Let $Q = \sequence {b_j}_{0 \mathop \le j \mathop \le m}$ be a [[Definition:Geometric Sequence of Integers|geometric sequence of integers]] of [[Definition:Length of Sequence|length]] $m$. Let $r$ be the [[Definition:Common Ratio|common ratio]] of $Q$. Let $b_0$ and $b_m$ be such that $\dfrac {b_0} {b_m} = \dfrac {a_0} {a_n}$. Then $m = n$. {{:Euclid:Proposition/VIII/8}}	0
The [[Definition:Inverse Cotangent|arccotangent function]] has a [[Definition:Taylor Series|Taylor series expansion]]: :$\operatorname {arccot} x = \begin{cases} \displaystyle \frac \pi 2 - \sum_{n \mathop = 0}^\infty \left({-1}\right)^n \frac {x^{2 n + 1} } {2 n + 1} & : -1 \le x \le 1 \\ \displaystyle \sum_{n \mathop = 0}^\infty \left({-1}\right)^n \frac 1 {\left({2 n + 1}\right) x^{2 n + 1} } & : x \ge 1 \\ \displaystyle \pi + \sum_{n \mathop = 0}^\infty \left({-1}\right)^n \frac 1 {\left({2 n + 1}\right) x^{2 n + 1} } & : x \le -1 \end{cases}$ That is: :$\operatorname {arccot} x = \begin{cases} \displaystyle \frac \pi 2 - \left({x - \frac {x^3} 3 + \frac {x^5} 5 - \frac {x^7} 7 + \cdots}\right) & : -1 \le x \le 1 \\ \displaystyle \frac 1 x - \frac 1 {3 x^3} + \frac 1 {5 x^5} - \cdots & : x \ge 1 \\ \displaystyle \pi + \frac 1 x - \frac 1 {3 x^3} + \frac 1 {5 x^5} - \cdots & : x \le -1 \end{cases}$	0
From [[Semigroup is Subsemigroup of Itself]], $\left({S, \circ}\right)$ is a [[Definition:Subsemigroup|subsemigroup]] of $\left({S, \circ}\right)$. Also from [[Semigroup is Subsemigroup of Itself]], $\left({C, \circ {\restriction_C}}\right)$ is a [[Definition:Subsemigroup|subsemigroup]] of $\left({C, \circ {\restriction_C}}\right)$. The result follows from [[Cross-Relation is Equivalence Relation]]. {{qed}}	0
From [[Projection is Surjection]], $\operatorname{pr}_j$ is a [[Definition:Surjection|surjection]] for all $j$. We now need to show it is a [[Definition:Homomorphism (Abstract Algebra)|homomorphism]]. Let $s, t \in \left({S, \circ}\right)$ where $s = \left({s_1, s_2, \ldots, s_j, \ldots, s_n}\right)$ and $t = \left({t_1, t_2, \ldots, t_j, \ldots, t_n}\right)$. Then: {{begin-eqn}} {{eqn | l = \operatorname{pr}_j \left({s \circ t}\right) | r = \operatorname{pr}_j \left({\left({s_1, s_2, \ldots, s_j, \ldots, s_n}\right) \circ \left({t_1, t_2, \ldots, t_j, \ldots, t_n}\right)}\right) | c = }} {{eqn | r = \operatorname{pr}_j \left({\left({s_1 \circ_1 t_1, s_2 \circ_2 t_2, \ldots, s_j \circ_j t_j, \ldots, s_n \circ_n t_n}\right) }\right) | c = }} {{eqn | r = s_j \circ_j t_j | c = }} {{eqn | r = \operatorname{pr}_j \left({s}\right) \circ_j \operatorname{pr}_j \left({t}\right) | c = }} {{end-eqn}} ... and thus the [[Definition:Morphism Property|morphism property]] is demonstrated. {{Qed}}	0
Let $V$ be a vector space with norm $\norm {\, \cdot \,}$. The function $\norm {\, \cdot \,}: V \to \R$ is continuous.	0
With a view to expressing the [[Definition:Primitive|primitive]] in the form: :$\ds \int u \frac {\d v} {\d x} \rd x = u v - \int v \frac {\d u} {\d x} \rd x$ let: {{begin-eqn}} {{eqn | l = u | r = x | c = }} {{eqn | ll= \leadsto | l = \frac {\d u} {\d x} | r = 1 | c = [[Derivative of Identity Function]] }} {{end-eqn}} and let: {{begin-eqn}} {{eqn | l = \frac {\d v} {\d x} | r = \frac 1 {1 - \sin a x} | c = }} {{eqn | ll= \leadsto | l = v | r = \frac 1 a \map \tan {\frac \pi 4 + \frac {a x} 2} | c = [[Primitive of Reciprocal of 1 minus Sine of a x]] }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = \int \frac {x \rd x} {1 - \sin a x} | r = x \paren {\frac 1 a \map \tan {\frac \pi 4 + \frac {a x} 2} } - \int \paren {\frac 1 a \map \tan {\frac \pi 4 + \frac {a x} 2} } \times 1 \rd x + C | c = [[Integration by Parts]] }} {{eqn | r = \frac x a \map \tan {\frac \pi 4 + \frac {a x} 2} - \frac 1 a \int \map \tan {\frac \pi 4 + \frac {a x} 2} \rd x + C | c = simplifying }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = z | r = \frac \pi 4 + \frac {a x} 2 }} {{eqn | l = \frac {\d z} {\d x} | r = \frac a 2 | c = [[Derivative of Power]] }} {{eqn | ll= \implies | l = \frac 1 a \int \map \tan {\frac \pi 4 + \frac {a x} 2} \rd x | r = \frac 1 a \int \frac 2 a \tan z \rd z | c = [[Integration by Substitution]] }} {{eqn | r = -\frac 2 {a^2} \ln \size {\cos z} + C | c = [[Primitive of Tangent Function/Cosine Form|Primitive of $\tan z$: Cosine Form]] }} {{eqn | r = -\frac 2 {a^2} \ln \size {\map \cos {\frac \pi 4 + \frac {a x} 2} } + C | c = substituting back for $z$ }} {{eqn | r = -\frac 2 {a^2} \ln \size {\map \sin {\frac \pi 2 - \paren {\frac \pi 4 + \frac {a x} 2} } } + C | c = [[Sine of Complement equals Cosine]] }} {{eqn | r = -\frac 2 {a^2} \ln \size {\map \sin {\frac \pi 4 - \frac {a x} 2} } + C | c = }} {{end-eqn}} Putting it all together: :$\ds \int \frac {x \rd x} {1 - \sin a x} = \frac x a \map \tan {\frac \pi 4 + \frac {a x} 2} + \frac 2 {a^2} \ln \size {\map \sin {\frac \pi 4 - \frac {a x} 2} } + C$ {{qed}}	0
Checking in turn each of the critera for [[Definition:Equivalence Relation|equivalence]]: === Reflexive === We have that [[Equal Numbers are Congruent]]: :$\forall x, y, z \in \Z: x = y \implies x \equiv y \pmod z$ so it follows that: :$\forall x \in \Z: x \equiv x \pmod z$ and so [[Definition:Congruence Modulo Integer|congruence modulo $z$]] is [[Definition:Reflexive Relation|reflexive]]. {{qed|lemma}} === Symmetric === {{begin-eqn}} {{eqn | l = x | o = \equiv | r = y \bmod z | c = }} {{eqn | ll= \leadsto | l = x - y | r = k z | c = }} {{eqn | ll= \leadsto | l = y - x | r = \paren {-k} z | c = }} {{eqn | l = y | o = \equiv | r = x \bmod z | c = }} {{end-eqn}} So [[Definition:Congruence Modulo Integer|congruence modulo $z$]] is [[Definition:Symmetric Relation|symmetric]]. {{qed|lemma}} === Transitive === {{begin-eqn}} {{eqn | l = x_1 | o = \equiv | r = x_2 \pmod z | c = }} {{eqn | lo= \land | l = x_2 | o = \equiv | r = x_3 \pmod z | c = }} {{eqn | ll= \leadsto | l = \paren {x_1 - x_2} | r = k_1 z | c = }} {{eqn | lo= \land | l = \paren {x_2 - x_3} | r = k_2 z | c = }} {{eqn | ll= \leadsto | l = \paren {x_1 - x_2} + \paren {x_2 - x_3} | r = \paren {k_1 + k_2} z | c = }} {{eqn | ll= \leadsto | l = \paren {x_1 - x_3} | r = \paren {k_1 + k_2} z | c = }} {{eqn | l = x_1 | o = \equiv | r = x_3 \pmod z | c = }} {{end-eqn}} So [[Definition:Congruence Modulo Integer|congruence modulo $z$]] is [[Definition:Transitive Relation|transitive]]. {{qed|lemma}} So we are justified in supposing that [[Definition:Congruence Modulo Integer|congruence]], as we have defined it, is an [[Definition:Equivalence Relation|equivalence]]. {{qed}}	0
:$\displaystyle \int \map F {a x + b} \rd x = \frac 1 a \int \map F u \rd u$ where $u = a x + b$.	0
Let $f, g, h: S \to \R$ be [[Definition:Real-Valued Function|real-valued functions]]. Let $f + g: S \to \R$ denote the [[Definition:Pointwise Addition of Real-Valued Functions|pointwise sum of $f$ and $g$]]. Then: :$\paren {f + g} + h = f + \paren {g + h}$	0
Let $A$ and $B$ be [[Definition:Separated Sets|separated sets]] of $T$. Let $A^*$ and $B^*$ be defined as: :$A^* := \displaystyle \bigcup \set {\closedint a b: a, b \in A, \closedint a b \cap B^- = \O}$ :$B^* := \displaystyle \bigcup \set {\closedint a b: a, b \in B, \closedint a b \cap A^- = \O}$ where $A^-$ and $B^-$ denote the [[Definition:Closure (Topology)|closure]] of $A$ and $B$ in $T$. Let $A^*$, $B^*$ and $\complement_S \left({A^* \cup B^*}\right)$ be expressed as the [[Definition:Set Union|union]] of [[Definition:Convex Component|convex components]] of $S$: :$\displaystyle A^* = \bigcup A_\alpha, \quad B^* = \bigcup B_\beta, \quad \relcomp S {A^* \cup B^*} = \bigcup C_\gamma$ where $\relcomp S X$ denotes the [[Definition:Relative Complement|complement of $X$ with respect to $S$]]. Let $M$ be the [[Definition:Linearly Ordered Set|linearly ordered set]]: :$M = \set {A_\alpha, B_\beta, C_\gamma}$ as defined in [[Partition of Linearly Ordered Space by Convex Components is Linearly Ordered Set]]. Let: :$S_\alpha$ be the [[Definition:Set|set]] of [[Definition:Strict Upper Bound|strict upper bounds]] for $A_\alpha$. :$S_\beta$ be the [[Definition:Set|set]] of [[Definition:Strict Upper Bound|strict upper bounds]] for $B_\beta$. From [[Successor Sets of Linearly Ordered Set Induced by Convex Component Partition]]: :each of the [[Definition:Set|sets]] $A_\alpha \in M$ has an [[Definition:Immediate Successor Element|immediate successor]] in $M$ if $A_\alpha$ [[Definition:Set Intersection|intersects]] the [[Definition:Closure (Topology)|closure]] of $S_\alpha$ :each of the [[Definition:Set|sets]] $B_\beta \in M$ has an [[Definition:Immediate Successor Element|immediate successor]] in $M$ if $B_\beta$ [[Definition:Set Intersection|intersects]] the [[Definition:Closure (Topology)|closure]] of $S_\beta$ :that [[Definition:Immediate Successor Element|immediate successor]] ${C_\alpha}^+$ to $A_\alpha$ is an [[Definition:Element|element]] in $\set {C_\gamma}$. For each $\gamma$, let $k_\gamma \in C_\gamma$ be selected and fixed. {{explain|We probably need AoC for this.}} Let $A_\alpha \cap {S_\alpha}^- \ne \O$. Then there exists a unique ${k_\alpha}^+ \in {C_\alpha}^+$. In such cases, let $I_\alpha = \hointr p { {k_\alpha}^+}$ where $p \in A \cap {S_\alpha}^-$. The other case is when $A_\alpha \cap {S_\alpha}^- = \O$. In this case, let $I_\alpha = \O$. Let $J_\alpha$ be defined similarly for the [[Definition:Strict Lower Bound|strict lower bounds]] of $A_\alpha$, using the same [[Definition:Set|set]] of points $k_\gamma \in C_\gamma$. Then: :For each $\alpha$, let $U_\alpha = J_\alpha \cup A_\alpha \cup I_\alpha$. :For each $\beta$, let $V_\beta = J_\beta \cup A_\beta \cup I_\beta$. Each $U_\alpha$ and $V_\beta$ is a [[Definition:Convex Set|convex]] [[Definition:Open Set (Topology)|open set]] in $S$ containing $A_\alpha$ and $B_\beta$ respectively. Thus $\displaystyle U = \bigcup U_\alpha$ and $\displaystyle V = \bigcup V_\beta$ are [[Definition:Open Set (Topology)|open sets]] in $T$ containing $A^*$ and $B^*$ respectively. We have that: :no $A_\alpha$ [[Definition:Set Intersection|intersects]] no $B_\beta$ :the same $K_\gamma$ being used throughout implies that no $J_\beta$ or $I_\beta$ can [[Definition:Set Intersection|intersect]] any $J_\alpha$ or $I_\alpha$. Thus no $U_\alpha$ can [[Definition:Set Intersection|intersect]] any $V_\beta$. Thus $U \cap V = \O$. So we have two [[Definition:Disjoint Sets|disjoint]] [[Definition:Open Set (Topology)|open sets]] $U, V$ in $S$ containing the two [[Definition:Separated Sets|separated sets]] $A$ and $B$ respectively. As $A$ and $B$ are arbitrary, it follows that such $U$ and $V$ can be found whatever $A$ and $B$ are, provided they are [[Definition:Separated Sets|separated]]. Hence the result by definition of [[Definition:T5 Space|$T_5$ space]]. {{qed}}	0
We have by [[Definition:First Projection|definition of first projection]] that: :$\map {\pr_1} w = \map {\pr_1} {a, b} = a$ Then: {{begin-eqn}} {{eqn | l = \bigcup \bigcap w | r = \bigcup \bigcap \tuple {a, b} | c = Definition of $w$ }} {{eqn | r = \bigcup \bigcap \set {\set a, \set {a, b} } | c = {{Defof|Kuratowski Formalization of Ordered Pair|Ordered Pair}} }} {{eqn | r = \map \bigcup {\set a \cap \set {a, b} } | c = [[Intersection of Doubleton]] }} {{eqn | r = \bigcup \set a | c = {{Defof|Set Intersection}} }} {{eqn | r = a | c = [[Union of Singleton]] }} {{end-eqn}} {{qed}}	0
Let $B \subseteq A^\perp$. Then by [[Orthocomplement Reverses Subset]]: :$A^{\perp\perp} \subseteq B^\perp$ By [[Double Orthocomplement is Closed Linear Span]] and the definition of [[Definition:Closed Linear Span|closed linear span]]: :$A \subseteq A^{\perp\perp}$ Hence, by [[Subset Relation is Transitive]]: :$A \subseteq B^\perp$ {{qed}} [[Category:Hilbert Spaces]] llqojzv5zg3rru2iy6w3z2fl6ud7645	0
Let $a, b, c \in \Z$. We have that $a \perp b$. That is: :$\gcd \set {a, b} = 1$ where $\gcd$ denotes [[Definition:Greatest Common Divisor of Integers|greatest common divisor]]. From [[Bézout's Lemma]], we may write: :$a x + b y = 1$ for some $x, y \in \Z$. Upon multiplication by $c$, we see that: :$c = c \paren {a x + b y} = c a x + c b y$ Now note that $c a x + c b y$ is an [[Definition:Integer Combination|integer combination]] of $a c$ and $b c$. So, since: :$a \divides a c$ and: :$a \divides b c$ it follows from [[Common Divisor Divides Integer Combination]] that: :$a \divides \paren {c a x + c b y}$ However: : $c a x + c b y = c \paren {a x + b y} = c \cdot 1 = c$ Therefore: : $a \divides c$ {{qed}}	0
Let $k \in \Z_{>0}$ be a [[Definition:Strictly Positive Integer|(strictly) positive integer]]. The largest [[Definition:Even Integer|even integer]] which cannot be expressed as the [[Definition:Integer Addition|sum]] of $2 k$ [[Definition:Odd Integer|odd]] [[Definition:Positive Integer|positive]] [[Definition:Composite Number|composite integers]] is $18 k + 20$.	0
Let $\struct {D, +, \circ}$ be an [[Definition:Integral Domain|integral domain]] whose [[Definition:Ring Zero|zero]] is $0_D$. Let $D \sqbrk X$ be the [[Definition:Ring of Polynomials|ring of polynomials]] over $D$ in the [[Definition:Indeterminate (Polynomial Theory)|indeterminate]] $X$. For $f \in D \sqbrk X$ let $\map \deg f$ denote the [[Definition:Degree of Polynomial|degree]] of $f$. Then: :$\forall f, g \in D \sqbrk X: \map \deg {f g} = \map \deg f + \map \deg g$	0
By [[Path-Connectedness is Equivalence Relation]], it suffices to prove that every point is [[Definition:Path-Connected Points|path-connected]] with $g$. Let $x \in S$. Define a [[Definition:Path (Topology)|path]] $\gamma: \closedint 0 1 \to S$ by: :$\map \gamma t = \begin{cases} x & : t \le \dfrac 1 2 \\ g & : t > \dfrac 1 2 \end{cases}$ We show that $\gamma$ is indeed [[Definition:Everywhere Continuous Mapping (Topology)|continuous]]. Let $U \subseteq S$ be [[Definition:Open Set (Topology)|open]] and [[Definition:Non-Empty Set|non-empty]]. Because $g$ is a [[Definition:Generic Point of Topological Space|generic point]], $g \in U$. If $x \in U$, then its [[Definition:Preimage of Subset under Mapping|preimage]] $\gamma^{-1} \sqbrk U = \closedint 0 1$ is [[Definition:Open Set (Topology)|open]]. If $x \notin U$, then its [[Definition:Preimage of Subset under Mapping|preimage]] $\gamma^{-1} \sqbrk U = \hointl {\dfrac 1 2} 1$ is also [[Definition:Open Set (Topology)|open]]. Thus $x$ and $g$ are [[Definition:Path-Connected Points|path-connected]]. {{qed}} [[Category:Path-Connected Spaces]] 15rjj65wcrgh4ibiu4mwgszydj02m6b	0
Let $\CC$ be an [[Definition:Open Cover|open cover]] of $\R$. Let $p \in \R$. Consider the set: :$\BB_p = \set {\openint {-\infty} {-n} \cup \openint {p - \dfrac 1 n} {p + \dfrac 1 n} \cup \openint n \infty: n \in \N}$ From [[Countable Local Basis in Compact Complement Topology]], $\BB_p$ is a [[Definition:Countable Set|countable]] [[Definition:Local Basis|local basis]] for $T$. Hence the result, by definition of [[Definition:First-Countable Space|first-countable space]]. {{qed}}	0
Let $f: \C \to \C$ be a [[Definition:Complex Function|function]] [[Definition:Meromorphic Function|meromorphic]] on some [[Definition:Region (Complex Analysis)|region]], $D$, containing $a$. Let $f$ have a single [[Definition:Pole|pole]] in $D$, of order $N$, at $a$. Then the [[Definition:Residue (Complex Analysis)|residue]] of $f$ at $a$ is given by: :$\displaystyle \Res f a = \frac 1 {\paren {N - 1}!} \lim_{z \mathop \to a} \frac { \d^{N - 1} } { \d z^{N - 1} } \paren {\paren {z - a}^N \map f z}$	0
Let $T = \left({S, \tau}\right)$ be a [[Definition:Topological Space|topological space]]. Let $P = \left({\tau, \subseteq}\right)$ be an [[Definition:Subset|inclusion]] [[Definition:Ordered Set|ordered set]] of $\tau$. Then $P$ is [[Definition:Bounded Below Set|bounded below]] and $\bot_P = \varnothing$	0
Let $T = \struct {X, \tau}$ be a [[Definition:Topological Space|topological space]] with [[Definition:Finite Set|finite]] [[Definition:Weight of Topological Space|weight]]. Then there exist a [[Definition:Analytic Basis|basis]] $\BB$ of $T$ and a mapping $f:X \to \tau$ such that: :$\BB = \Img f$ and :$\forall x \in X: \paren {x \in \map f x \land \forall U \in \tau: x \in U \implies \map f x \subseteq U}$ where $\Img f$ denotes the [[Definition:Image of Mapping|image]] of $f$.	0
Let $C_i$ be [[Definition:Parameterization of Directed Smooth Curve|parameterized]] by the [[Definition:Smooth Path (Complex Analysis)|smooth path]] $\gamma_i: \left[{a_i \,.\,.\, b_i}\right] \to \C$ for all $i \in \left\{ {1, \ldots, n}\right\}$. From [[Reversed Directed Smooth Curve is Directed Smooth Curve]], it follows that $-C_i$ is independent of the paraterization $\gamma_i$ of $C_i$. We now prove that the [[Definition:End Point of Contour (Complex Plane)|end point]] of $-C_i$ is equal to the [[Definition:Start Point of Contour (Complex Plane)|start point]] of $-C_{i-1}$ for all $i \in \left\{ {2, \ldots, n}\right\}$. By [[Definition:Reversed Directed Smooth Curve|definition of reversed directed smooth curve]], $-C_i$ is [[Definition:Parameterization of Directed Smooth Curve (Complex Plane)|parameterized]] by $\rho_i: \left[{a_i \,.\,.\, b_i}\right] \to \C$. Here, $\rho_i \left({t}\right) = \gamma_i \left({a_i + b_i - t}\right)$. From [[Reparameterization of Directed Smooth Curve Maps Endpoints To Endpoints]], it follows that the [[Definition:Endpoints of Contour|endpoints]] $\rho_i \left({a_i}\right)$ and $\rho_i \left({b_i}\right)$ are independent of the [[Definition:Parameterization of Directed Smooth Curve|parameterization]] $\rho_i$. Then: {{begin-eqn}} {{eqn | l = \rho_i \left({b_i}\right) | r = \phi_i \left({a_i + b_i - b_i}\right) }} {{eqn | r = \phi_i \left({a_i}\right) }} {{eqn | r = \phi_{i - 1} \left({b_{i - 1} }\right) | c = {{Defof|Contour (Complex Plane)}} }} {{eqn | r = \rho_{i - 1} \left({a_{i - 1} }\right) }} {{end-eqn}} By definition, it follows that $-C_n, \ldots, -C_1$ can be [[Definition:Concatenation of Contours|concatenated]] to form a [[Definition:Contour|contour]]. {{qed}}	0
=== Sufficient Condition === Let $G = \struct {V, E}$ be [[Definition:Bipartite Graph|bipartite]]. So, let $V = A \cup B$ such that $A \cap B = \O$ and that all [[Definition:Edge of Graph|edges]] $e \in E$ are such that $e$ is of the form $\set {a, b}$ where $a \in A$ and $b \in B$. (This is the definition of a [[Definition:Bipartite Graph|bipartite graph]].) Suppose $G$ has (at least) one [[Definition:Odd Cycle (Graph Theory)|odd cycle]] $C$. Let the [[Definition:Length of Walk|length]] of $C$ be $n$. Let $C = \tuple {v_1, v_2, \ldots, v_n, v_1}$. {{WLOG}}, let $v_1 \in A$. It follows that $v_2 \in B$ and hence $v_3 \in A$, and so on. Hence we see that $\forall k \in \set {1, 2, \ldots, n}$, we have: :$v_k \in \begin{cases} A : & k \text{ odd} \\ B : & k \text{ even} \end{cases}$ But as $n$ is [[Definition:Odd Integer|odd]], $v_n \in A$. But $v_1 \in A$, and $v_n v_1 \in C_n$. So $v_n v_1 \in E$ which contradicts the assumption that $G$ is [[Definition:Bipartite Graph|bipartite]]. Hence if $G$ is [[Definition:Bipartite Graph|bipartite]], it has no [[Definition:Odd Cycle (Graph Theory)|odd cycles]]. {{qed|lemma}} === Necessary Condition === It is enough to consider $G$ as being [[Definition:Connected Graph|connected]], as otherwise we could consider each [[Definition:Component (Graph Theory)|component]] separately. Suppose $G$ has no [[Definition:Odd Cycle (Graph Theory)|odd cycles]]. Choose any [[Definition:Vertex of Graph|vertex]] $v \in G$. Divide $G$ into two sets of [[Definition:Vertex of Graph|vertices]] like this: :Let $A$ be the [[Definition:Set|set]] of [[Definition:Vertex of Graph|vertices]] such that the shortest [[Definition:Path (Graph Theory)|path]] from each element of $A$ to $v$ is of [[Definition:Odd Integer|odd]] [[Definition:Length of Walk|length]] :Let $B$ be the [[Definition:Set|set]] of [[Definition:Vertex of Graph|vertices]] such that the shortest [[Definition:Path (Graph Theory)|path]] from each element of $B$ to $v$ is of [[Definition:Even Integer|even]] [[Definition:Length of Walk|length]]. Then $v \in B$ and $A \cap B = \O$. Suppose $a_1, a_2 \in A$ are [[Definition:Adjacent Vertices (Graph Theory)|adjacent]]. Then there would be a [[Definition:Closed Walk|closed walk]] of odd length $\tuple {v, \ldots, a_1, a_2, \ldots, v}$. But from [[Graph containing Closed Walk of Odd Length also contains Odd Cycle]], it follows that $G$ would then contain an [[Definition:Odd Cycle (Graph Theory)|odd cycle]]. This contradicts our initial supposition that $G$ contains no [[Definition:Odd Cycle (Graph Theory)|odd cycles]]. So no two [[Definition:Vertex of Graph|vertices]] in $A$ can be [[Definition:Adjacent Vertices (Graph Theory)|adjacent]]. By the same argument, neither can any two [[Definition:Vertex of Graph|vertices]] in $B$ be [[Definition:Adjacent Vertices (Graph Theory)|adjacent]]. Thus $A$ and $B$ satisfy the conditions for $G = \struct {A \cup B, E}$ to be [[Definition:Bipartite Graph|bipartite]]. {{qed}} [[Category:Bipartite Graphs]] bfz90ijp1enww187l7qamiya14j3jb3	0
{{begin-eqn}} {{eqn | l = \int_0^1 x^x \rd x | r = \sum_{n \mathop = 1}^\infty \frac {\paren {-1}^{n + 1} } {n^n} }} {{eqn | r = -\sum_{n \mathop = 1}^\infty \paren {-n}^{-n} }} {{eqn | r = 0.78343 \ 05107 \ 12\ldots }} {{end-eqn}}	0
From [[Skewness in terms of Non-Central Moments]], we have: :$\gamma_1 = \dfrac {\expect {X^3} - 3 \mu \sigma^2 - \mu^3} {\sigma^3}$ where: :$\mu$ is the [[Definition:Expectation|expectation]] of $X$. :$\sigma$ is the [[Definition:Standard Deviation|standard deviation]] of $X$. By [[Expectation of Exponential Distribution]] we have: :$\mu = \beta$ By [[Variance of Exponential Distribution]] we have: :$\sigma = \beta$ By [[Raw Moment of Exponential Distribution]] we also have: :$\expect {X^3} = 3! \beta^3 = 6 \beta^3$ So: {{begin-eqn}} {{eqn | l = \gamma_1 | r = \frac {6 \beta^3 - 3\beta^3 - \beta^3} {\beta^3} }} {{eqn | r = \frac {2 \beta^3} {\beta^3} }} {{eqn | r = 2 }} {{end-eqn}} {{qed}} [[Category:Skewness]] [[Category:Exponential Distribution]] ewsnznswr0tnmxqwdfyu1hgbrth0keq	0
{{begin-eqn}} {{eqn | l = \map {\frac \d {\d x} } {\sech u} | r = \map {\frac \d {\d u} } {\sech u} \frac {\d u} {\d x} | c = [[Chain Rule for Derivatives]] }} {{eqn | r = -\sech u \tanh u \frac {\d u} {\d x} | c = [[Derivative of Hyperbolic Secant]] }} {{end-eqn}} {{qed}}	0
When expressed in [[Definition:Binary Notation|binary notation]], the number of [[Definition:Digit|digits]] in $1000$ is $10$.	0
{{begin-eqn}} {{eqn | l = \map \tan {2 \theta} | r = \frac {\map \sin {2 \theta} } {\map \cos {2 \theta} } | c = [[Tangent is Sine divided by Cosine]] }} {{eqn | r = \frac {2 \cos \theta \sin \theta} {\cos^2 \theta - \sin^2 \theta} | c = [[Double Angle Formula for Sine]] and [[Double Angle Formula for Cosine]] }} {{eqn | r = \frac {\frac {2 \cos \theta \sin \theta} {\cos^2 \theta} } {\frac {\cos^2 \theta - \sin^2 \theta} {\cos^2 \theta} } | c = dividing top and bottom by $\cos^2 \theta$ }} {{eqn | r = \frac {2 \tan \theta} {1 - \tan^2 \theta} | c = Simplifying: [[Tangent is Sine divided by Cosine]] }} {{end-eqn}} {{qed}}	0
:$\displaystyle \int \frac {\d x} {p^2 \sin^2 a x + q^2 \cos^2 a x} = \frac 1 {a p q} \map \arctan {\frac {p \tan a x} q} + C$	0
Let $S \subseteq \Z$ be the [[Definition:Set|set]] of [[Definition:Positive Integer|positive integers]] defined as: :$S := \set {n \in \Z: \forall k \in \Z_{>1}: k^2 \nmid n}$ That is, let $S$ be the [[Definition:Set|set]] of all [[Definition:Square-Free Integer|square-free]] [[Definition:Positive Integer|positive integers]]. Let $\chi_S: \N \to \Z$ denote the [[Definition:Characteristic Function of Set|characteristic function]] of $S$: :$\forall n \in \Z: \map {\chi_S} n = \sqbrk {n \in S}$ where $\sqbrk {n \in S}$ is [[Definition:Iverson's Convention|Iverson's convention]]. Then $\chi_S$ is [[Definition:Multiplicative Arithmetic Function|multiplicative]].	0
{{begin-eqn}} {{eqn | l = \paren {r e^{i \theta} }^\omega | r = \paren {r \paren {\cos x + i \sin x} }^\omega | c = {{Defof|Exponential Form of Complex Number}} }} {{eqn | r = r^\omega \paren {\cos \omega x + i \omega \sin x} | c = [[De Moivre's Formula]] }} {{eqn | r = r^\omega e^{i \omega \theta} | c = {{Defof|Exponential Form of Complex Number}} }} {{end-eqn}} {{qed}}	0
Let: :$\forall n \in \N_{>0}: \norm {n \cdot 1_R} \le 1$ Let $x, y \in R$. Let $y = 0_R$ where $0_R$ is the [[Definition:Ring Zero|zero]] of $R$. Then $\norm {x + y} = \norm x = \max \set {\norm x, 0} = \max \set {\norm x, \norm y}$ ==== [[Characterisation of Non-Archimedean Division Ring Norms/Sufficient Condition/Lemma 1|Lemma 1]] ==== {{:Characterisation of Non-Archimedean Division Ring Norms/Sufficient Condition/Lemma 1}} {{qed|lemma}} Hence to complete the proof it is sufficient to prove: :$\forall x \in R: \norm {x + 1_R} \le \max \set {\norm x, 1}$ For $n \in \N$: {{begin-eqn}} {{eqn | l = \norm {x + 1_R}^n | r = \norm {\sum_{i \mathop = 0}^n \binom n i \cdot x^i} | c = [[Binomial Theorem]] }} {{eqn | o = \le | r = \sum_{i \mathop = 0}^n \norm {\binom n i \cdot x^i} | c = {{NormAxiom|3}} }} {{eqn | r = \sum_{i \mathop = 0}^n \norm {\binom n i \cdot 1_R} \norm x^i | c = {{NormAxiom|2}} }} {{eqn | o = \le | r = \sum_{i \mathop = 0}^n \norm x^i | c = $\forall n \in \N_{>0}: \norm {n \cdot 1_R} \le 1$ }} {{end-eqn}} ==== [[Characterisation of Non-Archimedean Division Ring Norms/Sufficient Condition/Lemma 2|Lemma 2]] ==== {{:Characterisation of Non-Archimedean Division Ring Norms/Sufficient Condition/Lemma 2}} {{qed|lemma}} Hence {{begin-eqn}} {{eqn | l = \norm {x + 1_R}^n | o = \le | r = \sum_{i \mathop = 0}^n \norm x^i | c = continuing from above }} {{eqn | o = \le | r = \sum_{i \mathop = 0}^n \max \set {\norm x^n , 1} | c = [[Characterisation of Non-Archimedean Division Ring Norms/Sufficient Condition/Lemma 2|Lemma 2]] }} {{eqn | r = \paren {n + 1} \max \set {\norm x^n , 1} }} {{end-eqn}} Taking $n$th roots yields: :$\norm {x + 1_R} \le \paren {n + 1}^{1/n} \max \set {\norm x, 1}$ ==== [[Characterisation of Non-Archimedean Division Ring Norms/Sufficient Condition/Lemma 3|Lemma 3]] ==== {{:Characterisation of Non-Archimedean Division Ring Norms/Sufficient Condition/Lemma 3}}{{qed|lemma}} By the [[Multiple Rule for Real Sequences]]: :$\displaystyle \lim_{n \mathop \to \infty} \paren {n + 1}^{1/n} \max \set {\norm x, 1} = \max \set {\norm x, 1}$ By [[Inequality Rule for Real Sequences]]: :$\norm {x + 1_R} \le \max \set {\norm x, 1}$ The result follows.	0
We have that [[Singleton Set in Discrete Space is Compact]]. We also have that $S$ is the [[Definition:Set Union|union]] of all its [[Definition:Singleton|singleton sets]]: :$\displaystyle S = \bigcup_{x \mathop \in S} \set x$ As $S$ is [[Definition:Countable Set|countable]], it is the [[Definition:Set Union|union]] of [[Definition:Countable Set|countably]] many [[Definition:Compact Topological Subspace|compact]] sets. Hence the result, by definition of [[Definition:Sigma-Compact Space|$\sigma$-compact]]. {{qed}}	0
{{proof wanted}} {{namedfor|Jun-iti Nagata|name2 = Yurii Mikhailovich Smirnov|cat = Nagata J|cat2 = Smirnov Y M}}	0
Let: {{begin-eqn}} {{eqn | l = z | r = x^2 - a^2 | c = }} {{eqn | ll= \leadsto | l = \frac {\d z} {\d x} | r = 2 x | c = [[Power Rule for Derivatives]] }} {{eqn | ll= \leadsto | l = \int \frac {\d x} {x \paren {x^2 - a^2} } | r = \int \frac {\d z} {2 z} | c = [[Integration by Substitution]] }} {{eqn | r = \frac 1 2 \int \frac {\d z} z | c = [[Primitive of Constant Multiple of Function]] }} {{eqn | r = \frac 1 2 \ln z + C | c = [[Primitive of Reciprocal/Corollary|Primitive of Reciprocal: Corollary]] as $z > 0$ }} {{eqn | r = \frac 1 2 \map \ln {x^2 - a^2} + C | c = substituting for $z$ }} {{end-eqn}} {{qed}}	0
Let $\struct {\Z, -}$ denote the [[Definition:Algebraic Structure|algebraic structure]] formed by the set of [[Definition:Integer|integers]] under the [[Definition:Binary Operation|operation]] of [[Definition:Integer Subtraction|subtraction]]. Then $\struct {\Z, -}$ is not a [[Definition:Group|group]].	0
A [[Definition:Compact Topological Subspace|compact]] [[Definition:Subset|subset]] of a [[Definition:Compact Topological Space|compact space]] not necessarily [[Definition:Closed Set (Topology)|closed]].	0
The [[Definition:Additive Group of Integers|additive group of integers]] $\struct {\Z, +}$ is an [[Definition:Infinite Cyclic Group|infinite cyclic group]] which is [[Definition:Generator of Cyclic Group|generated by]] the element $1 \in \Z$.	0
By [[Orthogonal Group is Subgroup of General Linear Group]], $M \in \GL {n, \R}$. From [[Pushforward of Lebesgue Measure under General Linear Group]], it follows that: :$M_* \lambda^n = \size {\det M^{-1} } \lambda^n$ Since $M^{-1} \in \map {\mathrm O} {n, \R}$ by [[Orthogonal Group is Group]], [[Determinant of Orthogonal Matrix]] applies to yield: :$\size {\det M^{-1} } = 1$ Hence the result. {{qed}} {{wtd|In order to avoid circularity (through [[Pushforward of Lebesgue Measure under General Linear Group]] and [[Determinant as Volume of Parallelotope]]) the direct proof Schilling produces also needs to be covered}}	0
By [[Lower Closure of Element is Closed under Directed Suprema]]: :$x^\preceq$ is [[Definition:Closed under Directed Suprema|closed under directed suprema]]. By [[Lower Closure of Singleton]]: :$\left\{ {x}\right\}^\preceq = x^\preceq$ By [[Lower Closure is Lower Set]]: :$x^\preceq$ is a [[Definition:Lower Set|lower set]]. Thus by [[Closed Set iff Lower and Closed under Directed Suprema in Scott Topological Ordered Set]]: :$x^\preceq$ is [[Definition:Closed Set (Topology)|closed]]. {{qed}}	0
[[Proof by Counterexample]]: Let $a = 30, b = 40, r = 2, s = 10$. We have that: {{begin-eqn}} {{eqn | l = 30 | o = \equiv | r = 40 | rr= \pmod 2 | c = }} {{eqn | l = 30 | o = \equiv | r = 40 | rr= \pmod {10} | c = }} {{eqn-intertext|But note that:}} {{eqn | l = 30 | o = \not \equiv | r = 40 | rr= \pmod {20} | c = }} {{end-eqn}} {{qed}}	0
We have that the [[Arens-Fort Space is Completely Hausdorff]]. Then from [[Sequence of Implications of Separation Axioms]], a [[Definition:Completely Hausdorff Space|$T_{2 \frac 1 2}$ (completely Hausdorff) space]] is a [[Definition:Fréchet Space (Topology)|$T_1$ space]]. {{qed}}	0
Consider the [[Definition:Farey Sequence|Farey sequence]]: :$F = \dfrac 1 2, \dfrac 1 3, \dfrac 2 3, \dfrac 1 4, \dfrac 2 4, \dfrac 3 4, \dfrac 1 5, \dfrac 2 5, \dfrac 3 5, \dfrac 4 5, \dfrac 1 6, \ldots$ $F$ is not [[Definition:Convergent Real Sequence|convergent]].	0
Let us define $\eqclass {\tuple {a, b} } \boxminus$ as in the [[Definition:Integer/Formal Definition|formal definition of integers]]. That is, $\eqclass {\tuple {a, b} } \boxminus$ is an [[Definition:Equivalence Class|equivalence class]] of [[Definition:Ordered Pair|ordered pairs]] of [[Definition:Natural Numbers|natural numbers]] under the [[Definition:Congruence Relation|congruence relation]] $\boxminus$. $\boxminus$ is the [[Definition:Congruence Relation|congruence relation]] defined on $\N \times \N$ by $\tuple {x_1, y_1} \boxminus \tuple {x_2, y_2} \iff x_1 + y_2 = x_2 + y_1$. In order to streamline the notation, we will use $\eqclass {a, b} {}$ to mean $\eqclass {\tuple {a, b} } \boxminus$, [[Definition:Integer/Formal Definition/Notation|as suggested]]. From [[Construction of Inverse Completion/Identity of Quotient Structure|the method of construction]], $\eqclass {c, c} {}$, where $c$ is any element of the [[Definition:Natural Numbers|natural numbers]] $\N$, is the [[Definition:Identity (Abstract Algebra)|identity]] of $\struct {\Z, +}$. To ease the algebra, we will take $\eqclass {0, 0} {}$ as a canonical instance of this equivalence class. We need to show that: $\forall a, b, c \in \N: \eqclass {a, b} {} \times \eqclass {0, 0} {} = \eqclass {0, 0} {} = \eqclass {0, 0} {} \times \eqclass {a, b} {}$. From [[Natural Numbers form Commutative Semiring]], we can take it for granted that [[Definition:Natural Number Addition|addition]] and [[Definition:Natural Number Multiplication|multiplication]] are [[Definition:Commutative Operation|commutative]] on the [[Definition:Natural Numbers|natural numbers]] $\N$. {{begin-eqn}} {{eqn | l = \eqclass {a, b} {} \times \eqclass {0, 0} {} | r = \eqclass {a \times 0 + b \times 0, a \times 0 + b \times 0} {} | c = }} {{eqn | r = \eqclass {0, 0} {} | c = [[Construction of Inverse Completion/Equivalence Relation/Equivalence Class of Equal Elements|Construction of Inverse Completion: Equivalence Class of Equal Elements]] }} {{eqn | r = \eqclass {0 \times a + 0 \times b, 0 \times a + 0 \times b} {} | c = }} {{eqn | r = \eqclass {0, 0} {} \times \eqclass {a, b} {} | c = }} {{end-eqn}} {{qed}}	0
By definition of [[Definition:Restriction of Mapping|restriction]]: :$\forall x, y \in H: d_H \left({x, y}\right) = d \left({x, y}\right)$ As $d$ is a [[Definition:Metric|metric]], the [[Definition:Metric Space Axioms|metric space axioms]] are all fulfilled by all $x, y \in A$ under $d$. As $H \subseteq A$, by definition of [[Definition:Subset|subset]], all $x, y \in H$ are also [[Definition:Element|elements]] of $A$. Therefore the [[Definition:Metric Space Axioms|metric space axioms]] are all fulfilled by all $x, y \in H$ under $d_H$. {{qed}}	0
[[Proof by Contradiction]]: {{AimForCont}} $H$ is [[Definition:Finite Set|finite]]. From [[Finite T1 Space is Discrete|Finite $T_1$ Space is Discrete]], $H$ has the [[Definition:Discrete Topology|discrete topology]]. From [[Discrete Space is not Dense-In-Itself]] it then follows that $H$ can not be [[Definition:Dense-in-itself|dense-in-itself]]. So for $H$ to be [[Definition:Dense-in-itself|dense-in-itself]], it must be [[Definition:Infinite Set|infinite]]. {{qed}}	0
{{begin-eqn}} {{eqn | l = \map \Gamma z \map \Gamma {1 - z} | r = \dfrac \pi {\sin \pi z} | c = [[Euler's Reflection Formula]] }} {{eqn | ll= \leadsto | l = \map \ln {\map \Gamma z \map \Gamma {1 - z} } | r = \map \ln {\dfrac \pi {\sin \pi z} } | c = applying $\ln$ on both sides }} {{eqn | ll= \leadsto | l = \map \ln {\map \Gamma z} + \map \ln {\map \Gamma {1 - z} } | r = \map \ln \pi - \map \ln {\sin \pi z} | c = [[Sum of Logarithms]] and [[Difference of Logarithms]] }} {{eqn | ll= \leadsto | l = \dfrac \d {\d z} \map \ln {\map \Gamma z} + \dfrac \d {\d z} \map \ln {\map \Gamma {1 - z} } | r = \dfrac \d {\d z} \map \ln \pi - \dfrac \d {\d z} \map \ln {\sin \pi z} | c = taking first [[Definition:Derivative|derivative]] }} {{eqn | ll= \leadsto | l = \dfrac {\map {\Gamma'} z} {\map \Gamma z} - \dfrac {\map {\Gamma'} {1 - z} } {\map \Gamma {1 - z} } | r = 0 - \pi \cot \pi z | c = [[Derivative of Natural Logarithm Function]], [[Derivative of Sine Function]], [[Chain Rule]], [[Derivative of Constant]] }} {{eqn | ll= \leadsto | l = \map \psi z - \map \psi {1 - z} | r = -\pi \cot \pi z | c = {{Defof|Digamma Function}} }} {{eqn | ll= \leadsto | l = \dfrac {\d^n} {\d z^n} \map \psi z - \dfrac {\d^n} {\d z^n} \map \psi {1 - z} | r = -\pi \dfrac {\d^n} {\d z^n} \cot \pi z | c = taking $n$th [[Definition:Derivative|derivative]] }} {{eqn | ll= \leadsto | l = \map {\psi_n} z - \paren {-1}^n \map {\psi_n} {1 - z} | r = -\pi \dfrac {\d^n} {\d z^n} \cot \pi z | c = {{Defof|Polygamma Function}} }} {{end-eqn}} {{qed}}	0
Removing one [[Definition:Edge of Graph|edge]] from a [[Definition:Cycle Graph|cycle graph]] leaves a [[Definition:Path Graph|path graph]].	0
From [[Additive Group of Reals is Subgroup of Complex]], $\struct {\R, +}$ is a [[Definition:Subgroup|subgroup]] of $\struct {\C, +}$. From [[Multiplicative Group of Reals is Subgroup of Complex]], $\struct {\R, \times}$ is a [[Definition:Subgroup|subgroup]] of $\struct {\C, \times}$. The result follows from the [[Subfield Test]] via the [[One-Step Subgroup Test]] and [[Two-Step Subgroup Test]]. {{qed}}	0
=== Necessary Condition === Let $T$ be a [[Definition:Compact Topological Space|compact]] [[Definition:Discrete Topology|discrete space]]. {{AimForCont}} $T$ is [[Definition:Infinite Discrete Topology|infinite]]. Let $\mathcal C$ be the [[Definition:Cover of Set|cover]] for $S$ defined as: :$\mathcal C = \left\{{\left\{{x}\right\}: x \in S}\right\}$ As $S$ is an [[Definition:Infinite Set|infinite set]] then so is $\mathcal C$. Let $\mathcal C'$ be a [[Definition:Proper Subset|proper subset]] of $\mathcal C$. Then: : $\exists y \in S: \left\{{y}\right\} \notin \mathcal C'$ and so $\mathcal C'$ is not a [[Definition:Cover of Set|cover]] for $S$. So by definition $\mathcal C'$ is not a [[Definition:Subcover|subcover]] of $\mathcal C$. So $\mathcal C$ can have no [[Definition:Finite Subcover|finite subcover]]. Hence by definition $T$ can not be [[Definition:Compact Topological Space|compact]]. By [[Proof by Contradiction]] it follows that of $T$ is [[Definition:Compact Space|compact]] then $S$ must be [[Definition:Finite Set|finite]]. {{qed|lemma}} === Sufficient Condition === Let $T$ be a [[Definition:Finite Discrete Topology|finite discrete space]]. Then from [[Finite Topological Space is Compact]] it follows that $T$ is a [[Definition:Compact Topological Space|compact space]]. {{qed}}	0
{{begin-eqn}} {{eqn | l = \sin 90 \degrees | r = 1 | c = [[Sine of Right Angle]] }} {{eqn | ll= \leadsto | l = \map \sin {2 \times 45 \degrees} | r = 1 | c = }} {{eqn | ll= \leadsto | l = 2 \sin 45 \degrees \cos 45 \degrees | r = 1 | c = [[Double Angle Formula for Sine]] }} {{eqn | ll= \leadsto | l = 2 \sin 45 \degrees \map \sin {90 \degrees - 45 \degrees} | r = 1 | c = [[Sine of Complement equals Cosine]] }} {{eqn | ll= \leadsto | l = 2 \sin 45 \degrees \sin 45 \degrees | r = 1 | c = }} {{eqn | ll= \leadsto | l = 2 \sin^2 45 \degrees | r = 1 | c = by $(1)$ }} {{eqn | ll= \leadsto | l = \sin 45 \degrees | r = \pm \frac 1 {\sqrt 2} | c = }} {{end-eqn}} The negative solution is rejected because $45 \degrees$ is an [[Definition:Acute Angle|acute angle]] and [[Definition:Sine/Definition from Circle/First Quadrant|Sine of Acute Angle is Positive]]. Therefore: :$\sin 45 \degrees = \dfrac 1 {\sqrt 2} = \dfrac {\sqrt 2} 2$ {{qed}}	0
{{begin-eqn}} {{eqn | l = \cos x | r = 1 - 2 \sin^2 \frac x 2 | c = [[Double Angle Formulas/Cosine/Corollary 2|Cosine Double Angle Formula]] }} {{eqn | ll= \iff | l = 1 - \cos x | r = 2 \sin^2 \frac x 2 | c = rearranging }} {{eqn | ll= \iff | l = \frac 1 {1 - \cos x} | r = \frac 1 2 \frac 1 {\sin^2 \frac x 2} | c = taking the [[Definition:Reciprocal|reciprocal]] of both sides }} {{eqn | r = \frac 1 2 \csc^2 \frac x 2 | c = Definition of [[Definition:Cosecant|Cosecant]] }} {{end-eqn}} {{qed}}	0
Let $\sequence {f_n}$ be the [[Definition:Sequence|sequence]] of [[Definition:Mapping|mappings]] $f_n: \R_{>0} \to \R$ defined as: :$\map {f_n} x = n \paren {\sqrt [n] x - 1 }$ Fix $x \in \R_{>0}$. We first show that $\forall n \in \N : 1 - \dfrac 1 x \le < n \paren {\sqrt [n] x - 1}$ Let $n \in \N$. From [[Sum of Geometric Sequence]]: :$\sqrt [n] x - 1 = \dfrac {x - 1} {1 + \sqrt [n] x + \sqrt [n] x^2 + \cdots + \sqrt [n] x^{n - 1} }$ === Case 1: $0 < x < 1$ === {{begin-eqn}} {{eqn | l = 0 < x < 1 | o = \leadsto | r = \forall k < n: \sqrt [n] x^{n - k} > x > 0 | c = [[Power Function on Base between Zero and One is Strictly Decreasing/Rational Number]] }} {{eqn | o = \leadsto | r = 0 < n x < \sum_{k = 0}^{n - 1} \sqrt [n] x^{n - k} | c = [[Real Number Ordering is Compatible with Addition]] }} {{eqn | o = \leadsto | r = \dfrac 1 {1 + \sqrt [n] x + \sqrt [n] x^2 + \cdots + \sqrt [n] x^{n - 1} } > \dfrac 1 {n x} | c = [[Ordering of Reciprocals]] }} {{eqn | o = \leadsto | r = \dfrac {x - 1} {n x} < \dfrac {x - 1} {1 + \sqrt [n] x + \sqrt [n] x^2 + \cdots + \sqrt [n] x^{n - 1} } | c = [[Order of Real Numbers is Dual of Order of their Negatives]] }} {{eqn | o = \leadsto | r = \dfrac {x - 1} {n x} < \sqrt [n] x - 1 | c = [[Sum of Geometric Sequence]] }} {{eqn | o = \leadsto | r = 1 - \dfrac 1 x < n \paren {\sqrt [n] x - 1} | c = [[Real Number Ordering is Compatible with Multiplication]] }} {{end-eqn}} {{qed|lemma}} === Case 2: $x = 1$ === {{begin-eqn}} {{eqn | l = \dfrac {x - 1} x | r = 0 }} {{eqn | r = \sqrt [n] 1 - 1 }} {{end-eqn}} {{qed|lemma}} === Case 3: $x > 1$ === {{begin-eqn}} {{eqn | l = x > 1 | o = \leadsto | r = \forall k < n: 1 < \sqrt [n] x^{n - k} < x | c = [[Power Function on Base Greater than One is Strictly Increasing/Rational Number]] }} {{eqn | o = \leadsto | r = 0 < \sum_{k \mathop = 0}^{n - 1} \sqrt [n] x^{n - k} < n x | c = [[Real Number Ordering is Compatible with Addition]] }} {{eqn | o = \leadsto | r = 0 < \dfrac 1 {n x} < \dfrac 1 {1 + \sqrt [n] x + \sqrt [n] x^2 + \cdots + \sqrt [n] x^{n - 1} } | c = [[Ordering of Reciprocals]] }} {{eqn | o = \leadsto | r = \dfrac {x - 1} {n x} < \dfrac {x - 1} {1 + \sqrt [n] x + \sqrt [n] x^2 + \cdots + \sqrt [n] x^{n - 1} } | c = [[Real Number Ordering is Compatible with Multiplication]] }} {{eqn | o = \leadsto | r = \dfrac {x - 1} {n x} < \sqrt [n] x - 1 | c = [[Sum of Geometric Sequence]] }} {{eqn | o = \leadsto | r = 1 - \dfrac 1 x < n \paren {\sqrt [n] x - 1 } | c = [[Real Number Ordering is Compatible with Multiplication]] }} {{end-eqn}} {{qed|lemma}} Thus: :$\forall n \in \N : 1 - \dfrac 1 x \le n \paren {\sqrt [n] x - 1 }$ by [[Proof by Cases]]. Thus: :$\displaystyle 1 - \dfrac 1 x \le \lim_{n \mathop \to \infty} n \paren {\sqrt [n] x - 1 }$ from [[Limit of Bounded Convergent Sequence is Bounded]]. Hence the result, from the [[Definition:Real Natural Logarithm|definition of $\ln$]]. {{qed}}	0
{{begin-eqn}} {{eqn | l = y | r = \cosh^{-1} x | c = }} {{eqn | ll= \leadsto | l = x | r = \cosh y | c = {{Defof|Real Inverse Hyperbolic Cosine}} }} {{eqn | ll= \leadsto | l = \frac {\d x} {\d y} | r = \sinh y | c = [[Derivative of Hyperbolic Cosine]] }} {{eqn | ll= \leadsto | l = \frac {\d y} {\d x} | r = \frac 1 {\sinh y} | c = [[Derivative of Inverse Function]] }} {{eqn | ll= \leadsto | l = \frac {\d y} {\d x} | r = \pm \frac 1 {\sqrt {\cosh^2 y - 1} } | c = [[Difference of Squares of Hyperbolic Cosine and Sine]] }} {{end-eqn}} Note that when $y = 0$, $\cosh y$ is defined and equals $1$. But from [[Derivative of Hyperbolic Cosine]]: :$\valueat {\dfrac \d {\d y} \cosh y} {y \mathop = 0} = \sinh 0 = 0$ Thus $\dfrac {\d y} {\d x} = \dfrac 1 {\sinh y}$ is not defined at $y = 0$. Hence the limitation of the [[Definition:Domain of Mapping|domain]] of $\map {\dfrac \d {\d x} } {\cosh^{-1} x}$ to exclude $x = 1$. Now it is necessary to determine the [[Definition:Sign of Number|sign]] of $\dfrac {\d y} {\d x}$. From: :[[Real Inverse Hyperbolic Cosine is Strictly Increasing]] :[[Derivative of Strictly Increasing Real Function is Strictly Positive]] it follows that $\map {\dfrac \d {\d x} } {\cosh^{-1} x} > 0$ on $\R_{>1}$. Thus: :$\dfrac {\d y} {\d x} = \dfrac 1 {\sqrt {\cosh^2 y - 1} }$ where $\sqrt {\cosh^2 y - 1}$ denotes the [[Definition:Positive Square Root|positive square root]] of $\cosh^2 y - 1$. Hence by definition of $x$ and $y$ above: :$\map {\dfrac \d {\d x} } {\cosh^{-1} x} = \dfrac 1 {\sqrt {x^2 - 1} }$ {{qed}}	0
:$\map {\operatorname S} 0 = 0$	0
:$\displaystyle \int \frac {\mathrm d x} {p + q \tanh a x} = \frac {p x} {p^2 - q^2} - \frac q {a \left({p^2 - q^2}\right)} \ln \left\vert{q \sinh a x + p \cosh a x}\right\vert + C$	0
It can be seen that $(1)$ is a [[Definition:Constant Coefficient Homogeneous Linear Second Order ODE|constant coefficient homogeneous linear second order ODE]]. Let $(1)$ be written in the form: :$y'' - 2 y + 4 y = 0$ Its [[Definition:Auxiliary Equation|auxiliary equation]] is: :$(2): \quad: m^2 - 2 m + 4 = 0$ From [[Solution to Quadratic Equation with Real Coefficients]], the [[Definition:Root of Polynomial|roots]] of $(2)$ are: :$m_1 = 1 + \sqrt 3 i$ :$m_2 = 1 - \sqrt 3 i$ These are [[Definition:Complex Number|complex]] and unequal. So from [[Solution of Constant Coefficient Homogeneous LSOODE]], the [[Definition:General Solution|general solution]] of $(1)$ is: :$y = e^x \paren {C_1 \cos \sqrt 3 x + C_2 \sin \sqrt 3 x}$ {{qed}}	0
Let $\left({X, \Sigma}\right)$ be a [[Definition:Measurable Space|measurable space]]. Let $\left({f_n}\right)_{n \mathop \in \N}$, $f_n: X \to \overline \R$ be a [[Definition:Sequence|sequence]] of [[Definition:Measurable Function|$\Sigma$-measurable functions]]. Then the [[Definition:Pointwise Lower Limit|pointwise lower limit]]: :$\displaystyle \liminf_{n \mathop \to \infty} f_n: X \to \overline \R$ is also [[Definition:Measurable Function|$\Sigma$-measurable]].	0
Let $k < m, m < n$. By definition it follows that $k \in m, m \in n$. We have from [[Element of Finite Ordinal iff Subset]] that: :$k \in m \iff k \subseteq m$ :$m \in n \iff m \subseteq n$ It follows from [[Subset Relation is Transitive]] that $k \subseteq n$. Hence the result. {{qed}} [[Category:Natural Numbers]] 3h3h6rhf4et2e2b2hq753efl4aepldy	0
Let $S$ be a [[Definition:Set|set]] and let $p \in S$. Let $\tau_{\bar p}$ be the [[Definition:Excluded Point Topology|excluded point topology]] on $S$. Let $T = \struct {S \setminus \set p, \tau_D}$ be the [[Definition:Discrete Space|discrete topological space]] on $S \setminus \set p$. Then $T^* = \struct {S, \tau_{\bar p} }$ is an [[Definition:Open Extension Space|open extension space]] of $T$.	0
=== [[Law of Cosines/Right Triangle|Lemma: Right Triangle]] === {{:Law of Cosines/Right Triangle}} === [[Law of Cosines/Proof 3/Acute Triangle|Acute Triangle]] === {{:Law of Cosines/Proof 3/Acute Triangle}} === [[Law of Cosines/Proof 3/Obtuse Triangle|Obtuse Triangle]] === {{:Law of Cosines/Proof 3/Obtuse Triangle}}	0
Let $T = \left({S, \tau}\right)$ be a [[Definition:Hausdorff Space|$T_2$ (Hausdorff) space]]. Let $X \subseteq T$ be [[Definition:Finite Set|finite]]. From [[Separation Properties Preserved in Subspace]], it follows that $\left({X, \tau_X}\right)$ is also a [[Definition:Hausdorff Space|$T_2$ (Hausdorff) space]]. From [[T2 Space is T1 Space|$T_2$ Space is $T_1$ Space]] it follows that $\left({X, \tau_X}\right)$ is a [[Definition:Fréchet Space (Topology)|$T_1$ (Fréchet) space]]. From [[Finite T1 Space is Discrete|Finite $T_1$ Space is Discrete]], it follows that $\left({X, \tau_X}\right)$ is a [[Definition:Discrete Space|discrete space]]. The result follows from [[Topological Space is Discrete iff All Points are Isolated]]. {{qed}}	0
{{begin-eqn}} {{eqn | l = \cosh^2 x | r = \frac 1 4 \paren {e^x + e^{-x} }^2 | c = {{Defof|Hyperbolic Cosine}} }} {{eqn | r = \frac {e^{2 x} + e^{-2 x} + 2} 4 }} {{eqn | r = \frac {\cosh 2 x + 1} 2 | c = {{Defof|Hyperbolic Cosine}} }} {{end-eqn}} {{qed}}	0
To show that $\struct {\tau, \subseteq}$ is a [[Definition:Complete Lattice|complete lattice]], we must show that every [[Definition:Subset|subset]] of $\tau$ has a [[Definition:Supremum of Set|supremum]] and an [[Definition:Infimum of Set|infimum]]. Let $S \subseteq \tau$. By the definition of a [[Definition:Topology|topology]]: :$\displaystyle \bigcup S \in \tau$ By [[Union is Smallest Superset]], $\displaystyle \bigcup S$ is the [[Definition:Supremum of Set|supremum]] of $S$. Let $I$ be the [[Definition:Interior (Topology)|interior]] of $\displaystyle \bigcap S$, where by [[Intersection of Empty Set]] $\displaystyle \bigcap \O$ is conventionally taken to be $X$. Then by the definition of [[Definition:Interior (Topology)|interior]] and [[Intersection is Largest Subset]]: :$I \in \tau$ and :$I \subseteq U$ for each $U \in S$. Let $V \in \tau$ with $V \subseteq U$ for each $U \in S$. By [[Intersection is Largest Subset]]: :$\displaystyle V \subseteq \bigcap S$. Then by the definition of [[Definition:Interior (Topology)|interior]]: :$V \subseteq I$ Thus $I$ is the [[Definition:Infimum of Set|infimum]] of $S$. So each [[Definition:Subset|subset]] of $\tau$ has a [[Definition:Supremum of Set|supremum]] and an [[Definition:Infimum of Set|infimum]]. Thus, by definition, $\struct {\tau, \subseteq}$ is a [[Definition:Complete Lattice|complete lattice]]. {{qed}} [[Category:Topology]] [[Category:Complete Lattices]] e80gtf0e1vr5oz1zjtffa3nnnfmzk5z	0
The [[Definition:Second Order ODE|second order ODE]]: :$(1): \quad y'' + y' - 12 y = 0$ has the [[Definition:General Solution to Differential Equation|general solution]]: :$y = C_1 e^{3 x} + C_2 e^{-4 x}$	0
Let $I$ be an [[Definition:Indexing Set|indexing set]] with [[Definition:Uncountable Set|uncountable cardinality]]. Let $\family {\struct {S_\alpha, \tau_\alpha} }_{\alpha \mathop \in I}$ be a [[Definition:Indexed Family|family]] of [[Definition:Topological Space|topological spaces]] [[Definition:Indexed Family|indexed]] by $I$. Let $\displaystyle \struct {S, \tau} = \prod_{\alpha \mathop \in I} \struct {S_\alpha, \tau_\alpha}$ be the [[Definition:Product Space of Topological Spaces|product space]] of $\family {\struct {S_\alpha, \tau_\alpha} }_{\alpha \mathop \in I}$. Let each of $\struct {S_\alpha, \tau_\alpha}$ be a [[Definition:First-Countable Space|first-countable space]]. Then it is not necessarily the case that $\struct {S, \tau}$ is also a [[Definition:First-Countable Space|first-countable space]].	0
Let $S$ be a [[Definition:Set|set]] containing exactly one element. Suppose $S = \set x$ for a certain object $x$. From [[Topology on Singleton is Indiscrete Topology]], the only possible topology on $S$ is the [[Definition:Indiscrete Topology|indiscrete topology]]. From [[Union is Idempotent]], the [[Definition:Set Union|union]] of any number of [[Definition:Indiscrete Topology|indiscrete topologies]] on $S$ is the [[Definition:Indiscrete Topology|indiscrete topology]]. Thus the union of any number of topologies on a set with exactly one element is a topology on that set. {{qed|lemma}} Let $S$ be a [[Definition:Set|set]] containing exactly two elements. Suppose $S = \set {x, y}$ for certain objects $x$ and $y$. Then the [[Definition:Power Set|power set]] of $S$ is the set: : $\map {\mathcal P} S = \set{\varnothing, \set{x}, \set{y}, \set{x, y}}$ Since all [[Definition:Topology|topologies]] $\tau$ on $S$ are subsets of $\tau \subseteq \mathcal P \left({S}\right)$, one of the following must hold: : $\tau_1 = \O$ : $\tau_2 = \set{\O}$ : $\tau_3 = \set{\set{x}}$ : $\tau_4 = \set{\set{y}}$ : $\tau_5 = \set{\O, \set{x}}$ : $\tau_6 = \set{\O, \set{y}}$ : $\tau_7 = \set{\set{x}, \set{y}}$ : $\tau_8 = \set{\O, \set{x}, \set{y}}$ : $\tau_9 = \set{\set{x}, \set{x, y}}$ : $\tau_{10} = \set{\set{y}, \set{x, y}}$ : $\tau_{11} = \set{\set{x}, \set{y}, \set{x, y}}$ : $\tau_{12} = \set{\set{x, y}}$ : $\tau_{13} = \set{\O, \set{x, y}}$ : $\tau_{14} = \set{\O, \set{x}, \set{x, y}}$ : $\tau_{15} = \set{\O, \set{y}, \set{x, y}}$ : $\tau_{16} = \set{\O, \set{x}, \set{y}, S}$. By definition of a topology, $S$ must be an element of the topology. Thus $\tau_1$ up to $\tau_8$ are not topologies on $S$. By [[Empty Set is Element of Topology]], for $\tau$ to be a topology for $S$, it is necessary that $\varnothing \in \tau$. Therefore $\tau_9$ up to $\tau_{12}$ are also not topologies on $S$. By [[Indiscrete Topology is Topology]], $\tau_{13}$ is a topology on $S$. By [[Discrete Topology is Topology]], $\tau_{16}$ is a topology on $S$. By [[Particular Point Topology is Topology]], both $\tau_{14}$ and $\tau_{15}$ are topologies. Finally, it remains to show that any union of elements in $\{\tau_{13}, \tau_{14}, \tau_{15}, \tau_{16}\}$ gives a topology on $S$. By inspection, the following statements are seen to hold: : $\tau_{13} \cup \tau_{14} = \tau_{14}$ : $\tau_{13} \cup \tau_{15} = \tau_{15}$ : $\tau_{13} \cup \tau_{16} = \tau_{16}$ : $\tau_{14} \cup \tau_{15} = \tau_{16}$ : $\tau_{14} \cup \tau_{16} = \tau_{16}$ : $\tau_{15} \cup \tau_{16} = \tau_{16}$ Now let $\paren{\tau_i}_{i \mathop \in I}$ be an arbitrary non-empty [[Definition:Indexing Set|indexed set]] of [[Definition:Topology|topologies]] for a [[Definition:Set|set]] $S$. By the above, if $\tau_{16}$ is one of the $\tau_i$: : $\displaystyle \tau = \bigcup_{i \mathop \in I} \tau_i = \tau_{16}$ So assume that $\tau_{16}$ is not one of the $\tau_i$. If both $\tau_{14}$ and $\tau_{15}$ are in $\paren{\tau_i}_{i \mathop \in I}$, then by the above: : $\displaystyle \tau = \bigcup_{i \mathop \in I} \tau_i = \tau_{16}$ Now suppose that $\tau_{15}$ is in $\paren{\tau_i}_{i \mathop \in I}$ and $\tau_{14}$ is not. Then by the above it follows that: : $\tau = \tau_{15}$ Now suppose that $\tau_{14}$ is in $\paren{\tau_i}_{i \mathop \in I}$ and $\tau_{15}$ is not. Then by the above it follows that: : $\tau = \tau_{14}$ Finally, assume that $\tau_{14}$ and $\tau_{15}$ are not in $\paren{\tau_i}_{i \mathop \in I}$. Then the only topologies in $\paren{\tau_i}_{i \mathop \in I}$ are $\tau_{13}$. In the first case, we find: :$\tau = \tau_{13}$ Hence the result. {{qed}}	0
Let $T_1 = \struct {S, \tau_S}$ be a [[Definition:Topological Space|topological space]]. Let $D = \struct {A, \set {\O, A} }$ be the [[Definition:Indiscrete Topology|indiscrete topology]] on an arbitrary [[Definition:Doubleton|doubleton]] $A = \set {a, b}$. Let $T = \struct {T_1 \times D, \tau}$ be the [[Definition:Double Pointed Topology|double pointed topological space]] on $T_1$. Then $T$ is not a [[Definition:Kolmogorov Space|$T_0$ (Kolmogorov) space]].	0
Let $a, b \in \R_{\ne 0}$ be non-[[Definition:Zero (Number)|zero]] [[Definition:Real Number|real numbers]] such that $a < b$. Let $\map A {a, b}$ denote the [[Definition:Harmonic Mean|narmonic mean]] of $a$ and $b$. Then: :$a < \map A {a, b} < b$	0
=== Necessary Condition === Let $\norm {\,\cdot\,}_R$ be a [[Definition:Non-Archimedean Division Ring Norm|non-archimedean norm]]. Then for all $x,y \in R$: {{begin-eqn}} {{eqn | l = \norm {x + y}_S | r = \norm {\map \phi {\map {\phi^{-1} } x} + \map \phi {\map {\phi^{-1} } y} }_S | c = $\phi$ is a [[Definition:Bijection|bijection]] }} {{eqn | r = \norm {\map {\phi^{-1} } x + \map {\phi^{-1} } y}_R | c = $\phi$ is an [[Definition:Isometry (Metric Spaces)|isometry]]. }} {{eqn | o = \le | r = \max \set {\norm {\map {\phi^{-1} } x}_R, \norm {\map {\phi^{-1} } y}_R} | c = $\norm {\,\cdot\,}_R$ is [[Definition:Non-Archimedean Division Ring Norm|non-archimedean]]. }} {{eqn | r = \max \set {\norm {\map \phi {\map {\phi^{-1} } x} }_S, \norm {\map \phi {\map {\phi^{-1} } y} }_S} | c = $\phi$ is an [[Definition:Isometry (Metric Spaces)|isometry]]. }} {{eqn | r = \max \set {\norm x_S, \norm y_S} | c = $\phi$ is a [[Definition:Bijection|bijection]]. }} {{end-eqn}} {{qed|lemma}} === Sufficient Condition === Let $\norm {\, \cdot \,}_S$ be a [[Definition:Non-Archimedean Division Ring Norm|non-archimedean norm]]. By [[Inverse of Isometric Isomorphism]], $\phi^{-1}: S \to R$ is an [[Definition:Isometric Isomorphism|isometric isomorphism]]. By the '''[[Isometrically Isomorphic Non-Archimedean Division Rings#Necessary Condition|necessary condition]]''', $\norm {\, \cdot \,}_R$ is [[Definition:Non-Archimedean Division Ring Norm|non-archimedean]]. {{qed}} [[Category:Normed Division Rings]] m3vzfu8nxtrx8s5lgtieza28ol5q02r	0
{{begin-eqn}} {{eqn|l = \tanh \left({4 x}\right) |r = \frac {\sinh \left({4 x}\right)} {\cosh \left({4 x}\right)} |c = Definition of [[Definition:Hyperbolic Tangent/Definition 2|Hyperbolic Tangent]] }} {{eqn|r = \frac {8 \sinh^3 x \cosh x + 4 \sinh x \cosh x} {\cosh \left({4 x}\right)} |c = [[Quadruple Angle Formula for Hyperbolic Sine]] }} {{eqn|r = \frac {8 \sinh^3 x \cosh x + 4 \sinh x \cosh x} {8 \cosh^4 x - 8 \cosh^2 x + 1} |c = [[Quadruple Angle Formula for Hyperbolic Cosine]] }} {{eqn|r = \frac {8 \tanh^3 x + 4 \frac {\tanh x} {\cosh^2 x} } {8 - \frac 8 {\cosh^2 x} + \frac 1 {\cosh^4 x} } |c = dividing top and bottom by $\cosh^4 x$ }} {{eqn|r = \frac {8 \tanh^3 x + 4 \tanh x \operatorname{sech}^2 x} {8 - 8 \operatorname{sech}^2 x + \operatorname{sech}^4 x} |c = Definition of [[Definition:Hyperbolic Secant/Definition 2|Hyperbolic Secant]] }} {{eqn|r = \frac {8 \tanh^3 x + 4 \tanh x \left({1 - \tanh^2 x}\right)} {8 - 8 \left({1 - \tanh^2 x}\right) + \left({1 - \tanh^2 x}\right)^2} |c = [[Sum of Squares of Hyperbolic Secant and Tangent]] }} {{eqn|r = \frac {4 \tanh^3 x + 4 \tanh x} {1 + 6 \tanh^2 x + \tanh^4 x} |c = multiplying out and gathering terms }} {{end-eqn}} {{qed}}	0
=== Proof of Bounds of CDF === This follows directly from the definition of $\Pr$. {{begin-eqn}} {{eqn | o = | r = S \in \Sigma | c = }} {{eqn | o = \leadsto | r = \O \subseteq S \subseteq \Omega | c = }} {{eqn | o = \leadsto | r = 0 \le \map \Pr S \le 1 | c = [[Probability Measure is Monotone]] }} {{end-eqn}} {{qed}} === Proof that CDF is Increasing === Let $x, y \in \R: x \le y$. Let $\map X \omega \le x$. Then: :$\map X \omega \le y$ and so: :$\set {\omega \in \Omega: \map X \omega \le x} \subseteq \set {\omega \in \Omega: \map X \omega \le y}$ Hence the result. {{Qed}} === Proof of Limits of CDF === As $x \to -\infty$, $\hointl \gets x \to \O$. So: :$\map {X^{-1} } {\hointl \gets x} \to \O$ and so: :$\map F x \to 0$ {{explain|this definitely needs more attention}} Similarly, as $x \to +\infty$, $\hointl \gets x \to \R$. So: :$\map {X^{-1} } {\hointl \gets x} \to \Omega$ and so: :$\map F x \to 1$ {{qed}} [[Category:Cumulative Distribution Functions]] 9035007i4x30p5byq0l4nki6caodga6	0
Consider the [[Definition:Nonhomogeneous Linear Second Order ODE|nonhomogeneous linear second order ODE]]: :$(1): \quad \dfrac {\d^2 y} {\d x^2} + \map P x \dfrac {\d y} {\d x} + \map Q x y = \map R x$ Let $\map {y_g} x$ be the [[Definition:General Solution to Differential Equation|general solution]] of the [[Definition:Homogeneous Linear Second Order ODE|homogeneous linear second order ODE]]: :$(2): \quad \dfrac {\d^2 y} {\d x^2} + \map P x \dfrac {\d y} {\d x} + \map Q x y = 0$ Let $\map {y_p} x$ be a [[Definition:Particular Solution to Differential Equation|particular solution]] of $(1)$. Then $\map {y_g} x + \map {y_p} x$ is the [[Definition:General Solution to Differential Equation|general solution]] of $(1)$.	0
The number $666$ has the following interesting property: :$\map \phi {666} = 6 \times 6 \times 6$ where $\phi$ denotes the [[Definition:Euler Phi Function|Euler $\phi$ function]].	0
Let $\sigma: \Z_{>0} \to \Z_{>0}$ be the [[Definition:Sigma Function|$\sigma$ function]], defined on the [[Definition:Strictly Positive Integer|strictly positive integers]]. The equation: :$\map \sigma n = \map \sigma {n + 1}$ is satisfied by [[Definition:Strictly Positive Integer|integers]] in the [[Definition:Integer Sequence|sequence]]: :$14, 206, 957, 1334, 1364, 1634, 2685, 2974, 4364, 14841, 18873, \ldots$ {{OEIS|A002961}}	0
:$\displaystyle \int \frac {\d x} {-\sqrt {x^2 + a^2} } = \ln \size {x - \sqrt {x^2 + a^2} } + C$	0
Note that by definition, $\map \DD {\mathbb J} \subseteq \R^{\mathbb J}$. Let $f, g \in \map \DD {\mathbb J}$. Let $\lambda \in \R$. From [[Linear Combination of Derivatives]], we have that: :$f + \lambda g$ is [[Definition:Differentiable Function|differentiable]] on $\mathbb J$. That is: :$f + \lambda g \in \map \DD {\mathbb J}$ So, by [[One-Step Vector Subspace Test]]: :$\struct {\map \DD {\mathbb J}, +, \times}_\R$ is a [[Definition:Vector Subspace|subspace]] of $\R^{\mathbb J}$. {{qed}}	0
[[File:Roots-of-Unity-as-Polygon.png|600px]] The above diagram illustrates the [[Definition:Complex Roots of Unity|$7$th roots of unity]]. {{ProofWanted}}	0
Let $N$ be a [[Definition:Neighborhood (Metric Space)|neighborhood]] of $a$ in $M$. Then by definition: :$\exists \epsilon' \in \R_{>0}: \map {B_{\epsilon'} } a \subseteq N$ where $\map {B_{\epsilon'} } a$ is the [[Definition:Open Ball|open $\epsilon'$-ball at $a$]]. From [[Open Ball in Real Number Line is Open Interval]]: :$\map {B_{\epsilon'} } a = \openint {a - \epsilon'} {a + \epsilon'}$ Let $\epsilon \in \R_{>0}: \epsilon < \epsilon'$. Then by definition of [[Definition:Closed Real Interval|closed interval]] and [[Definition:Open Real Interval|open interval]]: :$\closedint {a - \epsilon} {a + \epsilon} \subseteq \openint {a - \epsilon'} {a + \epsilon'}$ From [[Subset Relation is Transitive]]: :$\closedint {a - \epsilon} {a + \epsilon} \subseteq N$ Also by definition of [[Definition:Closed Real Interval|closed interval]] and [[Definition:Open Real Interval|open interval]]: :$\openint {a - \epsilon} {a + \epsilon} \subseteq \closedint {a - \epsilon} {a + \epsilon}$ From [[Open Real Interval is Open Ball]], $\openint {a - \epsilon} {a + \epsilon}$ is the [[Definition:Open Ball|open $\epsilon$-ball at $a$]]. Thus by definition, $\closedint {a - \epsilon} {a + \epsilon}$ is a [[Definition:Neighborhood (Metric Space)|neighborhood]] of $a$ in $M$. Hence there exists a [[Definition:Neighborhood (Metric Space)|neighborhood]] $\closedint {a - \epsilon} {a + \epsilon}$ of $a$ which is a [[Definition:Subset|subset]] of $N$. Hence the result by definition of [[Definition:Basis for Neighborhood System|basis for the neighborhood system]] of $a$. {{qed}}	0
Take any $x,y \in A_1$ such that $x \preceq_1 y$. Since $x, y \in A_1$, it follows by the definition of a [[Definition:Mapping|mapping]] that: : $\phi\left({x}\right), \phi\left({y}\right) \in A_2$ So $x \in A_1$ and $y \in A_1$ and $x \preceq_1 y$. It follows from the definition of $\preceq_2$ that: : $\phi\left({x}\right) \preceq_2 \phi\left({y}\right)$ Conversely, suppose that: : $\phi\left({x}\right) \preceq_2 \phi\left({y}\right)$ By the definition of $\preceq_2$, it follows that: : $x \preceq_1 y$ Therefore, the biconditional holds: :$x \preceq_1 y \iff \phi\left({x}\right) \preceq_2 \phi\left({y}\right)$ By definition, it follows that: : $\phi: \left({A_1, \preceq_1}\right) \to \left({A_2, \preceq_2 }\right)$ is an [[Definition:Order Isomorphism|order isomorphism]]. {{qed}}	0
{{begin-eqn}} {{eqn | l = \int \frac {\mathrm d x} {\left({\sqrt {a x^2 + b x + c} }\right)^3} | r = \int \frac {\mathrm d x} {\left({\sqrt {\frac {\left({2 a x + b}\right)^2 + 4 a c - b^2} {4 a} } }\right)^3} | c = [[Completing the Square]] }} {{eqn | r = \int \frac {8 a \sqrt a \ \mathrm d x} {\left({\sqrt {\left({2 a x + b}\right)^2 + 4 a c - b^2} }\right)^3} | c = simplifying }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = z | r = 2 a x + b }} {{eqn | ll= \implies | l = \frac {\mathrm d z} {\mathrm d x} | r = 2 a | c = [[Derivative of Power]] }} {{eqn | ll= \implies | l = \int \frac {8 a \sqrt a \ \mathrm d x} {\left({\sqrt {\left({2 a x + b}\right)^2 + 4 a c - b^2} }\right)^3} | r = \int \frac {8 a \sqrt a \ \mathrm d z} {2 a \left({\sqrt {z^2 + 4 a c - b^2} }\right)^3} | c = [[Integration by Substitution]] }} {{eqn | r = 4 \sqrt a \int \frac {\mathrm d z} {\left({\sqrt {z^2 + 4 a c - b^2} }\right)^3} | c = [[Primitive of Constant Multiple of Function]] }} {{end-eqn}} Let $4 a c - b^2 > 0$. Then: {{begin-eqn}} {{eqn | l = 4 \sqrt a \int \frac {\mathrm d z} {\left({\sqrt {z^2 + 4 a c - b^2} }\right)^3} | r = 4 \sqrt a \left({\frac z {\left({4 a c - b^2}\right) \sqrt {z^2 + 4 a c - b^2} } }\right) + C | c = [[Primitive of Reciprocal of Root of x squared plus a squared cubed|Primitive of $\dfrac 1 {\left({\sqrt {x^2 + a^2} }\right)^3}$]] }} {{end-eqn}} Let $4 a c - b^2 < 0$. Then: {{begin-eqn}} {{eqn | l = 4 \sqrt a \int \frac {\mathrm d z} {\left({\sqrt {z^2 + 4 a c - b^2} }\right)^3} | r = 4 \sqrt a \int \frac {\mathrm d z} {\left({\sqrt {z^2 - \left({b^2 - 4 a c}\right)} }\right)^3} | c = }} {{eqn | r = 4 \sqrt a \left({\frac {-z} {\left({b^2 - 4 a c}\right) \sqrt {z^2 - \left({b^2 - 4 a c}\right)} } }\right) + C | c = [[Primitive of Reciprocal of Root of x squared minus a squared cubed|Primitive of $\dfrac 1 {\left({\sqrt {x^2 - a^2} }\right)^3}$]] }} {{eqn | r = 4 \sqrt a \left({\frac z {\left({4 a c - b^2}\right) \sqrt {z^2 + 4 a c - b^2} } }\right) + C | c = simplifying }} {{end-eqn}} Thus in both cases the same result applies, and so: {{begin-eqn}} {{eqn | l = 4 \sqrt a \int \frac {\mathrm d z} {\left({\sqrt {z^2 + 4 a c - b^2} }\right)^3} | r = \frac {4 \sqrt a \left({2 a x + b}\right)} {\left({4 a c - b^2}\right) \sqrt {\left({2 a x + b}\right)^2 + 4 a c - b^2} } + C | c = substituting for $z$ and simplifying }} {{eqn | r = \frac {4 \sqrt a \left({2 a x + b}\right)} {\left({4 a c - b^2}\right) \sqrt {4 a \left({a x^2 + b x + c}\right)} } + C | c = [[Completing the Square]] }} {{eqn | r = \frac {2 \left({2 a x + b}\right)} {\left({4 a c - b^2}\right) \sqrt {a x^2 + b x + c} } + C | c = simplifying }} {{end-eqn}} {{qed}}	0
=== Necessary Condition === Let $r$ be an [[Definition:Integer|integer]]. By definition of [[Definition:Geometric Sequence|geometric sequence]], the [[Definition:Term of Geometric Sequence|terms]] of $P$ are in the form: :$a_k = b r^{k - 1}$ where $b$ and $k$ are [[Definition:Integer|integers]]. It follows from [[Integer Multiplication is Closed]] that $a_k$ is an [[Definition:Integer|integer]]. {{qed|lemma}} === Sufficient Condition === From [[Common Ratio in Integer Geometric Sequence is Rational]], $r$ is a [[Definition:Rational Number|rational number]]. Let $r$ be expressed in [[Definition:Canonical Form of Rational Number|canonical form]] as: :$r = \dfrac p q$ where, by definition of [[Definition:Canonical Form of Rational Number|canonical form]], $p \perp q$, that is, $p$ is [[Definition:Coprime Integers|coprime]] to $q$. From [[Form of Geometric Sequence of Integers]], the [[Definition:Term of Geometric Sequence|terms]] of $P$ are in the form: :$(1): \quad a_j = k q^{j - 1} p^{n - j}$ Let $a_i \divides a_j$. From [[Powers of Coprime Numbers are Coprime]]: :$(2): \quad q^{j - i} \perp p^{j - i}$ Then: {{begin-eqn}} {{eqn | l = a_i | o = \divides | r = a_j | c = }} {{eqn | ll= \leadsto | l = k q^{i - 1} p^{n - i} | o = \divides | r = k q^{j - 1} p^{n - j} | c = from $(1)$ }} {{eqn | ll= \leadsto | lo= \exists m \in \Z: | l = m \paren {k q^{j - 1} p^{n - i} } q^{j - i} | r = \paren {k q^{j - 1} p^{n - i} } p^{j - i} | c = {{Defof|Divisor of Integer}} }} {{eqn | ll= \leadsto | l = m q^{j - i} | r = p^{j - i} | c = dividing both sides by $k q^{j - 1} p^{n - i}$ }} {{eqn | ll= \leadsto | l = q^{j - i} | o = \divides | r = p^{j - i} | c = {{Defof|Divisor of Integer}} }} {{end-eqn}} But from $(2)$: :$q^{j - i} \perp p^{j - i}$ Thus $q^{j - i} \divides p^{j - i}$ can happen only when $q^{j - 1} = q = 1$. That is, when $r$ is an [[Definition:Integer|integer]]. {{qed}} [[Category:Geometric Sequences of Integers]] 3k4xydo9q8ax698lep4fppvf96to2eu	0
:$\cos x$ is [[Definition:Absolutely Convergent Series|absolutely convergent]] for all $x \in \R$.	0
From [[Power of Complex Number minus 1/Corollary|Power of Complex Number minus 1: Corollary]]: :$\displaystyle \sum_{k \mathop = 0}^{n - 1} z^k = \prod_{k \mathop = 1}^{n - 1} \paren {z - \alpha^k}$ The result follows by setting $z = 1$. {{qed}}	0
The [[Definition:P-adic Norm|$p$-adic norm]] forms a [[Definition:Norm on Division Ring|norm]] on the [[Definition:Rational Number|rational numbers]] $\Q$.	0
As all the $\left({R_k, +_k, \circ_k}\right)$ are [[Definition:Ringoid (Abstract Algebra)|ringoids]], $\circ_k$ distributes over $+_k$ for all $k$. Let $x, y, z \in R$. Then: {{begin-eqn}} {{eqn | l = x \circ \left({y + z}\right) | r = \left({x_1, x_2, \ldots, x_n}\right) \circ \left({\left({y_1, y_2, \ldots, y_n}\right) + \left({z_1, z_2, \ldots, z_n}\right)}\right) | c = }} {{eqn | r = \left({x_1, x_2, \ldots, x_n}\right) \circ \left({y_1 + z_1, y_2 + z_2, \ldots, y_n + z_n}\right) | c = }} {{eqn | r = \left({x_1 \circ \left({y_1 + z_1}\right), x_2 \circ \left({y_2 + z_2}\right), \ldots, x_n \circ \left({y_n + z_n}\right)}\right) | c = }} {{eqn | r = \left({\left({x_1 \circ z_1}\right) + \left({y_1 \circ z_1}\right), \left({x_2 \circ z_2}\right) + \left({y_2 \circ z_2}\right), \ldots, \left({x_n \circ z_n}\right) + \left({y_n \circ z_n}\right)}\right) | c = }} {{eqn | r = \left({\left({x_1 \circ z_1}\right), \left({x_2 \circ z_2}\right), \ldots, \left({x_n \circ z_n}\right)}\right) + \left({\left({y_1 \circ z_1}\right) + \left({y_2 \circ z_2}\right) + \ldots + \left({y_n \circ z_n}\right)}\right) | c = }} {{eqn | r = \left({\left({x_1, x_2, \ldots, x_n}\right) \circ \left({z_1, z_2, \ldots, z_n}\right)}\right) + \left({\left({x_1, x_2, \ldots, x_n}\right) \circ \left({z_1, z_2, \ldots, z_n}\right)}\right) | c = }} {{eqn | r = \left({x \circ y}\right) + \left({x \circ z}\right) | c = }} {{end-eqn}} In the same way: :$\left({y + z}\right) \circ x = \left({y \circ x}\right) + \left({z \circ x}\right)$ {{qed}} [[Category:External Direct Products]] [[Category:Distributive Operations]] 0wp7cqiw919zcvcopuv7m87fb8j34dw	0
:$\displaystyle \int \operatorname{sech} a x \ \mathrm d x = \frac {\arcsin \left({\tanh a x}\right)} a + C$	0
Let $\struct {\R, \size {\, \cdot \,}}$ be the [[Real Numbers with Absolute Value form Normed Vector Space|normed vector space of real numbers]]. Let $\Q$ be the [[Definition:Rational Number|set of rational numbers]]. Then $\Q$ are [[Definition:Everywhere Dense/Normed Vector Space|everywhere dense]] in $\struct {\R, \size {\, \cdot \,}}$	0
By definition of the [[Definition:Imaginary Unit|imaginary unit]] $i$: {{begin-eqn}} {{eqn | l = i^2 | r = -1 }} {{eqn | l = i^3 | r = -i }} {{eqn | l = i^4 | r = 1 }} {{end-eqn}} thus demonstrating that $U_\C$ is [[Definition:Generator of Cyclic Group|generated]] by $i$. Thus $\left({U_\C, \times}\right)$ is by definition a [[Definition:Cyclic Group|cyclic group]] of [[Definition:Order of Structure|order $4$]]. {{qed}}	0
=== [[Complex Sequence is Cauchy iff Convergent/Lemma 1|Lemma]] === {{:Complex Sequence is Cauchy iff Convergent/Lemma 1}} Let $\sequence {x_n}$ be a [[Definition:Real Sequence|real sequence]] where: :$x_n = \Re \paren {z_n}$ for every $n$ :$\Re \paren {z_n}$ is the [[Definition:Real Part|real part]] of $z_n$ Let $\sequence {y_n}$ be a [[Definition:Real Sequence|real sequence]] where: :$y_n = \Im \paren {z_n}$ for every $n$ :$\Im \paren {z_n}$ is the [[Definition:Imaginary Part|imaginary part]] of $z_n$ === Necessary Condition === Let $\sequence {z_n}$ be a [[Definition:Cauchy Sequence|Cauchy sequence]]. We aim to prove that $\sequence {z_n}$ is [[Definition:Convergent Complex Sequence|convergent]]. We find: :$\sequence {z_n}$ is a [[Definition:Cauchy Sequence|Cauchy sequence]] :$\implies \sequence {x_n}$ and $\sequence {y_n}$ are [[Definition:Real Cauchy Sequence|Cauchy sequences]] by [[Complex Sequence is Cauchy iff Convergent/Lemma 1|Lemma]] :$\implies \sequence {x_n}$ and $\sequence {y_n}$ are [[Definition:Convergent Real Sequence|convergent]] by [[Real Sequence is Cauchy iff Convergent]] :$\implies \sequence {z_n}$ is [[Definition:Convergent Complex Sequence|convergent]] by definition of [[Definition:Convergent Complex Sequence|convergent complex sequence]]. {{qed|lemma}} === Sufficient Condition === Let $\sequence {z_n}$ be [[Definition:Convergent Complex Sequence|convergent]]. We aim to prove that $\sequence {z_n}$ is a [[Definition:Cauchy Sequence|Cauchy sequence]]. We find: :$\sequence {z_n}$ is [[Definition:Convergent Complex Sequence|convergent]] :$\implies \sequence {x_n}$ and $\sequence {y_n} $ are [[Definition:Convergent Real Sequence|convergent]] by definition of [[Definition:Convergent Complex Sequence|convergent complex sequence]] :$\implies \sequence {x_n}$ and $\sequence {y_n}$ are [[Definition:Real Cauchy Sequence|Cauchy sequences]] by [[Real Sequence is Cauchy iff Convergent]] :$\implies \sequence {z_n}$ is a [[Definition:Cauchy Sequence|Cauchy sequence]] by [[Complex Sequence is Cauchy iff Convergent/Lemma 1|Lemma]] {{qed}}	0
{{ProofWanted|Resembles [[Binet's Formula for Logarithm of Gamma Function]]}}	0
From the [[Power Rule for Derivatives]]: :$\map {D_x} {x^n} = n x^{n - 1}$ As $n$ is [[Definition:Odd Integer|odd]], $n - 1$ is [[Definition:Even Integer|even]]. Thus by [[Even Power is Non-Negative]]: :$\map {D_x} {x^n} \ge 0$ for all $x$. From [[Derivative of Monotone Function]], it follows that $f_n$ is [[Definition:Increasing Real Function|increasing]] over the whole of $\R$. The only place where $\map {D_x} {x^n} = 0$ is at $x = 0$. Everywhere else, $f_n$ is [[Definition:Strictly Increasing Real Function|strictly increasing]]. By [[Sign of Odd Power]]: :$\map {f_n} x < 0 = \map {f_n} 0$ when $x < 0$ and :$\map {f_n} 0 = 0 < \map {f_n} x$ when $0 < x$. Thus $f_n$ is [[Definition:Strictly Increasing Real Function|strictly increasing]] on $\R$. {{qed}} [[Category:Real Analysis]] [[Category:Real Numbers]] [[Category:Odd Power Function is Strictly Increasing]] 3ztw3ty74w9697jql4779mtobh2zy2y	0
From the definition of the [[Definition:Real Natural Logarithm|natural logarithm]]: {{begin-eqn}} {{eqn | l = \ln x | r = \int_1^x \dfrac 1 t \ \mathrm d t }} {{end-eqn}} The result follows from [[Integral of Reciprocal is Divergent]]. {{qed}}	0
Let $\ln: \R_{>0}$ denote the [[Definition:Real Natural Logarithm|real natural logarithm]]. Then: :$\displaystyle \forall x \in \R_{>0}: \ln x = \lim_{h \mathop \to 0} \frac {x^h - 1} h$	0
:$\map {\coth^{-1} } {i x} = i \cot^{-1} x$	0
:$\map \sec {\dfrac \pi 2 - \theta} = \csc \theta$ for $\theta \ne n \pi$ where $\sec$ and $\csc$ are [[Definition:Secant Function|secant]] and [[Definition:Cosecant|cosecant]] respectively. That is, the [[Definition:Cosecant|cosecant]] of an [[Definition:Angle|angle]] is the [[Definition:Secant Function|secant]] of its [[Definition:Complement of Angle|complement]]. This relation is defined wherever $\sin \theta \ne 0$.	0
Let: {{begin-eqn}} {{eqn | l = z | r = x^2 }} {{eqn | ll= \implies | l = \frac {\mathrm d z} {\mathrm d x} | r = 2 x | c = [[Power Rule for Derivatives]] }} {{eqn | ll= \implies | l = \int x \sqrt {a^2 - x^2} \ \mathrm d x | r = \int \frac {\sqrt z \sqrt {a^2 - z} \ \mathrm d z} {2 \sqrt z} | c = [[Integration by Substitution]] }} {{eqn | r = \frac 1 2 \int \sqrt {a^2 - z} \ \mathrm d z | c = [[Primitive of Constant Multiple of Function]] }} {{eqn | r = \frac 1 2 \frac {2 \left({\sqrt {a^2 - z} }\right)^3} {-3} + C | c = [[Primitive of Root of a x + b|Primitive of $\sqrt {a x + b}$]] }} {{eqn | r = \frac {-\left({\sqrt {a^2 - x^2} }\right)^3} 3 + C | c = substituting for $z$ and simplifying }} {{end-eqn}} {{qed}}	0
Let $\overline \BB$ be the [[Definition:Extended Real Sigma-Algebra|extended real $\sigma$-algebra]]. Let $\map \BB \R$ be the [[Definition:Borel Sigma-Algebra|Borel $\sigma$-algebra]] on $\R$. Then: :$\overline \BB_\R = \map \BB \R$ where $\overline \BB_\R$ denotes a [[Definition:Trace Sigma-Algebra|trace $\sigma$-algebra]].	0
{{begin-eqn}} {{eqn | l = \sinh^{-1} \frac x a | r = \map \ln {\frac x a + \sqrt {\paren {\frac x a}^2 + 1} } | c = {{Defof|Inverse Hyperbolic Sine|subdef = Real|index = 2}} }} {{eqn | r = \map \ln {\frac x a + \sqrt {\frac {x^2 + a^2} {a^2} } } | c = }} {{eqn | r = \map \ln {\frac x a + \frac {\sqrt {x^2 + a^2} } a} | c = }} {{eqn | r = \map \ln {\frac {x + \sqrt {x^2 + a^2} } a} | c = }} {{eqn | r = \map \ln {x + \sqrt {x^2 + a^2} } - \ln a | c = [[Difference of Logarithms]] }} {{end-eqn}} {{qed}}	0
Let: {{begin-eqn}} {{eqn | l = z^2 | r = x^2 + a^2 | c = }} {{eqn | ll= \leadsto | l = 2 z \frac {\d z} {\d x} | r = 2 x | c = [[Chain Rule for Derivatives]], [[Power Rule for Derivatives]] }} {{eqn | ll= \leadsto | l = \int \frac {x \rd x} {\sqrt {x^2 + a^2} } | r = \int \frac {z \rd z} {z} | c = [[Integration by Substitution]] }} {{eqn | r = \int \rd z | c = }} {{eqn | r = z + C | c = [[Primitive of Constant]] }} {{eqn | r = \sqrt {x^2 + a^2} + C | c = substituting for $z$ }} {{end-eqn}} {{qed}}	0
By definition, the [[Definition:Real Exponential Function|exponential function]] is the [[Definition:Inverse Mapping|inverse]] of the [[Definition:Natural Logarithm|natural logarithm function]]. From [[Logarithm is Strictly Increasing]], $\ln x$ is [[Definition:Strictly Increasing Real Function|strictly increasing]]. From [[Logarithm is Strictly Concave]], $\ln x$ is [[Definition:Strictly Concave Real Function|strictly concave]]. The result follows from [[Inverse of Strictly Increasing Strictly Concave Real Function is Strictly Convex]]. {{qed}} [[Category:Exponential Function]] pa119jqwoaw6rc4k41qso9nu8eayuv8	0
A direct application of the [[Distributive Property]]: :$\dfrac m n b + \dfrac m n d = \dfrac m n \paren {b + d}$ {{qed}}	0
Let $z = x + i y$ be a [[Definition:Complex Number|complex number]]. Let $\overline z$ denote the [[Definition:Complex Conjugate|complex conjugate]] of $z$. Then the [[Definition:Unary Operation|operation]] of [[Definition:Complex Conjugation|complex conjugation]] is an [[Definition:Involution (Mapping)|involution]]: :$\overline {\paren {\overline z} } = z$	0
Let $z$ be a [[Definition:Complex Number|complex number]]. Let $\csc z$ denote the [[Definition:Complex Cosecant Function|cosecant function]] and $i$ denote the [[Definition:Imaginary Unit|imaginary unit]]: $i^2 = -1$. Then: :$\csc z = \dfrac {2 i} {e^{i z} - e^{-i z} }$	0
Let $m, n \in \Z_{> 0}$ be [[Definition:Strictly Positive Integer|(strictly) positive integers]]. Let $\struct {\Z, +}$ denote the [[Definition:Additive Group of Integers|additive group of integers]]. Let $\gen {m, n}$ be the [[Definition:Subgroup|subgroup]] of $\struct {\Z, +}$ [[Definition:Generator of Subgroup|generated]] by $m$ and $n$. Then: :$\gen {m, n} = \struct {\gcd \set {m, n} \Z, +}$ That is, the [[Definition:Additive Group of Integer Multiples|additive groups of integer multiples]] of $\gcd \set {m, n}$, where $\gcd \set {m, n}$ is the [[Definition:Greatest Common Divisor|greatest common divisor]] of $m$ and $n$.	0
Let $\R_{>0}$ be the set of [[Definition:Strictly Positive Real Number|strictly positive real numbers]], that is: :$\R_{>0} = \set {x \in \R: x > 0}$ The [[Definition:Algebraic Structure|structure]] $\struct {\R_{>0}, \times}$ forms a [[Definition:Subgroup|subgroup]] of $\struct {\R_{\ne 0}, \times}$, where $\R_{\ne 0}$ is the [[Definition:Set|set]] of [[Definition:Real Number|real numbers]] without [[Definition:Zero (Number)|zero]], that is: :$\R_{\ne 0} = \R \setminus \set 0$	0
:$\left({f + g}\right)' \left({z}\right) = f' \left({z}\right) + g' \left({z}\right)$	0
:$\dfrac {1 + \sin \theta + i \cos \theta} {1 + \sin \theta - i \cos \theta} = \sin \theta + i \cos \theta$	0
Let $x \times y = 0$. {{WLOG}}, suppose that $x \ne 0$. Then: {{begin-eqn}} {{eqn | l = x \times y | r = 0 | c = }} {{eqn | ll= \leadsto | l = \frac 1 x \times \paren {x \times y} | r = \frac 1 x \times 0 | c = as $x \ne 0$ }} {{eqn | ll= \leadsto | l = \paren {\frac 1 x \times x} \times y | r = \frac 1 x \times 0 | c = [[Definition:Real Number Axioms|Real Number Axioms: $\R M 1$: Associativity]] }} {{eqn | ll= \leadsto | l = 1 \times y | r = \frac 1 x \times 0 | c = [[Definition:Real Number Axioms|Real Number Axioms: $\R M 4$: Inverse]] }} {{eqn | ll= \leadsto | l = y | r = \frac 1 x \times 0 | c = [[Definition:Real Number Axioms|Real Number Axioms: $\R M 3$: Identity]] }} {{eqn | ll= \leadsto | l = y | r = 0 | c = [[Real Zero is Zero Element]] }} {{end-eqn}} Thus: :$x \times y = 0, x \ne 0 \implies y = 0$ [[Definition:Mutatis Mutandis|Mutatis mutandis]] :$x \times y = 0, y \ne 0 \implies x = 0$ and so: :$x \times y = 0 \implies y = 0 \lor x = 0$ So: {{begin-eqn}} {{eqn | o = | r = x \times y = 0 | c = }} {{eqn | o = \leadsto | r = \paren {x = 0} \lor \paren {y = 0} | c = }} {{eqn | o = \leadsto | r = \neg \paren {x \ne 0 \land y \ne 0} | c = [[De Morgan's Laws (Logic)/Disjunction|De Morgan's Laws: Disjunction]] }} {{end-eqn}} The result follows by the [[Rule of Transposition]]. {{qed}}	0
Let $T_\alpha = \struct {S_\alpha, \tau_\alpha}$ and $T_\beta = \struct {S_\beta, \tau_\beta}$ be [[Definition:Topological Space|topological spaces]]. Let $f: S_\alpha \to S_\beta$ be a [[Definition:Continuous Mapping (Topology)|continuous mapping]] which is an [[Definition:Injection|injection]]. If $T_\beta$ is a [[Definition:Hausdorff Space|$T_2$ (Hausdorff) space]], then $T_\alpha$ is also a [[Definition:Hausdorff Space|$T_2$ (Hausdorff) space]].	0
[[Euclid's Theorem]] states that: : For any [[Definition:Finite Set|finite set]] of [[Definition:Prime Number|prime numbers]], there exists a [[Definition:Prime Number|prime number]] not in that set. The result follows by [[Definition:Corollary|corollary]]. {{qed}}	0
Let $x \in \R_{>0}$ be a [[Definition:Strictly Positive Real Number|(strictly) positive real number]]. Let $q \in \Q$ be a [[Definition:Rational Number|rational number]]. Then: :$x^q > 0$ where $x^q$ denotes the [[Definition:Rational Power|$x$ to the power of $q$]].	0
=== Forward implication === Let $z_1, z_2, \ldots, z_n$ be [[Definition:Linearly Independent Set|linearly independent]] over the [[Definition:Rational Number|rational numbers $\Q$]]. That is, if $q_1, q_2, \ldots, q_n$ are [[Definition:Rational Number|rational numbers]] such that: :$q_1 z_1 + q_2 z_2 + \cdots + q_n z_n = 0$ then: :$q_1 = q_2 = \cdots = q_n = 0$ Let $a_1, a_2, \ldots, a_n$ be [[Definition:Integer|integers]] such that: :$a_1 z_1 + a_2 z_2 + \cdots + a_n z_n = 0$ Then, by [[Integers form Subdomain of Rationals]] and the assumption, it follows that: :$a_1 = a_2 = \cdots = a_n = 0$ Hence it follows by definition that $z_1, z_2, \ldots, z_n$ are [[Definition:Linearly Independent Set|linearly independent]] over the [[Definition:Integer|integers $\Z$]]. {{qed|lemma}} === Backward implication === Let $z_1, z_2, \ldots, z_n$ be [[Definition:Linearly Independent Set|linearly independent]] over the [[Definition:Integer|integers $\Z$]]. That is, if $a_1, a_2, \ldots, a_n$ are [[Definition:Integer|integers]] such that: :$a_1 z_1 + \cdots + a_n z_n = 0$ then: :$a_1 = \cdots = a_n = 0$ Let $q_1, q_2, \ldots, q_n$ be [[Definition:Rational Number|rational numbers]] such that: :$q_1 z_1 + q_2 z_2 + \cdots + q_n z_n = 0$ Let the [[Definition:Lowest Common Multiple of Integers|lowest common multiple]] of the [[Definition:Denominator|denominators]] of $q_1, q_2, \ldots, q_n$ be $m$. Then, by the definition of [[Definition:Lowest Common Multiple of Integers|lowest common multiple]]: :$m q_1, m q_2, \ldots, m q_n \in \Z$ Thus: :$m q_1 z_1 + m q_2 z_2 + \cdots + m q_n z_n = 0$ where the coefficients of $z_1, z_2, \ldots, z_n$ are all [[Definition:Integer|integers]]. Hence, by the assumption: :$m q_1 = m q_2 = \cdots = m q_n = 0$ Since $m$ is non-zero, it follows that: :$q_1 = q_2 = \cdots = q_n = 0$ It follows by definition that $z_1, z_2, \ldots, z_n$ are [[Definition:Linearly Independent Set|linearly independent]] over the [[Definition:Rational Number|rational numbers $\Q$]]. {{qed}} [[Category:Complex Analysis]] 1x4vc8eendh9yty7n1l49dv6nkli3k6	0
:$\sin 240 \degrees = \sin \dfrac {4 \pi} 3 = -\dfrac {\sqrt 3} 2$	0
By the definition of [[Definition:Real Number|real number]]: :$\forall \epsilon > 0 : \exists t \in \N : \forall i > t: \size {x_i - x} < \epsilon$ {{explain|In order for this line to make sense, it needs the definition (or at least the relevant part) extracted and posted here, so the context of the convergence condition is clear.}} Let $\epsilon = \size x$. This is possible because $x \ne 0$, since it is required that $\epsilon > 0$. {{begin-eqn}} {{eqn | ll= \exists t \in \N : \forall i > t : | l = \size {x_i - x} | o = < | r = \size x | c = }} {{eqn | lll=\leadsto | ll= \exists t \in \N : \forall i > t : | l = \size {x_i - x} | o = < | r = \size {x_i - x} + \size {x_i} | c = [[Triangle Inequality for Real Numbers]] }} {{eqn | lll=\leadsto | ll= \exists t \in \N : \forall i > t : | l = \size {x_i} | o = > | r = 0 | c = }} {{end-eqn}} Construct a sequence $\sequence {y_n}$ as follows: :$y_n = \begin {cases} \dfrac 1 {x_n} & n > t \\ 0 & n \le t \end {cases}$ Let $u_n$ denote the [[Definition:Heaviside Step Function|Heaviside step function]] with parameter $t$. We have: {{begin-eqn}} {{eqn | l = \eqclass {\sequence {x_n} } {} \times \eqclass {\sequence {y_n} } {} | r = \eqclass {\sequence {x_n y_n} } {} | c = }} {{eqn | r = \eqclass {\sequence {u_n} } {} | c = }} {{eqn | r = 1 | c = }} {{end-eqn}} Similarly for $\eqclass {\sequence {y_n} } {} \times \eqclass {\sequence {x_n} } {}$. So the [[Definition:Inverse Element|inverse]] of $x \in \struct {\R_{\ne 0}, \times}$ is $x^{-1} = \dfrac 1 x = y$. {{qed}} [[Category:Real Multiplication]] [[Category:Inverse Elements]] 5yxnk8q1yhk8t3wadof1vjkb4mirq68	0
It is sufficient to prove that $\lcm \set {a, b} \times \gcd \set {a, b} = a b$, where $a, b \in \Z_{>0}$. {{begin-eqn}} {{eqn | l = d | r = \gcd \set {a, b} | c = }} {{eqn | ll= \leadsto | l = d | o = \divides | r = a b | c = }} {{eqn | ll= \leadsto | lo= \exists n \in \Z_{>0}: | l = a b | r = d n | c= }} {{end-eqn}} {{begin-eqn}} {{eqn | l = d \divides a | o = \land | r = d \divides b | c = }} {{eqn | ll= \leadsto | lo= \exists u, v \in \Z: | l = a = d u | o = \land | r = b = d v | c = }} {{eqn | ll= \leadsto | l = d u b = d n | o = \land | r = a d v = d n | c = }} {{eqn | ll= \leadsto | l = n = b u | o = \land | r = n = a v | c = }} {{eqn | ll= \leadsto | l = a \divides n | o = \land | r = b \divides n | c = }} {{end-eqn}} Now we have $a \divides m \land b \divides m \implies m = a r = b s$. Also, by [[Bézout's Lemma]] we have $d = a x + b y$. So: {{begin-eqn}} {{eqn | l = m d | r = a x m + b y m | c = }} {{eqn | r = b s a x + a r b y | c = }} {{eqn | r = a b \paren {s x + r y} | c = }} {{eqn | r = d n \paren {s x + r y} | c = }} {{end-eqn}} So: :$m = n \paren {s x + r y}$ Thus: :$n \divides m \implies n \le \size m$ while: :$a b = d n = \gcd \set {a, b} \times \lcm \set {a, b}$ as required. {{qed}}	0
:$\tan i = \left({\dfrac {e^2 - 1} {e^2 + 1} }\right) i$	0
{{begin-eqn}} {{eqn | l = \cos^n \theta | r = \paren {\frac {e^{i \theta} + e^{-i \theta} } 2}^n | c = [[De Moivre's Theorem]] }} {{eqn | r = \frac {\paren {e^{i \theta} + e^{-i \theta} }^n} {2^n} | c = }} {{eqn | r = \frac 1 {2^n} \sum_{k \mathop = 0}^n \binom n k e^{\paren {n - k} i \theta} e^{-k i \theta} | c = [[Binomial Theorem]] }} {{eqn | r = \frac 1 {2^n} \sum_{k \mathop = 0}^n \binom n k e^{\paren {n - 2 k} i \theta} | c = }} {{end-eqn}} Matching up terms from the beginning of this expansion with those from the end: {{begin-eqn}} {{eqn | l = 2^n \cos^n \theta | r = e^{n i \theta} + \binom n 1 e^{\paren {n - 2} i \theta} + \binom n 2 e^{\paren {n - 4} i \theta} + \cdots | c = }} {{eqn | o = | ro= + | r = \binom n {n - 2} e^{-\paren {n - 4} i \theta} + \binom n {n - 1} e^{-\paren {n - 2} i \theta} + e^{-n i \theta} | c = }} {{eqn | ll= \leadsto | l = \frac {2 n} 2 \cos^n \theta | r = \paren {\frac {e^{n i \theta} + e^{-n i \theta} } 2} + \binom n 1 \paren {\frac {e^{\paren {n - 2} i \theta} + e^{-\paren {n - 2} i \theta} } 2} | c = }} {{eqn | o = | ro= + | r = \binom n 2 \paren {\frac {e^{\paren {n - 4} i \theta} + e^{-\paren {n - 4} i \theta} } 2} + \cdots | c = }} {{end-eqn}} Thus: :$\cos^n \theta = \dfrac 1 {2^{n - 1} } \paren {\cos n \theta + n \cos \paren {n - 2} \theta + \dfrac {n \paren {n - 1} } {2!} \cos \paren {n - 4} \theta + \cdots + R_n}$ Now to determine $R_n$. The middle two terms of the sequence $0, 1, \ldots, n$ are $\dfrac {n - 1} 2$ and $\dfrac {n + 1} 2$. Thus, when $k = \dfrac {n - 1} 2$: {{begin-eqn}} {{eqn | l = n - 2 k | r = n - 2 \frac {n - 1} 2 | c = }} {{eqn | r = n - \frac {2 n - 2} 2 | c = }} {{eqn | r = n - n + 1 | c = }} {{eqn | r = 1 | c = }} {{end-eqn}} Similarly, when $k = \dfrac {n + 1} 2$: {{begin-eqn}} {{eqn | l = n + 2 k | r = n - 2 \frac {n + 1} 2 | c = }} {{eqn | r = n - \frac {2 n + 2} 2 | c = }} {{eqn | r = n - n - 1 | c = }} {{eqn | r = -1 | c = }} {{end-eqn}} The [[Definition:Binomial Coefficient|binomial coefficient]] in each case is the same, because: {{begin-eqn}} {{eqn | l = n - \frac {n - 1} 2 | r = \frac {2 n - n - 1} 2 | c = }} {{eqn | r = \frac {n + 1} 2 | c = }} {{end-eqn}} So: {{begin-eqn}} {{eqn | l = \binom n {\paren {n - 1} / 2} | r = \frac {n!} {\paren {\frac {n - 1} 2}! \paren {\frac {n + 1} 2}!} | c = }} {{eqn | r = \binom n {\paren {n + 1} / 2} | c = }} {{end-eqn}} Thus the two middle terms collapse to: {{begin-eqn}} {{eqn | l = R_n | r = \frac {n!} {\paren {\frac {n - 1} 2}! \paren {\frac {n + 1} 2}!} \paren {\frac {e^{i \theta} + e^{-i \theta} } 2} | c = }} {{eqn | r = \frac {n!} {\paren {\frac {n - 1} 2}! \paren {\frac {n + 1} 2}!} \cos \theta | c = }} {{end-eqn}} {{qed}}	0
Let $x, y \in Y_i$. Then for all $j \in I \setminus \set i$: :$x_j = z_j = y_j$ Let $\map {p_i} x = \map {p_i} y$. Then: :$x_i = y_i$ Thus: :$x = y$ It follows that $p_i$ is an [[Definition:Injection|injection]] by definition.	0
From [[Sine of Complex Number]]: :$\sin \paren {x + i y} = \sin x \cosh y + i \cos x \sinh y$ The result follows by definition of the [[Definition:Imaginary Part|imaginary part]] of a [[Definition:Complex Number|complex number]]. {{qed}}	0
The proof proceeds by [[Principle of Mathematical Induction|induction]]. First let: :$S := \left\{ {a_i: R \left({i}\right)}\right\}$ We have that $S$ is [[Definition:Finite Set|finite]]. Hence the contents of $S$ can be [[Definition:Well-Ordered Set|well-ordered]], by [[Finite Totally Ordered Set is Well-Ordered]]. Let $S$ have $m$ [[Definition:Element|elements]], identified as: :$S = \left\{ {s_1, s_2, \ldots, s_m}\right\}$ For all $n \in \Z_{\ge 0}$ such that $n \le m$, let $P \left({n}\right)$ be the [[Definition:Proposition|proposition]]: :$\displaystyle \log_b \left({\prod_{i \mathop = 1}^n s_i}\right) = \sum_{i \mathop = 1}^n \log_b s_i$ $P \left({0}\right)$ is the case: {{begin-eqn}} {{eqn | l = \log_b \left({\prod_{i \mathop = 1}^0 s_i}\right) | r = \log_b 1 | c = {{Defof|Vacuous Product}} }} {{eqn | r = 0 | c = [[Logarithm of 1 is 0]] }} {{eqn | r = \sum_{i \mathop = 1}^n \log_b s_i | c = {{Defof|Vacuous Summation}} }} {{end-eqn}} === Basis for the Induction === $P \left({1}\right)$ is the case: {{begin-eqn}} {{eqn | l = \log_b \left({\prod_{i \mathop = 1}^1 s_i}\right) | r = \log_b s_1 | c = {{Defof|Product Notation (Algebra)|Product}} }} {{eqn | r = \sum_{i \mathop = 1}^1 \log_b s_i | c = {{Defof|Summation}} }} {{end-eqn}} This is the [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that, if $P \left({k}\right)$ is true, where $k \ge 1$, then it logically follows that $P \left({k + 1}\right)$ is true. So this is the [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$\displaystyle \log_b \left({\prod_{i \mathop = 1}^k s_i}\right) = \sum_{i \mathop = 1}^k \log_b s_i$ from which it is to be shown that: :$\displaystyle \log_b \left({\prod_{i \mathop = 1}^{k + 1} s_i}\right) = \sum_{i \mathop = 1}^{k + 1} \log_b s_i$ === Induction Step === This is the [[Principle of Mathematical Induction#Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \log_b \left({\prod_{i \mathop = 1}^{k + 1} s_i}\right) | r = \log_b \left({\left({\prod_{i \mathop = 1}^k s_i}\right) \times s_{k + 1} }\right) | c = {{Defof|Product Notation (Algebra)|Product}} }} {{eqn | r = \log_b \left({\prod_{i \mathop = 1}^k s_i}\right) + \log_b s_{k + 1} | c = [[Sum of General Logarithms]] }} {{eqn | r = \sum_{i \mathop = 1}^k \log_b s_i + \log_b s_{k + 1} | c = [[Summation of General Logarithms#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \sum_{i \mathop = 1}^{k + 1} \log_b s_i | c = {{Defof|Summation}} }} {{end-eqn}} So $P \left({k}\right) \implies P \left({k + 1}\right)$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\displaystyle \log_b \left({\prod_{i \mathop = 1}^n s_i}\right) = \sum_{i \mathop = 1}^n \log_b s_i$ Hence, by definition of $S$: :$\displaystyle \log_b \left({\prod_{R \left({i}\right)} a_i}\right) = \sum_{R \left({i}\right)} \log_b a_i$ {{qed}}	0
{{begin-eqn}} {{eqn | l = \csc 15^\circ | r = \frac 1 {\sin 15^\circ} | c = [[Cosecant is Reciprocal of Sine]] }} {{eqn | r = \frac 1 {\frac {\sqrt 6 - \sqrt 2} 4} | c = [[Sine of 15 Degrees]] }} {{eqn | r = \frac 4 {\sqrt 6 - \sqrt 2} | c = multiplying top and bottom by $4$ }} {{eqn | r = \frac {4 \left({\sqrt 6 + \sqrt 2}\right)} {\left({\sqrt 6 - \sqrt 2}\right) \left({\sqrt 6 + \sqrt 2}\right)} | c = multiplying top and bottom by $\sqrt 6 + \sqrt 2$ }} {{eqn | r = \frac {4 \left({\sqrt 6 + \sqrt 2}\right)} {6 - 2} | c = [[Difference of Two Squares]] }} {{eqn | r = \sqrt 6 + \sqrt 2 | c = simplifying }} {{end-eqn}} {{qed}}	0
:$\displaystyle \int \frac {\cos^m a x} {\sin^n a x} \rd x = \frac {-\cos^{m + 1} a x} {a \paren {n - 1} \sin^{n - 1} a x} - \frac {m - n + 2} {n - 1} \int \frac {\cos^m a x} {\sin^{n - 2} a x} \rd x + C$	0
This proof depends on the [[Definition:Exponential Function/Real/Limit of Sequence|limit definition of the exponential function]]. Let: :$\displaystyle \map \exp x = \lim_{n \mathop \to \infty} \paren {1 + \dfrac x n}^n$ Fix $x_0 \in \R$. Consider $I := \closedint {x_0 - 1} {x_0 + 1}$. From [[Closed Bounded Subset of Real Numbers is Compact]], $I$ is compact. From [[Exponential Sequence is Uniformly Convergent on Compact Sets]]: :$\paren {1 + \dfrac x n}^n$ is [[Definition:Uniform Convergence/Metric Space|uniformly convergent]] on $I$. By the [[Uniform Limit Theorem]]: :$\displaystyle \lim_{n \mathop \to \infty} \paren {1 + \dfrac x n}^n = \exp$ is continuous on $I$. In particular, $\map \exp x$ is continuous at $x_0$. {{qed}}	0
$27$ is the smallest [[Definition:Positive Integer|positive integer]] the [[Definition:Decimal Expansion|decimal expansion]] of whose [[Definition:Reciprocal|reciprocal]] has a [[Definition:Period of Recurrence|period]] of $3$: :$\dfrac 1 {27} = 0 \cdotp \dot 03 \dot 7$ {{OEIS|A021027}}	0
The smallest [[Definition:Positive Integer|positive integer]] which is the [[Definition:Integer Addition|sum]] of $4$ [[Definition:Distinct|distinct]] [[Definition:Ordered Triple|ordered triples]], each of which has the same [[Definition:Integer Multiplication|product]], is $118$: {{begin-eqn}} {{eqn | l = 118 | r = 14 + 50 + 54 }} {{eqn | r = 15 + 40 + 63 | c = }} {{eqn | r = 18 + 30 + 70 | c = }} {{eqn | r = 21 + 25 + 72 | c = }} {{end-eqn}}	0
Let $I$ be a [[Definition:Non-Empty Set|non-empty]] [[Definition:Real Interval|real interval]] such that one of these holds: : $I = \left({a \,.\,.\, b}\right)$ : $I = \left[{a \,.\,.\, b}\right)$ : $I = \left({a \,.\,.\, b}\right]$ : $I = \left[{a \,.\,.\, b}\right]$ Let $I^-$ denote the [[Definition:Closure (Topology)|closure]] of $I$. Then $I^-$ is the [[Definition:Closed Real Interval|closed real interval]] $\left[{a \,.\,.\, b}\right]$.	0
We have by definition that $\Z \sqbrk i \subseteq \C$. Let $a, b \in \Z \sqbrk i$. We have from [[Modulus of Product]] that $\cmod a \cdot \cmod b = \cmod {a b}$. From [[Complex Modulus is Non-Negative]]: :$\forall a \in \C: \cmod a \ge 0$ and: :$\cmod a = 0 \iff a = 0$ Let $a = x + i y$. Suppose $a \in \Z \sqbrk i \ne 0$. Then $x \ne 0$ or $y \ne 0$ and $x^2 \ge 1$ or $y^2 \ge 1$. So: :$\cmod a \ge 1$ Similarly, $b \in \Z \sqbrk i, b \ne 0 \implies \cmod b \ge 1$. Thus it follows that $\cmod {a b} \ge \cmod a$ and so $\nu$ is a [[Definition:Euclidean Valuation|Euclidean valuation]] on $\Z \left[{i}\right]$. {{finish|definition of Euclidean valuation requires codomain $\N$, consider modulus squared instead}} Now, consider $x, y \in \Z \sqbrk i$. We want to find $q, r \in \Z \sqbrk i$ such that $x = q y + r$. Note that this means we want $r = y \paren {\dfrac x y - q}$ where $\dfrac x y$ is [[Definition:Complex Number|complex]] but not necessarily [[Definition:Gaussian Integer|Gaussian]]. We [[Definition:Extension of Mapping|extend]] $\nu$ to the [[Definition:Complex Number|complex numbers]] and define $\nu: \C \to \C$ as: :$\forall z \in \C: \map \nu z = \cmod z$ Then we have: :$\map \nu r = \map \nu y \cdot \map \nu {\dfrac x y - q}$ Thus if $\map \nu {\dfrac x y - q} < 1$ we have: :$\map \nu r < \map \nu y$ Consider the point $P = \dfrac x y$ as a point on the [[Definition:Complex Plane|complex plane]]. Let $Q$ lie at a point representing the [[Definition:Gaussian Integer|Gaussian integer]] $q$ which lies closest to $P$. The distance $P Q$ is at most half the length of a diagonal of a unit square in the complex plane. Thus: :$\map \nu {\dfrac x y - q} = \cmod {\dfrac x y - q} \le \dfrac {\sqrt 2} 2 = \dfrac 1 {\sqrt 2} < 1$ This element $q$ and the element $r$, where $\map \nu r < \map \nu y$, are the required values. Thus $\Z \sqbrk i$ is a [[Definition:Euclidean Domain|Euclidean domain]]. {{qed}} {{Improve}}	0
The following values of the [[Definition:Secant Function|secant function]] can be expressed as exact [[Definition:Algebraic Number|algebraic numbers]]. This list is non-exhaustive. === [[Secant of Zero]] === {{:Secant of Zero}} === [[Secant of 15 Degrees|Secant of $15 \degrees$]] === {{:Secant of 15 Degrees}} === [[Secant of 30 Degrees|Secant of $30 \degrees$]] === {{:Secant of 30 Degrees}} === [[Secant of 45 Degrees|Secant of $45 \degrees$]] === {{:Secant of 45 Degrees}} === [[Secant of 60 Degrees|Secant of $60 \degrees$]] === {{:Secant of 60 Degrees}} === [[Secant of 75 Degrees|Secant of $75 \degrees$]] === {{:Secant of 75 Degrees}} === [[Secant of Right Angle]] === {{:Secant of Right Angle}} === [[Secant of 105 Degrees|Secant of $105 \degrees$]] === {{:Secant of 105 Degrees}} === [[Secant of 120 Degrees|Secant of $120 \degrees$]] === {{:Secant of 120 Degrees}} === [[Secant of 135 Degrees|Secant of $135 \degrees$]] === {{:Secant of 135 Degrees}} === [[Secant of 150 Degrees|Secant of $150 \degrees$]] === {{:Secant of 150 Degrees}} === [[Secant of 165 Degrees|Secant of $165 \degrees$]] === {{:Secant of 165 Degrees}} === [[Secant of Straight Angle]] === {{:Secant of Straight Angle}} === [[Secant of 195 Degrees|Secant of $195 \degrees$]] === {{:Secant of 195 Degrees}} === [[Secant of 210 Degrees|Secant of $210 \degrees$]] === {{:Secant of 210 Degrees}} === [[Secant of 225 Degrees|Secant of $225 \degrees$]] === {{:Secant of 225 Degrees}} === [[Secant of 240 Degrees|Secant of $240 \degrees$]] === {{:Secant of 240 Degrees}} === [[Secant of 255 Degrees|Secant of $255 \degrees$]] === {{:Secant of 255 Degrees}} === [[Secant of Three Right Angles]] === {{:Secant of Three Right Angles}} === [[Secant of 285 Degrees|Secant of $285 \degrees$]] === {{:Secant of 285 Degrees}} === [[Secant of 300 Degrees|Secant of $300 \degrees$]] === {{:Secant of 300 Degrees}} === [[Secant of 315 Degrees|Secant of $315 \degrees$]] === {{:Secant of 315 Degrees}} === [[Secant of 330 Degrees|Secant of $330 \degrees$]] === {{:Secant of 330 Degrees}} === [[Secant of 345 Degrees|Secant of $345 \degrees$]] === {{:Secant of 345 Degrees}} === [[Secant of Full Angle]] === {{:Secant of Full Angle}}	0
Let $n = p + q$ where $p \le q$ and both $p$ and $q$ are [[Definition:Prime Number|primes]]. There can be no more different representations of $n$ as $p + q$ than there are the number of possible options for $q$. As $q \ge p$, it follows that $q \ge \dfrac n 2$. Note that as $p \ge 2$, it follows that $q \le n - 2$. The number of possible values of $q$ is therefore equal to the number of [[Definition:Prime Number|primes]] between $\dfrac n 2$ and $n - 2$ inclusive. That is, the number of [[Definition:Prime Number|primes]] in the [[Definition:Closed Real Interval|interval]] $\closedint {\dfrac n 2} {n - 2}$. Hence the result. {{qed}}	0
:$\arccot a + \arccot b = \arccot \dfrac {a b - 1} {a + b}$ where $\arccot$ denotes the [[Definition:Arccotangent|arccotangent]].	0
Let $T_A = \struct {S_A, \tau_A}$ and $T_B = \struct {S_B, \tau_B}$ be [[Definition:Topological Space|topological spaces]]. Let $\phi: T_A \to T_B$ be a [[Definition:Surjection|surjective]] [[Definition:Open Mapping|open mapping]] which is also [[Definition:Everywhere Continuous Mapping (Topology)|continuous]]. If $T_A$ is [[Definition:Second-Countable Space|second-countable]], then $T_B$ is also [[Definition:Second-Countable Space|second-countable]].	0
Let $z_1 = \left\langle{r_1, \theta_1}\right\rangle$ and $z_2 = \left\langle{r_2, \theta_2}\right\rangle$ be [[Definition:Polar Form of Complex Number|complex numbers expressed in polar form]]. Let $z_1$ and $z_2$ be represented on the [[Definition:Complex Plane|complex plane]] $\C$ in [[Definition:Complex Number as Vector|vector form]]. Let $z = z_1 z_2$ be the [[Definition:Complex Multiplication|product]] of $z_1$ and $z_2$. Then $z$ can be interpreted as the result of: : rotating $z_1$ about the [[Definition:Origin|origin]] of $\C$ by $\theta_2$ in the [[Definition:Positive Direction|positive direction]] : multiplying the [[Definition:Complex Modulus|modulus]] of $z_1$ by $r_2$.	0
As $p$ and $q$ are [[Definition:Distinct|distinct]] [[Definition:Prime Number|prime numbers]], it follows that $p$ and $q$ are [[Definition:Coprime Integers|coprime]]. Thus by [[Euler Phi Function is Multiplicative]]: :$\map \phi n = \map \phi p \, \map \phi q$ From [[Euler Phi Function of Prime]]: :$\map \phi p = p - 1$ :$\map \phi q = q - 1$ Hence the result. {{qed}}	0
:$n \divides 0$	0
Let $a, b \in A_p$. Then $a = \dfrac {p n_1} {d_1}, b = \dfrac {p n_1} {d_1}$ where: :$n_1, n_2 \in \Z$ :$d_1, d_2 \in \Z_{>0}$ :$p n_1 \perp d_1, p n_2 \perp d_2$ Then: {{begin-eqn}} {{eqn | l = a + b | r = \frac {p n_1} {d_1} + \frac {p n_2} {d_2} | c = }} {{eqn | r = \frac {p n_1 d_2 + p n_2 d_1} {d_1 d_2} | c = {{Defof|Rational Addition}} }} {{eqn | r = \frac {p \left({n_1 d_2 + n_2 d_1}\right)} {d_1 d_2} | c = }} {{end-eqn}} From [[Euclid's Lemma for Prime Divisors]], if $p \divides d_1 d_2$ then either $p \divides d_1$ or $p \divides d_2$. But neither of these is the case, so $p \nmid d_1 d_2$. Hence by [[Prime not Divisor implies Coprime]]: :$p \perp d_1 d_2$ where $\perp$ denotes [[Definition:Coprime Integers|coprimeness]]. So when $\dfrac {p \left({n_1 d_2 + n_2 d_1}\right)} {d_1 d_2}$ is expressed in [[Definition:Canonical Form of Rational Number|canonical form]], $p$ will still be a [[Definition:Divisor of Integer|divisor]] of the [[Definition:Numerator|numerator]]. Hence the result. {{qed}}	0
{{begin-eqn}} {{eqn | l = \map \cosh {a + b i} | r = \cosh a \map \cosh {b i} + \sinh a \map \sinh {b i} | c = [[Hyperbolic Cosine of Sum]] }} {{eqn | r = \cosh a \cos b + \sinh a \map \sinh {b i} | c = [[Cosine in terms of Hyperbolic Cosine]] }} {{eqn | r = \cosh a \cos b + i \sinh a \sin b | c = [[Sine in terms of Hyperbolic Sine]] }} {{end-eqn}} {{qed}}	0
The [[Definition:Integer|integer]] [[1|$1$ (one)]] is not a [[Definition:Prime Number|prime number]].	0
The [[Definition:Real Secant Function|(real) secant function]] has a [[Definition:Taylor Series|Taylor series expansion]]: {{begin-eqn}} {{eqn | l = \sec x | r = \sum_{n \mathop = 0}^\infty \paren {-1}^n \frac {E_{2 n} x^{2 n} } {\paren {2 n}!} }} {{eqn | r = 1 + \frac {x^2} 2 + \frac {5 x^4} {24} + \frac {61 x^6} {720} + \cdots }} {{end-eqn}} where $E_{2 n}$ denotes the [[Definition:Euler Numbers|Euler numbers]]. This [[Definition:Convergent Series|converges]] for $\size x < \dfrac \pi 2$.	0
Let $\Gamma$ denote the [[Definition:Gamma Function|Gamma function]]. Then: :$\map {\Gamma'} 1 = -\gamma$ where: :$\map {\Gamma'} 1$ denotes the [[Definition:Derivative|derivative]] of the [[Definition:Gamma Function|Gamma function]] evaluated at $1$ :$\gamma$ denotes the [[Definition:Euler-Mascheroni Constant|Euler-Mascheroni constant]].	0
The $3$rd [[Definition:Hardy-Ramanujan Number|Hardy-Ramanujan number]] $\operatorname {Ta} \left({3}\right)$ is $87 \, 539 \, 319$: {{begin-eqn}} {{eqn | l = 87 \, 539 \, 319 | r = 167^3 + 436^3 | c = }} {{eqn | r = 228^3 + 423^3 | c = }} {{eqn | r = 255^3 + 414^3 | c = }} {{end-eqn}}	0
By [[Existence of Laurent Series]], there exists a [[Definition:Laurent Series|Laurent series]]: :$\displaystyle \map f z = \sum_{n \mathop = -\infty}^\infty c_n \paren {z - a}^n$ convergent on $D \setminus \set a$. As $f$ has a pole of order $N$ at $a$, we have $c_n = 0$ for $n < -N$. So: :$\displaystyle \paren {z - a}^N \map f z = \sum_{n \mathop = -N}^\infty c_n \paren {z - a}^{n + N}$ Which can be rewritten: :$\displaystyle \paren {z - a}^N \map f z = \sum_{n \mathop = 0}^\infty c_{n - N} \paren {z - a}^n$ Note that this is a [[Definition:Taylor Series|Taylor series]] with centre $a$. By the [[Definition:Residue (Complex Analysis)|definition of a residue]]: :$\displaystyle \Res f a = c_{-1}$ This corresponds to the $\paren {N - 1}$th in the Taylor series of $\paren {z - a}^N \map f z$ about $a$. We therefore have by [[Taylor Series of Holomorphic Function]]: :$\displaystyle c_{-1} = \frac 1 {\paren {N - 1}!} \lim_{z \mathop \to a} \frac { \d^{N - 1} } { \d z^{N - 1} } \paren {\paren {z - a}^N \map f z}$ Hence the result. {{qed}} [[Category:Complex Analysis]] hsgyngvd2qagmuo7wyg4mdhcjcyobuj	0
Let $\N_{> 0}$ be the [[Definition:Natural Numbers|1-based natural numbers]]: :$\N_{> 0} = \left\{{1, 2, 3, \ldots}\right\}$ Then: :$\forall n \in \N_{> 0}: n \ne n + 1$	0
The smallest $18$ [[Definition:Prime Number|primes]] in [[Definition:Arithmetic Sequence|arithmetic sequence]] are: :$107\,928\,278\,317 + 9\,922\,782\,870 n$ for $n = 0, 1, \ldots, 16$.	0
Let $j$ be the largest [[Definition:Integer|integer]] such that: :$j m \le x y$ Let $p$ be the largest [[Definition:Integer|integer]] such that: :$p m \le y z$ By definition of [[Definition:Modulo Multiplication|multiplication modulo $m$]]: :$x \cdot_m y = x y - j m$ :$y \cdot_m z = y z - p m$ Let $k$ be the largest [[Definition:Integer|integer]] such that: :$k m \le \paren {x y - j m} z$ Let $q$ be the largest [[Definition:Integer|integer]] such that: :$q m \le x \paren {y z - p m}$ Then: :$\paren {j z + k} m \le \paren {x y} z$ :$\paren {q + x p} m \le x \paren {y z}$ Thus: {{begin-eqn}} {{eqn | l = \paren {x \cdot_m y} \cdot_m z | r = \paren {x y - j m} z - k m | c = {{Defof|Modulo Multiplication}} }} {{eqn | l = x \cdot_m \paren {y \cdot_m z} | r = x \left({y z - p m}\right) - q m | c = {{Defof|Modulo Multiplication}} }} {{end-eqn}} But suppose that there exists an [[Definition:Integer|integer]] $s$ such that: :$s m \le \paren {x y} z$ and: :$j z + k < s$ Then: :$\paren {j z + k + 1} m \le \paren {x y} z$ from which: :$\paren {k + 1} m \le \paren {x y - j m} z$ But this contradicts the definition of $k$. Thus $j z + k$ is the largest of those [[Definition:Integer|integers]] $i$ such that $i m \le \paren {x y} z$. Similarly, $q + x p$ is the largest of those [[Definition:Integer|integers]] $i$ such that $i m \le x \paren {y z}$. From [[Integer Multiplication is Associative]]: :$\paren {x y} z = x \paren {y z}$ Thus $j z + k = q + x p$ and so: {{begin-eqn}} {{eqn | l = \paren {x \cdot_m y} \cdot_m z | r = \paren {x y - j m} z - k m | c = {{Defof|Modulo Multiplication}} }} {{eqn | r = x y z - \paren {j z + k} m | c = }} {{eqn | r = x y z - \paren {q + x p} m | c = }} {{eqn | r = x \paren {y z - p m} - q m | c = }} {{eqn | r = x \cdot_m \paren {y \cdot_m z} | c = {{Defof|Modulo Multiplication}} }} {{end-eqn}} {{qed}}	0
Let $H_n^{\paren r}$ denote the [[Definition:General Harmonic Numbers|general harmonic number]]: :$\displaystyle H_n^{\paren r} = \sum_{k \mathop = 1}^n \frac 1 {k^r}$ for $r \in \R_{>0}$. Let $r > 1$. Then as $n \to \infty$, $H_n^{\paren r}$ is [[Definition:Convergent Series of Numbers|convergent]] with an [[Definition:Upper Bound|upper bound]] of $\dfrac {2^{r - 1} } {2^{r - 1} - 1}$.	0
By [[Cardinal Number Less than Ordinal/Corollary|Cardinal Number Less than Ordinal: Corollary]]: :$\left\vert{\omega}\right\vert \le \omega$ Moreover, for any $n \in \omega$, by [[Cardinal of Finite Ordinal]]: :$\left\vert{n}\right\vert < \left\vert{n+1}\right\vert \le \left\vert{\omega}\right\vert$ Thus by [[Cardinal of Finite Ordinal]]: : $n \in \left\vert{\omega}\right\vert$ Therefore: : $\omega = \left\vert{\omega}\right\vert$ By [[Cardinal of Cardinal Equal to Cardinal/Corollary|Cardinal of Cardinal Equal to Cardinal: Corollary]]: : $\omega \in \mathcal N’$ {{qed}} [[Category:Cardinals]] [[Category:Minimal Infinite Successor Set]] encs8nywgu8r7y5ek5ygnq7v3r0hw6l	0
Let $\N$ be the [[Definition:Natural Numbers|natural numbers]]. Let $+$ be [[Definition:Natural Number Addition|addition]] on $\N$. Then: :$\forall a, b, c \in \N: a + c = b + c \implies a = b$ :$\forall a, b, c \in \N: a + b = a + c \implies b = c$ That is, $+$ is [[Definition:Cancellable Operation|cancellable]] on $\N$.	0
The only [[Definition:Integer|integer]] whose [[Definition:Square (Algebra)|square]] and [[Definition:Cube (Algebra)|cube]] use each of the [[Definition:Digit|digits]] from $0$ to $9$ exactly once each is $69$.	0
Let $n \in \Z_{>0}$ be a [[Definition:Positive Integer|positive integer]]. For all $k \in \set {1, 2, \dotsc, n}$, let: :$z_k = r_k e^{i \theta_k}$ be [[Definition:Complex Zero|non-zero]] [[Definition:Complex Number|complex numbers]] in [[Definition:Exponential Form of Complex Number|exponential form]]. Let: :$r e^{i \theta} = \displaystyle \sum_{k \mathop = 1}^n z_k = z_1 + z_2 + \dotsb + z_k$ Then: {{begin-eqn}} {{eqn | l = r | r = \sqrt {\displaystyle \sum_{k \mathop = 1}^n r_k + \displaystyle \sum_{1 \mathop \le j \mathop < k \mathop \le n} 2 {r_j} {r_k} \, \map \cos {\theta_j - \theta_k} } }} {{eqn | l = \theta | r = \map \arctan {\dfrac {r_1 \sin \theta_1 + r_2 \sin \theta_2 + \dotsb + r_n \sin \theta_n} {r_1 \cos \theta_1 + r_2 \cos \theta_2 + \dotsb + r_n \cos \theta_n} } }} {{end-eqn}}	0
Let $\struct {\Q, \tau_d}$ be the [[Definition:Rational Number Space|rational number space]] formed by the [[Definition:Rational Number|rational numbers]] $\Q$ under the [[Definition:Euclidean Topology on Real Number Line|usual (Euclidean) topology]] $\tau_d$. Then $\tau_d$ forms a [[Definition:Topology|topology]].	0
Let $T = \struct {G, \circ, \tau}$ be a [[Definition:Topological Group|topological group]]. Let $\phi: G \to G$ be the [[Definition:Inversion Mapping|inversion mapping]] of $T$. Then $\phi$ is a [[Definition:Homeomorphism|homeomorphism]].	0
Using the [[Axiom:Axiomatization of 1-Based Natural Numbers|axiomatization]]: {{:Axiom:Axiomatization of 1-Based Natural Numbers}} For all $n \in \N_{> 0}$, let $P \left({n}\right)$ be the [[Definition:Proposition|proposition]]: :$n + 1 = 1 + n$ === Basis for the Induction === Setting $n = 1$ we have that: :$1 + 1 = 1 + 1$ and so $P \left({1}\right)$ holds trivially. This is our [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $P \left({k}\right)$ is true, where $k \ge 1$, then it logically follows that $P \left({k + 1}\right)$ is true. So this is our [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$k + 1 = 1 + k$ Then we need to show: :$\left({k + 1}\right) + 1 = 1 + \left({k + 1}\right)$ === Induction Step === This is our [[Principle of Mathematical Induction#Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = 1 + \left({k + 1}\right) | r = \left({1 + k}\right) + 1 | c = [[Axiom:Axiomatization of 1-Based Natural Numbers|Axiom $C$]] }} {{eqn | r = \left({k + 1}\right) + 1 | c = [[Natural Number Commutes with 1 under Addition#Induction Hypothesis|Induction Hypothesis]] }} {{end-eqn}} So $P \left({k}\right) \implies P \left({k + 1}\right)$ and the result follows by the [[Principle of Mathematical Induction]]. {{qed}} </onlyinclude>	0
By [[Reciprocal Function is Strictly Decreasing]], the reciprocal function is [[Definition:Strictly Decreasing Mapping|strictly decreasing]]. Thus :$x \le y \implies \dfrac 1 y \le \dfrac 1 x$ Suppose then that $\dfrac 1 y \le \dfrac 1 x$. If $x, y > 0$, then from [[Reciprocal of Strictly Positive Real Number is Strictly Positive]]: $\dfrac 1 y, \dfrac 1 x > 0$ Similarly, if $x, y < 0$ or $x, y > 0$, then from [[Reciprocal of Strictly Negative Real Number is Strictly Negative]]: :$\dfrac 1 y, \dfrac 1 x < 0$ Thus we can apply the above to show that: :$\dfrac 1 {1/x} \le \dfrac 1 {1/y}$ By [[Inverse of Multiplicative Inverse]]: :$x \le y$ {{qed}}	0
Because $\displaystyle \prod_{n \mathop = 1}^\infty \left({1 + a_n}\right)$ is [[Definition:Absolutely Convergent Product|absolutely convergent]], $\displaystyle \sum_{n \mathop = 1}^\infty a_n$ is [[Definition:Absolutely Convergent Series|absolutely convergent]]. By [[Terms in Convergent Series Converge to Zero]], $a_n\to0$. {{qed}}	0
From [[Square of Small-Digit Palindromic Number is Palindromic/Examples/11|Square of 11 is Palindromic]]: :$11^2 = 121$ Thus: <pre> 121 x 11 ----- 121 1210 ----- 1331 </pre>{{qed}}	0
Let a [[Definition:Point|point]] $P = \tuple {x, y}$ be placed in a [[Definition:Cartesian Plane|cartesian plane]] with [[Definition:Origin|origin]] $O$ such that $OP$ forms an [[Definition:Angle|angle]] $\theta$ with the [[Definition:X-Axis|$x$-axis]]. Then: {{begin-eqn}} {{eqn | l = \frac {\cos \theta} {\sin \theta} | r = \frac {x / r} {y / r} | c = [[Cosine of Angle in Cartesian Plane]] and [[Sine of Angle in Cartesian Plane]] }} {{eqn | r = \frac x r \frac r y | c = }} {{eqn | r = \frac x y | c = }} {{eqn | r = \cot \theta | c = [[Cotangent of Angle in Cartesian Plane]] }} {{end-eqn}} When $\sin \theta = 0$ the expression $\dfrac {\cos \theta} {\sin \theta}$ is not defined. {{qed}}	0
Let $M$ be both [[Definition:Complete Metric Space|complete]] and [[Definition:Totally Bounded Metric Space|totally bounded]]. Let $\left \langle{a_k}\right \rangle$ be any [[Definition:Infinite Sequence|infinite sequence]] in $A$. Let $\epsilon \in \R_{>0}$. Let $x_1, \ldots, x_n \in X$ be a [[Definition:Finite Set|finite set]] of points such that: :$\displaystyle A = \bigcup_{i \mathop = 1}^n B_\epsilon \left({x_i}\right)$ where $B_\epsilon \left({x_i}\right)$ represents the [[Definition:Open Ball of Metric Space|open $\epsilon$-ball]] of $x_i$. This is known to exist as $M$ is [[Definition:Totally Bounded Metric Space|totally bounded]]. Then for every $k \in \N$, there is some $j_k \in \left\{{0, \dots, n}\right\}$ such that $d \left({a_k, x_{j_k}}\right) \le \epsilon$. For some $j \in \left\{{0, \dots, n}\right\}$, we must have $j_k = j$ for infinitely many $k$, and it follows by setting $x := x_{j_k}$. Setting $x := x_{j_k}$, we see that: :$(1): \quad$ There is some $x \in X$ such that $d \left({a_k, x}\right) \le \epsilon$ for infinitely many $k$. Now let $\left \langle{a_k}\right \rangle$ be any [[Definition:Infinite Sequence|infinite sequence]] in $A$. By $(1)$, there is some $x_1 \in X$ such that $d \left({a_k, x_1}\right) \le 1/2$ for infinitely many $k$. {{AxiomReview|use only [[Axiom:Axiom of Countable Choice|axiom of countable choice]], not [[Axiom:Axiom of Dependent Choice|axiom of dependent choice]]<br>Keep this in case someone out there can figure out a way to fix this without making it like [[Complete and Totally Bounded Metric Space is Sequentially Compact/Proof 1|Proof 1]]}} Now we can apply $(1)$ to the [[Definition:Subsequence|subsequence]] of $\left \langle{a_k}\right \rangle$ which consisting of those elements for which $d \left({a_k, x_1}\right) \le 1/2$. Thus we can find $x_2 \in A$ such that infinitely many $k$ satisfy both $d \left({a_k, x_2}\right) \le 1/4$ and $d \left({a_k, x_1}\right) \le 1/2$. Now we proceed [[Principle of Mathematical Induction|inductively]], to obtain a sequence $\left \langle {x_m}\right \rangle$ with the property that there exist infinitely many $k$ such that, for $1 \le j \le m$: :$(2) \quad d \left({a_k, x_j}\right) \le 2^{-j}$ Now define a subsequence $\left \langle {a_{k_m}}\right \rangle$ inductively by letting $k_0$ be arbitrary, and choosing $k_{m+1}$ minimal such that $k_{m+1} > k_m$ and such that $(2)$ holds for $k = k_m$ and all $1 \le j \le m$. Let $\epsilon > 0$, and choose $n$ sufficiently large that $1/2^{n-1} < \epsilon$. Then: :$d \left({a_{k_r}, a_{k_s}}\right) \le d \left({a_{k_r}, x_n}\right) + d \left({a_{k_s}, x_n}\right) \le 2 \cdot 2^{-n} < \epsilon$ whenever $r, s \ge n$. So this subsequence is a [[Definition:Cauchy Sequence (Metric Space)|Cauchy sequence]] and hence, because $M = \left({A, d}\right)$ is [[Definition:Complete Metric Space|complete]] by assumption, it is [[Definition:Convergent Sequence (Metric Space)|convergent]]. Thus we see that $\left \langle{a_k}\right \rangle$ has a [[Definition:Convergent Sequence (Metric Space)|convergent]] [[Definition:Subsequence|subsequence]]. Hence, by definition, $M$ is [[Definition:Sequentially Compact Space|sequentially compact]]. {{qed}}	0
Let $\left({A, d}\right)$ be a [[Definition:Metric Space|metric space]]. Let $\left\langle{x_n}\right\rangle_{n \in \N}$ be a [[Definition:Cauchy Sequence (Metric Space)|Cauchy sequence]] in $A$. Let $x \in A$. Then $\left\langle{x_n}\right\rangle$ [[Definition:Convergent Sequence (Metric Space)|converges]] to $x$ {{iff}} it has a [[Definition:Subsequence|subsequence]] that [[Definition:Convergent Sequence (Metric Space)|converges]] to $x$.	0
From the [[Nth Root Test|$n$th root test]], $S \paren x$ is [[Definition:Convergent Series|convergent]] if $\displaystyle \limsup_{n \mathop \to \infty} \size {a_n \paren {x - \xi}^n}^{1/n} < 1$. Thus: {{begin-eqn}} {{eqn | l = \size {a_n \paren {x - \xi}^n}^{1/n} | o = < | r = 1 | c = }} {{eqn | ll= \leadstoandfrom | l = \size {a_n}^{1/n} \size {x - \xi} | o = < | r = 1 | c = }} {{eqn | ll= \leadstoandfrom | l = \size {a_n}^{1/n} | o = < | r = \frac 1 {\size {x - \xi} } | c = }} {{end-eqn}} The result follows from the definition of [[Definition:Radius of Convergence of Real Power Series|radius of convergence]]. {{qed}} {{Namedfor|Augustin Louis Cauchy|name2 = Jacques Salomon Hadamard}}	0
Let $\C$ denote the set of [[Definition:Complex Number|complex numbers]]. Then the [[Definition:Complex Vector Space|complex vector space $\C^n$]] is a [[Definition:Vector Space|vector space]].	0
:$\map {J_{-n} } x = \paren {-1}^n \map {J_n} x$	0
The [[Definition:Haversine|haversine]] is [[Definition:Non-Negative Real Number|non-negative]] for all $\theta \in \R$.	0
Let $x \in \R$ be a [[Definition:Strictly Positive Real Number|strictly positive real number]]. Let $n \in \R$ be any [[Definition:Natural Numbers|natural number]]. Let $\ln x$ be the [[Definition:Natural Logarithm|natural logarithm]] of $x$. Then: :$\ln \left({x^n}\right) = n \ln x$	0
Follows directly from the definition of [[Definition:Modulo Multiplication|multiplication modulo $m$]]: {{begin-eqn}} {{eqn | l = \eqclass x m \times_m \eqclass 1 m | r = \eqclass {x \times 1} m | c = }} {{eqn | r = \eqclass x m | c = }} {{eqn | r = \eqclass {1 \times x} m | c = }} {{eqn | r = \eqclass 1 m \times_m \eqclass x m | c = }} {{end-eqn}} Thus $\eqclass 1 m$ is the [[Definition:Identity Element|identity]] for [[Definition:Modulo Multiplication|multiplication modulo $m$]]. {{qed}}	0
Let $x, y \in \R$ be [[Definition:Strictly Positive Real Number|strictly positive real numbers]]. Then: :$\ln x + \ln y = \map \ln {x y}$ where $\ln$ denotes the [[Definition:General Logarithm|natural logarithm]].	0
From [[Sum of Reciprocals of Squares of Odd Integers]], :$\displaystyle \sum_{n \mathop = 0}^\infty \frac 1 {\paren {2n+1}^2} = \frac {\pi^2} 8$ Note that: {{begin-eqn}} {{eqn | l = \sum_{n \mathop = 1}^\infty \frac 1 {n^2} | r = \sum_{n \mathop = 1}^\infty \frac 1 {\paren {2 n}^2} + \sum_{n \mathop = 0}^\infty \frac 1 {\paren {2 n + 1}^2} | c = }} {{eqn | r = \frac 1 4 \sum_{n \mathop = 1}^\infty \frac 1 {n^2} + \frac {\pi^2} 8 | c = }} {{eqn | ll= \leadsto | l = \sum_{n \mathop = 1}^\infty \frac 1 {n^2} | r = \frac {\pi^2} 6 }} {{end-eqn}} {{qed}}	0
Let $a \in \R_{\ne 0}$. Then: :$\displaystyle \int x \sqrt {a x^2 + b x + c} \ \mathrm d x = \frac {\left({\sqrt {a x^2 + b x + c} }\right)^3} {3 a} - \frac {b \left({2 a x + b}\right) \sqrt {a x^2 + b x + c} } {8 a^2} - \frac {b \left({4 a c - b^2}\right)} {16 a^2} \int \frac {\mathrm d x} {\sqrt {a x^2 + b x + c} }$	0
{{begin-eqn}} {{eqn | l = \sin \left({\frac \pi 2 - \theta}\right) | r = \sin \frac \pi 2 \cos \theta - \cos \frac \pi 2 \sin \theta | c = [[Sine of Difference]] }} {{eqn | r = 1 \times \cos \theta - 0 \times \sin \theta | c = [[Sine of Right Angle]] and [[Cosine of Right Angle]] }} {{eqn | r = \cos \theta }} {{end-eqn}} {{qed}}	0
=== [[Cauchy-Riemann Equations/Necessary Condition|Necessary Condition]] === {{:Cauchy-Riemann Equations/Necessary Condition}} === [[Cauchy-Riemann Equations/Sufficient Condition|Sufficient Condition]] === {{:Cauchy-Riemann Equations/Sufficient Condition}} === [[Cauchy-Riemann Equations/Expression of Derivative|Expression of Derivative]] === {{:Cauchy-Riemann Equations/Expression of Derivative}} {{Namedfor|Augustin Louis Cauchy|name2 = Georg Friedrich Bernhard Riemann|cat = Cauchy|cat2 = Riemann}}	0
Let $a, b, c \in \Z$. Then: : $\lcm \set {a, \gcd \set {b, c} } = \gcd \set {\lcm \set {a, b}, \lcm \set {a, c} }$ : $\gcd \set {a, \lcm \set {b, c} } = \lcm \set {\gcd \set {a, b}, \gcd \set {a, c} }$ That is, [[Definition:Greatest Common Divisor of Integers|greatest common divisor]] and [[Definition:Lowest Common Multiple of Integers|lowest common multiple]] are [[Definition:Distributive Operation|distributive]] over each other.	0
Let $\size x < a$. Then: {{begin-eqn}} {{eqn | l = \int \frac {\d x} {a^2 - x^2} | r = \frac 1 a \tanh^{-1} {\frac x a} + C | c = [[Primitive of Reciprocal of a squared minus x squared/Inverse Hyperbolic Tangent Form|Primitive of $\dfrac 1 {a^2 - x^2}$: $\tanh^{-1}$ form]] }} {{eqn | r = \frac 1 a \paren {\dfrac 1 2 \map \ln {\dfrac {a + x} {a - x} } } + C | c = [[Inverse Hyperbolic Tangent of x over a in Logarithm Form|$\tanh^{-1} \dfrac x a$ in Logarithm Form]] }} {{eqn | r = \dfrac 1 {2 a} \map \ln {\dfrac {a + x} {a - x} } + C | c = simplifying }} {{end-eqn}}	0
Follows from: :[[Compact Complement Topology is Irreducible]] :[[Irreducible Space is Locally Connected]] {{qed}}	0
:$\map \phi 1 = 1$	0
Let $T_1 = \struct {S_1, \tau_1}$ and $T_2 = \struct {S_2, \tau_2}$ be [[Definition:Topological Space|topological spaces]]. Let $T = \struct {T_1 \times T_2, \tau}$ be the [[Definition:Product Space (Topology)|product space]] of $T_1$ and $T_2$, where $\tau$ is the [[Definition:Tychonoff Topology|Tychonoff topology]] on $S$. Let $\pr_1: T \to T_1$ and $\pr_2: T \to T_2$ be the [[Definition:Projection (Mapping Theory)|first and second projections]] from $T$ onto its [[Definition:Factor Space|factors]]. Then both $\pr_1$ and $\pr_2$ are [[Definition:Open Mapping|open]].	0
Let $x, y \in \R$ be [[Definition:Real Number|real numbers]]. Let $\size x$ denote the [[Definition:Absolute Value|absolute value]] of $x$. Then: :$\size {x + y} \le \size x + \size y$	0
Let $U$ be an [[Definition:Open Set (Complex Analysis)|open subset]] of $\C$. Let $\left\{ {f_n}\right\}_{n \mathop \in \N}$ be a [[Definition:Sequence|sequence]] of [[Definition:Analytic Function|analytic functions]] $f_n : U \to \C$. Let $\left\{ {f_n}\right\}$ [[Definition:Locally Uniform Convergence|converge locally uniformly]] to $f$ on $U$. Then $f$ is [[Definition:Analytic Function|analytic]].	0
Let: :$1 = \dfrac 1 v + \dfrac 1 w + \dfrac 1 x + \dfrac 1 y$ where $ 1 < v < w < x < y$ Suppose $v = 3$ and take the largest potential solution that can be generated: :$1 \stackrel {?} {=} \dfrac 1 3 + \dfrac 1 4 + \dfrac 1 5 + \dfrac 1 6$ But we find: :$1 > \dfrac 1 3 + \dfrac 1 4 + \dfrac 1 5 + \dfrac 1 6$ Therefore, there can be no solutions where $v \ge 3$, as that solution was the largest possible. Hence, $v = 2$ if there are any solutions. Repeating the above anaylsis on $w$: {{begin-eqn}} {{eqn | l = \dfrac 1 2 | r = \dfrac 1 w + \dfrac 1 x + \dfrac 1 y }} {{eqn | l = \dfrac 1 2 | o = < | r = \dfrac 1 3 + \dfrac 1 4 + \dfrac 1 5 }} {{eqn | l = \dfrac 1 2 | o = < | r = \dfrac 1 4 + \dfrac 1 5 + \dfrac 1 6 }} {{eqn | l = \dfrac 1 2 | o = < | r = \dfrac 1 5 + \dfrac 1 6 + \dfrac 1 7 }} {{eqn | l = \dfrac 1 2 | o = > | r = \dfrac 1 6 + \dfrac 1 7 + \dfrac 1 8 }} {{end-eqn}} Potential solutions are located where $w = 3, 4, 5$. Now that $v$ and $w$ are known, the variable $y$ can be written in terms of $x$: :$y = \dfrac 1 {\dfrac {w - 2} {2 w} - \dfrac 1 x}$ Solutions are only positive when: {{begin-eqn}} {{eqn | l = \dfrac 1 x | o = < | r = \dfrac {w - 2} {2 w} | c = }} {{eqn | ll= \leadsto | l = x | o = > | r = \dfrac {2 w} {w - 2} | c = }} {{end-eqn}} As $x < y$: {{begin-eqn}} {{eqn | l = x | o = < | r = \dfrac 1 {\dfrac {w - 2} {2 w} - \dfrac 1 x} | c = }} {{eqn | ll= \leadsto | l = \dfrac 1 x | o = < | r = \dfrac {w - 2} {2 w} - \dfrac 1 x | c = }} {{eqn | ll= \leadsto | l = \dfrac 2 x | o = < | r = \dfrac {w - 2} {2 w} | c = }} {{eqn | ll= \leadsto | l = x | o = < | r = \dfrac {4 w} {w - 2} | c = }} {{end-eqn}} Therefore solutions exist only in the domain: :$\dfrac {2 w} {w - 2} < x < \dfrac {4 w} {w - 2}$ and: :$w < x$ Case $w = 3$: {{begin-eqn}} {{eqn | l = 6 | o = < | r = x < 12 | rr= \text {and } 3 < x | c = }} {{eqn | ll= \leadsto | l = 6 | o = < | r = x < 12 | c = }} {{end-eqn}} Integer solutions in the above domain can then be found by inspection: :$\tuple {7, 42}, \tuple {8, 24}, \tuple {9, 18}, \tuple {10, 15}$ Case $w = 4$: {{begin-eqn}} {{eqn | l = 4 | o = < | r = x < 8 | rr= \text {and } 4 < x | c = }} {{eqn | ll= \leadsto | l = 4 | o = < | r = x < 8 | c = }} {{end-eqn}} Integer solutions in the above domain can again be found by inspection: :$\tuple {5, 20}, \tuple {6, 12}$ Case $w = 5$: {{begin-eqn}} {{eqn | l = \dfrac {10} 3 | o = < | r = \dfrac {20} 3 | rr= \text {and } 5 < x | c = }} {{eqn | ll= \leadsto | l = 5 | o = < | r = \dfrac {20} 3 | c = }} {{end-eqn}} and it is immediately seen that there are no integer solutions in this domain. All solutions have therefore been found: :$\tuple {2, 3, 7, 42}, \tuple {2, 3, 8, 24}, \tuple {2, 3, 9, 18}, \tuple {2, 3, 10, 15}, \tuple {2, 4, 5, 20}, \tuple {2, 4, 6, 12}$ Hence: {{begin-eqn}} {{eqn | l = 1 | r = \frac 1 2 + \frac 1 3 + \frac 1 7 + \frac 1 {42} }} {{eqn | r = \frac 1 2 + \frac 1 3 + \frac 1 8 + \frac 1 {24} }} {{eqn | r = \frac 1 2 + \frac 1 3 + \frac 1 9 + \frac 1 {18} }} {{eqn | r = \frac 1 2 + \frac 1 3 + \frac 1 {10} + \frac 1 {15} }} {{eqn | r = \frac 1 2 + \frac 1 4 + \frac 1 5 + \frac 1 {20} }} {{eqn | r = \frac 1 2 + \frac 1 4 + \frac 1 6 + \frac 1 {12} }} {{end-eqn}} {{qed}}	0
[[Proof by Counterexample]]: Let $a = 6, b = 21, x = 7, y = 12, m = 15$. We note that $\gcd \left({6, 15}\right) = 3$ and so $6$ and $15$ are not [[Definition:Coprime Integers|coprime]]. We have that: {{begin-eqn}} {{eqn | l = 6 | o = \equiv | r = 6 | rr= \pmod {15} | c = }} {{eqn | l = 21 | o = \equiv | r = 6 | rr= \pmod {15} | c = }} {{eqn | ll= \leadsto | l = a | o = \equiv | r = b | rr= \pmod {15} | c = }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = 6 \times 7 | r = 42 | c = }} {{eqn | o = \equiv | r = 12 | rr= \pmod {15} | c = }} {{eqn | l = 21 \times 12 | r = 252 | c = }} {{eqn | o = \equiv | r = 12 | rr= \pmod {15} | c = }} {{eqn | ll= \leadsto | l = a x | o = \equiv | r = b y | rr= \pmod {15} | c = }} {{end-eqn}} But: {{begin-eqn}} {{eqn | l = 7 | o = \equiv | r = 7 | rr= \pmod {15} | c = }} {{eqn | l = 12 | o = \equiv | r = 12 | rr= \pmod {15} | c = }} {{eqn | ll= \leadsto | l = x | o = \not \equiv | r = y | rr= \pmod {15} | c = }} {{end-eqn}} {{qed}}	0
Let $x \in \R$ be a [[Definition:Real Number|real number]]. Let $\exp x$ be the [[Definition:Real Exponential Function|exponential of $x$]]. Then:	0
Let $\Z$ be the set of all [[Definition:Integer|integers]]. Let $\Z_{>0}$ be the set of [[Definition:Strictly Positive Integer|strictly positive integers]]. Let $m \in \Z_{>0}$ and let $n \in \Z$. Let $\ideal m$ be the [[Definition:Principal Ideal of Ring|principal ideal]] of $\Z$ generated by $m$. Then: :$m \divides n \iff \ideal n \subseteq \ideal m$	0
Let the [[Definition:Field of Complex Numbers|field of complex numbers]] be denoted $\struct {\C, +, \times}$. By [[Complex Numbers under Addition form Abelian Group]], $\struct {\C, +}$ is an [[Definition:Abelian Group|abelian group]]. From [[Complex Multiplication Distributes over Addition]]: {{begin-eqn}} {{eqn | lo= \forall x, y, z \in \C: | l = x \times \paren {y + z} | r = x \times y + x \times z }} {{eqn | l = \paren {y + z} \times x | r = y \times x + z \times x }} {{end-eqn}} From [[Complex Multiplication is Associative]]: :$\forall x, y, z \in \C: x \times \paren {y \times z} = \paren {x \times y} \times z$ From [[Complex Multiplication Identity is One]]: :$\forall x \in \C: 1 \times x = x$ Therefore $\struct {\C, +, \times}$ forms a [[Definition:Vector Space|vector space]]. {{qed}}	0
Let $m$ be [[Definition:Prime Number|prime]]. From [[Ring of Integers Modulo Prime is Integral Domain]], $\struct {\Z_m, +, \times}$ is an [[Definition:Integral Domain|integral domain]]. From [[Finite Integral Domain is Galois Field]], $\struct {\Z_m, +, \times}$ is a [[Definition:Field (Abstract Algebra)|field]]. {{qed|lemma}} Now suppose $m \in \Z: m \ge 2$ is [[Definition:Composite Number|composite]]. From [[Ring of Integers Modulo Composite is not Integral Domain]], $\struct {\Z_m, +, \times}$ is not an [[Definition:Integral Domain|integral domain]]. From [[Field is Integral Domain]] $\struct {\Z_m, +, \times}$ is not a [[Definition:Field (Abstract Algebra)|field]]. {{qed}}	0
:$\displaystyle \int \frac {\d x} {\sec a x} = \frac {\sin a x} a + C$	0
{{begin-eqn}} {{eqn | l = \frac {\map \d {\map \arctan x} } {\d x} | r = \lim_{h \mathop \to 0} \frac {\map \arctan {x + h} - \map \arctan x} h | c = {{Defof|Derivative of Real Function at Point}} }} {{eqn | r = \lim_{h \mathop \to 0} \frac {\arctan {x + h} + \map \arctan {-x} } h | c = [[Arctangent Function is Odd]] }} {{eqn | r = \lim_{h \mathop \to 0} \frac 1 h \map \arctan {\frac {x + h - x} {1 + x \paren {x + h} } } | c = [[Sum of Arctangents]] }} {{eqn | r = \lim_{h \mathop \to 0} \frac 1 h \map \arctan {\frac h {1 + x^2 + h x} } }} {{eqn | r = \lim_{h \mathop \to 0} \frac 1 h \paren {\frac h {1 + x^2 + h x} - \frac 1 3 \paren {\frac h {1 + x^2 + h x} }^3 + \frac 1 5 \paren {\frac h {1 + x^2 + h x} }^5 + \map \OO {h^7} } | c = {{Defof|Real Arctangent}} }} {{eqn | r = \lim_{h \mathop \to 0} \paren {\frac 1 {1 + x^2 + h x} - \frac {h^2} {3 \paren {1 + x^2 + h x}^3} + \frac {h^4} {5 \paren {1 + x^2 + h x}^5} + \map \OO {h^6} } }} {{eqn | r = \frac 1 {1 + x^2 + 0 x} - \frac {0^2} {3 \paren {1 + x^2 + 0 x}^3} + \frac {0^4} {5 \paren {1 + x^2 + 0 x}^5} }} {{eqn | r = \frac 1 {1 + x^2} }} {{end-eqn}} {{qed}}	0
:$d \divides n \implies \map \phi d \divides \map \phi n$ where $d \divides n$ denotes that $d$ is a [[Definition:Divisor of Integer|divisor]] of $n$.	0
First the case where $n \ge 0$ is addressed. The proof proceeds by [[Principle of Mathematical Induction|induction]]. For all $n \in \Z_{\ge 0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\forall x \in \R:$ ::$2 n \pi < x < \paren {2 n + 1} \pi \implies \sin x > 0$ ::$\paren {2 n + 1} \pi < x < \paren {2 n + 2} \pi \implies \sin x < 0$ === Basis for the Induction === Let $n = 0$. From the [[Sine and Cosine are Periodic on Reals/Corollary|corollary to Sine and Cosine are Periodic on Reals]]: :$\sin x$ is [[Definition:Strictly Positive|strictly positive]] on the [[Definition:Open Real Interval|interval]] $\openint 0 \pi$ and: :$\sin x$ is [[Definition:Strictly Negative|strictly negative]] on the [[Definition:Open Real Interval|interval]] $\openint \pi {2 \pi}$ Thus: :$2 \cdot 0 \cdot \pi < x < \paren {2 \cdot 0 + 1} \pi \implies \sin x > 0$ :$\paren {2 \cdot 0 \cdot + 1} \pi < x < \paren {2 \cdot 0 + 2} \pi \implies \sin x < 0$ This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that if $\map P k$ is true, where $k \ge 0$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\forall x \in \R:$ ::$2 k \pi < x < \paren {2 k + 1} \pi \implies \sin x > 0$ ::$\paren {2 k + 1} \pi < x <\paren {2 k + 2} \pi \implies \sin x < 0$ Then we need to show: :$\forall x \in \R:$ ::$2 \paren {k + 1} \pi < x < \paren {2 \paren {k + 1} + 1} \pi \implies \sin x > 0$ ::$\paren {2 \paren {k + 1} + 1} \pi < x < \paren {2 \paren {k + 1} + 2} \pi \implies \sin x < 0$ That is: :$\forall x \in \R:$ ::$\paren {2 k + 2} \pi < x < \paren {2 k + 3} \pi \implies \sin x > 0$ ::$\paren {2 k + 3} \pi < x < \paren {2 k + 4} \pi \implies \sin x < 0$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = 2 k \pi < x < \paren {2 k + 1} \pi | o = \implies | r = \sin x > 0 }} {{eqn | ll= \leadsto | l = 2 k \pi < \paren {x - 2 \pi} < \paren {2 k + 1} \pi | o = \implies | r = \map \sin {x - 2 \pi} > 0 | c = replacing $x$ with $x - 2 \pi$ }} {{eqn | ll= \leadsto | l = 2 k \pi < \paren {x - 2 \pi} < \paren {2 k + 1} \pi | o = \implies | r = \sin x > 0 | c = [[Sine and Cosine are Periodic on Reals]] }} {{eqn | ll= \leadsto | l = \paren {2 k + 2} \pi < x < \paren {2 k + 3} \pi | o = \implies | r = \sin x > 0 | c = adding $2 \pi$ to all elements of inequality }} {{end-eqn}} Also: {{begin-eqn}} {{eqn | l = \paren {2 k + 1} \pi < x < \paren {2 k + 2} \pi | o = \implies | r = \sin x < 0 }} {{eqn | ll= \leadsto | l = \paren {2 k + 1} \pi < \paren {x - 2 \pi} < \paren {2 k + 2} \pi | o = \implies | r = \map \sin {x - 2 \pi} < 0 | c = replacing $x$ with $x - 2 \pi$ }} {{eqn | ll= \leadsto | l = \paren {2 k + 1} \pi < \paren {x - 2 \pi} < \paren {2 k + 2} \pi | o = \implies | r = \sin x < 0 | c = [[Sine and Cosine are Periodic on Reals]] }} {{eqn | ll= \leadsto | l = \paren {2 k + 3} \pi < x < \paren {2 k + 4} \pi | o = \implies | r = \sin x < 0 | c = adding $2 \pi$ to all elements of inequality }} {{end-eqn}} It follows by [[Principle of Mathematical Induction|induction]] that: :$\forall n \in \Z_{\ge 0}: \forall x \in \R:$ ::$2 n \pi < x < \paren {2 n + 1} \pi \implies \sin x > 0$ ::$\paren {2 n + 1} \pi < x < \paren {2 n + 2} \pi \implies \sin x < 0$ {{qed|lemma}} === Negative $n$ === Let $n \in \Z_{\le 0}$ be a [[Definition:Negative Integer|negative integer]]. Then, by definition, $-\paren {n + 1}$ is a [[Definition:Strictly Positive Integer|(strictly) positive integer]]. So: {{begin-eqn}} {{eqn | l = 2 \paren {-\paren {n + 1} } \pi < x < \paren {2 \paren {-\paren {n + 1} } + 1} \pi | o = \implies | r = \sin x > 0 | c = Result for [[Definition:Positive Integer|positive $n$]] above }} {{eqn | l = -\paren {2 n + 2} \pi < x < -\paren {2 n + 1} \pi | o = \implies | r = \sin x > 0 | c = simplifying }} {{eqn | ll= \leadsto | l = -\paren {2 n + 2} \pi < \paren {-x} < -\paren {2 n + 1} \pi | o = \implies | r = \map \sin {-x} > 0 | c = replacing $x$ with $-x$ }} {{eqn | ll= \leadsto | l = -\paren {2 n + 2} \pi < \paren {-x} < -\paren {2 n + 1} \pi | o = \implies | r = -\paren {\sin x} > 0 | c = [[Sine Function is Odd]] }} {{eqn | ll= \leadsto | l = \paren {2 n + 2} \pi > x > \paren {2 n + 1} \pi | o = \implies | r = \sin x < 0 | c = multiplying throughout by $-1$ }} {{eqn | ll= \leadsto | l = \paren {2 n + 1} \pi < x < \paren {2 n + 2} \pi | o = \implies | r = \sin x < 0 | c = rearranging }} {{end-eqn}} Similarly: {{begin-eqn}} {{eqn | l = \paren {2 \paren {-\paren {n + 1} } + 1} \pi < x < \paren {2 \paren {-\paren {n + 1} } + 2} \pi | o = \implies | r = \sin x < 0 | c = Result for [[Definition:Positive Integer|positive $n$]] above }} {{eqn | l = -\paren {2 n + 1} \pi < x < -2 n \pi | o = \implies | r = \sin x < 0 | c = simplifying }} {{eqn | ll= \leadsto | l = -\paren {2 n + 1} \pi < \paren {-x} < -2 n \pi | o = \implies | r = \map \sin {-x} < 0 | c = replacing $x$ with $-x$ }} {{eqn | ll= \leadsto | l = -\paren {2 n + 1} \pi < \paren {-x} < -2 n \pi | o = \implies | r = -\paren {\sin x} < 0 | c = [[Sine Function is Odd]] }} {{eqn | ll= \leadsto | l = -\paren {2 n + 1} \pi > x > 2 n \pi | o = \implies | r = \sin x > 0 | c = multiplying throughout by $-1$ }} {{eqn | ll= \leadsto | l = 2 n \pi < x < \paren {2 n + 1} \pi | o = \implies | r = \sin x > 0 | c = simplifying and rearranging }} {{end-eqn}} {{qed}}	0
This proof assumes the definition of $\ln$ as the [[Definition:Inverse Mapping|inverse]] of the [[Definition:Real Exponential Function|exponential function]]. As the [[Exponential Function is Differentiable]], the result follows from the [[Derivative of Inverse Function|differentiability of inverse functions]]. {{qed}}	0
{{begin-eqn}} {{eqn | l = {G_n}' | r = \paren {\prod_{1 \mathop = k}^n \dfrac 1 {x_k} }^{1/n} | c = {{Defof|Geometric Mean}} }} {{eqn | r = \paren {\dfrac 1 {\prod_{1 \mathop = k}^n x_k} }^{1/n} | c = }} {{eqn | r = \dfrac 1 {\paren {\prod_{1 \mathop = k}^n x_k}^{1/n} } | c = }} {{eqn | r = \dfrac 1 {G_n} | c = {{Defof|Geometric Mean}} }} {{end-eqn}} {{qed}} [[Category:Geometric Mean]] [[Category:Reciprocals]] 0yyp90q5hxvtmo032pg6qbo1to3ds61	0
Let $\struct {\C_{\ne 0}, \times}$ be the [[Definition:Multiplicative Group of Complex Numbers|multiplicative group of complex numbers]]. Let $\struct {\R_{\ne 0}, \times}$ be the [[Definition:Multiplicative Group of Real Numbers|multiplicative group of real numbers]]. Then the [[Definition:Group Direct Product|direct product]] $\struct {\R_{\ne 0}, \times} \times \struct {\R_{\ne 0}, \times}$ is not [[Definition:Group Isomorphism|isomorphic]] with $\struct {\C_{\ne 0}, \times}$.	0
Let $f: \C \to \C$ be an [[Definition:Entire Function|entire function]]. Let $k$ be its [[Definition:Rank of Entire Function|rank]] and $\tau$ be its [[Definition:Exponent of Convergence|exponent of convergence]]. Then: * $k=\tau=0$ if $f$ has [[Definition:Finitely Many|finitely many]] zeroes. * $k<\tau\leq k+1$ otherwise.	0
Let $r, s \in \Z$ such that $r \perp s$. === Case 1: Either factor is not [[Definition:Square-Free Integer|square-free]] === Let either $r \notin S$ or $s \notin S$ or both. Then either: :$\exists k \in \Z_{>1}: k^2 \divides r$ or: :$\exists k \in \Z_{>1}: k^2 \divides s$ Thus either: :$\map {\chi_S} r = 0$ or: :$\map {\chi_S} s = 0$ and so: :$\map {\chi_S} r \, \map {\chi_S} s = 0$ But then: :$\exists k \in \Z_{>1}: k^2 \divides r s$ and so: :$\map {\chi_S} {r s} = 0$ demonstrating that: :$\map {\chi_S} r \, \map {\chi_S} s = \map {\chi_S} {r s}$ {{qed|lemma}} === Case 1: Both factors are [[Definition:Square-Free Integer|square-free]] === Let $r \in S$ and $s \in S$. Thus: :$\nexists k \in \Z_{>1}: k^2 \divides r$ and: :$\nexists k \in \Z_{>1}: k^2 \divides s$ Hence: :$\map {\chi_S} r = 1$ and: :$\map {\chi_S} s = 1$ and so: :$\map {\chi_S} r \, \map {\chi_S} s = 1$ Because $r \perp s$: :$\nexists k \in \Z_{>1}: k \divides r, k \divides s$ Hence there can be no $k \in \Z_{>1}$ whose multiplicity in $r s$ is greater than $1$. Thus: :$\nexists k \in \Z_{>1}: k^2 \divides {r s}$ and so: :$\map {\chi_S} {r s} = 1$ once more demonstrating that: :$\map {\chi_S} r \, \map {\chi_S} s = \map {\chi_S} {r s}$ {{qed|lemma}} In both cases: :$\map {\chi_S} r \, \map {\chi_S} s = \map {\chi_S} {r s}$ Hence the result, by definition of [[Definition:Multiplicative Arithmetic Function|multiplicative function]]. {{Qed}}	0
:$\ds \int \frac {\d x} {x^2 - a^2} = -\frac 1 a \tanh^{-1} {\frac x a} + C$ where $\size x < a$.	0
{{begin-eqn}} {{eqn | l = \sec 180 \degrees | r = \map \sec {90 \degrees + 90 \degrees} | c = }} {{eqn | r = -\csc 90 \degrees | c = [[Secant of Angle plus Right Angle]] }} {{eqn | r = -1 | c = [[Cosecant of Right Angle]] }} {{end-eqn}} {{qed}}	0
Let $x$ be a [[Definition:Real Number|real number]]. Let $x \in \hointl {-\infty} {-1} \cup \hointr 1 {\infty}$. Then: :$\displaystyle \arccsc x = -i \map \Ln {\sqrt {1 - \frac 1 {x^2} } + \frac i x}$ where: :$\arccsc$ is the [[Definition:Arccosecant|arccosecant function]] :$\Ln$ is the [[Definition:Natural Logarithm/Complex/Principal Branch|principal branch]] of the [[Definition:Complex Natural Logarithm|complex logarithm]] whose imaginary part lies in $\hointl {-\pi} \pi$.	0
=== [[Sine of x minus Cosine of x/Sine Form|Sine Form]] === {{:Sine of x minus Cosine of x/Sine Form}} === [[Sine of x minus Cosine of x/Cosine Form|Cosine Form]] === {{:Sine of x minus Cosine of x/Cosine Form}}	0
Let $x \in \R$ be a [[Definition:Real Number|real number]]. Let $\exp x$ be the [[Definition:Real Exponential Function|exponential of $x$]]. Then $\exp x$ is [[Definition:Well-Defined Mapping|well-defined]].	0
{{begin-eqn}} {{eqn | l = \cos^2 x + \sin^2 x | r = \left({\cos x + i \, \sin x}\right) \, \left({\cos x - i \, \sin x}\right) | c = factoring over the [[Definition:Complex Number|complex numbers]] }} {{eqn | r = \left({\cos x + i \, \sin x}\right) \, \left({\cos \left({-x}\right) + i \, \sin \left({-x}\right)}\right) | c = [[Cosine Function is Even]] and [[Sine Function is Odd]] }} {{eqn | r = e^{ix} \, e^{-ix} | c = [[Euler's Formula]] }} {{eqn | r = 1 | c = }} {{end-eqn}} {{qed}}	0
By definition of [[Definition:Integer Power|$n$th power]] (for [[Definition:Positive Integer|positive]] $n$): :$x^n = \begin{cases} 1 & : n = 0 \\ x \times x^{n - 1} & : n > 0 \end{cases}$ Thus: {{begin-eqn}} {{eqn | l = x^2 | r = x \times x^1 | c = }} {{eqn | r = x \times x \times x^0 | c = }} {{eqn | r = x \times x \times 1 | c = }} {{eqn | r = x \times x | c = }} {{end-eqn}} Hence the result. {{qed}} [[Category:Square Function]] 0unisqa74pxlosnkezxy36diu2jkfgx	0
{{AimForCont}} $f$ is not bounded. Let $A_n = \set {x \in X: \norm {\map f x} < n}$ for every $n \in \N$. Then each $A_n$ is open, since $A_n = \map {\norm f^{-1} } {-n, n}$. {{explain|the notation $\map {\norm f^{-1} } {-n, n}$}} Moreover, $X = \bigcup A_n$. Since $X$ is compact, there are $n_1, n_2, \dots, n_m \in \N$ such that $X = \bigcup A_{n_k}$. However, since $f$ is not bounded, there exists $x \in X$ such that $\norm {\map f X} \ge \max \set {n_1, n_2, \dots, n_m}$, which is a [[Definition:Contradiction|contradiction]]. {{qed}} [[Category:Continuous Functions]] [[Category:Compact Spaces]] 1umavq3f7zzciycwmr8m6qorc6hz40c	0
{{ProofWanted}} {{Namedfor|Jacques Philippe Marie Binet|cat = Binet}}	0
First, inserting the definitions, the statement of the theorem reads: :$\displaystyle \map {\partial_1^{\alpha_1} \partial_2^{\alpha_2} \cdots \partial_n^{\alpha_n} } {f g} = \sum_{\beta_1 = 0}^{\alpha_1} \cdots \sum_{\beta_n \mathop = 0}^{\alpha_n} \binom {\alpha_1} {\beta_1} \cdots \binom {\alpha_n} {\beta_n} \paren {\partial_1^{\beta_1} \cdots \partial_n^{\beta_n} f} \paren {\partial_1^{\alpha_1 - \beta_1} \cdots \partial_n^{\alpha_n - \beta_n} g}$ We prove this by induction over $n \ge 1$. === Basis for the Induction === If $n = 1$, the result is a simple restatement of [[Leibniz's Rule/One Variable|Leibniz's Rule in one variable]]: :$\displaystyle \paren {\map f x \, \map g x}^{\paren n} = \sum_{k \mathop = 0}^n \binom n k \map {f^{\paren k} } x \, \map {g^{\paren {n - k} } } x$ This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Step === Suppose now that the result is true for [[Definition:Function|functions]] of $n - 1$ [[Definition:Real Independent Variable|variables]]. In particular, we suppose that: :$\displaystyle \map {\partial_2^{\alpha_2} \cdots \partial_n^{\alpha_n} } {f g} = \sum_{\beta_2 \mathop = 0}^{\alpha_2} \cdots \sum_{\beta_n \mathop = 0}^{\alpha_n} \binom {\alpha_2} {\beta_2} \cdots \binom {\alpha_n} {\beta_n} \paren {\partial_2^{\beta_2} \cdots \partial_n^{\beta_n} f} \paren {\partial_2^{\alpha_2 - \beta_2} \cdots \partial_n^{\alpha_n - \beta_n} g}$ Now let us apply $\partial_1^{\alpha_1}$. Using the [[Linear Combination of Derivatives|linearity of derivatives]]: :$\displaystyle \map {\partial_1^{\alpha_1} \partial_2^{\alpha_2} \cdots \partial_n^{\alpha_n} } {f g} = \sum_{\beta_2 \mathop = 0}^{\alpha_2} \cdots \sum_{\beta_n \mathop = 0}^{\alpha_n} \binom {\alpha_2} {\beta_2} \cdots \binom {\alpha_n} {\beta_n} \partial_1^{\alpha_1} \paren {\paren {\partial_2^{\beta_2} \cdots \partial_n^{\beta_n} f} \paren {\partial_2^{\alpha_2 - \beta_2} \cdots \partial_n^{\alpha_n - \beta_n} g} }$ Applying [[Leibniz's Rule/One Variable|Leibniz's Rule in one variable]] we have: :$\displaystyle \map {\partial_1^{\alpha_1} \partial_2^{\alpha_2} \cdots \partial_n^{\alpha_n} } {f g} = \sum_{\beta_2 \mathop = 0}^{\alpha_2} \cdots \sum_{\beta_n \mathop = 0}^{\alpha_n} \binom {\alpha_2} {\beta_2} \cdots \binom {\alpha_n} {\beta_n} \sum_{\beta_1 \mathop = 0}^{\alpha_1} \binom {\alpha_1} {\beta_1} \paren {\partial_1^{\beta_1} \partial_2^{\beta_2} \cdots \partial_n^{\beta_n} f} \paren {\partial_1^{\alpha_1 - \beta_1} \partial_2^{\alpha_2 - \beta_2} \cdots \partial_n^{\alpha_n - \beta_n} g}$ Now, all the [[Definition:Series|sums]] are [[Definition:Finite Series|finite]], thus trivially [[Definition:Absolutely Convergent Series|absolutely convergent]]. By [[Manipulation of Absolutely Convergent Series]] and [[Summation is Linear]] we can move the inner sum to the far left, giving: :$\displaystyle \map {\partial_1^{\alpha_1} \partial_2^{\alpha_2} \cdots \partial_n^{\alpha_n} } {f g} = \sum_{\beta_1 \mathop = 0}^{\alpha_1} \cdots \sum_{\beta_n \mathop = 0}^{\alpha_n} \binom {\alpha_1} {\beta_1} \cdots \binom {\alpha_n} {\beta_n} \paren {\partial_1^{\beta_1} \cdots \partial_n^{\beta_n} f} \paren {\partial_1^{\alpha_1 - \beta_1} \cdots \partial_n^{\alpha_n - \beta_n} g}$ The result now follows by the [[Principle of Mathematical Induction]]. {{Qed}}	0
Let $(1)$ be rearranged as: {{begin-eqn}} {{eqn | l = \frac {\d x} {\d y} | r = \frac {1 - x y} {y^2} | c = }} {{eqn | n = 2 | ll= \leadsto | l = \frac {\d x} {\d y} + \frac x y | r = \frac 1 {y^2} | c = }} {{end-eqn}} It can be seen that $(2)$ is a [[Definition:Linear First Order ODE|linear first order ODE]] in the form: :$\dfrac {\d x} {\d y} + \map P y x = \map Q y$ where: :$\map P y = \dfrac 1 y$ :$\map Q y = \dfrac 1 {y^2}$ Thus: {{begin-eqn}} {{eqn | l = \int \map P y \rd y | r = \int \dfrac 1 y \rd y | c = }} {{eqn | r = \ln y | c = }} {{eqn | ll= \leadsto | l = e^{\int P \rd y} | r = y | c = }} {{end-eqn}} Thus from [[Solution by Integrating Factor]], $(2)$ can be rewritten as: {{begin-eqn}} {{eqn | l = \map {\dfrac \d {\d y} } {x y} | r = \dfrac 1 y | c = }} {{eqn | ll= \leadsto | l = x y | r = \int \frac {\d y} y | c = }} {{eqn | r = \ln y + C | c = }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \int \frac {\d x} {x^2 \paren {x^2 + a^2} } | r = \int \paren {\frac 1 {a^2 x^2} - \frac 1 {a^2 \paren {x^2 + a^2} } } \rd x | c = [[Primitive of Reciprocal of x squared by x squared plus a squared/Partial Fraction Expansion|Partial Fraction Expansion]] }} {{eqn | r = \frac 1 {a^2} \int \frac {\d x} {x^2} - \frac 1 {a^2} \int \frac {1 \rd x} {x^2 + a^2} | c = [[Linear Combination of Integrals]] }} {{eqn | r = -\frac 1 {a^2 x} - \frac 1 {a^2} \int \frac {x \rd x} {x^2 + a^2} + C | c = [[Primitive of Power]] }} {{eqn | r = -\frac 1 {a^2 x} - \frac 1 {a^2} \paren {\frac 1 a \arctan \frac x a} + C | c = [[Primitive of Reciprocal of x squared plus a squared/Arctangent Form|Primitive of Reciprocal of $x^2 + a^2$]] }} {{eqn | r = -\frac 1 {a^2 x} - \frac 1 {a^3} \arctan \frac x a + C | c = simplifying }} {{end-eqn}} {{qed}}	0
:$\displaystyle \int \tanh a x \rd x = \frac {\ln \size {\cosh a x} } a + C$	0
:$\displaystyle \int \frac{\left({\sqrt {x^2 + a^2} }\right)^3} {x^2} \ \mathrm d x = \frac {-\left({\sqrt {x^2 + a^2} }\right)^3} x + \frac{3 x \sqrt {x^2 + a^2} } 2 + \frac {3 a^2} 2 \ln \left({x + \sqrt {x^2 + a^2} }\right) + C$	0
The [[Definition:Second Order ODE|second order ODE]]: :$(1): \quad y'' - 2 y' + y = 2 x$ has the [[Definition:General Solution to Differential Equation|general solution]]: :$y = C_1 e^x + C_2 x e^x + 2 x + 4$	0
{{begin-eqn}} {{eqn | l = \int \frac {x^m \rd x} {a x^2 + b x + c} | r = \int \frac 1 a \frac {a x^m \rd x} {a x^2 + b x + c} | c = }} {{eqn | r = \int \frac 1 a \frac {x^{m - 2} a x^2 \rd x} {a x^2 + b x + c} | c = }} {{eqn | r = \int \frac 1 a \frac {x^{m - 2} \paren {a x^2 + b x + c - b x - c} \rd x} {a x^2 + b x + c} | c = }} {{eqn | r = \frac 1 a \int \frac {x^{m - 2} \paren {a x^2 + b x + c} \rd x} {a x^2 + b x + c} - \frac b a \int \frac {x^{m - 2} x \rd x} {a x^2 + b x + c} - \frac c a \int \frac {x^{m - 2} \rd x} {a x^2 + b x + c} | c = [[Linear Combination of Integrals]] }} {{eqn | r = \frac 1 a \int x^{m - 2} \rd x - \frac b a \int \frac {x^{m - 1} \rd x} {a x^2 + b x + c} - \frac c a \int \frac {x^{m - 2} \rd x} {a x^2 + b x + c} | c = simplification }} {{eqn | r = \frac {x^{m - 1} } {\paren {m - 1} a} - \frac b a \int \frac {x^{m - 1} \rd x} {a x^2 + b x + c} - \frac c a \int \frac {x^{m - 2} \rd x} {a x^2 + b x + c} | c = [[Primitive of Power]] }} {{end-eqn}} {{qed}}	0
First note that: {{begin-eqn}} {{eqn | l = u | r = \arctan \frac x a | c = }} {{eqn | ll= \implies | l = x | r = a \tan u | c = Definition of [[Definition:Arctangent|Arctangent]] }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = u | r = \arctan \frac x a | c = }} {{eqn | ll= \implies | l = \frac{\mathrm d u} {\mathrm d x} | r = \frac a {a^2 + x^2} | c = [[Derivative of Arctangent Function/Corollary|Derivative of Arctangent Function: Corollary]] }} {{eqn | ll= \implies | l = \int F \left({\arctan \frac x a}\right) \ \mathrm d x | r = \int F \left({u}\right) \ \frac {a^2 + x^2} a \ \mathrm d u | c = [[Primitive of Composite Function]] }} {{eqn | r = \int F \left({u}\right) \ \frac {a^2 + a^2 \tan^2 u} a \ \mathrm d u | c = Definition of $x$ }} {{eqn | r = \int F \left({u}\right) \ a^2 \frac {1 + \tan^2 u} a \ \mathrm d u | c = }} {{eqn | r = \int F \left({u}\right) \ a \sec^2 u \ \mathrm d u | c = [[Difference of Squares of Secant and Tangent]] }} {{eqn | r = a \int F \left({u}\right) \ \sec^2 u \ \mathrm d u | c = [[Primitive of Constant Multiple of Function]] }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \mathcal M \left\{ {t^n f \left({t}\right)}\right\} \left({s}\right) | r = \int_0^{\to +\infty} t^{s - 1} t^n f \left({t}\right) \ \mathrm d t | c = Definition of [[Definition:Mellin Transform|Mellin Transform]] }} {{eqn | r = \int_0^{\to +\infty} t^{\left({s + n}\right)-1} f \left({t}\right) \ \mathrm d t | c = [[Exponent Combination Laws]] }} {{eqn | r = \mathcal M \left\{ {f \left({t}\right)} \right\} \left({s + n}\right) | c = Definition of [[Definition:Mellin Transform|Mellin Transform]] }} {{end-eqn}} {{qed}} [[Category:Mellin Transforms]] p05uwj706t6ykmc70j1u6xvni60pgpn	0
:$\displaystyle \int x^3 \sqrt {a^2 - x^2} \ \mathrm d x = \frac {\left({\sqrt {a^2 - x^2} }\right)^5} 5 - \frac {a^2 \left({\sqrt {a^2 - x^2} }\right)^3} 3 + C$	0
Let $\left[{a \,.\,.\, b}\right]$ be a [[Definition:Closed Real Interval|closed real interval]]. Let $\phi: \left[{a \,.\,.\, b}\right] \to \R$ be a [[Definition:Real Function|real function]] which has a [[Definition:Derivative|derivative]] on $\left[{a \,.\,.\, b}\right]$. Let $f: A \to \C$ be a [[Definition:Continuous Complex Function|continuous complex function]], where $A$ is a [[Definition:Subset|subset]] of the [[Definition:Image of Mapping|image]] of $\phi$. If $\phi \left({a}\right) \le \phi \left({b}\right)$, then: :$\displaystyle \int_{\phi \left({a}\right)}^{\phi \left({b}\right)} f \left({t}\right) \, \mathrm d t = \int_a^b f \left({\phi \left({u}\right)}\right) \phi' \left({u}\right) \, \mathrm d u$ If $\phi \left({a}\right) > \phi \left({b}\right)$, then: :$\displaystyle \int_{\phi \left({b}\right)}^{\phi \left({a}\right)} f \left({t}\right) \, \mathrm dt = -\int_a^b f \left({\phi \left({u}\right)}\right) \phi' \left({u}\right) ,\ \mathrm d u$	0
From [[Linear Second Order ODE/y'' - 2 y' - 5 y = 0|Linear Second Order ODE: $y'' - 2 y' - 5 y = 0$]], we have established that the [[Definition:General Solution to Differential Equation|general solution]] to $(1)$ is: :$y_g = C_1 \map \exp {\paren {1 + \sqrt 6} x} + C_2 \map \exp {\paren {1 - \sqrt 6} x}$ === [[Linear Second Order ODE/y'' - 2 y' - 5 y = 2 cos 3 x - sin 3 x/Particular Solution/Trigonometric Form|Solution using Trigonometric Form]] === {{:Linear Second Order ODE/y'' - 2 y' - 5 y = 2 cos 3 x - sin 3 x/Particular Solution/Trigonometric Form}} === [[Linear Second Order ODE/y'' - 2 y' - 5 y = 2 cos 3 x - sin 3 x/Particular Solution/Exponential Form|Solution using Exponential Form]] === {{:Linear Second Order ODE/y'' - 2 y' - 5 y = 2 cos 3 x - sin 3 x/Particular Solution/Exponential Form}} [[Category:Linear Second Order ODE/y'' - 2 y' - 5 y = 2 cos 3 x - sin 3 x]] [[Category:Examples of Method of Undetermined Coefficients]] gd3j1neepe2jlry4mk53bj7k6cpwbj4	0
{{begin-eqn}} {{eqn | l = \map {\dfrac \d {\d x} } {\map u x^n} | r = \lim_{h \mathop \to 0} \frac {\paren {\map u {x + h} }^n - \paren {\map u x}^n} h | c = }} {{eqn | r = \paren {\map u x}^n \lim_{h \mathop \to 0} \frac {\paren {\frac {\map u {x + h} } {\map u x} }^n - 1} h | c = [[Exponent Combination Laws/Power of Product]] }} {{eqn | r = \paren {\map u x}^n \lim_{h \mathop \to 0} \frac {\exp \paren {n \ln \frac {\map u {x + h} } {\map u x} } - 1} h | c = {{Defof|Power to Real Number}} }} {{eqn | r = \paren {\map u x}^n \lim_{h \mathop \to 0} \paren {\frac {\map \exp {n \ln \frac {\map u {x + h} } {\map u x} } - 1} {n \ln \frac {\map u {x + h} } {\map u x} } } \paren {\frac {n \ln \frac {\map u {x + h} } {\map u x} } h} | c = }} {{eqn | r = \paren {\map u x}^n \lim_{h \mathop \to 0} \frac {n \ln \frac {\map u {x + h} } {\map u x} } h | c = [[Derivative of Exponential at Zero]] }} {{eqn | r = n \paren {\map u x}^n \lim_{h \mathop \to 0} \frac {\ln \frac {\map u {x + h} } {\map u x} } h | c = }} {{eqn | r = n \paren {\map u x}^n \lim_{h \mathop \to 0} \frac {\map \ln {1 + \frac {\map u {x + h} - \map u x} {\map u x} } } h | c = }} {{eqn | r = n \paren {\map u x}^n \lim_{h \mathop \to 0} \paren {\frac {\map \ln {1 + \frac {\map u {x + h} - \map u x} {\map u x} } } {\frac {\map u {x + h} - \map u x} {\map u x} } } \paren {\frac {\frac {\map u {x + h} - \map u x} {\map u x} } h } | c = }} {{eqn | r = n \paren {\map u x}^n \lim_{h \mathop \to 0} \frac {\paren {\frac {\map u {x + h} - \map u x} {\map u x} } } h | c = [[Derivative of Logarithm at One]] }} {{eqn | r = n \paren {\map u x}^n \lim_{h \mathop \to 0} \frac 1 {\map u x} \frac {\map u {x + h} - \map u x} h | c = }} {{eqn | r = n \paren {\map u x}^{n - 1} \lim_{h \mathop \to 0} \frac {\map u {x + h} - \map u x} h | c = [[Exponent Combination Laws/Product of Powers]] }} {{eqn | r = n \paren {\map u x}^{n - 1} \map {\dfrac \d {\d x} } {\map u x} | c = }} {{end-eqn}} {{qed}}	0
A [[Definition:Linear First Order Ordinary Differential Equation|linear first order ordinary differential equation]] in the form: :$\dfrac {\d y} {\d x} + \map P x y = \map Q x$ has the [[Definition:General Solution to Differential Equation|general solution]]: :$\ds y = e^{-\int P \rd x} \paren {\int Q e^{\int P \rd x} \rd x + C}$	0
:$\displaystyle \int \frac {x^2 \rd x} {\sqrt {x^2 - a^2} } = \frac {x \sqrt {x^2 - a^2} } 2 + \frac {a^2} 2 \ln \size {x + \sqrt {x^2 - a^2} } + C$	0
Let $\map f t := \map \Si t = \displaystyle \int_0^t \dfrac {\sin u} u \rd u$. Then: :$\map f 0 = 0$ and: {{begin-eqn}} {{eqn | l = \map \Si t | r = \int_0^t \dfrac {\sin u} u \rd u | c = {{Defof|Sine Integral Function}} }} {{eqn | r = \int_0^t \dfrac 1 u \paren {u - \dfrac {u^3} {3!} + \dfrac {u^5} {5!} - \dfrac {u^7} {7!} + \dotsb} \rd u | c = {{Defof|Real Sine Function}} }} {{eqn | r = t - \dfrac {t^3} {3 \times 3!} + \dfrac {t^5} {5 \times 5!} - \dfrac {t^7} {7 \times 7!} + \dotsb | c = [[Primitive of Power]] }} {{eqn | ll= \leadsto | l = \laptrans {\map \Si t} | r = \laptrans {t - \dfrac {t^3} {3 \times 3!} + \dfrac {t^5} {5 \times 5!} - \dfrac {t^7} {7 \times 7!} + \dotsb} | c = }} {{eqn | r = \dfrac 1 {s^2} - \dfrac 1 {3 \times 3!} \dfrac {3!} {s^4} + \dfrac 1 {5 \times 5!} \dfrac {5!} {s^6} - \dfrac 1 {7 \times 7!} \dfrac {7!} {s^8} + \dotsb | c = [[Laplace Transform of Positive Integer Power]] }} {{eqn | r = \dfrac 1 {s^2} - \dfrac 1 {3 s^4} + \dfrac 1 {5 s^6} - \dfrac 1 {7 s^8} + \dotsb | c = simplifying }} {{eqn | r = \dfrac 1 s \paren {\dfrac {\paren {1 / s} } 1 - \dfrac {\paren {1 / s}^3} 3 + \dfrac {\paren {1 / s}^5} 5 - \dfrac {\paren {1 / s}^7} 7 + \dotsb} | c = rearranging }} {{eqn | r = \dfrac 1 s \arctan \dfrac 1 s | c = [[Power Series Expansion for Real Arctangent Function]] }} {{end-eqn}} {{qed}}	0
:$\map {\dfrac \d {\d x} } {\cot x} = -\csc^2 x = \dfrac {-1} {\sin^2 x}$ where $\sin x \ne 0$.	0
:$\displaystyle \int_0^\infty \frac {1 - \cos p x} {x^2} \rd x = \frac {\pi \size p} 2$	0
{{begin-eqn}} {{eqn | l = \int x \csch a x \rd x | r = \frac 1 {a^2} \int \theta \csch \theta \rd \theta | c = [[Integration by Substitution|Substitution of $a x \to \theta$]] }} {{eqn | r = \frac 1 {a^2} \int \theta \sum_{n \mathop = 0}^\infty \frac {\paren {-1}^{n - 1} 2 \paren {2^{2 n - 1} - 1} B_{2 n} \, \theta^{2 n - 1} } {\paren {2 n}!} \rd \theta | c = [[Power Series Expansion for Cosecant Function]] }} {{eqn | r = \frac 1 {a^2} \sum_{n \mathop = 0}^\infty \frac {\paren {-1}^{n - 1} 2 \paren {2^{2 n - 1} - 1} B_{2 n} } {\paren {2 n}!} \int \theta^{2 n} \rd \theta | c = [[Fubini's Theorem]] }} {{eqn | r = \frac 1 {a^2} \sum_{n \mathop = 0}^\infty \frac {\paren {-1}^{n - 1} 2 \paren {2^{2 n - 1} - 1} B_{2 n} \paren {a x}^{2 n + 1} } {\paren {2 n + 1}!} + C | c = [[Integration by Substitution|Substituting back $\theta \to ax$]] }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \cos b x + i \sin b x | r = e^{i b x} | c = [[Euler's Formula]] }} {{eqn | ll= \leadsto | l = e^{a x} \cos b x + i e^{a x} \sin b x | r = e^{a x} e^{i b x} | c = multiplying both sides by $e^{a x}$ }} {{eqn | r = e^{\paren {a + i b} x} | c = [[Exponent Combination Laws]] }} {{eqn | ll= \leadsto | l = \int e^{a x} \cos b x \, \d x + i \int e^{a x} \sin b x \d x | r = \int e^{\paren {a + i b} x} \d x | c = [[Linear Combination of Complex Integrals]] }} {{eqn | r = \frac 1 {a + i b} e^{\paren {a + i b} x} + C | c = [[Primitive of Exponential of a x|Primitive of $e^{a x}$]] }} {{eqn | r = \frac {a - i b} {a^2 + b^2} e^{\paren {a + i b} x} + C | c = multiplying top and bottom by $a - i b$ }} {{eqn | r = \frac {a - i b} {a^2 + b^2} e^{a x} e^{i b x} + C | c = [[Exponent Combination Laws]] }} {{eqn | r = \frac {a - i b} {a^2 + b^2} e^{a x} \paren {\cos b x + i \sin b x} + C | c = [[Euler's Formula]] }} {{eqn | r = \frac a {a^2 + b^2} e^{a x} \cos b x - \frac {i b} {a^2 + b^2} e^{a x} \cos b x }} {{eqn | o = | ro= + | r = \frac {i a} {a^2 + b^2} e^{a x} \sin b x + \frac b {a^2 + b^2} e^{a x} \sin b x + C }} {{end-eqn}} The result follows from equating imaginary parts. {{qed}}	0
{{begin-eqn}} {{eqn | l = \frac {\d \Psi} {\d x} | r = \frac {\partial \Psi} {\partial x} \frac {\d x} {\d x} + \frac {\partial \Psi} {\partial y} \frac {\d y} {\d x} | c = [[Chain Rule for Real-Valued Functions]] }} {{eqn | r = \frac {\partial \Psi} {\partial x} + \frac {\partial \Psi} {\partial y} \frac {\d y} {\d x} | c = [[Derivative of Identity Function]] }} {{end-eqn}} {{qed}}	0
From the [[Fundamental Theorem of Calculus]]: :$(1): \quad \displaystyle \int_0^b x^n \ \mathrm d x = \left[{F \left({x}\right)}\right]_0^b = F \left({b}\right) - F \left({0}\right)$ where $F \left({x}\right)$ is a [[Definition:Primitive (Calculus)|primitive]] of $x^n$. By [[Primitive of Power]], $\dfrac {x^{n+1} } {n+1}$ is a [[Definition:Primitive (Calculus)|primitive]] of $x^n$. Then: {{begin-eqn}} {{eqn | l = \int_0^b x^n \mathrm d x | r = \left[{\frac {x^{n+1} } {n+1} }\right]_0^b | c = substituting $\dfrac {x^{n+1} } {n+1}$ for $F$ in $(1)$ }} {{eqn | r = \frac {b^{n+1} } {n+1} - \frac {0^{n+1} } {n+1} | c = }} {{eqn | r = \frac {b^{n+1} } {n+1} | c = }} {{end-eqn}} {{qed}}	0
Let $n \in \N$. Let $f: \R \to \R$ be the [[Definition:Real Function|real function]] defined as $f \left({x}\right) = x^n$. Then: :$f' \left({x}\right) = n x^{n-1}$ everywhere that $f \left({x}\right) = x^n$ is defined. When $x = 0$ and $n = 0$, $f^{\prime} \left({x}\right)$ is undefined.	0
{{begin-eqn}} {{eqn | l = \map g t | r = \map f {-t} | c = [[Repeated Fourier Transform of Real Function]] }} {{eqn | r = \map f t | c = {{Defof|Even Function}} }} {{end-eqn}} {{qed}}	0
:$\displaystyle \int \frac {\mathrm d x} {p + q \tanh a x} = \frac {p x} {p^2 - q^2} - \frac q {a \left({p^2 - q^2}\right)} \ln \left\vert{q \sinh a x + p \cosh a x}\right\vert + C$	0
From [[Harmonic Series is Divergent]], we have that $\displaystyle \sum_{n \mathop = 1}^\infty \frac 1 n$ [[Definition:Divergent Series|diverges]] to $+\infty$. Thus from the [[Integral Test]]: :$\displaystyle \int_1^n \frac {\d x} x \to +\infty$ [[Definition:Divergent Improper Integral|diverges]]. {{qed}}	0
The proof proceeds by [[Principle of Mathematical Induction|induction]]. For all $n \in \Z_{\ge 0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :There are $m^n$ [[Definition:Partial Derivative|partial derivatives]] of $u$ of [[Definition:Order of Partial Derivative|order $n$]]. $\map P 0$ is the [[Definition:Degenerate Case|degenerate case]] where $f$ is not [[Definition:Partial Derivative|partially differentiated]] at all: :$\map f {x_1, x_2, \ldots, x_m}$ and it is apparent that there is only $1 = m^0$ such. Thus $\map P 0$ is seen to hold. === Basis for the Induction === $\map P 1$ is the case: :There are $m^1 = m$ [[Definition:Partial Derivative|partial derivatives]] of $u$ of [[Definition:Order of Partial Derivative|order $1$]]. These can be instanced as: {{begin-eqn}} {{eqn | l = \map {f_1} {x_1, x_2, \ldots, x_m} | r = \dfrac {\partial u} {\partial {x_1} } }} {{eqn | l = \map {f_2} {x_1, x_2, \ldots, x_m} | r = \dfrac {\partial u} {\partial {x_2} } }} {{eqn | o = \vdots }} {{eqn | l = \map {f_m} {x_1, x_2, \ldots, x_m} | r = \dfrac {\partial u} {\partial {x_m} } }} {{end-eqn}} and it is apparent that there are $m$ such. Thus $\map P 1$ is seen to hold. This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is the [[Definition:Induction Hypothesis|induction hypothesis]]: :There are $m^k$ [[Definition:Partial Derivative|partial derivatives]] of $u$ of [[Definition:Order of Partial Derivative|order $k$]]. from which it is to be shown that: :There are $m^{k + 1}$ [[Definition:Partial Derivative|partial derivatives]] of $u$ of [[Definition:Order of Partial Derivative|order $k + 1$]]. === Induction Step === This is the [[Definition:Induction Step|induction step]]: Let $g$ be one of the [[Definition:Partial Derivative|partial derivatives]] of $u$ of [[Definition:Order of Partial Derivative|order $k$]]. Then by the [[Number of Partial Derivatives of Order n#Basis for the Induction|basis for the induction]], there are $m$ [[Definition:Partial Derivative|partial derivatives]] of $g$. By the [[Number of Partial Derivatives of Order n#Induction Hypothesis|induction hypothesis]], there are $m^k$ [[Definition:Partial Derivative|partial derivatives]] of $u$ of [[Definition:Order of Partial Derivative|order $k$]]. Thus by the [[Product Rule for Counting]], there are $m \times m^n$ [[Definition:Partial Derivative|partial derivatives]] of $u$ of [[Definition:Order of Partial Derivative|order $k + 1$]]. That is, a total of $m^{k + 1}$ [[Definition:Partial Derivative|partial derivatives]] of $u$ of [[Definition:Order of Partial Derivative|order $k + 1$]]. So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\forall n \in \Z_{\ge 0}:$ there are $m^n$ [[Definition:Partial Derivative|partial derivatives]] of $u$ of [[Definition:Order of Partial Derivative|order $n$]]. {{qed}}	0
The [[Definition:Second Order ODE|second order ODE]]: :$(1): \quad y'' + 4 y = 4 \cos 2 x + 6 \cos x + 8 x^2 - 4 x$ has the [[Definition:General Solution to Differential Equation|general solution]]: :$y = C_1 \sin 2 x + C_2 \cos 2 x + x \sin 2 x + 2 \cos x - 1 - x + 2 x^2$	0
{{begin-eqn}} {{eqn | l = \int \frac {\mathrm d x} {\sin a x \cos a x} | r = \int \frac {\sec a x \ \mathrm d x} {\sin a x} | c = [[Secant is Reciprocal of Cosine]] }} {{eqn | r = \int \frac {\sec^2 a x \ \mathrm d x} {\sin a x \sec a x} | c = multiplying [[Definition:Numerator|top]] and [[Definition:Denominator|bottom]] by $\sec a x$ }} {{eqn | r = \int \frac {\sec^2 a x \ \mathrm d x} {\frac {\sin a x} {\cos a x} } | c = [[Secant is Reciprocal of Cosine]] }} {{eqn | r = \int \frac {\sec^2 a x \ \mathrm d x} {\tan a x} | c = [[Tangent is Sine divided by Cosine]] }} {{eqn | r = \frac 1 a \ln \left\vert{\tan a x}\right\vert + C | c = [[Primitive of Square of Secant of a x over Tangent of a x|Primitive of $\dfrac {\sec^2 a x} {\tan a x}$]] }} {{end-eqn}} {{qed}}	0
Let $c, d \in \closedint a b$ such that $c < d$. Then $f$ satisfies the conditions of the [[Mean Value Theorem]] on $\closedint c d$. Hence: :$\exists \xi \in \openint c d: \map {f'} \xi = \dfrac {\map f d - \map f c} {d - c}$ Let $f$ be such that: :$\forall x \in \openint a b: \map {f'} x \le 0$ Then: :$\map {f'} \xi \le 0$ and hence: :$\map f d \le \map f c$ Thus $f$ is [[Definition:Decreasing Real Function|decreasing]] on $\closedint a b$. {{qed}}	0
{{begin-eqn}} {{eqn | l = \int \frac {x \ \mathrm d x} {\left({a x + b}\right)^2} | r = \int \frac {a x \ \mathrm d x} {a \left({a x + b}\right)^2} | c = multiplying [[Definition:Numerator|top]] and [[Definition:Denominator|bottom]] by $a$ }} {{eqn | r = \int \frac {\left({a x + b - b}\right) \ \mathrm d x} {a \left({a x + b}\right)^2} | c = adding and subtracting $b$ }} {{eqn | r = \frac 1 a \int \frac {\left({a x + b}\right) \ \mathrm d x} {\left({a x + b}\right)^2} - \frac b a \int \frac {\mathrm d x} {\left({a x + b}\right)^2} | c = [[Linear Combination of Integrals]] }} {{eqn | r = \frac 1 a \int \frac {\mathrm d x} {a x + b} - \frac b a \int \frac {\mathrm d x} {\left({a x + b}\right)^2} | c = simplification }} {{eqn | r = \frac 1 a \left({\frac 1 a \ln \left\vert{a x + b}\right\vert}\right) - \frac b a \int \frac {\mathrm d x} {\left({a x + b}\right)^2} + C | c = [[Primitive of Reciprocal of a x + b|Primitive of Reciprocal of $\dfrac 1 {\left({a x + b}\right)}$]] }} {{eqn | r = \frac 1 a \left({\frac 1 a \ln \left\vert{a x + b}\right\vert}\right) - \frac b a \left({-\frac 1 {a \left({a x + b}\right)} }\right) + C | c = [[Primitive of Reciprocal of a x + b squared|Primitive of Reciprocal of $\dfrac 1 {\left({a x + b}\right)^2}$]] }} {{eqn | r = \frac b {a^2 \left({a x + b}\right)} + \frac 1 {a^2} \ln \left\vert{a x + b}\right\vert + C | c = simplification }} {{end-eqn}} {{qed}}	0
Let $f: \R \to \R$ be the [[Definition:Square (Algebra)|square function]]: :$\forall x \in \R: \map f x = x^2$ Then the [[Definition:Derivative|derivative]] of $f$ is given by: :$\map {f'} x = 2 x$	0
=== Necessary Condition === Set $\mathbf y = \map {\boldsymbol \psi} {x, \mathbf y}$ in the definition of [[Definition:Canonical Variable|momenta]] and [[Definition:Hamiltonian|Hamiltonian]]. Substitute corresponding definitions into the [[Euler's Equation for Vanishing Variation in Canonical Variables|consistency]] relation. On the {{LHS}} we have: :$\dfrac {\partial \map {p_i} {x, \mathbf y, \map {\boldsymbol \psi} {x, \mathbf y} } } {\partial x} = \dfrac {\partial^2 \map F {x, \mathbf y, \map {\boldsymbol \psi} {x,\mathbf y} } } {\partial x \partial y_i'}$ On the {{RHS}} we have: {{begin-eqn}} {{eqn | l = -\dfrac {\partial \map H {x, \mathbf y, \map {\boldsymbol \psi} {x, \mathbf y} } } {\partial y_i} | r = -\dfrac {\partial \paren {-\map F {x, \mathbf y, \map {\boldsymbol \psi} {x, \mathbf y} } + \map {\mathbf p} {x, \mathbf y, \map {\boldsymbol \psi} {x, \mathbf y} } \map {\mathbf y'} x} } {\partial y_i} }} {{eqn | r = \frac {\partial F} {\partial y_i} - \frac {\partial^2 F} {\partial y_i \partial \mathbf y'} \boldsymbol \psi - \frac {\partial F} {\partial \mathbf y'} \frac {\partial \boldsymbol \psi} {\partial y_i} }} {{end-eqn}} Together they imply: :$\dfrac {\partial^2 F} {\partial x \partial y_i'} = \dfrac {\partial F} {\partial y_i} - \dfrac {\partial^2 F} {\partial y_i \partial \mathbf y'} \boldsymbol \psi - \dfrac {\partial F} {\partial \mathbf y'} \dfrac {\partial \boldsymbol \psi} {\partial y_i}$ By [[Necessary and Sufficient Condition for Boundary Conditions to be Self-adjoint]]: :$\dfrac {\partial^2 F} {\partial y_i \partial y_k'} = \dfrac {\partial^2 F} {\partial y_k \partial y_i'}$ Then: :$\dfrac {\partial^2 F} {\partial x \partial y_i'} = \dfrac {\partial F} {\partial y_i} - \dfrac {\partial^2 F} {\partial \mathbf y \partial y_i'} \boldsymbol \psi - \dfrac {\partial F} {\partial \mathbf y'} \dfrac {\partial \boldsymbol \psi} {\partial y_i}$ $F$ [[Definition:Depend|depends]] on $\mathbf y'$ only through its third [[Definition:Vector|vector]] [[Definition:Variable|variable]], thus $\dfrac {\partial F} {\partial y_k'} = F_{y_k'}$: :$(2): \quad \dfrac {\partial F_{y_i'} } {\partial x} = \dfrac {\partial F} {\partial y_i} - \dfrac {\partial F_{y_i'} } {\partial \mathbf y} \boldsymbol \psi - F_{\mathbf y'} \dfrac {\partial \boldsymbol \psi} {\partial y_i}$ $F$ [[Definition:Depend|depends]] on $x$ directly through its first [[Definition:Variable|variable]] and indirectly through its third [[Definition:Vector|vector]] variable together with [[Definition:Boundary Condition|boundary conditions]] $(1)$: :$\dfrac {\partial F_{y_i'} } {\partial x} = F_{y_i' x} + F_{y_i' \mathbf y'} \boldsymbol \psi_x$ $F$ [[Definition:Depend|depends]] on $\mathbf y$ directly through its second [[Definition:Vector|vector]] [[Definition:Variable|variable]] and indirectly through its third [[Definition:Vector|vector]] [[Definition:Variable|variable]] together with [[Definition:Boundary Condition|boundary conditions]] $(1)$: :$\dfrac {\partial F} {\partial y_i} = F_{y_i} + F_{\mathbf y'} \boldsymbol \psi_{y_i}$ :$\ds \dfrac {\partial F_{y_i'} } {\partial \mathbf y} = F_{y_i' \mathbf y} + \sum_{k \mathop = 1}^N F_{y_i'y_k'} \dfrac {\partial \psi_k} {\partial \mathbf y}$ Substitution of the last three equations into $\paren 2$ leads to: :$\ds F_{y_i' x} + F_{y_i' \mathbf y'} \boldsymbol \psi_x = F_{y_i} + F_{\mathbf y'} \boldsymbol \psi_{y_i} - \paren {F_{y_i' \mathbf y} + \sum_{k \mathop = 1}^N F_{y_i'y_k'} \dfrac {\partial \psi_k} {\partial \mathbf y} } \boldsymbol \psi - F_{\mathbf y'} \dfrac {\partial \boldsymbol \psi} {\partial y_i}$ which can be simplified to: :$F_{y_i} - F_{y_i' x} - F_{y_i' \mathbf y} \boldsymbol \psi - F_{y_i' y_j'} \paren {\dfrac {\partial \psi_j} {\partial x} + \dfrac {\partial \psi_j} {\partial y_j} \psi_j} = 0$ By assumption: :$\dfrac {\d y_k} {\d x} = \psi_k$ the [[Definition:Second Derivative|second]] [[Definition:Total Derivative|total derivative]] {{WRT}} $x$ of which yields: {{begin-eqn}} {{eqn | l = \frac {\d^2 y_k} {\d x^2} | r = \frac {\d y_k'} {\d x} }} {{eqn | r = \frac {\d \psi_k} {\d x} }} {{eqn | r = \frac {\partial \psi_k} {\partial x} + \frac {\partial \psi_k} {\partial \mathbf y} \frac {\d \mathbf y} {\d x} | c = [[Definition:Total Derivative|Total Derivative]] of $\psi_k$ {{WRT}} $x$ }} {{eqn | r = \frac {\partial \psi_k} {\partial x} + \frac {\partial \psi_k} {\partial \mathbf y} \boldsymbol \psi }} {{end-eqn}} Hence: :$F_{y_i} - \paren {F_{y_i' x} + F_{y_i' \mathbf y} \dfrac {\d \mathbf y} {\d x} + F_{y_i' \mathbf y'} \dfrac {\d \mathbf y'} {\d x} } = 0$ The second term is just a [[Definition:Total Derivative|total derivative]] {{WRT}} $x$, thus: :$(3): \quad F_{y_i} - \dfrac {\d F_{y_i'} } {\d x} = 0$ [[Definition:Boundary Condition|Boundary conditions]] $(1)$ are [[Definition:Mutually Consistent Boundary Conditions|mutually consistent]] {{WRT}} equation $(3)$ because they hold $\forall x \in \closedint a b$. By definition, they are [[Definition:Mutually Consistent Boundary Conditions/wrt Functional|consistent {{WRT}} the functional $J$]]. Since the [[Definition:Boundary Condition|boundary conditions]] are [[Definition:Mutually Consistent Boundary Conditions|consistent {{WRT}} $J$]] and [[Definition:Self-Adjoint Boundary Conditions|self-adjoint]], by definition they constitute a [[Definition:Field of Directions of Functional|field of $J$]]. {{qed|lemma}} === Sufficient Condition === By assumption, $(1)$ is a [[Definition:Field of Directions of Functional|field of $J$]]. Hence, $(1)$ is [[Definition:Self-Adjoint Boundary Conditions|self-adjoint]] and [[Definition:Mutually Consistent Boundary Conditions/wrt Functional|mutually consistent {{WRT}} $J$]]. Thus, by definition, they are [[Definition:Mutually Consistent Boundary Conditions/wrt Functional|consistent]] {{WRT}}: :$F_{y_i} - \dfrac {\d F_{y_i'} } {\d x} = 0$ The {{LHS}} can be rewritten as follows: {{begin-eqn}} {{eqn | l = F_{y_i} - \frac {\d F_{y_i'} } {\d x} | r = F_{y_i} - \paren {F_{y_i' x} + F_{y_i' \mathbf y} \frac {\d \mathbf y} {\d x} + F_{y_i' \mathbf y'} \frac {\d \mathbf y'} {\d x} } }} {{eqn | r = F_{y_i} - \paren {F_{y_i' x} + F_{y_i' \mathbf y} \boldsymbol \psi + F_{y_i' \mathbf y'} \paren {\frac {\partial \boldsymbol \psi} {\partial x} + \sum_{k \mathop = 1}^N \frac {\partial \boldsymbol \psi} {\partial y_k} \psi_k} } | c = as $\ds \frac {\d \mathbf y'} {\d x} = \frac {\partial \boldsymbol \psi} {\partial x} + \sum_{k \mathop = 1}^N \frac {\partial \boldsymbol \psi} {\partial y_k} \psi_k$ }} {{eqn | r = \frac {\partial F} {\partial y_i} - F_{\mathbf y'} \boldsymbol \psi_{y_i} - \paren {\frac {\partial F_{y_i'} } {\partial x} + F_{y_i' \mathbf y} \boldsymbol \psi + F_{y_i' \mathbf y'} \sum_{k \mathop = 1}^N \frac {\partial \boldsymbol \psi} {\partial y_k} \psi_k} | c = as $\dfrac {\partial F} {\partial y_i} = F_{y_i} + F_{\mathbf y'} \boldsymbol \psi_{y_i}$ }} {{eqn | r = \frac {\partial F} {\partial y_i} - F_{\mathbf y'} \boldsymbol \psi_{y_i} - \paren {\frac {\partial F_{y_i'} } {\partial x} + \paren { {\frac {\partial F_{y_i'} } {\partial \mathbf y} - \sum_{k \mathop = 1}^N F_{y_i' y_k'} \frac {\partial \psi_k} {\partial \mathbf y} } } \boldsymbol \psi + F_{y_i' \mathbf y'} \sum_{k \mathop = 1}^N \frac {\partial \boldsymbol \psi} {\partial y_k} \psi_k} | c = as $\dfrac {\partial F_{y_i'} } {\partial \mathbf y} = F_{y_i' \mathbf y} + \sum_{k \mathop = 1}^N F_{y_i' y_k'} \frac {\partial \psi_k} {\partial \mathbf y}$ }} {{eqn | r = \frac {\partial F} {\partial y_i} - F_{\mathbf y'} \boldsymbol \psi_{y_i} - \frac {\partial F_{y_i'} } {\partial x} - \frac {\partial F_{y_i'} } {\partial \mathbf y} \boldsymbol \psi }} {{eqn | r = \frac {\partial F} {\partial y_i} - \frac {\partial F} {\partial \mathbf y'} \frac {\partial \boldsymbol \psi} {\partial y_i} - \frac {\partial^2 F} {\partial x \partial y_i'} - \frac {\partial^2 F} {\partial \mathbf y \partial y_i'} \boldsymbol \psi | c = as $F$ [[Definition:Depend|depends]] on $\mathbf y'$ only through its third [[Definition:Vector|vector]] [[Definition:Variable|variable]] }} {{eqn | r = \frac {\partial F} {\partial y_i} - \frac {\partial F} {\partial \mathbf y'} \frac {\partial \boldsymbol \psi} {\partial y_i} - \frac {\partial^2 F} {\partial x \partial y_i'} - \frac {\partial^2 F} {\partial y_i \partial \mathbf y'} \boldsymbol \psi | c = By assumption, [[Necessary and Sufficient Condition for Boundary Conditions to be Self-adjoint|boundary conditions are self-adjoint]] }} {{eqn | r = \frac {\partial F} {\partial y_i} - \mathbf p \frac {\partial \mathbf y'} {\partial y_i} - \frac {\partial p_i} {\partial x} - \frac {\partial \mathbf p} {\partial y_i} \mathbf y' }} {{eqn | r = \frac {\partial F} {\partial y_i} - \frac {\partial p_i} {\partial x} - \frac {\partial \paren {\mathbf p \mathbf y'} } {\partial y_i} }} {{eqn | r = -\frac {\partial p_i} {\partial x} - \frac {\partial \paren {-F + \mathbf p \mathbf y'} } {\partial y_i} }} {{eqn | r = -\frac {\partial p_i} {\partial x} - \frac {\partial H} {\partial y_i} }} {{end-eqn}} The {{RHS}} vanishes. Therefore: :$\dfrac {\partial \mathbf p} {\partial x} = -\dfrac {\partial H} {\partial \mathbf y}$ By [[Necessary and Sufficient Condition for Boundary Conditions to be Self-adjoint]]: :$\dfrac {\partial^2 F} {\partial y_i \partial y_k'} = \dfrac {\partial^2 F} {\partial y_k \partial y_i'}$ By definition of [[Definition:Canonical Variable|canonical variable]]: :$\mathbf p = \dfrac {\partial F} {\partial \mathbf y'}$ Hence: :$\dfrac {\partial p_k} {\partial y_i} = \dfrac {\partial p_i} {\partial y_k}$ {{qed}}	0
With a view to expressing the [[Definition:Primitive|primitive]] in the form: :$\displaystyle \int u \frac {\mathrm d v}{\mathrm d x} \ \mathrm d x = u v - \int v \frac {\mathrm d u}{\mathrm d x} \ \mathrm d x$ let: {{begin-eqn}} {{eqn | l = u | r = x | c = }} {{eqn | ll= \implies | l = \frac {\mathrm d u}{\mathrm d x} | r = 1 | c = [[Derivative of Identity Function]] }} {{end-eqn}} and let: {{begin-eqn}} {{eqn | l = \frac {\mathrm d v}{\mathrm d x} | r = \cosh^2 a x | c = }} {{eqn | ll= \implies | l = v | r = \frac {\sinh 2 a x} {4 a} + \frac x 2 | c = [[Primitive of Square of Hyperbolic Cosine of a x/Corollary|Primitive of $\cosh^2 a x$]] }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = \int x \cosh^2 a x \ \mathrm d x | r = x \left({\frac {\sinh 2 a x} {4 a} + \frac x 2}\right) - \int \left({\frac {\sinh 2 a x} {4 a} + \frac x 2}\right) \times 1 \ \mathrm d x + C | c = [[Integration by Parts]] }} {{eqn | r = \frac {x \sinh 2 a x} {4 a} + \frac {x^2} 2 - \frac 1 {4 a} \int \sinh 2 a x \ \mathrm d x - \frac 1 2 \int x \ \mathrm d x + C | c = [[Linear Combination of Integrals]] }} {{eqn | r = \frac {x \sinh 2 a x} {4 a} + \frac {x^2} 2 - \frac 1 {4 a} \int \sinh 2 a x \ \mathrm d x - \frac {x^2} 4 + C | c = [[Primitive of Power]] }} {{eqn | r = \frac {x \sinh 2 a x} {4 a} + \frac {x^2} 2 - \frac 1 {4 a} \frac {\cosh 2 a x} {2 a} - \frac {x^2} 4 + C | c = [[Primitive of Hyperbolic Sine of a x|Primitive of $\sinh a x$]] }} {{eqn | r = \frac {x \sinh 2 a x} {4 a} - \frac {\cosh 2 a x} {8 a^2} + \frac {x^2} 4 + C | c = simplifying }} {{end-eqn}} {{qed}}	0
In the [[Definition:Summation|summation]]: :$\displaystyle \sum_{j \mathop = 0}^2 D_u^j w \sum_{\substack {\sum_{p \mathop \ge 1} k_p \mathop = j \\ \sum_{p \mathop \ge 1} p k_p \mathop = 2 \\ \forall p \ge 1: k_p \mathop \ge 0} } 2! \prod_{m \mathop = 1}^2 \dfrac {\left({D_x^m u}\right)^{k_m} } {k_m! \left({m!}\right)^{k_m} }$ we need to consider $j = 0, j = 1$ and $j = 2$. Note that when $k_m = 0$: :$\dfrac {\left({D_x^m u}\right)^{k_m} } {k_m! \left({m!}\right)^{k_m} } = 1$ by definition of [[Definition:Zeroth Derivative|zeroth derivative]] and [[Definition:Factorial|factorial of $0$]]. Thus any contribution to the [[Definition:Summation|summation]] where $k_m = 0$ can be disregarded. Let $j = 0$. Consider the set of $k_p$ such that: :$k_1 + k_2 + \cdots = 0$ :$1 \times k_1 + 2 k_2 + \cdots = 2$ :$k_1, k_2, \ldots \ge 0$ It is apparent by inspection that no set of $k_p$ can fulfil these conditions. Therefore when $j = 0$ the [[Definition:Summation|summation]] is [[Definition:Vacuous Summation|vacuous]] Let $j = 1$. Consider the set of $k_p$ such that: :$k_1 + k_2 + \cdots = 1$ :$1 \times k_1 + 2 k_2 + \cdots = 2$ :$k_1, k_2, \ldots \ge 0$ By inspection, it is seen that these can be satisfied only by: :$k_2 = 1$ and all other $k_p = 0$. Let $j = 2$. Consider the set of $k_p$ such that: :$k_1 + k_2 + \cdots = 2$ :$1 \times k_1 + 2 k_2 + \cdots = 2$ :$k_1, k_2, \ldots \ge 0$ By inspection, it is seen that these can be satisfied only by: :$k_1 = 2$ and all other $k_p = 0$. Thus we have: {{begin-eqn}} {{eqn | o = | r = \sum_{j \mathop = 0}^2 D_u^j w \sum_{\substack {k_1 \mathop + k_2 \mathop = j \\ k_1 \mathop + 2 k_2 \mathop = 2 \\ k_1, k_2 \mathop \ge 0} } 2! \dfrac {\left({D_x^1 u}\right)^{k_1} \left({D_x^2 u}\right)^{k_2} } {k_1! \left({1!}\right)^{k_1} k_2! \left({2!}\right)^{k_2} } | c = }} {{eqn | r = D_u^1 w \dfrac {2! \left({D_x^1 u}\right)^0 \left({D_x^2 u}\right)^1} {0! \left({1!}\right)^0 1! 2^1} + D_u^2 w \dfrac {2! \left({D_x^1 u}\right)^2 \left({D_x^2 u}\right)^0} {2! \left({1!}\right)^2 0! \left({2!}\right)^0} | c = substituting for $k_1$ and $k_2$ for each case }} {{eqn | r = D_u^1 w \left({D_x^2 u}\right) + D_u^2 w \left({D_x^1 u}\right)^2 | c = simplifying }} {{end-eqn}} {{qed}}	0
It can be seen that $(1)$ is a [[Definition:Constant Coefficient Homogeneous Linear Second Order ODE|constant coefficient homogeneous linear second order ODE]]. Its [[Definition:Auxiliary Equation|auxiliary equation]] is: :$(2): \quad: m^2 - 2 m - 5 = 0$ From [[Solution to Quadratic Equation with Real Coefficients]], the [[Definition:Root of Polynomial|roots]] of $(2)$ are: :$m_1 = 1 + \sqrt 6$ :$m_2 = 1 - \sqrt 6$ So from [[Solution of Constant Coefficient Homogeneous LSOODE]], the [[Definition:General Solution to Differential Equation|general solution]] of $(1)$ is: :$y = C_1 \, \map \exp {\paren {1 + \sqrt 6} x} + C_2 \, \map \exp {\paren {1 - \sqrt 6} x}$ {{qed}} [[Category:Examples of Constant Coefficient Homogeneous LSOODEs]] 4x3uefk7dz7qyoq1ta764cjytli7mrl	0
:$\displaystyle \int \frac {\mathrm d x} {\sinh a x \cosh^2 a x} = \frac 1 a \ln \left\vert{\tanh \frac {a x} 2}\right\vert + \frac {\operatorname{sech} a x} a + C$	0
{{begin-eqn}} {{eqn | l = \int \frac {\d x} {\sqrt {x^2 + a^2} } | r = \sinh^{-1} {\frac x a} + C | c = [[Primitive of Reciprocal of Root of x squared plus a squared/Inverse Hyperbolic Sine Form|Primitive of $\dfrac 1 {\sqrt {x^2 - a^2} }$ in $\sinh^{-1}$ form]] }} {{eqn | r = \map \ln {x + \sqrt {x^2 + a^2} } - \ln a + C | c = [[Inverse Hyperbolic Sine of x over a in Logarithm Form|$\sinh^{-1} {\dfrac x a}$ in Logarithm Form]] }} {{eqn | r = \map \ln {x + \sqrt {x^2 + a^2} } + C | c = subsuming $-\ln a$ into [[Definition:Arbitrary Constant (Calculus)|arbitrary constant]] }} {{end-eqn}} {{qed}}	0
The [[Definition:Second Order ODE|second order ODE]]: :$(1): \quad y'' + k^2 y = \sin b x$ has the [[Definition:General Solution to Differential Equation|general solution]]: :$y = \begin{cases} C_1 \sin k x + C_2 \cos k x + \dfrac {\sin b x} {k^2 - b^2} & : b \ne k \\ C_1 \sin k x + C_2 \cos k x - \dfrac {x \cos k x} {2 k} & : b = k \end{cases}$	0
Let $\map f t := \map \Si t = \displaystyle \int_0^t \dfrac {\sin u} u \rd u$. Then: :$\map f 0 = 0$ and: {{begin-eqn}} {{eqn | l = \map \Si t | r = \int_0^t \dfrac {\sin u} u \rd u | c = {{Defof|Sine Integral Function}} }} {{eqn | r = \int_0^t \dfrac 1 u \paren {u - \dfrac {u^3} {3!} + \dfrac {u^5} {5!} - \dfrac {u^7} {7!} + \dotsb} \rd u | c = {{Defof|Real Sine Function}} }} {{eqn | r = t - \dfrac {t^3} {3 \times 3!} + \dfrac {t^5} {5 \times 5!} - \dfrac {t^7} {7 \times 7!} + \dotsb | c = [[Primitive of Power]] }} {{eqn | ll= \leadsto | l = \laptrans {\map \Si t} | r = \laptrans {t - \dfrac {t^3} {3 \times 3!} + \dfrac {t^5} {5 \times 5!} - \dfrac {t^7} {7 \times 7!} + \dotsb} | c = }} {{eqn | r = \dfrac 1 {s^2} - \dfrac 1 {3 \times 3!} \dfrac {3!} {s^4} + \dfrac 1 {5 \times 5!} \dfrac {5!} {s^6} - \dfrac 1 {7 \times 7!} \dfrac {7!} {s^8} + \dotsb | c = [[Laplace Transform of Positive Integer Power]] }} {{eqn | r = \dfrac 1 {s^2} - \dfrac 1 {3 s^4} + \dfrac 1 {5 s^6} - \dfrac 1 {7 s^8} + \dotsb | c = simplifying }} {{eqn | r = \dfrac 1 s \paren {\dfrac {\paren {1 / s} } 1 - \dfrac {\paren {1 / s}^3} 3 + \dfrac {\paren {1 / s}^5} 5 - \dfrac {\paren {1 / s}^7} 7 + \dotsb} | c = rearranging }} {{eqn | r = \dfrac 1 s \arctan \dfrac 1 s | c = [[Power Series Expansion for Real Arctangent Function]] }} {{end-eqn}} {{qed}}	0
The [[Definition:First Order ODE|first order ODE]]: :$(1): \quad x \rd y = k y \rd x$ has the [[Definition:General Solution of Differential Equation|general solution]]: :$y = C x^k$	0
Let $I = \closedint a b$ and $J = \closedint c d$ be [[Definition:Closed Real Interval|closed real intervals]]. Let $I^o = \openint a b$ and $J^o = \openint c d$ be the corresponding [[Definition:Open Real Interval|open real intervals]]. Let $f: I \to J$ be a [[Definition:Real Function|real function]] which is [[Definition:Continuous on Interval|continuous]] on $I$ and [[Definition:Differentiable on Interval|differentiable]] on $I^o$ such that $J = f \sqbrk I$. Let either: :$\forall x \in I^o: D \map f x > 0$ or: :$\forall x \in I^o: D \map f x < 0$ Then: :$f^{-1}: J \to I$ exists and is [[Definition:Continuous on Interval|continuous]] on $J$ :$f^{-1}$ is [[Definition:Differentiable on Interval|differentiable]] on $J^o$ :$\forall y \in J^o: D \map {f^{-1} } y = \dfrac 1 {D \map f x}$	0
Consider a [[Definition:Particle|particle]] $P$ which is constrained to move on a [[Definition:Curved Surface|curved surface]] $C$. Let $P$ be such that no [[Definition:Force|force]] acts upon it. Then $P$ moves along a [[Definition:Geodesic Curve|geodesic]].	0
{{begin-eqn}} {{eqn | l = \int e^{a x} e^{i b x} \rd x | r = i \int e^{a x} \sin b x \rd x + \int e^{a x} \cos b x \rd x | c = [[Euler's Formula]] }} {{eqn | ll= \leadsto | l = \int e^{a x} \cos b x \rd x | r = \map \Re {\int e^{\paren {a + i b} x} \rd x} }} {{eqn | r = \map \Re {\frac {e^{\paren {a + i b} x} } {a + i b} } + C | c = [[Primitive of Exponential of a x]] }} {{eqn | r = \map \Re {\frac {\paren {a - i b} e^{\paren {a + i b} x} } {a^2 + b^2} } + C | c = multiplying through by $\dfrac {a - i b} {a - i b}$ }} {{eqn | r = \map \Re {\frac {i a e^{a x} \sin b x + a e^{a x} \cos b x - i b \paren {i e^{a x} \sin b x + e^{a x} \cos b x} } {a^2 + b^2} } + C | c = [[Euler's Formula]] }} {{eqn | r = \map \Re {\frac {i \paren {a e^{a x} \sin b x - b e^{a x} \cos b x} + \paren {a e^{a x} \cos b x + b e^{a x} \sin b x} } { a^2 + b^2} } + C }} {{eqn | r = \frac {e^{a x} \paren {a \cos b x + b \sin b x} } {a^2 + b^2} + C | c = isolating real part }} {{end-eqn}} {{qed}}	0
Let $v_1, v_2, \dots, v_n$ be linearly independent vectors in $\R^n$, and let $\phi_i$ be solutions to the IVPs $x' = A \left({t}\right) x, \, x \left({t_0}\right) = v_i$ for $i = 1, 2, \dots, n$. Suppose the solutions are not independent, i.e. $c_1 \phi_1 + c_2 \phi_2 + \cdots + c_n \phi_n = 0$ for some constants $c_i$ not all zero. Then: : $c_1 \phi_1 \left({t_0}\right) + c_2 \phi_2 \left({t_0}\right) + \cdots c_n \phi_n \left({t_0}\right) = c_1 v_1 + c_2 v_2 + \cdots + c_n v_n = 0$ meaning the vectors $v_i$ are linearly dependent, a contradiction, so the solutions $\phi_i$ must be linearly independent. By linearity of the system, every vector function of the form $ x = c_1 \phi_1 + \cdots + c_n \phi_n$ is a solution. Let $z$ be an arbitrary solution of the system. Since $\phi_i \left({t_0}\right)$ are linearly independent and count $n$ in number, they form a basis for $\R^n$, hence $z \left({t_0}\right)$ must be a linear combination of those solutions, and then by uniqueness of solutions $z$ is a linear combination of the vector functions $\phi_i$. This proves this is a general solution. {{qed}} [[Category:Ordinary Differential Equations]] e8ruc4vwedz8lj7on6a708g9e0wpcv7	0
=== [[Laplace Transform of Dirac Delta Function/Lemma|Lemma]] === {{:Laplace Transform of Dirac Delta Function/Lemma}} Then: {{begin-eqn}} {{eqn | l = \laptrans {\map \delta t} | r = \lim_{\epsilon \mathop \to 0} \laptrans {\map {F_\epsilon} t} | c = {{Defof|Dirac Delta Function}} }} {{eqn | r = \lim_{\epsilon \mathop \to 0} \dfrac {1 - e^{-s \epsilon} } {\epsilon s} | c = [[Laplace Transform of Dirac Delta Function/Lemma|Lemma]] }} {{eqn | r = \lim_{\epsilon \mathop \to 0} \dfrac 1 {\epsilon s} \paren {1 - \paren {1 - s \epsilon + \dfrac {s^2 \epsilon^2} {2!} - \dotsb} } | c = {{Defof|Exponential Function/Real|subdef = Sum of Series|Exponential Function}} }} {{eqn | r = \lim_{\epsilon \mathop \to 0} \paren {1 - \dfrac {s \epsilon} {2!} + \dotsb} | c = }} {{eqn | r = 1 | c = }} {{end-eqn}} {{qed}}	0
Let $\Omega\subset\R^n$ be [[Definition:Open Set of Real Euclidean Space|open]]. Let $f : \Omega \to \R^k$ be an [[Definition:Submersion|submersion]]. Let $p\in\Omega$. Then $n\geq k$, and there exists a [[Definition:Local Diffeomorphism|local diffeomorphism]] $\phi$ around $f(p)$ such that :$\phi\circ f (x, y) = x$ for all $(x, y)$ in a [[Definition:Neighborhood (Topology)|neighborhood]] of $p$.	0
:$\displaystyle \int \frac {x \ \mathrm d x} {\left({x^2 + a^2}\right)^n} = \frac {-1} {2 \left({n - 1}\right) \left({x^2 + a^2}\right)^{n - 1} }$	0
There are three cases: :$0 \le k$ :$-x^2 < k < 0$ :$k < -x^2$ === $(1): \quad 0 \le k$ === If $0 \le k$ then $k = a^2$ for some $a \in \R$. Then [[Primitive of Reciprocal of Root of x squared plus a squared|Primitive of $\dfrac 1 {\sqrt {x^2 + a^2} }$]] applies: :$\displaystyle \int \frac {\d x} {\sqrt {x^2 + a^2} } = \map \ln {x + \sqrt {x^2 + a^2} } + C$ === $(2): \quad -x^2 < k < 0$ === If $-x^2 < k < 0$ then: :$k = -a^2$ for some $a \in \R$ and: :$x^2 - a^2 > 0$ Then [[Primitive of Reciprocal of Root of x squared minus a squared|Primitive of $\dfrac 1 {\sqrt {x^2 - a^2} }$]] applies: :$\displaystyle \int \frac {\d x} {\sqrt {x^2 - a^2} } = \map \ln {x + \sqrt {x^2 - a^2} } + C$ === $(3): \quad k < -x^2$ === If $k < -x^2$ then: :$k = -a^2$ for some $a \in \R$ and: :$a^2 - x^2 > 0$ Then [[Primitive of Reciprocal of Root of a squared minus x squared/Arcsine Form|Primitive of $\dfrac 1 {\sqrt {a^2 - x^2} }$]] applies: :$\displaystyle \int \frac {\d x} {\sqrt {a^2 - x^2} } = \map \ln {x + \sqrt {a^2 - x^2} } + C$ The result holds for all three cases. {{qed}} [[Category:Primitives involving Root of x squared plus a squared]] [[Category:Primitives involving Root of x squared minus a squared]] [[Category:Primitives involving Root of a squared minus x squared]] [[Category:Primitives involving Reciprocals]] d9jhgj45z2hif4ntthtibtbnusj6dwu	0
Let $n \in \R: n \ne -1$. Then: :$\ds \int x^n \rd x = \frac {x^{n + 1} } {n + 1} + C$ where $C$ is an [[Definition:Arbitrary Constant (Calculus)|arbitrary constant]]. That is: :$\dfrac {x^{n + 1} } {n + 1}$ is a [[Definition:Primitive (Calculus)|primitive]] of $x^n$.	0
From [[Reduction Formula for Primitive of Power of a x + b by Power of p x + q/Decrement of Power|Reduction Formula for Primitive of Power of $a x + b$ by Power of $p x + q$: Decrement of Power]]: :$\displaystyle \int \paren {a x + b}^m \paren {p x + q}^n \rd x = \frac {\paren {a x + b}^{m + 1} \paren {p x + q}^n} {\paren {m + n + 1} a} - \frac {n \paren {b p - a q} } {\paren {m + n + 1} a} \int \paren {a x + b}^m \paren {p x + q}^{n - 1} \rd x$ Setting $a := 1, b := 0, p x + q := a x + b$: {{begin-eqn}} {{eqn | l = \int x^m \paren {a x + b}^n \rd x | r = \frac {\paren {1 x + 0}^{m + 1} \paren {a x + b}^n} {\paren {m + n + 1} 1} - \frac {n \paren {0 a - 1 b} } {\paren {m + n + 1} 1} \int \paren {1 x + 0}^m \paren {a x + b}^{n - 1} \rd x | c = }} {{eqn | r = \frac {x^{m + 1} \paren {a x + b}^n} {m + n + 1} - \frac {n b} {\paren {m + n + 1} } \int x^m \paren {a x + b}^{n - 1} \rd x | c = }} {{end-eqn}} {{qed}}	0
From [[Continuous Real Function is Darboux Integrable]], $f$ is [[Definition:Darboux Integrable Function|Darboux integrable]] on $\closedint a b$. Let $F : \closedint a b \to \R$ be a [[Definition:Real Function|real function]] defined by: :$\displaystyle \map F x = \int_a^x \map f x \rd x$ We are assured that this function is [[Definition:Well-Defined|well-defined]], since $f$ is [[Definition:Darboux Integrable Function|integrable]] on $\closedint a b$. From [[Fundamental Theorem of Calculus/First Part|Fundamental Theorem of Calculus: First Part]], we have: : $F$ is [[Definition:Continuous Real Function|continuous]] on $\closedint a b$ : $F$ is [[Definition:Differentiable Real Function|differentiable]] on $\openint a b$ with [[Definition:Derivative of Real Function|derivative]] $f$ By the [[Mean Value Theorem]], there therefore exists $k \in \openint a b$ such that: :$\map {F'} k = \dfrac {\map F b - \map F a} {b - a}$ As $F$ is [[Definition:Differentiable Real Function|differentiable]] on $\openint a b$ with [[Definition:Derivative of Real Function|derivative]] $f$: :$\map {F'} k = \map f k$ We therefore have: {{begin-eqn}} {{eqn | l = \map f k | r = \frac {\map F b - \map F a} {b - a} }} {{eqn | r = \frac 1 {b - a} \paren {\int_a^b \map f x \rd x - \int_a^a \map f x \rd x} }} {{eqn | r = \frac 1 {b - a} \int_a^b \map f x \rd x | c = [[Definite Integral on Zero Interval]] }} {{end-eqn}} giving: :$\displaystyle \int_a^b \map f x \rd x = \paren {b - a} \map f k$ as required. {{qed}}	0
{{begin-eqn}} {{eqn | l = \int \frac {\d x} {\sin x} | r = \int \csc x \rd x | c = {{Defof|Real Cosecant Function}} }} {{eqn | r = \ln \size {\csc x - \cot x} + C | c = [[Primitive of Cosecant Function/Cosecant minus Cotangent Form|Primitive of $\csc x$: Cosecant minus Cotangent Form]] }} {{eqn | ll= \leadsto | l = \int \frac {\d x} {\sin a x} | r = \frac 1 a \ln \size {\csc a x - \cot a x} + C | c = [[Primitive of Function of Constant Multiple]] }} {{end-eqn}} {{qed}}	0
The [[Definition:Second Order ODE|second order ODE]]: :$(1): \quad y'' + 3 y' - 10 y = 6 e^{4 x}$ has the [[Definition:General Solution to Differential Equation|general solution]]: :$y = C_1 e^{2 x} + C_2 e^{-5 x} + \dfrac {e^{4 x} } 3$	0
By definition, $ \Delta J \sqbrk y$ can be expressed as: :$\Delta J \sqbrk {y; h} = \delta J \sqbrk {y; h} + \delta^2 J \sqbrk {y; h} + \epsilon \size h^2$ By [[Condition for Differentiable Functional to have Extremum|assumption]]: :$\delta J \sqbrk {\hat y; h} = 0$ Hence: :$\Delta J \sqbrk {\hat y; h} = \delta^2 J \sqbrk {\hat y; h} + \epsilon \size h^2$ Therefore, for sufficiently small $\size h$ both $\Delta J \sqbrk {\hat y; h}$ and $\delta^2 J \sqbrk {\hat y; h}$ will have the same [[Definition:Sign of Number|sign]]. {{qed|lemma}} {{AimForCont}} there exists $h = h_0$ such that: :$\delta^2 J \sqbrk {\hat y; h_0} < 0$ Then, for any $\alpha \ne 0$: {{begin-eqn}} {{eqn | l = \delta^2 J \sqbrk {\hat y; \alpha h_0} | r = \alpha^2 \delta^2 J \sqbrk {\hat y; h_0} }} {{eqn | o = < | r = 0 }} {{end-eqn}} Therefore, $\Delta J \sqbrk {\hat y; h}$ can be made negative for arbitrary small $\size h$. However, by assumption $\Delta J \sqbrk {\hat y; h}$ is a [[Definition:Minimum Value of Functional|minimum]] of $\Delta J \sqbrk {y; h}$ for all sufficiently small $\size h$. This is a [[Definition:Contradiction|contradiction]]. Thus, a [[Definition:Function|function]] $h_0: \delta^2 J \sqbrk {\hat y; h_0} < 0$ does not exist. In other words: :$\delta^2 J \sqbrk {\hat y; h} \ge 0$ for all $h$. {{qed}}	0
:$\displaystyle \int \frac {\d x} {\left({x^2 - a^2}\right)^2} = \frac {-x} {2 a^2 \left({x^2 - a^2}\right)} + \frac 1 {4 a^3} \ln \left({\frac {x + a} {x - a} }\right) + C$ for $x^2 > a^2$.	0
From [[Reduction Formula for Primitive of Power of x by Power of a x + b/Decrement of Power of a x + b|Reduction Formula for Primitive of Power of $x$ by Power of $a x + b$: Decrement of Power of $a x + b$]]: :$\displaystyle \int x^m \paren {a x + b}^n \rd x = \frac {x^{m + 1} \paren {a x + b}^n} {m + n + 1} + \frac {n b} {m + n + 1} \int x^m \paren {a x + b}^{n - 1} \rd x$ Putting $m = -1$ and $n = \dfrac 1 2$: {{begin-eqn}} {{eqn | l = \int \frac {\sqrt {a x + b} } x \rd x | r = \int x^{-1} \paren {a x + b}^{1/2} \rd x | c = }} {{eqn | r = \frac {x^0 \paren {a x + b}^{1/2} } {\frac 1 2} + \frac {\frac 1 2 b} {\frac 1 2} \int x^{-1} \paren {a x + b}^{- 1/2} \rd x | c = }} {{eqn | r = 2 \sqrt {a x + b} + b \int \frac {\d x} {x \sqrt {a x + b} } | c = simplifying }} {{end-eqn}} {{qed}}	0
:$\displaystyle \int \tan^3 a x \rd x = \frac {\tan^2 a x} {2 a} + \frac 1 a \ln \size {\cos a x} + C$	0
{{begin-eqn}} {{eqn | l = \laptrans {\sin a t} | r = \laptrans {\frac {e^{i a t} - e^{-i a t} } {2 i} } | c = [[Sine Exponential Formulation]] }} {{eqn | r = \frac 1 {2 i} \paren {\laptrans {e^{i a t} } - \laptrans {e^{-i a t} } } | c = [[Linear Combination of Laplace Transforms]] }} {{eqn | r = \frac 1 {2 i} \paren {\frac 1 {s - i a} - \frac 1 {s + i a} } | c = [[Laplace Transform of Exponential]] }} {{eqn | r = \frac 1 {2 i} \paren {\frac {s + i a - s + i a} {s^2 + a^2} } | c = simplifying }} {{eqn | r = \frac 1 {2 i} \paren {\frac {2 i a} {s^2 + a^2} } | c = simplifying }} {{eqn | r = \frac a {s^2 + a^2} | c = simplifying }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \int_0^\infty \frac {\map f {a x} - \map f {b x} } x \rd x | r = \int_0^\infty \intlimits {\frac {\map f {x t} } x} {t = b} a \rd x }} {{eqn | r = \int_0^\infty \int_b^a \map {f'} {x t} \rd t \rd x | c = [[Fundamental Theorem of Calculus]] }} {{eqn | r = \int_b^a \int_0^\infty \map {f'} {x t} \rd x \rd t | c = [[Fubini's Theorem]] }} {{eqn | r = \int_b^a \intlimits {\frac {\map f {x t} } t} {x = 0} \infty \rd t | c = [[Fundamental Theorem of Calculus]] }} {{eqn | r = \int_b^a \frac {\map f \infty - \map f 0} t \rd t }} {{eqn | r = \paren {\map f \infty - \map f 0} \paren {\ln a -\ln b} | c = [[Primitive of Reciprocal]], [[Fundamental Theorem of Calculus]] }} {{eqn | r = \paren {\map f \infty - \map f 0} \ln \frac a b | c = [[Difference of Logarithms]] }} {{end-eqn}} {{qed}} {{Namedfor|Giuliano Frullani|cat = Frullani}}	0
This can be done in sections. === [[Power Rule for Derivatives/Natural Number Index/Proof by Binomial Theorem|Proof for Natural Number Index]] === {{:Power Rule for Derivatives/Natural Number Index/Proof by Binomial Theorem}} === [[Power Rule for Derivatives/Integer Index|Proof for Integer Index]] === {{:Power Rule for Derivatives/Integer Index}} === [[Power Rule for Derivatives/Fractional Index/Proof 1|Proof for Fractional Index]] === {{:Power Rule for Derivatives/Fractional Index/Proof 1}} === [[Power Rule for Derivatives/Rational Index|Proof for Rational Index]] === {{:Power Rule for Derivatives/Rational Index}} === [[Power Rule for Derivatives/Real Number Index/Proof 1|Proof for Real Number Index]] === {{:Power Rule for Derivatives/Real Number Index/Proof 1}}	0
Let: {{begin-eqn}} {{eqn | l = z | r = x^2 }} {{eqn | ll= \leadsto | l = \frac {\d z} {\d x} | r = 2 x | c = [[Power Rule for Derivatives]] }} {{eqn | ll= \leadsto | l = \int \frac {\sqrt {a^2 - x^2} } x \rd x | r = \int \frac {\sqrt {a^2 - z} \rd z} {2 \sqrt z \sqrt z} | c = [[Integration by Substitution]] }} {{eqn | r = \frac 1 2 \int \frac {\sqrt {a^2 - z} \rd z} z | c = [[Primitive of Constant Multiple of Function]] }} {{eqn | r = \frac 1 2 \paren {2 \sqrt {a^2 - z} + a^2 \int \frac {\d z} {z \sqrt {a^2 - z} } } + C | c = [[Primitive of Root of a x + b over x|Primitive of $\dfrac {\sqrt {a x + b} } x$]] }} {{eqn | r = \sqrt {a^2 - x^2} + \frac {a^2} 2 \int \frac {2 x \rd x} {x^2 \sqrt {a^2 - x^2} } + C | c = substituting for $z$ }} {{eqn | r = \sqrt {a^2 - x^2} + a^2 \int \frac {\d x} {x \sqrt {a^2 - x^2} } + C | c = simplifying }} {{eqn | r = \sqrt {a^2 - x^2} - a^2 \paren {-\frac 1 a \, \map \ln {\frac {a + \sqrt {a^2 - x^2} } x} } + C | c = [[Primitive of Reciprocal of x by Root of a squared minus x squared/Logarithm Form|Primitive of $\dfrac 1 {x \sqrt {a^2 - x^2} }$]] }} {{eqn | r = \sqrt {a^2 - x^2} - a \, \map \ln {\frac {a + \sqrt {a^2 - x^2} } x} + C | c = simplification }} {{end-eqn}} {{qed}}	0
Let $q$ be a [[Definition:Constant|constant]] [[Definition:Complex Number|complex number]] with $\map \Re q > -1$ Let $t^q: \R_{>0} \to \C$ be a [[Definition:Branch of Multifunction|branch]] of the [[Definition:Power to Complex Number|complex power multifunction]] chosen such that $f$ is [[Definition:Continuous Complex Function|continuous]] on the [[Definition:Complex Half-Plane|half-plane]] $\map \Re s > 0$. Then $f$ has a [[Definition:Laplace Transform|Laplace transform]] given by: :$\laptrans {t^q} = \dfrac {\map \Gamma {q + 1} } {s^{q + 1} }$ where $\Gamma$ denotes the [[Definition:Gamma Function|gamma function]].	0
This page gathers together the [[Definition:Primitive (Calculus)|primitives]] of some [[Definition:Real Function|functions]] involving $\sqrt{a x + b}$ and $p x + q$.	0
Let $\size x < a$. Then: :$\displaystyle \int \frac {\d x} {x^2 - a^2} = \dfrac 1 {2 a} \map \ln {\dfrac {a - x} {a + x} } + C$	0
Note that: {{begin-eqn}} {{eqn | l = y_1 | r = x | c = }} {{eqn | ll= \leadsto | l = {y_1}' | r = 1 | c = [[Power Rule for Derivatives]] }} {{eqn | ll= \leadsto | l = {y_1}'' | r = 0 | c = [[Derivative of Constant]] }} {{end-eqn}} and so by inspection: :$y_1 = x$ is a [[Definition:Particular Solution|particular solution]] of $(1)$. $(1)$ can be expressed as: :$(2): \quad y'' - \dfrac {2 x} {x^2 - 1} y' + \dfrac 2 {x^2 - 1} y = 0$ which is in the form: :$y'' + \map P x y' + \map Q x y = 0$ where: :$\map P x = - \dfrac {2 x} {x^2 - 1}$ :$\map Q x = \dfrac 2 {x^2 - 1}$ From [[Particular Solution to Homogeneous Linear Second Order ODE gives rise to Another]]: :$\map {y_2} x = \map v x \, \map {y_1} x$ where: :$\displaystyle v = \int \dfrac 1 { {y_1}^2} e^{-\int P \rd x} \rd x$ is also a [[Definition:Particular Solution|particular solution]] of $(1)$. We have that: {{begin-eqn}} {{eqn | l = \int P \rd x | r = \int \paren {- \dfrac {2 x} {x^2 - 1} } \rd x | c = }} {{eqn | r = -\map \ln {x^2 - 1} | c = [[Primitive of Function under its Derivative]] }} {{eqn | ll= \leadsto | l = e^{-\int P \rd x} | r = e^{\map \ln {x^2 - 1} } | c = }} {{eqn | r = x^2 - 1 | c = }} {{end-eqn}} Hence: {{begin-eqn}} {{eqn | l = v | r = \int \dfrac 1 { {y_1}^2} e^{-\int P \rd x} \rd x | c = Definition of $v$ }} {{eqn | r = \int \dfrac 1 {x^2} \paren {x^2 - 1} \rd x | c = }} {{eqn | r = \int \paren {1 - \dfrac 1 {x^2} } \rd x | c = }} {{eqn | r = x + \frac 1 x | c = [[Primitive of Power]] }} {{end-eqn}} and so: {{begin-eqn}} {{eqn | l = y_2 | r = v y_1 | c = Definition of $y_2$ }} {{eqn | r = \paren {x + \frac 1 x} x | c = }} {{eqn | r = x^2 + 1 | c = }} {{end-eqn}} From [[Two Linearly Independent Solutions of Homogeneous Linear Second Order ODE generate General Solution]]: :$y = C_1 x + C_2 \paren {x^2 + 1}$ {{qed}} [[Category:Examples of Homogeneous LSOODEs]] qg4jptdxydcikqwktj9ed8dkcpb9j3n	0
:$\ds \int \csch^3 a x \rd x = \frac {-\csch a x \coth a x} {2 a} - \frac 1 {2 a} \ln \size {\tanh a x} + C$	0
=== [[First Order ODE/(x + y + 4) over (x + y - 6)|$\dfrac {\d y} {\d x} = \dfrac {x + y + 4} {x + y - 6}$]] === {{:First Order ODE/(x + y + 4) over (x + y - 6)}}	0
{{begin-eqn}} {{eqn | l = -\map {\sinh^{-1} } {\frac x a} | r = \map {\sinh^{-1} } {-\frac x a} | c = [[Inverse Hyperbolic Sine is Odd Function]] }} {{eqn | r = \map \ln {-\paren {\frac x a} + \sqrt {\paren {-\frac x a}^2 + a^2} } | c = {{Defof|Inverse Hyperbolic Sine|subdef = Real|index = 2}} }} {{eqn | r = \map \ln {-\frac x a + \dfrac 1 a \sqrt {x^2 + a^2} } | c = }} {{eqn | r = \map \ln {-\dfrac 1 a \paren {x - \sqrt {x^2 + a^2} } } | c = }} {{eqn | r = \map \ln {-x + \sqrt {x^2 + a^2} } - \ln a | c = [[Difference of Logarithms]] }} {{eqn | r = \ln \size {x - \sqrt {x^2 + a^2} } - \ln a | c = as $\sqrt {x^2 + a^2} > -x$ }} {{eqn | ll= \leadsto | l = \map {\dfrac \d {\d x} } {\ln \size {x - \sqrt {x^2 + a^2} } } | r = \map {\dfrac \d {\d x} } {-\map {\sinh^{-1} } {\frac x a} + \ln a} | c = [[Sum of Logarithms]] }} {{eqn | r = -\dfrac 1 {\sqrt {x^2 + a^2} } + \map {\dfrac \d {\d x} } {\ln a} | c = [[Derivative of Inverse Hyperbolic Sine of x over a]] }} {{eqn | r = -\dfrac 1 {\sqrt {x^2 + a^2} } + 0 | c = [[Derivative of Constant]] }} {{end-eqn}} {{qed}}	0
:$\dfrac {\map \d {\map {\sinh^{-1} } {\frac x a} } } {\d x} = \dfrac 1 {\sqrt {x^2 + a^2}}$	0
Let $M$ be a [[Definition:Topological Space|topological space]]. Let $k$ and $d$ be [[Definition:Natural Number|natural numbers]]. Let $S$ be a $d$-dimensional [[Definition:Differentiable Structure|differentiable structure]] of class $C^k$ on $M$. Then $S$ contains a [[Definition:Unique|unique]] [[Definition:Maximal Atlas|maximal $C^k$-atlas]].	0
Let $\mathcal F$ be the [[Definition:Equivalence Class|equivalence class]] of $\mathcal A$ under the [[Definition:Relation|relation]] of [[Definition:Compatible Atlases|compatibility]]. By [[Compatibility of Atlases is Equivalence Relation]], this is indeed an [[Definition:Equivalence Relation|equivalence relation]]. By definition we have $\mathcal A \in \mathcal F$. By [[Relation Partitions Set iff Equivalence]], $\mathcal F$ is an [[Definition:Element|element]] of the [[Definition:Partition (Set Theory)|partition]] of [[Definition:Equivalence Class|equivalence classes]]. By definition, the [[Definition:Element|elements]] of a [[Definition:Partition (Set Theory)|partition]] are [[Definition:Pairwise Disjoint|pairwise disjoint]]. Therefore if $\mathcal G \ne \mathcal F$ is an [[Definition:Element|element]] of the [[Definition:Partition (Set Theory)|partition]], we must have: : $\mathcal A \notin \mathcal G$ Therefore $\mathcal A$ belongs to exactly one [[Definition:Differentiable Structure|differentiable structure]]. {{qed}} {{explain|Clarification is needed as to why this result should be categorised in [[:Category:Manifolds]].}} [[Category:Manifolds]] 1d6a163jw7q2sy421hs3o2njg2xs4ya	0
Let the [[Definition:First Order Ordinary Differential Equation|first order ordinary differential equation]]: :$(1): \quad \map M {x, y} + \map N {x, y} \dfrac {\d y} {\d x} = 0$ be non-[[Definition:Homogeneous Differential Equation|homogeneous]] and not [[Definition:Exact Differential Equation|exact]]. By [[Existence of Integrating Factor]], if $(1)$ has a [[Definition:General Solution to Differential Equation|general solution]], there exists an [[Definition:Integrating Factor|integrating factor]] $\map \mu {x, y}$ such that: :$\displaystyle \map \mu {x, y} \paren {\map M {x, y} + \map N {x, y} \frac {\d y} {\d x} } = 0$ is an [[Definition:Exact Differential Equation|exact differential equation]]. Unfortunately, there is no systematic method of finding such a $\map \mu {x, y}$ for all such equations $(1)$.<ref>"In general this is quite difficult." ::: -- {{BookReference|Differential Equations|1972|George F. Simmons}}: $\S 2.9$: Integrating Factors</ref> However, there are certain types of [[Definition:First Order Ordinary Differential Equation|first order ODE]] for which an [[Definition:Integrating Factor|integrating factor]] ''can'' be found procedurally.	0
{{begin-eqn}} {{eqn | l = \int \frac {\mathrm d x} {\sinh a x \cosh a x} | r = \int \frac {\operatorname{sech} a x \ \mathrm d x} {\sinh a x} | c = Definition of [[Definition:Hyperbolic Secant/Definition 2|Hyperbolic Secant]] }} {{eqn | r = \int \frac {\operatorname{sech}^2 a x \ \mathrm d x} {\sinh a x \operatorname{sech} a x} | c = multiplying [[Definition:Numerator|top]] and [[Definition:Denominator|bottom]] by $\operatorname{sech} a x$ }} {{eqn | r = \int \frac {\operatorname{sech}^2 a x \ \mathrm d x} {\frac {\sinh a x} {\cosh a x} } | c = Definition of [[Definition:Hyperbolic Secant/Definition 2|Hyperbolic Secant]] }} {{eqn | r = \int \frac {\operatorname{sech}^2 a x \ \mathrm d x} {\tanh a x} | c = Definition of [[Definition:Hyperbolic Tangent/Definition 2|Hyperbolic Tangent]] }} {{eqn | r = \frac 1 a \ln \left\vert{\tanh a x}\right\vert + C | c = [[Primitive of Square of Hyperbolic Secant of a x over Hyperbolic Tangent of a x|Primitive of $\dfrac {\operatorname{sech}^2 a x} {\tanh a x}$]] }} {{end-eqn}} {{qed}}	0
$D_x^n$ can be expressed as a [[Definition:Determinant of Matrix|determinant]]: :$D_x^n = \begin{vmatrix} \dbinom {n - 1} 0 u_1 & \dbinom {n - 1} 1 u_2 & \dbinom {n - 1} 2 u_3 & \cdots & \dbinom {n - 1} {n - 2} u_{n - 1} & \dbinom {n - 1} {n - 1} u_n \\ -1 & \dbinom {n - 2} 0 u_1 & \dbinom {n - 2} 1 u_2 & \cdots & \dbinom {n - 2} {n - 3} u_{n - 2} & \dbinom {n - 2} {n - 2} u_{n - 1} \\ 0 & -1 & \dbinom {n - 3} 0 u_1 & \cdots & \dbinom {n - 3} {n - 4} u_{n - 3} & \dbinom {n - 3} {n - 3} u_{n - 2} \\ \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\ 0 & 0 & 0 & \cdots & -1 & \dbinom 0 0 u_1 \end{vmatrix}$ where $u_j := \paren {D_x^j u} D_u$. Both sides of this equation are differential operators which are to be applied to $w$. {{finish|Fill in the details}}	0
{{begin-eqn}} {{eqn | l = \map {\dfrac \d {\d x} } {\map u x^n} | r = \lim_{h \mathop \to 0} \frac {\paren {\map u {x + h} }^n - \paren {\map u x}^n} h | c = }} {{eqn | r = \paren {\map u x}^n \lim_{h \mathop \to 0} \frac {\paren {\frac {\map u {x + h} } {\map u x} }^n - 1} h | c = [[Exponent Combination Laws/Power of Product]] }} {{eqn | r = \paren {\map u x}^n \lim_{h \mathop \to 0} \frac {\exp \paren {n \ln \frac {\map u {x + h} } {\map u x} } - 1} h | c = {{Defof|Power to Real Number}} }} {{eqn | r = \paren {\map u x}^n \lim_{h \mathop \to 0} \paren {\frac {\map \exp {n \ln \frac {\map u {x + h} } {\map u x} } - 1} {n \ln \frac {\map u {x + h} } {\map u x} } } \paren {\frac {n \ln \frac {\map u {x + h} } {\map u x} } h} | c = }} {{eqn | r = \paren {\map u x}^n \lim_{h \mathop \to 0} \frac {n \ln \frac {\map u {x + h} } {\map u x} } h | c = [[Derivative of Exponential at Zero]] }} {{eqn | r = n \paren {\map u x}^n \lim_{h \mathop \to 0} \frac {\ln \frac {\map u {x + h} } {\map u x} } h | c = }} {{eqn | r = n \paren {\map u x}^n \lim_{h \mathop \to 0} \frac {\map \ln {1 + \frac {\map u {x + h} - \map u x} {\map u x} } } h | c = }} {{eqn | r = n \paren {\map u x}^n \lim_{h \mathop \to 0} \paren {\frac {\map \ln {1 + \frac {\map u {x + h} - \map u x} {\map u x} } } {\frac {\map u {x + h} - \map u x} {\map u x} } } \paren {\frac {\frac {\map u {x + h} - \map u x} {\map u x} } h } | c = }} {{eqn | r = n \paren {\map u x}^n \lim_{h \mathop \to 0} \frac {\paren {\frac {\map u {x + h} - \map u x} {\map u x} } } h | c = [[Derivative of Logarithm at One]] }} {{eqn | r = n \paren {\map u x}^n \lim_{h \mathop \to 0} \frac 1 {\map u x} \frac {\map u {x + h} - \map u x} h | c = }} {{eqn | r = n \paren {\map u x}^{n - 1} \lim_{h \mathop \to 0} \frac {\map u {x + h} - \map u x} h | c = [[Exponent Combination Laws/Product of Powers]] }} {{eqn | r = n \paren {\map u x}^{n - 1} \map {\dfrac \d {\d x} } {\map u x} | c = }} {{end-eqn}} {{qed}}	0
Let $M$ be a [[Definition:Topological Space|topological space]]. {{TFAE}} :$(1):\quad$ $M$ is [[Definition:Locally Euclidean Space|locally euclidean]]. :$(2):\quad$ There exists a [[Definition:Atlas|$C^0$-atlas]] on $M$.	0
Let $g$ be the [[Definition:Function|function]] defined as: :$\map g t = \begin{cases} \map f {t - a} & : t > a \\ 0 & : t \le a \end{cases}$ Then: :$\laptrans {\map g t} = e^{-a s} \map F s$	0
The [[Definition:First Order Ordinary Differential Equation|first order ordinary differential equation]]: :$\dfrac {\d y} {\d x} = k \paren {y_a - y}$ where $k \in \R: k > 0$ has the [[Definition:General Solution to Differential Equation|general solution]]: :$y = y_a + C e^{-k x}$ where $C$ is an [[Definition:Arbitrary Constant|arbitrary constant]]. If $y = y_0$ at $x = 0$, then: :$y = y_a + \paren {y_0 - y_a} e^{-k x}$ This differential equation is known as the '''decay equation'''.	0
With a view to expressing the [[Definition:Primitive|primitive]] in the form: :$\displaystyle \int u \frac {\d v} {\d x} \rd x = u v - \int v \frac {\d u} {\d x} \rd x$ let: {{begin-eqn}} {{eqn | l = u | r = \arccot \frac x a | c = }} {{eqn | ll= \leadsto | l = \frac {\d u} {\d x} | r = \frac {-a} {x^2 + a^2} | c = [[Derivative of Arccotangent of x over a|Derivative of $\arccot \dfrac x a$]] }} {{end-eqn}} and let: {{begin-eqn}} {{eqn | l = \frac {\d v} {\d x} | r = \frac 1 {x^2} | c = }} {{eqn | ll= \leadsto | l = v | r = \frac {-1} x | c = [[Primitive of Power]] }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = \int \frac {\arccot \frac x a \rd x} {x^2} | r = \arccot \frac x a \paren {\frac {-1} x} - \int \paren {\frac {-1} x} \paren {\frac {-a} {x^2 + a^2} } \rd x + C | c = [[Integration by Parts]] }} {{eqn | r = \frac {-\arccot \frac x a} x - a \int \frac {\d x} {x \paren {x^2 + a^2} } \rd x + C | c = simplifying }} {{eqn | r = \frac {-\arccot \frac x a} x - \frac 1 a \paren {\frac 1 {2 a^2} \map \ln {\frac {x^2} {x^2 + a^2} } } + C | c = [[Primitive of Reciprocal of x by x squared plus a squared|Primitive of $\dfrac 1 {x \paren {x^2 + a^2} }$]] }} {{eqn | r = \frac {-\arccot \frac x a} x + \frac 1 {2 a} \map \ln {\frac {x^2 + a^2} {x^2} } + C | c = [[Logarithm of Reciprocal]] }} {{end-eqn}} {{qed}}	0
Using [[Solution of Second Order Differential Equation with Missing Independent Variable]], $(1)$ can be expressed as: {{begin-eqn}} {{eqn | l = p \frac {\d p} {\d y} | r = k^2 y | c = where $p = \dfrac {\d y} {\d x}$ }} {{eqn | ll= \leadsto | l = p^2 | r = k^2 y^2 + k^2 \alpha | c = [[First Order ODE/y dy = k x dx|First Order ODE: $y \rd y = k x \rd x$]] }} {{eqn | ll= \leadsto | l = p = \dfrac {\d y} {\d x} | r = \pm k \sqrt {y^2 + k^2 \alpha} | c = }} {{eqn | ll= \leadsto | l = \int \dfrac {\d y} {\sqrt {y^2 + \alpha} } | r = \int \pm k \rd x | c = [[Separation of Variables]] }} {{eqn | ll= \leadsto | l = \map \ln {y + \sqrt{y^2 + \alpha} } | r = \pm k x + \beta | c = [[Primitive of Reciprocal of Root of x squared plus k|Primitive of $\dfrac 1 {\sqrt {x^2 + k} }$]] }} {{eqn | ll= \leadsto | l = y + \sqrt {y^2 + \alpha} | r = e^{\pm k x + \beta} | c = }} {{eqn | r = C e^{\pm k x} | c = where $C = e^\beta$ }} {{eqn | ll= \leadsto | l = y^2 + \alpha | r = \paren {C e^{\pm k x} - y}^2 | c = }} {{eqn | r = C^2 e^{\pm 2 k x} - 2 C e^{\pm k x} + y^2 | c = }} {{eqn | ll= \leadsto | l = y | r = \frac {C^2 e^{\pm 2 k x} - \alpha} {2 C e^{\pm k x} } | c = [[Quadratic Formula]] }} {{eqn | r = \frac {C e^{\pm k x} - \frac \alpha C e^{\mp k x} } 2 | c = [[Quadratic Formula]] }} {{end-eqn}} Setting $C_1 = \dfrac C 2$ and $C_2 = - \dfrac \alpha {2 C}$: :$y = C_1 e^{\pm k x} + C_2 e^{\mp k x}$ which is the same thing as: :$y = C_1 e^{k x} + C_2 e^{-k x}$ by allowing for the constants to be interchanged. {{qed}}	0
:$\displaystyle \int_0^\infty \frac {x \sin m x} {x^2 + a^2} \rd x = \frac \pi 2 e^{-m a}$	0
:$\displaystyle \int \frac {\mathrm d x} {x \left({x^2 - a^2}\right)^n} = \frac {-1} {2 \left({n - 1}\right) a^2 \left({x^2 - a^2}\right)^{n - 1} } - \frac 1 {a^2} \int \frac {\mathrm d x} {x \left({x^2 - a^2}\right)^{n - 1} }$ for $x^2 > a^2$.	0
:$\map {\dfrac \d {\d x} } {\sech x} = -\sech x \tanh x$	0
Let $J \sqbrk y$ and $K \sqbrk y$ be [[Definition:Real Functional|(real) functionals]], such that :$\ds J \sqbrk y = \int_a^b \map F {x, y, y'} \rd x$ :$\ds K \sqbrk y = \int_a^b \map G {x, y, y'} \rd x = l$ where $l$ is a constant. Let $y = \map y x$ be an extremum of $F \sqbrk y$, and satisfy boundary conditions: :$\map y a = A$ :$\map y b = B$ Then, if $y = \map y x$ is not an extremal of $K \sqbrk y$, there exists a constant $\lambda$ such that $y = \map y x$ is an extremal of the functional: :$\ds \int_a^b \paren {F + \lambda G} \rd x$ or, in other words, $y = \map y x$ satisfies: :$F_y - \dfrac {\d} {\d x} F_{y'} + \lambda \paren {G_y - \dfrac {\d} {\d x} G_{y'} } = 0$	0
:$\displaystyle \int \frac {\cos a x \rd x} {p + q \sin a x} = \frac 1 {a q} \ln \left\vert{p + q \sin a x}\right\vert + C$	0
Let $f$ fail to be [[Definition:Continuous Mapping|continuous]] at $t = 0$, but let: :$\displaystyle \lim_{t \mathop \to 0} \map f t = \map f {0^+}$ exist. Then $\laptrans f$ exists for $\map \Re s > a$, and: :$\laptrans {\map {f'} t} = s \laptrans {\map f t} - \map f {0^+}$	0
Let there be an infinitesimal transformation of generalised coordinates such that: :$q_i \to \tilde q_i = q_i + q_i^\alpha \left({q, \dot q, t}\right) \varepsilon_\alpha + \hbox {terms vanishing on shell}$ where $\varepsilon$ is not time-dependent. Under this transformation, let the variation of the Lagrangian be: :$L \left({q + \delta q, \dot q + \delta \dot q, t}\right) - L \left({q, \dot q, t}\right) = \dfrac {\mathrm d}{\mathrm d t} \mathcal L^\alpha \left({q, \dot q, t}\right) \varepsilon_\alpha$ Let $s$ be the number of degrees of freedom of the system. Then the quantity: :$\displaystyle \mathcal J^\alpha = \sum_{i \mathop = 1}^s \frac {\partial L} {\partial \dot q_i} q_i^\alpha - \mathcal L^\alpha$ is conserved.	0
First let $n$ be a [[Definition:Positive Integer|positive integer]]. Take a [[Definition:Real Number|real number]] $r \in \R$ such that $0 < r < 1$ but reasonably close to $1$. Consider a [[Definition:Subdivision (Real Analysis)|subdivision]] $S$ of the [[Definition:Closed Real Interval|closed interval]] $\closedint 0 b$ defined as: :$S = \set {0, \ldots, r^2 b, r b, b}$ that is, by taking as the points of subdivision successive powers of $r$. Now we take the [[Definition:Upper Sum|upper sum]] $\map U S$ over $S$ (starting from the right): {{begin-eqn}} {{eqn | l = \map U S | r = b^n \paren {b - r b} + \paren {r b}^n \paren {r b - r^2 b} + \paren {r^2 b}^n \paren {r^2 b - r^3 b} + \cdots | c = }} {{eqn | r = b^{n + 1} \paren {1 - r} + b^{n + 1} r^{n + 1} \paren {1 - r} + b^{n + 1} r^{2 n + 2} \paren {1 - r} + \cdots | c = }} {{eqn | r = b^{n + 1} \paren {1 - r} \paren {1 + r^{n + 1} + r^{\paren {n + 1}^2} + \cdots} | c = }} {{eqn | r = \frac {b^{n + 1} \paren {1 - r} } {1 - r^{n + 1} } | c = [[Sum of Geometric Sequence]] }} {{eqn | r = \frac {b^{n + 1} } {1 + r + r^2 + \cdots + r^n} | c = }} {{end-eqn}} Now we let $r \to 1$ and see that each of the terms on the bottom also approach $1$. Thus: :$\displaystyle \lim_{r \mathop \to 1} S = \frac {b^{n + 1} } {n + 1}$ That is: :$\displaystyle \int_0^b x^n \rd x = \frac {b^{n + 1} } {n + 1}$ for every [[Definition:Positive Integer|positive integer]] $n$. Now assume $n = \dfrac p q$ be a [[Definition:Strictly Positive|strictly positive]] [[Definition:Rational Number|rational number]]. We set $s = r^{1/q}$ and proceed: {{begin-eqn}} {{eqn | l = \frac {1 - r} {1 - r^{n + 1} } | r = \frac {1 - s^q} {1 - \paren {s^q}^{p / q + 1} } | c = }} {{eqn | r = \frac {1 - s^q} {1 - s^{p + q} } | c = }} {{eqn | r = \frac {\paren {1 - s^q} / \paren {1 - s} } {\paren {1 - s^{p + q} } / \paren {1 - s} } | c = }} {{eqn | r = \frac {1 + s + s^2 + \cdots + s^{q - 1} }{1 + s + s^2 + \cdots + s^{p + q - 1} } | c = }} {{end-eqn}} As $r \to 1$ we have $s \to 1$ and so that last expression shows: {{begin-eqn}} {{eqn | l = \frac {1 - r} {1 - r^{n + 1} } | o = \to | r = \frac q {p + q} | c = }} {{eqn | r = \frac 1 {p / q + 1} | c = }} {{eqn | r = \frac 1 {n + 1} | c = }} {{end-eqn}} So the expression for the main result still holds for [[Definition:Rational Number|rational]] $n$. {{qed}}	0
Let $f$ be a [[Definition:Real Function|real function]] which is [[Definition:Continuous on Interval|continuous]] on any [[Definition:Closed Real Interval|closed interval]] $I$. Let $a, b, c \in I$. Then: :$\ds \int_a^c \map f t \rd t + \int_c^b \map f t \rd t = \int_a^b \map f t \rd t$	0
{{begin-eqn}} {{eqn | l = z | r = \cot a x | c = }} {{eqn | ll= \implies | l = \frac {\mathrm d z} {\mathrm d x} | r = -a \csc^2 a x | c = [[Derivative of Cotangent Function/Corollary|Derivative of Cotangent Function: Corollary]] }} {{eqn | ll= \implies | l = \int \cot^n a x \csc^2 a x \ \mathrm d x | r = \int \frac {-1} a z^n \ \mathrm d z | c = [[Integration by Substitution]] }} {{eqn | r = \frac {-1} a \frac {z^{n + 1} } {n + 1} | c = [[Primitive of Power]] }} {{eqn | r = \frac {-\cot^{n + 1} a x} {\left({n + 1}\right) a} + C | c = substituting for $z$ and simplifying }} {{end-eqn}} {{qed}}	0
Aiming for an expression in the form: : $\displaystyle \int u \frac {\mathrm d v} {\mathrm d x} \ \mathrm d x = u v - \int v \ \frac {\mathrm d u} {\mathrm d x} \ \mathrm d x$ in order to use the technique of [[Integration by Parts]], let: {{begin-eqn}} {{eqn | l = v | r = \left({a x + b}\right)^s | c = }} {{eqn | ll= \implies | l = \frac {\mathrm d v} {\mathrm d x} | r = a s \left({a x + b}\right)^{s-1} | c = [[Derivative of Power]] and [[Derivative of Function of Constant Multiple/Corollary|Derivative of Function of Constant Multiple: Corollary]] }} {{end-eqn}} In order to make $u \dfrac {\mathrm d v} {\mathrm d x}$ equal to the [[Definition:Integrand|integrand]], let: {{begin-eqn}} {{eqn | l = u | r = \frac {\left({a x + b}\right)^{m - s + 1} } {a s} \left({p x + q}\right)^n | c = }} {{eqn | ll= \implies | l = \frac {\mathrm d u} {\mathrm d x} | r = \frac {a \left({m - s + 1}\right) \left({a x + b}\right)^{m - s} \left({p x + q}\right)^n + p n \left({a x + b}\right)^{m - s + 1} \left({p x + q}\right)^{n-1} } {a s} | c = [[Product Rule for Derivatives]] and above }} {{eqn | r = \frac {\left({a x + b}\right)^{m - s} \left({p x + q}\right)^{n-1} } {a s} \left({a \left({m - s + 1}\right) \left({p x + q}\right) + p n \left({a x + b}\right) }\right) | c = extracting common factor }} {{eqn | r = \frac {\left({a x + b}\right)^{m - s} \left({p x + q}\right)^{n-1} } {a s} \left({a p x \left({m - s + 1 + n}\right) + a q \left({m - s + 1}\right) + p b n}\right) | c = separating out terms in $x$ }} {{end-eqn}} Select $s$ such that $m - s + n + 1 = 0$, and so $s = m + n + 1$: {{begin-eqn}} {{eqn | l = \frac {\mathrm d u} {\mathrm d x} | r = \frac {\left({a x + b}\right)^{m - s} \left({p x + q}\right)^{n-1} } {a \left({m + n + 1}\right)} \left({a q \left({m - \left({m + n + 1}\right) + 1}\right) + p b n}\right) | c = term in $x$ vanishes }} {{eqn | r = \frac {\left({a x + b}\right)^{m - s} \left({p x + q}\right)^{n-1} } {a \left({m + n + 1}\right)} \left({n \left({p b - a q}\right)}\right) | c = simplifying }} {{end-eqn}} Other instances of $s$ are left as they are, anticipating that they will cancel out later. Thus: {{begin-eqn}} {{eqn | o = | r = \int \left({a x + b}\right)^m \left({p x + q}\right)^n \ \mathrm d x | c = }} {{eqn | r = \int \frac {\left({a x + b}\right)^{m - s + 1} } {a s} \left({p x + q}\right)^n a s \left({a x + b}\right)^{s-1} \ \mathrm d x | c = in the form $\displaystyle \int u \frac {\mathrm d v} {\mathrm d x} \ \mathrm d x$ }} {{eqn | r = \frac {\left({a x + b}\right)^{m - s + 1} } {a s} \left({p x + q}\right)^n \left({a x + b}\right)^s | c = in the form $\displaystyle u v - \int v \frac {\mathrm d u} {\mathrm d x} \ \mathrm d x$ }} {{eqn | o = | ro= - | r = \int \left({a x + b}\right)^s \frac {\left({a x + b}\right)^{m - s} \left({p x + q}\right)^{n-1} } {a \left({m + n + 1}\right)} \left({n \left({p b - a q}\right)}\right) \ \mathrm d x | c = }} {{eqn | r = \frac {\left({a x + b}\right)^{m+1} \left({p x + q}\right)^n} {\left({m + n + 1}\right) a} - \frac {n \left({b p - a q}\right)} {\left({m + n + 1}\right) a} \int \left({a x + b}\right)^m \left({p x + q}\right)^{n-1} \ \mathrm d x | c = [[Primitive of Constant Multiple of Function]] }} {{end-eqn}} {{qed}}	0
It can be seen that $(1)$ is a [[Definition:Nonhomogeneous Linear Second Order ODE|nonhomogeneous linear second order ODE]] with [[Definition:Constant|constant]] [[Definition:Coefficient|coefficients]] in the form: :$y'' + p y' + q y = \map R x$ where: :$p = 0$ :$q = 4$ :$\map R x = 6 \cos x$ First we establish the solution of the corresponding [[Definition:Constant Coefficient Homogeneous Linear Second Order ODE|constant coefficient homogeneous linear second order ODE]]: :$(2): \quad y'' + 4 y = 0$ From [[Linear Second Order ODE/y'' + 4 y = 0|Linear Second Order ODE: $y'' + 4 y = 0$]], this has the [[Definition:General Solution to Differential Equation|general solution]]: :$y_g = C_1 \sin 2 x + C_2 \cos 2 x$ It is noted that $\cos x$ is not a [[Definition:Particular Solution to Differential Equation|particular solution]] of $(2)$. So from the [[Method of Undetermined Coefficients/Sine and Cosine|Method of Undetermined Coefficients for Sine and Cosine]]: :$y_p = A \sin x + B \cos x$ where $A$ and $B$ are to be determined. Hence: {{begin-eqn}} {{eqn | l = y_p | r = A \sin x + B \cos x | c = }} {{eqn | ll= \leadsto | l = {y_p}' | r = A \cos x - B \sin x | c = [[Derivative of Sine Function]], [[Derivative of Cosine Function]] }} {{eqn | ll= \leadsto | l = {y_p}'' | r = -A \sin x - B \cos x | c = [[Derivative of Sine Function]], [[Derivative of Cosine Function]] }} {{end-eqn}} Substituting into $(1)$: {{begin-eqn}} {{eqn | l = -A \sin x - B \cos x + 4 \paren {A \sin x + B \cos x} | r = 6 \cos x | c = }} {{eqn | ll= \leadsto | l = 3 A \sin x | r = 0 | c = equating coefficients }} {{eqn | l = 3 B \cos x | r = 6 \cos x | c = }} {{eqn | ll= \leadsto | l = A | r = 0 | c = }} {{eqn | l = B | r = 2 | c = }} {{end-eqn}} So from [[General Solution of Linear 2nd Order ODE from Homogeneous 2nd Order ODE and Particular Solution]]: :$y = y_g + y_p = C_1 \sin k x + C_2 \cos k x + 2 \cos x$ is the [[Definition:General Solution to Differential Equation|general solution]] to $(1)$. {{qed}} [[Category:Examples of Constant Coefficient LSOODEs]] [[Category:Examples of Method of Undetermined Coefficients]] i707s896lgr763ay1nl3jlne0l5pbdl	0
With a view to expressing the [[Definition:Primitive|primitive]] in the form: :$\displaystyle \int u \frac {\mathrm d v}{\mathrm d x} \ \mathrm d x = u v - \int v \frac {\mathrm d u}{\mathrm d x} \ \mathrm d x$ let: {{begin-eqn}} {{eqn | l = u | r = \arcsin \frac x a | c = }} {{eqn | ll= \implies | l = \frac {\mathrm d u} {\mathrm d x} | r = \frac 1 {\sqrt {a^2 - x^2} } | c = [[Derivative of Arcsine of x over a|Derivative of $\arcsin \dfrac x a$]] }} {{end-eqn}} and let: {{begin-eqn}} {{eqn | l = \frac {\mathrm d v} {\mathrm d x} | r = \frac 1 {x^2} | c = }} {{eqn | ll= \implies | l = v | r = \frac {-1} x | c = [[Primitive of Power]] }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = \int \frac {\arcsin \frac x a \ \mathrm d x} {x^2} | r = \arcsin \frac x a \left({\frac {-1} x}\right) - \int \left({\frac {-1} x}\right) \left({\frac 1 {\sqrt {a^2 - x^2} } }\right) \ \mathrm d x + C | c = [[Integration by Parts]] }} {{eqn | r = \frac {-\arcsin \frac x a} x + \int \frac {\mathrm d x} {x \sqrt {a^2 - x^2} } \ \mathrm d x + C | c = simplifying }} {{eqn | r = \frac {-\arcsin \frac x a} x - \frac 1 a \ln \left({\frac {a + \sqrt {a^2 - x^2} } x}\right) + C | c = [[Primitive of Reciprocal of x by Root of a squared minus x squared/Logarithm Form|Primitive of $\dfrac 1 {x \sqrt {a^2 - x^2} }$]] }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \int_0^{2 \pi} \frac {\d x} {a + b \cos x} | r = \int_0^\pi \frac {\d x} {a + b \cos x} + \int_\pi^{2 \pi} \frac {\d x} {a + b \cos x} | c = [[Sum of Integrals on Adjacent Intervals for Integrable Functions]] }} {{eqn | r = \intlimits {\frac 2 {\sqrt {a^2 - b^2} } \map \arctan {\sqrt {\frac {a - b} {a + b} } \tan \frac x 2} } 0 \pi + \intlimits {\frac 2 {\sqrt {a^2 - b^2} } \map \arctan {\sqrt {\frac {a - b} {a + b} } \tan \frac x 2} } \pi {2 \pi} | c = [[Primitive of Reciprocal of p plus q by Cosine of a x|Primitive of $\dfrac 1 {p + q \cos a x}$]] }} {{eqn | r = \frac 2 {\sqrt {a^2 - b^2} } \paren {\lim_{x \mathop \to \pi^+} \map \arctan {\sqrt {\frac {a - b} {a + b} } \tan \frac x 2} - \map \arctan {\sqrt {\frac {a - b} {a + b} } \tan 0} } }} {{eqn | o = | ro= + | r = \frac 2 {\sqrt {a^2 - b^2} } \paren {\map \arctan {\sqrt {\frac {a - b} {a + b} } \tan \pi} - \lim_{x \mathop \to \pi^-} \map \arctan {\sqrt {\frac {a - b} {a + b} } \tan \frac x 2} } }} {{eqn | r = \frac 2 {\sqrt {a^2 - b^2} } \paren {\lim_{x \mathop \to \pi^+} \map \arctan {\sqrt {\frac {a - b} {a + b} } \tan \frac x 2} - \map \arctan {\sqrt {\frac {a - b} {a + b} } \tan 0} } | c = [[Tangent Function is Periodic on Reals]] }} {{eqn | o = | ro= + | r = \frac 2 {\sqrt {a^2 - b^2} } \paren { \map \arctan {\sqrt {\frac {a - b} {a + b} } \tan 0} - \lim_{x \mathop \to \pi^-} \map \arctan {\sqrt {\frac {a - b} {a + b} } \tan \frac x 2} } | c = }} {{eqn | r = \frac 2 {\sqrt {a^2 - b^2} } \paren {\lim_{x \mathop \to \pi^+} \map \arctan {\sqrt {\frac {a - b} {a + b} } \tan \frac x 2} - \lim_{x \mathop \to \pi^-} \map \arctan {\sqrt {\frac {a - b} {a + b} } \tan \frac x 2} } | c = simplfying }} {{eqn | r = \frac 2 {\sqrt {a^2 - b^2} } \paren {\lim_{u \mathop \to \infty} \map \arctan {\sqrt {\frac {a - b} {a + b} } u} - \lim_{u \mathop \to -\infty} \map \arctan {\sqrt {\frac {a - b} {a + b} } u} } | c = letting $u = \tan \dfrac x 2$: [[Tangent Function Tends to Positive and Negative Infinity|Tangent Function $\to \pm \infty$]] }} {{eqn | r = \frac 2 {\sqrt {a^2 - b^2} } \paren {\frac \pi 2 - \paren {-\frac \pi 2} } | c = [[Limit to Positive and Negative Infinity of Arctangent Function]] }} {{eqn | r = \frac {2 \pi} {\sqrt {a^2 - b^2} } }} {{end-eqn}} {{qed}}	0
First: {{begin-eqn}} {{eqn | l = c | r = 0 | c = }} {{eqn | ll= \leadsto | l = \int \frac {\d x} {a x^2 + b x + c} | r = \int \frac {\d x} {a x^2 + b x} | c = }} {{eqn | r = \int \frac {\d x} {x \paren {a x + b} } | c = }} {{eqn | r = \frac 1 b \ln \size {\frac x {a x + b} } + C | c = [[Primitive of Reciprocal of x by a x + b|Primitive of $\dfrac 1 {x \paren {a x + b} }$]] }} {{end-eqn}} {{qed}}	0
Let $\sin$ denote the [[Definition:Real Sine Function|real sine function]]. Let $\laptrans f$ denote the [[Definition:Laplace Transform|Laplace transform]] of a [[Definition:Real Function|real function]] $f$. Then: :$\laptrans {t \sin a t} = \dfrac {2 a s} {\paren {s^2 + a^2}^2}$	0
Let $f: \R \to \R$ be a [[Definition:Real Function|real function]] which is [[Definition:Integrable|integrable]] on the [[Definition:Closed Real Interval|interval]] $\closedint a b$. Let the [[Definition:Point|points]] be defined: :$A = \tuple {a, \map f a}$ :$B = \tuple {b, \map f b}$ :$C = \tuple {b, 0}$ :$D = \tuple {a, 0}$ Let the [[Definition:Plane Figure|figure]] $ABCD$ be defined as being bounded by the [[Definition:Straight Line|straight lines]] $y = 0$, $x = a$, $x = b$ and the [[Definition:Curve|curve]] defined by $\set {\map f x: a \le x \le b}$. Let the [[Definition:Solid of Revolution|solid of revolution]] $S$ be generated by rotating $ABCD$ around the [[Definition:X-Axis|$x$-axis]] (that is, $y = 0$). Then the [[Definition:Volume|volume]] $V$ of $S$ is given by: :$\displaystyle V = \pi \int_a^b \paren {\map f x}^2 \rd x$	0
{{begin-eqn}} {{eqn | l = \int \frac {\d x} {p^2 + q^2 \sin^2 a x} | r = \int \frac {\sec^2 a x \rd x} {p^2 \sec^2 a x + q^2 \tan^2 a x} | c = multiplying [[Definition:Numerator|numerator]] and [[Definition:Denominator|denominator]] by $\sec^2 a x$ }} {{eqn | r = \int \frac {\sec^2 a x \rd x} {p^2 + \paren {p^2 + q^2} \tan^2 a x} | c = [[Difference of Squares of Secant and Tangent]] }} {{eqn | r = \int \frac {\paren {\tan a x}' \rd x} {a p^2 + a \paren {p^2 + q^2} \tan^2 a x} | c = [[Derivative of Tangent Function]] }} {{eqn | r = \int \frac {\d t} {a p^2 + a \paren {p^2 + q^2} t^2} | c = substituting $t = \tan a x$ }} {{eqn | r = \frac 1 {a \paren {p^2 + q^2} } \int \frac {\rd t} {\paren {\tfrac p {\sqrt {p^2 + q^2} } }^2 + t^2} | c = }} {{eqn | r = \frac 1 {a \paren {p^2 + q^2} } \frac {\sqrt {p^2 + q^2} } p \map \arctan {\frac {\sqrt {p^2 + q^2} } p t} + C | c = [[Primitive of Reciprocal of x squared plus a squared/Arctangent Form|Primitive of $\dfrac 1 {x^2 + a^2}$]] }} {{eqn | r = \frac 1 {a p \sqrt {p^2 + q^2} } \map \arctan {\frac {\sqrt {p^2 + q^2} } p t} + C | c = }} {{eqn | r = \frac 1 {a p \sqrt {p^2 + q^2} } \map \arctan {\frac {\sqrt {p^2 + q^2} \tan a x} p} + C | c = substituting $t = \tan a x$ }} {{end-eqn}} {{qed}}	0
:$\displaystyle \int \frac {\mathrm d x} {\sinh a x \cosh a x} = \frac 1 a \ln \left\vert{\tanh a x}\right\vert + C$	0
From [[Solution to Linear First Order ODE with Constant Coefficients]], the [[Definition:General Solution to Differential Equation|general solution]] to $(1)$ is: :$(2): \quad \displaystyle y = e^{-a x} \int e^{a x} \map Q x \rd x + C e^{-a x}$ Let $y = y_0$ when $x = x_0$. We have: :$(3): \quad y_0 = e^{-a x_0} \int e^{a x_0} \map Q {x_0} \rd x_0 + C e^{-a x_0}$ Thus: {{begin-eqn}} {{eqn | l = y e^{a x} | r = \int e^{a x} \map Q x \rd x + C | c = multiplying $(2)$ by $e^{a x}$ }} {{eqn | l = y_0 e^{a x_0} | r = \int e^{a x_0} \map Q {x_0} \rd x + C | c = multiplying $(3)$ by $e^{a x}$ }} {{eqn | ll= \leadsto | l = y e^{a x} | r = y_0 e^{a x_0} + \int e^{a x} \map Q x \rd x - \int e^{a x_0} \map Q {x_0} \rd x | c = substituting for $C$ and rearranging }} {{eqn | r = y_0 e^{a x_0} + \int_{x_0}^x e^{a \xi} \map Q \xi \rd \xi | c = [[Fundamental Theorem of Calculus]] }} {{eqn | ll= \leadsto | l = y | r = e^{a x} \int_{x_0}^x e^{a \xi} \map Q \xi \rd \xi + y_0 e^{-a \paren {x - x_0} } | c = dividing by $e^{a x}$ and rearranging }} {{end-eqn}} {{qed}}	0
The [[Definition:Linear First Order ODE|linear first order ODE]]: :$(1): \quad y' + y = 2 x e^{-x} + x^2$ has the [[Definition:General Solution of Differential Equation|general solution]]: :$y = x^2 e^{-x} + x^2 - 2 x + 2 + C e^{-x}$	0
This page gathers together the [[Definition:Primitive (Calculus)|primitives]] of some expressions involving $\left({x^2 - a^2}\right)^n$.	0
:$\displaystyle \lim_{x \mathop \to 0} \frac x {\sin x} = 1$	0
{{begin-eqn}} {{eqn | l = \int \sec^2 x \ \mathrm d x | r = \tan x + C | c = [[Primitive of Square of Secant Function|Primitive of $\sec^2 x$]] }} {{eqn | ll= \implies | l = \int \sec^2 a x \ \mathrm d x | r = \frac 1 a \left({\tan a x}\right) + C | c = [[Primitive of Function of Constant Multiple]] }} {{eqn | r = \frac {\tan a x} a + C | c = simplifying }} {{end-eqn}} {{qed}}	0
The [[Definition:First Order ODE|first order ODE]]: :$(1): \quad \dfrac {\d y} {\d x} = \dfrac {x + y + 4} {x + y - 6}$ has the [[Definition:General Solution of Differential Equation|general solution]]: :$y - x = 5 \, \map \ln {x + y - 1} + C$	0
is a [[Definition:Homogeneous Differential Equation|homogeneous differential equation]] with [[Definition:General Solution|solution]]: :$\cos \dfrac y x + \ln C x = 0$	0
This page gathers together [[Definition:Derivative|derivatives]] of [[Definition:Inverse Trigonometric Function|inverse trigonometric functions]].	0
Let: :$\map M {x, y} = y + 2 x e^{-y/x}$ :$\map N {x, y} = x$ Put $t x, t y$ for $x, y$: {{begin-eqn}} {{eqn | l = \map M {t x, t y} | r = t y + 2 t x e^{-t y / t x} | c = }} {{eqn | r = t \paren {y + 2 x e^{-y / x} } | c = }} {{eqn | r = t \, \map M {x, y} | c = }} {{end-eqn}} {{begin-eqn}} {{eqn | l = \map N {t x, t y} | r = t x | c = }} {{eqn | r = t \, \map N {x, y} | c = }} {{end-eqn}} Thus both $M$ and $N$ are [[Definition:Homogeneous Real Function|homogeneous functions]] of [[Definition:Degree of Homogeneous Real Function|degree]] $1$. Thus, by definition, $(1)$ is a [[Definition:Homogeneous Differential Equation|homogeneous differential equation]]. By [[Solution to Homogeneous Differential Equation]], its solution is: :$\displaystyle \ln x = \int \frac {\d z} {\map f {1, z} - z} + C$ where: :$\map f {x, y} = \dfrac {y + 2 x e^{-y / x} } x$ Thus: {{begin-eqn}} {{eqn | l = \ln x | r = \int \frac {\d z} {\dfrac {z + 2 e^{-z} } 1 - z} + C_1 | c = }} {{eqn | r = \int \frac {e^z} 2 \rd z + C_1 | c = }} {{eqn | r = \frac {e^z} 2 + C_1 | c = [[Primitive of Exponential Function]] }} {{eqn | ll= \leadsto | l = 2 \ln x + C | r = e^z | c = putting $C = -\dfrac {C_1} 2$ }} {{eqn | ll= \leadsto | l = e^{y / x} | r = \ln x^2 + C | c = }} {{end-eqn}} {{qed}}	0
:$\displaystyle \int \frac {\sinh a x \ \mathrm d x} {x^n} = \frac {-\sinh a x} {\left({n - 1}\right) x^{n - 1} } + \frac a {n - 1} \int \frac {\cosh a x \ \mathrm d x} {x^{n - 1} } + C$	0
Let: {{begin-eqn}} {{eqn | l = z | r = x^2 }} {{eqn | ll= \implies | l = \frac {\mathrm d z} {\mathrm d x} | r = 2 x | c = [[Power Rule for Derivatives]] }} {{eqn | ll= \implies | l = \int \frac {\mathrm d x} {x^2 \sqrt {a^2 - x^2} } | r = \int \frac {\mathrm d z} {2 z \sqrt z \sqrt {a^2 - z} } | c = [[Integration by Substitution]] }} {{eqn | r = \frac 1 2 \int \frac {\mathrm d z} {z^{3/2} \sqrt {a^2 - z} } | c = }} {{end-eqn}} Using [[Primitive of Reciprocal of Power of x by Root of a x + b|Primitive of $ \dfrac 1{x^m \sqrt{a x + b} }$]]: :$\displaystyle \int \frac {\mathrm d x} {x^m \sqrt{a x + b} } = -\frac {\sqrt{a x + b} } {\left({m - 1}\right) b x^{m-1} } - \frac {\left({2 m - 3}\right) a} {\left({2 m - 2}\right) b} \int \frac {\mathrm d x} {x^{m - 1} \sqrt{a x + b} }$ Setting: {{begin-eqn}} {{eqn | l = x | o = := | r = -z }} {{eqn | l = m | o = := | r = \frac 3 2 }} {{eqn | l = a | o = := | r = 1 }} {{eqn | l = b | o = := | r = a^2 }} {{end-eqn}} {{begin-eqn}} {{eqn | l = \frac 1 2 \int \frac {\mathrm d z} {\left({-z}\right)^{3/2} \sqrt {-z + a^2} } | r = \frac {-\sqrt{-z + a^2} } {2 \left({\left({\frac 3 2}\right) - 1}\right) a^2 \left({-z}\right)^{\left({3/2}\right) - 1} } - \frac {2 \left({\frac 3 2}\right) - 3} {2 \left({2 \left({\frac 3 2}\right) - 2}\right) a^2} \int \frac {\mathrm d z} {\left({-z}\right)^{\left({\frac 3 2}\right) - 1} \sqrt{-z + a^2} } + C | c = [[Primitive of Reciprocal of Power of x by Root of a x + b|Primitive of $ \dfrac 1{x^m \sqrt{a x + b} }$]] }} {{eqn | r = \frac {-\sqrt{a^2 - z} } {a^2 z^{1/2} } - 0 + C | c = simplifying }} {{eqn | r = \frac {-\sqrt {a^2 - x^2} } {a^2 x} + C | c = substituting back for $z$ }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn|l = \tan x \left({\tan x + \cot x}\right) |r = \tan x \sec x \csc x |c = [[Sum of Tangent and Cotangent]] }} {{eqn|r = \frac {\sin x} {\cos x} \sec x \csc x |c = [[Tangent is Sine divided by Cosine]] }} {{eqn|r = \frac {\sin x} {\cos^2 x} \csc x |c = [[Secant is Reciprocal of Cosine]] }} {{eqn|r = \frac {\sin x} {\cos^2 x \sin x} |c = [[Cosecant is Reciprocal of Sine]] }} {{eqn|r = \frac 1 {\cos^2 x} }} {{eqn|r = \sec^2 x |c = [[Secant is Reciprocal of Cosine]] }} {{end-eqn}} {{qed}}	0
:$\map {\dfrac \d {\d x} } {\ln \size {x + \sqrt {x^2 + a^2} } } = \dfrac 1 {\sqrt {x^2 + a^2} }$	0
Let $\struct {\R, \tau_d}$ be the [[Definition:Real Number Line with Euclidean Topology|real number line with the usual (Euclidean) topology]]. Then $\struct {\R, \tau_d}$ is [[Definition:Separable Space|separable]].	0
Let: :$1 = \dfrac 1 a + \dfrac 1 b + \dfrac 1 c$ where: :$0 < a \le b \le c$ and: {{AimForCont}} $a = 1$. Then: :$1 = \dfrac 1 1 + \dfrac 1 b + \dfrac 1 c$ and so: :$\dfrac 1 b + \dfrac 1 c = 0$ which [[Definition:Contradiction|contradicts]] the stipulation that $b, c > 0$. So there is no solution possible when $a = 1$. Therefore $a \ge 2$. === $a = 2$ === Let $a = 2$. ==== $b = 2$ ==== Let $b = 2$. Then: :$\dfrac 1 a + \dfrac 1 b = 1$ leaving no room for $c$. Hence there are no solutions where $a = 2$ and $b = 2$. {{qed|lemma}} ==== $b = 3$ ==== Let $b = 3$. {{begin-eqn}} {{eqn | l = \dfrac 1 a + \dfrac 1 b | r = \dfrac 1 2 + \dfrac 1 3 | c = }} {{eqn | r = \dfrac {3 + 2} 6 | c = }} {{eqn | r = \dfrac 5 6 | c = }} {{eqn | ll= \leadsto | l = \dfrac 1 c | r = 1 - \dfrac 5 6 | c = }} {{eqn | r = \dfrac 1 6 | c = }} {{eqn | ll= \leadsto | l = \dfrac 1 c | r = \dfrac 1 6 | c = }} {{eqn | ll= \leadsto | l = c | r = 6 | c = }} {{end-eqn}} Thus we have: :$(1): \quad 1 = \dfrac 1 2 + \dfrac 1 3 + \dfrac 1 6$ {{qed|lemma}} ==== $b = 4$ ==== Let $b = 4$. {{begin-eqn}} {{eqn | l = \dfrac 1 a + \dfrac 1 b | r = \dfrac 1 2 + \dfrac 1 4 | c = }} {{eqn | r = \dfrac {2 + 1} 4 | c = }} {{eqn | r = \dfrac 3 4 | c = }} {{eqn | ll= \leadsto | l = \dfrac 1 c | r = 1 - \dfrac 3 4 | c = }} {{eqn | r = \dfrac 1 4 | c = }} {{eqn | ll= \leadsto | l = c | r = 4 | c = }} {{end-eqn}} Thus we have: :$(2): \quad 1 = \dfrac 1 2 + \dfrac 1 4 + \dfrac 1 4$ ==== $b > 4$ ==== Let $b > 4$. Then: {{begin-eqn}} {{eqn | l = \dfrac 1 a + \dfrac 1 b + \dfrac 1 c | o = < | r = \dfrac 1 2 + \dfrac 1 4 + \dfrac 1 4 | c = }} {{eqn | r = 1 | c = }} {{end-eqn}} Hence there are no solutions such that $a = 2, b > 4$. {{qed|lemma}} === $a = 3$ === Let $a = 3$. ==== $b = 3$ ==== Let $b = 3$. {{begin-eqn}} {{eqn | l = \dfrac 1 a + \dfrac 1 b | r = \dfrac 1 3 + \dfrac 1 3 | c = }} {{eqn | r = \dfrac 2 3 | c = }} {{eqn | ll= \leadsto | l = \dfrac 1 c | r = 1 - \dfrac 2 3 | c = }} {{eqn | r = \dfrac 1 3 | c = }} {{eqn | ll= \leadsto | l = c | r = 3 | c = }} {{end-eqn}} Thus we have: :$(3): \quad 1 = \dfrac 1 3 + \dfrac 1 3 + \dfrac 1 3$ {{qed|lemma}} === $a > 3$ === Let $a > 3$. Then: {{begin-eqn}} {{eqn | l = \dfrac 1 a + \dfrac 1 b + \dfrac 1 c | o = \le | r = \dfrac 1 a + \dfrac 1 a + \dfrac 1 a | c = }} {{eqn | o = < | r = 1 | c = }} {{end-eqn}} Hence there are no solutions for $a>3$. {{qed|lemma}} === Summary === Hence our $3$ solutions: {{begin-eqn}} {{eqn | n = 1 | r = \dfrac 1 2 + \dfrac 1 3 + \dfrac 1 6 | o = }} {{eqn | n = 2 | r = \dfrac 1 2 + \dfrac 1 4 + \dfrac 1 4 | o = }} {{eqn | n = 3 | r = \dfrac 1 3 + \dfrac 1 3 + \dfrac 1 3 | o = }} {{end-eqn}} {{qed}}	0
Let $\ln$ denote the [[Definition:Complex Logarithm|complex logarithm]]. Let $z \in \C$ with $\cmod z \le \dfrac 1 2$. Then: :$\dfrac 1 2 \cmod z \le \cmod {\map \ln {1 + z} } \le \dfrac 3 2 \cmod z$	0
Let $S \subset \R$ be a [[Definition:Non-Empty Set|non-empty]] [[Definition:Subset|subset]] of the [[Definition:Real Numbers|real numbers]]. Let $S$ be [[Definition:Bounded Above Subset of Real Numbers|bounded above]]. Let $\omega \in \R$. {{TFAE}} :$(1): \quad \omega$ is the [[Definition:Supremum of Subset of Real Numbers|supremum]] of $S$ :$(2): \quad \omega$ is an [[Definition:Upper Bound of Subset of Real Numbers|upper bound]] for $S$ ::and: :::$\forall \epsilon \in \R_{> 0}$ there exists $x \in S$ with $x > \omega - \epsilon$	0
=== [[Complex Sequence is Cauchy iff Convergent/Lemma 1|Lemma]] === {{:Complex Sequence is Cauchy iff Convergent/Lemma 1}} Let $\sequence {x_n}$ be a [[Definition:Real Sequence|real sequence]] where: :$x_n = \Re \paren {z_n}$ for every $n$ :$\Re \paren {z_n}$ is the [[Definition:Real Part|real part]] of $z_n$ Let $\sequence {y_n}$ be a [[Definition:Real Sequence|real sequence]] where :$y_n = \Im \paren {z_n}$ for every $n$ :$\Im \paren {z_n}$ is the [[Definition:Imaginary Part|imaginary part]] of $z_n$ We find: :$\sequence {z_n}$ is a [[Definition:Complex Cauchy Sequence|Cauchy sequence]] :$\iff \sequence {x_n}$ and $\sequence {y_n}$ are [[Definition:Real Cauchy Sequence|Cauchy sequences]] by [[Complex Sequence is Cauchy iff Convergent/Lemma 1|Lemma]] :$\iff \sequence {x_n}$ and $\sequence {y_n}$ are [[Definition:Convergent Real Sequence|convergent]] by [[Real Sequence is Cauchy iff Convergent]] :$\iff \sequence {z_n}$ is [[Definition:Convergent Complex Sequence|convergent]] by definition of [[Definition:Convergent Complex Sequence|convergent complex sequence]] {{qed}}	0
:$\displaystyle \int_0^{2 \pi} \frac {\d x} {a + b \cos x} = \frac {2 \pi} {\sqrt {a^2 - b^2} }$	0
Let $\sin$ denote the [[Definition:Real Sine Function|real sine function]]. Let $\laptrans f$ denote the [[Definition:Laplace Transform|Laplace transform]] of a [[Definition:Real Function|real function]] $f$. Then: :$\laptrans {t^2 \cos a t} = \dfrac {2 s^3 - 6 a^2 s} {\paren {s^2 + a^2}^3}$	0
{{begin-eqn}} {{eqn | l = \int \frac {\d x} {x^3 \paren {a x + b} } | r = \int \paren {\frac {a^2} {b^3 x} + \frac {-a} {b^2 x^2} + \frac 1 {b x^3} + \frac {-a^3} {b^3 \paren {a x + b} } } \rd x | c = [[Primitive of Reciprocal of x cubed by a x + b/Partial Fraction Expansion|Partial Fraction Expansion]] }} {{eqn | r = \frac {a^2} {b^3} \int \frac {\d x} x + \frac {-a} {b^2} \int \frac {\d x} {x^2} + \frac 1 b \int \frac {\d x} {x^3} + \frac {-a^3} {b^3} \int \frac {\d x} {a x + b} | c = [[Linear Combination of Integrals]] }} {{eqn | r = \frac {a^2} {b^3} \int \frac {\d x} x + \frac {-a} {b^2} \frac {-1} x + \frac 1 b \frac {-1} {2 x^2} + \frac {-a^3} {b^3} \int \frac {\d x} {a x + b} + C | c = [[Primitive of Power]] }} {{eqn | r = \frac {a^2} {b^3} \ln \size x + \frac a {b^2 x} - \frac 1 {2 b x^2} + \frac {-a^3} {b^3} \int \frac {\d x} {a x + b} + C | c = [[Primitive of Reciprocal]] }} {{eqn | r = \frac {a^2} {b^3} \ln \size x + \frac a {b^2 x} - \frac 1 {2 b x^2} + \frac {-a^3} {b^3} \frac 1 a \ln \size {a x + b} + C | c = [[Primitive of Reciprocal of a x + b]] }} {{eqn | r = \frac a {b^2 x} - \frac 1 {2 b x^2} + \frac {a^2} {b^3} \ln \size {\frac x {a x + b} } + C | c = [[Difference of Logarithms]] }} {{eqn | r = \frac {2 a x - b} {2 b^2 x^2} + \frac {a^2} {b^3} \ln \size {\frac x {a x + b} } + C | c = rearranging }} {{end-eqn}} {{qed}}	0
By the given definition of the [[Definition:Natural Numbers in Real Numbers|natural numbers]]: :$\N = \bigcap \II$ where $\II$ is the collection of all [[Definition:Inductive Set as Subset of Real Numbers|inductive sets]]. The result is a direct application of [[Intersection of Inductive Set as Subset of Real Numbers is Inductive Set]]. {{qed}}	0
:$\displaystyle \int \frac {\mathrm d x} {x \left({x^4 + a^4}\right)} = \frac 1 {4 a^4} \ln \left({\frac {x^4} {x^4 + a^4} }\right)$	0
Let $a \in \R_{\ne 0}$. Then: :$\displaystyle \int \frac {x \ \mathrm d x} {\left({\sqrt {a x^2 + b x + c} }\right)^3} = \frac {2 \left({b x + 2 c}\right)} {\left({b^2 - 4 a c}\right) \sqrt {a x^2 + b x + c} }$	0
Let $a \in \R_{\ne 0}$. Then: :$\displaystyle \int \frac {x^2 \rd x} {a x^2 + b x + c} = \frac x a - \frac b {2 a^2} \ln \size {a x^2 + b x + c} - \frac {b^2 - 2 a c} {2 a^2} \int \frac {\d x} {a x^2 + b x + c}$	0
By definition, the [[Definition:Order of Group|order]] of a [[Definition:Group|group]] is the [[Definition:Cardinality|cardinality]] of its [[Definition:Underlying Set|underlying set]]. By definition, the [[Definition:Underlying Set|underlying set]] of $\struct {\Z'_m, \times_m}$ is the [[Definition:Reduced Residue System|reduced residue system ]] $\Z'_m$: :$\Z'_m = \set {\eqclass {a_1} m, \eqclass {a_2} m, \ldots, \eqclass {a_{\map \phi m} } m}$ where: :$\forall k: a_k \perp m$ From [[Cardinality of Reduced Residue System]], $\Z'_m$ has $\map \phi m$ [[Definition:Element|elements]]. Hence the result. {{qed}}	0
Let $\mathbf{Mon}$ be the [[Definition:Category of Monoids|category of monoids]]. Let $\left({\N, +}\right)$ denote the [[Definition:Monoid|monoid]] of [[Definition:Natural Numbers|natural numbers]] as on [[Natural Numbers under Addition form Commutative Monoid]]. Let $\left({\Z, +}\right)$ denote the [[Definition:Monoid|monoid]] of [[Definition:Integer|integers]] as on [[Definition:Additive Group of Integers|additive group of integers]]. Denote with $\iota: \N \to \Z$ the [[Definition:Inclusion Mapping|inclusion mapping]]. Then $\iota: \N \to \Z$ is an [[Definition:Epimorphism (Category Theory)|epimorphism]] in $\mathbf{Mon}$.	0
:$\ln x \to -\infty$ as $x \to 0^+$	0
Let $T_1 = \struct {S_1, \tau_1}$ and $T_2 = \struct {S_2, \tau_2}$ be [[Definition:Topological Space|topological spaces]]. Let $f: S_1 \to S_2$ be a [[Definition:Mapping|mapping]] from $S_1$ to $S_2$. Let $x \in S_1$. {{TFAE|def = Continuous at Point of Topological Space|view = continuity at a point of a topological space}} === [[Definition:Continuous Mapping (Topology)/Point/Open Sets|Definition using Open Sets]] === {{Definition:Continuous Mapping (Topology)/Point/Open Sets}} === [[Definition:Continuous Mapping (Topology)/Point/Filters|Definition using Filters]] === {{Definition:Continuous Mapping (Topology)/Point/Filters}}	0
:$\displaystyle \int x^m \cos a x \rd x = \frac {x^m \sin a x} a + \frac {m x^{m - 1} \cos a x} {a^2} - \frac {m \paren {m - 1} } {a^2} \int x^{m - 2} \cos a x \rd x$	0
From [[Ring of Integers Modulo m is Ring]], $\struct {\Z_m, +, \times}$ is a [[Definition:Ring (Abstract Algebra)|ring]]. It remains to be shown that $\struct {\Z_m, +, \times}$ has no [[Definition:Proper Zero Divisor|proper zero divisors]] {{iff}} $m$ is [[Definition:Prime Number|prime]]. === $m$ Composite === Let $m$ be [[Definition:Composite Number|composite]]. Then: :$m = m_1 m_2$ where $0 < m_1 < m, 0 < m_2 < m$. Then: :$\eqclass {m_1} m \eqclass {m_2} m = \eqclass 0 m$ and so both $\eqclass {m_1} m$ and $\eqclass {m_2} m$ are [[Definition:Proper Zero Divisor|proper zero divisors]]. Hence if $m$ is not [[Definition:Prime Number|prime]] then $\struct {\Z_m, +, \times}$ is not an [[Definition:Integral Domain|integral domain]] by definition. {{qed|lemma}} === $m$ Prime === Let $m$ be [[Definition:Prime Number|prime]]. Let $\eqclass a m \eqclass b m = \eqclass 0 m$. Then by [[Modulo Multiplication is Well-Defined]]: :$\eqclass {a b} m = \eqclass 0 m$ Thus either :$m \divides a$ or $m \divides b$ where $\divides$ denotes the [[Definition:Divisor of Integer|divisibility relation]]. If $m \divides a$ then $\eqclass a m = 0$. If $m \divides b$ then $\eqclass b m = 0$. Thus neither $a$ nor $b$ is a [[Definition:Proper Zero Divisor|proper zero divisor]]. Hence there are no [[Definition:Proper Zero Divisor|proper zero divisors]] of $\struct {\Z_m, +, \times}$. Hence, by definition, $\struct {\Z_m, +, \times}$ is an [[Definition:Integral Domain|integral domain]] {{qed}}	0
{{ProofWanted}} [[Category:Natural Numbers]] 1zzp324216wqgotazjznwwhve8ejfzz	0
Let: {{begin-eqn}} {{eqn | l = z | r = x^2 }} {{eqn | ll= \leadsto | l = \frac {\d z} {\d x} | r = 2 x | c = [[Power Rule for Derivatives]] }} {{eqn | ll= \leadsto | l = \int \frac {\paren {\sqrt {x^2 + a^2} }^3} {x^3} \rd x | r = \int \frac {\paren {\sqrt {z + a^2} }^3} {2 z^2} \rd z | c = [[Integration by Substitution]] }} {{eqn | r = \frac 1 2 \paren {\frac {-\paren {\sqrt {z + a^2} }^3} z + \frac 3 2 \int \frac {\sqrt {z + a^2} } z \rd z} | c = [[Primitive of Power of a x + b over Power of p x + q/Formulation 3|Primitive of $\dfrac {\paren {a x + b}^m} {\paren {p x + q}^n}$: Formulation 3]] }} {{eqn | r = \frac {-\paren {\sqrt {x^2 + a^2} }^3} {2 x^2} + \frac 3 2 \int \frac {\sqrt {x^2 + a^2} } x \rd x | c = substituting for $z$ and simplifying }} {{eqn | r = \frac {-\paren {\sqrt {x^2 + a^2} }^3} {2 x^2} + \frac 3 2 \paren {\sqrt {x^2 + a^2} - a \map \ln {\frac {a + \sqrt {x^2 + a^2} } a} } + C | c = [[Primitive of Root of x squared plus a squared over x|Primitive of $\dfrac {\sqrt {x^2 + a^2} } x$]] }} {{eqn | r = \frac {-\paren {\sqrt {x^2 + a^2} }^3} {2 x^2} + \frac {3 \sqrt {x^2 + a^2} } 2 - \frac {3 a} 2 \map \ln {\frac {a + \sqrt {x^2 + a^2} } x} + C | c = simplifying }} {{end-eqn}} {{qed}}	0
Let $x$ be a [[Definition:Real Number|real number]] which is both [[Definition:Positive Real Number|positive]] and [[Definition:Negative Real Number|negative]]. Thus: :$x \in \set {x \in \R: x \ge 0}$ and: :$x \in \set {x \in \R: x \le 0}$ and so: :$0 \le x \le 0$ from which: :$x = 0$ {{qed}}	0
:$\displaystyle \int \frac {\d x} {x \sqrt {x^2 - a^2} } = \frac 1 a \arcsec \size {\frac x a} + C$ for $\size x > a$.	0
{{AimForCont}} that $\sqrt 2$ is [[Definition:Rational Number|rational]]. Then $\sqrt 2 = \dfrac p q$ for some $p, q \in \Z_{>0}$ Consider the quantity $\paren {\sqrt 2 - 1}$: {{begin-eqn}} {{eqn | ll = 1 | l = < | o = \sqrt 2 | r = < | rr = 2 | c = [[Ordering of Squares in Reals]] }} {{eqn | lll = \leadsto | ll = 0 | l = < | o = \sqrt 2 - 1 | r = < | rr = 1 }} {{end-eqn}} Now, observe that for any $n \in \Z_{>0}$: {{begin-eqn}} {{eqn | l = \paren {\sqrt 2 - 1}^n | r = \sum_{k \mathop = 0}^n \binom n k \paren {\sqrt 2}^k \paren {-1}^{n-k} | c = [[Binomial Theorem]] }} {{eqn | r = \sum_{\substack {0 \mathop \le k \mathop \le n \\ k \, \text{even} } } \binom n k 2^{k/2} \paren {-1}^{n - k} + \sqrt 2 \sum_{\substack {0 \mathop \le k \mathop \le n \\ k \, \text{odd} } } \binom n k 2^{\paren {k - 1}/2} \paren {-1}^{n-k} }} {{eqn | r = a_n + b_n \sqrt 2 | c = for some [[Definition:Integer|integers]] $a_n, b_n$ }} {{eqn | r = a_n + b_n \paren {\frac p q} | c = recalling the assumption that $\sqrt 2 = \dfrac p q$ }} {{eqn | r = \frac {a_n q + b_n p} q }} {{eqn | o = \ge | r = \frac 1 q | c = as the [[Definition:Numerator|numerator]] is an integer and $\sqrt 2 - 1 > 0$ }} {{end-eqn}} By [[Sequence of Powers of Number less than One]]: :$\displaystyle \lim_{n \mathop \to \infty} \paren {\sqrt 2 - 1}^n = 0$ where $\lim$ denotes [[Definition:Limit of Real Sequence|limit]]. Recall the definition of $a_n$ and $b_n$. By [[Lower and Upper Bounds for Sequences]]: :$0 = \displaystyle \lim_{n \mathop \to \infty} \frac {a_n q + b_n p} q \ge \frac 1 q$ which is a [[Proof by Contradiction|contradiction]]. {{qed}}	0
Let $\left\langle{a_n}\right\rangle$ be a [[Definition:Sequence|sequence]] which has a [[Definition:Generating Function|generating function]] which is [[Definition:Convergent Real Function|convergent]]. Let $G \left({z}\right)$ be the [[Definition:Generating Function|generating function]] for $\left\langle{a_n}\right\rangle$. Let $f \left({x}\right)$ be the [[Definition:Step Function|step function]]: :$f \left({x}\right) = \displaystyle \sum_{k \mathop \in \Z} a_k \left[{0 \le k \le x}\right]$ where $\left[{0 \le k \le x}\right]$ is [[Definition:Iverson's Convention|Iverson's convention]]. Then the [[Definition:Laplace Transform|Laplace transform]] of $f \left({x}\right)$ is given by: :$\mathcal L \left\{ {f \left({s}\right)}\right\} = \dfrac {G \left({e^{-s} }\right)} s$	0
By definition of [[Definition:Half-Range Fourier Cosine Series|half-range Fourier cosine series]]: :$\displaystyle \map f x \sim \frac {a_0} 2 + \sum_{n \mathop = 1}^\infty a_n \cos n x$ where for all $n \in \Z_{> 0}$: :$a_n = \displaystyle \frac 2 \pi \int_0^\pi \map f x \cos n x \rd x$ Thus by definition of $f$: {{begin-eqn}} {{eqn | l = a_0 | r = \frac 2 \pi \int_0^\pi \map f x \rd x | c = [[Cosine of Zero is One]] }} {{eqn | r = \frac 2 \pi \int_0^\pi \cos \lambda x \rd x | c = Definition of $f$ }} {{eqn | r = \frac 2 \pi \intlimits {\frac {\sin \lambda x} \lambda} 0 \pi | c = [[Primitive of Cosine of a x|Primitive of $\cos a x$]] }} {{eqn | r = \frac 2 \pi \paren {\frac {\sin \lambda \pi} \lambda - \frac {\sin 0} \lambda} | c = }} {{eqn | r = \frac {2 \sin \lambda \pi} {\pi \lambda} | c = [[Sine of Zero is Zero]] }} {{end-eqn}} {{qed|lemma}} Because $\lambda \notin \Z$ we have that $\lambda \ne n$ for all $n$. Thus for $n > 0$: {{begin-eqn}} {{eqn | l = a_n | r = \frac 2 \pi \int_0^\pi \map f x \cos n x \rd x | c = }} {{eqn | r = \frac 2 \pi \int_0^\pi \cos \lambda x \cos n x \rd x | c = Definition of $f$ }} {{eqn | r = \frac 2 \pi \intlimits {\frac {\sin \paren {\lambda - n} x} {2 \paren {\lambda - n} } + \frac {\sin \paren {\lambda + n} x} {2 \paren {\lambda + n} } } 0 \pi | c = [[Primitive of Cosine of a x by Cosine of p x|Primitive of $\cos \lambda x \cos n x$]] }} {{eqn | r = \frac 2 \pi \paren {\paren {\frac {\sin \paren {\lambda - n} \pi} {2 \paren {\lambda - n} } + \frac {\sin \paren {\lambda + n} \pi} {2 \paren {\lambda + n} } } - \paren {\frac {\sin 0} {2 \paren {\lambda - n} } + \frac {\sin 0} {2 \paren {\lambda + n} } } } | c = }} {{eqn | r = \frac 1 \pi \paren {\frac {\sin \paren {\lambda - n} \pi} {\lambda - n} + \frac {\sin \paren {\lambda + n} \pi} {\lambda + n} } | c = [[Sine of Multiple of Pi]] and simplification }} {{eqn | r = \frac 1 \pi \paren {\frac {\sin \lambda \pi \cos n \pi - \cos \lambda \pi \sin n \pi} {\lambda - n} + \frac {\sin \lambda \pi \cos n \pi + \cos \lambda \pi \sin n \pi} {\lambda + n} } | c = [[Sine of Sum]] }} {{eqn | r = \frac {\sin \lambda \pi \cos n \pi} \pi \paren {\frac 1 {\lambda - n} + \frac 1 {\lambda + n} } | c = [[Sine of Multiple of Pi]] and simplification }} {{eqn | r = \frac {\paren {-1}^n \sin \lambda \pi} \pi \frac {\lambda + n + \lambda - n} {\paren {\lambda - n} \paren {\lambda + n} } | c = [[Cosine of Multiple of Pi]] and manipulation }} {{eqn | r = \paren {-1}^n \frac {2 \sin \lambda \pi} \pi \frac \lambda {\lambda^2 - n^2} | c = [[Difference of Two Squares]] }} {{end-eqn}} {{qed|lemma}} Finally: {{begin-eqn}} {{eqn | l = \map f x | o = \sim | r = \frac {a_0} 2 + \sum_{n \mathop = 1}^\infty a_n \cos n x | c = }} {{eqn | r = \frac 1 2 \frac {2 \sin \lambda \pi} {\pi \lambda} + \sum_{n \mathop = 1}^\infty \paren {-1}^n \frac {2 \sin \lambda \pi} \pi \frac \lambda {\lambda^2 - n^2} \cos n x | c = substituting for $a_0$ and $a_n$ from above }} {{eqn | r = \frac {2 \sin \lambda \pi} \pi \paren {\frac 1 {2 \lambda} + \sum_{n \mathop = 1}^\infty \paren {-1}^n \frac \lambda {\lambda^2 - n^2} \cos n x} | c = simplifying }} {{eqn | r = \frac {2 \lambda \sin \lambda \pi} \pi \paren {\frac 1 {2 \lambda^2} + \sum_{n \mathop = 1}^\infty \paren {-1}^n \frac {\cos n x} {\lambda^2 - n^2} } | c = further manipulation }} {{end-eqn}} {{qed}}	0
By [[Cantor's Theorem]] there is no [[Definition:Surjection|surjection]]: : $\N \twoheadrightarrow \mathcal P \left({\N}\right)$ Additionally, we have [[Power Set of Natural Numbers is not Countable]]. Therefore, if we can show that $\mathcal P \left({\N}\right)$ [[Definition:Injection|injects]] into $\R$ then there is no [[Definition:Injection|injection]] $\R \hookrightarrow \N$ and $\R$ is uncountable. To prove the theorem we construct an [[Definition:Injection|injection]] $f: \mathcal P \left({\N}\right) \to \R$. For a subset $S \subseteq \N$, let $\chi_S$ be the [[Definition:Characteristic Function of Set|characteristic function]] of $S$, and let $d_i = \chi_S \left({i}\right)$ for all $i \in \N$. By the definition of [[Definition:Characteristic Function of Set|characteristic function]], $\left\langle{d_i}\right\rangle_{i \in \N}$ is an [[Definition:Infinite Sequence|infinite sequence]] of $1$s and $0$s. There are two cases: $\left\langle{d_i}\right\rangle_{i \in \N}$ terminates in an [[Definition:Infinite Sequence|infinite sequence]] of $1$s, or it does not. Suppose $\left\langle{d_i}\right\rangle_{i \in \N}$ does ''not'' terminate in an [[Definition:Infinite Sequence|infinite sequence]] of $1$s. Then $f \left({S}\right)$ is the [[Definition:Binary Notation|binary]] [[Definition:Basis Expansion|expansion]] of the following number in $\left[{0 \,.\,.\, 1}\right)$: :$0.d_1 d_2 d_3 d_4 \ldots$ Otherwise $\left\langle{d_i}\right\rangle_{i \in \N}$ ''does'' terminate in an [[Definition:Infinite Sequence|infinite sequence]] of $1$s. Then $f \left({S}\right)$ is the [[Definition:Integer|integer]] expressed in [[Definition:Binary Notation|binary]] as: :$1 d_1 d_2 d_3 \ldots d_k$ where $d_k$ is the last member of the sequence not equal to $1$. In either case, every [[Definition:Subset|subset]] of $\N$, that is, element of $\mathcal P \left({\N}\right)$, is mapped to an element of $\R$. That $f$ is an [[Definition:Injection|injection]] follows from the uniqueness statement of [[Existence of Base-N Representation]]. {{qed}}	0
{{begin-eqn}} {{eqn | l = \dfrac 1 {2 n} + \dfrac 1 {6 n} | r = \dfrac 3 {6 n} + \dfrac 1 {6 n} | c = }} {{eqn | r = \dfrac {3 + 1} {6 n} | c = }} {{eqn | r = \dfrac 2 {3 n} | c = }} {{eqn | r = \dfrac 1 n \times \dfrac 2 3 | c = }} {{end-eqn}} Note the case where we multiply $\dfrac 2 3$ by $\dfrac 2 3$ itself: {{begin-eqn}} {{eqn | l = \dfrac 2 3 \times \dfrac 2 3 | r = \dfrac 4 9 | c = }} {{eqn | r = \dfrac 3 9 + \dfrac 1 9 | c = }} {{eqn | r = \dfrac 1 3 + \dfrac 1 9 | c = which is in [[Definition:Egyptian Fraction|Egyptian form]] }} {{end-eqn}} {{qed}}	0
[[Definition:Euler's Number|Euler's Number]] $e$ is [[Definition:Transcendental|transcendental]].	0
Follows directly from the [[Definition:Rational Number|definition of rational numbers]] as the [[Definition:Field of Quotients|field of quotients]] of the [[Definition:Integral Domain|integral domain]] $\struct {\Z, +, \times}$ of [[Definition:Integer|integers]]. So $\struct {\Q, +, \times}$ is a [[Definition:Field (Abstract Algebra)|field]], and therefore [[Definition:A Priori|a priori]] $\times$ is [[Definition:Commutative Operation|commutative]] on $\Q$. {{qed}}	0
Let $\zeta$ denote the [[Definition:Riemann Zeta Function|Riemann zeta function]]. The [[Definition:Analytic Continuation|analytic continuation]] of $\zeta$ to the [[Definition:Complex Halfplane|half-plane]] $\map \Re s > 0$ is given by: :$\displaystyle \frac s {s - 1} - s \int_1^\infty \fractpart x x^{-s - 1} \rd x$ where $x^{-s - 1}$ takes the principle value $e^{-\map \ln x \paren {s + 1} }$	0
From [[Primitive of Power of a x + b|Primitive of Power of $a x + b$]]: :$\displaystyle \int \left({a x + b}\right)^n \ \mathrm d x = \frac {\left({a x + b}\right)^{n + 1} } {\left({n + 1}\right) a} + C$ where $n \ne 1$. The result follows by setting $n = -3$. {{qed}}	0
:$\displaystyle \int_0^\infty e^{-a x^2} \rd x = \frac 1 2 \sqrt {\frac \pi a}$	0
{{begin-eqn}} {{eqn | l = \tan 15^\circ | r = \tan \frac {30^\circ} 2 | c = }} {{eqn | r = \frac {\sin 30^\circ} {1 + \cos 30^\circ} | c = [[Half Angle Formulas/Tangent/Corollary 1|Half Angle Formula for Tangent: Corollary 1]] }} {{eqn | r = \frac {\frac 1 2} {1 + \frac {\sqrt 3} 2} | c = [[Sine of 30 Degrees|Sine of $30^\circ$]] and [[Cosine of 30 Degrees|Cosine of $30^\circ$]] }} {{eqn | r = \frac {\frac 1 2} {\frac {2 + \sqrt 3} 2} | c = }} {{eqn | r = \frac 1 {2 + \sqrt 3} | c = }} {{eqn | r = \frac {2 - \sqrt 3} {\left({2 + \sqrt 3}\right) \left({2 - \sqrt 3}\right)} | c = multiplying top and bottom by $2 - \sqrt 3$ }} {{eqn | r = \frac {2 - \sqrt 3} {4 - 3} | c = [[Difference of Two Squares]] }} {{eqn | r = 2 - \sqrt 3 | c = }} {{end-eqn}} {{qed}}	0
From [[Cosecant is Reciprocal of Sine]]: : $\csc \theta = \dfrac 1 {\sin \theta}$ From [[Sine of Zero is Zero]]: : $\sin 0 = 0$ Thus $\csc \theta$ is undefined at this value. {{qed}}	0
From [[Euler's Formula]]: :$e^{i \theta} = \cos \theta + i \sin \theta$ Hence: {{begin-eqn}} {{eqn | l = \sum_{k \mathop = 1}^\infty r^k \sin k x | r = \map \Im {\sum_{k \mathop = 1}^\infty r^k e^{i k x} } | c = }} {{eqn | r = \map \Im {\sum_{k \mathop = 0}^\infty \paren {r e^{i x} }^k} | c = as $\map \Im {e^{i \times 0 \times x} } = \map \Im 1 = 0$ }} {{eqn | r = \map \Im {\frac 1 {1 - r e^{i x} } } | c = [[Sum of Infinite Geometric Sequence]]: valid because $\size r < 1$ }} {{eqn | r = \map \Im {\frac {1 - r e^{-i x} } {\paren {1 - r e^{-i x} } \paren {1 - r e^{i x} } } } | c = }} {{eqn | r = \map \Im {\frac {1 - r e^{-i x} } {1 - r \paren {e^{i x} + e^{- i x} } + r^2} } | c = }} {{eqn | r = \map \Im {\frac {1 - r \paren {\cos x - i \sin x} } {1 - 2 r \cos x + r^2} } | c = [[Euler's Formula/Corollary|Corollary to Euler's Formula]] }} {{eqn | r = \dfrac {r \sin x} {1 - 2 r \cos x + r^2} | c = after simplification }} {{end-eqn}} It is noted that when $x$ is a multiple of $2 \pi$ then: :$1 - 2 r \cos x + r^2 = 1 - 2 + 1 = 0$ leaving the {{RHS}} undefined. {{qed}}	0
We are required to prove that: :$\xi \left({s}\right) = \dfrac 1 2 s \left({s - 1}\right) \pi^{-s/2} \Gamma \left({\dfrac s 2}\right) \zeta \left({s}\right) \ll \exp \left({|s|^\beta}\right)$ for all $\beta > 1$, where $\ll$ is the [[Definition:Big-O Notation|order notation]]. Note that by the [[Functional Equation for Riemann Zeta Function]], it is sufficient to check this for $\Re \left({s}\right) \ge \dfrac 1 2$. We simply check this fact for each factor. Evidently: {{begin-eqn}} {{eqn | l = \frac 1 2 s \left({s - 1}\right) \pi^{-s/2} | o = \ll | r = \exp\left({2 \log s - \frac s 2 \log \pi}\right) }} {{eqn | o = \ll | r = \exp\left({c_1 \left\vert{s}\right\vert}\right) }} {{end-eqn}} for some $c_1 > 0$. For the [[Definition:Gamma Function|gamma]] factor, we have [[Stirling's Formula for Gamma Function]]: :$\displaystyle \log \Gamma \left({s}\right) = \left({s - \frac 1 2}\right)\log s - s + \frac {\log 2 \pi} 2 + \sum_{n \mathop = 1}^{d-1} \frac{B_{2 n}}{ 2 n \left({2 n - 1}\right)s^{2 n-1}} + \mathcal O \left({s^{1 - 2 d} }\right)$ This is valid only away from the [[Definition:Pole|poles]] of $\Gamma$ at $s = 0, -1, -2, \ldots$ However, it is assumed that $\Re \left({s}\right) \ge \dfrac 1 2$, so this is not a problem. The error term $\mathcal O \left({s^{1 - 2d} }\right)$ is small for large $s$. More generally, the largest contribution is the term $\left({s - \dfrac 1 2}\right)\log s$, so we have: :$\log \Gamma\left({\dfrac s 2}\right) \ll \left\vert{s}\right\vert \log \left\vert{s}\right\vert$ That is: :$\Gamma \left({\dfrac s 2}\right) \ll \exp \left({\left\vert{s}\right\vert \log \left\vert{s}\right\vert}\right)$ Finally, from [[Integral Representation of Riemann Zeta Function in terms of Fractional Part]], for $\Re \left({s}\right) > \dfrac 1 2$: :$\displaystyle \zeta \left({s}\right) = \frac s {s-1} - s \int_1^\infty \left\{{x}\right\} x^{-s-1} \ \mathrm d x$ It is seen that for $\Re \left({s}\right) > \dfrac 1 2$, the integral is bounded, and therefore: :$\left({1 - s}\right) \zeta \left({s}\right) \ll \mathcal O (\left\vert{s}\right\vert^2) \ll \exp \left({\left\vert{s}\right\vert}\right)$ Combining these facts, and using that $\log s \ll s^\epsilon$ for all $\epsilon > 0$ (shown by [[Upper Bound of Natural Logarithm]]), we have: :$\left|{\xi \left({s}\right)}\right| \ll \exp\left({\left\vert{s}\right\vert^{1 + \epsilon} }\right)$ for all $\epsilon > 0$, and the proof is complete. {{qed}} [[Category:Riemann Zeta Function]] jk1z74v284tro7oyhtwcf4lspax9183	0
Let $\map N z$ denote the [[Definition:Field Norm of Complex Number|field norm]] of $z \in \Z \sqbrk {i \sqrt 5}$. Let $z = x + i y$. Then: {{begin-eqn}} {{eqn | l = \map N z | r = 2 | c = }} {{eqn | ll= \leadsto | l = x^2 + 5 y^2 | r = 2 | c = [[Field Norm on 5th Cyclotomic Ring]] }} {{eqn | ll= \leadsto | l = x^2 | r = 2 | c = as $y$ is an [[Definition:Integer|integer]] and has to equal $0$ }} {{eqn | ll= \leadsto | l = x | r = \sqrt 2 | c = }} {{end-eqn}} But [[Square Root of Prime is Irrational]] so $x \notin \Z$. Similarly for $\map N z = 3$. {{qed}}	0
$(1): \quad \forall n \in \N: x_n \ge a \implies l \ge a$: Let $\epsilon > 0$. Then: :$\exists N \in \N: n > N \implies \size {x_n - l} < \epsilon$ So from [[Negative of Absolute Value]]: :$l - \epsilon < x_n < l + \epsilon$ But $x_n \ge a$, so: :$a \le x_n < l + \epsilon$ Thus, for ''any'' $\epsilon > 0$: :$a < l + \epsilon$ From [[Real Plus Epsilon]] it follows that $a \le l$. {{qed|lemma}} $(2): \quad \forall n \in \N: x_n \le b \implies l \le b$: If $x_n \le b$ it follows that $-x_n \ge -b$ and the above result can be used. {{qed}}	0
Let $C$ denote the [[Definition:Sequence|sequence]] in question. We have that $554 \, 688 \, 278 \, 429$ is [[Definition:Prime Number|prime]]. First note that: :$\dfrac {554 \, 688 \, 278 \, 429 - 1} 2 = 277 \, 344 \, 139 \, 214 = 2 \times 138 \, 672 \, 069 \, 607$ and so is not [[Definition:Prime Number|prime]]. Thus $554 \, 688 \, 278 \, 429$ is not a [[Definition:Safe Prime|safe prime]], and thus fulfils the requirement for $C$ to be a [[Definition:Cunningham Chain of the First Kind|Cunningham chain of the first kind]]. Then: {{begin-eqn}} {{eqn | n = 1 | l = 2 \times 554 \, 688 \, 278 \, 429 + 1 | r = 1 \, 109 \, 376 \, 556 \, 859 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | n = 2 | l = 2 \times 1 \, 109 \, 376 \, 556 \, 859 + 1 | r = 2 \, 218 \, 753 \, 113 \, 719 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | n = 3 | l = 2 \times 2 \, 218 \, 753 \, 113 \, 719 + 1 | r = 4 \, 437 \, 506 \, 227 \, 439 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | n = 4 | l = 2 \times 4 \, 437 \, 506 \, 227 \, 439 + 1 | r = 8 \, 875 \, 012 \, 454 \, 879 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | n = 5 | l = 2 \times 8 \, 875 \, 012 \, 454 \, 879 + 1 | r = 17 \, 750 \, 024 \, 909 \, 759 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | n = 6 | l = 2 \times 17 \, 750 \, 024 \, 909 \, 759 + 1 | r = 35 \, 500 \, 049 \, 819 \, 519 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | n = 7 | l = 2 \times 35 \, 500 \, 049 \, 819 \, 519 + 1 | r = 71 \, 000 \, 099 \, 639 \, 039 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | n = 8 | l = 2 \times 71 \, 000 \, 099 \, 639 \, 039 + 1 | r = 142 \, 000 \, 199 \, 278 \, 079 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | n = 9 | l = 2 \times 142 \, 000 \, 199 \, 278 \, 079 + 1 | r = 284 \, 000 \, 398 \, 556 \, 159 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | n = 10 | l = 2 \times 284 \, 000 \, 398 \, 556 \, 159 + 1 | r = 568 \, 000 \, 797 \, 112 \, 319 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | n = 11 | l = 2 \times 568 \, 000 \, 797 \, 112 \, 319 + 1 | r = 1 \, 136 \, 001 \, 594 \, 224 \, 639 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | n = 12 | l = 2 \times 1 \, 136 \, 001 \, 594 \, 224 \, 639 + 1 | r = 2 \, 272 \, 003 \, 188 \, 449 \, 279 | c = which is $19 \times 119 \, 579 \, 115 \, 181 \, 541$ [[Definition:Prime Number|prime]] }} {{end-eqn}} Establishing that this is indeed the smallest such [[Definition:Cunningham Chain of the First Kind|Cunningham chain of the first kind]] of [[Definition:Length of Sequence|length]] $12$ can be done by a computer search. {{qed}}	0
{{:Euclid:Proposition/V/18}} That is: :$a : b = c : d \implies \left({a + b}\right) : b = \left({c + d}\right) : d$	0
{{begin-eqn}} {{eqn | l = \lim_{x \mathop \to 0} \frac {\map \ln {1 + x} } x | r = \lim_{x \mathop \to 0} \frac {\map \ln {1 + x} - \ln 1} x | c = subtract $\ln 1 = 0$ from the numerator, from [[Logarithm of 1 is 0]] }} {{eqn | r = \intlimits {\dfrac {\d} {\d x} \ln x} {x \mathop = 1} {} | c = {{Defof|Derivative of Real Function at Point}} }} {{eqn | r = \frac 1 1 | c = [[Derivative of Natural Logarithm Function]] }} {{eqn | r = 1 }} {{end-eqn}} {{qed}}	0
Let us cast the proposition in the form: :$\forall a, b, n \in \N_{> 0}: a \times \paren {b + n} = \paren {a \times b} + \paren {a \times n}$ For all $n \in \N_{> 0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\forall a, b \in \N_{> 0}: a \times \paren {b + n} = \paren {a \times b} + \paren {a \times n}$ === Basis for the Induction === $\map P 1$ is the case: {{begin-eqn}} {{eqn | l = a \times \paren {b + 1} | r = \paren {a \times b} + a | c = [[Axiom:Axiomatization of 1-Based Natural Numbers|Axiom $\text B$]] }} {{eqn | r = \paren {a \times b} + \paren {a \times 1} | c = [[Axiom:Axiomatization of 1-Based Natural Numbers|Axiom $\text A$]] }} {{end-eqn}} and so $\map P 1$ holds. This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\forall a, b \in \N_{> 0}: a \times \paren {b + k} = \paren {a \times b} + \paren {a \times k}$ Then we need to show: :$\forall a, b \in \N_{> 0}: a \times \paren {b + \paren {k + 1} } = \paren {a \times b} + \paren {a \times \paren {k + 1} }$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = a \times \paren {b + \paren {k + 1} } | r = a \times \paren {\paren {b + k} + 1} | c = [[Axiom:Axiomatization of 1-Based Natural Numbers|Axiom $\text C$]] }} {{eqn | r = \paren {a \times \paren {b + k} } + a | c = [[Axiom:Axiomatization of 1-Based Natural Numbers|Axiom $\text B$]] }} {{eqn | r = \paren {\paren {a \times b} + \paren {a \times k} } + a | c = [[Left Distributive Law for Natural Numbers#Induction Hypothesis|Induction hypothesis]] }} {{eqn | r = \paren {a \times b} + \paren {\paren {a \times k} + a} | c = [[Natural Number Addition is Associative]] }} {{eqn | r = \paren {a \times b} + \paren {a \times \paren {k + 1} } | c = [[Axiom:Axiomatization of 1-Based Natural Numbers|Axiom $\text B$]] }} {{end-eqn}} The result follows by the [[Principle of Mathematical Induction]].	0
The [[Definition:Hyperbolic Cotangent|hyperbolic cotangent function]] has a [[Definition:Taylor Series|Taylor series expansion]]: {{begin-eqn}} {{eqn | l = \coth x | r = \sum_{n \mathop = 0}^\infty \frac {2^{2 n} B_{2 n} \, x^{2 n - 1} } {\left({2 n}\right)!} | c = }} {{eqn | r = \frac 1 x + \frac x 3 - \frac {x^3} {45} + \frac {2 x^5} {45} + \cdots | c = }} {{end-eqn}} where $B_{2 n}$ denotes the [[Definition:Bernoulli Numbers|Bernoulli numbers]]. This [[Definition:Convergent Series|converges]] for $0 < \left|{x}\right| < \pi$.	0
Let $r \in \R$ such that $\size r < 1$. Let $x \in \R$ such that $x \ne 2 m \pi$ for any $m \in \Z$. Then: {{begin-eqn}} {{eqn | l = \sum_{k \mathop = 1}^\infty r^k \sin k x | r = r \sin x + r^2 \sin 2 x + r^3 \sin 3 x + \cdots | c = }} {{eqn | r = \dfrac {r \sin x} {1 - 2 r \cos x + r^2} | c = }} {{end-eqn}}	0
Let $a \in \R_{>0}$ be a [[Definition:Strictly Positive Real Number|strictly positive real]] [[Definition:Constant|constant]]. Let $x \in \R$ such that $\size x \ne a$.	0
:$\arccot a - \arccot b = \arccot \dfrac {a b + 1} {a - b}$ where $\arccot$ denotes the [[Definition:Arccotangent|arccotangent]].	0
{{begin-eqn}} {{eqn | l = \int_0^\infty \frac {\cos a x} {\cosh b x} \rd x | r = \int_0^\infty \frac {e^{-b x} \paren {e^{i a x} + e^{-i a x} } } {1 - \paren {-e^{-2 b x} } } \rd x | c = [[Cosine Exponential Formulation]], {{Defof|Hyperbolic Cosine}} }} {{eqn | r = \int_0^\infty \paren {e^{\paren {i a - b} x} + e^{-\paren {i a + b} x} } \paren {\sum_{n \mathop = 0}^\infty \paren {-1}^n e^{-2 n b x} } \rd x | c = [[Sum of Infinite Geometric Sequence]] }} {{eqn | r = \sum_{n \mathop = 0}^\infty \int_0^\infty \paren {-1}^n \paren {e^{\paren {i a - \paren {2 n + 1} b} x} + e^{-\paren {i a + \paren {2 n + 1} b} x} } \rd x | c = [[Fubini's Theorem]] }} {{eqn | r = \sum_{n \mathop = 0}^\infty \paren {-1}^n \paren {\intlimits {-\frac {e^{\paren {i a - \paren {2 n + 1} b} x} } {\paren {2 n + 1} b - i a} } 0 \infty + \intlimits {-\frac {e^{-\paren {i a + \paren {2 n + 1} b} x} } {\paren {2 n + 1} + i a} } 0 \infty} | c = [[Primitive of Exponential of a x|Primitive of $e^{a x}$]] }} {{end-eqn}} We have, as $b, n > 0$: {{begin-eqn}} {{eqn | l = \size {\lim_{x \mathop \to \infty} e^{\paren {i a - \paren {2 n + 1} b} x} } | r = \lim_{x \mathop \to \infty} \size {e^{\paren {i a - \paren {2 n + 1} b} x} } | c = [[Modulus of Limit]] }} {{eqn | r = \lim_{x \mathop \to \infty} \size {e^{i a x} } \size {e^{-\paren {2 n + 1} b x} } | c = [[Exponential of Sum]] }} {{eqn | r = \lim_{x \mathop \to \infty} e^{-\paren {2 n + 1} b x} }} {{eqn | r = 0 | c = [[Exponential Tends to Zero and Infinity]] }} {{end-eqn}} We similarly have: {{begin-eqn}} {{eqn | l = \size {\lim_{x \mathop \to \infty} e^{-\paren {i a + \paren {2 n + 1} b} x} } | r = \lim_{x \mathop \to \infty} \size {e^{-\paren {i a + \paren {2 n + 1} b} x} } | c = [[Modulus of Limit]] }} {{eqn | r = \lim_{x \mathop \to \infty} \size {e^{-i a x} } \size {e^{-\paren {2 n + 1} b x} } | c = [[Exponential of Sum]] }} {{eqn | r = \lim_{x \mathop \to \infty} e^{-\paren {2 n + 1} b x} }} {{eqn | r = 0 | c = [[Exponential Tends to Zero and Infinity]] }} {{end-eqn}} So: {{begin-eqn}} {{eqn | l = \sum_{n \mathop = 0}^\infty \paren {-1}^n \paren {\intlimits {-\frac {e^{\paren {i a - \paren {2 n + 1} b} x} } {\paren {2 n + 1} b - i a} } 0 \infty + \intlimits {-\frac {e^{-\paren {i a + \paren {2 n + 1} b} x} } {\paren {2 n + 1} + i a} } 0 \infty} | r = \sum_{n \mathop = 0}^\infty \paren {-1}^n \paren {\frac 1 {\paren {2 n + 1} b - i a} + \frac 1 {\paren {2 n + 1} b + i a} } | c = [[Exponential of Zero]] }} {{eqn | r = \sum_{n \mathop = 0}^\infty \paren {-1}^n \paren {\frac {2 \paren {2 n + 1} b} {\paren {2 n + 1}^2 b^2 + a^2} } | c = [[Difference of Two Squares]] }} {{eqn | r = \frac 2 b \sum_{n \mathop = 0}^\infty \paren {-1}^n \frac {2 n + 1} {\paren {2 n + 1} + 4 \paren {\frac a {2 b} }^2} }} {{end-eqn}} By [[Mittag-Leffler Expansion for Hyperbolic Secant Function]]: :$\displaystyle \pi \map \sech {\pi z} = 4 \sum_{n \mathop = 0}^\infty \paren {-1}^n \frac {2 n + 1} {\paren {2 n + 1} + 4 z^2}$ Setting $z = \dfrac a {2 b}$ gives: :$\displaystyle \pi \map \sech {\frac {a \pi} {2 b} } = 4 \sum_{n \mathop = 0}^\infty \paren {-1}^n \frac {2 n + 1} {\paren {2 n + 1} + 4 \paren {\frac a {2 b} }^2}$ We therefore have: {{begin-eqn}} {{eqn | l = \int_0^\infty \frac {\cos a x} {\cosh b x} \rd x | r = \frac 2 b \sum_{n \mathop = 0}^\infty \paren {-1}^n \frac {2 n + 1} {\paren {2 n + 1} + 4 \paren {\frac a {2 b} }^2} }} {{eqn | r = \frac {\pi} {2 b} \sech \frac {a \pi} {2 b} }} {{end-eqn}} {{qed}}	0
=== $(2)$ implies $(1)$ === By [[Generalized Sum is Linear]], the stated convergences lead to: {{begin-eqn}} {{eqn | l = z | r = \operatorname{Re} z + i \operatorname{Im} z | c = Definition of [[Definition:Real Part|Real]] and [[Definition:Imaginary Part|Imaginary Parts]] }} {{eqn | r = \sum \left\{ {\operatorname{Re} z_i : i \in I}\right\} + i \sum \left\{ {\operatorname{Im} z_i : i \in I}\right\} | c = Statement $(2)$ }} {{eqn | r = \sum \left\{ {\operatorname{Re} z_j + i \operatorname{Im} z_j: j \in I}\right\} | c = [[Generalized Sum is Linear]] }} {{eqn | r = \sum \left\{ {z_i : i \in I}\right\} | c = Definition of [[Definition:Real Part|Real]] and [[Definition:Imaginary Part|Imaginary Parts]] }} {{end-eqn}} {{qed|lemma}} === $(1)$ implies $(2)$ === Statement $(1)$, according to the definition of [[Definition:Generalized Sum|convergence]], amounts to the following: For every $\epsilon > 0$, there exists a [[Definition:Finite|finite]] $G \subseteq I$ such that: :For every [[Definition:Finite|finite]] $F \subseteq I$ with $G \subseteq F$: ::$\displaystyle \left\vert{z - \sum_{i \mathop \in F} z_i}\right\vert < \epsilon$ Now suppose that for $\epsilon > 0$, $G$ and $F$ are as above. Then observe that: {{begin-eqn}} {{eqn | l = \epsilon^2 | o = > | r = \left\vert{z - \sum_{i \mathop \in F} z_i}\right\vert^2 }} {{eqn | r = \left({\operatorname{Re} z - \sum_{i \mathop \in F} \operatorname{Re} z_i}\right)^2 + \left({\operatorname{Im} z - \sum_{i \mathop \in F} \operatorname{Im} z_i}\right)^2 | c = Definition of [[Definition:Modulus of Complex Number|Modulus]] }} {{end-eqn}} Hence, by [[Square of Real Number is Non-Negative]], both of the terms on the right hand side are smaller than $\epsilon^2$. It follows that, taking [[Definition:Square Root|square roots]], $G$ satisfies, for any [[Definition:Finite|finite]] $F \supseteq G$: :$\displaystyle \left\vert{\operatorname{Re} z - \sum_{i \mathop \in F} \operatorname{Re} z_i}\right\vert < \epsilon$ :$\displaystyle \left\vert{\operatorname{Im} z - \sum_{i \mathop \in F} \operatorname{Im} z_i}\right\vert < \epsilon$ As $\epsilon > 0$ was arbitrary, using the definition of [[Definition:Generalized Sum|convergence]], this implies precisely that: :$\displaystyle \sum \left\{{\operatorname{Re} z_i : i \in I}\right\}, \sum \left\{{\operatorname{Im} z_i : i \in I}\right\}$ [[Definition:Generalized Sum|converge]] to $\operatorname{Re} z, \operatorname{Im} z \in \R$, respectively. Hence, $(1)$ is shown to imply $(2)$. {{qed}}	0
{{ProofWanted}} {{Namedfor|Magnus Gustaf Mittag-Leffler|cat = Mittag-Leffler}}	0
It is given by [[Division Theorem/Positive Divisor/Existence|Division Theorem: Positive Divisor: Existence]] that such $q$ and $r$ exist. Suppose that: :$a = b q_1 + r_1 = b q_2 + r_2$ where both $0 \le r_1 < b$ and $0 \le r_2 < b$. {{WLOG}}, suppose $r_1 \ge r_2$. Then: :$r_1 - r_2 = b \paren {q_2 - q_1}$ That is: :$b \divides \paren {r_2 - r_1}$ where $\divides$ denotes [[Definition:Divisor of Integer|divisibility]]. But: :$r_1 - r_2 < b$ while from [[Absolute Value of Integer is not less than Divisors/Corollary|Absolute Value of Integer is not less than Divisors: Corollary]]: :$r_1 - r_2 \ge b$ unless from [[Integer Divides Zero]] $r_1 - r_2 = 0$. So $r_1 = r_2$ and it follows directly that $q_1 = q_2$. {{qed}}	0
Let $\zeta$ be the [[Definition:Riemann Zeta Function|Riemann zeta function]]. Let $s\in\C$ be a [[Definition:Complex Number|complex number]] with [[Definition:Real Part|real part]] $\sigma>1$. Then :$\displaystyle \zeta \left({s}\right) = \frac s {s - 1} - s \int_1^\infty \left\{ {x}\right\} x^{-s - 1} \rd x$ where $\left\{{x}\right\}$ denotes the [[Definition:Fractional Part|fractional part]] of $x$.	0
It is apparent by inspection that: :$(1): \quad g$ is an [[Definition:Extension of Mapping|extension]] of $f$ :$(2): \quad g$ is an [[Definition:Even Function|even function]]. Let $\map T x$ be the [[Definition:Fourier Series|Fourier series]] representing $g$: :$\map g x \sim \map T x = \dfrac {a_0} 2 + \displaystyle \sum_{n \mathop = 1}^\infty \paren {a_n \cos \frac {n \pi x} \lambda + b_n \sin \frac {n \pi x} \lambda}$ where for all $n \in \Z_{> 0}$: :$a_n = \displaystyle \frac 1 \lambda \int_{-\lambda}^\lambda \map g x \cos \frac {n \pi x} \lambda \rd x$ :$b_n = \displaystyle \frac 1 \lambda \int_{-\lambda}^\lambda \map g x \sin \frac {n \pi x} \lambda \rd x$ From [[Fourier Sine Coefficients for Even Function over Symmetric Range]]: :$\forall n \in \Z_{> 0}: b_n = 0$ and from [[Fourier Cosine Coefficients for Even Function over Symmetric Range]]: :$\forall n \in \Z_{>0}: a_n = \displaystyle \frac 2 \lambda \int_0^\lambda \map g x \cos \frac {n \pi x} \lambda \rd x$ But on $\openint 0 \lambda$, by definition: :$\forall x \in \openint 0 \lambda: \map g x = \map f x$ Hence: :$\map T x = \dfrac {a_0} 2 + \displaystyle \sum_{n \mathop = 1}^\infty \paren a_n \cos \frac {n \pi x} \lambda$ where: :$a_n = \displaystyle \frac 2 \lambda \int_0^\lambda \map f x \cos \frac {n \pi x} \lambda \rd x$ That is, $\map T x$ is the same as $\map S x$. Hence the result. {{qed}} [[Category:Half-Range Fourier Series]] 4jkesnhoecrlce0p4zm4l919iuqymah	0
Let $z$ be a [[Definition:Complex Number|complex number]] with a [[Definition:Positive Real Number|positive]] [[Definition:Real Part|real part]]. Then: :$\displaystyle \Ln \map \Gamma z = \paren {z - \frac 1 2} \Ln z - z + \frac 1 2 \ln 2 \pi + 2 \int_0^\infty \frac {\map \arctan {t / z} } {e^{2 \pi t} - 1} \rd t$ where: :$\Gamma$ is the [[Definition:Gamma Function|Gamma function]] :$\Ln$ is the [[Definition:Principal Branch of Complex Natural Logarithm|principal branch]] of the [[Definition:Complex Natural Logarithm|complex logarithm]].	0
{{begin-eqn}} {{eqn | l = x | o = < | r = y }} {{eqn | ll= \leadstoandfrom | l = y - x | o = > | r = 0 | c = [[Inequality iff Difference is Positive]] }} {{eqn | ll= \leadstoandfrom | lr = -x + y | o = > | r = 0 | c = [[Definition:Real Number Axioms|Real Number Axioms: $\R \text A 2 $: Commutativity of Addition]] }} {{eqn | ll= \leadstoandfrom | l = -x + -\paren {-y} | o = > | r = 0 | c = [[Negative of Negative Real Number]] }} {{eqn | ll= \leadstoandfrom | l = -x - \paren {-y} | o = > | r = 0 | c = {{Defof|Real Subtraction}} }} {{eqn | ll= \leadstoandfrom | l = -y | o = < | r = -x | c = [[Inequality iff Difference is Positive]] }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \csch^{-1} \frac x a | r = \map \ln {\frac {1 + \sqrt {1 + \paren {\frac x a}^2} } {\frac x a} } | c = {{Defof|Inverse Hyperbolic Cosecant|subdef = Real|index = 2}} }} {{eqn | r = \map \ln {\frac {a \paren {1 + \sqrt {\dfrac {a^2 + x^2} {a^2} } } } x} | c = }} {{eqn | r = \map \ln {\frac {a \paren {\dfrac {a + \sqrt {a^2 + x^2} } a} } x} | c = }} {{eqn | r = \map \ln {\frac {a + \sqrt {a^2 + x^2} } x} | c = }} {{end-eqn}} {{qed}} {{expand|Work out what happens when $x$ is real such that $x < 0$}}	0
Let $n \Z$ be the [[Definition:Set of Integer Multiples|set of integer multiples]] of $n$. Then the [[Definition:Algebraic Structure|algebraic structure]] $\struct {n \Z, \times}$ is [[Definition:Closed Algebraic Structure|closed]] under [[Definition:Integer Multiplication|multiplication]].	0
The number $666$ has the following interesting property: :$\map \phi {666} = 6 \times 6 \times 6$ where $\phi$ denotes the [[Definition:Euler Phi Function|Euler $\phi$ function]].	0
Let $\size x > a$. Then: {{begin-eqn}} {{eqn | l = \int \frac {\d x} {a^2 - x^2} | r = \frac 1 a \coth^{-1} {\frac x a} + C | c = [[Primitive of Reciprocal of a squared minus x squared/Inverse Hyperbolic Cotangent Form|Primitive of $\dfrac 1 {a^2 - x^2}$: $\coth^{-1}$ form]] }} {{eqn | r = \frac 1 a \paren {\dfrac 1 2 \map \ln {\dfrac {x + a} {x - a} } } + C | c = [[Inverse Hyperbolic Cotangent of x over a in Logarithm Form|$\coth^{-1} \dfrac x a$ in Logarithm Form]] }} {{eqn | r = \dfrac 1 {2 a} \map \ln {\frac {x + a} {x - a} } + C | c = simplifying }} {{end-eqn}} {{qed}}	0
Let $R^* = R \setminus \set 0$. Let $\tau^*$ be the [[Definition:Subspace Topology|subspace topology]] on $R^*$. By definition of a [[Definition:Topological Division Ring|topological division ring]]: :$\phi: \struct {R^*, \tau^*} \to \struct {R, \tau_{_R} }$ such that $\forall x \in R^*: \map \phi x = x^{-1}$ is a [[Definition:Everywhere Continuous Mapping (Topology)|continuous mapping]] Let $g^*: \struct {U, \tau_{_U} } \to \struct {R^*, \tau^*}$ be the [[Definition: Restriction of Mapping|restriction]] of $g$ to $U \subseteq R$. From [[Restriction of Continuous Mapping is Continuous]], $g^*$ is a [[Definition:Everywhere Continuous Mapping (Topology)|continuous mapping]]. From [[Composite of Continuous Mappings is Continuous]], the [[Definition:Composition of Mappings|composition]] $\phi \circ g^* : \struct {U, \tau_{_U} } \to \struct {R, \tau_{_R} }$ is [[Definition:Everywhere Continuous Mapping (Topology)|continuous]]. Now: {{begin-eqn}} {{eqn | lo= \forall x \in U : | l = \map {\paren {g^{-1} } } x | r = \map g x^{-1} | c = Definition of $g^{-1}$ }} {{eqn | r = \map \phi {\map g x} | c = Definition of $\phi$ }} {{eqn | r = \map \phi {\map {g^*} x} | c = Since $\map g x \neq 0$ }} {{eqn | r = \map {\paren {\phi \circ g^*} } x | c = {{Defof|Composition of Mappings}} }} {{end-eqn}} From [[Equality of Mappings]]: :$g^{-1} = \phi \circ g^*$ The result follows. {{qed}} [[Category:Combination Theorem for Continuous Mappings to Topological Division Ring]] 0ausrn4zvo920c3rfoac6m9adr6f0sg	0
:$\displaystyle \int \frac {x^2 \rd x} {\paren {a^2 - x^2}^2} = \frac x {2 \paren {a^2 - x^2} } - \frac 1 {4 a} \map \ln {\frac {a + x} {a - x} } + C$ for $x^2 < a^2$.	0
Let $\lambda \in \R \setminus \Z$ be a [[Definition:Real Number|real number]] which is not an [[Definition:Integer|integer]]. :[[File:Sneddon-1-Exercise-5.png|500px|thumb|right|$\map f x$ for $\lambda = 4 \cdotp 6$ and its $5$th approximation]] Let $\map f x$ be the [[Definition:Real Function|real function]] defined on $\openint 0 \pi$ as: :$\map f x = \cos \lambda x$ Then its [[Definition:Half-Range Fourier Cosine Series|half-range Fourier cosine series]] can be expressed as: {{begin-eqn}} {{eqn | l = \map f x | o = \sim | r = \frac {2 \lambda \sin \lambda \pi} \pi \paren {\frac 1 {2 \lambda^2} + \sum_{n \mathop = 1}^\infty \paren {-1}^n \frac {\cos n x} {\lambda^2 - n^2} } | c = }} {{eqn | r = \frac {2 \lambda \sin \lambda \pi} \pi \paren {\frac 1 {2 \lambda^2} - \frac {\cos x} {\lambda^2 - 1} + \frac {\cos 2 x} {\lambda^2 - 4} - \frac {\cos 3 x} {\lambda^2 - 9} + \frac {\cos 4 x} {\lambda^2 - 16} - \dotsb} | c = }} {{end-eqn}}	0
The proof proceeds by [[Principle of Mathematical Induction|induction]]. For all $n \in \Z_{\ge 0}$, let $P \left({n}\right)$ be the [[Definition:Proposition|proposition]]: :$\displaystyle \left({e^z - 1}\right)^n = n! \sum_{k \mathop \in \Z} \left\{ {k \atop n}\right\} \frac {z^k} {k!}$ $P \left({0}\right)$ is the case: {{begin-eqn}} {{eqn | l = 0! \sum_{k \mathop \in \Z} \left\{ {k \atop 0}\right\} \frac {z^k} {k!} | r = \sum_{k \mathop \in \Z} \left\{ {k \atop 0}\right\} \frac {z^k} {k!} | c = {{Defof|Factorial}}: $0! = 1$ }} {{eqn | r = \sum_{k \mathop \in \Z} \delta_{k 0} \frac {z^k} {k!} | c = {{Defof|Stirling Numbers of the Second Kind|index = 1}} }} {{eqn | r = \sum_{k \mathop = 0} \frac {z^k} {k!} | c = }} {{eqn | r = \frac {z^0} {0!} | c = }} {{eqn | r = 1 | c = }} {{eqn | r = \left({e^z - 1}\right)^0 | c = }} {{end-eqn}} Thus $P \left({0}\right)$ is seen to hold. === Basis for the Induction === $P \left({1}\right)$ is the case: {{begin-eqn}} {{eqn | l = 1! \sum_{k \mathop \in \Z} \left\{ {k \atop 1}\right\} \frac {z^k} {k!} | r = \sum_{k \mathop \in \Z} \left\{ {k \atop 1}\right\} \frac {z^k} {k!} | c = {{Defof|Factorial}}: $1! = 1$ }} {{eqn | r = \sum_{k \mathop \ge 1} \frac {z^k} {k!} | c = [[Stirling Number of the Second Kind of n+1 with 1]] }} {{eqn | r = \sum_{k \mathop \ge 0} \frac {z^k} {k!} - 1 | c = }} {{eqn | r = e^z - 1 | c = [[Power Series Expansion for Exponential Function]] }} {{eqn | r = \left({e^z - 1}\right)^1 | c = }} {{end-eqn}} Thus $P \left({1}\right)$ is seen to hold. This is the [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that, if $P \left({r}\right)$ is true, where $r \ge 1$, then it logically follows that $P \left({r + 1}\right)$ is true. So this is the [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$\displaystyle \left({e^z - 1}\right)^r = r! \sum_{k \mathop \in \Z} \left\{ {k \atop r}\right\} \frac {z^k} {k!}$ from which it is to be shown that: :$\displaystyle \left({e^z - 1}\right)^{r + 1} = \left({r + 1}\right)! \sum_{k \mathop \in \Z} \left\{ {k \atop {r + 1} }\right\} \frac {z^k} {k!}$ === Induction Step === This is the [[Principle of Mathematical Induction#Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \left({e^z - 1}\right)^{r + 1} | r = \left({e^z - 1}\right)^r \left({e^z - 1}\right) | c = }} {{eqn | r = \left({r! \sum_{k \mathop \in \Z} \left\{ {k \atop r}\right\} \frac {z^k} {k!} }\right) \left({e^z - 1}\right) | c = [[Power Series Expansion for Integer Power of Exponential Function minus 1/Proof#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \left({r! \sum_{k \mathop \in \Z} \left\{ {k \atop r}\right\} \frac {z^k} {k!} }\right) \left({\sum_{k \mathop \ge 0} \frac {z^k} {k!} - 1}\right) | c = [[Power Series Expansion for Exponential Function]] }} {{eqn | r = \left({r! \sum_{k \mathop \ge 0} \left\{ {k \atop r}\right\} \frac {z^k} {k!} }\right) \left({\sum_{k \mathop \ge 0} \frac {z^k} {k!} - 1}\right) | c = $\displaystyle \left\{ {k \atop r}\right\} = 0$ for $k < 0$ }} {{eqn | r = r! \sum_{k \mathop \ge 0} \binom r k \left\{ {k \atop r}\right\} \frac {z^k} {k!} - r! \sum_{k \mathop \ge 0} \left\{ {k \atop r}\right\} \frac {z^k} {k!} | c = [[Product of Exponential Generating Functions]] }} {{eqn | r = r! \sum_{k \mathop \ge 0} \left\{ { {k + 1} \atop {r + 1} }\right\} \frac {z^k} {k!} - r! \sum_{k \mathop \ge 0} \left\{ {k \atop r}\right\} \frac {z^k} {k!} | c = [[Sum over k of Stirling Numbers of the Second Kind of k with m by n choose k]] }} {{eqn | r = r! \sum_{k \mathop \ge 0} \left({\left({r + 1}\right) \left\{ {k \atop {r + 1} }\right\} + \left\{ {k \atop r}\right\} - \left\{ {k \atop r}\right\} }\right) \frac {z^k} {k!} | c = {{Defof|Stirling Numbers of the Second Kind|index = 1}} }} {{eqn | r = \left({r + 1}\right)! \sum_{k \mathop \ge 0} \left\{ {k \atop {r + 1} }\right\} \frac {z^k} {k!} | c = }} {{eqn | r = \left({r + 1}\right)! \sum_{k \mathop \in \Z} \left\{ {k \atop {r + 1} }\right\} \frac {z^k} {k!} | c = $\displaystyle \left\{ {k \atop r}\right\} = 0$ for $k < 0$ }} {{end-eqn}} So $P \left({r}\right) \implies P \left({r + 1}\right)$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\forall n \in \Z_{\ge 0}: \displaystyle \left({e^z - 1}\right)^n = n! \sum_{k \mathop \in \Z} \left\{ {k \atop n}\right\} \frac {z^k} {k!}$ {{qed}}	0
By definition of a [[Definition:Convergent Real Sequence|convergent real sequence]]: :$\displaystyle \lim_{n \mathop \to \infty} \map d {x_n, l} = 0$ {{iff}} :$\forall \epsilon \in \R_{>0}: \exists N \in \R_{>0}: n > N \implies \size {\map d {x_n, l} - 0} < \epsilon$ From [[Distance in Pseudometric is Non-Negative]]: :$\forall x, y \in A: \map d {x, y} \ge 0$ Hence: :$\forall n \in \N: \map d {x_n, l} = \size {\map d {x_n, l}} = \size {\map d {x_n, l} - 0}$ The result follows.	0
With a view to expressing the [[Definition:Primitive|primitive]] in the form: :$\displaystyle \int u \frac {\mathrm d v}{\mathrm d x} \ \mathrm d x = u v - \int v \frac {\mathrm d u}{\mathrm d x} \ \mathrm d x$ let: {{begin-eqn}} {{eqn | l = u | r = \operatorname{arcsec} \frac x a | c = }} {{eqn | ll= \implies | l = \frac {\mathrm d u} {\mathrm d x} | r = \begin{cases} \dfrac a {x \sqrt {x^2 - a^2} } & : 0 < \operatorname{arcsec} \dfrac x a < \dfrac \pi 2 \\ \dfrac {-a} {x \sqrt {x^2 - a^2} } & : \dfrac \pi 2 < \operatorname{arcsec} \dfrac x a < \pi \\ \end{cases} | c = [[Derivative of Arcsecant of x over a|Derivative of $\operatorname{arcsec} \dfrac x a$]] }} {{end-eqn}} and let: {{begin-eqn}} {{eqn | l = \frac {\mathrm d v} {\mathrm d x} | r = x^2 | c = }} {{eqn | ll= \implies | l = v | r = \frac {x^3} 3 | c = [[Primitive of Power]] }} {{end-eqn}} First let $\operatorname{arcsec} \dfrac x a$ be in the [[Definition:Open Real Interval|interval]] $\left({0 \,.\,.\,\dfrac \pi 2}\right)$. Then: {{begin-eqn}} {{eqn | l = \int x^2 \operatorname{arcsec} \frac x a \ \mathrm d x | r = \frac {x^3} 3 \operatorname{arcsec} \frac x a - \int \frac {x^3} 3 \left({\frac a {x \sqrt {x^2 - a^2} } }\right) \ \mathrm d x + C | c = [[Integration by Parts]] }} {{eqn | r = \frac {x^3} 3 \operatorname{arcsec} \frac x a - \frac a 3 \int \frac {x^2 \ \mathrm d x} {\sqrt {x^2 - a^2} } + C | c = [[Primitive of Constant Multiple of Function]] }} {{eqn | r = \frac {x^3} 3 \operatorname{arcsec} \frac x a - \frac a 3 \left({\frac {x \sqrt {x^2 - a^2} } 2 + \frac {a^2} 2 \ln \left({x + \sqrt {x^2 - a^2} }\right)}\right) + C | c = [[Primitive of x squared over Root of x squared minus a squared|Primitive of $\dfrac {x^2} {\sqrt {x^2 - a^2} }$]] }} {{eqn | r = \frac {x^3} 3 \operatorname{arcsec} \frac x a - \frac {a x \sqrt{x^2 - a^2} } 6 - \frac {a^3} 6 \ln \left({x + \sqrt {x^2 - a^2} }\right) + C | c = simplifying }} {{end-eqn}} Similarly, let $\operatorname{arcsec} \dfrac x a$ be in the [[Definition:Open Real Interval|interval]] $\left({\dfrac \pi 2 \,.\,.\, \pi}\right)$. Then: {{begin-eqn}} {{eqn | l = \int x^2 \operatorname{arcsec} \frac x a \ \mathrm d x | r = \frac {x^3} 3 \operatorname{arcsec} \frac x a - \int \frac {x^3} 3 \left({\frac {-a} {x \sqrt {x^2 - a^2} } }\right) \ \mathrm d x + C | c = [[Integration by Parts]] }} {{eqn | r = \frac {x^3} 3 \operatorname{arcsec} \frac x a + \frac a 3 \int \frac {x^2 \ \mathrm d x} {\sqrt {x^2 - a^2} } + C | c = [[Primitive of Constant Multiple of Function]] }} {{eqn | r = \frac {x^3} 3 \operatorname{arcsec} \frac x a + \frac a 3 \left({\frac {x \sqrt {x^2 - a^2} } 2 + \frac {a^2} 2 \ln \left({x + \sqrt {x^2 - a^2} }\right)}\right) + C | c = [[Primitive of x squared over Root of x squared minus a squared|Primitive of $\dfrac {x^2} {\sqrt {x^2 - a^2} }$]] }} {{eqn | r = \frac {x^3} 3 \operatorname{arcsec} \frac x a + \frac {a x \sqrt{x^2 - a^2} } 6 + \frac {a^3} 6 \ln \left({x + \sqrt {x^2 - a^2} }\right) + C | c = simplifying }} {{end-eqn}} {{qed}}	0
Let $\xi, \delta \in \R$ be [[Definition:Real Number|real numbers]]. Let $\delta > 0$. Then:	0
:$\displaystyle \int \frac {\d x} {a x + b} = \frac 1 a \ln \size {a x + b} + C$	0
With a view to expressing the [[Definition:Primitive|primitive]] in the form: :$\displaystyle \int u \frac {\mathrm d v}{\mathrm d x} \ \mathrm d x = u v - \int v \frac {\mathrm d u}{\mathrm d x} \ \mathrm d x$ let: {{begin-eqn}} {{eqn | l = u | r = \arctan \frac x a | c = }} {{eqn | ll= \implies | l = \frac {\mathrm d u} {\mathrm d x} | r = \frac a {x^2 + a^2} | c = [[Derivative of Arctangent of x over a|Derivative of $\arctan \dfrac x a$]] }} {{end-eqn}} and let: {{begin-eqn}} {{eqn | l = \frac {\mathrm d v} {\mathrm d x} | r = \frac 1 {x^2} | c = }} {{eqn | ll= \implies | l = v | r = \frac {-1} x | c = [[Primitive of Power]] }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = \int \frac {\arctan \frac x a \ \mathrm d x} {x^2} | r = \arctan \frac x a \left({\frac {-1} x}\right) - \int \left({\frac {-1} x}\right) \left({\frac a {x^2 + a^2} }\right) \ \mathrm d x + C | c = [[Integration by Parts]] }} {{eqn | r = \frac {-\arctan \frac x a} x + a \int \frac {\mathrm d x} {x \left({x^2 + a^2}\right)} \ \mathrm d x + C | c = simplifying }} {{eqn | r = \frac {-\arctan \frac x a} x + \frac 1 a \left({\frac 1 {2 a^2} \ln \left({\frac {x^2} {x^2 + a^2} }\right)}\right) + C | c = [[Primitive of Reciprocal of x by x squared plus a squared|Primitive of $\dfrac 1 {x \left({x^2 + a^2}\right)}$]] }} {{eqn | r = \frac {-\arctan \frac x a} x - \frac 1 {2 a} \ln \left({\frac {x^2 + a^2} {x^2} }\right) + C | c = [[Logarithm of Reciprocal]] }} {{end-eqn}} {{qed}}	0
Let $f: \R \to \R$ be a [[Definition:Real Function|real function]]. Then: :$(1): \quad \displaystyle \lim_{x \mathop \to +\infty} \map f x = -\infty \implies \lim_{x \mathop \to +\infty} -\map f x = +\infty$ :$(2): \quad \displaystyle \lim_{x \mathop \to -\infty} \map f x = -\infty \implies \lim_{x \mathop \to -\infty} -\map f x = +\infty$	0
{{begin-eqn}} {{eqn | l = \int_0^x \frac {\d t} {\sqrt{1 - t^2} } | r = \intlimits {\arcsin \frac t 1} 0 x | c = [[Primitive of Reciprocal of Root of a squared minus x squared/Arcsine Form|Primitive of $\dfrac 1 {\sqrt {a^2 - x^2} }$]], {{Defof|Definite Integral}} }} {{eqn | r = \arcsin x - \arcsin 0 | c = }} {{eqn | r = \arcsin x }} {{end-eqn}} {{qed}}	0
A [[Definition:Strictly Positive Integer|(strictly) positive integer]] $p$ is a [[Definition:Prime Number|prime]] {{iff}}: :$\paren {p - 1}! \equiv -1 \pmod p$	0
Define: :$\displaystyle \BB = \left\{{\bigcap \AA: \AA \subseteq \SS, \AA \text{ is finite}}\right\} \subseteq \powerset {X_2}$ Let $B \in \BB$. Then [[Definition:Existential Quantifier|there exists]] a [[Definition:Finite Set|finite]] [[Definition:Subset|subset]] $\AA \subseteq \SS$ such that: :$\displaystyle B = \bigcap \AA$ Hence: {{begin-eqn}} {{eqn | l = f^{-1} \sqbrk B | r = f^{-1} \sqbrk {\bigcap \AA} }} {{eqn | r = \bigcap_{S \mathop \in \AA} f^{-1} \sqbrk S | c = [[Preimage of Intersection under Mapping/General Result|Preimage of Intersection under Mapping: General Result]] }} {{eqn | o = \in | r = \tau_1 | c = [[General Intersection Property of Topological Space]] }} {{end-eqn}} Define: :$\displaystyle \tau = \set {\bigcup \AA: \AA \subseteq \BB} \subseteq \powerset {X_2}$ By the definition of an [[Definition:Analytic Sub-Basis|analytic sub-basis]], we have $\tau_2 \subseteq \tau$. Let $U \in \tau_2$. Then $U \in \tau$; therefore: :$\displaystyle \exists \AA \subseteq \BB: U = \bigcup \AA$ Hence: {{begin-eqn}} {{eqn | l = f^{-1} \sqbrk U | r = f^{-1} \sqbrk {\bigcup \AA} }} {{eqn | r = \bigcup_{S \mathop \in \AA} f^{-1} \sqbrk S | c = [[Preimage of Union under Mapping/General Result|Preimage of Union under Mapping: General Result]] }} {{eqn | o = \in | r = \tau_1 | c = because $\forall B \in \BB: f^{-1} \sqbrk B \in \tau_1$, and by [[Definition:Open Set Axioms|open set axiom]] $({1})$ applied to $\tau_1$ }} {{end-eqn}} That is, $f$ is [[Definition:Everywhere Continuous Mapping (Topology)|continuous]]. {{qed}}	0
Suppose $\sqrt 2$ could be expressed as the [[Definition:Root of Polynomial|root]] of the [[Definition:Linear Polynomial|linear polynomial]]: :$a_1 x + a_0 = 0$ for some $a_0, a_1 \in \Q$. Then: :$\sqrt 2 = -\dfrac {a_0} {a_1}$ and would be [[Definition:Rational Number|rational]]. But as [[Square Root of 2 is Irrational]], this is not the case. However, $\sqrt 2$ is a [[Definition:Root of Polynomial|root]] of the [[Definition:Polynomial (Analysis)|polynomial]] of [[Definition:Degree of Polynomial|degree]] $2$: :$x^2 - 2 = 0$ Hence the result by definition of [[Definition:Degree of Algebraic Number|degree of algebraic number]]. {{qed}}	0
From [[Logarithm is Strictly Concave]]: :$\ln$ is [[Definition:Strictly Concave Real Function|(strictly) concave]]. From [[Mean Value of Concave Real Function]]: :$\ln y - \ln 1 \le \left({D \ln 1}\right) \left({y - 1}\right)$ From [[Derivative of Natural Logarithm]]: :$D \ln 1 = \dfrac 1 1 = 1$ So: :$\ln y - \ln 1 \le \left({y - 1}\right)$ But from [[Logarithm of 1 is 0]]: :$\ln 1 = 0$ Hence the result. {{qed}}	0
:$\forall x \in \R, y \in \R_{\ne 0}: \dfrac {-x} y = -\dfrac x y = \dfrac x {-y}$	0
{{begin-eqn}} {{eqn | l = \cos \theta | r = 2 \cos^2 \frac \theta 2 - 1 | c = [[Double Angle Formulas/Cosine/Corollary 1|Double Angle Formula for Cosine: Corollary 1]] }} {{eqn | ll= \leadsto | l = 2 \cos^2 \frac \theta 2 | r = 1 + \cos \theta }} {{eqn | ll= \leadsto | l = \cos \frac \theta 2 | r = \pm \sqrt {\frac {1 + \cos \theta} 2} }} {{end-eqn}} We also have that: :In [[Definition:Cosine/Definition from Circle/First Quadrant|quadrant $\text I$]], and [[Definition:Cosine/Definition from Circle/Fourth Quadrant|quadrant $\text {IV}$]], $\cos \dfrac \theta 2 > 0$ :In [[Definition:Cosine/Definition from Circle/Second Quadrant|quadrant $\text {II}$]] and [[Definition:Cosine/Definition from Circle/Third Quadrant|quadrant $\text {III}$]], $\cos \dfrac \theta 2 < 0$. {{qed}}	0
The [[Definition:Sine|sine]] function is: :$(1): \quad$ [[Definition:Strictly Increasing Real Function|strictly increasing]] on the [[Definition:Closed Real Interval|interval]] $\closedint {-\dfrac \pi 2} {\dfrac \pi 2}$ :$(2): \quad$ [[Definition:Strictly Decreasing Real Function|strictly decreasing]] on the [[Definition:Closed Real Interval|interval]] $\closedint {\dfrac \pi 2} {\dfrac {3 \pi} 2}$ :$(3): \quad$ [[Definition:Concave Real Function|concave]] on the [[Definition:Closed Real Interval|interval]] $\closedint 0 \pi$ :$(4): \quad$ [[Definition:Convex Real Function|convex]] on the [[Definition:Closed Real Interval|interval]] $\closedint \pi {2 \pi}$	0
Let $f$ and $g$ be [[Definition:Multiplicative Arithmetic Function|multiplicative]]. Let $m \perp n$. Then: {{begin-eqn}} {{eqn | l = \map {f \times g} {m \times n} | r = \map f {m \times n} \times \map g {m \times n} | c = {{Defof|Pointwise Multiplication of Integer-Valued Functions}} }} {{eqn | r = \map f m \times \map f n \times \map g m \times \map g n | c = {{Defof|Multiplicative Arithmetic Function}} }} {{eqn | r = \map f m \times \map g m \times \map f n \times \map g n | c = [[Integer Multiplication is Commutative]] }} {{eqn | r = \paren {\map {f \times g} n} \times \paren {\map {f \times g} n} | c = {{Defof|Pointwise Multiplication of Integer-Valued Functions}} }} {{end-eqn}} Hence the result by definition of [[Definition:Multiplicative Arithmetic Function|multiplicative function]]. {{qed}}	0
With a view to expressing the problem in the form: :$\displaystyle \int u \frac {\d v} {\d x} \rd x = u v - \int v \frac {\d u} {\d x} \rd x$ let: {{begin-eqn}} {{eqn | l = u | r = x^2 | c = }} {{eqn | ll= \leadsto | l = \frac {\d u} {\d x} | r = 2 x | c = [[Power Rule for Derivatives]] }} {{end-eqn}} and let: {{begin-eqn}} {{eqn | l = \frac {\d v} {\d x} | r = \frac x {\sqrt {x^2 - a^2} } | c = }} {{eqn | ll= \leadsto | l = v | r = \sqrt {x^2 - a^2} | c = [[Primitive of x over Root of x squared minus a squared|Primitive of $\dfrac x {\sqrt {x^2 - a^2} }$]] }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = \int \frac {x^3 \rd x} {\sqrt {x^2 - a^2} } | r = \int x^2 \frac {x \rd x} {\sqrt {x^2 - a^2} } | c = }} {{eqn | r = x^2 \sqrt {x^2 - a^2} - \int 2 x \sqrt {x^2 - a^2} \rd x | c = [[Integration by Parts]] }} {{eqn | r = x^2 \sqrt {x^2 - a^2} - 2 \paren {\frac {\paren {\sqrt {x^2 - a^2} }^3} 3} + C | c = [[Primitive of x by Root of x squared minus a squared|Primitive of $x \sqrt {x^2 - a^2}$]] }} {{eqn | r = \paren {x^2 - a^2 + a^2} \sqrt {x^2 - a^2} - 2 \paren {\frac {\paren {\sqrt {x^2 - a^2} }^3} 3} + C | c = }} {{eqn | r = \paren {\sqrt {x^2 - a^2} }^3 + a^2 \sqrt {x^2 - a^2} - 2 \paren {\frac {\paren {\sqrt {x^2 - a^2} }^3} 3} + C | c = }} {{eqn | r = \frac {\paren {\sqrt {x^2 - a^2} }^3} 3 + a^2 \sqrt {x^2 - a^2} + C | c = }} {{end-eqn}} {{qed}}	0
:[[File:Arcsech.png|300px]]	0
Let $\CC$ be an [[Definition:Open Cover|open cover]] for $\R$. Then $\CC$ covers each of the [[Definition:Closed Real Interval|closed real intervals]] $\closedint n {n + 1}$ for all $n \in \Z$. By the [[Heine-Borel Theorem]], each of $\closedint n {n + 1}$ is [[Definition:Compact Topological Space|compact]]. So, for each of these intervals $\closedint n {n + 1}$, it follows that $\CC$ can be reduced to a [[Definition:Sequence|sequence]] $\sequence {G_i^{\paren n} }$ of [[Definition:Finite Subcover|finite subcovers]]. Then each of $G_i^{\paren n} \cap \openint {n - 1} {n + 2}$ forms a [[Definition:Refinement of Cover|refinement]] of $\CC$ which is [[Definition:Locally Finite Cover|locally finite]]. Hence, by definition, $\R$ is [[Definition:Paracompact Space|paracompact]]. {{qed}}	0
Let $f: \R \to \R$ be a [[Definition:Completely Multiplicative Function|completely multiplicative function]]. Then: :$\forall x, y \in \R, y \ne 0: f \left({\dfrac x y}\right) = \dfrac {f \left({x}\right)} {f \left({y}\right)}$ whenever $f \left({y}\right) \ne 0$.	0
:$\sinh x + \sinh y = 2 \sinh \left({\dfrac {x + y} 2}\right) \cosh \left({\dfrac {x - y} 2}\right)$	0
:$\cot 165 \degrees = \cot \dfrac {11 \pi} {12} = -\paren {2 + \sqrt 3}$	0
=== Definition 1 iff Definition 2 === By definition, the [[Definition:Metric Induced by Norm on Division Ring|metric induced by the norm]] $\norm {\, \cdot \,}$ is the [[Definition:Mapping|mapping]] $d: R \times R \to \R_{\ge 0}$ defined as: :$\map d {x, y} = \norm {x - y}$ From [[Metric Induced by Norm on Normed Division Ring is Metric]], $d$ is a [[Definition:Metric|metric]]. By definition of a [[Definition:Convergent Sequence in Metric Space|convergent sequence]] in a [[Definition:Metric Space|metric space]], $\sequence{x_n}$ [[Definition:Convergent Sequence in Metric Space|converges]] to $x \in R$ {{iff}}: :$\forall \epsilon \in \R_{>0}: \exists N \in \R_{>0}: \forall n \in \N: n > N \implies \map d {x_n, x} < \epsilon$ {{iff}}: :$\forall \epsilon \in \R_{>0}: \exists N \in \R_{>0}: \forall n \in \N: n > N \implies \norm {x_n - x} < \epsilon$ The result follows. {{qed|lemma}} === Definition 1 iff Definition 3 === Let $x \in R$. By definition of [[Definition:Norm on Division Ring|norm on a division ring]], $\norm {\, \cdot \,}$ is a [[Definition:Mapping|mapping]] $\norm {\, \cdot \,}:R \to \R_{\ge 0}$. Then: :$\forall n \in \N: \size {\norm{x_n - x} - 0} = \size {\norm{x_n - x}} = \norm{x_n - x}$ By definition of [[Definition:Convergent Real Sequence|convergence]] of a [[Definition:Real Sequence|real sequence]], the [[Definition:Real Sequence|real sequence]] $\sequence {\norm {x_n - x} }$ [[Definition:Convergent Real Sequence|converges]] to $0$ in the [[Definition:Real Numbers|reals]] $\R$ {{iff}} :$\forall \epsilon \in \R_{>0}: \exists N \in \R_{>0}: n > N \implies \size {\norm{x_n - x} - 0} < \epsilon$ {{iff}}: :$\forall \epsilon \in \R_{>0}: \exists N \in \R_{>0}: n > N \implies \norm{x_n - x} < \epsilon$ The result follows. {{qed}}	0
Let $\ln$ be the [[Definition:Real Natural Logarithm|natural logarithm function on the real numbers]]. Then the [[Definition:Image of Mapping|image]] of $\ln$ is the set of [[Definition:Real Number|real numbers]]: :$\Img \ln = \R$	0
For example, $X + 2$ is a [[Definition:Polynomial over Ring in One Variable|polynomials over $\Z$ in $X$]] with an [[Definition:Even Integer|even]] [[Definition:Constant Term of Polynomial|constant term]]. So $S$ is not [[Definition:Empty Set|empty]]. Let $P_1 = \displaystyle \sum_{k \mathop = 0}^n a_k X^k$ and $P_2 = \displaystyle \sum_{k \mathop = 0}^n b_k X^k$ be [[Definition:Element|elements]] of $S$. We have: {{begin-eqn}} {{eqn | l = P_1 - P_2 | r = \sum_{k \mathop = 0}^n a_k X^k + \sum_{k \mathop = 0}^n b_k X^k | c = }} {{eqn | r = \sum_{k \mathop = 0}^{\max \set {m, n} } \paren {a_k - b_k} X^k | c = }} {{end-eqn}} The [[Definition:Constant Term of Polynomial|constant term]] of $P_1 - P_2$ is $a_0 - b_0$ which is [[Definition:Even Integer|even]]. Thus $P_1 - P_2 \in S$. Let $P_3 = \sum_{k \mathop = 0}^s c_k X^k \in \Z \sqbrk X$. Then the [[Definition:Constant Term of Polynomial|constant term]] of $P_3 \times P_1$ is $c_0 \times a_0$. As $a_0$ is [[Definition:Even Integer|even]], so is $c_0 \times a_0$. The result follows by [[Test for Ideal]]. {{qed}}	0
: $\left({\dfrac a b}\right)^{-x} = \left({\dfrac b a}\right)^x$	0
{{begin-eqn}} {{eqn | l = \int \frac {x^3 \rd x} {x^2 + a^2} | r = \int \paren {x - \frac {a^2 x} {x^2 + a^2} } \rd x | c = long division }} {{eqn | r = \int x \rd x - a^2 \int \frac {x \rd x} {x^2 + a^2} | c = [[Linear Combination of Integrals]] }} {{eqn | r = \frac {x^2} 2 - a^2 \int \frac {x \rd x} {x^2 + a^2} + C | c = [[Primitive of Power]] }} {{eqn | r = \frac {x^2} 2 - a^2 \paren {\frac 1 2 \map \ln {x^2 + a^2} } + C | c = [[Primitive of x over x squared plus a squared|Primitive of $\dfrac x {x^2 + a^2}$]] }} {{eqn | r = \frac {x^2} 2 - \frac {a^2} 2 \map \ln {x^2 + a^2} + C | c = simplifying }} {{end-eqn}} {{qed}}	0
Let $A \subseteq \R$ be the [[Definition:Set|set]] of all points on $\R$ defined as: :$A := \set 0 \cup \set {\dfrac 1 n : n \in \Z_{>0} }$ Let $\struct {A, \tau_d}$ be the [[Definition:Integer Reciprocal Space|integer reciprocal space]] with [[Definition:Zero (Number)|zero]] under the [[Definition:Euclidean Topology on Real Number Line|usual (Euclidean) topology]]. Then the [[Definition:Component (Topology)|components]] of $A$ are [[Definition:Singleton|singletons]].	0
Recall that [[Rational Numbers form Field]] under the [[Definition:Binary Operation|operations]] of [[Definition:Rational Addition|addition]] and [[Definition:Rational Multiplication|multiplication]]. By definition of a [[Definition:Field (Abstract Algebra)|field]], the [[Definition:Algebraic Structure|algebraic structure]] $\struct {\Q_{\ne 0}, \times}$ is a [[Definition:Group|group]]. Thus, by definition, $\times$ is [[Definition:Closed Algebraic Structure|closed]] in $\struct {\Q_{\ne 0}, \times}$. {{qed}}	0
Fix $x \in \R_{>0}$. From [[Defining Sequence of Natural Logarithm is Strictly Decreasing]], $\left\langle{ f_n \left({ x }\right) }\right\rangle$ is [[Definition:Strictly Decreasing/Sequence | strictly decreasing]]. From [[Lower Bound of Natural Logarithm/Proof 3]], $\left\langle{ f_n \left({ x }\right) }\right\rangle$ is [[Definition:Bounded Below Real Sequence|bounded below]]. From [[Monotone Convergence Theorem (Real Analysis)|Monotone Convergence Theorem]], $\left\langle{ f_n \left({ x }\right) }\right\rangle$ is [[Definition:Convergent Real Sequence|convergent]] Hence the result, by definition of [[Definition:Pointwise Convergence|pointwise convergence]]. {{qed}} [[Category:Natural Logarithms]] g613kd5i1wa3ssljn1w1bfk4gqetbha	0
The strategy is to show that: :$\map \ln {\map \Gamma {\dfrac x 2 + \dfrac y 2} } \le \dfrac 1 2 \map \ln {\map \Gamma x} + \dfrac 1 2 \map \ln {\map \Gamma y}$ Let $0 < \delta < \Delta$. Then: {{begin-eqn}} {{eqn | l = \paren {\int_\delta^\Delta t^{\paren {x + y - 2} / 2} e^{-t} \rd t}^2 | r = \paren {\int_\delta^\Delta \paren {t^{\paren {x - 1} / 2} e^{-t/2} } \paren {t^{\paren {y - 1} / 2} e^{-t/2} } \rd t}^2 | c = }} {{eqn | n = 1 | o = \le | r = \paren {\int_\delta^\Delta t^{x - 1} e^{-t} \rd t} \paren {\int_\delta^\Delta t^{y - 1} e^{-t} \rd t} | c = [[Cauchy-Bunyakovsky-Schwarz Inequality for Definite Integrals]] }} {{end-eqn}} Letting $\delta \to 0$ and $\Delta \to \infty$, $(1)$ becomes equivalent to: :$\paren {\map \Gamma {\dfrac {x + y} 2} }^2 \le \paren {\map \Gamma x} \paren {\map \Gamma y}$ {{begin-eqn}} {{eqn | l = \paren {\map \Gamma {\dfrac {x + y} 2} }^2 | o = \le | r = \paren {\map \Gamma x} \paren {\map \Gamma y} | c = }} {{eqn | ll= \leadsto | l = \map \ln {\paren {\map \Gamma {\dfrac {x + y} 2} }^2} | o = \le | r = \map \ln {\paren {\map \Gamma x} \paren {\map \Gamma y} } | c = }} {{eqn | ll= \leadsto | l = 2 \map \ln {\map \Gamma {\dfrac {x + y} 2} } | o = \le | r = \map \ln {\map \Gamma x} + \map \ln {\map \Gamma y} | c = }} {{eqn | ll= \leadsto | l = \map \ln {\map \Gamma {\dfrac x 2 + \dfrac y 2} } | o = \le | r = \frac 1 2 \map \ln {\map \Gamma x} + \frac 1 2 \map \ln {\map \Gamma y} | c = }} {{end-eqn}} The result follows by definition of [[Definition:Convex Real Function|convex function]]. {{qed}}	0
{{begin-eqn}} {{eqn | l = A^- | r = \left({\left({a \,.\,.\, b}\right) \cup \left({b \,.\,.\, c}\right)}\right)^- | c = }} {{eqn | r = \left({a \,.\,.\, b}\right)^- \cup \left({b \,.\,.\, c}\right)^- | c = [[Closure of Finite Union equals Union of Closures]] }} {{eqn | r = \left[{a \,.\,.\, b}\right] \cup \left[{b \,.\,.\, c}\right] | c = [[Closure of Open Ball in Metric Space]] }} {{eqn | r = \left[{a \,.\,.\, c}\right] | c = {{Defof|Closed Real Interval}} }} {{end-eqn}} {{qed}} [[Category:Set Closures]] [[Category:Union of Adjacent Open Intervals]] p1ts9xym8w2qx2gim0b0f2bqkl6dw7t	0
Let $n$ be a [[Definition:Positive Integer|positive integer]]. Then: :$\displaystyle \int x^n e^{a x} \rd x = \frac {x^n e^{a x} } a - \frac n a \int x^{n - 1} e^{a x} \rd x + C$	0
: $\dbinom {p^n k} {p^n} \equiv k \pmod p$ where $\dbinom {p^n k} {p^n}$ is a [[Definition:Binomial Coefficient|binomial coefficient]].	0
:$\sin 300 \degrees = \sin \dfrac {5 \pi} 3 = -\dfrac {\sqrt 3} 2$	0
From [[Sum of Cuts is Cut]], $p^* + q^*$ is a [[Definition:Cut (Analysis)|cut]]. Let $r \in p^* + q^*$. Then: :$r = s + t$ where $s < p$ and $t < q$ Thus: :$r < p + q$ and so: :$r \in \paren {p + q}^*$ Hence: :$p^* + q^* \subseteq \paren {p + q}^*$ {{qed|lemma}} Let $r \in \paren {p + q}^*$. Then: :$r < p + q$ Let: :$h = p + q - r$ :$s = p - \dfrac h 2$ :$t = q - \dfrac h 2$ Then: :$s \in p^*$ :$t \in q^*$ Hence: :$r = s + t$ and so: :$r \in p^* + q^*$ So: :$\paren {p + q}^* \subseteq p^* + q^*$ {{qed|lemma}} Hence the result by definition of [[Definition:Set Equality|set equality]]. {{Qed}}	0
{{begin-eqn}} {{eqn | l = x | o = > | r = 0 | c = }} {{eqn | lo= \land | l = y | o = > | r = 0 | c = [[Real Number Ordering is Compatible with Addition]] }} {{eqn | ll= \leadsto | l = x + y | o = > | r = 0 + 0 | c = [[Real Number Inequalities can be Added]] }} {{eqn | r = 0 | c = [[Definition:Real Number Axioms|Real Number Axioms: $\R \text A 3$: Identity]] }} {{end-eqn}} {{qed}}	0
:$\ds \int \sec a x \rd x = \frac 1 a \ln \size {\map \tan {\frac \pi 4 + \frac {a x} 2} } + C$ where $\map \tan {\dfrac \pi 4 + \dfrac {a x} 2} \ne 0$.	0
A specific instance of [[Power of Prime is Deficient]]. {{qed}}	0
Let $\epsilon \in \R_{>0}$ be a [[Definition:Strictly Positive Real Number|strictly positive real number]]. For all $x \in A_1$, define: :$\map \Delta x = \set {\delta \in \R_{>0}: \forall y \in A_1: \map {d_1} {x, y} < 2 \delta \implies \map {d_2} {\map f x, \map f y} < \dfrac \epsilon 2}$ Define: :$\mathcal C = \set {\map {B_{\delta} } x: x \in A_1, \, \delta \in \map \Delta x}$ where $B_{\delta} \left({x}\right)$ denotes the [[Definition:Open Ball|open $\delta$-ball of $x$ in $M_1$]]. From the definition of [[Definition:Continuous Mapping (Metric Spaces)|continuity]], it follows that $\mathcal C$ is a [[Definition:Cover of Set|cover]] for $A_1$. From [[Open Ball of Metric Space is Open Set]], it therefore follows that $\mathcal C$ is an [[Definition:Open Cover|open cover]] for $A_1$. By the definition of a [[Definition:Compact Metric Space|compact metric space]], there exists a [[Definition:Finite Subcover|finite subcover]] $\set {\map {B_{\delta_1} } {x_1}, \map {B_{\delta_2} } {x_2}, \ldots, \map {B_{\delta_n} } {x_n} }$ of $\mathcal C$ for $A_1$. Define: :$\delta = \min \set {\delta_1, \delta_2, \ldots, \delta_n}$ Let $x, y \in A_1$ satisfy $\map {d_1} {x, y} < \delta$. By the definition of a [[Definition:Cover of Set|cover]], there exists a $k \in \set{1, 2, \ldots, n}$ such that $\map {d_1} {x, x_k} < \delta_k$. Then: {{begin-eqn}} {{eqn | l = \map {d_1} {y, x_k} | o = \le | r = \map {d_1} {y, x} + \map {d_1} {x, x_k} | c = [[Definition:Triangle Inequality|Triangle Inequality]] }} {{eqn | o = < | r = \delta + \delta_k | c = [[Definition:Metric Space Axioms|Metric Space Axiom $\paren {M3}$]] }} {{eqn | o = \le | r = 2 \delta_k }} {{end-eqn}} By the definition of $\Delta \left({x_k}\right)$, it follows that: :$\map {d_2} {\map f x, \map f {x_k} } < \dfrac \epsilon 2$ :$\map {d_2} {\map f y, \map f {x_k} } < \dfrac \epsilon 2$ Hence: {{begin-eqn}} {{eqn | l = \map {d_2} {\map f x, \map f y} | o = \le | r = \map {d_2} {\map f x, \map f {x_k} } + \map {d_2} {\map f {x_k}, \map f y} | c = [[Definition:Triangle Inequality|Triangle Inequality]] }} {{eqn | o = < | r = \frac \epsilon 2 + \frac \epsilon 2 | c = [[Definition:Metric Space Axioms|Metric Space Axiom $\paren{M3}$]] }} {{eqn|r = \epsilon }} {{end-eqn}} The result follows from the definition of [[Definition:Uniformly Continuous Mapping (Metric Spaces)|uniform continuity]]. {{qed}}	0
There are $3462$ ways to represent $1$ as the sum of exactly $6$ [[Definition:Unit Fraction|unit fractions]].	0
{{begin-eqn}} {{eqn | l = 1 | r = \cos 0 | c = [[Cosine of Zero is One]] }} {{eqn | r = \map \cos {x - x} | c = }} {{eqn | r = \cos x \, \map \cos {-x} - \sin x \, \map \sin {-x} | c = [[Cosine of Sum]] }} {{eqn | r = \cos x \cos x - \paren {-\sin x \sin x} | c = [[Cosine Function is Even]] and [[Sine Function is Odd]] }} {{eqn | r = \cos^2 x + \sin^2 x | c = }} {{end-eqn}} {{qed}} === Notes === Note that we need to start from the algebraic definitions of [[Definition:Complex Sine Function|sine]] and [[Definition:Complex Cosine Function|cosine]]: :$\displaystyle \sin x = \sum_{n \mathop = 0}^\infty \paren {-1}^n \frac {x^{2 n + 1} } {\paren {2 n + 1}!} = x - \frac {x^3} {3!} + \frac {x^5} {5!} - \cdots$ :$\displaystyle \cos x = \sum_{n \mathop = 0}^\infty \paren {-1}^n \frac {x^{2 n} } {\paren {2 n}!} = 1 - \frac {x^2} {2!} + \frac {x^4} {4!} - \cdots$ and then use the proofs of the [[Cosine of Sum]] that derive directly from these. Otherwise these proofs are circular.	0
:$\Beta \left({x, 1}\right) = \Beta \left({1, x}\right) = \dfrac 1 x$	0
{{begin-eqn}} {{eqn | l = \prod_{k \mathop = 1}^n \paren {m + k} | r = \frac {\paren {m + n}!} {m!} | c = }} {{eqn | r = n! \frac {\paren {m + n}!} {m! \, n!} | c = }} {{eqn | r = n! \binom {m + n} m | c = {{Defof|Binomial Coefficient}} }} {{eqn | r = \binom {m + n} m \prod_{k \mathop = 1}^n k | c = }} {{end-eqn}} Hence the result, and note that for a bonus we have identified exactly what the [[Definition:Divisor of Integer|divisor]] is: :$\dbinom {m + n} m$ {{qed}}	0
A '''complex sequence''' is a [[Definition:Sequence|sequence]] (usually [[Definition:Infinite Sequence|infinite]]) whose [[Definition:Codomain of Sequence|codomain]] is the [[Definition:Complex Number|set of complex numbers $\C$]].	0
From [[Sum Less Minimum is Maximum]]: :$\forall x \in S : \max \set {\map f x, \map g x} = \map f x + \map g x - \min \set {\map f x, \map g x}$ Thus: :$\max \set {f, g} = f + g - \min \set{f, g}$ From [[Minimum Rule for Continuous Functions]]: :$\min \set {f, g}$ is [[Definition:Everywhere Continuous Mapping (Topology)|continuous]] From [[Multiple Rule for Continuous Mappings into Topological Ring]]: :$-\min \set {f, g}$ is [[Definition:Everywhere Continuous Mapping (Topology)|continuous]] From [[Sum Rule for Continuous Mappings into Topological Ring]]: :$f + g -\min \set {f, g}$ is [[Definition:Everywhere Continuous Mapping (Topology)|continuous]] Thus: :$\max \set {f, g}$ is [[Definition:Everywhere Continuous Mapping (Topology)|continuous]] {{qed}}	0
:$\cos 180^\circ = \cos \pi = - 1$	0
From [[Additive Group of Integers is Normal Subgroup of Reals]], $\struct {\Z, +} \lhd \struct {\R, +}$. From [[Additive Group of Reals is Subgroup of Complex]], $\struct {\R, +} \lhd \struct {\C, +}$. Thus $\struct {\Z, +} \le \struct {\C, +}$. From [[Complex Numbers under Addition form Abelian Group]], $\struct {\C, +}$ is [[Definition:Abelian Group|abelian]]. From [[Subgroup of Abelian Group is Normal]], it follows that $\struct {\Z, +} \lhd \struct {\C, +}$. {{qed}} [[Category:Additive Group of Integers]] [[Category:Additive Group of Complex Numbers]] [[Category:Examples of Normal Subgroups]] ikeecuhel3tpbsr0yhe0vfstw909fqw	0
Proof by [[Principle of Mathematical Induction|induction]]: For all $m \in \Z_{> 0}$, let $\map P m$ be the [[Definition:Proposition|proposition]]: :$\map \Gamma {-m + \dfrac 1 2} = \dfrac {\paren {-1}^m 2^{2 m} m!} {\paren {2 m}!} \sqrt \pi$ === Basis for the Induction === $\map P 1$ is the case: {{begin-eqn}} {{eqn | l = \map \Gamma {-1 + \frac 1 2} | r = \frac {\map \Gamma {\frac 1 2} } {-1 + \frac 1 2} | c = [[Gamma Function for Non-Negative Integer Argument]] }} {{eqn | r = \frac {\sqrt \pi} {-\frac 1 2} | c = [[Gamma Function of One Half]] }} {{eqn | r = \frac {\paren {-1}^1 \times 4} 2 \sqrt \pi | c = }} {{eqn | r = \frac {\paren {-1}^1 2^{2 \times 1} 1!} {2!} \sqrt \pi | c = Definition of [[Definition:Factorial|Factorial]] }} {{eqn | r = \frac {\paren {-1}^1 2^{2 m} m!} {\paren {2 m}!} \sqrt \pi | c = where $m = 1$ }} {{end-eqn}} and so $P(1)$ holds. This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\map \Gamma {-k + \dfrac 1 2} = \dfrac {\paren {-1}^k 2^{2 k} k!} {\paren {2 k}!} \sqrt \pi$ Then we need to show: :$\map \Gamma {-\paren {k + 1} + \dfrac 1 2} = \dfrac {\paren {-1}^{k + 1} 2^{2 \paren {k + 1} } \paren {k + 1}!} {\paren {2 \paren {k + 1} } !} \sqrt \pi$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \map \Gamma {-\paren {k + 1} + \frac 1 2} | r = \frac {\map \Gamma {k + \frac 1 2} } {\paren {-\paren {k + 1} + \frac 1 2} } | c = [[Gamma Difference Equation]] }} {{eqn | r = \frac {\dfrac {\paren {-1}^k 2^{2 k} k!} {\paren {2 k}!} \sqrt \pi} {-k - \frac 1 2} | c = [[Gamma Function of Negative Half-Integer#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \frac {\paren {-1}^k \paren {-2} \times 2^{2 k} k!} {\paren {2 k + 1} \paren {2 k} !} \sqrt \pi | c = simplifying }} {{eqn | r = \frac {\paren {-1}^{k + 1} 2 \paren {2 k + 2} 2^{2 k} k!} {\paren {2 k}! \paren {2 k + 1} \paren {2 k + 2} } \sqrt \pi | c = multiplying [[Definition:Numerator|top]] and [[Definition:Denominator|bottom]] by $2 k + 2$ }} {{eqn | r = \frac {\paren {-1}^{k + 1} 2^{2 k + 1} \paren {2 \paren {k + 1} } k!} {\paren {2 k + 2}!} \sqrt \pi | c = }} {{eqn | r = \frac {\paren {-1}^{k + 1} 2^{2 \paren {k + 1} } \paren {k + 1}!} {\paren {2 \paren {k + 1} }!} \sqrt \pi | c = further simplification }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Finally: {{begin-eqn}} {{eqn | l = \frac {2^{2 m} m!} {\paren {2 m}!} | r = \frac {2^{2 m} \ 1 \times 2 \times 3 \times \cdots \times m} {1 \times 2 \times 3 \times \cdots \times 2 m} | c = }} {{eqn | r = \frac {2^m \, 2^m \, \paren {1 \times 2 \times 3 \times \cdots \times m} } {1 \times 2 \times 3 \times \cdots \times \paren {2 m - 1} \times 2 m} | c = }} {{eqn | r = \frac {2^m \paren {\paren {2 \times 1} \times \paren {2 \times 2} \times \paren {2 \times 3} \times \cdots \times 2 m} } {1 \times 2 \times 3 \times \cdots \times \paren {2 m - 1} \times 2 m} | c = }} {{eqn | r = \frac {2^m \paren {2 \times 4 \times 6 \times \cdots \times 2 m} } {1 \times 2 \times 3 \times \cdots \times \paren {2 m - 1} \times 2 m} | c = }} {{eqn | r = \frac {2^m} {1 \times 3 \times 5 \times \cdots \times \paren {2 m - 1} } | c = }} {{end-eqn}} Therefore: {{begin-eqn}} {{eqn | ll= \forall m \in \Z_{>0}: | l = \map \Gamma {-m + \frac 1 2} | r = \frac {\paren {-1}^m 2^{2 m} m!} {\paren {2 m} !} \sqrt \pi | c = }} {{eqn | r = \frac {\paren {-1}^m 2^m} {1 \times 3 \times 5 \times \cdots \times \paren {2 m - 1} } \sqrt \pi | c = }} {{end-eqn}} {{qed}}	0
Consider the [[Definition:Linear Congruence|linear congruence]] $a x \equiv b \pmod n$. Suppose $\exists x_0 \in \Z: a x_0 \equiv b \pmod n$. Then $\exists y_0 \in Z: a x_0 - b = n y_0$ by definition of [[Definition:Congruence (Number Theory)|congruence]]. Thus $x = x_0, y = y_0$ is a solution to the [[Definition:Linear Diophantine Equation|linear Diophantine equation]] $a x - n y = b$. On the other hand, if $x = x_0, y = y_0$ is a solution to the [[Definition:Linear Diophantine Equation|linear Diophantine equation]] $a x - n y = b$, then it follows that $a x \equiv b \pmod n$. Hence: : the problem of finding all integers satisfying the [[Definition:Linear Congruence|linear congruence]] $a x \equiv b \pmod n$ is the same problem as: : the problem of finding all the $x$ values in the [[Definition:Linear Diophantine Equation|linear Diophantine equation]] $a x - n y = b$. From [[Solution of Linear Diophantine Equation]]: The [[Definition:Linear Diophantine Equation|linear Diophantine equation]] $a x - n y = b$ has at least one [[Definition:Polynomial Congruence/Solution|solution]] {{iff}}: :$\gcd \set {a, n} \divides b$ Hence the result. {{qed}} [[Category:Solution of Linear Congruence]] i2q79zyugpt7691hpi24jfc0wf67dz4	0
By [[Gregory Series]]: :$\displaystyle \arctan t = \sum_{m \mathop = 0}^\infty \frac {\paren {-1}^m t^{2 m + 1} } {2 m + 1}$ Let $t = \dfrac x {\sqrt {1 - x^2} }$. Let $y = \arcsin x$. Then: {{begin-eqn}} {{eqn | l = t | r = \frac {\sin y} {\sqrt {1 - \sin^2 y} } }} {{eqn | r = \frac {\sin y} {\cos y} | c = [[Sum of Squares of Sine and Cosine]] }} {{eqn | r = \tan y }} {{end-eqn}} Hence $\arctan t = \arcsin x$. We have: {{begin-eqn}} {{eqn | l = \frac {2 x \arcsin x} {\sqrt {1 - x^2} } | r = 2 t \arctan t }} {{eqn | r = 2 t \sum_{m \mathop = 0}^\infty \frac {\paren {-1}^m t^{2 m + 1} } {2 m + 1} | c = [[Gregory Series]] }} {{eqn | r = 2 t \sum_{m \mathop = 1}^\infty \frac {\paren {-1}^{m - 1} t^{2 m - 1} } {2 m - 1} | c = [[Translation of Index Variable of Summation]] }} {{eqn | r = 2 \sum_{m \mathop = 1}^\infty \frac {\paren {-1}^{m - 1} t^{2 m} } {2 m - 1} }} {{eqn | r = 2 \sum_{m \mathop = 1}^\infty \frac {\paren {-1}^{m - 1} x^{2 m} } {\paren {2 m - 1} \paren {1 - x^2}^m} }} {{eqn | r = 2 \sum_{m \mathop = 1}^\infty \frac {\paren {-1}^{m - 1} x^{2 m} } {2 m - 1} \sum_{k \mathop = 0}^\infty \dbinom {m + k - 1} {m - 1} x^{2 k} | c = [[Binomial Theorem for Negative Index and Negative Parameter]] }} {{end-eqn}} It remains to show the the coefficient of $x^{2 n}$ on the {{RHS}} is equal to $\dfrac {2^{2 n} } {n \dbinom {2 n} n}$, that is: :$\displaystyle 2 \sum_{r \mathop = 1}^n \frac {\paren {-1}^{r - 1} } {2 r - 1} \dbinom {r + n - r - 1} {r - 1} = \frac {2^{2 n} } {n \dbinom {2 n} n}$ The {{LHS}} above is generated by picking, for each $m > 0$, the corresponding $k = n - m$ from the right sum $\displaystyle \sum_{k \mathop = 0}^\infty \dbinom {m + k - 1} {m - 1} x^{2 k}$. We have: {{begin-eqn}} {{eqn | r = 2 n \dbinom {2 n} n \sum_{r \mathop = 1}^n \frac {\paren {-1}^{r - 1} } {2 r - 1} \dbinom {n - 1} {r - 1} | o = }} {{eqn | r = 2 n \dbinom {2 n} n \sum_{r \mathop = 0}^{n - 1} \frac {\paren {-1}^r} {2 r + 1} \dbinom {n - 1} r | c = [[Translation of Index Variable of Summation]] }} {{eqn | r = 2 n \dbinom {2 n} n \int_0^1 \sum_{r \mathop = 0}^{n - 1} \paren {-1}^r \dbinom {n - 1} r y^{2 r} \d y }} {{eqn | r = 2 n \dbinom {2 n} n \int_0^1 \paren {1 - y^2}^{n - 1} \d y | c = [[Binomial Theorem]] }} {{eqn | r = 2 n \dbinom {2 n} n \int_{\frac \pi 2}^0 \sin^{2 n - 2} \theta \, \frac {\d y} {\d \theta} \d \theta | c = by substitution of $y = \cos \theta$ }} {{eqn | r = 2 n \dbinom {2 n} n \int_0^{\frac \pi 2} \sin^{2 n - 1} \theta \, \d \theta }} {{eqn | r = 2 n \dbinom {2 n} n \frac {\paren {2^{n - 1} \paren {n - 1}!}^2} {\paren {2 n - 1}!} | c = [[Definite Integral from 0 to Half Pi of Odd Power of Sine x]] }} {{eqn | r = 2 n \paren {\frac {\paren {2 n}!} {n! \, n!} } \paren {\frac {\paren {2^{n - 1} \paren {n - 1}!}^2} {\paren {2 n - 1}!} } | c = {{Defof|Binomial Coefficient}} }} {{eqn | r = 2 n \paren {\frac {2 n} {n^2} } \paren {2^{2 n - 2} } }} {{eqn | r = 2^{2 n} }} {{end-eqn}} Hence the result. {{qed}}	0
Let $p$ be a [[Definition:Prime Number|prime number]]. Let $\struct {\Z_p, +, \times}$ be the [[Ring of Integers Modulo Prime is Field|field of integers modulo $p$]]. Then $\struct {\Z_p, +, \times}$ is a [[Definition:Prime Field|prime field]].	0
By definition of [[Definition:Congruence (Number Theory)|congruence]]: :$a \not \equiv 0 \pmod p \iff p \nmid a$ where $p \nmid a$ denotes that $p$ is not a [[Definition:Divisor of Integer|divisor]] of $a$. From [[Prime not Divisor implies Coprime]]: :$p \nmid a \iff p \perp a$ where $p \perp a$ denotes that $p$ and $a$ are [[Definition:Coprime Integers|coprime]]. The result follows from [[Integer Coprime to Modulus iff Linear Congruence to 1 exists]]. {{qed}}	0
The proof proceeds by [[Principle of Mathematical Induction|induction]]. === Basis for the Induction === For all $n \in \Z_{\ge 3}$, let $P \left({n}\right)$ be the [[Definition:Proposition|proposition]]: :$\displaystyle \left[{n \atop n - 3}\right] = \binom n 6 + 8 \binom {n + 1} 6 + 6 \binom {n + 2} 6$ $P \left({3}\right)$ is the case: {{begin-eqn}} {{eqn | l = \left[{3 \atop 0}\right] | r = \delta_{3 0} | c = {{Defof|Unsigned Stirling Numbers of the First Kind}} }} {{eqn | r = 0 | c = {{Defof|Kronecker Delta}} }} {{end-eqn}} This is the [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that, if $P \left({k}\right)$ is true, where $k \ge 3$, then it logically follows that $P \left({k + 1}\right)$ is true. So this is the [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$\displaystyle \left[{k \atop k - 3}\right] = \binom k 6 + 8 \binom {k + 1} 6 + 6 \binom {k + 2} 6$ from which it is to be shown that: :$\displaystyle \left[{ {k + 1} \atop k - 2}\right] = \binom {k + 1} 6 + 8 \binom {k + 2} 6 + 6 \binom {k + 3} 6$ === Induction Step === This is the [[Principle of Mathematical Induction#Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \left[{k + 1 \atop k - 2}\right] | r = k \left[{k \atop k - 2}\right] + \left[{k \atop k - 3}\right] | c = {{Defof|Unsigned Stirling Numbers of the First Kind}} }} {{eqn | r = k \left({\binom n 4 + 2 \binom {n + 1} 4}\right) + \left[{k \atop k - 3}\right] | c = [[Unsigned Stirling Number of the First Kind of n with n-2]] }} {{eqn | r = k \left({\binom n 4 + 2 \binom {n + 1} 4}\right) + \binom k 6 + 8 \binom {k + 1} 6 + 6 \binom {k + 2} 6 | c = [[Unsigned Stirling Number of the First Kind of n with n-2#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = k \left({\dfrac {k \left({k - 1}\right) \left({k - 2}\right) \left({k - 3}\right)} {4!} + 2 \dfrac {\left({k + 1}\right) k \left({k - 1}\right) \left({k - 2}\right)} {4!} }\right) | c = {{Defof|Binomial Coefficient}} }} {{eqn | o = | ro= + | r = \dfrac {k \left({k - 1}\right) \left({k - 2}\right) \left({k - 3}\right) \left({k - 4}\right) \left({k - 5}\right)} {6!} | c = }} {{eqn | o = | ro= + | r = 8 \dfrac {\left({k + 1}\right) k \left({k - 1}\right) \left({k - 2}\right) \left({k - 3}\right) \left({k - 4}\right)} {6!} | c = }} {{eqn | o = | ro= + | r = 6 \dfrac {\left({k + 2}\right) \left({k + 1}\right) k \left({k - 1}\right) \left({k - 2}\right) \left({k - 3}\right)} {6!} | c = }} {{eqn | r = k \left({k - 1}\right) \left({k - 2}\right) \left({\dfrac {k \left({k - 3}\right) + 2 k \left({k + 1}\right)} {4!} }\right) | c = }} {{eqn | o = | ro= + | r = k \left({k - 1}\right) \left({k - 2}\right) \left({k - 3}\right) \dfrac {\left({k - 4}\right) \left({k - 5}\right) + 8 \left({k + 1}\right) \left({k - 4}\right) + 6 \left({k + 2}\right) \left({k + 1}\right)} {6!} | c = }} {{eqn | r = k \left({k - 1}\right) \left({k - 2}\right) \left({\dfrac {k^2 - 3 k + 2 k^2 + 2 k} {4!} }\right) | c = }} {{eqn | o = | ro= + | r = k \left({k - 1}\right) \left({k - 2}\right) \left({k - 3}\right) \dfrac {k^2 - 9 k + 20 + 8 \left({k^2 - 3 k - 4}\right) + 6 \left({k^2 + 3 k + 2}\right)} {6!} | c = }} {{eqn | r = k \left({k - 1}\right) \left({k - 2}\right) \left({\dfrac {3 k^2 - k} {4!} }\right) | c = }} {{eqn | o = | ro= + | r = k \left({k - 1}\right) \left({k - 2}\right) 15 \left({k - 3}\right) \dfrac {k^2 - k} {6!} | c = }} {{eqn | r = k \left({k - 1}\right) \left({k - 2}\right) 15 \left({\dfrac {6 k^2 - 2 k + k^3 - 4 k^2 + 3 k} {6!} }\right) | c = }} {{eqn | r = k \left({k - 1}\right) \left({k - 2}\right) 15 \left({\dfrac {k^3 + 2 k^2 + k} {6!} }\right) | c = }} {{eqn | r = \left({k + 1}\right) k \left({k - 1}\right) \left({k - 2}\right) 15 \left({\dfrac {k^2 + k} {6!} }\right) | c = }} {{eqn | r = \left({k + 1}\right) k \left({k - 1}\right) \left({k - 2}\right) \left({\dfrac {15 k^2 + 15 k} {6!} }\right) | c = }} {{eqn | r = \left({k + 1}\right) k \left({k - 1}\right) \left({k - 2}\right) \left({\dfrac {\left({k^2 - 7 k + 12}\right) + \left({8 k^2 - 8 k - 48}\right) + \left({6 k^2 + 30 k + 36}\right)} {6!} }\right) | c = }} {{eqn | r = \left({k + 1}\right) k \left({k - 1}\right) \left({k - 2}\right) \left({\dfrac {\left({k - 3}\right) \left({k - 4}\right) + 8 \left({k + 2}\right) \left({k - 3}\right) + 6 \left({k + 3}\right) \left({k + 2}\right)} {6!} }\right) | c = }} {{eqn | r = \dfrac {\left({k + 1}\right) k \left({k - 1}\right) \left({k - 2}\right) \left({k - 3}\right) \left({k - 4}\right)} {6!} | c = }} {{eqn | o = | ro= + | r = 8 \dfrac {\left({k + 2}\right) \left({k + 1}\right) k \left({k - 1}\right) \left({k - 2}\right) \left({k - 3}\right)} {6!} | c = }} {{eqn | o = | ro= + | r = 6 \dfrac {\left({k + 3}\right) \left({k + 2}\right) \left({k + 1}\right) k \left({k - 1}\right) \left({k - 2}\right)} {6!} | c = }} {{eqn | r = \binom {k + 1} 6 + 8 \binom {k + 2} 6 + 6 \binom {k + 3} 6 | c = {{Defof|Binomial Coefficient}} }} {{end-eqn}} So $P \left({k}\right) \implies P \left({k + 1}\right)$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\displaystyle \forall n \in \Z_{\ge 3}: \left[{n \atop n - 3}\right] = \binom n 6 + 8 \binom {n + 1} 6 + 6 \binom {n + 2} 6$ {{qed}}	0
From the definition: {{begin-eqn}} {{eqn | l = \binom n 0 | r = \frac {n!} {0! \ n!} | c = {{Defof|Binomial Coefficient}} }} {{eqn | r = \frac {n!} {1 \cdot n!} | c = {{Defof|Factorial}} of $0$ }} {{eqn | r = 1 | c = }} {{end-eqn}} {{qed}}	0
Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \N$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\displaystyle \sum_{k \mathop = 0}^n \binom k m = \binom {n + 1} {m + 1}$ === Basis for the Induction === $\map P 0$ says: :$\dbinom 0 m = \dbinom 1 {m + 1}$ When $m = 0$ we have by [[Definition:Binomial Coefficient|definition]]: :$\dbinom 0 0 = 1 = \dbinom 1 1$ When $m > 0$ we also have by [[Definition:Binomial Coefficient|definition]]: :$\dbinom 0 m = 0 = \dbinom 1 {m + 1}$ This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P r$ is true, where $r \ge 0$, then it logically follows that $\map P {r + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\displaystyle \sum_{k \mathop = 0}^r \binom k m = \binom {r + 1} {m + 1}$ Then we need to show: :$\displaystyle \sum_{k \mathop = 0}^{r + 1} \binom k m = \binom {r + 2} {m + 1}$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \sum_{k \mathop = 0}^{r + 1} \binom k m | r = \sum_{k \mathop = 0}^r \binom k m + \binom {r + 1} m | c = }} {{eqn | r = \binom {r + 1} {m + 1} + \binom {r + 1} m | c = [[Sum of Binomial Coefficients over Upper Index#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \binom {r + 2} {m + 1} | c = [[Pascal's Rule]] }} {{end-eqn}} So $\map P r \implies \map P {r + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\displaystyle \forall m, n \in \Z, m \ge 0, n \ge 0: \sum_{k \mathop = 0}^n \binom k m = \binom {n + 1} {m + 1}$ {{qed}}	0
[[Definition:Pentagonal Number|Pentagonal numbers]] are [[Definition:Polygonal Number|$k$-gonal numbers]] where $k = 5$. From [[Closed Form for Polygonal Numbers]] we have that: :$\map P {k, n} = \dfrac n 2 \paren {\paren {k - 2} n - k + 4}$ Hence: {{begin-eqn}} {{eqn | l = P_n | r = \frac n 2 \paren {\paren {5 - 2} n - 5 + 4} | c = [[Closed Form for Polygonal Numbers]] }} {{eqn | r = \dfrac {n \paren {3 n - 1} } 2 | c = }} {{end-eqn}} Hence the result. {{qed}}	0
Let $a_1, a_2, a_3, \ldots$ be the sequence: :$\left \langle{a_n}\right \rangle = 1, 2, 2, 3, 3, 3, 4, 4, 4, 4, \ldots$ Then: :$a_n = \left \lceil{\dfrac {\sqrt {1 + 8 n} - 1} 2}\right \rceil$	0
There exist no [[Definition:Fermat Number|Fermat numbers]] which are [[Definition:Square Number|square]].	0
{{begin-eqn}} {{eqn | l = \binom r k | r = \frac {r^{\underline k} } {k!} | c = {{Defof|Binomial Coefficient}} }} {{eqn | r = \frac 1 {k!} \prod_{j \mathop = 0}^{k - 1} \paren {r - j} | c = {{Defof|Falling Factorial}} }} {{eqn | r = \frac {\paren {-1}^k} {k!} \prod_{j \mathop = 0}^{k - 1} \paren {-\paren {r - j} } | c = }} {{eqn | r = \frac {\paren {-1}^k} {k!} \prod_{j \mathop = 0}^{k - 1} \paren {j - r} | c = }} {{eqn | r = \frac {\paren {-1}^k} {k!} \prod_{j \mathop = 0}^{k - 1} \paren {\paren {k - 1} - j - r} | c = [[Permutation of Indices of Product]] }} {{eqn | r = \frac {\paren {-1}^k} {k!} \prod_{j \mathop = 0}^{k - 1} \paren {\paren {k - r - 1} - j} | c = }} {{eqn | r = \paren {-1}^k \frac {\paren {k - r - 1}^{\underline j} } {k!} | c = {{Defof|Falling Factorial}} }} {{eqn | r = \paren {-1}^k \binom {k - r - 1} k | c = {{Defof|Binomial Coefficient}} }} {{end-eqn}} {{qed}}	0
Let $m, n \in \Z_{\ge 0}$. :$\displaystyle \sum_{k \mathop \le n} {k \brack m} \frac {n!} {k!} = {n + 1 \brack m + 1}$ where: :$\displaystyle {k \brack m}$ denotes an [[Definition:Unsigned Stirling Numbers of the First Kind|unsigned Stirling number of the first kind]] :$ n!$ denotes a [[Definition:Factorial|factorial]].	0
The [[Definition:Multiplicity of Prime Factor|multiplicity]] of $720$ in $720!$ is $178$. That is: :$720^{178} \divides 720!$ but: :$720^{179} \nmid 720!$ where: :$720!$ denotes [[Definition:Factorial|$720$ factorial]] :$\divides$ denotes [[Definition:Divisor of Integer|divisibility]] :$\nmid$ denotes non-[[Definition:Divisor of Integer|divisibility]].	0
Let $\pi, \rho \in S_n$. Let $\pi * f$ be the [[Definition:Permutation on Polynomial|permutation on the polynomial]] $f$ by $\pi$. Let $e \in S_n$ be the [[Definition:Identity Element|identity]] of $S_n$. From [[Symmetric Group is Group]]: :$e * f = f$ thus fulfilling {{GroupActionAxiom|1}}. Then we have that: {{begin-eqn}} {{eqn | l = \paren {\pi \circ \rho} * f | r = \map \pi {\rho * f} | c = }} {{eqn | r = \pi * \paren {\rho * f} | c = }} {{end-eqn}} thus fulfilling {{GroupActionAxiom|2}} {{qed}}	0
For all $N \in \N$: :$\dfrac 1 N + \dfrac 1 {N + 1} + \cdots + \dfrac 1 {2 N} > N \cdot \dfrac 1 {2 N} = \dfrac 1 2$ Hence, by [[Cauchy's Convergence Criterion for Series]], the Harmonic series is divergent. {{qed}}	0
Let $n, k \in \Z_{\ge 0}$ be [[Definition:Positive Integer|positive integers]]. Let $\dbinom n k$ denote the [[Definition:Binomial Coefficient|binomial coefficient]] of $n$ choose $k$. Then for a given value of $n$, the value of $k$ for which $\dbinom n k$ is a [[Definition:Maximum Element|maximum]] is: :$k_\max = \floor {\dfrac n 2}$ and also: :$k_\max = \ceiling {\dfrac n 2}$	0
Let $n \in \Z_{>0}$ be a [[Definition:Strictly Positive Integer|strictly positive integer]]. Let $\dbinom n k$ be the [[Definition:Binomial Coefficient|binomial coefficient]] of $n$ over $k$ for a [[Definition:Positive Integer|positive integer]] $k \in \Z_{\ge 0}$. Let $S_n = \left\langle{x_k}\right\rangle$ be the [[Definition:Sequence|sequence]] defined as: :$x_k = \dbinom n k$ Then $S_n$ is [[Definition:Strictly Increasing Sequence|strictly increasing]] exactly where $0 \le k < \dfrac n 2$.	0
Either $n + m$ or $n - m + 1$ is [[Definition:Even Integer|even]]. Thus: :$\dfrac {n + m} 2 \bmod 1 + \dfrac {n - m + 1} 2 \bmod 1 = \dfrac 1 2 < 1$ and so: {{begin-eqn}} {{eqn | l = \floor {\dfrac {n + m} 2} + \floor {\dfrac {n - m + 1} 2} | r = \floor {\dfrac {n + m} 2 + \dfrac {n - m + 1} 2} | c = [[Sum of Floors not greater than Floor of Sum]] }} {{eqn | r = \floor {\dfrac {n + m + n - m + 1} 2} | c = }} {{eqn | r = \floor {n + \dfrac 1 2} | c = }} {{eqn | r = n | c = }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = 1^2 | r = 1 }} {{eqn | l = 11^2 | r = 121 | c = }} {{eqn | l = 111^2 | r = 12 \, 321 | c = }} {{eqn | l = 1111^2 | r = 1 \, 234 \, 321 | c = }} {{eqn | l = 11 \, 111^2 | r = 123 \, 454 \, 321 | c = }} {{eqn | l = 111 \, 111^2 | r = 12 \, 345 \, 654 \, 321 | c = }} {{eqn | l = 1 \, 111 \, 111^2 | r = 1 \, 234 \, 567 \, 654 \, 321 | c = }} {{eqn | l = 11 \, 111 \, 111^2 | r = 123 \, 456 \, 787 \, 654 \, 321 | c = }} {{eqn | l = 111 \, 111 \, 111^2 | r = 12 \, 345 \, 678 \, 987 \, 654 \, 321 | c = }} {{end-eqn}} but: :$1 \, 111 \, 111 \, 111^2 = 1 \, 234 \, 567 \, 900 \, 987 \, 654 \, 321$ {{qed}}	0
Let $n$ be an [[Definition:Integer|integer]] such that $n \ge 2$. Let the [[Definition:Prime Decomposition|prime decomposition]] of $n$ be: :$n = p_1^{k_1} p_2^{k_2} \ldots p_r^{k_r}$ Then from [[Tau Function from Prime Decomposition]] we have that: : $\displaystyle \tau \left({n}\right) = \prod_{i \mathop = 1}^r \left({k_i + 1}\right)$ === Sufficient Condition === Let $\tau \left({n}\right)$ be [[Definition:Odd Integer|odd]]. Then all factors of $\displaystyle \prod_{i \mathop = 1}^r \left({k_i + 1}\right)$ are [[Definition:Odd Integer|odd]] (and of course $\ge 3$). Therefore all factors of $\displaystyle \prod_{i \mathop = 1}^r \left({k_i}\right)$ are [[Definition:Even Integer|even]]. Thus $n = p_1^{2 s_1} p_2^{2 s_2} \ldots p_r^{2 s_r}$ for $r_i = k_i / 2$ for all $i$. Hence $n = \left({p_1^{s_1} p_2^{s_2} \ldots p_r^{s_r}}\right)^2$ and therefore is [[Definition:Square Number|square]]. {{qed|lemma}} === Necessary Condition === Now suppose $n$ is [[Definition:Square Number|square]]. The above argument reverses, and we see that all factors of $\displaystyle \prod_{i \mathop = 1}^r \left({k_i + 1}\right)$ are [[Definition:Odd Integer|odd]]. Hence $\tau \left({n}\right)$ is itself [[Definition:Odd Integer|odd]]. {{qed}} [[Category:Tau Function]] [[Category:Square Numbers]] scw54galnfy6hw3o2xigr6k775s2ei8	0
We have that: :$\displaystyle \map T n = 1 + 2 + \dotsb + n = \sum_{i \mathop = 1}^n i$ Thus: {{begin-eqn}} {{eqn | l = \map T n | r = n + \paren {n - 1} + \paren {n - 2} + \dotsb + 2 + 1 | c = }} {{eqn | r = n + \paren {n - 1} + \paren {n - 2} + \dotsb + \paren {n - \paren {n - 2} } + \paren {n - \paren {n - 1} } | c = }} {{eqn | r = \underbrace {n + n + \dotsb + n}_{n \text { times} } | c = extracting $n$ from each term }} {{eqn | o = | ro= + | r = \paren {-1} + \paren {-2} + \dotsb + \paren {-\paren {n - 2} } + \paren {-\paren {n - 1} } | c = }} {{eqn | r = n^2 - \paren {1 + 2 + \dotsb + \paren {n - 1} } | c = }} {{eqn | n = 1 | ll= \leadsto | l = \map T n | r = n^2 - \map T {n - 1} | c = }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | n = 2 | l = \map T n | r = n + \map T {n - 1} | c = {{Defof|Triangular Number|index = 1}} }} {{eqn | ll= \leadsto | l = 2 \, \map T n | r = n^2 + n | c = $(1) + (2)$ }} {{eqn | ll= \leadsto | l = \map T n | r = \frac {n \paren {n + 1} } 2 | c = }} {{end-eqn}} {{qed}}	0
=== Definition 1 implies Definition 2 === Let $H_n$ be a [[Definition:Heptagonal Number/Definition 1|heptagonal number by definition 1]]. Let $n = 0$. By definition: :$H_0 = 0$ By [[Definition:Vacuous Summation|vacuous summation]]: :$\displaystyle H_0 = \sum_{i \mathop = 1}^0 \paren {5 i - 4} = 0$ By definition of [[Definition:Summation|summation]]: {{begin-eqn}} {{eqn | l = H_{n - 1} | r = \sum_{i \mathop = 1}^{n - 1} \paren {5 i - 4} | c = }} {{eqn | r = 1 + 6 + \cdots + 5 \paren {n - 1} + 4 | c = }} {{end-eqn}} and so: {{begin-eqn}} {{eqn | l = H_n | r = H_{n - 1} + 5 n - 4 | c = }} {{eqn | r = \sum_{i \mathop = 1}^n \paren {5 n - 4} | c = }} {{eqn | r = 1 + 6 + \cdots + 5 n - 4 | c = }} {{end-eqn}} Thus $H_n$ is a [[Definition:Heptagonal Number/Definition 2|heptagonal number by definition 2]]. {{qed|lemma}} === Definition 2 implies Definition 1 === Let $H_n$ be a [[Definition:Heptagonal Number/Definition 2|heptagonal number by definition 2]]. Then: {{begin-eqn}} {{eqn | l = H_n | r = \sum_{i \mathop = 1}^n \paren {5 i - 4} | c = }} {{eqn | r = 1 + 6 + \cdots + \paren {5 \paren {n - 1} - 4} + \paren {5 n - 4} | c = }} {{eqn | r = H_{n - 1} + 5 n - 4 | c = }} {{end-eqn}} Then: :$\displaystyle H_0 = \sum_{i \mathop = 1}^0 \paren {5 i - 4}$ is a [[Definition:Vacuous Summation|vacuous summation]] and so: :$H_0 = 0$ Thus $H_n$ is a [[Definition:Heptagonal Number/Definition 1|heptagonal number by definition 1]]. {{qed|lemma}} === Definition 1 equivalent to Definition 3 === We have by definition that $H_0 = 0 = \map P {7, 0}$. Then: {{begin-eqn}} {{eqn | lo= \forall n \in \N_{>0}: | l = \map P {7, n} | r = \map P {7, n - 1} + \paren {7 - 2} \paren {n - 1} + 1 | c = }} {{eqn | r = \map P {7, n - 1} + 5 \paren {n - 1} + 1 | c = }} {{eqn | r = \map P {7, n - 1} + 5 n - 4 | c = }} {{end-eqn}} Thus $\map P {7, n}$ and $H_n$ are generated by the same recurrence relation. {{qed}} [[Category:Heptagonal Numbers]] j1nufkda0hxuuykaaoridcuh4s2ftl6	0
{{begin-eqn}} {{eqn | l = \sum_{k \mathop = 0}^{n - 1} \left({f + g}\right) \left({x + \frac k n}\right) | r = \sum_{k \mathop = 0}^{n - 1} \left({f \left({x + \frac k n}\right) + g \left({x + \frac k n}\right)}\right) | c = {{Defof|Pointwise Sum}} }} {{eqn | r = \sum_{k \mathop = 0}^{n - 1} f \left({x + \frac k n}\right) + \sum_{k \mathop = 0}^{n - 1} g \left({x + \frac k n}\right) | c = }} {{eqn | r = f \left({n x}\right) + g \left({n x}\right) | c = {{Defof|Replicative Function}} }} {{eqn | r = \left({f + g}\right) \left({n x}\right) | c = {{Defof|Pointwise Sum}} }} {{end-eqn}} Hence the result by definition of [[Definition:Replicative Function|replicative function]]. {{qed}}	0
{{begin-eqn}} {{eqn | l = \lim_{m \mathop \to \infty} \frac {m^n m!} {\left({n + 1}\right) \left({n + 2}\right) \cdots \left({n + m}\right)} | r = \lim_{m \mathop \to \infty} \frac {m^n m!} {\frac {\left({n + m}\right)!} {n!} } | c = }} {{eqn | r = n! \lim_{m \mathop \to \infty} \frac {m^n} {\left({m + 1}\right) \left({m + 2}\right) \cdots \left({m + n}\right)} | c = }} {{eqn | r = n! | c = }} {{end-eqn}} Now we have from [[Factorial of Integer plus Reciprocal of Integer]] that: :$\displaystyle \lim_{m \mathop \to \infty} \dfrac {\left({m + n}\right)!} {m! m^n} = 1$ Now: {{begin-eqn}} {{eqn | l = \dfrac {n! \left({n + 1}\right) \left({n + 2}\right) \cdots \left({n + m}\right)} {m! m^n} | r = \dfrac {\left({m + n}\right)!} {m! m^n} | c = }} {{eqn | ll= \leadsto | l = \lim_{m \mathop \to \infty} \dfrac {n! \left({n + 1}\right) \left({n + 2}\right) \cdots \left({n + m}\right)} {m! m^n} | r = 1 | c = }} {{eqn | ll= \leadsto | l = \lim_{m \mathop \to \infty} \dfrac {m! m^n} {\left({n + 1}\right) \left({n + 2}\right) \cdots \left({n + m}\right)} | r = n! | c = }} {{end-eqn}}	0
Let $r, \alpha \in \C$ be [[Definition:Complex Number|complex numbers]]. Let $z \in \C$ be a [[Definition:Complex Number|complex number]] such that $\left|{z}\right| < 1$. Then: :$\displaystyle \paren {1 + z}^r = \sum_{k \mathop \in \Z} \dbinom r {\alpha + k} z^{\alpha + k}$ where $\dbinom r {\alpha + k}$ denotes a [[Definition:Binomial Coefficient/Complex Numbers|binomial coefficient]].	0
Let $H_n^{\paren r}$ denote the [[Definition:General Harmonic Numbers|general harmonic number]]: :$\displaystyle H_n^{\paren r} = \sum_{k \mathop = 1}^n \frac 1 {k^r}$ for $r \in \R_{>0}$. Let $r > 1$. Then as $n \to \infty$, $H_n^{\paren r}$ is [[Definition:Convergent Series of Numbers|convergent]] with an [[Definition:Upper Bound|upper bound]] of $\dfrac {2^{r - 1} } {2^{r - 1} - 1}$.	0
Evaluating the equation for $\tuple {r, s - t, t, n - 1}$: {{begin-eqn}} {{eqn | l = \sum_{k \mathop \ge 0} \binom {r - t k} k \binom {\paren {s - t} - t \paren {\paren {n - 1} - k} } {\paren {n - 1} - k} \frac r {r - t k} | r = \binom {r + \paren {s - t} - t \paren {n - 1} } {n - 1} | c = }} {{eqn | ll= \leadsto | l = \sum_{k \mathop \ge 0} \binom {r - t k} k \binom {s - t - t n + t + t k} {n - k - 1} \frac r {r - t k} | r = \binom {r + s - t - t n + 1} {n - 1} | c = }} {{eqn | ll= \leadsto | l = \sum_{k \mathop \ge 0} \binom {r - t k} k \binom {s - t \paren {n - k} } {n - k - 1} \frac r {r - t k} | r = \binom {r + s - t n} {n - 1} | c = }} {{end-eqn}} Adding the equation in $\tuple {r, s, t, n}$: {{begin-eqn}} {{eqn | l = \sum_{k \mathop \ge 0} \binom {r - t k} k \paren {\binom {s - t \paren {n - k} } {n - k - 1} + \binom {s - t \paren {n - k} } {n - k} } \frac r {r - t k} | r = \binom {r + s - t n} {n - 1} + \binom {r + s - t n} n | c = }} {{eqn | l = \sum_{k \mathop \ge 0} \binom {r - t k} k \binom {s + 1 - t \paren {n - k} } {n - k } \frac r {r - t k} | r = \binom {r + s + 1 - t n} n | c = [[Pascal's Rule]] }} {{end-eqn}} Hence the equation holds for $\tuple {r, s + 1, t, n}$ {{qed}}	0
From the definition of the [[Definition:Beta Function/Definition 3|Beta function]]: :$\Beta \left({x, y}\right) := \dfrac {\Gamma \left({x}\right) \Gamma \left({y}\right)} {\Gamma \left({x + y}\right)}$ Setting $x = y = \dfrac 1 2$: {{begin-eqn}} {{eqn | l = \Beta \left({\dfrac 1 2, \dfrac 1 2}\right) | r = \frac {\Gamma \left({\dfrac 1 2}\right) \Gamma \left({\dfrac 1 2}\right)} {\Gamma \left({\dfrac 1 2 + \dfrac 1 2}\right)} | c = }} {{eqn | r = \left({\Gamma \left({\dfrac 1 2}\right)}\right)^2 | c = }} {{end-eqn}} Then from [[Beta Function of Half with Half]]: :$\Beta \left({\dfrac 1 2, \dfrac 1 2}\right) = \pi$ Hence the result. {{qed}}	0
{{begin-eqn}} {{eqn | l = \ln \left({G \left({z}\right)}\right) | r = \sum_{k \mathop \ge 1} \left({-1}\right)^{k + 1} \dfrac {S_k z^k} k | c = }} {{end-eqn}}	0
{{refactor|Include this as examples}} {{begin-eqn}} {{eqn | l = \map \phi {714} | r = 192 | c = {{EulerPhiLink|714}} }} {{eqn | l = \map \sigma {714} | r = 1728 | c = {{SigmaLink|714}} }} {{eqn | l = \map \sigma {714} / \map \phi {714} | r = 1728 / 192 | c = }} {{eqn | r = 9 | c = }} {{eqn | r = 3^2 | c = }} {{end-eqn}} {{ProofWanted|Finish this off}}	0
=== Proof of Surjection === Let $a \in G$. By definition of $\iota$: :$\iota(a^{-1}) = \left({a^{-1}}\right)^{-1}$ By [[Inverse of Inverse]]: :$\left({a^{-1}}\right)^{-1} = a$ Hence $a$ has a [[Definition:Preimage of Element under Mapping|preimage]]. Since $a$ was arbitrary, $\iota$ is a [[Definition:Surjection|surjection]]. === Proof of Injection === Suppose for some $a, b \in G$ that: :$\iota \left({a}\right) = \iota \left({b}\right)$ Then by the definition of $\iota$: :$a^{-1} = b^{-1}$ It follows from [[Inverse in Group is Unique]] that: :$a = b$ Hence $\iota$ is an [[Definition:Injection|injection]]. {{qed|lemma}} Hence by definition $\iota$ is a [[Definition:Bijection|bijection]]. A [[Definition:Bijection|bijection]] from a [[Definition:Set|set]] to itself is by definition a [[Definition:Permutation|permutation]]. {{qed}}	0
:$\displaystyle {n \brace n - 2} = \binom {n + 1} 4 + 2 \binom n 4$	0
=== Prime Modulus === $\struct {\Z_m, +, \times}$ is a [[Definition:Commutative Ring with Unity|commutative ring with unity]] by definition. From [[Reduced Residue System under Multiplication forms Abelian Group]], $\struct {\Z'_m, \times}$ is an [[Definition:Abelian Group|abelian group]]. $\Z'_m$ consists of all the elements of $\Z_m$ [[Definition:Coprime Integers|coprime]] to $m$. Now when $m$ is [[Definition:Prime Number|prime]], we have, from [[Reduced Residue System Modulo Prime]]: :$\Z'_m = \set {\eqclass 1 m, \eqclass 2 m, \ldots, \eqclass {m - 1} m}$ That is: :$\Z'_m = \Z_m \setminus \set {\eqclass 0 m}$ where $\setminus$ denotes [[Definition:Set Difference|set difference]]. Hence the result. {{qed|lemma}} === Composite Modulus === Now suppose $m \in \Z: m \ge 2$ is [[Definition:Composite Number|composite]]. From [[Ring of Integers Modulo Composite is not Integral Domain]], $\struct {\Z_m, +, \times}$ is not an [[Definition:Integral Domain|integral domain]]. From [[Field is Integral Domain]] $\struct {\Z_m, +, \times}$ is not a [[Definition:Field (Abstract Algebra)|field]]. {{qed}}	0
:$\floor {-\dfrac 1 2} = -1$	0
Let $a, b \in \Z$. Then: {{begin-eqn}} {{eqn | l = \map \phi {a + b} | r = \eqclass {a + b} m | c = Definition of $\phi$ }} {{eqn | r = \eqclass a m +_m \eqclass b m | c = {{Defof|Modulo Addition}} }} {{eqn | r = \map \phi a +_m \map \phi b | c = Definition of $\phi$ }} {{end-eqn}} {{begin-eqn}} {{eqn | l = \map \phi {a \times b} | r = \eqclass {a \times b} m | c = Definition of $\phi$ }} {{eqn | r = \eqclass a m \times_m \eqclass b m | c = {{Defof|Modulo Multiplication}} }} {{eqn | r = \map \phi a \times_m \map \phi b | c = Definition of $\phi$ }} {{end-eqn}} Hence $\phi$ is a [[Definition:Ring Homomorphism|ring homomorphism]]. Now let $\eqclass a m \in \Z_m$. By definition of [[Definition:Residue Class|residue class modulo $m$]]: :$\eqclass a m = \set {x \in \Z: \exists k \in \Z: z = a + k m}$ Setting $k = 0$: :$\map \phi a = \eqclass a m$ and so: :$\map {\phi^{-1} } {\eqclass a m} \ne \O$ Thus $\phi$ is a [[Definition:Surjection|surjection]]. Now setting $k = 1$, for example, we have that: :$\map \phi {a + m} = \eqclass a m$ and so: :$\map \phi a = \map \phi {a + m}$. So $\phi$ is specifically not an [[Definition:Injection|injection]]. It follows by definition that $\phi$ is a [[Definition:Ring Epimorphism|ring epimorphism]], but specifically not a [[Definition:Ring Monomorphism|ring monomorphism]]. Next we note that: :$\forall x \in \Z: \map \phi x \in \Z_m$ and so: :$\Img \phi = \Z_m$ Finally, we have that the [[Definition:Kernel of Ring Homomorphism|kernel of $\phi$]] is: :$\map \ker \phi = \set {x \in \Z: \map \phi x = \eqclass 0 m}$ Let $\map \phi x = \eqclass 0 m$ Then $x = 0 + k m$ for some $k \in \Z$. That is, $x \in m \Z$ and so: :$\map \ker \phi \subseteq m \Z$ Now let $x \in m \Z$. Then: :$\exists k \in \Z: x = 0 + k m$ and so by definition: :$\map \phi x = \eqclass 0 m$ So: :$m \Z \subseteq \map \ker \phi$ Hence: :$\map \ker \phi = m \Z$ {{qed}}	0
Let $p$ be a [[Definition:Prime Number|prime number]]. Then: :$0 \le k \le p - 1 \implies \dbinom {p - 1} k \equiv \left({-1}\right)^k \pmod p$ where $\dbinom {p - 1} k$ denotes a [[Definition:Binomial Coefficient|binomial coefficient]].	0
There exist no [[Definition:Row of Pascal's Triangle|rows]] of [[Definition:Pascal's Triangle|Pascal's triangle]] which contain $3$ [[Definition:Integer|integers]] in [[Definition:Harmonic Sequence|harmonic sequence]].	0
From [[Sum of Powers of Positive Integers]]: {{begin-eqn}} {{eqn | l = \sum_{i \mathop = 1}^n i^p | r = 1^p + 2^p + \cdots + n^p | c = }} {{eqn | r = \frac {n^{p + 1} } {p + 1} + \sum_{k \mathop = 1}^p \frac {B_k \, p^{\underline {k - 1} } \, n^{p - k + 1} } {k!} | c = }} {{end-eqn}} where $B_k$ are the [[Definition:Bernoulli Numbers|Bernoulli numbers]]. Setting $p = 2$: {{begin-eqn}} {{eqn | l = \sum_{i \mathop = 1}^n i^2 | r = 1^2 + 2^2 + \cdots + n^2 | c = }} {{eqn | r = \frac {n^{2 + 1} } {2 + 1} + \frac {B_1 \, p^{\underline 0} \, n^2} {1!} + \frac {B_2 \, p^{\underline 1} \, n^1} {2!} | c = }} {{eqn | r = \frac {n^3} 3 + B_1 n^2 + B_2 n | c = {{Defof|Falling Factorial}} and simplification }} {{eqn | r = \frac {n^3} 3 + \frac {n^2} 2 + \frac n 6 | c = {{Defof|Bernoulli Numbers}} }} {{eqn | r = \frac {n \left({n + 1}\right) \left({2 n + 1}\right)} 6 | c = after algebra }} {{end-eqn}} Hence the result. {{qed}}	0
{{begin-eqn}} {{eqn | l = \map \sgn {\frac {a - b} {a + b} } | r = \map \sgn {a - b} \frac 1 {\map \sgn {a + b} } | c = [[Signum Function is Completely Multiplicative]] }} {{eqn | r = \map \sgn {a - b} \map \sgn {a + b} | c = [[Signum Function of Reciprocal]] }} {{eqn | r = \map \sgn {\paren {a - b} \paren {a + b} } | c = [[Signum Function is Completely Multiplicative]] }} {{eqn | r = \map \sgn {a^2 - b^2} | c = [[Difference of Two Squares]] }} {{eqn | r = \map \sgn {\paren {a + b} \paren {a - b} } | c = [[Difference of Two Squares]] }} {{eqn | r = \map \sgn {a + b} \map \sgn {a - b} | c = [[Signum Function is Completely Multiplicative]] }} {{eqn | r = \map \sgn {a + b} \frac 1 {\map \sgn {a - b} } | c = [[Signum Function of Reciprocal]] }} {{eqn | r = \map \sgn {\frac {a + b} {a - b} } | c = [[Signum Function is Completely Multiplicative]] }} {{end-eqn}} {{qed}} [[Category:Real Analysis]] [[Category:Signum Function]] ss7k87h3t6ty6ypqnd7cqi9f1xktmko	0
The [[Square Root of 2|decimal expansion of $\sqrt 2$]] is: :$\sqrt 2 \approx 1.41421 \ 35623 \ 73095 \ 0488 \ldots$ Thus: :$1 < \sqrt 2 \le 2$ Hence $2$ is the [[Definition:Ceiling Function|ceiling]] of $\sqrt 2$ by definition. {{qed}}	0
:$\displaystyle \forall n \in \Z: n \ge 0: \sum_{k \mathop = 0}^n \binom {r + k} k = \binom {r + n + 1} n$	0
:$20^3 = \displaystyle \sum_{k \mathop = 11}^{14} k^3$ That is: :$20^3 = 11^3 + 12^3 + 13^3 + 14^3$	0
Let $m \in \Z_{\ne 0}$ be a non-[[Definition:Zero (Number)|zero]] [[Definition:Integer|integer]]. Let $\N_m = \set {0, 1, 2, \ldots, m - 1}$ denote the [[Definition:Initial Segment of Zero-Based Natural Numbers|initial segment of $\N$]] Then $\N_m$ is a [[Definition:Complete Residue System|complete residue system modulo $m$]].	0
Let $x, y, z \in \R$ be [[Definition:Real Number|real numbers]]. Let $y > 0$. Let $0 \le z < y$. Let: :$\dfrac {x - z} y = k$ for some [[Definition:Integer|integer]] $k$. Then: :$z = x \bmod y$ where $\bmod$ denotes the [[Definition:Modulo Operation|modulo operation]].	0
Let $t \in \R$ be a [[Definition:Real Number|real number]]. Then: :$\cmod {\map \Gamma {\dfrac 1 2 + i t} } = \sqrt {\pi \map \sech {\pi t} }$ where: :$\Gamma$ is the [[Definition:Gamma Function|Gamma function]] :$\sech$ is the [[Definition:Hyperbolic Secant|hyperbolic secant function]].	0
From [[Closed Form for Triangular Numbers]]: : $(1): \quad \displaystyle \map A n := \sum_{i \mathop = 1}^n i = \frac{n \paren {n + 1} } 2$ From [[Sum of Sequence of Squares]]: : $(2): \quad \displaystyle \map B n := \sum_{i \mathop = 1}^n i^2 = \frac{n \paren {n + 1} \paren {2 n + 1} } 6$ Let $\displaystyle \map S n = \sum_{i \mathop = 1}^n i^3$. Then: {{begin-eqn}} {{eqn | l = \map S n | r = n^3 + \paren {n - 1}^3 + \paren {n - 2}^3 + \cdots + 2^3 + 1^3 | c = }} {{eqn | r = \sum_{k \mathop = 0}^{n \mathop - 1} \paren {n - k}^3 | c = }} {{eqn | r = \sum_{k \mathop = 0}^{n \mathop - 1} \paren {n^3 - 3 n^2 k + 3 n k^2 - k^3} | c = }} {{eqn | r = n^4 - 3 n^2 \cdot \map A {n - 1} + 3 n \cdot \map B {n - 1} - \map S {n - 1} | c = }} {{eqn | n = 3 | ll= \leadsto | l = \map S n | r = n^4 - 3 n^2 \cdot \frac {n \paren {n - 1} } 2 + 3n \cdot \frac{n \paren {n - 1} \paren {2 n - 1} } 6 - \map S {n - 1} | c = substituting from $(1)$ and $(2)$ }} {{eqn | n = 4 | l = \map S n | r = n^3 + \map S {n - 1} | c = recursive definition }} {{eqn | ll= \leadsto | l = 2 \map S n | r = n^4 + n^3 - 3 n^2 \cdot \frac {n \paren {n - 1} } 2 + 3 n \cdot \frac {n \paren {n - 1} \paren {2 n - 1} } 6 | c = adding $(3)$ and $(4)$ }} {{eqn | ll= \leadsto | r = \frac {n^2 \paren {n + 1}^2} 2 | c = simplification }} {{eqn | ll= \leadsto | l = \map S n | r = \frac {n^2 \paren {n + 1}^2} 4 | c = }} {{end-eqn}} {{qed}}	0
=== [[Dixon's Identity/Gaussian Binomial Form/Formulation 1|Formulation 1]] === {{:Dixon's Identity/Gaussian Binomial Form/Formulation 1}} === [[Dixon's Identity/Gaussian Binomial Form/Formulation 2|Formulation 2]] === {{:Dixon's Identity/Gaussian Binomial Form/Formulation 2}}	0
{{begin-eqn}} {{eqn | l = \lg 32 | o = \le | m = \lg 35 | mo= < | r = \lg 64 | c = }} {{eqn | ll= \leadsto | l = 5 | o = \le | m = \lg 35 | mo= < | r = 6 | c = }} {{end-eqn}} Hence $5$ is the [[Definition:Floor Function|floor]] of $\lg 35$ by definition. {{qed}}	0
Let $\sequence {a_n}$ be the [[Definition:Sequence|sequence]] defined as: : $\forall n \in \N: a_n = r$ for some $r \in \R$. Then the [[Definition:Generating Function|generating function]] for $\sequence {a_n}$ is given as: :$\map G z = \dfrac r {1 - z}$ for $\size z < 1$	0
The [[Definition:Integer Sequence|sequence]] of [[Definition:Integer|integers]] whose [[Definition:Square (Algebra)|squares]] have a [[Definition:Decimal Notation|decimal representation]] consisting of the concatenation of $2$ consecutive increasing [[Definition:Integer|integers]] begins: :$428, 573, 727, 846, 7810, 36 \, 365, 63 \, 636, 326 \, 734, \ldots$ {{OEIS|A030467}}	0
By definition of [[Definition:Signed Stirling Numbers of the First Kind|signed Stirling number of the first kind]]: $\displaystyle x^{\underline 0} = \sum_k s \left({0, k}\right) x^k$ Thus we have: {{begin-eqn}} {{eqn | l = x^{\underline 0} | r = 1 | c = [[Number to Power of Zero Falling is One]] }} {{eqn | r = x^0 | c = Definition of [[Definition:Integer Power|Integer Power]] }} {{end-eqn}} Thus, in the expression: :$\displaystyle x^{\underline 0} = \sum_k s \left({0, k}\right) x^k$ we have: :$s \left({0, 0}\right) = 1$ and for all $k \in \Z_{>0}$: :$s \left({0, k}\right) = 0$ That is: :$s \left({0, k}\right) = \delta_{0 k}$ {{qed}}	0
Add the terms of $H_{p - 1}$ using the definition of [[Definition:Rational Addition|rational addition]] to obtain $\dfrac m n$. Do not cancel common [[Definition:Prime Factor|prime factors]] from $m$ and $n$. It is seen that $n = \paren {p - 1}!$ Hence $p$ is not a [[Definition:Divisor of Integer|divisor]] of $n$. The [[Definition:Numerator|numerator]] $m$ is seen to be: :$m = \dfrac {\paren {p - 1}!} 1 + \dfrac {\paren {p - 1}!} 2 + \cdots + \dfrac {\paren {p - 1}!} {p - 1}$ Thus it is sufficient to show that $m$ is a [[Definition:Multiple of Integer|multiple]] of $p$. Each term in this sum is an integer of the form $\dfrac {\paren {p - 1}!} k$. For each $k \in \set {1, 2, \ldots, p - 1}$, define $k'= - \dfrac {\paren {p - 1}!} k \bmod p$. By [[Wilson's Theorem]] :$k k' \equiv -\paren {p - 1}! \equiv 1 \pmod p$ Therefore :$k' \equiv k^{-1} \pmod p$ From the [[Reduced Residue System under Multiplication forms Abelian Group/Corollary|corollary to Reduced Residue System under Multiplication forms Abelian Group]]: :$\struct {\Z'_p, \times}$ is an [[Definition:Abelian Group|abelian group]]. Since [[Inverse in Group is Unique]], the [[Definition:Set|set]]: :$\set {1', 2', \ldots, \paren {p - 1}'}$ is merely the [[Definition:Set|set]]: :$\set {1, 2, \ldots, p - 1}$ in a different order. Thus {{begin-eqn}} {{eqn | l = m | r = \dfrac {\paren {p - 1}!} 1 + \dfrac {\paren {p - 1}!} 2 + \cdots + \dfrac {\paren {p - 1}!} {p - 1} }} {{eqn | o = \equiv | r = 1 + 2 + \cdots + p - 1 | rr= \pmod p }} {{eqn | o = \equiv | r = \frac {p \paren {p - 1} } 2 | rr= \pmod p | c = [[Closed Form for Triangular Numbers]] }} {{eqn | o = \equiv | r = 0 | rr= \pmod p | c = }} {{end-eqn}} {{qed}}	0
If $n$ is a [[Definition:Square Number|perfect square]] other than $0$, then $n+1$ is not a perfect square.	0
{{begin-eqn}} {{eqn | l = \sqbrk {z^n} \map G z | r = \dfrac 1 {n!} \map {G^{\paren n} } 0 | c = [[Derivative of Generating Function/General Result/Corollary]] }} {{eqn | r = \dfrac 1 {n!} \paren {\dfrac {n!} {2 \pi i} \int_{\partial D} \frac {\map G z} {z^{n + 1} } \d z} | c = [[Cauchy's Integral Formula/General Result]] }} {{eqn | r = \frac 1 {2 \pi i} \oint_{\cmod z \mathop = r} \dfrac {\map G z \d z} {z^{n + 1} } | c = }} {{end-eqn}} {{qed}}	0
From [[Integer as Sum of Three Odd Squares]], $8 n + 3$ is the sum of $3$ [[Definition:Odd Integer|odd]] [[Definition:Square Number|squares]]. So: {{begin-eqn}} {{eqn | lo= \forall n \in \Z_{\ge 0}: | l = 8 n + 3 | r = \paren {2 x + 1}^2 + \paren {2 y + 1}^2 + \paren {2 z + 1}^2 | c = for some $x, y, z \in \Z_{\ge 0}$ }} {{eqn | r = 4 x^2 + 4 x + 4 y^2 + 4 y + 4 z^2 + 4 z + 3 | c = }} {{eqn | r = 4 \paren {x \paren {x + 1} + y \paren {y + 1} + z \paren {z + 1} } + 3 | c = }} {{eqn | ll= \leadsto | l = n | r = \frac {x \paren {x + 1} } 2 + \frac {y \paren {y + 1} } 2 + \frac {z \paren {z + 1} } 2 | c = subtracting $3$ and dividing both sides by $8$ }} {{end-eqn}} By [[Closed Form for Triangular Numbers]], each of $\dfrac {x \paren {x + 1} } 2$, $\dfrac {y \paren {y + 1} } 2$ and $\dfrac {z \paren {z + 1} } 2$ are [[Definition:Triangular Number|triangular numbers]]. {{qed}}	0
We have: {{begin-eqn}} {{eqn | l = 1^2 + 2^2 + 3^2 + \cdots + 24^2 | r = \dfrac {24 \times \paren {24 + 1} \times \paren {2 \times 24 + 1} } 6 | c = [[Sum of Sequence of Squares]] }} {{eqn | r = \dfrac {24 \times 25 \times 49} 6 | c = }} {{eqn | r = \dfrac {2^3 \times 3 \times 5^2 \times 7^2} {2 \times 3} | c = }} {{eqn | r = 2^2 \times 5^2 \times 7^2 | c = }} {{eqn | r = \paren {2 \times 5 \times 7}^2 | c = }} {{eqn | r = 70^2 | c = }} {{end-eqn}} and: {{begin-eqn}} {{eqn | l = 18^2 + 19^2 + \cdots + 28^2 | r = \dfrac {28 \times \paren {28 + 1} \times \paren {2 \times 28 + 1} } 6 - \dfrac {17 \times \paren {17 + 1} \times \paren {2 \times 17 + 1} } 6 | c = [[Sum of Sequence of Squares]] }} {{eqn | r = \dfrac {28 \times 29 \times 57 - 17 \times 18 \times 35} 6 | c = }} {{eqn | r = \dfrac {\paren {2^2 \times 7} \times 29 \times \paren {3 \times 19} - 17 \times \paren {2 \times 3^2} \times \paren {5 \times 7} } {2 \times 3} | c = }} {{eqn | r = 2 \times 7 \times 29 \times 19 - 17 \times 3 \times 5 \times 7 | c = }} {{eqn | r = 7 \times \paren {1102 - 255} | c = }} {{eqn | r = 7 \times 847 | c = }} {{eqn | r = 7 \times 7 \times 11^2 | c = }} {{eqn | r = 77^2 | c = }} {{end-eqn}} and: {{begin-eqn}} {{eqn | l = 25^2 + 26^2 + \cdots + 624^2 | r = \dfrac {624 \times \paren {624 + 1} \times \paren {2 \times 624 + 1} } 6 - \dfrac {24 \times \paren {24 + 1} \times \paren {2 \times 24 + 1} } 6 | c = [[Sum of Sequence of Squares]] }} {{eqn | r = \dfrac {624 \times 625 \times 1249 - 24 \times 25 \times 49} 6 | c = }} {{eqn | r = \dfrac {\paren {2^4 \times 3 \times 13} \times 5^4 \times 1249 - \paren {2^3 \times 3} \times 5^2 \times 7^2} {2 \times 3} | c = }} {{eqn | r = 2^3 \times 5^4 \times 13 \times 1249 - 2^2 \times 5^2 \times 7^2 | c = }} {{eqn | r = 2^2 \times 5^2 \times \paren {2 \times 5^2 \times 13 \times 1249 - 7^2} | c = }} {{eqn | r = 2^2 \times 5^2 \times \paren {811 \, 850 - 49} | c = }} {{eqn | r = 2^2 \times 5^2 \times \paren {811 \, 801} | c = }} {{eqn | r = 2^2 \times 5^2 \times \paren {17^2 \times 53^2} | c = }} {{eqn | r = 9010^2 | c = }} {{end-eqn}} {{qed}}	0
:$\floor {\sqrt 5} = 2$	0
Let $S$ be a [[Definition:Set|set]]. Let $S^S$ be the [[Definition:Set of All Mappings|set of all mappings]] from $S$ to itself Let $\struct {\Gamma \paren S, \circ}$ denote the [[Definition:Symmetric Group|symmetric group on $S$]]. Let $\struct {S^S, \circ}$ be the [[Definition:Monoid|monoid]] of [[Definition:Self-Map|self-maps]] under [[Definition:Composition of Mappings|composition of mappings]]. Then $\struct {\Gamma \paren S, \circ}$ is a [[Definition:Subgroup|subgroup]] of $\struct {S^S, \circ}$.	0
From [[Newton-Girard Formulas]]: :$\displaystyle \sum_{a \mathop \le j_1 \mathop < \cdots \mathop < j_m \mathop \le b} x_{j_1} \cdots x_{j_m} = \sum_{\substack {k_1, k_2, \ldots, k_m \mathop \ge 0 \\ k_1 \mathop + 2 k_2 \mathop + \mathop \cdots \mathop + m k_m \mathop = m} } \dfrac { {S_1}^{k_1} } {1^{k_1} k_1 !} \dfrac {\left({-S_2}\right)^{k_2} } {2^{k_2} k_2 !} \dfrac { {S_3}^{k_3} } {3^{k_3} k_3 !} \cdots \dfrac {\left({\left({-1}\right)^{m + 1} S_m}\right)^{k_m} } {m^{k_m} k_m !}$ where: :$S_r = \displaystyle \sum_{k \mathop = a}^b {x_k}^r$ for $r \in \Z_{\ge 0}$. Setting $m = 3$, and setting $x_i := x_{j_1}, x_j := x_{j_2}, x_k := x_{j_3}$: {{begin-eqn}} {{eqn | l = \sum_{a \mathop < j_1 \mathop < j_2 \mathop < j_3 \mathop \le b} x_{j_1} x_{j_2} x_{j_3} | r = \sum_{\substack {k_1, k_2, k_3 \mathop \ge 0 \\ k_1 \mathop + 2 k_2 \mathop + 3 k_3 \mathop = 3} } \dfrac { {S_1}^{k_1} } {1^{k_1} k_1 !} \dfrac {\left({-S_2}\right)^{k_2} } {2^{k_2} k_2 !} \dfrac { {S_3}^{k_3} } {3^{k_3} k_3 !} | c = }} {{end-eqn}} We need to find all sets of $k_1, k_2, k_3 \in \Z_{\ge 0}$ such that: :$k_1 + 2 k_2 + 3 k_3 = 3$ Thus $\left({k_1, k_2, k_3}\right)$ can be: :$\left({3, 0, 0}\right)$ :$\left({1, 1, 0}\right)$ :$\left({0, 0, 1}\right)$ Hence: {{begin-eqn}} {{eqn | l = \sum_{a \mathop \le j_1 \mathop \le j_2 \mathop \le j_3 \mathop \le b} x_{j_1} x_{j_2} x_{j_3} | r = \dfrac { {S_1}^3 \left({-S_2}\right)^0 {S_3}^0} {\left({1^3 \times 3!}\right) \left({2^0 \times 0!}\right) \left({3^0 \times 0!}\right)} + \dfrac { {S_1}^1 \left({-S_2}\right)^1 {S_3}^0} {\left({1^1 \times 1!}\right) \left({2^1 \times 1!}\right) \left({3^0 \times 0!}\right)} + \dfrac { {S_1}^0 \left({-S_2}\right)^0 {S_3}^1} {\left({1^0 \times 0!}\right) \left({2^0 \times 0!}\right) \left({3^1 \times 1!}\right)} | c = }} {{eqn | r = \dfrac { {S_1}^3} 6 - \dfrac {S_1 S_2} 2 + \dfrac {S_3} 3 | c = }} {{end-eqn}} {{qed}}	0
By definition of [[Definition:Modulo 0|modulo $0$]]: :$\forall x \in \R: x \bmod 0 = x$ Hence: :$-100 \bmod 0 = -100$ {{qed}}	0
:$\displaystyle \sum_k \binom r k \binom s {n - k} = \binom {r + s} n$	0
From [[Difference between Two Squares equal to Repunit]], $R_{2n} = x^2 - y^2$ exactly when $R_{2n} = a b$ where $x = \dfrac {a + b} 2$ and $y = \dfrac {a - b} 2$. By the [[Basis Representation Theorem]] {{begin-eqn}} {{eqn | l = R_{2n} | r = \sum_{0 \mathop \le k \mathop < 2 n} 10^k | c = }} {{eqn | r = \sum_{\substack {0 \mathop \le k \mathop < 2 n \\ k \text { even} } } 10^k + \sum_{\substack {0 \mathop \le k \mathop < 2 n \\ k \text { odd} } } 10^k | c = }} {{eqn | r = \sum_{\substack {0 \mathop \le k \mathop < 2 n \\ k \text { even} } } 10^k + 10 \times \sum_{\substack {0 \mathop \le k \mathop < 2 n \\ k \text { even} } } 10^k | c = }} {{eqn | r = \sum_{k \mathop = 0}^{n - 1} 10^{2 k} + 10 \times \sum_{k \mathop = 0}^n 10^{2 k} | c = change of indices }} {{eqn | r = \sum_{k \mathop = 0}^{n - 1} 11 \times 10^{2 k} | c = }} {{eqn | r = 11 \sum_{k \mathop = 0}^{n - 1} 10^{2 k} | c = }} {{eqn | r = 11 \times \underbrace {10101 \ldots 01}_{n \ 1 \text{'s} } | c = }} {{end-eqn}} Thus, let: :$a = \displaystyle \sum_{k \mathop = 0}^{n - 1} \times 10^{2 k}$ :$b = 11$ So: {{begin-eqn}} {{eqn | l = a + b | r = \sum_{k \mathop = 0}^{n - 1} 10^{2 k} + 11 | c = }} {{eqn | r = \sum_{k \mathop = 1}^{n - 1} 10^{2 k} + 12 | c = }} {{eqn | ll= \leadsto | l = \dfrac {a + b} 2 | r = \sum_{k \mathop = 1}^{n - 1} \frac {10^{2 k} } 2 + 6 | c = }} {{eqn | r = \sum_{k \mathop = 1}^{n - 1} 5 \times 10^{2 k - 1} + 6 | c = }} {{eqn | r = \underbrace {5050 \ldots 50}_{n - 1 \ 5 \text{'s} } + 6 | c = }} {{eqn | r = \underbrace{5050 \ldots 56}_{n - 1 \ 5 \text{'s} } | c = }} {{end-eqn}} Similarly: {{begin-eqn}} {{eqn | l = a - b | r = \sum_{k \mathop = 0}^{n - 1} \times 10^{2 k} - 11 | c = }} {{eqn | r = \sum_{k \mathop = 1}^{n - 1} 10^{2 k} - 10 | c = }} {{eqn | ll= \leadsto | l = \dfrac {a - b} 2 | r = \sum_{k \mathop = 1}^{n - 1} \frac {10^{2 k} } 2 - 5 | c = }} {{eqn | r = \sum_{k \mathop = 1}^{n - 1} 5 \times 10^{2 k - 1} - 5 | c = }} {{eqn | r = \underbrace {5050 \ldots 50}_{n - 1 \ 5 \text{'s} } - 5 | c = }} {{eqn | r = \underbrace{5050 \ldots 45}_{n - 1 \ 5 \text{'s} } | c = }} {{end-eqn}} Hence the result. {{qed}} [[Category:Difference between Two Squares equal to Repunit]] 6a93mucf5ecaddxmcog2ma01dprm4w5	0
Follows from [[Factorial as Product of Two Factorials]]: :$10! = 6! \times 7!$ and so: :$\dfrac {10!} {7!} = 10 \times 9 \times 8 = 6 \times 5 \times 4 \times 3 \times 2 \times 1$ Hence the result. {{qed}}	0
Let $\gamma$ denote the [[Definition:Euler-Mascheroni Constant|Euler-Mascheroni constant]]. Let $\map \zeta s$ denote the [[Definition:Riemann Zeta Function|Riemann zeta function]]. Let $\map \Gamma z$ denote the [[Definition:Gamma Function|gamma function]]. Let $\Log$ denote the [[Definition:Natural Logarithm|natural logarithm]]. Then $\map \Log {\map \Gamma z}$ has the [[Definition:Power Series|power series expansion]]: {{begin-eqn}} {{eqn | l = \map \Log {\map \Gamma z} | r = -\map \gamma {z - 1} + \sum_{k \mathop = 2}^\infty \frac {\paren {-1}^k \map \zeta k} k \paren {z - 1}^k }} {{end-eqn}} which is valid for all $z \in \C$ such that $\cmod {z - 1} < 1$.	0
From [[Polynomial x^p - x is Congruent mod p to x to the p-1 Rising]]: :$x^{\overline p} \equiv x^p - x$ {{TheoremWanted|The above is Knuth 4.6.2-6}} Thus from [[Sum over k of Unsigned Stirling Numbers of First Kind by x^k]]: :$\displaystyle \left[{p \atop k}\right] \equiv \delta_{k p} - \delta _{k 1}$ where: :$\displaystyle \left[{p \atop k}\right]$ denotes an [[Definition:Unsigned Stirling Numbers of the First Kind|unsigned Stirling number of the first kind]] :$\delta$ is the [[Definition:Kronecker Delta|Kronecker delta]]. The result follows from [[Harmonic Number as Unsigned Stirling Number of First Kind over Factorial]]. {{finish|Considerable work is needed to explain some of the above. For a start, the result in 4.6.2-6 appears to be for the falling, not rising, factorial, which looks on the surface like a mistake.}}	0
Let $\sequence {a_n}$ be the [[Definition:Sequence|sequence]] defined as: : $\forall n \in \N_{> 0}: a_n = n - 1$ That is: :$\sequence {a_n} = 0, 1, 2, 3, 4, \ldots$ Then the [[Definition:Generating Function|generating function]] for $\sequence {a_n}$ is given as: :$G \paren z = \dfrac 1 {\paren {1 - z}^2}$	0
:$\displaystyle \sum_{i \mathop = 1}^n i^5 + \sum_{i \mathop = 1}^n i^7 = 2 \paren {\sum_{i \mathop = 1}^n i}^4$	0
{{begin-eqn}} {{eqn | l = 1 | r = \dfrac {1 \paren {3 \times 1 - 1} } 2 | c = [[Closed Form for Pentagonal Numbers]] }} {{eqn | r = 1 \paren {2 \times 1 - 1} | c = [[Closed Form for Hexagonal Numbers]] }} {{end-eqn}} {{begin-eqn}} {{eqn | l = 40 \, 755 | r = \dfrac {165 \paren {3 \times 165 - 1} } 2 | c = [[Closed Form for Pentagonal Numbers]] }} {{eqn | r = 143 \paren {2 \times 143 - 1} | c = [[Closed Form for Hexagonal Numbers]] }} {{end-eqn}} {{ProofWanted|It remains to be shown that these are the only such instances.}}	0
Let $n_1, n_2, \ldots, n_r$ be [[Definition:Positive Integer|positive integers]] such that $n_i \perp n_j$ for all $i \ne j$ (that is, $\gcd \left\{{n_i, n_j}\right\} = 1$). Let $N = n_1 \cdots n_r$. For an integer $k$, let $\Z / k \Z$ denote the [[Definition:Ring of Integers Modulo m|ring of integers modulo $k$]]. Then we have a [[Definition:Ring Isomorphism|ring isomorphism]]: :$\Z / N \Z \simeq \Z / n_1 \Z \times \cdots \times \Z / n_r \Z$	0
Let $r$ be a [[Definition:Square Number|square number]]. Let $r = s t$ where $s$ and $t$ are [[Definition:Coprime Integers|coprime]]. Then both $s$ and $t$ are [[Definition:Square Number|square]].	0
We have: {{begin-eqn}} {{eqn | l = 232 | r = 14^2 + 6^2 | c = }} {{eqn | l = 233 | r = 13^2 + 8^2 | c = }} {{eqn | l = 234 | r = 15^2 + 3^2 | c = }} {{end-eqn}} {{ProofWanted|It remains to be shown this is the smallest such triple.}}	0
From the definition of [[Definition:Modulo Addition|addition modulo $z$]], we have: :$\eqclass x z +_z \eqclass y z = \eqclass {x + y} z$ As $x, y \in R$, we have that $x + y \in \R$ as [[Real Addition is Closed]]. Hence by definition of [[Definition:Congruence (Number Theory)|congruence]], $\eqclass {x + y} z \in \R_z$. {{qed}}	0
:$x - \floor x \in \hointr 0 1$	0
{{begin-eqn}} {{eqn | l = \sum_{i \mathop = 1}^n i^3 | r = \frac {n^2 \paren {n + 1}^2} 4 | c = [[Sum of Sequence of Cubes]] }} {{eqn | r = \paren {\frac {n \paren {n + 1} } 2}^2 | c = }} {{eqn | r = {T_n}^2 | c = [[Closed Form for Triangular Numbers]] }} {{end-eqn}} {{qed}}	0
Let $a, b \in \R$ and $m \in \Z$. Let $a$ be [[Definition:Congruence Modulo Integer|congruent to $b$ modulo $m$]], that is: :$a \equiv b \pmod m$ Then: :$\forall n \in \Z_{\ge 0}: a^n \equiv b^n \pmod m$	0
{{begin-eqn}} {{eqn | l = C_n | r = 3 n \paren {n - 1} + 1 | c = [[Closed Form for Centered Hexagonal Numbers]] }} {{eqn | r = 6 \paren {\dfrac {\paren {n - 1} n} 2} + 1 | c = }} {{eqn | r = 6 T_{n - 1} + 1 | c = [[Closed Form for Triangular Numbers]] }} {{end-eqn}} {{qed}}	0
For all $r \in \R, k \in \Z$: :$k \dbinom r k = r \dbinom {r - 1} {k - 1}$ where $\dbinom r k$ is a [[Definition:Binomial Coefficient|binomial coefficient]]. Hence: :$\dbinom r k = \dfrac r k \dbinom {r - 1} {k - 1}$ (if $k \ne 0$) and: :$\dfrac 1 r \dbinom r k = \dfrac 1 k \dbinom {r - 1} {k - 1}$ (if $k \ne 0$ and $r \ne 0$)	0
Let $x \in \R$. Then: :$\floor x + \floor {-x} = \begin{cases} 0 & : x \in \Z \\ -1 & : x \notin \Z \end{cases}$ where $\floor x$ denotes the [[Definition:Floor Function|floor]] of $x$.	0
:$\dbinom 1 n = \begin{cases} 1 & : n \in \left\{ {0, 1}\right\} \\ 0 & : \text {otherwise} \end{cases}$	0
Let $S = \sequence {s_n}$ be the [[Definition:Integer Sequence|integer sequence]] defined as: :$\displaystyle s_n = \sum_{i \mathop = 1}^n {p_i}^2$ where $P_i$ denotes the $i$th [[Definition:Prime Number|prime number]]. Then $S$ begins: :$4, 13, 38, 87, 208, 377, 666, 1027, 1556, 2397, 3358, 4727, 6408, 8257, 10466, \ldots$ {{OEIS|A024450}}	0
Let $n \in \Z_{>0}$ be a [[Definition:Strictly Positive Integer|(strictly) positive integer]]. Let $p$ be a [[Definition:Prime Number|prime number]]. Let $n$ be expressed in [[Definition:Number Base|base $p$ representation]]. Let $r$ be the [[Definition:Digit Sum|digit sum]] of the representation of $n$ in [[Definition:Number Base|base $p$]]. Then $n!$ is [[Definition:Divisor of Integer|divisible]] by $p^\mu$ but not by $p^{\mu + 1}$, where: :$\mu = \dfrac {n - r} {p - 1}$	0
Let $b \in \N_{>1}$ be a [[Definition:Natural Number|natural number]] greater than $1$. An '''$n$-digit integer base $b$''' is an [[Definition:Integer|integer]] which has no more than $n$ [[Definition:Digit|digits]] when expressed in [[Definition:Number Base|base $b$]]. That is, it is strictly less than $b^n$.	0
First some [[Definition:Lemma|lemmata]]: === [[Integer as Sum of Polygonal Numbers/Lemma 1|Lemma 1]] === {{:Integer as Sum of Polygonal Numbers/Lemma 1}}{{qed|lemma}} === [[Integer as Sum of Polygonal Numbers/Lemma 2|Lemma 2]] === {{:Integer as Sum of Polygonal Numbers/Lemma 2}}{{qed|lemma}} === [[Integer as Sum of Polygonal Numbers/Lemma 3|Lemma 3]] === {{:Integer as Sum of Polygonal Numbers/Lemma 3}}{{qed|lemma}} First note that [[Cauchy's Lemma (Number Theory)]] gives us: {{:Cauchy's Lemma (Number Theory)}}{{qed|lemma}} Now we consider the numbered statements as asserted. For $(1)$, we have [[Integer is Sum of Three Triangular Numbers]]. For $(2)$, we have [[Lagrange's Four Square Theorem]]. For each $m \ge 3$, we prove that $n$ is the [[Definition:Integer Addition|sum]] of at most $m + 2$ [[Definition:Polygonal Number|polygonal numbers of order $m + 2$]]. We choose to consider [[Definition:Polygonal Number|polygonal numbers of order $m + 2$]], rather than [[Definition:Polygonal Number|$m$-gonal numbers]], because the former have a neater [[Closed Form for Polygonal Numbers|closed form]]: :$\map P {m + 2, k} = \dfrac m 2 \paren {k^2 - k} + k$ For $n < 116 m$ the result is shown in [[Integer as Sum of Polygonal Numbers/Lemma 1|Lemma 1]]. It remains to investigate the [[Definition:Integer|integers]] $n \ge 116 m$. Define: :$I = \openint {\dfrac 2 3 + \sqrt {8 \paren {\dfrac n m} - 8} } {\dfrac 1 2 + \sqrt {6 \paren {\dfrac n m} - 3} }$ By [[Integer as Sum of Polygonal Numbers/Lemma 2|Lemma 2]]: :For $\dfrac n m \ge 116$, the [[Definition:Length of Real Interval|length]] of $I$ is greater than $4$. Thus $I$ must contain at least $2$ consecutive [[Definition:Odd Integer|odd integers]]. Let $b_1, b_2$ be those consecutive [[Definition:Odd Integer|odd integers]]. Because $b_1 + m - 1 = b_2 + m - 3$: :the [[Definition:Set|set]] $\set {b + r: b \in \set {b_1, b_2}, r \in \set {0, 1, \dots, m - 2} }$ contains a [[Definition:Complete Residue System|complete residue system modulo $m$]]. Hence one can choose some $b, r$ and write $n \equiv b + r \pmod m$. Define: :$a = 2 \paren {\dfrac {n - b - r} m} + b = \paren {1 - \dfrac 2 m} b + 2 \paren {\dfrac {n - r} m}$ Since $m \divides \paren {n - b - r}$ and $b$ is [[Definition:Odd Integer|odd]]: :$a$ is an [[Definition:Odd Integer|odd integer]]. Since $b \in I$, from [[Integer as Sum of Polygonal Numbers/Lemma 3|Lemma 3]] we have: :$b^2 < 4 a$ :$3 a < b^2 + 2 b + 4$ Then by [[Cauchy's Lemma (Number Theory)]], we can write: :$a = s^2 + t^2 + u^2 + v^2$ :$b = s + t + u + v$ for [[Definition:Non-Negative Integer|nonnegative integers]] $s, t, u, v$. Thus: {{begin-eqn}} {{eqn | l = n | r = \frac m 2 \paren {a - b} + b + r | c = From $a = 2 \paren {\dfrac {n - b - r} m} + b$ }} {{eqn | r = \frac m 2 \paren {s^2 + t^2 + u^2 + v^2 - s - t - u - v} + s + t + u + v + r }} {{eqn | r = \paren {\frac m 2 \paren {s^2 - s} + s} + \paren {\frac m 2 \paren {t^2 - t} + t} + \paren {\frac m 2 \paren {u^2 - u} + u} + \paren {\frac m 2 \paren {v^2 - v} + v} + r \times 1 }} {{eqn | r = \map P {m + 2, s} + \map P {m + 2, t} + \map P {m + 2, u} + \map P {m + 2, v} + r \map P {m + 2, 1} }} {{end-eqn}} Since $r \le m - 2$, the above expression comprises at most $m + 2$ [[Definition:Polygonal Number|polygonal numbers of order $m + 2$]]. {{qed}}	0
From [[Sum over k to n of k Choose m by kth Harmonic Number]]: :$\displaystyle \sum_{k \mathop = 1}^n \binom k m H_k = \binom {n + 1} {m + 1} \left({H_{n + 1} - \frac 1 {m + 1} }\right)$ Setting $m = 0$: {{begin-eqn}} {{eqn | l = \sum_{k \mathop = 1}^n \binom k 0 H_k | r = \binom {n + 1} {0 + 1} \left({H_{n + 1} - \frac 1 {0 + 1} }\right) | c = }} {{eqn | ll= \leadsto | l = \sum_{j \mathop = 1}^n H_k | r = \left({n + 1}\right) \left({H_{n + 1} - 1}\right) | c = [[Binomial Coefficient with Zero|Binomial Coefficient with $0$]], [[Binomial Coefficient with One|Binomial Coefficient with $1$]] }} {{eqn | r = \left({n + 1}\right) \left({H_n + \frac 1 {n + 1} - 1}\right) | c = {{Defof|Harmonic Number}} }} {{eqn | r = \left({n + 1}\right) H_n + \left({n + 1}\right) \frac 1 {n + 1} - \left({n + 1}\right) 1 | c = }} {{eqn | r = \left({n + 1}\right) H_n + 1 - \left({n + 1}\right) | c = }} {{eqn | r = \left({n + 1}\right) H_n - n | c = }} {{end-eqn}} {{qed}}	0
Suppose $\dbinom n k$, $\dbinom n {k + 1}$ and $\dbinom n {k + 2}$ are in a [[Definition:Geometric Sequence|geometric sequence]]. Then: {{begin-eqn}} {{eqn | l = \dbinom n {k + 2} / \dbinom n {k + 1} | r = \dbinom n {k + 1} / \dbinom n k | c = {{Defof|Geometric Sequence}} }} {{eqn | l = \paren {\frac {n!} {\paren {n - k - 2}! \paren {k + 2}!} } \paren {\frac {\paren {n - k - 1}! \paren {k + 1}!} {n!} } | r = \paren {\frac {n!} {\paren {n - k - 1}! \paren {k + 1}!} } \paren {\frac {\paren {n - k}! \paren k!} {n!} } | c = {{Defof|Binomial Coefficient}} }} {{eqn | l = \frac {n - k - 1} {k + 2} | r = \frac {n - k} {k + 1} | c = }} {{eqn | l = \paren {n - k - 1} \paren {k + 1} | r = \paren {n - k} \paren {k + 2} | c = }} {{eqn | l = n k - k^2 - k + n -k - 1 | r = n k + 2 n - k^2 - 2 k | c = }} {{eqn | l = n | r = -1 | c = }} {{end-eqn}} Since $n > 0$, no [[Definition:Row of Pascal's Triangle|row]] of [[Definition:Pascal's Triangle|Pascal's triangle]] contains $3$ [[Definition:Integer|integers]] in [[Definition:Geometric Sequence|geometric sequence]]. However, suppose one extends the definition of [[Definition:Binomial Coefficient|binomial coefficients]] to allow $n < 0$. Then by [[Negated Upper Index of Binomial Coefficient]], we have: :$\dbinom {-1} k = \paren {-1}^k$ which indeed forms a [[Definition:Geometric Sequence|geometric sequence]]. {{qed}}	0
By definition, the [[Definition:Integral Form of Gamma Function|Gamma function]] $\Gamma: \R_{> 0} \to \R$ is defined as: :$\displaystyle \Gamma \left({z}\right) = \int_0^{\infty} t^{z - 1} e^{-t} \rd t$ :$\forall z > 0: \Gamma \left({z}\right) > 0$, as an integral of a strictly positive function in $t$. {{explain|A separate page is needed for the above statement}} The function is smooth according to [[Gamma Function is Smooth on Positive Reals]], and :$\displaystyle \forall k \in \N: \Gamma^\left({k}\right) \left({z}\right) = \int_0^{\infty} \ln \left({t}\right)^k t^{z - 1} e^{-t} \, \mathrm d t$ {{explain|Prove the above}} Let $f \left({z}\right) := \ln \left({\Gamma \left({z}\right) }\right)$. :$f$ is smooth because $\Gamma$ is smooth and positive. {{explain|A link to why this follows}} Then: : $f' \left({z}\right) = \dfrac {\Gamma' \left({z}\right)} {\Gamma \left({z}\right)}$ :$f^{\left({2}\right)} \left({z}\right) = \dfrac {\Gamma^{\left(2\right)} \left({z}\right) \Gamma \left({z}\right) - \Gamma' \left({z}\right)^2} {\Gamma \left({z}\right)^2} > 0$ {{explain|Invoke the result that this comes from: Derivative of Quotient or whatever it is}} The [[Definition:Numerator|numerator]] is positive due to the [[Cauchy-Bunyakovsky-Schwarz Inequality/Inner Product Spaces|Cauchy-Bunyakovsky-Schwarz Inequality]] applied to the scalar products: :$\displaystyle \left \langle {g, h} \right \rangle = \int_0^\infty g \left({t}\right) h \left({t}\right) t^{z - 1} e^{-t} \rd t \quad \forall z \gt 0$ applied to $g = \ln$ and $h = 1$. :$\forall z \in \R_{>0}: f^{\left({2}\right)} \left({z}\right) \gt 0 \implies$ $f$ is [[Definition:Convex Real Function|convex]]. {{qed}}	0
We pick the elements of $S$ in any arbitrary order. There are $n$ elements of $S$, so there are $n$ options for the first element. Then there are $n - 1$ elements left in $S$ that we haven't picked, so there are $n-1$ options for the second element. Then there are $n - 2$ elements left, so there are $n - 2$ options for the third element. And so on, to the $r$th element of our selection: we now have $n - \paren {r - 1}$ possible choices. Each mapping is independent of the choices made for all the other mappings, so by the [[Product Rule for Counting]], the total number of ordered selections from $S$: {{begin-eqn}} {{eqn | l = {}^r P_n | r = n \paren {n - 1} \paren {n - 2} \cdots \paren {n - r + 1} }} {{eqn | r = n \paren {n - 1} \paren {n - 2} \ldots \paren {n - r + 1} \dfrac {\paren {n - r}!} {\paren {n - r}!} | c = multiplying [[Definition:Numerator|top]] and [[Definition:Denominator|bottom]] by $\paren {n - r}!$ }} {{eqn | r = \dfrac {n!} {\paren {n - r}!} | c = simplifying the [[Definition:Numerator|numerator]] }} {{end-eqn}} {{qed}}	0
It can be assumed that both $x$ and $y$ are [[Definition:Integer|integers]]. {{begin-eqn}} {{eqn | l = \dbinom {x + y} y | r = \dfrac {\paren {x + y}!} {x! \, y!} | c = }} {{eqn | ll= \leadsto | l = \displaystyle \lim_{x, y \mathop \to \infty} \dbinom {x + y} y | r = \dfrac {\sqrt {2 \pi \paren {x + y} } \paren {\dfrac {x + y} e}^{\paren {x + y} } } {\sqrt {2 \pi x} \paren {\dfrac x e}^x \, \sqrt {2 \pi y} \paren {\dfrac y e}^y} | c = [[Stirling's Formula]] }} {{eqn | r = \dfrac 1 {\sqrt {2 \pi} } \dfrac {\paren {\frac 1 e}^{x + y} } {\paren {\frac 1 e}^x \paren {\frac 1 e}^y} \sqrt {\dfrac {x + y} {x y} } \dfrac {\paren {x + y}^x \paren {x + y}^y} {x^x \, y^y} | c = rearrangement }} {{eqn | r = \dfrac 1 {\sqrt {2 \pi} } \sqrt {\frac 1 x + \frac 1 y} \paren {1 + \dfrac y x}^x \paren {1 + \dfrac x y}^y | c = simplifying }} {{eqn | r = \sqrt {\dfrac 1 {2 \pi} \paren {\frac 1 x + \frac 1 y} } \paren {1 + \dfrac y x}^x \paren {1 + \dfrac x y}^y | c = }} {{end-eqn}} {{qed}}	0
:$x^2 + y^2 = \left({x + \sqrt {2 x y} + y}\right) \left({x - \sqrt {2 x y} + y}\right)$	0
Let $r \in \R$, $m \in \Z$. :$\displaystyle \sum_{k \mathop \in \Z} \binom r k \binom {-r} {m - 2 k} \paren {-1}^{m + k} = \binom r m$	0
By definition, a [[Definition:Cycle Decomposition|cycle decomposition]] of an [[Definition:Element|element]] of $S_n$ is a product of [[Definition:Disjoint Permutations|disjoint]] [[Definition:Cyclic Permutation|cycles]]. === Construction of Disjoint Permutations === Let $\sigma \in S_n$ be a [[Definition:Permutation|permutation]] on $S_n$. Let $\mathcal R_\sigma$ be the [[Definition:Equivalence Relation|equivalence]] defined in [[Permutation Induces Equivalence Relation]]. Let $\N_n$ be used to denote the [[Definition:Initial Segment of One-Based Natural Numbers|(one-based) initial segment of natural numbers]]: :$\N_n = \closedint 1 n = \set {1, 2, 3, \ldots, n}$ Let $\N_n / \mathcal R_\sigma = \set {E_1, E_2, \ldots, E_m}$ be the [[Definition:Quotient Set|quotient set]] of $\N_n$ determined by $\mathcal R_\sigma$. By [[Equivalence Class of Element is Subset]]: :$E \in \N_n / \mathcal R_\sigma \implies E \subseteq \N_n$ For any $E_i \in \N_n / \mathcal R_\sigma$, let $\rho_i: \paren {\N_n \setminus E_i} \to \paren {\N_n \setminus E_i}$ be the [[Definition:Identity Mapping|identity mapping]] on $\N_n \setminus E_i$. By [[Identity Mapping is Permutation]], $\rho_i$ is a [[Definition:Permutation|permutation]]. Also, let $\phi_i = \tuple {E_i, E_i, R}$ be a [[Definition:Relation|relation]] where $R$ is defined as: :$\forall x, y \in E_i: \tuple {x, y} \in R \iff \map \sigma x = y$ It is easily seen that $\phi_i$ is [[Definition:Many-to-One Relation|many to one]]. For all $x \in E_i$: {{begin-eqn}} {{eqn | l = x | o = \mathcal R_\sigma | r = \map \sigma x | c = }} {{eqn | ll= \leadsto | l = \map \sigma x | o = \in | r = E_i | c = }} {{eqn | ll= \leadsto | l = \sigma \sqbrk {E_i} | o = \subseteq | r = E_i | c = }} {{end-eqn}} which shows that $\phi_i$ is [[Definition:Left-Total Relation|left-total]]. It then follows from the definition of a [[Definition:Mapping|mapping]] that $\phi_i: E_i \to E_i$ is a [[Definition:Mapping|mapping]] defined by: :$\map {\phi_i} x = \map \sigma x$ It is seen that $\phi_i$ is an [[Definition:Injection|injection]] because $\sigma$ is an [[Definition:Injection|injection]]. So by [[Injection from Finite Set to Itself is Surjection/Corollary|Injection from Finite Set to Itself is Permutation]], $\phi_i$ is a [[Definition:Permutation|permutation]] on $E_i$. By [[Intersection with Relative Complement is Empty]], $E_i$ and $\N_n \setminus E_i$ are [[Definition:Disjoint Sets|disjoint]]. By [[Union with Relative Complement]]: : $E_i \cup \paren {\N_n \setminus E_i} = \N_n$ So by [[Union of Bijections with Disjoint Domains and Codomains is Bijection]], let the [[Definition:Permutation|permutation]] $\sigma_i \in S_n$ be defined by: :$\map {\sigma_i} x = \map {\paren {\phi_i \cup \rho_i} } x = \begin{cases} \map \sigma x & : x \in E_i \\ x & : x \notin E_i \end{cases}$ By [[Equivalence Classes are Disjoint]], it follows that each of the $\sigma_i$ are [[Definition:Disjoint Permutations|disjoint]]. {{qed|lemma}} === These Permutations are Cycles === It is now to be shown that all of the $\sigma_i$ are [[Definition:Cyclic Permutation|cycles]]. From [[Order of Element Divides Order of Finite Group]], there exists $\alpha \in \Z_{\gt 0}$ such that $\sigma_i^\alpha = e$, and so: :$\map {\sigma_i^\alpha} x = \map e x = x$ By the [[Well-Ordering Principle]], let $k = \min \set {\alpha \in \N_{\gt 0}: \map {\sigma_i^\alpha} x = x}$ Because $\sigma_i$ [[Definition:Fixed Element of Permutation|fixes]] each $y \notin E_i$, it suffices to show that: :$E_i = \set {x, \map {\sigma_i} x, \ldots, \map {\sigma_i^{k - 1} } x}$ for some $x \in E_i$. If $x \in E_i$, then for all $t \in \Z$: :$x \mathrel {\mathcal R_\sigma} \map {\sigma_i^t} x \implies \map {\sigma_i^t} x \in E_i$ It has been shown that: :$(1) \quad \set {x, \map {\sigma_i} x, \ldots, \map {\sigma_i^{k - 1} } x} \subseteq E_i$ Let $x, y \in E_i$. Then: {{begin-eqn}} {{eqn | l = x | o = \mathcal R_\sigma | r = y }} {{eqn | ll= \leadsto | l = \map {\sigma_i^t} x | r = y | c = for some $t \in \Z$, by [[Permutation Induces Equivalence Relation]] }} {{eqn | ll= \leadsto | l = \map {\sigma_i^{k q + r} } x | r = y | c = for some $q \in \Z$, and $0 \le r \lt k$ by the [[Division Theorem]] }} {{eqn | ll= \leadsto | l = \map {\sigma_i^r \sigma_i^{k q} } x | r = y }} {{eqn | ll= \leadsto | l = \map {\sigma_i^r} x | r = y | c = [[Fixed Point of Permutation is Fixed Point of Power]] }} {{end-eqn}} It has been shown that: :$(2) \quad E_i \subseteq \set {x, \map {\sigma_i} x, \ldots, \map {\sigma_i^{k - 1} } x}$ Combining $(1)$ and $(2)$ yields: :$E_i = \set {x, \map {\sigma_i} x, \ldots, \map {\sigma_i^{k - 1} } x}$ {{qed|lemma}} === The Product of These Cycles form the Permutation === Finally, it is now to be shown that $\sigma = \sigma_1 \sigma_2 \cdots \sigma_m$. From the [[Fundamental Theorem on Equivalence Relations]]: :$x \in \N_n \implies x \in E_j$ for some $j \in \set {1, 2, \ldots, m}$. Therefore: {{begin-eqn}} {{eqn | l = \map {\sigma_1 \sigma_2 \cdots \sigma_m} x | r = \map {\sigma_1 \sigma_2 \cdots \sigma_j} x }} {{eqn | r = \map {\sigma_j} x | c = because $\sigma_j \sqbrk {E_j} = E_j$ }} {{eqn | r = \map \sigma x | c = Definition of $\sigma_i$ }} {{end-eqn}} and so existence of a [[Definition:Cycle Decomposition|cycle decomposition]] has been shown. {{qed|lemma}} === Uniqueness of Cycle Decomposition === Take the [[Definition:Cycle Decomposition|cycle decomposition]] of $\sigma$, which is $\sigma_1 \sigma_2 \cdots \sigma_m$. Let $\tau_1 \tau_2 \cdots \tau_s$ be some product of [[Definition:Disjoint Permutations|disjoint]] [[Definition:Cyclic Permutation|cycles]] such that $\sigma = \tau_1 \tau_2 \cdots \tau_s$. It is assume that this product describes $\sigma$ completely and does not contain any duplicate [[Definition:Cyclic Permutation|$1$-cycles]]. Let $x$ be a [[Definition:Moved Element of Permutation|moved element]] of $\sigma$. Then there exists a $j \in \set {1, 2, \ldots, s}$ such that $\map {\tau_j} x \ne x$. And so: {{begin-eqn}} {{eqn | l = \map \sigma x | r = \map {\tau_1 \tau_2 \cdots \tau_j} x }} {{eqn | r = \map {\tau_j} x | c = [[Power of Moved Element is Moved]] }} {{end-eqn}} It has already been shown that $x \in E_i$ for some $i \in \set {1, 2, \ldots, m}$. Therefore: {{begin-eqn}} {{eqn | l = \map {\sigma_i} x | r = \map {\tau_j} x }} {{eqn | l = \map {\sigma_i^2} x | r = \map {\tau_{j \prime} \tau_j} x | c = by [[Power of Moved Element is Moved]] }} {{eqn | r = \map {\tau_j^2} x | c = because $\map {\sigma_i^2} x \ne \map {\sigma_i} x$ and this product is [[Definition:Disjoint Permutations|disjoint]] }} {{eqn | l = \vdots | o = \vdots | r = \vdots }} {{eqn | l = \map {\sigma_i^{k - 1} } x | r = \map {\tau_j^{k - 1} } x }} {{end-eqn}} This effectively shows that $\sigma_i = \tau_j$. Doing this for every $E_i$ implies that $m = s$ and that there exists a $\rho \in S_m$ such that: :$\sigma_{\map \rho i} = \tau_i$ In other words, $\tau_1 \tau_2 \cdots \tau_m$ is just a reordering of $\sigma_1 \sigma_2 \cdots \sigma_m$. {{qed}}	0
Let $a, b, x, y, m \in \Z$. Let: :$a x \equiv b y \pmod m$ and $a \equiv b \pmod m$ where $a \equiv b \pmod m$ denotes that $a$ is [[Definition:Congruence Modulo Integer|congruent modulo $m$]] to $b$. Then: :$x \equiv y \pmod {m / d}$ where $d = \gcd \set {a, m}$.	0
Proof by [[Principle of Mathematical Induction|induction]]: Let $n \in \Z$. For all $m \in \N$, let $\map P m$ be the [[Definition:Proposition|proposition]]: :$\displaystyle \sum_{j \mathop = 0}^m \binom {n + j} n = \binom {n + m + 1} {n + 1}$ $\map P 0$ is true, as this just says: :$\dbinom n n = \dbinom {n + 1} {n + 1}$ But $\dbinom n n = \dbinom {n + 1} {n + 1} = 1$ from the {{Defof|Binomial Coefficient}}. === Basis for the Induction === $\map P 1$ is the case: {{begin-eqn}} {{eqn | l = \sum_{j \mathop = 0}^1 \binom {n + j} n | r = \binom n n + \binom {n + 1} n | c = }} {{eqn | r = 1 + \paren {n + 1} | c = {{Defof|Binomial Coefficient}} }} {{eqn | r = n + 2 | c = }} {{eqn | r = \binom {n + 2} {n + 1} | c = {{Defof|Binomial Coefficient}} }} {{end-eqn}} So: :$\displaystyle \sum_{j \mathop = 0}^1 \binom {n + j} n = \binom {n + 2} {n + 1}$ and $\map P 1$ is seen to hold. This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\displaystyle \sum_{j \mathop = 0}^k \binom {n + j} n = \binom {n + k + 1} {n + 1}$ Then we need to show: :$\displaystyle \sum_{j \mathop = 0}^{k+1} \binom {n + j} n = \binom {n + k + 2} {n + 1}$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \sum_{j \mathop = 0}^{k + 1} \binom {n + j} n | r = \sum_{j \mathop = 0}^k \binom {n + j} n + \binom {n + k + 1} n | c = }} {{eqn | r = \binom {n + k + 1} {n + 1} + \binom {n + k + 1} n | c = [[Rising Sum of Binomial Coefficients#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \binom {n + k + 2} {n + 1} | c = [[Pascal's Rule]] }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\displaystyle \sum_{j \mathop = 0}^m \binom {n + j} n = \binom {n + m + 1} {n + 1}$ Finally, from [[Symmetry Rule for Binomial Coefficients]]: :$\dbinom {n + m + 1} {n + 1} = \dbinom {n + m + 1} m$ {{qed}}	0
{{begin-eqn}} {{eqn | l = {}^{n - 1} P_n | r = \dfrac {n!} {\paren {n - \paren {n - 1} }!} | c = [[Number of Permutations]] }} {{eqn | r = \dfrac {n!} {1!} | c = }} {{eqn | r = n! | c = }} {{eqn | r = {}^n P_n | c = [[Number of Permutations]] }} {{end-eqn}} {{qed}}	0
Let $x = \floor x$. As $\floor x \in \Z$, then so must $x$ be. Now let $x \in \Z$. We have: :$\floor x = \sup \set {m \in \Z: m \le x}$ As $x \in \sup \set {m \in \Z: m \le x}$, and there can be no greater $n \in \Z$ such that $n \in \sup \set {m \in \Z: m \le x}$, it follows that: :$x = \floor x$ {{qed}}	0
=== Necessary Condition === Let $x < n$. By definition of the [[Definition:Floor Function|floor]] of $x$: :$\left \lfloor {x} \right \rfloor \le x$ Hence: :$\left \lfloor {x} \right \rfloor < n$ {{qed|lemma}} === Sufficient Condition === Let $\left \lfloor{x}\right \rfloor < n$. We have that: :$\forall m, n \in \Z: m < n \iff m + 1 \le n$ and so: :$(1): \quad \left \lfloor{x}\right \rfloor + 1 \le n$ Then: {{begin-eqn}} {{eqn | l = x | o = < | r = \left \lfloor{x}\right \rfloor + 1 | c = Definition of [[Definition:Floor Function|Floor Function]] }} {{eqn | o = \le | r = n | c = from $(1)$ }} {{end-eqn}} {{qed|lemma}} Hence the result: :$\left \lfloor{x}\right \rfloor < n \iff x < n$ {{qed}}	0
The [[Definition:Floor Function|floor function]] is a [[Definition:Replicative Function|replicative function]] in the sense that: :$\displaystyle \forall n \in \Z_{> 0}: \sum_{k \mathop = 0}^{n - 1} \left \lfloor{x + \frac k n}\right \rfloor = \left \lfloor{n x}\right \rfloor$	0
:$\forall n \in \Z_{>0}: \dfrac 1 n = \displaystyle \sum_{k \mathop = 0}^{n - 1} \paren {-1}^k \dbinom {n - 1} k \dfrac 1 {k + 1}$ where $\dbinom {n - 1} k$ denotes a [[Definition:Binomial Coefficient|binomial coefficient]]. That is, for example: {{begin-eqn}} {{eqn | l = \dfrac 1 1 | r = 1 }} {{eqn | l = \dfrac 1 2 | r = 1 - \dfrac 1 2 }} {{eqn | l = \dfrac 1 3 | r = 1 - 2 \times \dfrac 1 2 + \dfrac 1 3 }} {{eqn | l = \dfrac 1 4 | r = 1 - 3 \times \dfrac 1 2 + 3 \times \dfrac 1 3 - \dfrac 1 4 }} {{eqn | l = \dfrac 1 5 | r = 1 - 4 \times \dfrac 1 2 + 6 \times \dfrac 1 3 - 4 \times \dfrac 1 4 + \dfrac 1 5 }} {{end-eqn}}	0
{{begin-eqn}} {{eqn | l = n! | r = \sum_{k \mathop \ge 0} \dfrac { {!k} \, n^{\underline k} } {k!} | c = }} {{eqn | r = \dfrac { !0 \times n^{\underline 0} } {0!} + \dfrac { {!1} \times n^{\underline 1} } {1!} + \dfrac { {!2} \times n^{\underline 2} } {2!} + \dfrac { {!3} \times n^{\underline 3} } {3!} + \cdots | c = }} {{eqn | r = 1 + \left({1 - \dfrac 1 {1 !} }\right) n + \left({1 - \dfrac 1 {1 !} + \dfrac 1 {2 !} }\right) n \left({n - 1}\right) + \left({1 - \dfrac 1 {1 !} + \dfrac 1 {2 !} - \dfrac 1 {3 !} }\right) n \left({n - 1}\right) \left({n - 2}\right) + \cdots | c = }} {{end-eqn}}	0
{{begin-eqn}} {{eqn | l = \dbinom n k | o = < | r = \dbinom n {k + 1} }} {{eqn | ll = \leadstoandfrom | l = \frac {n!} {\paren {n - k}! k!} | o = < | r = \frac {n!} {\paren {n - k - 1}! \paren {k + 1}!} | c = {{Defof|Binomial Coefficient}} }} {{eqn | ll = \leadstoandfrom | l = k + 1 | o = < | r = n - k | c = Multiplying both sides by $\dfrac {\paren {n - k}! \paren {k + 1}!} {n!}$ }} {{eqn | ll = \leadstoandfrom | l = 2 k | o = < | r = n - 1 }} {{eqn | ll = \leadstoandfrom | l = k | o = < | r = \frac {n - 1} 2 }} {{end-eqn}} {{qed}}	0
From [[Lagrange's Four Square Theorem]], every [[Definition:Positive Integer|positive integer]] can be expressed as the [[Definition:Integer Addition|sum]] of $4$ [[Definition:Square Number|squares]], some of which may be [[Definition:Zero (Number)|zero]]. The existence of [[Definition:Positive Integer|positive integers]] which cannot be expressed as the [[Definition:Integer Addition|sum]] of $4$ non-[[Definition:Zero (Number)|zero]] [[Definition:Square Number|squares]] is noted by the trivial examples $1$, $2$ and $3$. Thus [[Lagrange's Four Square Theorem]] can be expressed in the form: :$(1): \quad$ Every [[Definition:Positive Integer|positive integer]] can be expressed as the [[Definition:Integer Addition|sum]] of $1$, $2$, $3$ or $4$ non-[[Definition:Zero (Number)|zero]] [[Definition:Square Number|squares]]. We note the following from [[169 as Sum of up to 155 Squares]]: {{begin-eqn}} {{eqn | l = 169 | r = 13^2 | c = }} {{eqn | r = 12^2 + 5^2 | c = }} {{eqn | r = 12^2 + 4^2 + 3^2 | c = }} {{eqn | r = 8^2 + 8^2 + 5^2 + 4^2 | c = }} {{eqn | r = 8^2 + 8^2 + 4^2 + 4^2 + 3^2 | c = }} {{end-eqn}} Let $n > 169$. Then $n$ can be expressed as: :$n = m + 169$ where $m \ge 1$. From $(1)$, $m$ can be expressed as the sum of [[Definition:Integer Addition|sum]] of $1$, $2$, $3$ or $4$ non-[[Definition:Zero (Number)|zero]] [[Definition:Square Number|squares]]. Thus at least one of the following holds: :$m = a^2$ :$m = a^2 + b^2$ :$m = a^2 + b^2 + c^2$ :$m = a^2 + b^2 + c^2 + d^2$ Thus one of the following holds: {{begin-eqn}} {{eqn | l = n | r = a^2 + b^2 + c^2 + d^2 + 13^2 | c = }} {{eqn | l = n | r = a^2 + b^2 + c^2 + 12^2 + 5^2 | c = }} {{eqn | l = n | r = a^2 + b^2 + 12^2 + 4^2 + 3^2 | c = }} {{eqn | l = n | r = a^2 + 8^2 + 8^2 + 5^2 + 4^2 | c = }} {{end-eqn}} It remains to be shown that of the [[Definition:Positive Integer|positive integers]] less than $169$, all but the following can be expressed in this way: :$1, 2, 3, 4, 6, 7, 9, 10, 12, 15, 18, 33$ Note that by [[Integer as Sum of Three Squares]], all integers not of the form: :$4^n \paren {8 m + 7}$ can be written as a sum of $1$, $2$ or $3$ non-[[Definition:Zero (Number)|zero]] [[Definition:Square Number|squares]]. Also note that: {{begin-eqn}} {{eqn | l = 18 | r = 3^2 + 3^2 }} {{eqn | r = 4^2 + 1^2 + 1^2 }} {{eqn | r = 3^2 + 2^2 + 2^2 + 1^2 }} {{end-eqn}} Similar to the above, for $x = y + 18$ where $y \ne 4^n \paren {8 m + 7}$, at least one of the following holds: {{begin-eqn}} {{eqn | l = n | r = a^2 + b^2 + c^2 + 3^2 + 3^2 | c = }} {{eqn | l = n | r = a^2 + b^2 + 4^2 + 1^2 + 1^2 | c = }} {{eqn | l = n | r = a^2 + 3^2 + 2^2 + 2^2 + 1^2 | c = }} {{end-eqn}} the ineligible $0 < y < 151$ are: :$7, 15, 23, 28, 31, 39, 47, 55, 60, 63, 71, 79, 87, 92, 95, 103, 111, 112, 119, 124, 127, 135, 143$ with corresponding $x$: :$25, 33, 41, 46, 49, 57, 65, 73, 78, 81, 89, 97, 105, 110, 113, 121, 129, 130, 137, 142, 145, 153, 161$ for $x > 18$. Similarly, for $45$: {{begin-eqn}} {{eqn | l = 45 | r = 6^2 + 3^2 }} {{eqn | r = 5^2 + 4^2 + 2^2 }} {{eqn | r = 4^2 + 4^2 + 3^2 + 2^2 }} {{end-eqn}} So if we can write $x = y + 45$ where $y \ne 4^n \paren {8 m + 7}$, $x$ can be expressed as a sum of $5$ non-[[Definition:Zero (Number)|zero]] [[Definition:Square Number|squares]]. The ineligible $x > 45$ for $0 < y < 124$ are: :$52, 60, 68, 73, 76, 84, 92, 100, 105, 108, 116, 124, 132, 137, 140, 148, 156, 157, 164$ Comparing both lists, we only need to check: :$x < 18$ and $x = 25, 33, 41, 73, 105, 137$ And we have: {{begin-eqn}} {{eqn | l = 5 | r = 1^2 + 1^2 + 1^2 + 1^2 + 1^2 | c = }} {{eqn | l = 8 | r = 2^2 + 1^2 + 1^2 + 1^2 + 1^2 | c = }} {{eqn | l = 11 | r = 2^2 + 2^2 + 1^2 + 1^2 + 1^2 | c = }} {{eqn | l = 13 | r = 3^2 + 1^2 + 1^2 + 1^2 + 1^2 | c = }} {{eqn | l = 14 | r = 2^2 + 2^2 + 2^2 + 1^2 + 1^2 | c = }} {{eqn | l = 16 | r = 3^2 + 2^2 + 1^2 + 1^2 + 1^2 | c = }} {{eqn | l = 17 | r = 2^2 + 2^2 + 2^2 + 2^2 + 1^2 | c = }} {{eqn | l = 25 | r = 3^2 + 2^2 + 2^2 + 2^2 + 2^2 | c = }} {{eqn | l = 41 | r = 4^2 + 4^2 + 2^2 + 2^2 + 1^2 | c = }} {{eqn | l = 73 | r = 6^2 + 5^2 + 2^2 + 2^2 + 2^2 | c = }} {{eqn | l = 105 | r = 6^2 + 6^2 + 5^2 + 2^2 + 2^2 | c = }} {{eqn | l = 137 | r = 10^2 + 5^2 + 2^2 + 2^2 + 2^2 | c = }} {{end-eqn}} while for the rest: :$1, 2, 3, 4 < 5 \times 1^2$ :$5 \times 1^2 < 6, 7 < 2^2 + 4 \times 1^2$ :$2^2 + 4 \times 1^2 < 9, 10 < 2 \times 2^2 + 3 \times 1^2$ $12, 15, 18, 33$ are [[Definition:Divisor of Integer|divisible]] by $3$. By [[Square Modulo 3]], $n^2 \equiv 0$ or $1 \pmod 3$. We must require the $5$ non-[[Definition:Zero (Number)|zero]] [[Definition:Square Number|squares]] to be equivalent to: :$0, 0, 1, 1, 1 \pmod 3$ The smallest non-[[Definition:Zero (Number)|zero]] [[Definition:Square Number|square]] [[Definition:Divisor of Integer|divisible]] by $3$ is $3^2 = 9$. The sum of the squares must therefore be greater than: :$3^2 + 3^2 = 18$ hence $12, 15, 18$ cannot be expressed as the sum of $5$ non-[[Definition:Zero (Number)|zero]] [[Definition:Square Number|squares]]. Since $6^2 > 33$, we must have $33 = 3^2 + 3^2 + a^2 + b^2 + c^2$. But $15$ cannot be expressed as the sum of $3$ non-[[Definition:Zero (Number)|zero]] [[Definition:Square Number|squares]]: :$15 < 4^2$ :$15 - 3^2 = 6$ is not the sum of $2$ squares :$15 > 3 \times 2^2$ The proves the theorem. {{qed}}	0
By definition of [[Definition:Modulo Operation|modulo operation]]: :$x \bmod y := x - y \left \lfloor {\dfrac x y}\right \rfloor$ for $y \ne 0$. We have: :$\dfrac 5 3 = 1 + \dfrac 2 3$ and so: :$\left\lfloor{\dfrac 5 3}\right\rfloor = 1$ Thus: :$5 \bmod 3 = 5 - 3 \times \left\lfloor{\dfrac 5 3}\right\rfloor = 5 - 3 \times 1 = 2$ {{qed}}	0
Let $I_n$ be defined as: :$\displaystyle I_n = \int_0^{\frac \pi 2} \sin^n x \rd x$ Then: :$\displaystyle \lim_{n \mathop \to \infty} \frac {I_{2 n} } {I_{2 n + 1} } = 1$	0
We have: :$H_{12 \, 366} = \displaystyle \sum_{k \mathop = 1}^{12 \, 366} \frac 1 k \approx 9 \cdotp 99996 \, 214$ and: :$H_{12 \, 367} = \displaystyle \sum_{k \mathop = 1}^{12 \, 367} \frac 1 k \approx 10 \cdotp 00004 \, 30083$	0
Let $\struct {G, \circ}$ be a [[Definition:Finite Group|finite group]] whose [[Definition:Identity Element|identity element]] is $e$. Then $\struct {G, \circ}$ is [[Definition:Cyclic Group|cyclic]] of [[Definition:Order of Structure|order $n$]] {{iff}} $\struct {G, \circ}$ is [[Definition:Group Isomorphism|isomorphic]] with the [[Definition:Additive Group of Integers Modulo m|additive group of integers modulo $n$]] $\struct {\Z_n, +_n}$.	0
The [[Definition:Decimal Notation|decimal representation]] of the following [[Definition:Square Number|square numbers]] can be split into two parts which are each themselves [[Definition:Square Number|square]]: {{begin-eqn}} {{eqn | l = 7^2 | r = 49 | c = $4 = 2^2$, | cc= $9 = 3^2$ }} {{eqn | l = 13^2 | r = 169 | c = $16 = 4^2$, | cc= $9 = 3^2$ }} {{eqn | l = 19^2 | r = 361 | c = $36 = 6^2$, | cc= $1 = 1^2$ }} {{eqn | l = 35^2 | r = 1225 | c = $1 = 1^2$, | cc= $225 = 15^2$ }} {{eqn | l = 38^2 | r = 1444 | c = $144 = 12^2$, | cc= $4 = 2^2$ }} {{eqn | l = 41^2 | r = 1681 | c = $16 = 4^2$, | cc= $81 = 9^2$ }} {{eqn | l = 57^2 | r = 3249 | c = $324 = 18^2$, | cc= $9 = 3^2$ }} {{eqn | l = 65^2 | r = 4225 | c = $4 = 2^2$, | cc= $225 = 15^2$ }} {{eqn | l = 70^2 | r = 4900 | c = $4 = 2^2$, | cc= $900 = 30^2$ }} {{eqn | l = 125^2 | r = 15 \, 625 | c = $1 = 1^2$, | cc= $5625 = 75^2$ }} {{eqn | l = 130^2 | r = 16 \, 900 | c = $16 = 4^2$, | cc= $900 = 30^2$ }} {{eqn | l = 190^2 | r = 36 \, 100 | c = $36 = 6^2$, | cc= $100 = 10^2$ }} {{eqn | l = 205^2 | r = 42 \, 025 | c = $4 = 2^2$, | cc= $2025 = 45^2$ }} {{eqn | l = 223^2 | r = 49 \, 729 | c = $49 = 7^2$, | cc= $729 = 27^2$ }} {{end-eqn}} {{OEIS|A048375}}	0
Let $n \in \Z_{>0}$ be a [[Definition:Strictly Positive Integer|(strictly) positive integer]]. Let $2 n^2 \pm 1 = m^2$ be a [[Definition:Square Number|square number]]. Then $\paren {m n}^2$ is a [[Definition:Triangular Number|triangular number]].	0
This [[Definition:Set|set]] of $5$ [[Definition:Integer|integers]] has the property that the [[Definition:Integer Addition|sum]] of any $3$ of them is [[Definition:Square Number|square]]: {{begin-eqn}} {{eqn | l = 26 \, 072 \, 323 \, 311 \, 568 \, 661 \, 931 | o = }} {{eqn | l = 43 \, 744 \, 839 \, 742 \, 282 \, 591 \, 947 | o = }} {{eqn | l = 118 \, 132 \, 654 \, 413 \, 675 \, 138 \, 222 | o = }} {{eqn | l = 186 \, 378 \, 732 \, 807 \, 587 \, 076 \, 747 | o = }} {{eqn | l = 519 \, 650 \, 114 \, 814 \, 905 \, 002 \, 347 | o = }} {{end-eqn}}	0
Let $n \in \Z_{> 0}$ be a [[Definition:Strictly Positive Integer|strictly positive integer]]. Let $b \in \Z$ such that $b \ge 2$. Then: :$\displaystyle \sum_{k \mathop = 1}^n \left \lfloor{\sqrt k}\right \rfloor = \left \lfloor{\sqrt n}\right \rfloor \left({n - \dfrac {\left({2 \left \lfloor{\sqrt n}\right \rfloor + 5}\right) \left({\left \lfloor{\sqrt n}\right \rfloor - 1}\right)} 6 }\right)$	0
{{ProofWanted|research and invoke [[Wolstenholme's Theorem]]}}	0
{{begin-eqn}} {{eqn | l = \int \frac {\d x} {\csc a x} | r = \int \sin a x \rd x | c = [[Cosecant is Reciprocal of Sine]] }} {{eqn | r = \frac {-\cos a x} a + C | c = [[Primitive of Sine of a x|Primitive of $\sin a x$]] }} {{end-eqn}} {{qed}}	0
Let $\triangle ABC$ be a [[Definition:Right Spherical Triangle|right spherical triangle]] such that the [[Definition:Spherical Angle|angle]] $\sphericalangle C$ is a [[Definition:Right Angle|right angle]]. :[[File:Right-spherical-triangle.png|500px]] Let the remaining parts of $\triangle ABC$ be arranged according to the '''interior''' of the [[Definition:Circle|circle]] above, where the [[Definition:Symbol|symbol]] $\Box$ denotes a [[Definition:Right Angle|right angle]]. ==== $\sin a$ ==== {{begin-eqn}} {{eqn | l = \cos a \cos C | r = \sin a \cot b - \sin C \cot B | c = [[Four-Parts Formula]] on $B, a, C, b$ }} {{eqn | ll= \leadsto | l = \cos a \times 0 | r = \sin a \cot b - 1 \times \cot B | c = [[Cosine of Right Angle]], [[Sine of Right Angle]] as $C = \Box$ }} {{eqn | ll= \leadsto | l = \sin a \cot b | r = \cot B | c = }} {{eqn | ll= \leadsto | l = \sin a | r = \tan b \cot B | c = multiplying both sides by $\tan b = \dfrac 1 {\cot b}$ }} {{eqn | ll= \leadsto | l = \sin a | r = \tan b \, \map \tan {\Box - B} | c = [[Tangent of Complement equals Cotangent]] }} {{end-eqn}} {{qed|lemma}} ==== $\sin b$ ==== {{begin-eqn}} {{eqn | l = \cos b \cos C | r = \sin b \cot a - \sin C \cot A | c = [[Four-Parts Formula]] on $a, C, b, A$ }} {{eqn | ll= \leadsto | l = \cos b \times 0 | r = \sin b \cot a - 1 \times \cot A | c = [[Cosine of Right Angle]], [[Sine of Right Angle]] as $C = \Box$ }} {{eqn | ll= \leadsto | l = \sin b \cot a | r = \cot A | c = }} {{eqn | ll= \leadsto | l = \sin b | r = \tan a \cot A | c = multiplying both sides by $\tan a = \dfrac 1 {\cot a}$ }} {{eqn | ll= \leadsto | l = \sin b | r = \tan a \, \map \tan {\Box - A} | c = [[Tangent of Complement equals Cotangent]] }} {{end-eqn}} {{qed|lemma}} ==== $\map \sin {\Box - A}$ ==== {{begin-eqn}} {{eqn | l = \sin a \cos C | r = \cos c \sin b - \sin c \cos b \cos A | c = [[Analogue Formula for Spherical Law of Cosines]] for [[Definition:Spherical Angle|angle]] $A$ }} {{eqn | ll= \leadsto | l = \sin a \times 0 | r = \cos c \sin b - \sin c \cos b \cos A | c = [[Cosine of Right Angle]] as $C = \Box$ }} {{eqn | ll= \leadsto | l = \sin c \cos b \cos A | r = \cos c \sin b | c = }} {{eqn | ll= \leadsto | l = \cos A | r = \cot c \tan b | c = dividing both sides by $\sin c \cos b$ }} {{eqn | ll= \leadsto | l = \map \sin {\Box - A} | r = \map \tan {\Box - c} \tan b | c = [[Sine of Complement equals Cosine]], [[Tangent of Complement equals Cotangent]] }} {{end-eqn}} {{qed|lemma}} ==== $\map \sin {\Box - c}$ ==== {{begin-eqn}} {{eqn | l = \cos C | r = -\cos A \cos B + \sin A \sin B \cos c | c = [[Spherical Law of Cosines/Angles|Spherical Law of Cosines]] for [[Definition:Spherical Angle|angle]] $C$ }} {{eqn | ll= \leadsto | l = 0 | r = -\cos A \cos B + \sin A \sin B \cos c | c = [[Cosine of Right Angle]] as $C = \Box$ }} {{eqn | ll= \leadsto | l = \sin A \sin B \cos c | r = \cos A \cos B | c = }} {{eqn | ll= \leadsto | l = \cos c | r = \cot A \cot B | c = dividing both sides by $\sin A \sin B$ }} {{eqn | ll= \leadsto | l = \map \sin {\Box - c} | r = \map \tan {\Box - A} \, \map \tan {\Box - B} | c = [[Sine of Complement equals Cosine]], [[Tangent of Complement equals Cotangent]] }} {{end-eqn}} {{qed|lemma}} ==== $\map \sin {\Box - B}$ ==== {{begin-eqn}} {{eqn | l = \sin b \cos C | r = \cos c \sin a - \sin c \cos a \cos B | c = [[Analogue Formula for Spherical Law of Cosines]] for [[Definition:Spherical Angle|angle]] $B$ }} {{eqn | ll= \leadsto | l = \sin b \times 0 | r = \cos c \sin a - \sin c \cos a \cos B | c = [[Cosine of Right Angle]] as $C = \Box$ }} {{eqn | ll= \leadsto | l = \sin c \cos a \cos B | r = \cos c \sin a | c = }} {{eqn | ll= \leadsto | l = \cos B | r = \cot c \tan a | c = dividing both sides by $\sin c \cos a$ }} {{eqn | ll= \leadsto | l = \map \sin {\Box - B} | r = \map \tan {\Box - c} \tan a | c = [[Sine of Complement equals Cosine]], [[Tangent of Complement equals Cotangent]] }} {{end-eqn}} {{qed}}	0
Let the [[Definition:Radius Vector|radius vector]] $\mathbf r$ from the [[Definition:Origin|origin]] to $p$ be expressed as: :$(1): \quad \mathbf r = r \mathbf u_r$ :[[File:MotionInPolarPlane.png|600px]] From [[Derivatives of Unit Vectors in Polar Coordinates]]: {{begin-eqn}} {{eqn | n = 2 | l = \dfrac {\mathrm d \mathbf u_r} {\mathrm d \theta} | r = \mathbf u_\theta | c = }} {{eqn | n = 3 | l = \dfrac {\mathrm d \mathbf u_\theta} {\mathrm d \theta} | r = -\mathbf u_r | c = }} {{end-eqn}} From [[Velocity Vector in Polar Coordinates]]: :$\mathbf v = r \dfrac {\mathrm d \theta} {\mathrm d t} \mathbf u_\theta + \dfrac {\mathrm d r} {\mathrm d t} \mathbf u_r$ where $\mathbf v$ is the [[Definition:Velocity|velocity]] of $p$. The [[Definition:Acceleration|acceleration]] of $p$ is by definition the [[Definition:Rate of Change|rate of change]] in its [[Definition:Velocity|velocity]]: {{begin-eqn}} {{eqn | l = \mathbf a | r = \dfrac {\mathrm d \mathbf v} {\mathrm d t} | c = }} {{eqn | r = r \dfrac {\mathrm d^2 \theta} {\mathrm d t^2} \mathbf u_\theta + \dfrac {\mathrm d r} {\mathrm d t} \dfrac {\mathrm d \theta} {\mathrm d t} \mathbf u_\theta + r \dfrac {\mathrm d \theta} {\mathrm d t} \dfrac {\mathrm d \mathbf u_\theta} {\mathrm d t} + \dfrac {\mathrm d^2 r} {\mathrm d t^2} \mathbf u_r + \dfrac {\mathrm d r} {\mathrm d t} \dfrac {\mathrm d \mathbf u_r} {\mathrm d t} | c = [[Product Rule for Derivatives]] }} {{eqn | r = r \dfrac {\mathrm d^2 \theta} {\mathrm d t^2} \mathbf u_\theta + \dfrac {\mathrm d r} {\mathrm d t} \dfrac {\mathrm d \theta} {\mathrm d t} \mathbf u_\theta + r \dfrac {\mathrm d \theta} {\mathrm d t} \dfrac {\mathrm d \mathbf u_\theta} {\mathrm d \theta} \dfrac {\mathrm d \theta} {\mathrm d t} + \dfrac {\mathrm d^2 r} {\mathrm d t^2} \mathbf u_r + \dfrac {\mathrm d r} {\mathrm d t} \dfrac {\mathrm d \mathbf u_r} {\mathrm d \theta} \dfrac {\mathrm d \theta} {\mathrm d t} | c = [[Chain Rule for Derivatives]] }} {{eqn | r = r \dfrac {\mathrm d^2 \theta} {\mathrm d t^2} \mathbf u_\theta + \dfrac {\mathrm d r} {\mathrm d t} \dfrac {\mathrm d \theta} {\mathrm d t} \mathbf u_\theta - r \dfrac {\mathrm d \theta} {\mathrm d t} \mathbf u_r \dfrac {\mathrm d \theta} {\mathrm d t} + \dfrac {\mathrm d^2 r} {\mathrm d t^2} \mathbf u_r + \dfrac {\mathrm d r} {\mathrm d t} \mathbf u_\theta \dfrac {\mathrm d \theta} {\mathrm d t} | c = substituting from $(2)$ and $(3)$ }} {{eqn | r = \left({r \dfrac {\mathrm d^2 \theta} {\mathrm d t^2} + 2 \dfrac {\mathrm d r} {\mathrm d t} \dfrac {\mathrm d \theta} {\mathrm d t} }\right) \mathbf u_\theta + \left({\dfrac {\mathrm d^2 r} {\mathrm d t^2} - r \left({\dfrac {\mathrm d \theta} {\mathrm d t} }\right)^2}\right) \mathbf u_r | c = gathering terms }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \map \cos {x + \pi} | r = \frac 1 2 \paren {e^{i \paren {x + \pi} } + e^{-i \paren {x + \pi} } } | c = [[Cosine Exponential Formulation]] }} {{eqn | r = \frac 1 2 \paren {e^{i x} e^{i \pi} + e^{-i x} e^{-i \pi} } | c = [[Exponential of Sum/Complex Numbers|Exponential of Sum: Complex Numbers]] }} {{eqn | r = \frac 1 2 \paren {-e^{i x} - e^{-i x} } | c = [[Euler's Identity]] }} {{eqn | r = -\frac 1 2 \paren {e^{i x} + e^{-i x} } | c = }} {{eqn | r = -\cos x | c = [[Cosine Exponential Formulation]] }} {{end-eqn}} {{qed}}	0
:$\displaystyle \int_0^{2 \pi} \frac {\d x} {a + b \cos x} = \frac {2 \pi} {\sqrt {a^2 - b^2} }$	0
Let $\alpha$ be an [[Definition:Angle|angle]] which is to be [[Definition:Trisection|trisected]]. This can be achieved by means of a [[Definition:Hyperbola|hyperbola]].	0
{{begin-eqn}} {{eqn | l = \sin b \sin c \cos A | r = \cos a - \cos b \cos c | c = [[Spherical Law of Cosines]] }} {{eqn | ll= \leadsto | l = \sin^2 b \sin^2 c \cos^2 A | r = \cos^2 a - 2 \cos a \cos b \cos c + \cos^2 b \cos^2 c | c = }} {{eqn | ll= \leadsto | l = \sin^2 b \sin^2 c \paren {1 - \sin^2 A} | r = \cos^2 a - 2 \cos a \cos b \cos c + \cos^2 b \cos^2 c | c = [[Sum of Squares of Sine and Cosine]] }} {{eqn | ll= \leadsto | l = \sin^2 b \sin^2 c - \sin^2 b \sin^2 c \sin^2 A | r = \cos^2 a - 2 \cos a \cos b \cos c + \cos^2 b \cos^2 c | c = multiplying out }} {{eqn | ll= \leadsto | l = \paren {1 - \cos^2 b} \paren {1 - \cos^2 c} - \sin^2 b \sin^2 c \sin^2 A | r = \cos^2 a - 2 \cos a \cos b \cos c + \cos^2 b \cos^2 c | c = [[Sum of Squares of Sine and Cosine]] }} {{eqn | ll= \leadsto | l = 1 - \cos^2 b - \cos^2 c + \cos^2 b \cos^2 c - \sin^2 b \sin^2 c \sin^2 A | r = \cos^2 a - 2 \cos a \cos b \cos c + \cos^2 b \cos^2 c | c = multiplying out }} {{eqn | n = 1 | ll= \leadsto | l = \sin^2 b \sin^2 c \sin^2 A | r = 1 - \cos^2 a - \cos^2 b - \cos^2 c + 2 \cos a \cos b \cos c | c = rearranging and simplifying }} {{end-eqn}} Let $X \in \R_{>0}$ such that: :$X^2 \sin^2 a \sin^2 b \sin^2 c = 1 - \cos^2 a - \cos^2 b - \cos^2 c + 2 \cos a \cos b \cos c$ Then from $(1)$: {{begin-eqn}} {{eqn | l = \dfrac {X^2 \sin^2 a \sin^2 b \sin^2 c} {\sin^2 b \sin^2 c \sin^2 A} | o = = | r = \dfrac {1 - \cos^2 a - \cos^2 b - \cos^2 c + 2 \cos a \cos b \cos c} {1 - \cos^2 a - \cos^2 b - \cos^2 c + 2 \cos a \cos b \cos c} | c = }} {{eqn | ll= \leadsto | l = X^2 | r = \dfrac {\sin^2 A} {\sin^2 a} | c = }} {{end-eqn}} In a [[Definition:Spherical Triangle|spherical triangle]], all of the [[Definition:Side of Spherical Triangle|sides]] are less than $\pi$ [[Definition:Radian|radians]]. The same applies to the [[Definition:Spherical Angle|angles]]. From [[Shape of Sine Function]]: :$\sin \theta > 0$ for all $0 < \theta < \pi$ Hence the [[Definition:Negative Square Root|negative root]] of $\dfrac {\sin^2 A} {\sin^2 a}$ does not apply, and so: :$X = \dfrac {\sin A} {\sin a}$ Similarly, from applying the [[Spherical Law of Cosines]] to $\cos B$ and $\cos C$: {{begin-eqn}} {{eqn | l = \sin a \sin c \cos B | r = \cos b - \cos a \cos c }} {{eqn | l = \sin a \sin b \cos C | r = \cos c - \cos a \cos b }} {{end-eqn}} we arrive at the same point: {{begin-eqn}} {{eqn | l = X | r = \dfrac {\sin B} {\sin b} }} {{eqn | r = \dfrac {\sin A} {\sin a} }} {{end-eqn}} where: :$X^2 \sin^2 a \sin^2 b \sin^2 c = 1 - \cos^2 a - \cos^2 b - \cos^2 c + 2 \cos a \cos b \cos c$ as before. Hence we have: :$\dfrac {\sin a} {\sin A} = \dfrac {\sin b} {\sin B} = \dfrac {\sin c} {\sin C}$ {{qed}}	0
With a view to expressing the [[Definition:Primitive|primitive]] in the form: :$\displaystyle \int u \frac {\d v} {\d x} \rd x = u v - \int v \frac {\d u} {\d x} \rd x$ let: {{begin-eqn}} {{eqn | l = u | r = \sin^{m - 1} a x | c = }} {{eqn | ll= \leadsto | l = \frac {\d u} {\d x} | r = a \paren {m - 1} \sin^{m - 2} a x \cos a x | c = [[Derivative of Sine of a x|Derivative of $\sin a x$]], [[Derivative of Power]], [[Chain Rule for Derivatives]] }} {{end-eqn}} and let: {{begin-eqn}} {{eqn | l = \frac {\d v} {\d x} | r = \sin a x \cos^n a x | c = }} {{eqn | ll= \leadsto | l = v | r = \frac {-\cos^{n + 1} a x} {\paren {n + 1} a} | c = [[Primitive of Power of Cosine of a x by Sine of a x|Primitive of $\cos^n a x \sin a x$]] }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = \int \sin^m a x \cos^n a x \rd x | r = \int \paren {\sin^{m - 1} a x} \paren {\sin a x \cos^n a x} \rd v | c = }} {{eqn | r = \paren {\sin^{m - 1} a x} \paren {\frac {-\cos^{n + 1} a x} {\paren {n + 1} a} } | c = [[Integration by Parts]] }} {{eqn | o = | ro= - | r = \int \paren {\frac {-\cos^{n + 1} a x} {\paren {n + 1} a} } \paren {a \paren {m - 1} \sin^{m - 2} a x \cos a x} \rd x + C | c = }} {{eqn | r = \frac {-\sin^{m - 1} a x \cos^{n + 1} a x} {a \paren {n + 1} } + \frac {m - 1} {n + 1} \int \sin^{m - 2} a x \cos^{n + 2} a x \rd x + C | c = simplifying }} {{eqn | r = \frac {-\sin^{m - 1} a x \cos^{n + 1} a x} {a \paren {n + 1} } | c = }} {{eqn | o = | ro= + | r = \frac {m - 1} {n + 1} \int \sin^{m - 2} a x \cos^n a x \paren {1 - \sin^2 a x} \rd x + C | c = [[Sum of Squares of Sine and Cosine]] }} {{eqn | r = \frac {-\sin^{m - 1} a x \cos^{n + 1} a x} {a \paren {n + 1} } + \frac {m - 1} {n + 1} \int \sin^{m - 2} a x \cos^n a x \rd x | c = [[Linear Combination of Integrals]] }} {{eqn | o = | ro= - | r = \frac {m - 1} {n + 1} \int \sin^m a x \cos^n a x \rd x + C | c = }} {{end-eqn}} Hence after rearranging: {{begin-eqn}} {{eqn | r = \frac {-\sin^{m - 1} a x \cos^{n + 1} a x} {a \paren {n + 1} } + \frac {m - 1} {n + 1} \int \sin^{m - 2} a x \cos^n a x \rd x | o = | c = }} {{eqn | r = \int \sin^m a x \cos^n a x \rd x + \frac {m - 1} {n + 1} \int \sin^m a x \cos^n a x \rd x + C | c = }} {{eqn | r = \frac {n + 1} {n + 1} \int \sin^m a x \cos^n a x \rd x + \frac {m - 1} {n + 1} \int \sin^m a x \cos^n a x \rd x + C | c = common [[Definition:Denominator|denominator]] }} {{eqn | r = \frac {m + n} {n + 1} \int \sin^m a x \cos^n a x \rd x + C | c = simplifying }} {{eqn | ll= \leadsto | l = \int \sin^m a x \cos^n a x \rd x | r = \frac {-\sin^{m - 1} a x \cos^{n + 1} a x} {a \paren {m + n} } + \frac {m - 1} {m + n} \int \sin^{m - 2} a x \cos^n a x \rd x + C | c = simplifying }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \cos^2 x + \sin^2 x | r = 1 | c = [[Sum of Squares of Sine and Cosine]] }} {{eqn | ll= \leadsto | l = \cos^2 x | r = 1 - \sin^2 x }} {{eqn | ll= \leadsto | l = \cos x | r = \pm \sqrt {1 - \sin^2 x} }} {{end-eqn}} Then from [[Sign of Cosine]]: {{begin-eqn}} {{eqn | l = \cos x | o = > | r = 0 | c = if there exists an [[Definition:Integer|integer]] $n$ such that $\paren {2 n - \dfrac 1 2} \pi < x < \paren {2 n + \dfrac 1 2} \pi$ }} {{eqn | l = \cos x | o = < | r = 0 | c = if there exists an [[Definition:Integer|integer]] $n$ such that $\paren {2 n + \dfrac 1 2} \pi < x < \paren {2 n + \dfrac 3 2} \pi$ }} {{end-eqn}} {{qed}}	0
By definition of the [[Definition:Laplace Transform|Laplace transform]]: :$\displaystyle \laptrans {\sin a t} = \int_0^{\to +\infty} e^{-s t} \sin a t \rd t$ From [[Integration by Parts]]: :$\displaystyle \int f g' \rd t = f g - \int f' g \rd t$ Here: {{begin-eqn}} {{eqn | l = f | r = \sin a t }} {{eqn | ll= \leadsto | l = f' | r = a \cos a t | c = [[Derivative of Sine of a x|Derivative of $\sin a x$]] }} {{eqn | l = g' | r = e^{-s t} }} {{eqn | ll= \leadsto | l = g | r = -\frac 1 s e^{-s t} | c = [[Primitive of Exponential of a x|Primitive of $e^{a x}$]] }} {{end-eqn}} So: {{begin-eqn}} {{eqn | n = 1 | l = \int e^{-s t} \sin a t \rd t | r = -\frac 1 s e^{-s t} \sin a t + \frac a s \int e^{-s t} \cos a t \rd t }} {{end-eqn}} Consider: :$\displaystyle \int e^{-s t} \cos a t \rd t$ Again, using [[Integration by Parts]]: :$\displaystyle \int h j\,' \rd t = h j - \int h' j \rd t$ Here: {{begin-eqn}} {{eqn | l = h | r = \cos a t }} {{eqn | ll= \leadsto | l = h' | r = -a \sin a t | c = [[Derivative of Cosine Function]] }} {{eqn | l = j\,' | r = e^{-s t} }} {{eqn | ll= \leadsto | l = j | r = -\frac 1 s e^{-s t} | c = [[Primitive of Exponential Function]] }} {{end-eqn}} So: {{begin-eqn}} {{eqn | l = \int e^{-s t} \cos a t \rd t | r = -\frac 1 s e^{-st} \cos a t - \frac a s \int e^{-s t} \sin a t \rd t }} {{end-eqn}} Substituting this into $(1)$: {{begin-eqn}} {{eqn | l = \int e^{-s t} \sin a t \rd t | r = -\frac 1 s e^{-s t} \sin a t + \frac a s \paren {-\frac 1 s e^{-s t} \cos a t - \frac a s \int e^{-s t} \sin a t \rd t} }} {{eqn | r = -\frac 1 s e^{-s t} \sin a t - \frac a {s^2} e^{-s t} \cos a t - \frac {a^2} {s^2} \int e^{-s t} \sin a t \rd t }} {{eqn | ll= \leadsto | l = \paren {1 + \frac {a^2} {s^2} } \int e^{-s t} \sin a t \rd t | r = -e^{-s t} \paren {\frac 1 s \sin a t + \frac a {s^2} \cos a t} }} {{end-eqn}} Evaluating at $t = 0$ and $t \to +\infty$: {{begin-eqn}} {{eqn | l = \paren {1 + \frac {a^2} {s^2} } \laptrans {\sin a t} | r = \intlimits {-e^{-s t} \paren {\frac 1 s \sin a t + \frac a {s^2} \cos a t} } {t \mathop = 0} {t \mathop \to +\infty} }} {{eqn | r = 0 - \paren {-1 \paren {\frac 1 s \times 0 + \frac a {s^2} \times 1} } | c = [[Boundedness of Real Sine and Cosine]], [[Complex Exponential Tends to Zero]] }} {{eqn | r = \frac a {s^2} }} {{eqn | ll= \leadsto | l = \laptrans {\sin a t} | r = \frac a {s^2} \paren {1 + \frac {a^2} {s^2} }^{-1} }} {{eqn | r = \frac a {s^2} \paren {\frac {s^2} {a^2 + s^2} } }} {{eqn | r = \frac a {s^2 + a^2} }} {{end-eqn}} {{qed}}	0
:$\displaystyle \int x \tan a x \rd x = \frac 1 {a^2} \paren {\frac {\paren {a x} ^ 3} 3 + \frac {\paren {a x}^5} {15} + \frac {2 \paren {a x}^7} {105} + \cdots + \frac {\paren {-1}^{n - 1} 2^{2 n} \paren {2^{2 n} - 1} B_{2 n} \paren {a x}^{2 n + 1} } {\paren {2 n + 1}!} + \cdots} + C$ where $B_{2 n}$ denotes the $2 n$th [[Definition:Bernoulli Numbers|Bernoulli number]].	0
{{begin-eqn}} {{eqn | l = e^x \cos x | r = \sum_{n \mathop = 1}^\infty \frac {2^{n / 2} \, \cos \left({n \pi / 4}\right) x^n} {n!} | c = }} {{eqn | r = 1 + x - \frac {x^3} 3 - \frac {x^4} 6 + \cdots | c = }} {{end-eqn}} for all $x \in \R$.	0
:$\displaystyle \int \frac {\cot a x} x \ \mathrm d x = \frac {-1} a x - \frac {a x} 3 - \frac {\paren {a x}^3} {135} - \cdots - \frac {\paren {-1}^{n - 1} 2^{2 n} B_{2 n} \paren {a x}^{2 n - 1} } {\paren {2 n - 1} \paren {2 n}!} - \cdots + C$ where $B_n$ denotes the $n$th [[Definition:Bernoulli Numbers|Bernoulli number]].	0
{{begin-eqn}} {{eqn | l = \map \cos {a + b} + i \, \map \sin {a + b} | r = e^{i \paren {a + b} } | c = [[Euler's Formula]] }} {{eqn | r = e^{i a} e^{i b} | c = [[Exponential of Sum]] }} {{eqn | r = \paren {\cos a + i \sin a} \paren {\cos b + i \sin b} | c = [[Euler's Formula]] }} {{eqn | r = \paren {\cos a \cos b - \sin a \sin b} + i \paren {\sin a \cos b + \cos a \sin b} | c = [[Complex Numbers form Field]] }} {{end-eqn}} By equating the [[Definition:Imaginary Part|imaginary]] parts, the result follows. {{qed}}	0
Let a [[Definition:Horizontal|horizontal]] [[Definition:Plane|plane]] be divided into strips by a series of [[Definition:Parallel Lines|parallel lines]] a fixed [[Definition:Distance (Linear Measure)|distance]] apart, like floorboards. Let a needle whose [[Definition:Length of Line|length]] equals the [[Definition:Distance (Linear Measure)|distance]] between the [[Definition:Parallel Lines|parallel lines]] be dropped onto the [[Definition:Plane|plane]] randomly from a random [[Definition:Height (Linear Measure)|height]]. Then the [[Definition:Probability|probability]] that the needle falls across one of the [[Definition:Parallel Lines|parallel lines]] is $\dfrac 2 \pi$.	0
From [[Tangent to Cycloid passes through Top of Generating Circle]], the [[Definition:Tangent to Curve|tangent]] to $C$ at a point $P = \left({x, y}\right)$ passes through the top of the [[Definition:Generating Circle of Cycloid|generating circle]]. By definition, the [[Definition:Normal to Curve|normal]] to $C$ at $P$ is [[Definition:Perpendicular|perpendicular]] to the [[Definition:Tangent to Curve|tangent]] to $C$ at $P$. From [[Thales' Theorem]], the [[Definition:Normal to Curve|normal]], the [[Definition:Tangent to Curve|tangent]] and the [[Definition:Diameter of Circle|diameter]] of the [[Definition:Generating Circle of Cycloid|generating circle]] form a [[Definition:Right Triangle|right triangle]]. Thus the [[Definition:Normal to Curve|normal]] to $C$ at $P$ meets the [[Definition:Generating Circle of Cycloid|generating circle]] at the opposite end of the [[Definition:Diameter of Circle|diameter]] to the [[Definition:Tangent to Curve|tangent]]. Hence the result. {{qed}}	0
Let $\triangle ABC$ be a [[Definition:Triangle (Geometry)|triangle]] Let the [[Definition:Vertex of Polygon|vertices]] of $\triangle ABC$ all have [[Definition:Plane Angle|angles]] less than $120 \degrees$. Let $\triangle ABG$, $\triangle BCE$ and $\triangle ACF$ be [[Definition:Equilateral Triangle|equilateral triangles]] constructed on the [[Definition:Side of Polygon|sides]] of $ABC$. Let $AE$, $BF$ and $CG$ be constructed. Let $P$ be the [[Definition:Point|point]] at which $AE$, $BF$ and $CG$ meet. :[[File:FermatPointConstruction.png|500px]] Then $P$ is the [[Definition:Fermat-Torricelli Point|Fermat-Torricelli point]] of $\triangle ABC$. If one of [[Definition:Vertex of Polygon|vertices]] of $\triangle ABC$ be of $120 \degrees$ or more, then that [[Definition:Vertex of Polygon|vertex]] is itself the [[Definition:Fermat-Torricelli Point|Fermat-Torricelli point]] of $\triangle ABC$.	0
A [[Definition:Point Set|point set]] $R$ in [[Definition:The Plane|the plane]] is a '''region''' {{iff}}: :$(1): \quad$ Each [[Definition:Point|point]] of $R$ is the [[Definition:Center of Circle|center of a circle]] all of whose [[Definition:Element|elements]] consist of [[Definition:Point|points]] of $R$ :$(2): \quad$ Each [[Definition:Point|point]] of $R$ can be joined by a [[Definition:Curve|curve]] consisting entirely of [[Definition:Point|points]] of $R$.	0
:[[File:Euclid-I-32.png|300px]] Let $\triangle ABC$ be a [[Definition:Triangle (Geometry)|triangle]]. Let $BC$ be extended to a point $D$. From [[External Angle of Triangle equals Sum of other Internal Angles]]: : $\angle ACD = \angle ABC + \angle BAC$ Bby [[Axiom:Euclid's Common Notions|by Euclid's Second Common Notion]]: : $\angle ACB + \angle ACD = \angle ABC + \angle BAC + \angle ACB$ But from [[Two Angles on Straight Line make Two Right Angles]], $\angle ACB + \angle ACD$ equals two [[Definition:Right Angle|right angles]]. So by [[Axiom:Euclid's Common Notions|Euclid's First Common Notion]], $\angle ABC + \angle BAC + \angle ACB$ equals two [[Definition:Right Angle|right angles]]. {{qed}}	0
Consider a [[Definition:Circle|circle]] of [[Definition:Radius of Circle|radius]] $a$ rolling without slipping along the [[Definition:X-Axis|x-axis]] of a [[Definition:Cartesian Plane|cartesian plane]]. Consider the [[Definition:Point|point]] $P$ on the [[Definition:Circumference of Circle|circumference]] of this [[Definition:Circle|circle]] which is at the [[Definition:Origin|origin]] when its [[Definition:Center of Circle|center]] is on the [[Definition:Y-Axis|y-axis]]. Consider the [[Definition:Cycloid|cycloid]] traced out by the [[Definition:Point|point]] $P$. Let $\tuple {x, y}$ be the [[Definition:Cartesian Coordinate Pair|coordinates]] of $P$ as it travels over [[Definition:The Plane|the plane]]. The [[Definition:Point|point]] $P = \tuple {x, y}$ is described by the equations: :$x = a \paren {\theta - \sin \theta}$ :$y = a \paren {1 - \cos \theta}$	0
{{begin-eqn}} {{eqn | l = \sin^4 x - \cos^4 x | r = \sin^2 x \left({1 - \cos^2 x}\right) - \cos^2 x \left({1 - \sin^2 x}\right) | c = [[Sum of Squares of Sine and Cosine]] }} {{eqn | r = \sin^2 x - \sin^2 x \ \cos^2 x - \cos^2 x + \sin^2 x \ \cos^2 x }} {{eqn | r = \sin^2 x - \cos^2 x }} {{end-eqn}} {{qed}}	0
From [[Tangent to Cycloid passes through Top of Generating Circle]], the [[Definition:Tangent to Curve|tangent]] to $C$ at a point $P = \left({x, y}\right)$ passes through the top of the [[Definition:Generating Circle of Cycloid|generating circle]]. By definition, the [[Definition:Normal to Curve|normal]] to $C$ at $P$ is [[Definition:Perpendicular|perpendicular]] to the [[Definition:Tangent to Curve|tangent]] to $C$ at $P$. From [[Thales' Theorem]], the [[Definition:Normal to Curve|normal]], the [[Definition:Tangent to Curve|tangent]] and the [[Definition:Diameter of Circle|diameter]] of the [[Definition:Generating Circle of Cycloid|generating circle]] form a [[Definition:Right Triangle|right triangle]]. Thus the [[Definition:Normal to Curve|normal]] to $C$ at $P$ meets the [[Definition:Generating Circle of Cycloid|generating circle]] at the opposite end of the [[Definition:Diameter of Circle|diameter]] to the [[Definition:Tangent to Curve|tangent]]. Hence the result. {{qed}}	0
:[[File:Euclid-XI-18.png|350px]] Let $AB$ be an arbitrary [[Definition:Straight Line|straight line]] which is [[Definition:Line Perpendicular to Plane|perpendicular]] to the [[Definition:Plane of Reference|plane of reference]]. It is to be demonstrated that every [[Definition:Plane|plane]] holding $AB$ is [[Definition:Plane Perpendicular to Plane|perpendicular]] to the [[Definition:Plane of Reference|plane of reference]]. Let an arbitrary [[Definition:Plane|plane]] $DE$ be drawn through $AB$. Let $CE$ be the [[Definition:Common Section|common section]] of the [[Definition:Plane|plane]] $DE$ and the [[Definition:Plane of Reference|plane of reference]]. Let $F$ be an arbitrary [[Definition:Point|point]] on $CE$. From {{EuclidPropLink|book = I|prop = 11|title = Construction of Perpendicular Line}}: :let $FG$ be drawn in $DE$ [[Definition:Perpendicular|perpendicular]] to $CE$. We have that $AB$ is [[Definition:Plane Perpendicular to Plane|perpendicular]] to the [[Definition:Plane of Reference|plane of reference]]. Therefore from {{EuclidDefLink|XI|3|Line at Right Angles to Plane}}: :$AB$ is [[Definition:Perpendicular|perpendicular]] to all the [[Definition:Straight Line|straight lines]] which meet it and are in the [[Definition:Plane of Reference|plane of reference]]. Therefore $AB$ is [[Definition:Perpendicular|perpendicular]] to $CE$. Therefore $\angle ABF$ is a [[Definition:Right Angle|right angle]]. But $\angle GFB$ is also a [[Definition:Right Angle|right angle]]. Therefore by {{EuclidPropLink|book = I|prop = 28|title = Supplementary Interior Angles implies Parallel Lines}}: :$AB \parallel FG$ But $AB$ is [[Definition:Plane Perpendicular to Plane|perpendicular]] to the [[Definition:Plane of Reference|plane of reference]]. Therefore from {{EuclidPropLink|book = XI|prop = 8|title = Line Parallel to Perpendicular Line to Plane is Perpendicular to Same Plane}}: : $FG$ is [[Definition:Plane Perpendicular to Plane|perpendicular]] to the [[Definition:Plane of Reference|plane of reference]]. Thus the conditions are fulfilled for {{EuclidDefLink|XI|4|Plane at Right Angles to Plane}} to apply: :$DE$ is [[Definition:Plane Perpendicular to Plane|perpendicular]] to the [[Definition:Plane of Reference|plane of reference]]. As $DE$ is arbitrary, the result follows. {{qed}} {{Euclid Note|18|XI}}	0
=== Necessary Condition === Let $\triangle ABC$ be an [[Definition:Equilateral Triangle|equilateral triangle]]. By definition, each [[Definition:Side of Polygon|side]] of $\triangle ABC$ is the [[Definition:Base of Isosceles Triangle|base]] of an [[Definition:Isosceles Triangle|isosceles triangle]]. :[[File:EquilateralWithAltitudes.png|400px]] Let $AE$, $BF$ and $CD$ be the [[Definition:Altitude of Triangle|altitudes]] of $\triangle ABC$ through $A$, $B$ and $C$ respectively. From [[Altitudes of Triangle Meet at Point]], let them [[Definition:Intersection (Geometry)|intersect]] at $G$. From [[Altitude, Median and Perpendicular Bisector Coincide iff Triangle is Isosceles]]: :$AE$, $BF$ and $CD$ are the [[Definition:Median of Triangle|medians]] of $\triangle ABC$ and: :$AE$, $BF$ and $CD$ are the [[Definition:Perpendicular Bisector|perpendicular bisectors]] of $\triangle ABC$. They all meet at a single [[Definition:Point|point]], that is $G$. Hence by definition, the [[Definition:Circumcenter of Triangle|circumcenter]], [[Definition:Centroid of Triangle|centroid]] and [[Definition:Orthocenter|orthocenter]] of $\triangle ABC$ are the same [[Definition:Point|point]]. {{qed|lemma}} === Converse Condition === Let $\triangle ABC$ not be an [[Definition:Equilateral Triangle|equilateral triangle]]. Thus at least one pair of [[Definition:Side of Polygon|sides]] of $\triangle ABC$ is not equal. {{WLOG}}, suppose $AC \ne BC$. Then $AB$ is not the [[Definition:Base of Isosceles Triangle|base]] of an [[Definition:Isosceles Triangle|isosceles triangle]]. :[[File:AltitudeMedianPerpendicularBisector.png|400px]] Thus from [[Altitude, Median and Perpendicular Bisector Coincide iff Triangle is Isosceles]], the [[Definition:Altitude of Triangle|altitude]] from $AB$, the [[Definition:Midpoint of Line|midpoint]] of $AB$ and the [[Definition:Perpendicular Bisector|perpendicular bisector]] of $AB$ are all different. So the [[Definition:Circumcenter of Triangle|circumcenter]], [[Definition:Centroid of Triangle|centroid]] and [[Definition:Orthocenter|orthocenter]] of $\triangle ABC$ likewise cannot be the same [[Definition:Point|point]]. {{qed}} {{improve|A clumsy proof for a trivial result.}} [[Category:Equilateral Triangles]] c0y457k3m8c19ntyeehorieam9ec8kc	0
Proof by [[Second Principle of Mathematical Induction|induction]]: For all $n \in \N$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$F_n = \dfrac {\phi^n - \hat \phi^n} {\sqrt 5}$ === Basis for the Induction === $\map P 0$ is true, as this just says: :$\dfrac {\phi^0 - \hat \phi^0} {\sqrt 5} = \dfrac {1 - 1} {\sqrt 5} = 0 = F_0$ $\map P 1$ is the case: {{begin-eqn}} {{eqn | l = \frac {\phi - \hat \phi} {\sqrt 5} | r = \frac {\paren {\frac {1 + \sqrt 5} 2} - \paren {\frac {1 - \sqrt 5} 2} } {\sqrt 5} | c = }} {{eqn | r = \frac {\paren {1 - 1} + \paren {\sqrt 5 + \sqrt 5} } {2 \sqrt 5} | c = }} {{eqn | r = 1 | c = }} {{eqn | r = F_1 | c = }} {{end-eqn}} This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P j$ is true for all $0 \le j \le k + 1$, then it logically follows that $\map P {k + 2}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\forall 0 \le j \le k + 1: F_j = \dfrac {\phi^j - \hat \phi^j} {\sqrt 5}$ Then we need to show: :$F_{k + 2} = \dfrac {\phi^{k + 2} - \hat \phi^{k + 2} } {\sqrt 5}$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: We observe that we have the following two identities: :$\phi^2 = \paren {\dfrac {1 + \sqrt 5} 2}^2 = \dfrac 1 4 \paren {6 + 2 \sqrt 5} = \dfrac {3 + \sqrt 5} 2 = 1 + \phi$ :$\hat \phi^2 = \paren {\dfrac {1 - \sqrt 5} 2}^2 = \dfrac 1 4 \paren {6 - 2 \sqrt 5} = \dfrac {3 - \sqrt 5} 2 = 1 + \hat \phi$ This can also be deduced from the definition of the [[Definition:Golden Mean|golden mean]]: the fact that $\phi$ and $\hat \phi$ are the [[Solution to Quadratic Equation|solutions]] to the [[Definition:Quadratic Equation|quadratic equation]] $x^2 = x + 1$. Thus: {{begin-eqn}} {{eqn | l = \phi^{k + 2} - \hat \phi^{k + 2} | r = \paren {1 + \phi} \phi^k - \paren {1 + \hat \phi} \hat \phi^k }} {{eqn | r = \paren {\phi^k - \hat \phi^k} + \paren {\phi^{k + 1} - \hat \phi^{k + 1} } }} {{eqn | r = \sqrt 5 \paren {F_k + F_{k + 1} } | c = [[Euler-Binet Formula/Proof 1#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \sqrt 5 F_{k + 2} | c = {{Defof|Fibonacci Numbers}} }} {{end-eqn}} The result follows by the [[Second Principle of Mathematical Induction]]. Therefore: :$\forall n \in \N: F_n = \dfrac {\phi^n - \hat \phi^n} {\sqrt 5}$ {{qed}}	0
:$\map {\dfrac \d {\d x} } {\sinh^{-1} u} = \dfrac 1 {\sqrt {1 + u^2} } \dfrac {\d u} {\d x}$	0
Let $AB$ be a [[Definition:Line Segment|line segment]]. Using a [[Definition:Straightedge|straightedge]] and [[Definition:Rusty Compass|rusty compass]], it is possible to divide $AB$ into as many equal parts as required.	0
Let $0 < x < a$. Then $0 < \dfrac x a < 1$ and so: {{begin-eqn}} {{eqn | l = \frac {\map \d {\csch^{-1} } {\frac x a} } {\d x} | r = \frac 1 a \dfrac {-1} {\size {\frac x a} \sqrt {1 + \paren {\frac x a}^2} } | c = [[Derivative of Inverse Hyperbolic Cosecant|Derivative of $\csch^{-1}$]] and [[Derivative of Function of Constant Multiple]] }} {{eqn | r = \frac 1 a \frac {-a} {\size x \sqrt {\frac {a^2 + x^2} {a^2} } } | c = }} {{eqn | r = \frac {-a} {\size x \sqrt{a^2 + x^2} } | c = }} {{end-eqn}} $\csch^{-1} \dfrac x a$ is not defined when $x = 0$. {{qed}}	0
:[[File:Spherical-Cosine-Formula-Analog.png|500px]] Suppose $c$ is less than $\dfrac \pi 2$. Let $BA$ be [[Definition:Production|produced]] to $D$ so that $BD = \dfrac \pi 2$. Then: :$AD = \dfrac \pi 2 - c$ and: :$\angle CAD = pi - A$ Let $C$ and $D$ be joined by an [[Definition:Arc of Circle|arc]] of a [[Definition:Great Circle|great circle]], denoted $x$. From the [[Definition:Spherical Triangle|triangle]] $\sphericalangle DAC$, using the [[Spherical Law of Cosines]]: {{begin-eqn}} {{eqn | l = \cos x | r = \map \cos {\dfrac \pi 2 - c} \cos b + \map \sin {\dfrac \pi 2 - c} \sin b \, \map \cos {\pi - A} | c = }} {{eqn | r = \sin c \cos b - \cos c \sin b \cos A | c = }} {{end-eqn}} From the [[Definition:Spherical Triangle|triangle]] $\sphericalangle DBC$, using the [[Spherical Law of Cosines]]: {{begin-eqn}} {{eqn | l = \cos x | r = \cos \dfrac \pi 2 \cos a + \sin \pi 2 \sin a \cos B | c = }} {{eqn | r = \sin a \cos B | c = }} {{end-eqn}} Hence: :$\sin a \cos B = \sin c \cos b - \cos c \sin b \cos A$ The case where $c > \dfrac \pi 2$ is worked similarly, but by making $D$ the [[Definition:Point|point]] between $A$ and $B$ such that $BD$ is $\dfrac \pi 2$. {{qed}}	0
{{begin-eqn}} {{eqn | l = \sec 255 \degrees | r = \map \sec {360 \degrees - 105 \degrees} | c = }} {{eqn | r = \sec 105 \degrees | c = [[Secant of Conjugate Angle]] }} {{eqn | r = -\paren {\sqrt 6 + \sqrt 2} | c = [[Secant of 105 Degrees|Secant of $105 \degrees$]] }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \int_0^\infty e^{-a x} \cos b x \rd x | r = \intlimits {\frac {e^{-a x} \paren {-a \cos b x + b \sin b x} } {a^2 + b^2} } 0 \infty | c = [[Primitive of Exponential of a x by Cosine of b x|Primitive of $e^{a x} \cos b x$]] }} {{eqn | r = \lim_{x \mathop \to \infty} \paren {\frac {e^{-a x} \paren {-a \cos b x + b \sin b x} } {a^2 + b^2} } + \frac {e^0 \paren {a \cos 0 - b \sin 0} } {a^2 + b^2} }} {{eqn | r = \lim_{x \mathop \to \infty} \paren {\frac {e^{-a x} \paren {-a \cos b x + b \sin b x} } {a^2 + b^2} } + \frac a {a^2 + b^2} | c = [[Exponential of Zero]], [[Cosine of Zero is One]], [[Sine of Zero is Zero]] }} {{end-eqn}} Note that we have, by [[Linear Combination of Sine and Cosine]]: :$\displaystyle 0 \le \size {\frac {e^{-a x} \paren {-a \cos b x + b \sin x} } {a^2 + b^2} } \le \frac {e^{-a x} \sqrt {a^2 + b^2} } {a^2 + b^2} = \frac {e^{-a x} } {\sqrt {a^2 + b^2} }$ By [[Exponential Tends to Zero and Infinity]]: :$\displaystyle \lim_{x \mathop \to \infty} \paren {\frac {e^{-a x} } {\sqrt {a^2 + b^2} } } = 0$ So by the [[Squeeze Theorem]]: :$\displaystyle \lim_{x \mathop \to \infty} \paren {\frac {e^{-a x} \paren {-a \cos b x + b \sin x} } {a^2 + b^2} } = 0$ So: :$\displaystyle \int_0^\infty e^{-a x} \cos b x \rd x = \frac a {a^2 + b^2}$ {{qed}}	0
{{begin-eqn}} {{eqn | l = \int \tan^3 a x \rd x | r = \int \tan a x \tan^2 a x \rd x | c = }} {{eqn | r = \int \tan a x \paren {\sec^2 a x - 1} \rd x | c = [[Difference of Squares of Secant and Tangent]] }} {{eqn | r = \int \tan a x \sec^2 a x \rd x - \int \tan a x \rd x | c = [[Linear Combination of Integrals]] }} {{eqn | r = \frac {\tan^2 a x} {2 a} - \int \tan a x \rd x + C | c = [[Primitive of Power of Tangent of a x by Square of Secant of a x|Primitive of $\tan^n a x \sec^2 a x$]]: $n = 1$ }} {{eqn | r = \frac {\tan^2 a x} {2 a} - \paren {\frac {-\ln \size {\cos a x} } a} + C | c = [[Primitive of Tangent of a x/Cosine Form|Primitive of $\tan a x$]] }} {{eqn | r = \frac {\tan^2 a x} {2 a} + \frac 1 a \ln \size {\cos a x} + C | c = simplifying }} {{end-eqn}} {{qed}}	0
Let $A$ be a [[Definition:Noetherian Ring|Noetherian ring]]. Let $n \ge 1$ be an [[Definition:Integer|integer]]. Let $A \sqbrk {x_1, \ldots, x_n}$ be the [[Definition:Ring of Polynomial Forms|ring of polynomial forms over $A$ in the indeterminates $x_1, \ldots, x_n$]]. Then $A \sqbrk {x_1, \ldots, x_n}$ is also a [[Definition:Noetherian Ring|Noetherian ring]].	0
From [[Arccosine of Reciprocal equals Arcsecant]]: :$\operatorname {arcsec} x = \arccos \dfrac 1 x$ From [[Power Series Expansion for Real Arccosine Function]]: :$\displaystyle \arccos x = \frac \pi 2 - \sum_{n \mathop = 0}^\infty \frac {\left({2 n}\right)!} {2^{2 n} \left({n!}\right)^2} \frac {x^{2 n + 1} } {2 n + 1}$ which is converges for $\left\lvert{x}\right\rvert \le 1$. The result follows by subtituting $\dfrac 1 x$ for $x$. This converges for $\left\lvert{\dfrac 1 x}\right\rvert \le 1$, that is, for $\left\lvert{x}\right\rvert \ge 1$ {{qed}}	0
In any given [[Definition:Regular Pentagon|regular pentagon]] it is possible to [[Definition:Inscribe/Circle in Polygon|inscribe]] a [[Definition:Circle|circle]]. {{:Euclid:Proposition/IV/13}}	0
Let $n \in \Z$ be an [[Definition:Integer|integer]]. Then: :$F_{2 n + 1} \phi \bmod 1 = \phi^{-2 n - 1}$ where: :$F_n$ denotes the $n$th [[Definition:Fibonacci Numbers|Fibonacci number]] :$\phi$ is the [[Definition:Golden Mean|golden mean]]: $\phi = \dfrac {1 + \sqrt 5} 2$	0
$\Box ABCD$ can be divided into $2$ [[Definition:Triangle (Geometry)|triangles]]: $\triangle ABC$ and $\triangle ADC$. Hence $\mathcal A$ is the [[Definition:Sum (Addition)|sum]] of the [[Definition:Area|areas]] of $\triangle ABC$ and $\triangle ADC$. From [[Area of Triangle in Determinant Form]]: {{begin-eqn}} {{eqn | l = \map \Area {\triangle ABC} | r = \dfrac 1 2 \size {\paren {\begin{vmatrix} x_1 & y_1 & 1 \\ x_2 & y_2 & 1 \\ x_3 & y_3 & 1 \\ \end{vmatrix} } } }} {{eqn | l = \map \Area {\triangle ADC} | r = \dfrac 1 2 \size {\paren {\begin{vmatrix} x_1 & y_1 & 1 \\ x_4 & y_4 & 1 \\ x_3 & y_3 & 1 \\ \end{vmatrix} } } }} {{end-eqn}} Hence the result. {{qed}}	0
:[[File:Euclid-III-24.png|600px]] Let $AEB$ and $CFD$ be [[Definition:Similar Segments|similar segments of circles]] on equal [[Definition:Base of Segment|bases]] $AB$ and $CD$. Let the [[Definition:Segment of Circle|segment]] $AEB$ be applied to $CFD$ so that $A$ be placed on $C$ and $AB$ on $CD$. Then $B$ will coincide with $D$ as $AB = CD$. Suppose that [[Definition:Segment of Circle|segment]] $AEB$ does not coincide with [[Definition:Segment of Circle|segment]] $CFD$. It will fall in one of three ways: :$(1) \quad$ Inside it :$(2) \quad$ Outside it :$(3) \quad$ Awry, as $CGD$. If $CFD$ falls inside or outside $AEB$, then by definition $AEB$ and $CFD$ are not similar. But from [[Two Circles have at most Two Points of Intersection]] option $(3)$ is impossible. Hence the result. {{Qed}} {{Euclid Note|24|III}}	0
For any [[Definition:Real Number|real number]] $x: -1 \le x \le 1$: :$\arccos x = \dfrac 1 i \map \ln {x + \sqrt {x^2 - 1} }$ where $\arccos x$ is the [[Definition:Arccosine|arccosine]] and $i^2 = -1$.	0
{{begin-eqn}} {{eqn | l = \int \frac {\d x} {\sin a x + \cos a x} | r = \frac 1 a \int \frac {\dfrac {2 \rd u} {1 + u^2} } {\dfrac {2 u} {1 + u^2} + \dfrac {1 - u^2} {1 + u^2} } | c = [[Weierstrass Substitution]]: $u = \tan \dfrac {a x} 2$ }} {{eqn | r = \frac 2 a \int \frac {\d u} {- u^2 + 2 u + 1} | c = simplifying }} {{eqn | r = \frac 2 a \paren {\frac 1 {\sqrt 8} \ln \size {\frac {-2 u + 2 - \sqrt 8} {-2 u + 2 + \sqrt 8} } } + C | c = [[Primitive of Reciprocal of a x squared plus b x plus c|Primitive of $\dfrac 1 {a x^2 + b x + c}$]] }} {{eqn | r = \frac 1 {a \sqrt 2} \ln \size {\frac {u - 1 + \sqrt 2} {u - 1 - \sqrt 2} } + C | c = simplifying }} {{eqn | r = \frac 1 {a \sqrt 2} \ln \size {\frac {\tan \dfrac {a x} 2 - \paren {1 - \sqrt 2} } {\tan \dfrac {a x} 2 - \paren {1 + \sqrt 2} } } + C | c = substituting for $u$ }} {{eqn | r = \frac 1 {a \sqrt 2} \ln \size {\frac {\tan \dfrac {a x} 2 - \tan \dfrac \pi 8} {\tan \dfrac {a x} 2 - \tan \dfrac {3 \pi} 8} } + C | c = [[Tangent of 22.5 Degrees|Tangent of $\dfrac \pi 8$]] and [[Tangent of 67.5 Degrees|Tangent of $\dfrac {3 \pi} 8$]] }} {{end-eqn}}	0
From [[Equation of Circle in Complex Plane/Formulation 1|Equation of Circle in Complex Plane]], the [[Definition:Circle|circle]] $C$ itself is given by: :$\left\lvert{z - \alpha}\right\rvert = r$ {{ProofWanted|This needs to be put into the rigorous context of Jordan curves, so as to define what is actually meant by "interior". At the moment, the understanding is intuitive.}}	0
:$\cot 195 \degrees = \cot \dfrac {13 \pi} {12} = 2 + \sqrt 3$	0
{{begin-eqn}} {{eqn | l = \frac 1 {1 + \cos x} | r = \frac 1 {1 + \frac {1- \tan^2 \frac x 2} {1 + \tan^2 \frac x 2} } | c = [[Tangent Half-Angle Substitution for Cosine]] }} {{eqn | r = \frac {1 + \tan^2 \frac x 2} 2 | c = multiplying through $\frac {1 + \tan^2 \frac x 2} {1 + \tan^2 \frac x 2}$ }} {{eqn | r = \frac 1 2 \sec^2 \frac x 2 | c = [[Difference of Squares of Secant and Tangent]] }} {{end-eqn}} {{qed}}	0
From the definition of the [[Definition:Cotangent|cotangent]] function: :$\cot x = \dfrac {\cos x} {\sin x}$ From [[Derivative of Sine Function]]: :$\map {\dfrac \d {\d x} } {\sin x} = \cos x$ From [[Derivative of Cosine Function]]: :$\map {\dfrac \d {\d x} } {\cos x}= -\sin x$ Then: {{begin-eqn}} {{eqn | l = \map {\dfrac \d {\d x} } {\cot x} | r = \frac {\sin x \paren {-\sin x} - \cos x \cos x} {\sin^2 x} | c = [[Quotient Rule for Derivatives]] }} {{eqn | r = \frac {-\paren {\sin^2 x + \cos^2 x} } {\sin^2 x} | c = }} {{eqn | r = \frac {-1} {\sin^2 x} | c = [[Sum of Squares of Sine and Cosine]] }} {{end-eqn}} This is valid only when $\sin x \ne 0$. The result follows from the definition of the [[Definition:Real Cosecant Function|real cosecant]] function. {{qed}}	0
{{begin-eqn}} {{eqn | l = \int \sec x \rd x | r = \ln \size {\tan x + \sec x} + C | c = [[Primitive of Secant Function/Secant plus Tangent Form|Primitive of $\sec x$: Secant plus Tangent Form]] }} {{eqn | r = \ln \size {\map \tan {\frac x 2 + \frac \pi 4} } + C | c = [[Tangent of Half Angle plus Quarter Pi|Tangent of Half Angle plus $\dfrac \pi 4$]] }} {{end-eqn}} {{qed}}	0
: $\cos \paren {6 \theta} = 32 \cos^6 \theta - 48 \cos^4 \theta + 18 \cos^2 \theta - 1$	0
Let the [[Definition:Circle|circles]] $ABC$ and $ADE$ touch externally at $A$. Let $F$ be the center of $ABC$ and let $G$ be the center of $ADE$. We are to show that the [[Definition:Straight Line|straight line]] joining $F$ to $G$ passes through $A$. :[[File:Euclid-III-12.png|400px]] Suppose, as in the diagram above, that it does not, and that it were possible for it to pass through $C$ and $D$, as $FCDG$. (It is clear that the diagram does ''not'' have $F$ and $G$ as the ''actual'' centers of these circles - it is the point of this proof to demonstrate that this would ''not'' be possible.) [[Axiom:Euclid's First Postulate|Join]] $AF$ and $AG$. We have that: * Since $F$ is the [[Definition:Center of Circle|center]] of $ABC$, then $FA$ and $FC$ are both [[Definition:Radius of Circle|radii]] of $ABC$, and so $FA = FC$. * Since $G$ is the [[Definition:Center of Circle|center]] of $ADE$, then $GA$ and $GD$ are both [[Definition:Radius of Circle|radii]] of $ADE$, and so $GA = GD$. So $FA + AG = FC + GD$. So all of $FCDG$ is greater than $FA + AG$. But from [[Sum of Two Sides of Triangle Greater than Third Side]] $FA + AG$ is greater than $FCDG$. Hence we have a contradiction, and so $FG$ has to go through point $A$, the point of contact of the two circles. Hence the result. {{Qed}} {{Euclid Note|12|III}}	0
:$\displaystyle \int x^m \operatorname{arcsec} \frac x a \ \mathrm d x = \begin{cases} \displaystyle \frac {x^{m + 1} } {m + 1} \operatorname{arcsec} \frac x a - \frac a {m + 1} \int \frac {x^m \ \mathrm d x} {\sqrt {x^2 - a^2} } + C & : 0 < \operatorname{arcsec} \dfrac x a < \dfrac \pi 2 \\ \displaystyle \frac {x^{m + 1} } {m + 1} \operatorname{arcsec} \frac x a + \frac a {m + 1} \int \frac {x^m \ \mathrm d x} {\sqrt {x^2 - a^2} } + C & : \dfrac \pi 2 < \operatorname{arcsec} \dfrac x a < \pi \\ \end{cases}$	0
:$\displaystyle \int \frac {\arccos \frac x a \rd x} x = \frac \pi 2 \ln \size x - \int \frac {\arcsin \frac x a \rd x} x + C$	0
: $\tan \left({x + \pi}\right) = \tan x$	0
{{begin-eqn}} {{eqn | l = \sin \sqrt t | r = \sum_{n \mathop = 0}^\infty \paren {-1}^n \frac {\paren {\sqrt t}^{2 n + 1} } {\paren {2 n + 1}!} | c = {{Defof|Real Sine Function}} }} {{eqn | r = \sum_{n \mathop = 0}^\infty \frac {\paren {-1}^n} {\paren {2 n + 1}!} t^{n + \frac 1 2} | c = }} {{eqn | ll= \leadsto | l = \laptrans {\sin \sqrt t} | r = \sum_{n \mathop = 0}^\infty \paren {-1}^n \frac {\map \Gamma {n + \frac 3 2} } {\paren {2 n + 1}! s^{n + \frac 3 2} } | c = [[Laplace Transform of Power]], [[Linear Combination of Laplace Transforms]] }} {{eqn | r = \frac 1 {s^{3/2} } \sum_{n \mathop = 0}^\infty \paren {-1}^n \frac {\paren {n + \frac 1 2} \map \Gamma {n + \frac 1 2} } {\paren {2 n + 1}! s^n} | c = [[Gamma Difference Equation]] }} {{eqn | r = \frac {\sqrt \pi} {2 s^{3/2} } \sum_{n \mathop = 0}^\infty \paren {-1}^n \frac {\paren {2 n + 1} \paren {2 n}!} {2^{2 n} n! \paren {2 n + 1}! s^n} | c = [[Gamma Function of Positive Half-Integer]] }} {{eqn | r = \frac {\sqrt \pi} {2 s^{3/2} } \sum_{n \mathop = 0}^\infty \frac {\paren {-1}^n} {2^{2 n} n! s^n} | c = }} {{eqn | r = \frac {\sqrt \pi} {2 s^{3/2} } \sum_{n \mathop = 0}^\infty \frac 1 {n!} \paren {-\frac 1 {2^2 s} }^n | c = }} {{eqn | r = \dfrac {\sqrt \pi} {2 s^{3/2} } e^{-1/\paren {2^2 s} } | c = {{Defof|Exponential Function/Real|subdef = Sum of Series|Exponential Function}} }} {{eqn | r = \dfrac {\sqrt \pi} {2 s^{3/2} } \map \exp {-\dfrac 1 {4 s} } | c = simplifying }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \int \frac {\d x} {p + q \cos a x} | r = \frac 2 {a \paren {p - q} } \int \frac {\d u} {u^2 + \dfrac {p + q} {p - q} } | c = [[Primitive of Reciprocal of p plus q by Cosine of a x/Weierstrass Substitution|Weierstrass Substitution]]: $u = \tan \dfrac {a x} 2$ }} {{end-eqn}} Let $p^2 > q^2$. Then, by [[Sign of Quotient of Factors of Difference of Squares]]: :$\dfrac {p + q} {p - q} > 0$ Thus, let $\dfrac {p + q} {p - q} = d^2$. Then: {{begin-eqn}} {{eqn | l = \int \frac {\d x} {p + q \cos a x} | r = \frac 2 {a \paren {p - q} } \int \frac {\d u} {u^2 + d^2} | c = }} {{eqn | r = \frac 2 {a \paren {p - q} } \frac 1 d \arctan \frac u d + C | c = [[Primitive of Reciprocal of x squared plus a squared/Arctangent Form|Primitive of $\dfrac 1 {x^2 + a^2}$]] }} {{eqn | r = \frac 2 {a \paren {p - q} } \frac 1 {\sqrt {\dfrac {p + q} {p - q} } } \map \arctan {\frac {\tan \dfrac {a x} 2} {\sqrt {\dfrac {p + q} {p - q} } } } + C | c = substituting for $u$ and $d$ }} {{eqn | r = \frac 2 {a \sqrt {p^2 - q^2} } \map \arctan {\sqrt {\frac {p - q} {p + q} } \tan \dfrac {a x} 2} + C | c = simplifying }} {{end-eqn}} {{qed|lemma}} Now let $p^2 < q^2$. Then, by [[Sign of Quotient of Factors of Difference of Squares]]: :$\dfrac {p + q} {p - q} < 0$ Thus, let: :$-\dfrac {p + q} {p - q} = d^2$ or: :$\dfrac {q + p} {q - p} = d^2$ Then: {{begin-eqn}} {{eqn | l = \int \frac {\d x} {p + q \cos a x} | r = \frac 2 {a \paren {p - q} } \int \frac {\d u} {u^2 - d^2} | c = }} {{eqn | r = \frac 2 {a \paren {p - q} } \frac 1 {2 d} \ln \size {\frac {u - d} {u + d} } + C | c = [[Primitive of Reciprocal of x squared minus a squared/Logarithm Form|Primitive of $\dfrac 1 {x^2 - a^2}$]] }} {{eqn | r = \frac 1 {a \paren {p - q} } \frac 1 {\sqrt {\dfrac {q + p} {q - p} } } \ln \size {\frac {\tan \dfrac {a x} 2 - \sqrt {\dfrac {q + p} {q - p} } } {\tan \dfrac {a x} 2 + \sqrt {\dfrac {q + p} {q - p} } } } + C | c = substituting for $u$ and $d$ }} {{eqn | r = \frac 1 {a \sqrt {q^2 - p^2} } \ln \size {\frac {\tan \dfrac {a x} 2 - \sqrt {\dfrac {q + p} {q - p} } } {\tan \dfrac {a x} 2 + \sqrt {\dfrac {q + p} {q - p} } } } + C | c = simplifying }} {{end-eqn}} {{qed}}	0
Let $L_1$ and $L_2$ be [[Definition:Straight Line|straight lines]] in [[Definition:The Plane|the plane]]. Let $L_1$ and $L_2$ have [[Definition:Slope|slopes]] of $m_1$ and $m_2$ respectively. Then $L_1$ and $L_2$ are [[Definition:Perpendicular Lines|perpendicular]] {{iff}} $m_1 m_2 = -1$.	0
From the [[General Binomial Theorem]]: {{begin-eqn}} {{eqn | l = \paren {1 - x^2}^{-1/2} | r = 1 + \frac 1 2 x^2 + \frac {1 \times 3} {2 \times 4} x^4 + \frac {1 \times 3 \times 5} {2 \times 4 \times 6} x^6 + \cdots | c = }} {{eqn | n = 1 | r = \sum_{n \mathop = 0}^\infty \frac {\paren {2 n}!} {2^{2 n} \paren {n!}^2} x^{2 n} | c = }} {{end-eqn}} for $-1 < x < 1$. From [[Power Series is Termwise Integrable within Radius of Convergence]], $(1)$ can be [[Definition:Integration|integrated]] term by term: {{begin-eqn}} {{eqn | l = \int_0^x \frac 1 {\sqrt{1 - t^2} } \rd t | r = \sum_{n \mathop = 0}^\infty \int_0^x \frac {\paren {2 n}!} {2^{2 n} \paren {n!}^2} t^{2 n} \rd t | c = }} {{eqn | ll= \leadsto | l = \arcsin x | r = \sum_{n \mathop = 0}^\infty \frac {\paren {2 n}!} {2^{2 n} \paren {n!}^2} \frac {x^{2 n + 1} } {2 n + 1} | c = [[Derivative of Arcsine Function]] }} {{end-eqn}} We will now prove that the series [[Definition:Convergent Series|converges]] for $-1 \le x \le 1$. By [[Stirling's Formula]]: {{begin-eqn}} {{eqn | l = \frac {\paren {2 n}!} {2^{2 n} \paren {n!}^2} \frac {x^{2 n + 1} } {2 n + 1} | o = \sim | r = \frac {\paren {2 n}^{2 n} e^{-2 n} \sqrt {4 \pi n} } {2^{2 n} n^{2 n} e^{-2 n} 2 \pi n} \frac {x^{2 n + 1} } {2 n + 1} | c = }} {{eqn | r = \frac 1 {\sqrt {\pi n} } \frac {x^{2 n + 1} } {2 n + 1} | c = }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = \size {\frac 1 {\sqrt {\pi n} } \frac {x^{2 n + 1} } {2 n + 1} } | o = < | r = \size {\frac {x^{2 n + 1} } {n^{3/2} } } | c = }} {{eqn | o = \le | r = \frac 1 {n^{3/2} } | c = }} {{end-eqn}} Hence by [[Convergence of P-Series]]: :$\displaystyle \sum_{n \mathop = 1}^\infty \frac 1 {n^{3/2} }$ is [[Definition:Convergent Series|convergent]]. So by the [[Comparison Test]], the [[Definition:Taylor Series|Taylor series]] is [[Definition:Convergent Series|convergent]] for $-1 \le x \le 1$. {{qed}}	0
Since the [[Definition:Open Real Interval|open interval]] $\openint 0 \infty$ is [[Definition:Connected (Topology)|connected]], then so is $G$ by [[Continuous Image of Connected Space is Connected]]. It is enough, from [[Set between Connected Set and Closure is Connected]], to show that $J \subseteq \map \cl G$. Let $p \in J$, say, $\tuple {0, y}$ where $-1 \le y \le 1$. We need to show that: :$\forall \epsilon > 0: \map {N_\epsilon} p \cap G \ne \O$ where $\map {N_\epsilon} p$ is the [[Definition:Epsilon-Neighborhood (Real Number Line)|$\epsilon$-neighborhood]] of $p$. Let us choose $n \in \N: \dfrac 1 {2 n \pi} < \epsilon$. From [[Sine of Half-Integer Multiple of Pi]]: :$\map \sin {\dfrac {\paren {4 n + 1} \pi} 2} = 1$ and: :$\map \sin {\dfrac {\paren {4 n + 3} \pi} 2} = -1$ So by the [[Intermediate Value Theorem]], $\map \sin {\dfrac 1 x}$ takes every value between $-1$ and $1$ in the [[Definition:Closed Real Interval|closed interval]] $\closedint {\dfrac 2 {\paren {4 n + 3} \pi} } {\dfrac 2 {\paren {4 n + 1} \pi} }$. In particular, $\map \sin {\dfrac 1 {x_0} } = y$ for some $x_0$ in this interval. The distance between the points $\tuple {0, y}$ and $\tuple {x_0, \map \sin {\dfrac 1 {x_0} } } = \tuple {x_0, y}$ is $x_0 < \epsilon$. So: :$\tuple {x_0, \map \sin {\dfrac 1 {x_0} } } \in \map {N_\epsilon} p \cap G$ as required. {{qed}}	0
{{begin-eqn}} {{eqn | l = \map {\tanh^{-1} } {\dfrac 1 x} | r = y | c = }} {{eqn | ll= \leadstoandfrom | l = \frac 1 x | r = \tanh y | c = {{Defof|Inverse Hyperbolic Tangent}} }} {{eqn | ll= \leadstoandfrom | l = \frac 1 x | r = \frac {\cosh y} {\sinh y} | c = {{Defof|Hyperbolic Tangent|index = 2}} }} {{eqn | ll= \leadstoandfrom | l = x | r = \frac {\sinh y} {\cosh y} | c = }} {{eqn | ll= \leadstoandfrom | l = x | r = \coth y | c = {{Defof|Hyperbolic Cotangent|index = 2}} }} {{eqn | ll= \leadstoandfrom | l = \coth^{-1} x | r = y | c = {{Defof|Inverse Hyperbolic Cotangent}} }} {{end-eqn}} {{qed}}	0
:$\map \cos {\dfrac \pi 2 - \theta} = \sin \theta$	0
Let $T = \struct {S, \tau}$ be [[Definition:Irreducible Space|irreducible]]. Then: :$\forall U_1, U_2 \in \tau: U_1, U_2 \ne \O \implies U_1 \cap U_2 \ne \O$ So trivially there are no two [[Definition:Open Set (Topology)|open sets]] that can form a [[Definition:Separation (Topology)|separation]] of $T$. As a [[Definition:Basis (Topology)|basis]] consists of [[Definition:Open Set (Topology)|open sets]], this applies to all sets in a [[Definition:Basis (Topology)|basis]] for $T$. The result follows from definition of [[Definition:Locally Connected Space|locally connected]]. {{qed}}	0
{{begin-eqn}} {{eqn | l = \int \sin a x \cos a x \rd x | r = \int \frac {\sin 2 a x} 2 \rd x | c = [[Double Angle Formula for Sine]] }} {{eqn | r = \frac {-\cos 2 a x} {4 a} + C | c = [[Primitive of Cosine of a x|Primitive of $\cos a x$]] }} {{eqn | r = \frac {-\paren {1 - 2 \sin^2 a x} } {4 a} + C | c = [[Double Angle Formulas/Cosine/Corollary 2|Double Angle Formula for Cosine: Corollary 2]] }} {{eqn | r = \frac {-1} {4 a} + \frac {\sin^2 a x} {2 a} + C | c = separating fraction }} {{eqn | r = \frac {\sin^2 a x} {2 a} + C | c = subsuming $\dfrac {-1} {4 a}$ into [[Definition:Arbitrary Constant (Calculus)|arbitrary constant]] }} {{end-eqn}} {{qed}}	0
Let $A = \begin{pmatrix} 1 & 1 \\ 1 & 0 \end{pmatrix}$. First by the [[Cassini's Identity/Lemma|lemma to Cassini's Identity]]: :$(1): \quad \forall n \in \Z_{>1}: A^n = \begin{bmatrix} F_{n + 1} & F_n \\ F_n & F_{n - 1} \end{bmatrix}$ Next is is demonstrated that $A$ has the [[Definition:Eigenvalue|eigenvalues]] $\phi$ and $\hat \phi$, where $\hat \phi = 1 - \phi$. Now we have that: {{begin-eqn}} {{eqn | n = 2 | l = A \begin{pmatrix} \phi \\ 1 \end{pmatrix} | r = \begin{pmatrix} \phi + 1 \\ \phi \end{pmatrix} }} {{eqn | r = \phi \begin{pmatrix} \phi \\ 1 \end{pmatrix} | c = since $\phi$ is a solution of $x^2 - x - 1 = 0$ }} {{eqn | l = A \begin{pmatrix} \hat \phi \\ 1 \end{pmatrix} | r = \begin{pmatrix} \hat \phi + 1 \\ \hat \phi \end{pmatrix} }} {{eqn | r = \hat \phi \begin{pmatrix} \hat \phi \\ 1 \end{pmatrix} | c = since $\hat \phi$ is a solution of $x^2 - x - 1 = 0$ }} {{end-eqn}} This shows that: :$\displaystyle \begin{pmatrix} \phi \\ 1 \end{pmatrix}$ is an [[Definition:Eigenvector|eigenvector]] of $A$ with [[Definition:Eigenvalue|eigenvalue]] $\phi$ and: :$\displaystyle \begin{pmatrix} \hat \phi \\ 1 \end{pmatrix}$ is an [[Definition:Eigenvector|eigenvector]] of $A$ with [[Definition:Eigenvalue|eigenvalue]] $\hat \phi$. Thus: :$\displaystyle \begin{pmatrix} \frac \phi {\sqrt 5} \\ \frac 1 {\sqrt 5} \end{pmatrix}$ is an [[Definition:Eigenvector|eigenvector]] of $A$ with [[Definition:Eigenvalue|eigenvalue]] $\phi$ and: :$\displaystyle \begin{pmatrix} \frac {\hat \phi} {\sqrt 5} \\ \frac 1 {\sqrt 5} \end{pmatrix}$ is an [[Definition:Eigenvector|eigenvector]] of $A$ with [[Definition:Eigenvalue|eigenvalue]] $\hat \phi$. By [[Eigenvalue of Matrix Powers]] we get for a positive integer $n$: {{begin-eqn}} {{eqn | l = \phi^n \begin{pmatrix} \frac \phi {\sqrt 5} \\ \frac 1 {\sqrt 5} \end{pmatrix} | r = A^n \begin{pmatrix} \frac \phi {\sqrt 5} \\ \frac 1 {\sqrt 5} \end{pmatrix} }} {{eqn | l = {\hat \phi}^n \begin{pmatrix} \frac {\hat \phi} {\sqrt 5} \\ \frac 1 {\sqrt 5} \end{pmatrix} | r = A^n \begin{pmatrix} \frac {\hat \phi} {\sqrt 5} \\ \frac 1 {\sqrt 5} \end{pmatrix} }} {{end-eqn}} From $(1)$ we get: :$A^n \begin{pmatrix} 1 \\ 0 \end{pmatrix} = \begin{pmatrix} F_{n + 1} \\ F_n \end{pmatrix}$ Substituting: :$\begin{pmatrix} 1 \\ 0 \end{pmatrix} = \begin{pmatrix} \frac \phi {\sqrt 5} \\ \frac 1 {\sqrt 5} \end{pmatrix} - \begin{pmatrix} \frac {\hat \phi} {\sqrt 5} \\ \frac 1 {\sqrt 5} \end{pmatrix}$ we get: {{begin-eqn}} {{eqn | l = \begin{pmatrix} F_{n + 1} \\ F_n \end{pmatrix} | r = \frac 1 {\sqrt 5} A^n \left({\begin{pmatrix} \phi \\ 1 \end{pmatrix} - \begin{pmatrix} \hat \phi \\ 1 \end{pmatrix} }\right) }} {{eqn | r = A^n \begin{pmatrix} \frac \phi {\sqrt 5} \\ \frac 1 {\sqrt 5} \end{pmatrix} - A^n \begin{pmatrix} \frac {\hat \phi} {\sqrt 5} \\ \frac 1 {\sqrt 5} \end{pmatrix} }} {{eqn | r = \phi^n \begin{pmatrix} \frac \phi {\sqrt 5} \\ \frac 1 {\sqrt 5} \end{pmatrix} - \hat \phi^n \begin{pmatrix} \frac {\hat \phi} {\sqrt 5} \\ \frac 1 {\sqrt 5} \end{pmatrix} }} {{eqn | r = \frac 1 {\sqrt 5} \begin{pmatrix} \phi^n \cdot \phi - \hat \phi^n \cdot \hat \phi \\ \phi^n - \hat \phi^n \end{pmatrix} }} {{end-eqn}} Hence the result. {{Qed}}	0
{{begin-eqn}} {{eqn | l = \int e^{a x} \cos b x \rd x | r = \frac {e^{a x} \cos b x} a + \frac b a \int e^{a x} \sin b x \rd x | c = [[Primitive of Exponential of a x by Cosine of b x/Lemma|Primitive of $e^{a x} \cos b x$: Lemma]] }} {{eqn | r = \frac {e^{a x} \cos b x} a + \frac b a \paren {\frac {e^{a x} \sin b x} a - \frac b a \int e^{a x} \cos b x \rd x} | c = [[Primitive of Exponential of a x by Sine of b x/Lemma|Primitive of $e^{a x} \sin b x$: Lemma]] }} {{eqn | r = \frac {e^{a x} a \cos b x + e^{a x} b \sin b x} {a^2} - \frac {b^2} {a^2} \int e^{a x} \cos b x \rd x | c = simplifying }} {{eqn | ll= \leadsto | l = \paren {1 + \frac {b^2} {a^2} } \int e^{a x} \cos b x \rd x | r = \frac {e^{a x} \paren {a \cos b x + b \sin b x} } {a^2} | c = simplifying }} {{eqn | ll= \leadsto | l = \frac {a^2 + b^2} {a^2} \int e^{a x} \cos b x \rd x | r = \frac {e^{a x} \paren {a \cos b x + b \sin b x} } {a^2} | c = common denominator }} {{eqn | ll= \leadsto | l = \int e^{a x} \cos b x \rd x | r = \frac {e^{a x} \paren {a \cos b x + b \sin b x} } {a^2 + b^2} | c = multiplying by $\dfrac {a^2} {a^2 + b^2}$ }} {{end-eqn}} {{qed}}	0
Let $p$ be an [[Definition:Odd Prime|odd prime]]. Let $C$ be a [[Definition:Circle|circle]] whose [[Definition:Center of Circle|center]] is $O$. Consider the [[Definition:Set|set]] $P$ of $p$ [[Definition:Point|points]] on the [[Definition:Circumference of Circle|circumference]] of $C$ dividing it into $p$ equal [[Definition:Arc of Circle|arcs]]. Let $S$ be the [[Definition:Set|set]] of all non-[[Definition:Regular Stellated Polygon|regular]] [[Definition:Stellated Polygon|stellated $p$-gons]] whose [[Definition:Vertex of Polygon|vertices]] are the [[Definition:Element|elements]] of $P$. Let $\sim$ denote the [[Definition:Equivalence Relation|equivalence relation on $S$]] defined as: :$\forall \tuple {a, b} \in S \times S: a \sim b \iff$ there exists a [[Definition:Plane Rotation|plane rotation]] about $O$ transforming $a$ to $b$. Then the [[Definition:Equivalence Class|$\sim$-equivalence classes]] of $S$ into which $S$ can thereby be [[Definition:Set Partition|partitioned]] all have [[Definition:Cardinality|cardinality]] $p$.	0
The proof proceeds by [[Principle of Mathematical Induction|induction]]. For all $n \in \Z_{> 0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\displaystyle \int_0^{\frac \pi 2} \cos^{2 n} x \rd x = \dfrac {\paren {2 n}!} {\paren {2^n n!}^2} \dfrac \pi 2$ === Basis for the Induction === $\map P 1$ is the case: {{begin-eqn}} {{eqn | l = \int_0^{\frac \pi 2} \cos^2 x \rd x | r = \frac \pi 4 | c = [[Definite Integral from 0 to Half Pi of Square of Cosine x]] }} {{eqn | r = \dfrac 1 2 \times \dfrac \pi 2 | c = }} {{eqn | r = \dfrac 2 {\paren {2 \times 1}^2} \dfrac \pi 2 | c = }} {{eqn | r = \dfrac {\paren {2 \times 1}!} {\paren {2^1 \times 1!}^2} \dfrac \pi 2 | c = }} {{end-eqn}} Thus $\map P 1$ is seen to hold. This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is the [[Definition:Induction Hypothesis|induction hypothesis]]: :$\displaystyle \int_0^{\frac \pi 2} \cos^{2 k} x \rd x = \dfrac {\paren {2 k}!} {\paren {2^k k!}^2} \dfrac \pi 2$ from which it is to be shown that: :$\displaystyle \int_0^{\frac \pi 2} \cos^{2 \paren {k + 1} } x \rd x = \dfrac {\paren {2 \paren {k + 1} }!} {\paren {2^{k + 1} \paren {k + 1}!}^2} \dfrac \pi 2$ === Induction Step === This is the [[Definition:Induction Step|induction step]]: Let $I_k = \displaystyle \int_0^{\frac \pi 2} \cos^{2 k} x \rd x$. {{begin-eqn}} {{eqn | l = I_{k + 1} | r = \frac {2 \paren {k + 1} - 1} {2 \paren {k + 1} } I_k | c = [[Reduction Formula for Definite Integral of Power of Cosine]] }} {{eqn | r = \frac {2 \paren {k + 1} - 1} {2 \paren {k + 1} } \dfrac {\paren {2 k}!} {\paren {2^k k!}^2} \dfrac \pi 2 | c = [[Definite Integral from 0 to Half Pi of Even Power of Cosine x#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \frac {2 \paren {k + 1} \paren {2 \paren {k + 1} - 1} } {2^2 \paren {k + 1}^2} \dfrac {\paren {2 k}!} {\paren {2^k k!}^2} \dfrac \pi 2 | c = }} {{eqn | r = \dfrac {\paren {2 \paren {k + 1} }!} {\paren {2^{k + 1} \paren {k + 1}!}^2} \dfrac \pi 2 | c = }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\displaystyle \forall n \in \Z_{> 0}: \int_0^{\frac \pi 2} \cos^{2 n} x \rd x = \dfrac {\paren {2 n}!} {\paren {2^n n!}^2} \dfrac \pi 2$ {{qed}}	0
:$\displaystyle \int \tan^n a x \ \mathrm d x = \frac {\tan^{n - 1} a x} {\left({n - 1}\right) a} - \int \tan^{n - 2} a x \ \mathrm d x + C$	0
{{WLOG}}, we will only prove $OB$ [[Definition:Angle Bisector|bisects]] $\angle AOC$. Let the [[Definition:Vector (Euclidean Space)|position vector]] of $A$, $B$ and $C$ with respect to $O$ be $\mathbf a$, $\mathbf b$ and $\mathbf c$ respectively. By definition of [[Definition:Rhombus|rhombus]], we have: {{begin-eqn}} {{eqn | n = a | l = \mathbf a + \mathbf c | r = \mathbf b | c = [[Parallelogram Law]] }} {{eqn | n = b | l = \norm {\mathbf a} | r = \norm {\mathbf c} | c = }} {{end-eqn}} From the above we have: {{begin-eqn}} {{eqn | l = \cos \angle \mathbf a, \mathbf b | r = \frac {\mathbf a \cdot \mathbf b} {\norm {\mathbf a} \norm {\mathbf b} } | c = {{Defof|Dot Product|index = 2}} }} {{eqn | r = \frac {\mathbf a \cdot \paren {\mathbf a + \mathbf c} } {\norm {\mathbf a} \norm {\mathbf b} } | c = from $(a)$ above: $\mathbf b = \mathbf a + \mathbf c$ }} {{eqn | r = \frac {\mathbf a \cdot \mathbf a + \mathbf a \cdot \mathbf c} {\norm {\mathbf a} \norm {\mathbf b} } | c = [[Dot Product Distributes over Addition]] }} {{eqn | r = \frac { {\norm {\mathbf a} }^2 + \mathbf a \cdot \mathbf c} {\norm {\mathbf a} \norm {\mathbf b} } | c = [[Dot Product of Vector with Itself]] }} {{eqn | r = \frac { {\norm {\mathbf c} }^2 + \mathbf a \cdot \mathbf c} {\norm {\mathbf c} \norm {\mathbf b} } | c = from $(b)$ above: $\norm {\mathbf a} = \norm {\mathbf c}$ }} {{eqn | r = \frac {\mathbf c \cdot \mathbf c + \mathbf a \cdot \mathbf c} {\norm {\mathbf c} \norm {\mathbf b} } | c = [[Dot Product of Vector with Itself]] }} {{eqn | r = \frac {\mathbf c \cdot \left({\mathbf a + \mathbf c}\right)} {\norm {\mathbf c} \norm {\mathbf b} } | c = [[Dot Product Distributes over Addition]] }} {{eqn | r = \frac {\mathbf c \cdot \mathbf b} {\norm {\mathbf c} \norm {\mathbf b} } | c = from $(a)$ above: $\mathbf b = \mathbf a + \mathbf c$ }} {{eqn | r = \cos \angle \mathbf c, \mathbf b | c = {{Defof|Dot Product|index = 2}} }} {{end-eqn}} By definition of [[Definition:Dot Product/Definition 2|dot product]], the angle between the vectors is between $0$ and $\pi$. From [[Shape of Cosine Function]], [[Definition:Cosine|cosine]] is [[Definition:Injection|injective]] on this interval. Hence: :$\angle \mathbf a, \mathbf b = \angle \mathbf c, \mathbf b$ The result follows. {{qed}}	0
{{begin-eqn}} {{eqn | l = \cos i | r = \cosh 1 | c = [[Hyperbolic Cosine in terms of Cosine]] }} {{eqn | r = \frac {e^1 + e^{-1} } 2 | c = {{Defof|Hyperbolic Cosine}} }} {{eqn | r = \frac e 2 + \frac 1 {2 e} }} {{end-eqn}} {{qed}}	0
Let $M$ and $N$ be [[Definition:Metric Space|metric spaces]]. Let $M$ be [[Definition:Complete Metric Space|complete]]. Let $f : M \times N \to M$ be a [[Definition:Continuous Mapping|continuous]] [[Definition:Uniform Contraction Mapping|uniform contraction]]. Then for all $t \in N$ there exists a [[Definition:Unique|unique]] $g \left({t}\right) \in M$ such that $f(g \left({t}\right), t) = g \left({t}\right)$, and the [[Definition:Mapping|mapping]] $g: N \to M$ is [[Definition:Continuous Mapping (Metric Spaces)|continuous]].	0
Let $\lambda \in \R_{>0}$ be a [[Definition:Strictly Positive Real Number|strictly positive real number]]. Let $\map f x: \openint {-\lambda} \lambda \to \R$ be the [[Definition:Identity Function|identity function]] on the [[Definition:Open Real Interval|open real interval]] $\openint {-\lambda} \lambda$: :$\forall x \in \openint {-\lambda} \lambda: \map f x = x$ The [[Definition:Fourier Series|Fourier series]] of $f$ over $\openint {-\lambda} \lambda$ can be given as: :$\map f x \sim \dfrac {2 \lambda} \pi \displaystyle \sum_{n \mathop = 1}^\infty \frac {\paren {-1}^{n + 1} } n \sin \frac {n \pi x} \lambda$	0
{{begin-eqn}} {{eqn | l = \map \arccot {-x} | r = y | c = }} {{eqn | ll= \leadstoandfrom | l = -x | r = \cot y: | rr= 0 \le y \le \pi | c = {{Defof|Arccotangent}} }} {{eqn | ll= \leadstoandfrom | l = x | r = -\cot y: | rr= -\pi \le y \le 0 | c = }} {{eqn | ll= \leadstoandfrom | l = x | r = \map \cot {\pi - y}: | rr= 0 \le y \le \pi | c = [[Cotangent of Supplementary Angle]] }} {{eqn | ll= \leadstoandfrom | l = \arccot x | r = \pi - y | c = {{Defof|Arccotangent}} }} {{end-eqn}} {{qed}}	0
:$\cos 315 \degrees = \cos \dfrac {7 \pi} 4 = \dfrac {\sqrt 2} 2$	0
Let $T = \left({S, \tau}\right)$ be a [[Definition:Finite Set|finite]] [[Definition:Irreducible Space|irreducible topological space]]. Then $T$ is [[Definition:Path-Connected Space|path-connected]].	0
Let $C$ be a [[Definition:Cardioid|cardioid]] embedded in a [[Definition:Polar Coordinate Plane|polar coordinate plane]] such that: :its [[Definition:Stator of Epicycloid|stator]] of [[Definition:Radius of Circle|radius]] $a$ is positioned with its [[Definition:Center of Circle|center]] at $\polar {a, 0}$ :there is a [[Definition:Cusp of Epicycloid|cusp]] at the [[Definition:Origin|origin]]. The [[Definition:Polar Equation|polar equation]] of $C$ is: :$r = 2 a \paren {1 + \cos \theta}$	0
{{ProofWanted|Work to be done yet to establish method of creation}}	0
:$\cosh x + \cosh y = 2 \map \cosh {\dfrac {x + y} 2} \map \cosh {\dfrac {x - y} 2}$	0
:$\hat \phi = - \dfrac 1 \phi$ where: :$\phi$ denotes the [[Definition:Golden Mean|golden mean]] :$\hat \phi$ denotes [[Definition:One Minus Golden Mean|one minus the golden mean]]: $\hat \phi = 1 - \phi$.	0
:$\map \arccos {\dfrac 1 x} = \arcsec x$	0
:$\displaystyle \int \frac {\csc^2 a x \ \mathrm d x} {\cot a x} = \frac {-\ln \left\vert{\cot a x}\right\vert} a + C$	0
{{begin-eqn}} {{eqn | l = \cos 15^\circ | r = \cos \frac {30 \degrees} 2 | c = }} {{eqn | r = \sqrt {\frac {1 + \cos 30 \degrees} 2} | c = [[Half Angle Formula for Cosine]]: $\theta$ is in [[Definition:Cosine/Definition from Circle/First Quadrant|Quadrant I]] }} {{eqn | r = \sqrt {\frac {1 + \frac {\sqrt 3} 2} 2} | c = [[Cosine of 30 Degrees|Cosine of $30 \degrees$]] }} {{eqn | r = \sqrt {\frac {2 + \sqrt 3} 4} | c = }} {{eqn | r = \sqrt {\frac {8 + 4 \sqrt 3} {16} } | c = }} {{eqn | r = \sqrt {\frac {6 + 2 + 2 \sqrt 2 \sqrt 6} {16} } | c = }} {{eqn | r = \sqrt {\frac {\paren {\sqrt 6 + \sqrt 2}^2} {16} } | c = }} {{eqn | r = \frac {\sqrt 6 + \sqrt 2} 4 | c = positive because $\theta$ is in the [[Definition:Cosine/Definition from Circle/First Quadrant|first quadrant]] }} {{end-eqn}} {{qed}}	0
{{:Euclid:Proposition/II/5}} :[[File:Euclid-II-5.png|400px]] Let $AB$ be cut into equal segments at $C$ and unequal segments at $D$. Then the [[Definition:Containment of Rectangle|rectangle contained]] by $AD$ and $DB$ together with the square on $CD$ equals the square on $BC$. (That is, let $x = AC, y = CD$. Then $\paren {x + y} \paren {x - y} + y^2 = x^2$.) This is proved as follows. [[Construction of Square on Given Straight Line|Construct the square $CBFE$]] on $CB$, and join $BE$. [[Construction of Parallel Line|Construct $DG$ parallel]] to $CE$ through $G$, and let $DG$ cross $BE$ at $H$. [[Construction of Parallel Line|Construct $KM$ parallel]] to $AB$ through $H$. [[Construction of Parallel Line|Construct $AK$ parallel]] to $BF$ through $A$. From [[Complements of Parallelograms are Equal]]: :$\Box CDHL = \Box FGHM$. Add the square $DBMH$ to each. Then $\Box CBML = \Box DBFG$. But as $AC = CB$, from [[Parallelograms with Equal Base and Same Height have Equal Area]] we have that: :$\Box ACLK = \Box CBML$ Add $\Box CDHL$ to each. Then $\Box ADHK$ is equal in area to the [[Definition:Gnomon|gnomon]] $CBFGHL$. But $\Box ADHK$ is the [[Definition:Containment of Rectangle|rectangle contained]] by $AD$ and $DB$, because $DB = DH$. So the [[Definition:Gnomon|gnomon]] $CBFGHL$ is equal in area to the [[Definition:Containment of Rectangle|rectangle contained]] by $AD$ and $DB$. Now $\Box LHGE$ is equal to the square on $CD$. Add $\Box LHGE$ to each of the [[Definition:Gnomon|gnomon]] $CBFGHL$ and $\Box ADHK$. Then the [[Definition:Gnomon|gnomon]] $CBFGHL$ together with $\Box LHGE$ equals the [[Definition:Containment of Rectangle|rectangle contained]] by $AD$ and $DB$ and the square on $CD$. But the [[Definition:Gnomon|gnomon]] $CBFGHL$ together with $\Box LHGE$ is the square $CBFE$. Hence the result. {{qed}}	0
Let $\mathcal E$ be an [[Definition:Affine Space|affine space]] with [[Definition:Difference Space|difference space]] $V$. Let $0$ denote the [[Definition:Zero Element|zero element]] of $V$. Then the following hold for all $p,q,r \in \mathcal E$ and all $u,v \in V$: : $(1): \quad p - p = 0$ : $(2): \quad p + 0 = p$ : $(3): \quad p + u = p + v \iff u = v$ : $(4): \quad q - p = r - p \iff q = r$	0
:$\displaystyle \int \sin a x \cos a x \rd x = \frac {\sin^2 a x} {2 a} + C$	0
Let $\mathcal L$ denote the [[Definition:Logarithmic Derivative of Meromorphic Function|logarithmic derivative]]. On the [[Definition:Open Subset of Complex Plane|open set]] $\C \setminus \Z$ we have: {{begin-eqn}} {{eqn | l = \pi \cot \pi z | r = \mathcal L \left({\sin \left({\pi z}\right)}\right) | c = [[Primitive of Cotangent Function]], or a complex version thereof }} {{eqn | r = \mathcal L \left({\pi z \prod_{n \mathop = 1}^\infty \left({1 - \frac {z^2} {n^2} }\right)}\right) | c = [[Euler Formula for Sine Function]] }} {{eqn | r = \mathcal L \left({\pi z}\right) + \sum_{n \mathop = 1}^\infty \mathcal L \left({1 - \frac {z^2} {n^2} }\right) | c = [[Logarithmic Derivative of Infinite Product of Analytic Functions]] }} {{eqn | r = \frac \pi {\pi z} + \sum_{n \mathop = 1}^\infty \frac 1 {1 - \frac {z^2} {n^2} } \cdot \frac {\mathrm d} {\mathrm d z} \left({1 - \frac {z^2} {n^2} }\right) | c = {{Defof|Logarithmic Derivative of Meromorphic Function}} }} {{eqn | r = \frac 1 z - 2 \sum_{n \mathop = 1}^\infty \frac z {n^2 - z^2} | c = [[Derivative of Power]] }} {{eqn | r = \frac 1 z + 2 \sum_{n \mathop = 1}^\infty \frac z {z^2 - n^2} }} {{end-eqn}} {{qed}}	0
Let $X$ be a [[Definition:Noetherian Topological Space|noetherian topological space]]. Then $X$ is [[Definition:Compact Space|compact]].	0
:$\cos 144 \degrees = \cos \dfrac {4 \pi} 5 = -\dfrac \phi 2 = -\dfrac {1 + \sqrt 5} 4$	0
:[[File:IsoscelesTriangleArea.png|300px]] {{begin-eqn}} {{eqn | l = \mathcal A | r = \frac 1 2 b h | c = [[Area of Triangle in Terms of Side and Altitude]] }} {{eqn | r = \frac 1 2 b \paren {r \cos \dfrac \theta 2} | c = Definition of [[Definition:Cosine of Angle|Cosine]] }} {{eqn | r = \frac 1 2 2 \paren {r \sin \dfrac \theta 2} \paren {r \cos \dfrac \theta 2} | c = Definition of [[Definition:Sine of Angle|Sine]] }} {{eqn | r = \frac 1 2 r^2 \sin \theta | c = [[Double Angle Formula for Sine]] }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \paren {x + y} \circ \paren {x + \paren {-y} } | r = x \circ x + y \circ x + x \circ \paren {-y} + y \circ \paren {-y} | c = [[Definition:Distributive Operation|Distributivity]] of $\circ$ over $+$ in a [[Definition:Ring (Abstract Algebra)|ring]] }} {{eqn | r = x \circ x + x \circ y + x \circ \paren {-y} + y \circ \paren {-y} | c = $R$ is a [[Definition:Commutative Ring|commutative ring]] }} {{eqn | r = x \circ x + x \circ \paren {y + \paren {-y} } + \paren {-\paren {y \circ y} } | c = various [[Definition:Ring (Abstract Algebra)|ring]] properties }} {{eqn | r = x \circ x + x \circ 0_R + \paren {-\paren {y \circ y} } | c = }} {{eqn | r = x \circ x + \paren {-\paren {y \circ y} } | c = }} {{end-eqn}} {{qed}}	0
:$\tan 30^\circ = \tan \dfrac \pi 6 = \dfrac {\sqrt 3} 3$	0
Everywhere that the function is defined: :$\map \arctan {-x} = -\arctan x$	0
A '''spiral''' is a [[Definition:Plane Curve|plane curve]], or part of a [[Definition:Plane Curve|plane curve]], which can be expressed in [[Definition:Polar Coordinates|polar coordinates]] in the form: :$r = \map f \theta$ where $f$ is either [[Definition:Strictly Increasing Real Function|(strictly) increasing]] or [[Definition:Strictly Decreasing Real Function|(strictly) decreasing]]. Hence a '''spiral''' is a [[Definition:Plane Curve|plane curve]] which emanates from a central [[Definition:Point|point]], getting progressively farther away (or closer in) as it revolves around that [[Definition:Point|point]].	0
:[[File:Euclid-I-45.png|600px]] Let $ABCD$ be the given [[Definition:Polygon|polygon]], and let $E$ be the given [[Definition:Rectilinear Angle|angle]]. Join $DB$, and [[Construction of Parallelogram equal to Triangle in Given Angle|construct the parallelogram]] $FGHK$ equal in size to $\triangle ABD$, in $\angle HKF = \angle E$. Then [[Construction of Parallelogram on Given Line equal to Triangle in Given Angle|construct the parallelogram]] $GLMH$ equal in area to $\triangle BCD$ on the [[Definition:Line Segment|line segment]] $GH$, in $\angle GHM = \angle E$. We now need to show that $KFLM$ is the required [[Definition:Parallelogram|parallelogram]]. By [[Axiom:Euclid's Common Notions|common notion 1]], $\angle HKF = \angle GHM$ as both are equal to $\angle E$. Add $\angle KHG$ to each, so as to make $\angle FKH + \angle KHG = \angle KHG + \angle GHM$. From [[Parallelism implies Supplementary Interior Angles]]: :$\angle FKH + \angle KHG$ Therefore $\angle KHG + \angle GHM$ equal two [[Definition:Right Angle|right angles]]. So from [[Two Angles making Two Right Angles make Straight Line]], $KH$ is in a [[Definition:Straight Line|straight line]] with $HM$. From [[Parallelism implies Equal Alternate Angles]]: :$\angle MHG = \angle HGF$ Add $\angle HGL$ to each, so as to make $\angle MHG + \angle HGL = \angle HGF + \angle HGL$. From [[Parallelism implies Supplementary Interior Angles]]: :$\angle MHG + \angle HGL$ Therefore $\angle HGF + \angle HGL$ equal two [[Definition:Right Angle|right angles]]. So from [[Two Angles making Two Right Angles make Straight Line]], $FG$ is in a [[Definition:Straight Line|straight line]] with $GL$. From [[Parallelism is Transitive Relation]], as $KF \parallel HG$ and $HG \parallel ML$, it follows that $KF \parallel ML$. Similarly, from [[Axiom:Euclid's Common Notions|common notion 1]], $KF = ML$. As $KM$ and $FL$ join them at their [[Definition:Endpoint of Line|endpoints]], $KM \parallel FL$ and $KM = FL$ from [[Lines Joining Equal and Parallel Straight Lines are Parallel]]. Therefore $KFLM$ is a [[Definition:Parallelogram|parallelogram]]. But the area of $KFLM$ equals the combined areas of $FGHK$ and $GLMH$, which are equal to the combined areas of $\triangle ABD$ and $\triangle BCD$. Therefore from [[Axiom:Euclid's Common Notions|common notion 2]], $KFLM$ has the same area as the [[Definition:Polygon|polygon]] $ABCD$, in the angle $E$ {{qed}} {{Euclid Note|45|I|Note that this technique can be expanded for a [[Definition:Polygon|polygon]] with any number of [[Definition:Side of Polygon|sides]], merely by dividing the polygon up into as many [[Definition:Triangle (Geometry)|triangles]] as it takes.}}	0
{{begin-eqn}} {{eqn | l = \csc 330 \degrees | r = \map \csc {360 \degrees - 30 \degrees} | c = }} {{eqn | r = -\csc 30 \degrees | c = [[Cosecant of Conjugate Angle]] }} {{eqn | r = -2 | c = [[Cosecant of 30 Degrees|Cosecant of $30 \degrees$]] }} {{end-eqn}} {{qed}}	0
The vectors $\left\Vert{\mathbf u}\right\Vert \mathbf v$ and $\left\Vert{\mathbf v}\right\Vert \mathbf u$ have equal length from [[Vector Times Magnitude Same Length As Magnitude Times Vector]]. Thus $\left\Vert{\mathbf u}\right\Vert \mathbf v + \left\Vert{\mathbf v}\right\Vert \mathbf u$ is the diagonal of a [[Definition:Rhombus|rhombus]]. The result follows from [[Diagonals of Rhombus Bisect Angles]]. {{qed}}	0
The points in $\C$ which correspond to the [[Definition:Interior (Complex Analysis)|interior]] of $C$ can be defined by: :$\left\lvert{z - \alpha}\right\rvert < r$	0
From [[Sine of 90 Degrees|Sine of $90 \degrees$]]: :$\sin \paren {5 \times 18 \degrees} = \sin 90 \degrees = 1$. Consider the equation: : $\sin 5x = 1$ where $x = 18 \degrees$ is one of the solutions. From [[Quintuple Angle Formulas/Sine|Quintuple Angle Formula of Sine]]: :$16 \sin^5 \theta - 20 \sin^3 \theta + 5 \sin \theta = 1$ Let $s = \sin \theta$: :$16 s^5 - 20 s^3 + 5s - 1 = 0$ That is: :$\paren {s - 1} \paren {4 s^2 + 2 s - 1}^2 = 0$ Therefore, either: :$s = 1$ or by the [[Quadratic Formula]]: :$s = \dfrac 1 4 \paren {\pm \sqrt 5 - 1}$ Since $0 < \sin 18 \degrees < 1$: :$\sin 18^\circ = \dfrac {\sqrt 5 - 1} 4$ {{qed}} [[Category:Sine Function]] q0tt2du7kh1dffh46qb53sjjb92qbxo	0
The [[Definition:Golden Mean|golden mean]] $\phi$ is [[Definition:Irrational Number|irrational]].	0
The only [[Definition:Invertible Element|invertible elements]] of $\Z$ for [[Definition:Integer Multiplication|multiplication]] (that is, [[Definition:Unit of Ring|units of $\Z$]]) are $1$ and $-1$.	0
:[[File:Straight-line-double-intercept-form.png|400px]] From the [[Equation of Straight Line in Plane/General Equation|General Equation of Straight Line in Plane]], $\mathcal L$ can be expressed in the form: :$(1): \quad \alpha_1 x + \alpha_2 y = \beta$ where $\alpha_1, \alpha_2, \beta \in \R$ are given, and not both $\alpha_1, \alpha_2$ are zero. Substituting for the two [[Definition:Point|points]] whose [[Definition:Cartesian Coordinate System|coordinates]] we know about: {{begin-eqn}} {{eqn | lo= x = a, y = 0: | l = \alpha_1 \times a + \alpha_2 \times 0 | r = \beta | c = }} {{eqn | ll= \leadsto | l = \alpha_1 | r = \dfrac \beta a | c = }} {{end-eqn}} {{begin-eqn}} {{eqn | lo= x = 0, y = b: | l = \alpha_1 \times 0 + \alpha_2 \times b | r = \beta | c = }} {{eqn | ll= \leadsto | l = \alpha_2 | r = \dfrac \beta b | c = }} {{end-eqn}} We know that $\beta \ne 0$ because none of $a, b, \alpha_1, \alpha_2$ are equal to $0$. Hence: {{begin-eqn}} {{eqn | l = \dfrac \beta a x + \dfrac \beta b y | r = \beta | c = substituting for $\alpha_1$ and $\alpha_2$ in $(1)$ }} {{eqn | ll= \leadsto | l = \dfrac x a + \dfrac y a | r = 1 | c = dividing both sides by $\beta$ }} {{end-eqn}} {{qed}}	0
:[[File:Sneddon-1-2-Example1.png|400px|right|thumb|$\map f x$ and $5$th order expansion]] Let $\map f x$ be the [[Definition:Real Function|real function]] defined on $\openint 0 {2 \pi}$ as: :$\map f x = \begin{cases} \paren {x - \pi}^2 & : 0 < x \le \pi \\ \pi^2 & : \pi < x < 2 \pi \end{cases}$ Then its [[Definition:Fourier Series over Range 2 Pi|Fourier series]] can be expressed as: {{begin-eqn}} {{eqn | l = \map f x | o = \sim | r = \frac {2 \pi^2} 3 + \sum_{n \mathop = 1}^\infty \paren {\frac {2 \cos n x} {n^2} + \paren {\frac {\paren {-1}^n \pi} n - \frac {2 \paren {1 - \paren {-1}^n} } {\pi n^3} } \sin n x} | c = }} {{eqn | r = \frac {2 \pi^2} 3 + 2 \paren {\cos x + \frac {\cos 2 x} {2^2} + \frac {\cos 3 x} {3^2} + \cdots} | c = }} {{eqn | o = | ro= - | r = \pi \sin x + \frac \pi 2 \sin x - \frac \pi 3 \sin x + \frac \pi 4 \sin x - \cdots | c = }} {{eqn | o = | ro= - | r = \dfrac 4 \pi \sin x - \frac 4 {\pi 3^3} \sin 3 x - \frac 4 {\pi 5^3} \sin 5 x \cdots | c = }} {{end-eqn}}	0
:$\displaystyle \int_0^\infty \frac {\sin x} {\sqrt x} \rd x = \sqrt {\frac \pi 2}$	0
Construct the [[Definition:Altitude of Triangle|altitude]] from $A$. Let the [[Definition:Length (Linear Measure)|length]] of the [[Definition:Altitude of Triangle|altitude]] be $h$ and the [[Definition:Foot of Altitude|foot]] of the [[Definition:Altitude of Triangle|altitude]] be $D$. Let the [[Definition:Distance (Linear Measure)|distance]] from $D$ to $B$ be $z$. :[[File:Heron1.png|300px]] From [[Pythagoras's Theorem]]: :$\paren 1: \quad h^2 + \paren {a - z}^2 = b^2$ and: :$\paren 2: \quad h^2 + z^2 = c^2$ By subtracting $\paren 1$ from $\paren 2$: :$2 a z - a^2 = c^2 - b^2$ which can be expressed in terms of $z$ as: :$z = \dfrac {a^2 + c^2 - b^2} {2 a}$ Substituting for $z$ in $\paren 2$ and simplifying yields: : $h = \sqrt {c^2 - \paren {\dfrac{a^2 + c^2 - b^2}{2a}}^2}$ and so: {{begin-eqn}} {{eqn | l = Q | r = \frac 1 2 a \sqrt {c^2 - \paren {\frac{a^2 + c^2 - b^2}{2a} }^2} | c = [[Area of Triangle in Terms of Side and Altitude]] }} {{eqn | r = \sqrt {\frac {4 c^2 a^2 - \left({a^2 + c^2 - b^2}\right)^2} {16} } }} {{eqn | r = \sqrt {\frac {\paren {2ac - a^2 - c^2 + b^2} \paren {2ac + a^2 + c^2 - b^2} } {16} } | c = [[Difference of Two Squares]] }} {{eqn | r = \sqrt {\frac {\paren {b^2 - \paren {a - c}^2} \paren {\paren {a + c}^2 - b^2} } {16} } }} {{eqn | r = \sqrt {\frac {\paren {b - a + c} \paren {b + a - c} \paren {a + c - b} \paren {a + b + c} } {16} } | c = [[Difference of Two Squares]] }} {{eqn | r = \sqrt {\frac {\paren {a + b + c} \paren {a + b - c} \paren {a - b + c} \paren {-a + b + c} } {16} } }} {{eqn | r = \sqrt {\paren {\frac {a + b + c} 2} \paren {\frac {a + b + c} 2 - c} \paren {\frac {a + b + c} 2 - b} \paren {\frac {a + b + c} 2 - a} } }} {{eqn | r = \sqrt {s \paren {s - c} \paren {s - b} \paren{s - a} } | c = Definition of [[Definition:Semiperimeter|semiperimeter]] }} {{end-eqn}} {{qed}}	0
{{WLOG}} let one of the [[Definition:Vertex of Polygon|vertices]] of $T$ be at $\tuple {0, 0}$. Let the other $2$ [[Definition:Vertex of Polygon|vertices]] be at $\tuple {a, b}$ and $\tuple {x, y}$. By [[Area of Triangle in Determinant Form with Vertex at Origin]]: :$\map \Area T = \dfrac {\size {b y - a x} } 2$ As the [[Definition:Vertex of Polygon|vertices]] of $T$ are non-[[Definition:Collinear Points|collinear]], $\map \Area T \ge 0$. Thus $\size {b y - a x} > 0$. As $\tuple {a, b}$ and $\tuple {x, y}$ are [[Definition:Lattice Point|lattice points]], all of $a, b, x, y \in \Z$. Thus $\size {b y - a x} \ge 1$. Hence the result. {{Qed}}	0
Recall the definition of [[Definition:Jacobson Radical|Jacobson radical]] of $A$: :$\map {\operatorname {Jac} } A$ is the [[Definition:Set Intersection|intersection]] of all [[Definition:Maximal Ideal of Ring|maximal ideals]] of $R$. === $\subset$ Direction === {{AimForCont}} that $x \in \map {\operatorname {Jac} } A$ such that there exists $y \in A$ such that $1_A - x y \notin A^\times$. By definition $x$ is contained in all [[Definition:Maximal Ideal of Ring|maximal ideals]] of $A$. Let $\mathfrak m \subseteq A$ be one particular such [[Definition:Maximal Ideal of Ring|maximal ideal]] of $A$. Then $x \in \map {\operatorname {Jac} } A \subseteq \mathfrak m$ implies that $xy \in \mathfrak m$ and therefore $1_A \in \mathfrak m$. But if $1_A \in \mathfrak m$ then from [[Ideal of Unit is Whole Ring/Corollary|Ideal of Unit is Whole Ring: Corollary]]: :$\mathfrak m = R$ This [[Definition:Contradiction|contradicts]] the definition of $\mathfrak m$ as a [[Definition:Maximal Ideal of Ring|maximal ideal]] of $A$. Hence by [[Proof by Contradiction]]: :$\map {\operatorname {Jac} } A \subseteq \set {a \in A: 1_A - a x \in A^\times \text{ for all } x \in A}$ {{qed|lemma}} === $\supset$ Direction === Now suppose that $x \notin \map {\operatorname {Jac} } A$. Then $x \notin \mathfrak m$ for some [[Definition:Maximal Ideal of Ring|maximal ideal]] $\mathfrak m$ of $A$. Because $\mathfrak m$ is [[Definition:Maximal Ideal of Ring|maximal]], $x$ and $\mathfrak m$ [[Definition:Generator of Ring|generate]] $A$. Therefore there exist $w \in \mathfrak m$ and $y \in A$ such that $w + x y = 1_A$. Thus $1_A - x y \in \mathfrak m$, and $1_A - x y \notin A^\times$. Hence: :$\map {\operatorname {Jac} } A \supseteq \set {a \in A: 1_A - a x \in A^\times \text{ for all } x \in A}$ {{qed|lemma}} The result follows by definition of [[Definition:Set Equality|set equality]]. {{qed}} [[Category:Commutative Algebra]] sr2jx31q78xi1evsr3ym5z0zl65mp6a	0
{{begin-eqn}} {{eqn | l = F_n \hat \phi + F_{n - 1} | r = F_n \left({-\dfrac 1 \phi}\right) + F_{n - 1} | c = [[Reciprocal Form of One Minus Golden Mean]] }} {{eqn | r = -\dfrac 1 \phi \left({F_n - \phi F_{n - 1} }\right) | c = }} {{eqn | r = -\dfrac 1 \phi \left({\left({-1}\right)^{n + 1} F_{-n} - \phi \left({-1}\right)^n F_{-\left({n - 1}\right)} }\right) | c = [[Fibonacci Number with Negative Index]] }} {{eqn | r = -\dfrac 1 \phi \left({\left({-1}\right)^{n + 1} F_{-n} + \phi \left({-1}\right)^{n + 1} F_{-\left({n - 1}\right)} }\right) | c = }} {{eqn | r = \left({-1}\right)^{n + 1} \left({-\dfrac 1 \phi \left({F_{-n} + \phi F_{-n + 1} }\right)}\right) | c = }} {{eqn | r = \left({-1}\right)^{n + 1} \left({-\dfrac 1 \phi }\right) \left({\phi^{-n + 1} }\right) | c = [[Fibonacci Number by Golden Mean plus Fibonacci Number of Index One Less]] }} {{eqn | r = \left({-1}\right)^n \left({\dfrac 1 {\phi^n} }\right) | c = }} {{eqn | r = \left({-\dfrac 1 \phi}\right)^n | c = }} {{eqn | r = \hat \phi^n | c = }} {{end-eqn}} {{qed}}	0
From [[Half-Range Fourier Cosine Series/Cosine of Non-Integer Multiple of x over 0 to Pi|Half-Range Fourier Cosine Series for $\cos \alpha x$ over $\openint 0 \pi$]]: :$\displaystyle \cos \alpha x \sim \frac {2 \alpha \sin \alpha \pi} \pi \paren {\frac 1 {2 \alpha^2} + \sum_{n \mathop = 1}^\infty \paren {-1}^n \frac {\cos n x} {\alpha^2 - n^2} }$ Setting $x = 0$: {{begin-eqn}} {{eqn | l = \cos 0 | r = \frac {2 \alpha \sin \alpha \pi} \pi \paren {\frac 1 {2 \alpha^2} + \sum_{n \mathop = 1}^\infty \paren {-1}^n \frac {\cos 0} {\alpha^2 - n^2} } | c = }} {{eqn | ll= \leadsto | l = 1 | r = \frac {2 \alpha \sin \alpha \pi} \pi \paren {\frac 1 {2 \alpha^2} + \sum_{n \mathop = 1}^\infty \frac {\paren {-1}^n} {\alpha^2 - n^2} } | c = [[Cosine of Zero is One]] }} {{eqn | ll= \leadsto | l = \frac \pi {2 \alpha \sin \alpha \pi} | r = \frac 1 {2 \alpha^2} + \sum_{n \mathop = 1}^\infty \frac {\paren {-1}^n} {\alpha^2 - n^2} | c = }} {{eqn | ll= \leadsto | l = \pi \cosec \pi \alpha | r = \dfrac 1 \alpha + \displaystyle 2 \sum_{n \mathop \ge 1} \paren {-1}^n \dfrac {\alpha} {\alpha^2 - n^2} | c = {{Defof|Cosecant|subdef = Real Function}} and rearranging }} {{end-eqn}} {{qed}}	0
Consider a [[Definition:Circle|circle]] of [[Definition:Radius of Circle|radius]] $a$ rolling without slipping along the [[Definition:X-Axis|$x$-axis]] of a [[Definition:Cartesian Plane|cartesian plane]]. Consider the [[Definition:Point|point]] $P$ on the [[Definition:Circumference of Circle|circumference]] of this [[Definition:Circle|circle]] which is at the [[Definition:Origin|origin]] when its [[Definition:Center of Circle|center]] is on the [[Definition:Y-Axis|y-axis]]. Consider the [[Definition:Cycloid|cycloid]] traced out by the [[Definition:Point|point]] $P$. Let $\tuple {x, y}$ be the [[Definition:Cartesian Coordinate Pair|coordinates]] of $P$ as it travels over [[Definition:The Plane|the plane]]. The [[Definition:Point|point]] $P = \tuple {x, y}$ is described by the equation: :$a \sin^{-1} \paren {\dfrac {\sqrt {2 a y - y^2} } a} = \sqrt {2 a y - y^2} + x$	0
The [[Definition:Midline of Triangle|midline]] of a [[Definition:Triangle (Geometry)|triangle]] is [[Definition:Parallel Lines|parallel]] to the third [[Definition:Side of Polygon|side]] of that [[Definition:Triangle (Geometry)|triangle]] and half its [[Definition:Length of Line|length]].	0
A '''compass''' is an [[Definition:Ideal (Physics)|ideal]] [[Definition:Tool|tool]] for drawing [[Definition:Circle|circles]]. Hence it can be used according to [[Axiom:Euclid's Third Postulate|Euclid's third postulate]] to construct a [[Definition:Circle|circle]] using any two given [[Definition:Point|points]]: :$(1): \quad$ the [[Definition:Center of Circle|center]] and: :$(2): \quad$ an arbitrary [[Definition:Point|point]] on the [[Definition:Circumference of Circle|circumference]].	0
By [[L'Hôpital's Rule]]: {{begin-eqn}} {{eqn |l = \lim_{x \mathop \to 0} \frac {\tan x} x |r = \lim_{x \mathop \to 0} \frac {\sec^2 x} 1 |c = [[Derivative of Tangent Function]] }} {{eqn |r = 1 |c = [[Secant of Zero]] }} {{end-eqn}} {{qed}}	0
Let $\triangle ABC$ be a [[Definition:Spherical Triangle|spherical triangle]] on the surface of a [[Definition:Sphere (Geometry)|sphere]] whose [[Definition:Center of Sphere|center]] is $O$. Let the [[Definition:Side of Spherical Triangle|sides]] $a, b, c$ of $\triangle ABC$ be measured by the [[Definition:Subtend|angles subtended]] at $O$, where $a, b, c$ are [[Definition:Opposite (in Triangle)|opposite]] $A, B, C$ respectively. Then: :$\cos a = \cos b \cos c + \sin b \sin c \cos A$	0
:$\cos 285^\circ = \cos \dfrac {19 \pi} {12} = \dfrac {\sqrt 6 - \sqrt 2} 4$	0
Let: :$x = \sin \theta$ By [[Derivative of Sine Function]], we have: :$\dfrac {\d x} {\d \theta} = \cos \theta$ We have, by [[Arcsine of Zero is Zero]]: :as $x \to 0$, $\theta \to \arcsin 0 = 0$. By [[Arcsine of One is Half Pi]], we have: :as $x \to 1$, $\theta \to \arcsin 1 = \dfrac \pi 2$. We have: {{begin-eqn}} {{eqn | l = \int_0^1 \frac {\arcsin x} x \rd x | r = \int_0^{\pi/2} \frac {\cos \theta \map \arcsin {\sin \theta} } {\sin \theta} \rd \theta | c = [[Integration by Substitution|substituting]] $x = \sin \theta$ }} {{eqn | r = \int_0^{\pi/2} \theta \cot \theta \rd \theta | c = {{Defof|Arcsine}}, {{Defof|Real Cotangent Function}} }} {{end-eqn}} By [[Primitive of Cotangent Function]]: :$\displaystyle \int \cot \theta \rd \theta = \map \ln {\sin \theta} + C$ So: {{begin-eqn}} {{eqn | l = \int_0^{\pi/2} \theta \cot \theta \rd \theta | r = \intlimits {\theta \map \ln {\sin \theta} } 0 {\frac \pi 2} - \int_0^{\pi/2} \map \ln {\sin \theta} \rd \theta | c = [[Integration by Parts]] }} {{eqn | r = \frac \pi 2 \map \ln {\sin \frac \pi 2} - \lim_{\theta \to 0^+} \paren {\theta \map \ln {\sin \theta} } + \frac \pi 2 \ln 2 | c = [[Definite Integral from 0 to Half Pi of Logarithm of Sine x|Definite Integral from 0 to $\dfrac \pi 2$ of $\map \ln {\sin x}$]] }} {{eqn | r = -\lim_{\theta \to 0^+} \paren {\theta \map \ln {\sin \theta} } + \frac \pi 2 \ln 2 | c = [[Sine of Right Angle]], [[Natural Logarithm of 1 is 0]] }} {{end-eqn}} We have: {{begin-eqn}} {{eqn | l = \lim_{\theta \to 0^+} \paren {\theta \map \ln {\sin \theta} } | r = \lim_{\theta \to 0^+} \paren {\theta \map \ln {\frac {\sin \theta} \theta \theta} } }} {{eqn | r = \lim_{\theta \to 0^+} \paren {\theta \map \ln {\frac {\sin \theta} \theta} } + \lim_{\theta \to 0^+} \theta \ln \theta | c = [[Sum of Logarithms]], [[Combination Theorem for Limits of Functions/Sum Rule|Combination Theorem for Limits of Functions: Sum Rule]] }} {{eqn | r = \paren {\lim_{\theta \to 0^+} \theta} \paren {\map \ln {\lim_{\theta \to 0^+} \frac {\sin \theta} \theta} } + \lim_{\theta \to 0^+} \theta \ln \theta | c = [[Combination Theorem for Limits of Functions/Product Rule|Combination Theorem for Limits of Functions: Product Rule]] }} {{eqn | r = 0 \ln 1 + 0 | c = [[Limit of Sine of X over X|Limit of $\dfrac {\sin x} x$]], [[Limit of Power of x by Logarithm of x|Limit of $x^n \paren {\ln x}^m$]] }} {{eqn | r = 0 }} {{end-eqn}} giving: :$\displaystyle \int_0^{\pi/2} \theta \cot \theta \rd \theta = \frac \pi 2 \ln 2$ hence the result. {{qed}}	0
Let $e \in G$ be the [[Definition:Identity Element|identity]] of $G$. Let $g \in G$ be an arbitrary [[Definition:Element|element]] of $G$ such that $g \ne e$. From [[Identity is Only Group Element of Order 1]], only $e$ has [[Definition:Order of Group Element|order]] $1$. Thus from [[Order of Element Divides Order of Finite Group]]: :$\order g \in \set {2, 4, 8}$ Suppose $\order g = 8$. Then $G$ is [[Definition:Cyclic Group|cyclic]]. So by [[Cyclic Group is Abelian]], $G$ would be [[Definition:Abelian Group|abelian]]. So $g$ cannot be of [[Definition:Order of Group Element|order]] $8$. Suppose all [[Definition:Element|elements]] of $G \setminus \set e$ are of order $2$. Then by definition $G$ is a [[Definition:Boolean Group|Boolean group]]. By [[Boolean Group is Abelian]], $G$ would be [[Definition:Abelian Group|abelian]]. So the only option left is for at least one [[Definition:Element|element]] of $G$ to be of [[Definition:Order of Group Element|order]] $4$. {{qed}}	0
{{begin-eqn}} {{eqn | l = \size {x + y}^2 | r = \paren {x + y}^2 | c = }} {{eqn | r = x^2 + 2 x y + y^2 | c = }} {{eqn | r = \size x^2 + 2 x y + \size y^2 | c = }} {{eqn | o = \le | r = \size x^2 + 2 \size {x y} + \size y^2 | c = [[Negative of Absolute Value]] }} {{eqn | r = \size x^2 + 2 \size x \cdot \size y + \size y^2 | c = [[Absolute Value Function is Completely Multiplicative]] }} {{eqn | r = \paren {\size x + \size y}^2 | c = }} {{end-eqn}} Then by [[Order is Preserved on Positive Reals by Squaring]]: :$\size {x + y} \le \size x + y$ {{qed}}	0
Let $F$ be a [[Definition:Field (Abstract Algebra)|field]]. Let $\FF$ be the collection of all [[Definition:Field Extension|extensions]] of $F$. {{explain|Is $\FF$ a [[Definition:Set|set]] or a [[Definition:Proper Class|proper class]]? It is not obvious that this collection is "small enough" to be a set, and I was unable to find a proof of this on ProofWiki.<br/>(On the other hand, does it matter which it is? // Yes, because Zorn's lemma only covers the case of it being a set.)}} Define an [[Definition:Ordering|ordering]] on $\FF$ thus: :$\forall K, L \in \FF: K \preceq L \iff L$ is an [[Definition:Field Extension|extension]] of $K$. Let $C$ be a [[Definition:Chain (Set Theory)|chain]] in $\FF$. Let $E = \bigcup_{K \mathop \in C} K$. $E$ satisfies all [[Definition:Field (Abstract Algebra)|field axioms]], so $E \in \FF$. {{explain|Why does $E$ satisfy all field axioms?}} By [[Set is Subset of Union]], $E$ is an [[Definition:Upper Bound of Set|upper bound]] for $C$. By [[Zorn's Lemma]], $C$ has a [[Definition:Maximal Element|maximal element]] $m$. Then $m$ is an [[Definition:Algebraic Closure|algebraic closure]] of $F$. {{explain|Why is this an algebraic closure of $F$?}} {{qed}} {{BPI}} [[Category:Field Theory]] 6ravysqwxem9dk60vu9am8rajmj2oum	0
From the [[Definition:Initial Segment of Natural Numbers|definition of $\N_0$]]: :$\N_0 = \set {n \in \N: n < 0}$ From the definition of [[Definition:Zero (Number)|zero]], $0$ is the [[Definition:Minimal Element|minimal element of $\N$]]. So there is no [[Definition:Element|element]] $n$ of $\N$ such that $n < 0$. Thus $\N_0 = \O$. {{qed}} [[Category:Natural Numbers]] qbigqp7k4plig58dwsn1gh24fsrjyqb	0
The [[Definition:Right Coset Space|right coset space]] of $H$ forms a [[Definition:Set Partition|partition]] of its [[Definition:Group|group]] $G$: {{begin-eqn}} {{eqn | l = x \equiv^r y \pmod H | o = \iff | r = H x = H y }} {{eqn | l = \neg \paren {x \equiv^r y} \pmod H | o = \iff | r = H x \cap H y = \O }} {{end-eqn}}	0
Let $\struct {G, \circ}$ be a [[Definition:Group|group]] whose [[Definition:Identity Element|identity]] is $e$. Let $x, y \in G$ such that $\exists a \in G: x \circ a = a \circ y$. That is, let $x$ and $y$ be [[Definition:Conjugate of Group Element|conjugate]]. Then: : $\forall n \in \Z: y^n = \paren {a^{-1} \circ x \circ a}^n = a^{-1} \circ x^n \circ a$ It follows directly that: : $\exists b \in G: \forall n \in \Z: y^n = b \circ x^n \circ b^{-1}$ In particular: : $y^{-1} = \paren {a^{-1} \circ x \circ a}^{-1} = a^{-1} \circ x^{-1} \circ a$	0
{{begin-eqn}} {{eqn | l = \dfrac 1 {x / y} | r = \frac 1 {x \times \dfrac 1 y} | c = {{Defof|Real Division}} }} {{eqn | r = 1 \times \frac 1 {x \times \dfrac 1 y} | c = [[Definition:Real Number Axioms|Real Number Axioms: $\R \text M 3$: Identity]] }} {{eqn | r = \paren {y \times \frac 1 y} \times \frac 1 {x \times \dfrac 1 y} | c = [[Definition:Real Number Axioms|Real Number Axioms: $\R \text M 4$: Inverses]] }} {{eqn | r = y \times \paren {\frac 1 y \times \frac 1 {x \times \dfrac 1 y} } | c = [[Definition:Real Number Axioms|Real Number Axioms: $\R \text M 1$: Associativity]] }} {{eqn | r = y \times \frac 1 {y \times \paren {x \times \dfrac 1 y} } | c = [[Product of Reciprocals of Real Numbers]] }} {{eqn | r = y \times \frac 1 {x \times \paren {y \times \dfrac 1 y} } | c = [[Definition:Real Number Axioms|Real Number Axioms: $\R \text M 1$: Associativity and $\R \text M 2$: Commutativity]] }} {{eqn | r = y \times \frac 1 {x \times 1} | c = [[Definition:Real Number Axioms|Real Number Axioms: $\R \text M 4$: Inverses]] }} {{eqn | r = y \times \frac 1 x | c = [[Definition:Real Number Axioms|Real Number Axioms: $\R \text M 3$: Identity]] }} {{eqn | r = \frac y x | c = {{Defof|Real Division}} }} {{end-eqn}} {{qed}}	0
From [[Right Operation is Associative]], $\rightarrow$ is [[Definition:Associative Operation|associative]]. By the nature of the [[Definition:Right Operation|right operation]], $\struct {S, \rightarrow}$ is [[Definition:Closed Algebraic Structure|closed]]: :$\forall x, y \in S: x \rightarrow y = y \in S$ whatever $S$ may be. So $\struct {S, \rightarrow}$ is a [[Definition:Semigroup|semigroup]]. From the definition of [[Definition:Right Operation|right operation]]: :$\forall x, y \in S: x \rightarrow y = y$ from which it is apparent that all [[Definition:Element|elements]] of $S$ are [[Definition:Left Identity|left identities]]. {{qed}} From [[More than one Left Identity then no Right Identity]], it also follows that there is no [[Definition:Right Identity|right identity]].	0
From the definition of [[Definition:Integer Combination|integer combination]] (or just because it's obvious): :$\Bbb S \subseteq \Z$ and clearly: :$\Bbb S \ne \O$ as $a 0 + b 0 = 0 \in \Bbb S$. Let $w_1, w_2 \in \Bbb S$: :$w_1 = a x_1 + b y_1, w_2 = a x_2 + b y_2$ Then $w_1 + \paren {-w_2} = a \paren {x_1 - x_2} + b \paren {y_1 - y_2} \in \Bbb S$ as $x_1 - x_2 \in \Z$ and $y_1 - y_2 \in \Z$. Let $r \in \Z$. Then: :$w_1 \times r = a x_1 r + b y_1 r = a \paren {x_1 r} + b \paren {y_1 r} \in \Bbb S$ :$r \times w_1 = r a x_1 + r b y_1 = \paren {r x_1} a + \paren {r y_1} b \in \Bbb S$ The result follows from [[Test for Ideal]]. {{qed}}	0
First note that from [[Group Homomorphism Preserves Inverses]]: :$\map \theta {g_2}^{-1} = \paren {\map \theta {g_2} }^{-1} = \map \theta { {g_2}^{-1} }$ and so $\map \theta {g_1} \map \theta {g_2}^{-1}$ is not [[Definition:Ambiguous|ambiguous]]: :$\map \theta {g_1} \map \theta {g_2}^{-1} = \map \theta {g_1} \paren {\map \theta {g_2} }^{-1} = \map \theta {g_1} \map \theta { {g_2}^{-1} }$ From [[External Direct Product of Groups is Group]], $G \times G$ is a [[Definition:Group|group]]. Let $a_1, a_2, b_1, b_2 \in G$. We have: {{begin-eqn}} {{eqn | l = \map \phi {a_1 b_1, a_2 b_2} | r = \map \theta {a_1 b_1} \map \theta {a_2 b_2}^{-1} | c = }} {{eqn | r = \map \theta {a_1 b_1} \paren {\map \theta {a_2 b_2} }^{-1} | c = [[Group Homomorphism Preserves Inverses]] }} {{eqn | r = \map \theta {a_1} \map \theta {b_1} \paren {\map \theta {a_2} \map \theta {b_2} }^{-1} | c = {{Defof|Group Homomorphism}} }} {{eqn | r = \map \theta {a_1} \map \theta {b_1} \paren {\map \theta {b_2}^{-1} } \paren {\map \theta {a_2}^{-1} } | c = [[Inverse of Group Product]] }} {{eqn | r = \map \theta {a_1} \paren {\map \theta {a_2}^{-1} } \map \theta {b_1} \paren {\map \theta {b_2}^{-1} } | c = {{Defof|Abelian Group}}: $H$ is [[Definition:Abelian Group|Abelian]] }} {{eqn | r = \map \phi {a_1, a_2} \map \phi {b_1, b_2} | c = Definition of $\phi$ }} {{end-eqn}} Hence the result by definition of [[Definition:Group Homomorphism|homomorphism]]. {{Qed}}	0
Let $x \ge 0$. Then $\size x = x \ge 0$. Let $x < 0$. Then $\size x = -x > 0$. The result follows. {{qed}}	0
Let $\struct {G, \circ}$ be a [[Definition:Group|group]] whose [[Definition:Identity Element|identity]] is $e$. Let $*: G \times G \to G$ be the [[Definition:Group Action|group action]]: :$\forall g, h \in G: g * h = \map {\lambda_g} h$ where $\lambda_g$ is the [[Definition:Left Regular Representation|left regular representation]] of $G$ with respect to $g$. Then $*$ is a [[Definition:Transitive Group Action|transitive group action]].	0
Let $G$ be a [[Definition:Cyclic Group|cyclic group]] [[Definition:Generator of Cyclic Group|generated]] by $a$. Let $H$ be a [[Definition:Subgroup|subgroup]] of $G$. If $H = \set e$, then $H$ is a [[Definition:Cyclic Group|cyclic group]] [[Definition:Generated Subgroup|subgroup generated]] by $e$. Let $H \ne \set e$. By definition of [[Definition:Cyclic Group|cyclic group]], every [[Definition:Element|element]] of $G$ has the form $a^n$. Then as $H$ is a [[Definition:Subgroup|subgroup]] of $G$, $a^n \in H$ for some $n \in \Z$. Let $m$ be the smallest [[Definition:Strictly Positive Integer|(strictly) positive integer]] such that $a^m \in H$. Consider an arbitrary [[Definition:Element|element]] $b$ of $H$. As $H$ is a [[Definition:Subgroup|subgroup]] of $G$, $b = a^n$ for some $n$. By the [[Division Theorem]], it is possible to find [[Definition:Integer|integers]] $q$ and $r$ such that $n = m q + r$ with $0 \le r < m$. It follows that: :$a^n = a^{m q + r} = \paren {a^m}^q a^r$ and hence: :$a^r = \paren {a^m}^{-q} a^n$ Since $a^m \in H$ so is its [[Definition:Inverse Element|inverse]] $\paren {a^m}^{-1}$ By {{GroupAxiom|0}}, so are all [[Definition:Power of Group Element|powers]] of its [[Definition:Inverse Element|inverse]]. Now $a^n$ and $\paren {a^m}^{-q}$ are both in $H$, thus so is their [[Definition:Product Element|product]] $a^r$, again by [[Definition:Group Axioms|Group Axiom $G 0$: Closure]]. However: : $m$ was the smallest [[Definition:Strictly Positive Integer|(strictly) positive integer]] such that $a^m \in H$ and: :$0 \le r < m$ Therefore it follows that: : $r = 0$ Therefore: :$n = q m$ and: :$b = a^n = \paren {a^m}^q$. We conclude that any arbitrary [[Definition:Element|element]] $b = a^n$ of $H$ is a [[Definition:Power of Group Element|power]] of $a^m$. So, by definition, $H = \gen {a^m}$ is [[Definition:Cyclic Group|cyclic]]. {{qed}}	0
Let $\displaystyle L = \bigcap \mathbb L$. By [[Intersection of Subgroups is Subgroup]], $\struct {L, +}$ is a [[Definition:Subgroup|subgroup]] of $\struct {R, +}$. By the [[One-Step Subgroup Test]]: :$\forall x, y \in \struct {L, +}: x + \paren {-y} \in L$ By [[Intersection of Subsemigroups]], $\struct {L, \circ}$ a [[Definition:Subsemigroup|subsemigroup]] of $\struct {R, \circ}$. So by definition of [[Definition:Subsemigroup|subsemigroup]]: :$\forall x, y \in \struct {L, \circ}: x \circ y \in L$ By the [[Subring Test]] it follows that $\struct {L, +, \circ}$ is a [[Definition:Subring|subring]] of $\struct {R, +, \circ}$. {{qed}}	0
Let $K \sqbrk X$ be the [[Definition:Ring of Polynomial Forms|ring of polynomial forms]] over $K$. By [[Polynomial Forms over Field form Unique Factorization Domain]], $K \sqbrk X$ is a [[Definition:Unique Factorization Domain|unique factorisation domain]]. Therefore, we can write $f = u g_1 \cdots g_r$, where $u$ a [[Definition:Unit of Ring|unit]] of $K \sqbrk X$ and $g_i$ is [[Definition:Irreducible Polynomial|irreducible]] for $i = 1, \ldots, r$. Clearly it is sufficient to find an extension of $K$ in which the irreducible factor $g_1$ of $f$ has a root. Let $L = K \sqbrk X / \gen {g_1}$, where $\gen {g_1}$ is the [[Definition:Generated Ideal of Ring|ideal generated]] by $g_1$. By [[Principal Ideal of Principal Ideal Domain is of Irreducible Element iff Maximal]], $\gen {g_1}$ is [[Definition:Maximal Ideal of Ring|maximal]]. Therefore by [[Maximal Ideal iff Quotient Ring is Field]], $L$ is a field. Moreover, writing $\overline {\map p x} = \map p X + \gen {g_1}$ for $\map p x \in K \sqbrk X$: {{begin-eqn}} {{eqn | l = \map {g_1} {\overline X} | r = \overline {\map {g_1} X} | c = }} {{eqn | r = \overline {0_{K \sqbrk X} } | c = }} {{eqn | r = 0_L | c = }} {{end-eqn}} So $\overline X$ is a root of $g_1$ in $L$. It remains to show that $\index L K \le n$. By the [[Euclidean Algorithm]] every polynomial $\map p X \in K \sqbrk X$ can be written as: :$\map p X = \map q X \map {g_1} X + \map r X$ with $\map \deg {\map r X} < \map \deg {\map {g_1} X} \le \map \deg {\map f X} = n$. Now we have by the definition of the quotient ring: {{begin-eqn}} {{eqn | l = \overline {\map p X} | r = \overline {\map q X \map {g_1} X + \map r X} | c = }} {{eqn | r = \overline {\map r X} | c = }} {{end-eqn}} So if $\map r X = r_0 + r_1 X + \cdots + r_{n - 1} X^{n - 1}$, we have: :$\overline {\map p X} = \overline {r_0 + r_1 X + \cdots + r_{n - 1} X^{n - 1} }$ Our choice of $p$ was arbitrary, so every polynomial can be written in this form. In particular the [[Definition:Set|set]] $\set {\overline 1, \overline X, \ldots, \overline {X^{n - 1} } }$ [[Definition:Spanning Set|spans]] $L$ over $K$. Thus by [[Spanning Set Contains Basis]], a [[Definition:Basis (Linear Algebra)|basis]] of $L$ has at most $n$ [[Definition:Element|elements]]. That is, $\index L K \le n$. {{qed}} {{Namedfor|Leopold Kronecker|cat = Kronecker}} [[Category:Field Extensions]] p81n7mn6mchiyahli6djva9jcnq4ctj	0
Let $\left({S, \circ, \preceq}\right)$ be a [[Definition:Naturally Ordered Semigroup|naturally ordered semigroup]]. Let $1$ be the [[Definition:One of Naturally Ordered Semigroup|one]] of $S$. Let $n \in S$. Then $n \circ 1$ is the [[Definition:Immediate Successor Element|immediate successor]] of $n$. That is, for all $m \in S$: :$n \prec m \iff n \circ 1 \preceq m$	0
Let the [[Definition:Identity Element|identities]] of $\struct {G, \circ}$ and $\struct {H, *}$ be $e_G$ and $e_H$ respectively. By [[Homomorphism to Group Preserves Identity]]: :$\map f {e_G} = \map g {e_G} = e_H$ Thus $e_G \in S$, and so $S \ne \O$. Similarly, from [[Homomorphism to Group Preserves Inverses]], $x \in S \implies x^{-1} \in S$. Let $x, y \in S$. Then: {{begin-eqn}} {{eqn | l = \map f {x \circ y} | r = \map f x * \map f y | c = [[Definition:Morphism Property|Morphism Property]] }} {{eqn | r = \map g x * \map g y | c = Definition of $S$ }} {{eqn | r = \map g {x \circ y} | c = [[Definition:Morphism Property|Morphism Property]] }} {{end-eqn}} Thus $x \circ y \in S$. So, by the [[Two-Step Subgroup Test]]: :$S \le G$ {{Qed}}	0
Let $Q_\pm = \set {q \in \Q: \pm q > 0}$. For every $q \in Q_+$, there exists at least one pair $\tuple {m, n} \in \N \times \N$ such that $q = \dfrac m n$. Therefore, we can find an [[Definition:Injection|injection]] $i: Q_+ \to \N \times \N$. By [[Cartesian Product of Natural Numbers with Itself is Countable]], $\N \times \N$ is [[Definition:Countable|countable]]. Hence $Q_+$ is [[Definition:Countable|countable]], by [[Domain of Injection to Countable Set is Countable]]. The map $-: q \mapsto -q$ provides a [[Definition:Bijection|bijection]] from $Q_-$ to $Q_+$, hence $Q_-$ is also [[Definition:Countable|countable]]. Hence $\Q$ is [[Definition:Countable Set|countable]]. {{qed}}	0
Let $\struct {G, \circ}$ be a [[Definition:Group|group]] of [[Definition:Order of Structure|finite order]] whose [[Definition:Identity Element|identity]] is $e$. Let $p$ be a [[Definition:Prime Number|prime number]] which [[Definition:Divisor of Integer|divides]] the [[Definition:Order of Structure|order]] of $G$. Then $\struct {G, \circ}$ has an [[Definition:Element|element]] of [[Definition:Order of Group Element|order]] $p$.	0
[[Definition:Congruence (Number Theory)|Congruence modulo zero]] is the [[Definition:Diagonal Relation|diagonal relation]]. That is: :$x \equiv y \pmod 0 \iff x = y$	0
Let $S \subset \Z$ be a [[Definition:Non-Empty Set|non-empty]] [[Definition:Subset|subset]] of the [[Definition:Integer|set of integers]]. Let $S$ be [[Definition:Bounded Below Subset of Real Numbers|bounded below]] in the [[Definition:Real Number|set of real numbers]]. Then its [[Definition:Infimum of Subset of Real Numbers|infimum]] $\inf S$ is an [[Definition:Integer|integer]].	0
Let $U$ be an arbitrary [[Definition:Ideal of Ring|ideal]] of $\Z$. Let $c$ be a non-[[Definition:Ring Zero|zero]] [[Definition:Element|element]] of $U$. Then both $c$ and $-c$ belong to $\ideal a$ and one of them is [[Definition:Positive Integer|positive]]. Thus $U$ contains [[Definition:Strictly Positive Integer|strictly positive]] elements. Let $b$ be the [[Definition:Smallest Element|smallest]] [[Definition:Strictly Positive Integer|strictly positive]] element of $U$. By the [[Set of Integers Bounded Below by Integer has Smallest Element]], $b$ is guaranteed to exist. If $\ideal b$ denotes the [[Definition:Generator of Ideal|ideal generated by $b$]], then $\ideal b \subseteq U$ because $b\in U$ and $U$ is an ideal. Let $a \in U$. By the [[Division Theorem]]: :$\exists q, r \in \Z, 0 \le r < b: a = b q + r$ As $a, b \in U$ it follows that so does $r = a - b q$. By definition of $b$ it follows that $r = 0$. Thus: :$a = b q \in \ideal b$ and so: :$U \subseteq \ideal b$ From the above: :$U = \ideal b$ It follows by definition that $U$ is a [[Definition:Principal Ideal of Ring|principal ideal]] of $\Z$. Recall that $U$ was an arbitrary [[Definition:Ideal of Ring|ideal]] of $\Z$. Hence by definition $\Z$ is a [[Definition:Principal Ideal Domain|principal ideal domain]]. {{qed}}	0
Let $\struct {D, +, \times, \le}$ be an [[Definition:Ordered Integral Domain|ordered integral domain]] whose [[Definition:Ring Zero|zero]] is denoted by $0_D$. For all $a \in D$, let $\size a$ denote the [[Definition:Absolute Value on Ordered Integral Domain|absolute value]] of $a$. Then: :$\size a \times \size b = \size {a \times b}$	0
Let $z_1 = a_1 + i a_2, z_2 = b_1 + i b_2$. {{begin-eqn}} {{eqn | l = \cmod {z_1 + z_2} | o = \le | r = \cmod {z_1} + \cmod {z_2} | c = }} {{eqn | ll= \leadstoandfrom | l = \paren {\paren {a_1 + b_1}^2 + \paren {a_2 + b_2}^2}^{\frac 1 2} | o = \le | r = \paren { {a_1}^2 + {a_2}^2}^{\frac 1 2} + \paren { {b_1}^2 + {b_2}^2}^{\frac 1 2} | c = {{Defof|Complex Modulus}} }} {{eqn | ll= \leadstoandfrom | l = \paren {a_1 + b_1}^2 + \paren {a_2 + b_2}^2 | o = \le | r = {a_1}^2 + {a_2}^2 + {b_1}^2 + {b_2}^2 + 2 \paren { {a_1}^2 + {a_2}^2}^{\frac 1 2} \paren { {b_1}^2 + {b_2}^2}^{\frac 1 2} | c = squaring both sides }} {{eqn | ll= \leadstoandfrom | l = {a_1}^2 + 2 a_1 b_1 + {b_1}^2 + {a_2}^2 + 2 a_2 b_2 + {b_2}^2 | o = \le | r = {a_1}^2 + {a_2}^2 + {b_1}^2 + {b_2}^2 + 2 \paren { {a_1}^2 + {a_2}^2}^{\frac 1 2} \paren { {b_1}^2 + {b_2}^2}^{\frac 1 2} | c = multiplying out }} {{eqn | ll= \leadstoandfrom | l = a_1 b_1 + a_2 b_2 | o = \le | r = \paren { {a_1}^2 + {a_2}^2}^{\frac 1 2} \paren { {b_1}^2 + {b_2}^2}^{\frac 1 2} | c = simplifying }} {{eqn | ll= \leadstoandfrom | l = \paren {a_1 b_1 + a_2 b_2}^2 | o = \le | r = \paren { {a_1}^2 + {a_2}^2} \paren { {b_1}^2 + {b_2}^2} | c = [[Cauchy's Inequality]] }} {{eqn | ll= \leadstoandfrom | l = {a_1}^2 {b_1}^2 + 2 a_1 b_1 a_2 b_2 + {a_2}^2 {b_2}^2 | o = \le | r = {a_1}^2 {b_1}^2 + {a_2}^2 {b_2}^2 + {a_1}^2 {b_2}^2 + {a_2}^2 {b_1}^2 | c = }} {{eqn | ll= \leadstoandfrom | l = 2 a_1 b_1 a_2 b_2 | o = \le | r = {a_1}^2 {b_2}^2 + {a_2}^2 {b_1}^2 | c = }} {{eqn | ll= \leadstoandfrom | l = 0 | o = \le | r = \paren {a_1 b_2}^2 - 2 \paren {a_1 b_2} \paren {a_2 b_1} + \paren {a_2 b_1}^2 | c = }} {{eqn | ll= \leadstoandfrom | l = 0 | o = \le | r = \paren {a_1 b_2 - a_2 b_1}^2 | c = }} {{end-eqn}} The final statement is a [[Definition:Tautology|tautology]], and all implications are reversible. Hence the result. {{qed}}	0
Taking the [[Definition:Group Axioms|group axioms]] in turn: === $\text G 0$: Closure === {{begin-eqn}} {{eqn | l = z, w | o = \in | r = K | c = }} {{eqn | ll= \leadsto | l = \cmod z | r = 1 = \cmod w | c = }} {{eqn | ll= \leadsto | l = \cmod {z w} | r = \cmod z \cmod w | c = }} {{eqn | ll= \leadsto | l = z w | o = \in | r = K | c = }} {{end-eqn}} So $\struct {\mathbb S, \cdot}$ is [[Definition:Closed Algebraic Structure|closed]]. {{qed|lemma}} === $\text G 1$: Associativity === [[Complex Multiplication is Associative]]. {{qed|lemma}} === $\text G 2$: Identity === From [[Complex Multiplication Identity is One]] we have that the [[Definition:Identity Element|identity element]] of $K$ is $1 + 0 i$. {{qed|lemma}} === $\text G 3$: Inverses === We have that: :$\cmod z = 1 \implies \dfrac 1 {\cmod z} = \cmod {\dfrac 1 z} = 1$ But: :$z \times \dfrac 1 z = 1 + 0 i$ So the [[Definition:Inverse Element|inverse]] of $z$ is $\dfrac 1 z$. {{qed|lemma}} === $\text C$: Commutative === We have that [[Complex Multiplication is Commutative]]. We also have from [[Restriction of Commutative Operation is Commutative]] that $\times$ is likewise [[Definition:Commutative Operation|commutative]] on $K$. {{qed|lemma}} === Uncountably Infinite === [[Circle Group is Uncountably Infinite]]. {{Qed|lemma}} All the criteria are satisfied, and the result follows. {{qed}}	0
Let $\struct {G, \circ}$ be a [[Definition:Finite Group|finite group]]. Let $\CC$ be a [[Definition:Cayley Table|Cayley table]] for $\struct {G, \circ}$ presented in [[Definition:Inverse Row form of Cayley Table for Group|inverse row form]]. Then all the [[Definition:Entry of Cayley Table|entries]] in the [[Definition:Main Diagonal|main diagonal]] of $\CC$ are instances of the [[Definition:Identity Element|identity element]].	0
Let $0$ be the [[Definition:Ring Zero|zero]] of $\struct {R, \norm {\,\cdot\,} }$. Let $d$ denote the [[Definition:Metric Induced by Norm|metric induced by $\norm {\, \cdot \,}$]], that is: :$\map d {x, y} = \norm {x - y}$ From [[Metric Induced by Norm on Normed Division Ring is Metric]] we have that $d$ is indeed a [[Definition:Metric|metric]]. Then, from the [[Reverse Triangle Inequality]] as applied to [[Definition:Metric Space|metric spaces]]: :$\forall x, y, z \in R: \bigsize {\norm {x - z} - \norm {y - z} } \le \norm {x - y}$ Then: :$\forall x, y \in R: \bigsize {\norm x - \norm y} = \bigsize {\norm{x - 0} - \norm{y - 0} } \le \norm {x - y}$ {{qed}} [[Category:Triangle Inequality]] [[Category:Normed Division Rings]] s4owpzx2q00sisb93nn4yho7dlsvgj2	0
Let $\struct {R, \norm {\,\cdot\,} }$ be a [[Definition:Normed Division Ring|normed division ring]] with [[Definition:Non-Archimedean Division Ring Norm|non-Archimedean norm]] $\norm{\,\cdot\,}$, Let $x, y \in R$ and $\norm x \ne \norm y$. Then: :$\norm {x + y} = \norm {x - y} = \norm {y - x} = \max \set {\norm x, \norm y}$	0
Let $\struct {G, \circ}$ be a [[Definition:Group|group]]. Let $\struct {\powerset G, \circ_\mathcal P}$ be the [[Definition:Algebraic Structure|algebraic structure]] consisting of the [[Definition:Power Set|power set]] of $G$ and the [[Definition:Subset Product|operation induced on $\powerset G$ by $\circ$]]. Then $\struct {\powerset G, \circ_\mathcal P}$ is a [[Definition:Semigroup|semigroup]].	0
Let $\eqclass {a_1, b_1} {}, \eqclass {a_2, b_2} {}, \eqclass {c_1, d_1} {}, \eqclass {c_2, d_2} {}$ be [[Definition:Equivalence Class|$\boxtimes$-equivalence classes]] such that $\eqclass {a_1, b_1} {} = \eqclass {a_2, b_2} {}$ and $\eqclass {c_1, d_1} {} = \eqclass {c_2, d_2} {}$. Then: {{begin-eqn}} {{eqn | l = \eqclass {a_1, b_1} {} | r = \eqclass {a_2, b_2} {} | c = {{Defof|Operation Induced by Direct Product}} }} {{eqn | lo= \land | l = \eqclass {c_1, d_1} {} | r = \eqclass {c_2, d_2} {} | c = {{Defof|Operation Induced by Direct Product}} }} {{eqn | ll= \leadstoandfrom | l = a_1 + b_2 | r = a_2 + b_1 | c = {{Defof|Cross-Relation}} }} {{eqn | lo= \land | l = c_1 + d_2 | r = c_2 + d_1 | c = {{Defof|Cross-Relation}} }} {{end-eqn}} Then we have: {{begin-eqn}} {{eqn | l = \tuple {a_1 + c_1} + \tuple {b_2 + d_2} | r = \tuple {a_1 + b_2} + \tuple {c_1 + d_2} | c = [[Definition:Commutative Operation|Commutativity]] and [[Definition:Associative Operation|Associativity]] of $+$ }} {{eqn | r = \tuple {a_2 + b_1} + \tuple {c_2 + d_1} | c = from above: $a_1 + b_2 = a_2 + b_1, c_1 + d_2 = c_2 + d_1$ }} {{eqn | r = \tuple {a_2 + c_2} + \tuple {b_1 + d_1} | c = [[Definition:Commutative Operation|Commutativity]] and [[Definition:Associative Operation|associativity]] of $+$ }} {{eqn | ll= \leadsto | l = \tuple {a_1 + c_1, b_1 + d_1} | o = \boxtimes | r = \tuple {a_2 + c_2, b_2 + d_2} | c = Definition of $\boxtimes$ }} {{eqn | ll= \leadsto | l = \tuple {\tuple {a_1, b_1} \oplus \tuple {c_1, d_1} } | o = \boxtimes | r = \tuple {\tuple {a_2, b_2} \oplus \tuple {c_2, d_2} } | c = Definition of $\oplus$ }} {{end-eqn}} {{qed}}	0
From [[Sum of All Ring Products is Additive Subgroup]] we have that $\left({S T, +}\right)$ is an [[Definition:Additive Subgroup|additive subgroup]] of $R$. Let $x_1, x_2 \in S T$. Then: : $\displaystyle x_1 = \sum_{i \mathop = 1}^m s_i \circ t_i, x_2 = \sum_{i \mathop = 1}^n s_j \circ t_j$ for some $s_i, t_i, s_j, t_j, m, n$, etc. Then: {{begin-eqn}} {{eqn | l = x_1 \circ x_2 | r = \left({\sum_{i \mathop = 1}^m s_i \circ t_i}\right) \circ \left({\sum_{j \mathop = 1}^n s'_j \circ t'_j}\right) | c = }} {{eqn | r = \sum_{ {1 \mathop \le i \mathop \le m} \atop {1 \mathop \le j \mathop \le n} } \left({s_i \circ s'_j}\right) \circ \left({t_i \circ t'_j}\right) | c = as $\circ$ is [[Definition:Commutative Operation|commutative]] }} {{end-eqn}} So $x_1 \circ x_2 \in S T$ and the result follows from the [[Subring Test]]. {{qed}}	0
Let $G$ be a [[Definition:Group|group]] whose [[Definition:Identity Element|identity]] is $e$ and whose [[Definition:Order of Structure|order]] is $n$. Then: :$\forall g \in G: g^n = e$	0
A (non-[[Definition:Zero (Number)|zero]]) [[Definition:Integer|integer]] is greater than or equal to its [[Definition:Divisor of Integer|divisors]] in [[Definition:Absolute Value|magnitude]]: :$\forall c \in \Z_{\ne 0}: a \divides c \implies a \le \size a \le \size c$	0
Follows immediately from [[Finite Multiplicative Subgroup of Field is Cyclic]]. {{qed}} [[Category:Galois Fields]] jjwa16ge80xdni2x02rvbql2smj1753	0
An [[Definition:Integral Domain|integral domain]] is by definition a [[Definition:Ring (Abstract Algebra)|ring]] which has no [[Definition:Proper Zero Divisor|proper zero divisors]]. By definition, a [[Definition:Galois Field|Galois field]] is a [[Definition:Field (Abstract Algebra)|field]] whose [[Definition:Underlying Set|underlying set]] is [[Definition:Finite Set|finite]]. The result follows from [[Finite Ring with No Proper Zero Divisors is Field]]. {{qed}}	0
Let $S$ be the [[Definition:Positive Real Number|positive]] [[Definition:Real Axis|real axis]] of the [[Definition:Complex Plane|complex plane]]: :$S = \set {z \in \C: z = x + 0 i, x \in \R_{>0} }$ Consider the [[Definition:Algebraic Structure|algebraic structure]] $\struct {S, \times}$ as a [[Definition:Subgroup|subgroup]] of the [[Definition:Multiplicative Group of Complex Numbers|multiplicative group of complex numbers]] $\struct {\C_{\ne 0}, \times}$. The [[Definition:Coset|cosets]] of $\struct {S, \times}$ are the [[Definition:Set|sets]] of the form: :$\set {z \in \C: \exists r \in \R_{>0}: z = r e^{i \theta}}$ for some $\theta \in \hointr 0 {2 \pi}$ That is, the [[Definition:Set|sets]] of all [[Definition:Complex Number|complex numbers]] with a constant [[Definition:Argument of Complex Number|argument]].	0
Consider the [[Definition:Initial Segment of Natural Numbers|initial segment of natural numbers]] $\N_n = \set {1, 2, \ldots, n}$. By the definition of [[Definition:Cardinality|cardinality]], $H$ is [[Definition:Set Equivalence|equivalent]] to $\N_n$. {{WLOG}} we can consider $S_n$ acting directly on $\N_n$. The [[Definition:Stabilizer|stabilizer]] of $n$ in $\N_n$ is all the [[Definition:Permutation|permutations]] of $S_n$ which fix $n$, which is clearly $S_{n - 1}$. A [[Definition:Permutation|permutation]] can be applied to $\N_n$ so that $i \to n$ for any $i$. Thus one can build an [[Definition:Group Isomorphism|isomorphism]] to show the result for a general $i$. {{qed}}	0
Let $\struct {S, \circ}$ be an [[Definition:Algebraic Structure|algebraic structure]] with more than one [[Definition:Left Identity|left identity]]. Take any two of these, and call them $e_{L_1}$ and $e_{L_2}$, where $e_{L_1} \ne e_{L_2}$. Suppose $\struct {S, \circ}$ has a [[Definition:Right Identity|right identity]]. Call this [[Definition:Right Identity|right identity]] $e_R$. Then, by the behaviour of $e_R$, $e_{L_1}$ and $e_{L_2}$: : $e_{L_1} = e_{L_1} \circ e_R = e_R$ : $e_{L_2} = e_{L_2} \circ e_R = e_R$ So $e_{L_1} = e_R = e_{L_2}$, which contradicts the supposition that $e_{L_1}$ and $e_{L_2}$ are different. Therefore, in an [[Definition:Algebraic Structure|algebraic structure]] with more than one [[Definition:Left Identity|left identity]], there can be no [[Definition:Right Identity|right identity]]. {{qed}}	0
Let $\struct {S, \circ}$ be a [[Definition:Monoid|monoid]] with [[Definition:Identity Element|identity element]] $e_S$. Let $x \in S$ such that $x$ has both a [[Definition:Left Inverse Element|left inverse]] and a [[Definition:Right Inverse Element|right inverse]]. That is: :$\exists x_L \in S: x_L \circ x = e_S$ :$\exists x_R \in S: x \circ x_R = e_S$ Then $x_L = x_R$, that is, $x$ has an [[Definition:Inverse Element|inverse]]. Furthermore, that element is the ''only'' [[Definition:Inverse Element|inverse]] (both [[Definition:Right Inverse Element|right]] and [[Definition:Left Inverse Element|left]]) for $x$	0
We have the result [[Center is Intersection of Centralizers]]. That is, $\map Z G$ is the [[Definition:Set Intersection|intersection]] of all the [[Definition:Centralizer of Group Element|centralizers]] of $G$. All of these are [[Definition:Subgroup|subgroups]] of $G$ by [[Centralizer of Group Element is Subgroup]]. Thus from [[Intersection of Subgroups is Subgroup]], $\map Z G$ is also a [[Definition:Subgroup|subgroup]] of $G$. {{qed}}	0
Let $G$ be a [[Definition:Group|group]] whose [[Definition:Identity Element|identity element]] is $e$. Let $H$ be a [[Definition:Subgroup|subgroup]] of $G$. Then: :$\index G H = 1 \iff G = H$ where $\index G H$ denotes the [[Definition:Index of Subgroup|index]] of $H$ in $G$.	0
If ones appear in a row of $\mathbf A$, then replace $\mathbf A$ by $\mathbf A^T$ and $\mathbf B$ by $\mathbf B^T$. Assume $\mathbf A$ has a column of ones. Apply [[Sum of Elements of Invertible Matrix]] to the [[Definition:Inverse Matrix|inverse]] $\mathbf B = \mathbf A^{-1}$: :$\displaystyle \sum_{i \mathop = 1}^n \sum_{j \mathop = 1}^n b_{i j} = 1 - \map \det {\mathbf B} \map \det {\mathbf B^{-1} - \mathbf J_n}$ where $\mathbf J_n$ denotes the [[Definition:Square Ones Matrix|square ones matrix]] of [[Definition:Order of Square Matrix|order]] $n$. If $\mathbf A = \mathbf B^{-1}$ has a column of ones, then $\mathbf B^{-1} - \mathbf J_n$ has a column of zeros, implying determinant zero. Substitute $\map \det {\mathbf B^{-1} - \mathbf J_n} = 0$ in [[Sum of Elements of Invertible Matrix]]: :$\displaystyle \sum_{i \mathop = 1}^n \sum_{j \mathop = 1}^n b_{i j} = 1 - 0$ which implies the statement. {{qed}}	0
:$100 \bmod 7 = 2$	0
From [[Group of Order p^2 q has Normal Sylow p-Subgroup|Group of Order $p^2 q$ has Normal Sylow $p$-Subgroup]], $G$ has a [[Definition:Normal Subgroup|normal subgroup]] of [[Definition:Order of Group|order $p^2$]]. Hence the result, by definition of [[Definition:Simple Group|simple group]]. {{qed}}	0
Suppose $P$ and $Q$ are [[Definition:Sylow p-Subgroup|Sylow $p$-subgroups]] of $G$. By the [[Second Sylow Theorem]], $Q$ is a [[Definition:Subset|subset]] of a [[Definition:Conjugate of Group Subset|conjugate]] of $P$. But since $\order P = \order Q$, it follows that $Q$ must equal a [[Definition:Conjugate of Group Subset|conjugate]] of $P$. {{qed}}	0
Since $m \preceq n$, by [[Definition:Naturally Ordered Semigroup Axioms|axiom $(NO3)$]]: :$\exists p \in S: m + p = n$ Now suppose that $p, q \in S$ are such that: :$m + p = m + q = n$ Then it follows from [[Definition:Naturally Ordered Semigroup Axioms|axiom $(NO2)$]] that: :$p = q$ Hence the result. {{qed}}	0
Let $\struct {G, \circ}$ be a [[Definition:Group|group]] whose [[Definition:Identity Element|identity]] is $e$. Let $S$ be a [[Definition:Set|set]]. Let $\struct {G^S, \oplus}$ be the [[Definition:Induced Structure|structure on $G^S$ induced]] by $\circ$. Then $\struct {G^S, \oplus}$ is a [[Definition:Group|group]].	0
Let $\mathbf A$ be a [[Definition:Matrix|matrix]] over a [[Definition:Field (Abstract Algebra)|field]]. Let $\mathbf A^\intercal$ denote the [[Definition:Transpose of Matrix|transpose]] of $\mathbf A$. Let $\mathbf A$ be an [[Definition:Invertible Matrix|invertible matrix]]. Then $\mathbf A^\intercal$ is also [[Definition:Invertible Matrix|invertible]] and: :$\paren {\mathbf A^\intercal}^{-1} = \paren {\mathbf A^{-1} }^\intercal$ where $\mathbf A^{-1}$ denotes the [[Definition:Inverse Matrix|inverse]] of $\mathbf A$.	0
{{:Even Integer Plus 5 is Odd}}	0
{{begin-eqn}} {{eqn | l = \eqclass x m \times_m \eqclass y m | r = \eqclass {x y} m | c = {{Defof|Modulo Multiplication}} }} {{eqn | r = \eqclass {y x} m | c = [[Integer Multiplication is Commutative]] }} {{eqn | r = \eqclass y m \times_m \eqclass x m | c = {{Defof|Modulo Multiplication}} }} {{end-eqn}} {{qed}}	0
Let $\struct {F, +, \times}$ be a [[Definition:Field (Abstract Algebra)|field]]. Then of the following two cases, exactly one applies:	0
Let $m \in \Z_{> 0}$. Let $x_1, x_2, y_1, y_2, c_1, c_2 \in \Z$. Let: :$x_1 \equiv y_1 \pmod m$ :$x_2 \equiv y_2 \pmod m$ Then: :$c_1 x_1 + c_2 x_2 \equiv c_1 y_1 + c_2 y_2 \pmod m$	0
From [[Sum of Geometric Sequence]]: {{begin-eqn}} {{eqn | l = \sum_{j \mathop = 0}^{n - 1} x^j | r = \frac {x^n - 1} {x - 1} | c = }} {{eqn | ll= \leadsto | l = \paren {\dfrac a b}^n - 1 | r = \paren {\dfrac a b - 1} \sum_{j \mathop = 0}^{n - 1} \paren {\dfrac a b}^j | c = }} {{eqn | ll= \leadsto | l = \paren {\dfrac {a^n - b^n} {b^n} } | r = \paren {\dfrac {a - b} b} \paren {\paren {\dfrac a b}^{n - 1} + \paren {\dfrac a b}^{n - 2} + \dotsb + \paren {\dfrac a b}^1 + 1} | c = }} {{eqn | ll= \leadsto | l = a^n - b^n | r = \paren {a - b} \paren {a^{n - 1} + a^{n - 2} b + \dotsb + a b^{n - 2} + b^{n - 1} } | c = multiplying both sides by $b^n$ }} {{end-eqn}} {{qed}}	0
Let $\Z \sqbrk X$ be the [[Definition:Ring of Polynomials in Ring Element|ring of polynomials]] in $X$ over $\Z$. Then $\Z \sqbrk X$ is not a [[Definition:Principal Ideal Domain|principal ideal domain]].	0
:$1 \cdotp 1 \bmod 1 = 0 \cdotp 1$	0
Let $G$ be a [[Definition:Group|group]]. Let $N$ be a [[Definition:Normal Subgroup|normal subgroup]] of $G$. Let $K$ be a [[Definition:Normal Subgroup|normal subgroup]] of $N$. Then it is not necessarily the case that $K$ is a [[Definition:Normal Subgroup|normal subgroup]] of $G$.	0
Let $\left({G, \circ, \preceq}\right)$ be an [[Definition:Ordered Group|ordered group]]. An '''ordered group automorphism''' from $\left({G, \circ, \preceq}\right)$ to itself is a [[Definition:Mapping|mapping]] $\phi: G \to G$ that is both: :$(1): \quad$ A [[Definition:Group Automorphism|group automorphism]], that is, a [[Definition:Group Isomorphism|group isomorphism]] from the [[Definition:Group|group]] $\left({G, \circ}\right)$ to itself :$(2): \quad$ An [[Definition:Order Isomorphism|order isomorphism]] from the [[Definition:Ordered Set|ordered set]] $\left({G, \preceq}\right)$ to itself.	0
Let $\left({S, \circ}\right)$ be a [[Definition:Finite Algebraic Structure|finite algebraic structure]]. Let $\mathcal T$ be the [[Definition:Cayley Table|Cayley table]] for $\left({S, \circ}\right)$. Let $a \in S$ be an [[Definition:Element|element]] of $S$. Then $a$ is [[Definition:Cancellable Element|cancellable]] for $\circ$ {{iff}}: :$(1): \quad$ no [[Definition:Element|element]] of $S$ is repeated in $\mathcal T$ in the row headed by $a$ and: :$(2): \quad$ no [[Definition:Element|element]] of $S$ is repeated in $\mathcal T$ in the column headed by $a$.	0
=== Necessary Condition === Let $a \perp b$. Suppose $a + b$ is not [[Definition:Coprime Integers|coprime]] to $a$. Then: :$\exists d \in \Z_{>1}: d \divides a, d \divides \paren {a + b}$ But then: :$d \divides \paren {\paren {a + b} - a}$ and so: :$d \divides b$ and so $a$ and $b$ are not [[Definition:Coprime Integers|coprime]]. From this [[Proof by Contradiction|contradiction]] it follows that $a + b$ is [[Definition:Coprime Integers|coprime]] to $a$. {{qed|lemma}} === Sufficient Condition === Let $a + b$ be [[Definition:Coprime Integers|coprime]] to $a$. Suppose $a$ is not [[Definition:Coprime Integers|coprime]] to $b$. Then: :$\exists d \in \Z_{>1}: d \divides a, d \divides b$ and so: :$d \divides \paren {a + b}$ and so $a$ and $\paren {a + b}$ are not [[Definition:Coprime Integers|coprime]]. From this [[Proof by Contradiction|contradiction]] it follows that $a$ is [[Definition:Coprime Integers|coprime]] to $b$. {{qed}} {{Euclid Note|28|VII}}	0
The [[Definition:Ring of Eisenstein Integers|ring of Eisenstein integers]] $\struct {\Z \sqbrk \omega, +, \times}$ is an [[Definition:Integral Domain|integral domain]].	0
Apart from $2$, all [[Definition:Prime Number|primes]] are [[Definition:Odd Integer|odd]]. From [[Sigma Function Odd iff Argument is Square or Twice Square]], for $\map \sigma n$ to be [[Definition:Odd Integer|odd]] it needs to be of the form $m^2$ or $2 m^2$. Suppose $n$ has two [[Definition:Coprime Integers|coprime]] [[Definition:Divisor of Integer|divisors]] $p$ and $q$, each to [[Definition:Integer Power|power]] $k_p$ and $k_q$ respectively. Then $\map \sigma n$ will have $\map \sigma {p^{k_p} }$ and $\map \sigma {q^{k_q} }$ as [[Definition:Divisor of Integer|divisors]]. Hence $\map \sigma n$ will not be [[Definition:Prime Number|prime]]. So for $\map \sigma n$ to be [[Definition:Prime Number|prime]], $n$ can have only one [[Definition:Prime Factor|prime factor]]. This gives possible values for $n$ as: :[[Definition:Integer Power|powers of $2$]], either [[Definition:Odd Power|odd]] or [[Definition:Even Power|even]] or: :[[Definition:Even Power|even powers]] of a [[Definition:Prime Number|prime number]]. These can be investigated in turn, using [[Sigma Function of Power of Prime]]: :$\map \sigma {p^k} = \dfrac {p^{k + 1} - 1} {p - 1}$ Note that as $\map \sigma {2^k} = \dfrac {2^{k + 1} - 1} {2 - 1} = 2^{k + 1} - 1$ it is necessary for powers of $2$ merely to report the appropriate [[Definition:Mersenne Prime|Mersenne prime]]. Hence when $k + 1$ is not [[Definition:Prime Number|prime]], $\map \sigma {2^k}$ will not be [[Definition:Prime Number|prime]] and there is no need to test it. Thus we test all $n$ such that: :$n = p^{2 k}$ for [[Definition:Prime Number|prime]] $p$ :$n = 2^k$ where $k + 1$ is [[Definition:Prime Number|prime]] and so: {{begin-eqn}} {{eqn | l = \map \sigma 2 | r = 2^2 - 1 | c = }} {{eqn | r = 3 | c = which is a [[Definition:Mersenne Prime|Mersenne prime]] }} {{end-eqn}} {{begin-eqn}} {{eqn | l = \map \sigma 4 | r = \map \sigma {2^2} }} {{eqn | r = 2^3 - 1 }} {{eqn | r = 7 | c = which is a [[Definition:Mersenne Prime|Mersenne prime]] }} {{end-eqn}} {{begin-eqn}} {{eqn | l = \map \sigma 9 | r = \map \sigma {3^2} }} {{eqn | r = \dfrac {3^3 - 1} {3 - 1} }} {{eqn | r = \dfrac {26} 2 }} {{eqn | r = 13 | c = which is [[Definition:Prime Number|prime]] }} {{end-eqn}} {{begin-eqn}} {{eqn | l = \map \sigma {16} | r = \map \sigma {2^4} }} {{eqn | r = \dfrac {2^5 - 1} {2 - 1} }} {{eqn | r = 31 | c = which is [[Definition:Prime Number|prime]] }} {{end-eqn}} {{begin-eqn}} {{eqn | l = \map \sigma {25} | r = \map \sigma {5^2} }} {{eqn | r = \dfrac {5^3 - 1} {5 - 1} }} {{eqn | r = \dfrac {124} 4 }} {{eqn | r = 31 | c = which is [[Definition:Prime Number|prime]] }} {{end-eqn}} {{begin-eqn}} {{eqn | l = \map \sigma {49} | r = \map \sigma {7^2} }} {{eqn | r = \dfrac {7^3 - 1} {7 - 1} }} {{eqn | r = \dfrac {342} 6 }} {{eqn | r = 57 = 3 \times 19 | c = which is not [[Definition:Prime Number|prime]] }} {{end-eqn}} {{begin-eqn}} {{eqn | l = \map \sigma {64} | r = \map \sigma {2^6} }} {{eqn | r = \dfrac {2^7 - 1} {2 - 1} }} {{eqn | r = 127 | c = which is a [[Definition:Mersenne Prime|Mersenne prime]] }} {{end-eqn}} {{begin-eqn}} {{eqn | l = \map \sigma {121} | r = \map \sigma {11^2} }} {{eqn | r = \dfrac {11^3 - 1} {11 - 1} }} {{eqn | r = \dfrac {1330} {10} }} {{eqn | r = 133 = 7 \times 19 | c = which is not [[Definition:Prime Number|prime]] }} {{end-eqn}} {{begin-eqn}} {{eqn | l = \map \sigma {169} | r = \map \sigma {13^2} }} {{eqn | r = \dfrac {13^3 - 1} {11 - 1} }} {{eqn | r = \dfrac {2196} {12} }} {{eqn | r = 183 = 3 \times 61 | c = which is not [[Definition:Prime Number|prime]] }} {{end-eqn}} {{begin-eqn}} {{eqn | l = \map \sigma {289} | r = \map \sigma {17^2} }} {{eqn | r = \dfrac {17^3 - 1} {17 - 1} }} {{eqn | r = \dfrac {4912} {16} }} {{eqn | r = 307 | c = which is [[Definition:Prime Number|prime]] }} {{end-eqn}} Hence the sequence as given. {{qed}}	0
=== [[Definition:Abelian Group/Definition 1|Definition 1]] === {{:Definition:Abelian Group/Definition 1}} === [[Definition:Abelian Group/Definition 2|Definition 2]] === {{:Definition:Abelian Group/Definition 2}}	0
Let $G$ be a [[Definition:Group|group]]. Let $S \subseteq G$. Let $\hat S = S \cup S^{-1}$, where $S^{-1}$ is the [[Definition:Inverse of Subset of Group|set of all the inverses]] of all the elements of $S$. Let $\tilde S = \set {a s a^{-1}: s \in \hat S, a \in G}$. That is, $\tilde S$ is the [[Definition:Set|set]] containing all the [[Definition:Conjugate of Group Element|conjugates]] of the [[Definition:Element|elements]] of $S$ and all their [[Definition:Inverse Element|inverses]]. Then: : $\forall x \in \tilde S: x^{-1} \in \tilde S$	0
Let $\struct {D, +, \circ}$ be a [[Definition:Principal Ideal Domain|principal ideal domain]]. Let $S = \set {a_1, a_2, \dotsc, a_n}$ be a [[Definition:Set|set]] of non-[[Definition:Ring Zero|zero]] [[Definition:Element|elements]] of $D$. Let $y$ be a [[Definition:Greatest Common Divisor of Ring Elements|greatest common divisor]] of $S$. Then $y$ is expressible in the form: :$y = d_1 a_1 + d_2 a_2 + \dotsb + d_n a_n$ where $d_1, d_2, \dotsc, d_n \in D$.	0
By definition, $\struct {F, +, \times}$ and $\struct {K, +, \times}$ are both [[Definition:Ring (Abstract Algebra)|rings]]. Thus $\struct {K, +, \times}$ is a [[Definition:Subring|subring]] of $\struct {F, +, \times}$ The result follows from [[Zero of Subring is Zero of Ring]]. {{qed}}	0
Let $n \in \Z_{>0}$ be a [[Definition:Integer Power|power]] of $2$. Then: :$\map \sigma n = 2 n - 1$	0
Let $\Q$ be the [[Definition:Set|set]] of all [[Definition:Rational Number|rational numbers]]. Let $d: \Q \times \Q \to \R$ be defined as: :$\map d {x_1, x_2} = \size {x_1 - x_2}$ where $\size x$ is the [[Definition:Absolute Value|absolute value]] of $x$. Then $d$ is a [[Definition:Metric|metric]] on $\Q$ and so $\struct {\Q, d}$ is a [[Definition:Metric Space|metric space]].	0
Let $S_n$ denote the [[Definition:Symmetric Group on n Letters|symmetric group on $n$ letters]]. Every finite [[Definition:Group|group]] is [[Definition:Group Isomorphism|isomorphic]] to a [[Definition:Subgroup|subgroup]] of $S_n$ for some $n \in \Z$.	0
From [[Rational Numbers are Countably Infinite]], $\Q$ is [[Definition:Countably Infinite Set|countable]]. Hence the result from definition of [[Countable Space is Sigma-Compact|Countable Space is $\sigma$-Compact]]. {{qed}}	0
[[Modulo Multiplication is Closed|Multiplication modulo $m$ is closed]]. [[Modulo Multiplication is Associative|Multiplication modulo $m$ is associative]]. [[Modulo Multiplication has Identity|Multiplication modulo $m$ has an identity]]: :$\forall k \in \Z: \eqclass k m \eqclass 1 m = \eqclass k m = \eqclass 1 m \eqclass k m$ This [[Identity of Monoid is Unique|identity is unique]]. [[Modulo Multiplication is Commutative|Multiplication modulo $m$ is commutative]]. Thus all the conditions are fulfilled for this to be a [[Definition:Commutative Monoid|commutative monoid]]. {{qed}}	0
Let $r \in \N: 0 < r \le n$. Let $B_r$ denote the [[Definition:Set|set]] of all [[Definition:Subset|subsets]] of $\N_n$ of [[Definition:Cardinality|cardinality]] $r$: :$B_r := \set {S \subseteq \N_n: \card S = r}$ Let $*$ be the [[Definition:Mapping|mapping]] $*: S_n \times B_r \to B_r$ defined as: :$\forall \pi \in S_n, \forall S \in B_r: \pi * B_r = \pi \sqbrk S$ where $\pi \sqbrk S$ denotes the [[Definition:Image of Subset under Mapping|image of $S$ under $\pi$]]. Then $*$ is a [[Definition:Transitive Group Action|transitive group action]].	0
Let $r \in \N: 0 < r \le n$. Let $B_r$ denote the [[Definition:Set|set]] of all [[Definition:Subset|subsets]] of $\N_n$ of [[Definition:Cardinality|cardinality]] $r$: :$B_r := \set {S \subseteq \N_n: \card S = r}$ Let $*$ be the [[Definition:Mapping|mapping]] $*: S_n \times B_r \to B_r$ defined as: :$\forall \pi \in S_n, \forall S \in B_r: \pi * B_r = \pi \sqbrk S$ where $\pi \sqbrk S$ denotes the [[Definition:Image of Subset under Mapping|image of $S$ under $\pi$]]. Then $*$ is a [[Definition:Group Action|group action]].	0
Let $\left({G, +}\right)$ be a [[Definition:Commutative Semigroup|commutative]] [[Definition:Topological Semigroup|topological semigroup]]. Let $\left({g_i}\right)_{i \in I}$ be an [[Definition:Indexed Set|indexed]] [[Definition:Subset|subset]] of $G$. Consider the set $\mathcal F$ of [[Definition:Finite|finite]] [[Definition:Subset|subsets]] of $I$. Let $\subseteq$ denote the [[Subset Relation is Ordering|subset relation]] on $\mathcal F$. By virtue of [[Finite Subsets form Directed Set]], $\left({\mathcal F, \subseteq}\right)$ is a [[Definition:Directed Set|directed set]]. Define the [[Definition:Net (Preordered Set)|net]]: :$\phi: \mathcal F \to G$ by: : $\displaystyle \phi \left({F}\right) = \sum_{i \mathop \in F} g_i$ Then $\phi$ is denoted: : $\displaystyle \sum \left\{{g_i: i \in I}\right\}$ and referred to as a '''generalized sum'''.	0
From the definition of [[Definition:Division|division]]: :$a \div b := a \times \paren {\dfrac 1 b}$ where $\dfrac 1 b$ is the [[Definition:Inverse Element|inverse]] for [[Definition:Real Multiplication|real number multiplication]]. From [[Strictly Positive Real Numbers under Multiplication form Uncountable Abelian Group]], the [[Definition:Algebraic Structure|algebraic structure]] $\struct {\R_{>0}, \times}$ forms a [[Definition:Group|group]]. Thus it follows that: :$\forall a, b \in \R_{>0}: a \times \paren {\dfrac 1 b} \in \R$ Therefore [[Definition:Division|real number division]] is [[Definition:Closed Algebraic Structure|closed]] in $\R_{>0}$. {{qed}}	0
This follows directly from the definition of an [[Definition:Ideal of Ring|ideal]] and [[Subring Test]]. {{qed}}	0
Suppose $p \divides n$. Then for all $m \in \Z$: {{begin-eqn}} {{eqn | l = m \perp n | o = \implies | r = m \perp n \land m \perp p | c = [[Law of Identity]]; [[Divisor of One of Coprime Numbers is Coprime to Other]] }} {{eqn | o = \implies | r = m \perp p^k n | c = [[Integer Coprime to all Factors is Coprime to Whole]] }} {{eqn | o = \implies | r = m \perp n | c = [[Divisor of One of Coprime Numbers is Coprime to Other]] }} {{eqn | ll = \leadsto | l = m \perp p^k n | o = \iff | r = m \perp n | c = {{Defof|Biconditional}} }} {{end-eqn}} Hence: {{begin-eqn}} {{eqn | l = \map {\Phi_{p^k n} } x | r = \prod_{\zeta} \paren {x - \zeta} | c = where the product runs over all [[Definition:Primitive Complex Root of Unity|primitive complex $p^k n$th roots of unity]] }} {{eqn | r = \prod_{\substack {1 \mathop \le m \mathop \le p^k n \\ \gcd \set {m, p^k n} = 1} } \paren {x - \map \exp {\frac {2 \pi i m} {p^k n} } } | c = [[Condition for Complex Root of Unity to be Primitive]] }} {{eqn | r = \prod_{\substack {1 \mathop \le m \mathop \le p^k n \\ \gcd \set {m, n} = 1} } \paren {x - \map \exp {\frac {2 \pi i m} {p^k n} } } | c = as $m \perp p^k n \iff m \perp n$ }} {{eqn | r = \prod_{q \mathop = 0}^{p^k - 1} \prod_{\substack {1 \mathop \le r \mathop \le n \\ \gcd \set {q n + r, n} = 1} } \paren {x - \map \exp {\frac {2 \pi i \paren {q n + r} } {p^k n} } } | c = Writing $m = q n + r$ by [[Division Theorem]] }} {{eqn | r = \prod_{\substack {1 \mathop \le r \mathop \le n \\ \gcd \set {r, n} = 1} } \prod_{q \mathop = 0}^{p^k - 1} \paren {x - \map \exp {\frac {2 \pi i} {p^k} }^q \map \exp {\frac {2 \pi i r} {p^k n} } } | c = rearranging; [[GCD with Remainder]] }} {{eqn | r = \prod_{\substack {1 \mathop \le r \mathop \le n \\ \gcd \set {r, n} = 1} } \paren {x^{p^k} - \map \exp {\frac {2 \pi i r} n} } | c = [[Factorisation of z^n-a|Factorisation of $z^n - a$]] }} {{eqn | r = \prod_{\zeta} \paren {x^{p^k} - \zeta} | c = where the product runs over all [[Definition:Primitive Complex Root of Unity|primitive complex $n$th roots of unity]]; [[Condition for Complex Root of Unity to be Primitive]] }} {{eqn | r = \map {\Phi_n} {x^{p^k} } | c = {{Defof|Cyclotomic Polynomial}} }} {{end-eqn}} {{qed|lemma}} Now suppose $p \nmid n$. We still have $p \divides p n$. Write $p^k = p^{k - 1} p n$. Notice that the result we proved above holds trivially for $k = 0$: :$\map {\Phi_{p^0 n} } x = \map {\Phi_n } x = \map {\Phi_n } {x^1} = \map {\Phi_n } {x^{p^0}}$ Hence from the above: :$\map {\Phi_{p^k n} } x = \map {\Phi_{p n}} {x^{p^{k - 1}}}$ We need the following result: :the sets $\set {m \in \Z: m \perp p n}$ and $\set {p r: r \perp n}$ are [[Definition:Disjoint Sets|disjoint]] and has [[Definition:Set Union|union]] $\set {m \in \Z: m \perp n}$ First to show that they are indeed [[Definition:Disjoint Sets|disjoint]]: Suppose $x \in \set {p r: r \perp n}$. Then $p \divides x$. Since $p \divides p n$: :$x \not \perp p n$ and thus: :$x \notin \set {m \in \Z: m \perp p n}$ Hence the sets are [[Definition:Disjoint Sets|disjoint]]. Now we show that their [[Definition:Set Union|union]] is indeed $\set {m \in \Z: m \perp n}$. By [[Divisor of One of Coprime Numbers is Coprime to Other]]: :$\forall m \in \Z: m \perp p n \implies \paren {m \perp p \land m \perp n}$ This gives: :$\set {m \in \Z: m \perp p n} \subseteq \set {m \in \Z: m \perp n}$ Let $x \in \set {p r: r \perp n}$. We are given that $p \perp n$. By [[Integer Coprime to all Factors is Coprime to Whole]]: :$x \perp n$ Hence $x \in \set {m \in \Z: m \perp n}$. This gives: :$\set {p r: r \perp n} \subseteq \set {m \in \Z: m \perp n}$ By [[Union of Subsets is Subset]]: :$\set {m \in \Z: m \perp p n} \cup \set {p r: r \perp n} \subseteq \set {m \in \Z: m \perp n}$ For the other direction, we let $x \notin \set {m \in \Z: m \perp p n} \cup \set {p r: r \perp n}$. Then by [[De Morgan's Laws (Set Theory)/Set Complement]]: :$x \in \set {m \in \Z: m \not \perp p n} \cap \set {p r: r \not \perp n}$. By definition of [[Definition:Set Intersection|intersection]]: :$x \in \set {p r: r \not \perp n}$ Thus: :$\exists d \in \Z: d > 1: d \divides r \divides x \land d \divides n$ Therefore $x \not \perp n$. This gives: :$x \notin \set {m \in \Z: m \perp n}$ Hence: :$\set {m \in \Z: m \perp n} \subseteq \set {m \in \Z: m \perp p n} \cup \set {p r: r \perp n}$ and we have our result by definition of [[Definition:Set Equality|set equality]]. Therefore: {{begin-eqn}} {{eqn | l = \map {\Phi_{p n} } {x^{p^{k - 1} } } | r = \prod_{\zeta} \paren {x^{p^{k - 1} } - \zeta} | c = where the product runs over all [[Definition:Primitive Complex Root of Unity|primitive complex $p n$th roots of unity]] }} {{eqn | r = \prod_{\substack {1 \mathop \le m \mathop \le p n \\ m \mathop \perp p n} } \paren {x^{p^{k - 1} } - \map \exp {\frac {2 \pi i m} {p n} } } | c = [[Condition for Complex Root of Unity to be Primitive]] }} {{eqn | r = \prod_{\substack {1 \mathop \le m \mathop \le p n \\ m \mathop \perp n} } \paren {x^{p^{k - 1} } - \map \exp {\frac {2 \pi i m} {p n} } } / \prod_{\substack {1 \mathop \le p r \mathop \le p n \\ \gcd \set {r, n} = 1} } \paren {x^{p^{k - 1} } - \map \exp {\frac {2 \pi i m} {p n} } } | c = from above }} {{eqn | r = \prod_{\substack {1 \mathop \le m \mathop \le p n \\ m \mathop \perp n} } \paren {x^{p^{k - 1} } - \map \exp {\frac {2 \pi i m} {p n} } } / \prod_{\zeta} \paren {x^{p^k} - \zeta} | c = where the product runs over all [[Definition:Primitive Complex Root of Unity|primitive complex $n$th roots of unity]]; [[Condition for Complex Root of Unity to be Primitive]] }} {{eqn | r = \prod_{\substack {1 \mathop \le m \mathop \le p n \\ m \mathop \perp n} } \paren {x^{p^{k - 1} } - \map \exp {\frac {2 \pi i m} {p n} } } / \map {\Phi_n} {x^{p^{k - 1} } } | c = {{Defof|Cyclotomic Polynomial}} }} {{eqn | r = \prod_{q \mathop = 0}^{p - 1} \prod_{\substack {1 \mathop \le r \mathop \le n \\ \gcd \set {q n + r, n} = 1} } \paren {x^{p^{k - 1} } - \map \exp {\frac {2 \pi i \paren {q n + r} } {p n} } } / \map {\Phi_n} {x^{p^{k - 1} } } | c = Writing $m = q n + r$ by [[Division Theorem]] }} {{eqn | r = \prod_{\substack {1 \mathop \le r \mathop \le n \\ \gcd \set {r, n} = 1} } \prod_{q \mathop = 0}^{p - 1} \paren {x^{p^{k - 1} } - \map \exp {\frac {2 \pi i} p}^q \map \exp {\frac {2 \pi i r} {p n} } } / \map {\Phi_n} {x^{p^{k - 1} } } | c = rearranging; [[GCD with Remainder]] }} {{eqn | r = \prod_{\substack {1 \mathop \le r \mathop \le n \\ \gcd \set {r, n} = 1} } \paren {x^{p^k} - \map \exp {\frac {2 \pi i r} n} } / \map {\Phi_n} {x^{p^{k - 1} } } | c = [[Factorisation of z^n-a|Factorisation of $z^n - a$]] }} {{eqn | r = \prod_{\zeta} \paren {x^{p^k} - \zeta} / \map {\Phi_n} {x^{p^{k - 1} } } | c = where the product runs over all [[Definition:Primitive Complex Root of Unity|primitive complex $n$th roots of unity]]; [[Condition for Complex Root of Unity to be Primitive]] }} {{eqn | r = \map {\Phi_n} {x^{p^k} } / \map {\Phi_n} {x^{p^{k - 1} } } | c = {{Defof|Cyclotomic Polynomial}} }} {{end-eqn}} as required. {{qed}} [[Category:Cyclotomic Polynomials]] bfpzg3nvi0k44pocm217165uhcntqfo	0
A specific instance of [[Inverse of Algebraic Structure Isomorphism is Isomorphism]]. {{qed}}	0
Let $\struct {R, \norm {\,\cdot\,} }$ be a [[Definition:Normed Division Ring|normed division ring]] with [[Definition:Unity of Ring|unity]] $1_R$. Then: :$\norm {\,\cdot\,}$ is [[Definition:Non-Archimedean Division Ring Norm|non-Archimedean]] $\implies \forall n \in \N_{>0}: \norm {n \cdot 1_R} \le 1$. where: $n \cdot 1_R = \underbrace {1_R + 1_R + \dots + 1_R}_{\text {$n$ times} }$	0
The result [[Identity Mapping is Automorphism]] holds directly, for both $+$ and $\circ$. As $I_R$ is a [[Definition:Bijection|bijection]], the only element that maps to $0$ is $0$ itself. Thus the [[Definition:Kernel of Ring Homomorphism|kernel]] is $\set 0$. {{qed}}	0
Let us define $\eqclass {\tuple {a, b} } \boxminus$ as in the [[Definition:Integer/Formal Definition|formal definition of integers]]. That is, $\eqclass {\tuple {a, b} } \boxminus$ is an [[Definition:Equivalence Class|equivalence class]] of [[Definition:Ordered Pair|ordered pairs]] of [[Definition:Natural Numbers|natural numbers]] under the [[Definition:Congruence Relation|congruence relation]] $\boxminus$. $\boxminus$ is the [[Definition:Congruence Relation|congruence relation]] defined on $\N \times \N$ as: :$\tuple {x_1, y_1} \boxminus \tuple {x_2, y_2} \iff x_1 + y_2 = x_2 + y_1$ In order to streamline the notation, we will use $\eqclass {a, b} {}$ to mean $\eqclass {\tuple {a, b} } \boxminus$, [[Definition:Integer/Formal Definition/Notation|as suggested]]. [[Definition:Integer Multiplication|Integer multiplication]] is defined as: :$\forall a, b, c, d \in \N: \eqclass {a, b} {} \times \eqclass {c, d} {} = \eqclass {a c + b d, a d + b c} {}$ From [[Integer Multiplication is Closed]], we have that $x, y \in \Z \implies x y \in \Z$. From [[Ring of Integers has no Zero Divisors]], we have that $x, y \in \Z: x, y \ne 0 \implies x y \ne 0$. Therefore [[Definition:Integer Multiplication|multiplication]] on the [[Definition:Zero (Number)|non-zero]] [[Definition:Integer|integers]] is [[Definition:Closed Algebraic Structure|closed]]. {{qed}}	0
Let $S$ be the [[Definition:Set|set]] of [[Definition:Integer|integers]] defined as: :$S = \set {2^k: k \in \Z}$ Then $\struct {S, \times}$ is an [[Definition:Infinite Group|infinite]] [[Definition:Abelian Group|abelian group]].	0
The forward implication is shown in [[Powers of Coprime Numbers are Coprime]]. The reverse implication is shown by substituting $n = 1$. {{qed}} [[Category:Coprime Integers]] 8k2ky39jzctjiltp3egexjushvinn3s	0
Let $\phi: \struct {R_1, +_1, \circ_1} \to \struct {R_2, +_2, \circ_2}$ be a [[Definition:Ring Epimorphism|ring epimorphism]]. Then: :The [[Definition:Kernel of Ring Homomorphism|kernel]] of $\phi$ is an [[Definition:Ideal of Ring|ideal]] of $R_1$. :There is a unique [[Definition:Ring Isomorphism|ring isomorphism]] $g: R_1 / K \to R_2$ such that: ::$g \circ q_K = \phi$ :$\phi$ is a [[Definition:Ring Isomorphism|ring isomorphism]] {{iff}} $K = \set {0_{R_1} }$.	0
: $x, y$ are in the same [[Definition:Left Coset|left coset]] of $H$ {{iff}} $x^{-1} y \in H$.	0
:$(1): \quad x \mathrel {\mathcal R} y \iff e \mathrel {\mathcal R} y \circ x^{-1}$ :$(2): \quad x \mathrel {\mathcal R} y \iff e \mathrel {\mathcal R} x^{-1} \circ y$ :$(3): \quad x \mathrel {\mathcal R} y \iff x \circ y^{-1} \mathrel {\mathcal R} e$ :$(4): \quad x \mathrel {\mathcal R} y \iff y^{-1} \circ x \mathrel {\mathcal R} e$	0
=== $K$ is [[Definition:Subgroup|Subgroup]] of $G$ === We first show that $K$ is a [[Definition:Subgroup|subgroup]] of $G$ using the [[Two-Step Subgroup Test]]. $(1): \quad K \ne \varnothing$: From [[Identity of Subgroup]]: :$e \in H$ From [[Indicator is Well-Defined]], $n > 0$ and so $n - 1 \ge 0$. Thus $k = 0$ fulfils the condition that $0 \le k < n$, and so: :$e = e a^0 \in K$ Thus $K \ne \varnothing$. $(2): \quad K$ is [[Definition:Closure (Abstract Algebra)|closed]]: Let $r = x a^k \in K$ and $s = y a^l \in K$ where $x, y \in H$ and $0 \le k < n, 0 \le l < n$. $G$ is [[Definition:Abelian Group|abelian]], so $r$, $s$ and $a$ [[Definition:Commute|commute]]. So: :$r s = x y a^{k + l}$. Since $H$ is a [[Definition:Group|group]] and $x, y \in H$ then also $x y \in H$. Let $k + l \le n - 1$. Then $r s \in K$ by definition of $K$. Let $n \le k + l \le 2 n$. Then: :$r s = x y a^n a^{k + l - n}$ By definition of [[Definition:Indicator of Group Element|indicator]], $a^n \in H$. Thus as $x, y, a^n \in H$ it follows that $x y a^n \in H$. As $0 \le k + l - n \le n - 1$ it follows that $\left({x y a^n}\right) a^{k + l - n} \in K$ by definition of $K$. So again $r s \in K$. Thus $K$ is [[Definition:Closure (Abstract Algebra)|closed]]. $(3): \quad K$ is [[Definition:Closure (Abstract Algebra)|closed]] under [[Definition:Inverse Element|inversion]]: Let $r = x a^k \in K$ where $x \in H$ and $0 \le k < n$. Then $x^{-1} \in H$. Let $k = 0$. Then :$r^{-1} = x^{-1} e = x^{-1} a^0 \in K$ Let $k > 0$. Then: :$r^{-1} = x^{-1} a^{-k} = x^{-1} a^{-n} a^{n - k}$ By definition of [[Definition:Indicator of Group Element|indicator]], $a^n \in H$. We have that $x^{-1}, a^n \in H$. As $G$ is [[Definition:Abelian Group|abelian]], $x$ and $a$ [[Definition:Commute|commute]]. Thus from [[Inverse of Commuting Pair]]: : $x^{-1} a^{-n} = \left({x a^n}\right)^{-1} \in H$ Also: :$0 \le n - k < n -1$ so: :$r^{-1} = \left({x a^n}\right)^{-1} a^{n - k} \in K$ Therefore by the [[Two-Step Subgroup Test]] we have shown that $K$ is a [[Definition:Subgroup|subgroup]] of $G$. === $H$ is [[Definition:Subgroup|Subgroup]] of $K$ === As: :$\forall x \in H: x = x a^0 \in K$ and so $H \subseteq K$. === [[Definition:Order of Structure|Order]] of $K$ === It remains to be shown that: :$\left\vert{K}\right\vert = n q$ where $q = \left\vert{H}\right\vert$. Let $x a^k = y a^l \in K$. [[Definition:WLOG|WLOG]], let $k \ge l$ (if not, just relabel the two). We have: : $a^{k - l} = x^{-1} y$ Since $H$ is a subgroup of $G$: :$x^{-1} y \in H$ and therefore: :$a^{k - l} \in H$ By definition of [[Definition:Indicator of Group Element|indicator]], $n$ is the least [[Definition:Strictly Positive Integer|(strictly) positive integer]] such that $a^n \in H$ Hence because $n > k \ge k - l$: :$k - l = 0$ Therefore $k = l$, and $x = y$. Therefore the elements $x a^k$ with $x \in H$ and $0 \le k < n$ are [[Definition:Distinct|distinct]]. So for each $x \in H$ there are $n$ elements of the form $x a^k$ in $K$. We have that there are $q$ elements in $H$. Thus it follows that there are $n q$ such [[Definition:Element|elements]]. By definition of $K$, these form all of $K$. Thus: :$\left\vert{K}\right\vert = n q$ as required {{qed}} [[Category:Subgroups]] ccxml4gy512g7balk0j604fvssw1m8y	0
=== Necessary Condition === Suppose $c \in \Z_{>0}$ is the [[Definition:Multiplicative Order of Integer|multiplicative order of $a$ modulo $n$]]. Then by definition: :$a^c \equiv 1 \pmod n$ Hence, by definition, $a^c = k n + 1$ for some $k \in \Z$. Thus: :$a r + n s = 1$ where $r = a^{c-1}$ and $s = -k$. It follows from [[Integer Combination of Coprime Integers]] that $a$ and $n$ are [[Definition:Coprime Integers|coprime]]. === Sufficient Condition === Suppose $a \perp n$. Then by [[Euler's Theorem]]: : $a^{\phi \left({n}\right)} \equiv 1 \pmod n$ where $\phi \left({n}\right)$ is the [[Definition:Euler Phi Function|Euler Phi Function]] of $n$. Hence the [[Definition:Multiplicative Order of Integer|multiplicative order of $a$ modulo $n$]] exists, by taking $c = \phi \left({n}\right)$. {{qed}} [[Category:Coprime Integers]] [[Category:Modulo Arithmetic]] ciiwxi45ftzbw816mx9aob2x1wfd3x4	0
Let $D_3$ denote the [[Definition:Symmetry Group of Equilateral Triangle|symmetry group of the equilateral triangle]]. Let $S_3$ denote the [[Symmetric Group on 3 Letters|symmetric group on $3$ letters]]. Then $D_3$ is [[Definition:Group Isomorphism|isomorphic]] to $S_3$.	0
{{ProofWanted}} [[Category:Integers]] 4lesc476t30awzjfte4szdcdh1hi33j	0
The [[Definition:Null Ring|null ring]], which contains one [[Definition:Element|element]], is ''not'' a [[Definition:Field (Abstract Algebra)|field]] as it is [[Definition:Null Ring|trivial]]. Therefore any [[Definition:Field (Abstract Algebra)|field]] must contain at least two [[Definition:Element|elements]]. For $\struct {\set {0_R, 1_R}, +, \circ}$ to be a [[Definition:Field (Abstract Algebra)|field]]: :$\struct {\set {0_R, 1_R}, +}$ must be an [[Definition:Abelian Group|abelian group]]. This is fulfilled as this is the [[Definition:Parity Group|parity group]]. :$\struct {\set {0_R, 1_R}, \circ}$ must be a [[Definition:Commutative Ring|commutative]] [[Definition:Division Ring|division ring]]. This is fulfilled, as $\struct {\set {0_R, 1_R}^*, \circ} = \struct {\set {1_R}, \circ}$ is the [[Definition:Trivial Group|trivial group]]. :$\circ$ needs to [[Definition:Distributive Operation|distribute]] over $+$. This follows directly from [[Ring Product with Zero]] and the behaviour of the [[Definition:Identity Element|identity element]] in a [[Definition:Group|group]]. {{qed}}	0
Let $x$ be a [[Definition:Rational Number|rational number]] such that $0 < x < \dfrac {\pi^2} 6 - 1$. Then $x$ can be expressed as the [[Definition:Rational Addition|sum]] of a [[Definition:Finite Set|finite number]] of [[Definition:Reciprocal|reciprocals]] of [[Definition:Distinct Objects|distinct]] [[Definition:Square Number|squares]].	0
Let $G$ be a [[Definition:Group|group]]. Then: :$G = \gen G$ where $\gen G$ denotes the [[Definition:Generator of Group|group generated]] by $G$.	0
The [[Definition:Sigma Function|sigma function]]: :$\displaystyle \sigma: \Z_{>0} \to \Z_{>0}: \sigma \left({n}\right) = \sum_{d \mathop \backslash n} d$ is [[Definition:Multiplicative Arithmetic Function|multiplicative]].	0
Let $n$ be an [[Definition:Integer|integer]] such that $n > 1$. Then $n$ can be expressed as the [[Definition:Integer Multiplication|product]] of one or more [[Definition:Prime Number|primes]].	0
Suppose $e_1$ and $e_2$ are both [[Definition:Identity Element|identity elements]] of $\struct {S, \circ}$. Then by the definition of [[Definition:Identity Element|identity element]]: :$\forall s \in S: s \circ e_1 = s = e_2 \circ s$ Then: :$e_1 = e_2 \circ e_1 = e_2$ So: :$e_1 = e_2$ and there is only one [[Definition:Identity Element|identity element]] after all. {{qed}}	0
Let $G$ be a [[Definition:Group|group]] whose [[Definition:Identity Element|identity]] is $e$. Then: : $\forall x \in G: \order x = \order {x^{-1} }$ where $\order x$ denotes the [[Definition:Order of Group Element|order]] of $x$.	0
By definition, $f$ is a [[Definition:Semigroup Homomorphism|semigroup homomorphism]] between [[Definition:Multiplicative Semigroup of Ring|multiplicative semigroups]]. A [[Definition:Unity of Ring|unity]] of a [[Definition:Ring (Abstract Algebra)|ring]] is by definition an [[Definition:Identity Element|identity element]] of its [[Definition:Multiplicative Semigroup of Ring|multiplicative semigroup]]. Thus the result follows from [[Epimorphism Preserves Identity]]. {{qed}} [[Category:Ring Epimorphisms]] 9nofbcnttzpsssgf79g3ug472j6fwcu	0
The [[Definition:Group Direct Product|group direct product]] of two [[Definition:Infinite Cyclic Group|infinite cyclic groups]] is not [[Definition:Cyclic Group|cyclic]].	0
A [[Definition:Ring Epimorphism|ring epimorphism]] is a [[Definition:Ring Homomorphism|ring homomorphism]] which is also a [[Definition:Surjection|surection]]. From [[Composition of Ring Homomorphisms is Ring Homomorphism]], $\psi \circ \phi$ is a [[Definition:Ring Homomorphism|ring homomorphism]]. From [[Composite of Surjections is Surjection]], $\psi \circ \phi$ is a [[Definition:Surjection|surection]]. {{qed}}	0
Follows from [[Regular Representations in Group are Permutations]]. Let $h \in H$. Then: : $\lambda_x \left({h}\right) = x h \in x H$ Thus: :$\forall h \in H: \lambda_x h \in x H$ demonstrating that $\lambda_x: H \to x H$ is a [[Definition:Mapping|mapping]]. A [[Definition:Permutation|permutation]] is a [[Definition:Bijection|bijection]] by definition, As [[Regular Representations in Group are Permutations]], it follows that $\lambda_x$ is a [[Definition:Bijection|bijection]]. {{qed}} Exactly the same argument applies to $\rho_x$. {{qed}}	0
Let $\sequence {y_n}$ be the [[Definition:Subsequence|subsequence]] of $\sequence {\norm {x_n}}$ defined by: :$\forall n: y_n =x_{N + n}$ The $\sequence {y_n}$ is the constant [[Definition:Sequence|sequence]] $\tuple {\lambda, \lambda, \lambda, \dotsc}$. Then: {{begin-eqn}} {{eqn | l = \displaystyle \lim_{n \mathop \to \infty} x_n | r = \displaystyle \lim_{n \mathop \to \infty} y_n | c = [[Limit of Subsequence equals Limit of Sequence in Normed Division Ring]] }} {{eqn | r = \lambda | c = [[Constant Sequence Converges to Constant in Normed Division Ring]] }} {{end-eqn}} {{qed}} [[Category:Sequences]] [[Category:Normed Division Rings]] ffxsfudtlibs04pt7ljl9sfyahebkvj	0
[[Proof by Counterexample]]: Consider the [[Definition:Symmetric Group|symmetric group]] $S_4$. Then the [[Definition:Order of Structure|order]] of the [[Definition:Alternating Group|alternating group]] $A_4$ is $12$. We list the [[Alternating Group on 4 Letters/Subgroups|subgroups of $A_4$]]: {{:Alternating Group on 4 Letters/Subgroups}} Now $6$ [[Definition:Divisor of Integer|divides]] $12$. But there is no [[Definition:Subgroup|subgroup]] of $A_4$ of [[Definition:Order of Structure|order]] $6$. {{qed}}	0
:$x^4 - y^4 = \paren {x - y} \paren {x + y} \paren {x^2 + y^2}$	0
Let $\map D n$ denote the [[Definition:Integer Multiplication|product]] of '''all''' the [[Definition:Divisor of Integer|divisors]] of $n$. From [[Product of Divisors]]: :$\map D n = n^{\map \tau n / 2}$ The [[Definition:Proper Divisor of Integer|proper divisors]] of $n$ are defined as being the [[Definition:Divisor of Integer|divisors]] of $n$ excluding $n$ itself. Thus: :$\map P n = \dfrac {\map D n} n = \dfrac {n^{\map \tau n / 2} } n = n^{\map \tau n / 2 - 1}$ {{qed}}	0
From [[Identity Element is Idempotent]]: :$e \circ e = e$ Hence the result by definition of [[Definition:Identity Element|identity element]]. {{qed}}	0
Note that, by [[Group Action determines Bijection|Group Action Determines Bijection]], $\phi_g \in \map \Gamma X$ for $g \in G$. Let $g, h \in G$. From the [[Definition:Group Action|definition of group action]]: :$\forall \tuple {g, x} \in G \times X: \map \phi {g, x} \in X = g \wedge x \in X$ First we show that for all $x \in X$: :$\map {\phi_g \circ \phi_h} x = \map {\phi_{g h} } x$ Thus: {{begin-eqn}} {{eqn | l = \map {\phi_g \circ \phi_h} x | r = g \wedge \paren {h \wedge x} | c = Definition of $\phi_g$, $\phi_h$ }} {{eqn | r = \paren {g h} \wedge x | c = {{Defof|Group Action}} }} {{eqn | r = \map {\phi_{g h} } x | c = Definition of $\phi_{g h}$ }} {{end-eqn}} Also, we have: : $e \wedge x = x \implies \map {\phi_e} x = x$ where $e$ is the [[Definition:Identity Element|identity]] of $G$. Therefore, we have shown that $\tilde \phi: G \to \map \Gamma X: g \mapsto \phi_g$ is a [[Definition:Group Homomorphism|group homomorphism]]. {{qed}}	0
Consider the [[Definition:Relation|relation]] $\mathcal R \subseteq G \times G$ defined as: :$\forall g, h \in G: \tuple {g, h} \in \mathcal R \iff \exists g \in X$ Then: :$\forall S \subseteq G: X \circ S = \map {\mathcal R} S$ Then: {{begin-eqn}} {{eqn | l = X \circ \paren {Y \cup Z} | r = \map {\mathcal R} {Y \cup Z} | c = }} {{eqn | r = \map {\mathcal R} y \cup \map {\mathcal R} Z | c = [[Image of Union under Relation]] }} {{eqn | r = \paren {X \circ Y} \cup \paren {X \circ Z} | c = }} {{end-eqn}} Next, consider the [[Definition:Relation|relation]] $\mathcal R \subseteq G \times G$ defined as: :$\forall g, h \in G: \tuple {g, h} \in \mathcal R \iff \exists h \in X$ Then: :$\forall S \subseteq G: S \circ X = \map {\mathcal R} S$ Then: {{begin-eqn}} {{eqn | l = \paren {Y \cup Z} \circ X | r = \map {\mathcal R} {Y \cup Z} | c = }} {{eqn | r = \map {\mathcal R} Y \cup \map {\mathcal R} Z | c = [[Image of Union under Relation]] }} {{eqn | r = \paren {Y \circ X} \cup \paren {Z \circ X} | c = }} {{end-eqn}} {{qed}}	0
Let $\struct {F, +, \times}$ be a [[Definition:Field (Abstract Algebra)|field]] whose [[Definition:Field Zero|zero]] is $0$. Let $\struct {K, +, \times}$ be a [[Definition:Subfield|subfield]] of $\struct {F, +, \times}$. {{:Zero of Subfield is Zero of Field}}	0
=== Necessary Condition === Let $H$ be a [[Definition:Subset|subset]] of $G$ that fulfils the conditions given. It is noted that the fact that $H$ is [[Definition:Non-Empty Set|nonempty]] is one of the conditions. It is also noted that the [[Definition:Group Operation|group operation]] of $\struct {H, \circ}$ is the same as that for $\struct {G, \circ}$, that is, $\circ$. So it remains to show that $\struct {H, \circ}$ is a [[Definition:Group|group]]. We check the four [[Definition:Group Axioms|group axioms]]: ==== $\text G 0$: Closure ==== The [[Definition:Closed Algebraic Structure|closure]] condition is given by condition $(2)$. {{qed|lemma}} ==== $\text G 1$: Associativity ==== From [[Closed Substructure of Semigroup is Semigroup]], [[Definition:Associative Operation|associativity]] is inherited by $\struct {H, \circ}$ from $\struct {G, \circ}$. {{qed|lemma}} ==== $\text G 2$: Identity ==== Let $e$ be the [[Definition:Identity Element|identity]] of $\struct {G, \circ}$. From condition $(1)$, $H$ is [[Definition:Non-Empty Set|non-empty]]. Therefore $\exists x \in H$. From condition $(3)$, $\struct {H, \circ}$ is [[Definition:Closed under Inversion|closed under inversion]]. Therefore $x^{-1} \in H$. Since $\struct {H, \circ}$ is [[Definition:Closed Algebraic Structure|closed]] under $\circ$, $x \circ x^{-1} = e = x^{-1} \circ x \in H$. {{qed|lemma}} ==== $\text G 3$: Inverses ==== From condition $(3)$, every element of $H$ has an [[Definition:Inverse Element|inverse]]. {{qed|lemma}} So $\struct {H, \circ}$ satisfies all the [[Definition:Group Axioms|group axioms]], and is therefore a [[Definition:Group|group]]. So by definition $\struct {H, \circ}$ is a [[Definition:Subgroup|subgroup]] of $\struct {G, \circ}$. {{qed|lemma}} === Sufficient Condition === Now suppose $\struct {H, \circ}$ is a [[Definition:Subgroup|subgroup]] of $\struct {G, \circ}$. :$(1): \quad H \le G \implies H \ne \O$ from the fact that $H$ is a [[Definition:Group|group]] and therefore [[Group is not Empty|can not be empty]]. :$(2): \quad a, b \in H \implies a \circ b \in H$ follows from {{GroupAxiom|0}} as applied to the [[Definition:Group|group]] $\struct {H, \circ}$. :$(3): \quad a \in H \implies a^{-1} \in H$ follows from {{GroupAxiom|3}} as applied to the [[Definition:Group|group]] $\struct {H, \circ}$. {{qed}}	0
Let $A, B$ be two [[Definition:Natural Number|numbers]] which are [[Definition:Coprime Integers|prime to one another]]. Let $C$ be any [[Definition:Natural Number|number]] greater than $1$ which [[Definition:Divisor of Integer|measures]] $A$. :[[File:Euclid-VII-23.png|250px]] Suppose $C$ and $B$ are not [[Definition:Coprime Integers|prime to one another]]. Then some [[Definition:Natural Number|number]] $D$ will [[Definition:Divisor of Integer|measure]] them both. We have that $D$ [[Definition:Divisor of Integer|measures]] $C$ and $C$ [[Definition:Divisor of Integer|measures]] $A$. So $D$ [[Definition:Divisor of Integer|measures]] $A$. But $D$ also [[Definition:Divisor of Integer|measures]] $B$. So $D$ [[Definition:Divisor of Integer|measures]] $A$ and $B$ which are [[Definition:Coprime Integers|prime to one another]]. By {{EuclidDefLink|VII|12|Relatively Prime}}, this is a [[Proof by Contradiction|contradiction]]. Therefore there can be no such $D$ that [[Definition:Divisor of Integer|measures]] both $B$ and $C$. That is, $B$ and $C$ are [[Definition:Coprime Integers|prime to one another]]. {{qed}}	0
Let $x \in \R_{\ne 0}$. Then either $x > 0$ or $x < 0$. Let $x > 0$. Then: {{begin-eqn}} {{eqn | l = \frac x {\left\vert{x}\right\vert} | r = \frac x x | c = Definition of [[Definition:Absolute Value|Absolute Value]], as $x > 0$ }} {{eqn | r = 1 | c = }} {{eqn | r = \operatorname{sgn} \left({x}\right) | c = Definition of [[Definition:Signum Function|Signum Function]], as $x > 0$ }} {{end-eqn}} Similarly: {{begin-eqn}} {{eqn | l = \frac {\left\vert{x}\right\vert} x | r = \frac x x | c = Definition of [[Definition:Absolute Value|Absolute Value]], as $x > 0$ }} {{eqn | r = 1 | c = }} {{eqn | r = \operatorname{sgn} \left({x}\right) | c = Definition of [[Definition:Signum Function|Signum Function]], as $x > 0$ }} {{end-eqn}} {{qed|lemma}} Let $x < 0$. Then: {{begin-eqn}} {{eqn | l = \frac x {\left\vert{x}\right\vert} | r = \frac x {-x} | c = Definition of [[Definition:Absolute Value|Absolute Value]], as $x < 0$ }} {{eqn | r = -1 | c = }} {{eqn | r = \operatorname{sgn} \left({x}\right) | c = Definition of [[Definition:Signum Function|Signum Function]], as $x < 0$ }} {{end-eqn}} Similarly: {{begin-eqn}} {{eqn | l = \frac {\left\vert{x}\right\vert} x | r = \frac {-x} x | c = Definition of [[Definition:Absolute Value|Absolute Value]], as $x < 0$ }} {{eqn | r = -1 | c = }} {{eqn | r = \operatorname{sgn} \left({x}\right) | c = Definition of [[Definition:Signum Function|Signum Function]], as $x < 0$ }} {{end-eqn}} {{qed}} [[Category:Signum Function]] [[Category:Absolute Value Function]] ijvb82dxkam36lfkeikjdgawoymdy7y	0
If $R$ has a nontrivial decomposition $R = R_1 \times R_2$ then $\tuple {1_R, 0_R}$ is a non-trivial idempotent element of $R$. {{explain|non-trivial decomposition, non-trivial element}} Conversely suppose there is $0_R, 1_R \ne e \in R$ with $e^2 = e$. Let $R_1 = \ideal e$, the [[Definition:Ideal of Ring|ideal]] [[Definition:Generator|generated]] by $e$, and $R_2 = R / \ideal e$. Since $e \paren {e - 1_R} = 0_R$, it follows by definition that $e$ is a [[Definition:Zero Divisor of Ring|zero divisor]]. So by [[Unit Not Zero Divisor]] it is not a [[Definition:Unit of Ring|unit]]. Therefore, $1 \notin R_1$ and $\ideal e \subsetneqq R$. Also $R_1 \cap R_2 = \set {0_R}$ so the product is direct (that is, the [[Universal Property for Direct Products]] is satisfied). Finally we define the "gluing [[Definition:Ring Homomorphism|homomorphism]]" $\phi : R \to R_1 \times R_2$ by :$\phi: a \mapsto \tuple {a e, a + \ideal e}$ which is easily shown to be an [[Definition:Ring Isomorphism|isomorphism]]. {{qed}} [[Category:Commutative Algebra]] fh03qu2of6klj77b3msijjski733boh	0
Let $\mathbf 1, \mathbf i, \mathbf j, \mathbf k$ denote the following four [[Definition:Element|elements]] of the [[Definition:Matrix Space|matrix space]] $\map {\mathcal M_\C} 2$: :$\mathbf 1 = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} \qquad \mathbf i = \begin{bmatrix} i & 0 \\ 0 & -i \end{bmatrix} \qquad \mathbf j = \begin{bmatrix} 0 & 1 \\ -1 & 0 \end{bmatrix} \qquad \mathbf k = \begin{bmatrix} 0 & i \\ i & 0 \end{bmatrix} $ where $\C$ is the set of [[Definition:Complex Number|complex numbers]]. Then $\mathbf 1, \mathbf i, \mathbf j, \mathbf k$ are related to each other in the following way: {{begin-eqn}} {{eqn | l = \mathbf i \mathbf j = - \mathbf j \mathbf i | r = \mathbf k }} {{eqn | l = \mathbf j \mathbf k = - \mathbf k \mathbf j | r = \mathbf i }} {{eqn | l = \mathbf k \mathbf i = - \mathbf i \mathbf k | r = \mathbf j }} {{eqn | l = \mathbf i^2 = \mathbf j^2 = \mathbf k^2 = \mathbf i \mathbf j \mathbf k | r = -\mathbf 1 }} {{end-eqn}}	0
Let $G$ be an [[Definition:Dimension (Linear Algebra)|$n$-dimensional]] [[Definition:Module|$R$-module]]. Let $G^*$ be the [[Definition:Algebraic Dual|algebraic dual]] of $G$. Let $G^{**}$ be the [[Definition:Algebraic Dual|algebraic dual]] of $G^*$. Then $G^*$ and $G^{**}$ are also [[Definition:Dimension (Linear Algebra)|$n$-dimensional]].	0
Let $\mathbf A = \sqbrk a_n$ be a [[Definition:Square Matrix|square matrix]] of [[Definition:Order of Square Matrix|order $n$]]. Let $\mathbf C$ be its [[Definition:Cofactor Matrix|cofactor matrix]]. The '''adjugate matrix''' of $\mathbf A$ is the [[Definition:Transpose of Matrix|transpose]] of $\mathbf C$: :$\adj {\mathbf A} = \mathbf C^\intercal$	0
Given $\epsilon > 0$: By the definition of a [[Definition:Cauchy Sequence in Normed Division Ring|Cauchy sequence]] then: :$\exists N': \forall n, m > N', \norm {y_n - y_m} < \epsilon$ Hence $\forall n, m > \paren {N' + N}$: {{begin-eqn}} {{eqn | l = \norm {x_n - x_m } | r = \norm {y_{n - N} - y_{m - N} } | c = $n, m > N$ }} {{eqn | o = < | r = \epsilon | c = $n - N, m - N > N'$ }} {{end-eqn}} The result follows. {{qed}}	0
Let $V$ be a [[Definition:Vector Space|vector space]]. Let $\BB = \tuple {\mathbf e_1, \mathbf e_2, \ldots, \mathbf e_n}$ be a [[Definition:Basis of Vector Space|basis of $V$]]. Then $\BB$ is an '''orthogonal basis''' {{iff}} $\mathbf e_1, \mathbf e_2, \ldots, \mathbf e_n$ are [[Definition:Pairwise Perpendicular|pairwise perpendicular]].	0
Let $z = a + i b \in \C$ be a [[Definition:Complex Number|complex number]]. Let $\overline z$ denote the [[Definition:Complex Conjugate|complex conjugate]] of $z$. Then: :$z \overline z = a^2 + b^2 = \cmod z^2$ and thus is [[Definition:Wholly Real|wholly real]].	0
By definition: :$\mathbf I_n := \sqbrk a_n: a_{i j} = \delta_{i j}$ That is: each of the elements on the [[Definition:Main Diagonal|main diagonal]] is equal to $1$. There are $n$ such elements. Hence the result. {{qed}}	0
By [[P-adic Norm not Complete on Rational Numbers]], no [[Definition:P-adic Norm|$p$-adic norm]] $\norm{\,\cdot\,}_p$ on the [[Definition:Set|set]] of the [[Definition:Rational Number|rational numbers]], for any [[Definition:Prime Number|prime]] $p$, is [[Definition:Complete Normed Division Ring|complete]]. By [[Rational Number Space is not Complete Metric Space]], the [[Definition:Absolute Value|absolute value]] $\size{\,\cdot\,}$ on the [[Definition:Set|set]] of the [[Definition:Rational Number|rational numbers]] is not [[Definition:Complete Normed Division Ring|complete]]. By [[Norm is Complete Iff Equivalent Norm is Complete]], no [[Definition:Norm on Division Ring|norm]] is [[Definition:Complete Normed Division Ring|complete]] if it is [[Definition:Equivalent Division Ring Norms|equivalent]] to either the [[Definition:Absolute Value|absolute value]] $\size{\,\cdot\,}$ or the [[Definition:P-adic Norm|$p$-adic norm]] $\norm{\,\cdot\,}_p$ for some [[Definition:Prime Number|prime]] $p$. By [[Ostrowski's Theorem]], every [[Definition:Nontrivial Division Ring Norm|non-trivial]] [[Definition:Norm on Division Ring|norm]] is [[Definition:Equivalent Division Ring Norms|equivalent]] to either the [[Definition:Absolute Value|absolute value]] $\size{\,\cdot\,}$ or the [[Definition:P-adic Norm|$p$-adic norm]] $\norm{\,\cdot\,}_p$ for some [[Definition:Prime Number|prime]] $p$. The result follows. {{qed}}	0
The [[Definition:Closure (Topology)|closure]] of the set $S$ (trivially) equals $S$. That is, $S$ is [[Definition:Everywhere Dense|everywhere dense]] in $T$. But as $S$ is [[Definition:Countable Set|countable]] it follows by definition that $T$ is [[Definition:Separable Space|separable]]. {{qed}}	0
The [[Cauchy-Binet Formula]] gives: :$\displaystyle \det \left({\mathbf A \mathbf B}\right) = \sum_{1 \mathop \le j_1 \mathop < j_2 \mathop < \cdots \mathop < j_m \le n} \det \left({\mathbf A_{j_1 j_2 \ldots j_m}}\right) \det \left({\mathbf B_{j_1 j_2 \ldots j_m}}\right)$ where: :$\mathbf A$ is an [[Definition:Matrix|$m \times n$ matrix]] :$\mathbf B$ is an [[Definition:Matrix|$n \times m$ matrix]]. :For $1 \le j_1, j_2, \ldots, j_m \le n$: ::$\mathbf A_{j_1 j_2 \ldots j_m}$ denotes the [[Definition:Matrix|$m \times m$ matrix]] consisting of [[Definition:Column of Matrix|columns]] $j_1, j_2, \ldots, j_m$ of $\mathbf A$. ::$\mathbf B_{j_1 j_2 \ldots j_m}$ denotes the [[Definition:Matrix|$m \times m$ matrix]] consisting of [[Definition:Row of Matrix|rows]] $j_1, j_2, \ldots, j_m$ of $\mathbf B$. From the definition of [[Definition:Transpose of Matrix|transpose]] $\mathbf A^\intercal$ is an [[Definition:Matrix|$n \times m$ matrix]]. Hence the [[Cauchy-Binet Formula]] can be applied directly: :$\displaystyle \det \left({\mathbf A \mathbf A^\intercal}\right) = \sum_{1 \mathop \le j_1 \mathop < j_2 \mathop < \cdots \mathop < j_m \le n} \det \left({\mathbf A_{j_1 j_2 \ldots j_m} }\right) \det \left({\mathbf A^\intercal_{j_1 j_2 \ldots j_m} }\right)$ Note that by construction: :$\mathbf A_{j_1 j_2 \ldots j_m}$ is a [[Definition:Square Matrix|square matrix]] Also, by definition of [[Definition:Transpose of Matrix|transpose]]: :$\mathbf A^\intercal_{j_1 j_2 \ldots j_m} = \left({\mathbf A_{j_1 j_2 \ldots j_m} }\right)^\intercal$ The result follows from [[Determinant of Transpose]]: :$\det \left({\mathbf A}\right) = \det \left({\mathbf A^\intercal}\right)$ {{qed}}	0
Let $H$ be a [[Definition:Hilbert Space|Hilbert space]] over $\Bbb F \in \left\{{\R, \C}\right\}$. Let $A \in B \left({H}\right)$ be a [[Definition:Normal Operator|normal operator]]. Let $\lambda \in \Bbb F$. Then $\ker \left({A - \lambda}\right)$ is a [[Definition:Reducing Subspace|reducing subspace]] for $A$. Here $\ker$ denotes [[Definition:Kernel of Linear Transformation|kernel]].	0
Let $x \in R$ and $\epsilon \in \R_{\gt 0}$ Then for $y \in R$: {{begin-eqn}} {{eqn | l = \norm {y - x}_1 < \epsilon | o = \leadstoandfrom | r = \norm {y - x}_2^\alpha < \epsilon }} {{eqn | o = \leadstoandfrom | r = \norm {y - x}_2 < \epsilon^{1 / \alpha} }} {{end-eqn}} Hence: :$\map {B^1_\epsilon} x = \map {B^2_{\epsilon^{1 / \alpha} } } x$ where: :$\map {B^1_\epsilon} x$ is the [[Definition:Open Ball|open ball]] in $d_1$ [[Definition:Center of Open Ball|centered]] on $x$ with [[Definition:Radius of Open Ball|radius]] $\epsilon$ :$\map {B^2_{\epsilon^{1 / \alpha} } } x$ is the [[Definition:Open Ball|open ball]] in $d_2$ [[Definition:Center of Open Ball|centered]] on $x$ with [[Definition:Radius of Open Ball|radius]] $\epsilon^{1 / \alpha}$ Since $x$ and $\epsilon$ were arbitrary then: :every [[Definition:Open Ball|$d_1$-open ball]] is a [[Definition:Open Ball|$d_2$-open ball]]. Similarly, for $y \in R$: {{begin-eqn}} {{eqn | l = \norm {y - x}_2 < \epsilon | o = \leadstoandfrom | r = \norm {y - x}_2^\alpha < \epsilon^\alpha }} {{eqn | o = \leadstoandfrom | r = \norm {y - x}_1 < \epsilon^\alpha }} {{end-eqn}} So: :every [[Definition:Open Ball|$d_2$-open ball]] is a [[Definition:Open Ball|$d_1$-open ball]]. By the definition of an [[Definition:Open Set of Metric Space|open set of a metric space]] it follows that $d_1$ and $d_2$ are [[Definition:Topologically Equivalent Metrics|topologically equivalent metrics]], {{qed}}	0
Let $z_1$ and $z_2$ be represented by the [[Definition:Point|points]] $A = \tuple {x_1, y_1}$ and $B = \tuple {x_2, y_2}$ respectively in the [[Definition:Complex Plane|complex plane]]. Let $z$ be an arbitrary [[Definition:Point|point]] on $L$ represented by the [[Definition:Point|point]] $P$. :[[File:Perpendicular Bisector of Two Points in Complex Plane.png|400px]] We have that $L$ passes through the [[Definition:Point|point]]: :$\dfrac {z_1 + z_2} 2$ and is [[Definition:Perpendicular|perpendicular]] to the [[Definition:Straight Line|straight line]]: :$z = z_1 + t \paren {z_2 - z_1}$ {{ProofWanted}} [[Category:Equation for Perpendicular Bisector of Two Points in Complex Plane]] azrcyl0u9al6hkpf7oqidu3zb161zkd	0
Let $G$ be an [[Definition:Module|$R$-module]]. Let $\sequence {a_k}_{1 \mathop \le k \mathop \le n}$ be a [[Definition:Sequence|sequence of elements]] of $G$. Let $b$ be an [[Definition:Element|element]] of $G$. Then: :$b$ is a [[Definition:Linear Combination of Sequence|linear combination]] of the [[Definition:Finite Sequence|sequence]] $\sequence {a_k}_{1 \mathop \le k \mathop \le n}$ {{iff}}: :$b$ is a [[Definition:Linear Combination of Subset|linear combination]] of the [[Definition:Set|set]] $\set {a_k: 1 \mathop \le k \mathop \le n}$	0
This is a special case of a [[Definition:Direct Product of Vector Spaces|direct product of vector spaces]] where each of the $G_k$ is the [[Definition:Vector Space|$K$-vector space]] $K$. {{qed}}	0
=== Definition 1 equivalent to Definition 3 === {{begin-eqn}} {{eqn | o = | r = \map \Re {\overline {z_1} z_2} | c = {{Defof|Dot Product|subdef = Complex|index = 3}} }} {{eqn | r = \map \Re {\paren {x_1 - i y_1} {x_2 + i y_2} } | c = {{Defof|Complex Conjugate}} }} {{eqn | r = \map \Re {\paren {x_1 x_2 + y_1 y_2} + i \paren {x_1 y_2 - x_2 y_1} } | c = {{Defof|Complex Multiplication}} }} {{eqn | r = x_1 x_2 + y_1 y_2 | c = {{Defof|Real Part}} }} {{end-eqn}} {{qed|lemma}} === Definition 2 equivalent to Definition 3 === {{begin-eqn}} {{eqn | o = | r = \map \Re {\overline {z_1} z_2} | c = {{Defof|Dot Product|subdef = Complex|index = 3}} }} {{eqn | r = r_1 r_2 \map \cos {\theta_2 - \theta_1} | c = [[Complex Dot Product in Exponential Form]] }} {{eqn | r = \cmod {z_1} \, \cmod {z_2} \map \cos {\theta_2 - \theta_1} | c = {{Defof|Polar Form of Complex Number}} }} {{eqn | r = \cmod {z_1} \, \cmod {z_2} \cos \theta | c = where $\theta = \theta_2 - \theta_1$ is the angle between $z_1$ and $z_2$ }} {{end-eqn}} {{qed|lemma}} === Definition 1 equivalent to Definition 4 === {{begin-eqn}} {{eqn | o = | r = \frac {\overline {z_1} z_2 + z_1 \overline {z_2} } 2 | c = {{Defof|Dot Product|subdef = Complex|index = 4}} }} {{eqn | r = \frac {\paren {x_1 - i y_1} \paren {x_2 + i y_2} + \paren {x_1 + i y_1} \paren {x_2 - i y_2} } 2 | c = {{Defof|Complex Conjugate}} }} {{eqn | r = \frac {\paren {\paren {x_1 x_2 + y_1 y_2} + i \paren {x_1 y_2 - x_2 y_1} } + \paren {\paren {x_1 x_2 + y_1 y_2} + i \paren {-x_1 y_2 + x_2 y_1} } } 2 | c = {{Defof|Complex Multiplication}} }} {{eqn | r = x_1 x_2 + y_1 y_2 | c = after algebra }} {{end-eqn}} {{qed}}	0
By definition, an [[Definition:Open Set in Normed Vector Space|open set]] $S \subseteq X$ is one where every [[Definition:Point|point]] inside it is an [[Definition:Element|element]] of an [[Definition:Open Ball|open ball]] contained entirely within that [[Definition:Set|set]]. That is, there are no [[Definition:Point|points]] in $S$ which have an [[Definition:Open Ball in Normed Vector Space|open ball]] some of whose [[Definition:Element|elements]] are not in $S$. As there are no [[Definition:Element|elements]] in $\O$, the result follows [[Definition:Vacuous Truth|vacuously]]. {{qed}}	0
From [[Change of Basis is Invertible]], if $\left \langle {b_n} \right \rangle$ is an [[Definition:Ordered Basis|ordered basis]] of $G$ then $\mathbf P$ is [[Definition:Invertible Matrix|invertible]]. Now let $\mathbf P$ be [[Definition:Invertible Matrix|invertible]]. Then by [[Linear Transformations Isomorphic to Matrix Space/Corollary|the corollary to Linear Transformations Isomorphic to Matrix Space]], there is an [[Definition:Module Automorphism|automorphism]] $u$ of $G$ which satisfies $\mathbf P = \left[{u; \left \langle {a_n} \right \rangle}\right]$. Therefore, as $\forall j \in \left[{1 \,.\,.\, n}\right]: b_j = u \left({a_j}\right)$, it follows that $\left \langle {b_n} \right \rangle$ is also an ordered basis of $G$. {{Qed}}	0
Let $A$ be a [[Definition:Commutative and Unitary Ring|commutative ring with unity]]. Let $M$ be a [[Definition:Finitely Generated Module|finitely generated]] [[Definition:Module|$A$-module]]. Let $\mathfrak a$ be an [[Definition:Ideal of Ring|ideal]] of $A$. Let $\phi$ be an [[Definition:Endomorphism|endomorphism]] of $M$ such that $\phi \left({M}\right) \subseteq \mathfrak a M$. Then $\phi$ satisfies an equation of the form: :$\phi^n + a_{n-1} \phi^{n-1} + \cdots + a_1 \phi + a_0 = 0$ with the $a_i \in \mathfrak a$.	0
Let: {{begin-eqn}} {{eqn | l = \prod_{k \mathop = 1}^n \paren {x - x_k} | r = a_nx^n + \sum_{m \mathop = 0}^{n-1} a_m x^m | c = Polynomial expansion in powers of $x$ }} {{eqn | r = x^n + \sum_{m \mathop = 0}^{n - 1} \paren {-1}^{n - m} \map {e_{n-m} } {x_1, \ldots, x_n} \, x^m | c = [[Viete's Formulas]] and {{Defof|Elementary Symmetric Function}} }} {{eqn | l = W_n | r = \begin{bmatrix} 1 & x_1 & \cdots & x_1^{n-1} \\ 1 & x_2 & \cdots & x_2^{n-1} \\ \vdots & \vdots & \ddots & \vdots \\ 1 & x_1^{n-1} & \cdots & x_n^{n-1} \\ \end{bmatrix} | c = {{Defof|Vandermonde Matrix}} of [[Definition:Order of Square Matrix|Order $n$]] }} {{end-eqn}} Let $W_n$ have a [[Definition:Inverse Matrix|matrix inverse]] $W_n^{-1} = \begin {bmatrix} d_{ij} \end {bmatrix}$. Let $a_n = \map {e_0} {x_1, \ldots, x_n} = 1$. Then: {{begin-eqn}} {{eqn | n = 1 | l = d_{ij} | r = \dfrac {\displaystyle \sum_{k \mathop = 0}^{n - i} a_{i + k} \, x_j^k} {\displaystyle \prod_{m \mathop = 1, m \mathop \ne j }^n \paren {x_j - x_m} } | c = for $i, j = 1, \ldots, n$ }} {{eqn | r = \dfrac {\displaystyle \sum_{k \mathop = 0}^{n - i} \paren {-1}^{n - i - k} \map {e_{n - i - k} } {x_1, \ldots, x_n} \, x_j^k} {\displaystyle \prod_{m \mathop = 1, m \mathop \ne j }^n \paren {x_j - x_m} } | c = for $i, j = 1, \ldots, n$ }} {{end-eqn}}	0
Let $T = \struct {S, \tau_p}$ be a [[Definition:Fort Space|Fort space]] on an [[Definition:Uncountable Set|uncountable set]] $S$. Then $T$ is not a [[Definition:Separable Space|separable space]].	0
This follows by [[Principle of Mathematical Induction|induction]] from {{Module-axiom|2}}, as follows. For all $m \in \N_{>0}$, let $\map P m$ be the [[Definition:Proposition|proposition]]: :$\ds \paren {\sum_{k \mathop = 1}^m \lambda_k} \circ x = \sum_{k \mathop = 1}^m \paren {\lambda_k \circ x}$ === Basis for the Induction === $\map P 1$ is true, as this just says: :$\lambda_1 \circ x = \lambda_1 \circ x$ This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P n$ is true, where $n \ge 1$, then it logically follows that $\map P {n + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\ds \paren {\sum_{k \mathop = 1}^n \lambda_k} \circ x = \sum_{k \mathop = 1}^n \paren {\lambda_k \circ x}$ Then we need to show: :$\ds \paren {\sum_{k \mathop = 1}^{n + 1} \lambda_k} \circ x = \sum_{k \mathop = 1}^{n + 1} \paren {\lambda_k \circ x}$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \paren {\sum_{k \mathop = 1}^{n + 1} \lambda_k} \circ x | r = \paren {\sum_{k \mathop = 1}^n \lambda_k + \lambda_{n + 1} } \circ x | c = }} {{eqn | r = \paren {\sum_{k \mathop = 1}^n \lambda_k \circ x} + \lambda_{n + 1} \circ x | c = {{Module-axiom|2}} }} {{eqn | r = \sum_{k \mathop = 1}^n \paren {\lambda_k \circ x} + \lambda_{n + 1} \circ x | c = [[Product with Sum of Scalar#Induction Hypothesis|Induction hypothesis]] }} {{eqn | r = \sum_{k \mathop = 1}^{n + 1} \paren {\lambda_k \circ x} | c = }} {{end-eqn}} So $\map P n \implies \map P {n + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\ds \forall m \in \N_{>0}: \paren {\sum_{k \mathop = 1}^m \lambda_k} \circ x = \sum_{k \mathop = 1}^m \paren {\lambda_k \circ x}$ {{qed}}	0
From [[Scalar Product with Identity]], $\forall \lambda: \lambda \circ e = e$. Let $H \subseteq G$ such that $e \in H$. Consider any [[Definition:Sequence|sequence]] $\sequence {a_k}_{1 \mathop \le k \mathop \le n}$ in $H$ which includes $e$. So, let $a_j = e$ for some $j \in \closedint 1 n$. Let $c \in R \ne 0_R$. Consider the [[Definition:Sequence|sequence]] $\sequence {\lambda_k}_{1 \mathop \le k \mathop \le n}$ of [[Definition:Element|elements]] of $R$ defined as: :$\lambda_k = \begin{cases} c & : k \ne j \\ 0_R & : k= j \end{cases}$ Then: {{begin-eqn}} {{eqn | l = \sum_{k \mathop = 1}^n \lambda_k \circ a_k | r = \lambda_1 \circ a_1 + \lambda_2 \circ a_2 + \cdots + \lambda_j \circ a_j + \cdots + \lambda_n \circ a_n | c = }} {{eqn | r = 0_R \circ a_1 + 0_R \circ a_2 + \cdots + c \circ e + \cdots + 0_R \circ a_n | c = }} {{eqn | r = e + e + \cdots + e + \cdots + e | c = }} {{eqn | r = e | c = }} {{end-eqn}} Thus there exists a [[Definition:Sequence|sequence]] $\sequence {\lambda_k}_{1 \mathop \le k \mathop \le n}$ in which not all $\lambda_k = 0_R$ such that: :$\displaystyle \sum_{k \mathop = 1}^n \lambda_k \circ a_k = e$ Hence the result. {{qed}}	0
{{begin-eqn}} {{eqn | l = y | r = u \circ x | c = }} {{eqn | ll= \leadstoandfrom | l = x | r = u^{-1} \circ y | c = {{Defof|Unit of Ring}} }} {{end-eqn}} By the definition of [[Definition:Divisor of Ring Element|divisor]]: :$x \divides y$ and $y \divides x$ {{qed|lemma}} Let $x \divides y$ and $y \divides x$. Then $\exists s, t \in D$ such that: :$(1): \quad y = t \circ x$ and: :$(2): \quad x = s \circ y$ If either $x = 0_D$ or $y = 0_D$, then so must be the other (as an [[Definition:Integral Domain|integral domain]] has no [[Definition:Zero Divisor of Ring|zero divisors]] by definition). So $x = 1_D \circ y$ and $y = 1_D \circ x$, and the result holds. Otherwise: {{begin-eqn}} {{eqn | l = 1_D \circ x | r = x | c = {{Defof|Unity of Ring}} }} {{eqn | r = s \circ y | c = from $(2)$ }} {{eqn | r = s \circ \paren {t \circ x} | c = from $(1)$ }} {{eqn | r = \paren {s \circ t} \circ x | c = {{Defof|Associative Operation}} }} {{end-eqn}} So: :$s \circ t = 1_D$ and both $s \in U_D$ and $t \in U_D$. The result follows. {{qed}}	0
Let $x, y \in S$. Let $\lambda \in R$. Then: {{begin-eqn}} {{eqn | l = \map \phi {x + y} | r = \map \phi x + \map \phi y | c = {{Defof|Linear Transformation}} }} {{eqn | r = \map \psi x + \map \psi y | c = $x, y \in S$ }} {{eqn | r = \map \psi {x + y} | c = {{Defof|Linear Transformation}} }} {{eqn | l = \map \phi {\lambda \circ x} | r = \lambda \circ \map \phi x | c = {{Defof|Linear Transformation}} }} {{eqn | r = \lambda \circ \map \psi x | c = $x \in S$ }} {{eqn | r = \map \psi {\lambda \circ x} | c = {{Defof|Linear Transformation}} }} {{end-eqn}} Hence $x + y, \lambda \circ x \in S$. By [[Submodule Test]], $S$ is a [[Definition:Submodule|submodule]] of $G$. {{qed}}	0
Let $M$ be a [[Definition:Unitary Module|unitary $R$-module]]. Let $S = \left\langle{m_i}\right\rangle_{i \mathop \in I}$ be a [[Definition:Indexed Family|family]] of [[Definition:Element|elements]] of $M$. Let $\Psi: R^{\left({I}\right)} \to M$ be the morphism given by [[Universal Property of Free Module Indexed by Set]]. Then $S$ is a [[Definition:Spanning Set|spanning set]] of $M$ {{iff}} $\Psi$ is [[Definition:Surjection|surjective]].	0
Let $x \in R_2$. By definition of the [[Definition:Completion (Normed Division Ring)|completion]] $\struct {R_2, \norm {\, \cdot \,}_2 }$: :$\map {\phi^\to} {R_1}$ is a [[Definition:Everywhere Dense |dense subset]] of $\struct {R_2, \norm {\, \cdot \,}_2 }$. By the definition of a [[Definition:Everywhere Dense|dense subset]]: :$\map \cl {\map {\phi^\to} {R_1}} = R_2$ By [[Closure of Subset of Metric Space by Convergent Sequence]]: :there exists a [[Definition:Sequence|sequence]] $\sequence {y_n} \subseteq \map {\phi^\to} {R_1}$ that [[Definition:Convergent Sequence in Normed Division Ring|converges]] to $x$ That is: :$\displaystyle \lim_{n \mathop \to \infty} y_n = x$ From [[Injection to Image is Bijection]], we can define: :$\forall n \in \N : x_n = \map {\phi^{-1}} {y_n}$ Then $\sequence{x_n}$ is a [[Definition:Sequence|sequence]] in $R_1$: :$\displaystyle \lim_{n \mathop \to \infty} \map \phi {x_n} = \lim_{n \mathop \to \infty} y_n = x$ {{qed}} [[Category:Completion of Normed Division Ring]] 618jsapz7vqhlo8rv16ux84u37xkck8	0
=== [[Definition:Closure (Abstract Algebra)/Algebraic Structure|Algebraic Structures]] === {{:Definition:Closure (Abstract Algebra)/Algebraic Structure}} === [[Definition:Closure (Abstract Algebra)/Scalar Product|Scalar Product]] === {{:Definition:Closure (Abstract Algebra)/Scalar Product}} [[Category:Definitions/Abstract Algebra]] [[Category:Definitions/Linear Algebra]] cx9tvgqnuptsin06zh38wl1671k2lmh	0
Let $M = \struct{X, \norm {\, \cdot \,}}$ be a [[Definition:Normed Vector Space|normed vector space]]. Then the [[Definition:Set|set]] $X$ is an [[Definition:Open Set in Normed Vector Space|open set]] of $M$.	0
Let $\sequence {x_n} $ be a [[Definition:Bounded Sequence in Normed Division Ring|bounded sequence]] in $\struct {R, \norm {\,\cdot\,} }$. Then: :$\exists K \in \R_{\gt 0} : \forall n : \norm {x_n} \le K$ Then $\forall n, m \in \N$: {{begin-eqn}} {{eqn | l = \map d { x_n , x_m } | r = \norm {x_n - x_m} | c = {{Defof|Metric Induced by Norm on Division Ring}} }} {{eqn | o = \le | r = \norm {x_n} + \norm {x_m} | c = [[Properties of Norm on Division Ring/Norm of Difference|Norm of Difference]] }} {{eqn | o = \le | r = K + K | c = {{Defof|Bounded Sequence in Normed Division Ring}} }} {{eqn | r = 2 K }} {{end-eqn}} Hence the [[Definition:Sequence|sequence]] $\sequence {x_n} $ is [[Definition:Bounded Sequence in Metric Space|bounded]] by $2 K$ in the [[Definition:Metric Space|metric space]] $\struct {R, d}$.	0
Let $e_1$ be the [[Definition:Elementary Row Operation|elementary row operation]] $\text {ERO} 1$: {{begin-axiom}} {{axiom | n = \text {ERO} 1 | t = For some $\lambda \ne 0$, [[Definition:Matrix Scalar Product|multiply]] [[Definition:Row of Matrix|row]] $k$ by $\lambda$ | m = r_k \to \lambda r_k }} {{end-axiom}} which is to operate on some arbitrary [[Definition:Matrix Space|matrix space]]. Let $\mathbf E_1$ be the [[Definition:Elementary Row Matrix|elementary row matrix]] corresponding to $e_1$. The [[Definition:Determinant of Matrix|determinant]] of $\mathbf E_1$ is: :$\map \det {\mathbf E_1} = \lambda$	0
{{TFAE|def = Associate in Integral Domain|context = Integral Domain|view = Associate}} Let $\struct {D, +, \circ}$ be an [[Definition:Integral Domain|integral domain]]. Let $x, y \in D$.	0
Let $D$ be the [[Definition:Set|set]] of all [[Definition:Finite Set|finitely]] [[Definition:Support of Mapping to Algebraic Structure|supported]] [[Definition:Sequence|sequences]] with [[Definition:Rational Number|rational]] terms: :$\displaystyle D = \set {\sequence {q_i}_{i \mathop \in \N} : n \in \N : i \le n : q_i \in \Q}$ We have that: :[[Rational Numbers are Countably Infinite]] :A [[Definition:Finite Set|finite set]] is [[Definition:Countable Set/Definition 3|countable]] :$D$ is a union of [[Definition:Finite Set|finite sets]] indexed by $n$, which is [[Definition:Countable|countable]] By [[Countable Union of Countable Sets is Countable]], $D$ is [[Definition:Countable Set|countable]]. Let $\mathbf x := \tuple {x_n}_{n \mathop \in \N} \in \ell^1$ By [[Definition:P-Sequence Space|definition]] of $\ell^1$: :$\displaystyle \sum_{n \mathop = 1}^\infty \size {x_n} < \infty$ Let $\displaystyle s_n := \sum_{i \mathop = 0}^n \size {x_i}$ be a [[Definition:Sequence|sequence]] of [[Definition:Partial Sum|partial sums]] of $\displaystyle s = \sum_{i \mathop = 0}^\infty \size {x_i}$. Then $s$ is a [[Definition:Convergent Sequence in Normed Vector Space|convergent sequence]]: :$\forall \epsilon' \in \R_{>0}: \exists N \in \N: \forall n \in \N: n > N \implies \size {s_n - s} < \epsilon'$ Note that: {{begin-eqn}} {{eqn | l = \size {s_n - s} | r = \size {\sum_{i \mathop = 0}^n \size {x_i} - \sum_{i \mathop = 0}^\infty \size {x_i} } }} {{eqn | r = \size {\sum_{i \mathop = n \mathop + 1}^\infty \size {x_i} } }} {{eqn | r = \sum_{i \mathop = n \mathop + 1}^\infty \size {x_i} | c = {{defof|Absolute Value}} }} {{end-eqn}} Let $\displaystyle \epsilon' = \frac \epsilon 2$. Let $\displaystyle N \in \N : \sum_{n \mathop = N + 1}^\infty \size {x_n} < \frac \epsilon 2$. We have that [[Rationals are Everywhere Dense in Reals/Normed Vector Space|$\Q$ is dense in $\R$]]. :$\forall x \in \R : \exists \epsilon'' \in \R_{\mathop > 0} : \exists q \in \Q : \size {x - q} < \epsilon''$ Then: :$\displaystyle \forall i \in \N : 1 \le i \le N : q_i \in \Q : \sum_{n \mathop = 1}^N \size {x_n - q_n} < \frac \epsilon 2$ where :$\displaystyle \frac \epsilon 2 = \sum_{i \mathop = 1}^N \epsilon_i''$ Let $\mathbf x' := \tuple {q_1, \ldots, q_N, 0, \ldots} \in D$. Then: :$\displaystyle \norm {\mathbf x - \mathbf x '} = \sum_{n \mathop = 1}^N \size {x_n - q_n} + \sum_{n \mathop = N + 1}^\infty \size {x_n} < \epsilon$ {{qed}}	0
From [[Structure Induced by Group Operation is Group]], $\struct {H^G, \oplus_H}$ is a [[Definition:Group|group]] Let $\phi, \psi \in \map {\LL_R} {G, H}$. From [[Addition of Linear Transformations]], $\phi \oplus_H \psi \in \map {\LL_R} {G, H}$. From [[Negative Linear Transformation]], $-\phi \in \map {\LL_R} {G, H}$. Thus, from the [[Two-Step Subgroup Test]], $\struct {\map {\LL_R} {G, H}, \oplus_H}$ is a [[Definition:Subgroup|subgroup]] of $\struct {H^G, \oplus_H}$. {{finish|Still need to show that it is abelian}}	0
If $n$ is [[Definition:Prime Number|prime]], the result is immediate. Let $n$ be [[Definition:Composite Number|composite]]. Then by [[Composite Number has Two Divisors Less Than It]]: :$\exists r, s \in \Z: n = r s, 1 < r < n, 1 < s < n$ This being the case, the set $S_1 = \set {d: d \divides n, 1 < d < n}$ is [[Definition:Non-Empty Set|nonempty]], and [[Definition:Bounded Below Set|bounded below]] by $1$. By [[Set of Integers Bounded Below by Integer has Smallest Element]], $S_1$ has a [[Definition:Smallest Element|smallest element]], which we will call $p_1$. {{AimForCont}} $p_1$ is [[Definition:Composite Number|composite]]. By [[Composite Number has Two Divisors Less Than It]], there exist $a, b$ such that $a, b \divides p_1$ and $1 < a < p_1, 1 < b < p_1$. But by [[Divisor Relation on Positive Integers is Partial Ordering]], it follows that $a, b \divides n$ and hence $a, b \in S$. This [[Definition:Contradiction|contradicts]] the assertion that $p_1$ is the [[Definition:Smallest Element|smallest element]] of $S_1$. Thus, $p_1$ is necessarily [[Definition:Prime Number|prime]]. We may now write $n = p_1 n_1$, where $n > n_1 > 1$. If $n_1$ is [[Definition:Prime Number|prime]], the proof is complete. Otherwise, the set $S_2 = \set {d: d \divides n_1, 1 < d < n_1}$ is [[Definition:Non-Empty Set|nonempty]], and [[Definition:Bounded Below Set|bounded below]] by $1$. By the above argument, the [[Definition:Smallest Element|smallest element]] $p_2$ of $S_2$ is [[Definition:Prime Number|prime]]. Thus we may write $n_1 = p_2 n_2$, where $1 < n_2 < n_1$. This gives us $n = p_1 p_2 n_2$. If $n_2$ is [[Definition:Prime Number|prime]], we are done. Otherwise, we continue this process. Since $n > n_1 > n_2 > \cdots > 1$ is a [[Definition:Strictly Decreasing Sequence|(strictly) decreasing sequence]] of [[Definition:Positive Integer|positive integers]], there must be a [[Definition:Finite Set|finite number]] of $n_i$'s. That is, we will arrive at some [[Definition:Prime Number|prime number]] $n_{k - 1}$, which we will call $p_k$. This results in the [[Definition:Prime Decomposition|prime decomposition]] $n = p_1 p_2 \cdots p_k$. {{qed}}	0
Let $D$ be an [[Definition:Everywhere Dense|everywhere dense]] [[Definition:Subset|subset]] of $S$ which is [[Definition:Countable Set|countable]], as is guaranteed as $T$ is [[Definition:Separable Space|separable]]. Consider the [[Definition:Mapping|mapping]] $\Phi: S \to 2^{\powerset D}$ defined as: :$\forall x \in S: \map {\map \Phi x} A = 1 \iff A = D \cap U_x$ for some [[Definition:Neighborhood of Point|neighborhood]] $U_x$ of $x$ {{explain|It is not clear in Steen & Seeabch what is meant by $\Phi: S \to 2^{\powerset D}$ -- presumably $2^{\powerset D}$ is the ordinal which is the power set of the power set of $D$. It is also not clear what the notation $\map {\map \Phi x} A$ means -- in fact is may be the case that a transcription error has been committed. Hence the proof cannot be attempted until these points have been cleared up.}} It is seen that if $T$ is a [[Definition:Hausdorff Space|Hausdorff space]], then $\Phi$ is an [[Definition:Injection|injection]]. It follows that: :$\card S \le \card {2^{\powerset D} } = 2^{2^{\aleph_0} }$ {{explain|the chain of reasoning leading to the above}}	0
We will demonstrate this for each of the $3$ types of [[Definition:Elementary Row Operation|elementary row operation]]. In the below: :$e$ denotes a given [[Definition:Elementary Row Operation|elementary row operation]] :$\mathbf E$ denotes the [[Definition:Elementary Row Matrix|elementary row matrix]] corresponding to $e$ :$e'$ denotes the [[Definition:Inverse of Elementary Row Operation|inverse]] of $e$ :$\mathbf E'$ denotes the [[Definition:Elementary Row Matrix|elementary row matrix]] corresponding to $e'$. Let $n$ denote the [[Definition:Order of Matrix|order]] of $\mathbf E$ and $\mathbf E'$. The strategy is to demonstrate that: :$\mathbf E \mathbf E' = \mathbf I$ where $\mathbf I$ denotes the [[Definition:Unit Matrix|unit matrix]] of [[Definition:Order of Matrix|order]] $n$. Let $x_{i, j}$ and $y_{i, j}$ denote the [[Definition:Element of Matrix|elements]] of $\mathbf E$ and $\mathbf E'$ respectively at [[Definition:Index of Matrix Element|indices]] $\tuple {i, j}$. Let $z_{i j}$ denote the [[Definition:Element of Matrix|element]] of $\mathbf E \mathbf E'$ at [[Definition:Index of Matrix Element|indices]] $\tuple {i, j}$. === $\text {ERO} 1$: Scalar Product of Row === Let $e$ be the [[Definition:Elementary Row Operation|elementary row operation]]: :$e := r_k \to \lambda r_k$ where $\lambda \ne 0$. From [[Elementary Matrix corresponding to Elementary Row Operation]], $\mathbf E$ is of the form: :$x_{a b} = \begin {cases} \delta_{a b} & : a \ne k \\ \lambda \cdot \delta_{a b} & : a = k \end {cases}$ where: :$\delta_{a b}$ is the [[Definition:Kronecker Delta|Kronecker delta]]: ::$\delta_{a b} = \begin {cases} 1 & : \text {if $a = b$} \\ 0 & : \text {if $a \ne b$} \end {cases}$ From [[Existence of Inverse Elementary Row Operation/Scalar Product of Row|Existence of Inverse Elementary Row Operation: Scalar Product of Row]], $e'$ is the [[Definition:Elementary Row Operation|elementary row operation]]: :$e' := r_k \to \dfrac 1 \lambda r_k$ From [[Elementary Matrix corresponding to Elementary Row Operation]], $\mathbf E'$ is of the form: :$y_{a b} = \begin {cases} \delta_{a b} & : a \ne k \\ \dfrac 1 \lambda \cdot \delta_{a b} & : a = k \end {cases}$ By definition of [[Definition:Matrix Product (Conventional)|matrix product]]: :$\displaystyle \forall a, b \in \set {1, 2, \ldots, n}: z_{a b} = \sum_{p \mathop = 1}^n x_{a p} y_{p b}$ Thus $z_{a b} \ne 0$ {{iff}} $a = p$ and $b = p$. When $a \ne k$: :$x_{a a} = y_{a a} = 1$ and so: :$z_{a a} = 1 \times 1 = 1$ When $a = k$: :$x_{a a} = \lambda$, $y_{l b} = \dfrac 1 \lambda$ and so: :$z_{a a} = \lambda \times \dfrac 1 \lambda = 1$ and for all $z_{a b}$ where $a \ne b$: :$z_{a b} = 0$ That is: :$z_{a b} = \delta_{a b}$ and by definition: :$\mathbf E \mathbf E' = \mathbf I$ {{qed|lemma}} === $\text {ERO} 2$: Add Scalar Product of Row to Another === Let $e$ be the [[Definition:Elementary Row Operation|elementary row operation]]: :$e := r_i \to r_i + \lambda r_j$ From [[Elementary Matrix corresponding to Elementary Row Operation]], $\mathbf E$ is of the form: :$x_{a b} = \delta_{a b} + \lambda \cdot \delta_{a i} \cdot \delta_{j b}$ From [[Existence of Inverse Elementary Row Operation/Add Scalar Product of Row to Another|Existence of Inverse Elementary Row Operation: Add Scalar Product of Row to Another]], $e'$ is the [[Definition:Elementary Row Operation|elementary row operation]]: :$e' := r_i \to r_i - \lambda r_j$ From [[Elementary Matrix corresponding to Elementary Row Operation]], $\mathbf E'$ is of the form: :$y_{a b} = \delta_{a b} - \lambda \cdot \delta_{a i} \cdot \delta_{j b}$ {{begin-eqn}} {{eqn | lo= \forall a, b \in \set {1, 2, \ldots, n}: | l = z_{a b} | r = \sum_{p \mathop = 1}^n x_{a p} y_{p b} | c = }} {{eqn | r = \sum_{p \mathop = 1}^n \paren {\delta_{a p} + \lambda \cdot \delta_{a i} \cdot \delta_{j p} } \cdot \paren {\delta_{p b} - \lambda \cdot \delta_{p i} \cdot \delta_{j b} } | c = }} {{eqn | r = \sum_{p \mathop = 1}^n \paren {\delta_{a p} \cdot \delta_{p b} + \lambda \cdot \delta_{a i} \cdot \delta_{j p} \cdot \delta_{p b} - \lambda \cdot \delta_{p i} \cdot \delta_{j b} \cdot \delta_{a p} - \lambda \cdot \delta_{a i} \cdot \delta_{j p} \cdot \lambda \cdot \delta_{p i} \cdot \delta_{j b} } | c = }} {{end-eqn}} We have that: {{begin-eqn}} {{eqn | l = \sum_{p \mathop = 1}^n \delta_{a p} \cdot \delta_{p b} | r = \delta_{a b} | c = }} {{eqn | l = \sum_{p \mathop = 1}^n \lambda \cdot \delta_{p i} \cdot \delta_{j b} \cdot \delta_{a p} | r = \lambda \cdot \delta_{a i} \cdot \delta_{j b} | c = }} {{eqn | l = -\sum_{p \mathop = 1}^n \lambda \cdot \delta_{a i} \cdot \delta_{j p} \cdot \delta_{p b} | r = -\lambda \cdot \delta_{j b} \cdot \delta_{a i} | c = }} {{eqn | l = \sum_{p \mathop = 1}^n \lambda \cdot \delta_{a i} \cdot \delta_{j p} \cdot \lambda \cdot \delta_{p i} \cdot \delta_{j b} | r = \lambda^2 \sum_{p \mathop = 1}^n \delta_{a i} \cdot \delta_{j p} \cdot \delta_{p i} \cdot \delta_{j b} | c = }} {{eqn | r = \lambda^2 \delta_{a i} \cdot \delta_{j i} \cdot \delta_{j b} | c = }} {{eqn | r = 0 | c = as $i \ne j$ }} {{end-eqn}} But: :$\lambda \cdot \delta_{j b} \cdot \delta_{a i} - \lambda \cdot \delta_{j b} \cdot \delta_{a i} = 0$ So everything vanishes except $\delta_{a b}$, and so: :$z_{a b} = \delta_{a b}$ and by definition, again: :$\mathbf E \mathbf E' = \mathbf I$ {{qed|lemma}} === $\text {ERO} 3$: Exchange Rows === Let $e$ be the [[Definition:Elementary Row Operation|elementary row operation]]: :$e := r_i \leftrightarrow r_j$ From [[Elementary Matrix corresponding to Elementary Row Operation]], $\mathbf E$ is of the form: :$x_{a b} = \begin {cases} \delta_{a b} & : \text {if $a \ne i$ and $a \ne j$} \\ \delta_{j b} & : \text {if $a = i$} \\ \delta_{i b} & : \text {if $a = j$} \end {cases}$ From [[Existence of Inverse Elementary Row Operation/Exchange Rows|Existence of Inverse Elementary Row Operation: Exchange Rows]], $e'$ is the [[Definition:Elementary Row Operation|elementary row operation]]: :$e' := r_i \leftrightarrow r_j$ From [[Elementary Matrix corresponding to Elementary Row Operation]], $\mathbf E'$ is of the form: :$y_{a b} = \begin {cases} \delta_{a b} & : \text {if $a \ne i$ and $a \ne j$} \\ \delta_{j b} & : \text {if $a = i$} \\ \delta_{i b} & : \text {if $a = j$} \end {cases}$ By definition of [[Definition:Matrix Product (Conventional)|matrix product]]: :$\displaystyle \forall a, b \in \set {1, 2, \ldots, n}: z_{a b} = \sum_{p \mathop = 1}^n x_{a p} y_{p b}$ When $a \ne i$ and $b \ne j$ we have: {{begin-eqn}} {{eqn | l = z_{a b} | r = \sum_{p \mathop = 1}^n \delta_{a p} \delta_{p b} | c = }} {{eqn | r = \delta_{a b} | c = }} {{end-eqn}} When $a = i$ and $b \ne i$ we have: {{begin-eqn}} {{eqn | l = z_{a b} | r = \sum_{p \mathop = 1}^n \delta_{j p} \delta_{p b} | c = }} {{eqn | r = 0 | c = }} {{end-eqn}} When $a = j$ and $b \ne j$ we have: {{begin-eqn}} {{eqn | l = z_{a b} | r = \sum_{p \mathop = 1}^n \delta_{i p} \delta_{p b} | c = }} {{eqn | r = 0 | c = }} {{end-eqn}} When $a = b = i$ we have: {{begin-eqn}} {{eqn | l = z_{i i} | r = \sum_{p \mathop = 1}^n \delta_{j p} \delta_{p j} | c = }} {{eqn | r = \delta_{j j} | c = }} {{eqn | r = 1 | c = }} {{end-eqn}} When $a = b = j$ we have: {{begin-eqn}} {{eqn | l = z_{j j} | r = \sum_{p \mathop = 1}^n \delta_{i p} \delta_{p i} | c = }} {{eqn | r = \delta_{i i} | c = }} {{eqn | r = 1 | c = }} {{end-eqn}} Hence by definition, again: :$\mathbf E \mathbf E' = \mathbf I$ {{qed|lemma}} Thus in all cases: :$\mathbf E \mathbf E' = \mathbf I$ Hence the result. {{qed}}	0
Follows from the [[Definition:Arithmetic Mean|definition of arithmetic mean]] and from [[Summation is Linear]]. {{qed}}	0
Let $R$ be a [[Definition:Ring (Abstract Algebra)|ring]]. Let $N$ be an [[Definition:Module|$R$-module]]. Let $\left({M_i}\right)_{i \mathop \in I}$ be a family of $R$-modules. Let $M = \displaystyle \bigoplus_{i \mathop \in I} M_i$ be their [[Definition:Module Direct Sum|direct sum]]. Let $\left({\psi_i}\right)_{i \mathop \in I}$ be a family of $R$-module morphisms $M_i \to N$. Then there exists a unique morphism: :$\Psi: M \to N$ such that: : $\forall i: \psi_i = \Psi \circ \iota_i$ where $\iota_i: M_i \to M$ is the $i$th canonical injection.	0
Let $K = \displaystyle \bigcup_{n \mathop \in \N} J_n$. Then from [[Increasing Union of Sequence of Ideals is Ideal]], $K$ is an [[Definition:Ideal of Ring|ideal]] of $D$. We have that $D$ is a [[Definition:Principal Ideal Domain|principal ideal domain]]. Hence there exists $a \in D$ such that: :$K = \ideal a$ where $\ideal a$ is the [[Definition:Principal Ideal of Ring|principal ideal]] of $D$ generated by $a$. But $a \in J_m$ for some $m \in \N$. Thus $K \subseteq J_m$ Thus it follows that $J_{m + 1} \subseteq J_m$ which [[Definition:Contradiction|contradicts]] our initial assertion that: :$\forall n \in \N: J_n \subsetneq j_{n + 1}$ Hence the result. {{qed}}	0
Let $\mathbf A$ and $\mathbf B$ be [[Definition:Square Matrix|square matrices]] of [[Definition:Order of Square Matrix|order $n$]]. Let $\mathbf A \mathbf B$ be the [[Definition:Matrix Product (Conventional)|(conventional) matrix product]] of $\mathbf A$ and $\mathbf B$. Then: :$\ds \map \tr {\mathbf A \mathbf B} = \sum_{i \mathop = 1}^n \sum_{j \mathop = 1}^n a_{i j} b_{j i}$ where $\map \tr {\mathbf A \mathbf B}$ denotes the [[Definition:Trace of Matrix|trace]] of $\mathbf A \mathbf B$. Using the [[Definition:Einstein Summation Convention|Einstein summation convention]], this can be expressed as: :$\map \tr {\mathbf A \mathbf B} = a_{i j} b_{j i}$	0
Let $\mathbf 0$ denote a [[Definition:Zero Vector Quantity|zero vector]]. {{AimForCont}} $\mathbf 0$ has a [[Definition:Direction|direction]]. Then $\mathbf 0$ can be [[Definition:Arrow Representation of Vector Quantity|represented as an arrow]] in a [[Definition:Real Vector Space|real vector space]] $\R^n$ with a [[Definition:Cartesian Coordinate System|Cartesian frame]]. Let $\mathbf 0$ be so embedded. Thus it consists of a [[Definition:Line Segment|line segment]] between two [[Definition:Point|points]] with an [[Definition:Initial Point of Vector|initial point]] $A$ and a [[Definition:Terminal Point of Vector|terminal point]] $B$. The [[Definition:Initial Point of Vector|initial point]] and a [[Definition:Terminal Point of Vector|terminal point]] are [[Definition:Distinct Elements|distinct]] from each other. Let these [[Definition:Point|points]] be identified as: {{begin-eqn}} {{eqn | l = A | r = \tuple {a_1, a_2, \ldots, a_n} }} {{eqn | l = B | r = \tuple {b_1, b_2, \ldots, b_n} }} {{end-eqn}} Hence we have that the [[Definition:Vector Length|length]] of $\mathbf 0$ is defined as: :$\norm {\mathbf 0} = \ds \sqrt {\sum_{i \mathop = 1}^n \paren {a_i - b_i}^2} > 0$ which means that at least one of $a_i - b_i$ is non-[[Definition:Zero (Number)|zero]]. But this [[Definition:Contradiction|contradicts]] the definition of $\mathbf 0$ being the [[Definition:Zero Vector Quantity|zero vector]]. It follows by [[Proof by Contradiction]] that our assumption that $\mathbf 0$ has a [[Definition:Direction|direction]] must be false. Hence the result. {{qed}}	0
Let $\left({G, +_G, \circ}\right)_R$ be an [[Definition:Module|$R$-module]]. Then $\left({G, +_G, \circ}\right)_R$ is a [[Definition:Submodule|submodule]] of itself.	0
Let $A$ be a [[Definition:Noetherian Ring|Noetherian ring]]. Let $n \ge 1$ be an [[Definition:Integer|integer]]. Let $A \sqbrk {x_1, \ldots, x_n}$ be the [[Definition:Ring of Polynomial Forms|ring of polynomial forms over $A$ in the indeterminates $x_1, \ldots, x_n$]]. Then $A \sqbrk {x_1, \ldots, x_n}$ is also a [[Definition:Noetherian Ring|Noetherian ring]].	0
Let $R$ be a [[Definition:Ring with Unity|ring with unity]]. Let $\left({G, +_G, \circ}\right)_R$ be a [[Definition:Unitary Module|unitary $R$-module]]. === [[Definition:Basis of Module/Definition 1|Definition 1]] === {{:Definition:Basis of Module/Definition 1}} === [[Definition:Basis of Module/Definition 2|Definition 2]] === {{:Definition:Basis of Module/Definition 2}}	0
Let $\Bbb F$ denote one of the [[Definition:Standard Number System|standard number systems]]. Let $\map \MM {m, n}$ be a [[Definition:Matrix Space|$m \times n$ matrix space]] over $\Bbb F$. Let $\mathbf A$ be an [[Definition:Element|element]] of $\map \MM {m, n}$. Let $-\mathbf A$ be the [[Definition:Negative Matrix|negative]] of $\mathbf A$. Then $-\mathbf A$ is the [[Definition:Inverse Element|inverse]] for the operation $+$, where $+$ is [[Definition:Matrix Entrywise Addition|matrix entrywise addition]].	0
=== Sufficient condition === Let $U$ be [[Definition:Cyclic Group|cyclic]]. Let $n \ge 0$ be an integer. Let $n = p_1^{e_1} \cdots p_r^{e_r}$, be the [[Definition:Prime Decomposition|decomposition]] of $n$ into [[Definition:Distinct|distinct]] [[Definition:Prime Number|prime]] [[Definition:Power (Algebra)|powers]] given by the [[Fundamental Theorem of Arithmetic]]. Then by the [[Chinese Remainder Theorem/Corollary|corollary to the Chinese remainder theorem]] we have an [[Definition:Ring Isomorphism|isomorphism]]: :$\Z / n \Z \simeq \Z / p_1 \Z \times \cdots \times \Z / p_r \Z$ By [[Units of Direct Product are Direct Product of Units]] we have: :$\paren {\Z / n \Z}^\times \simeq \paren {\Z / p_1 \Z}^\times \times \cdots \times \paren {\Z / p_r \Z}^\times$ Suppose that $r \ge 2$, and choose $i, j \in \set {1, \ldots, r}$ such that $i \ne j$. If $\paren {\Z / p_i \Z}^\times$ or $\paren {\Z / p_j \Z}^\times$ is not [[Definition:Cyclic Group|cyclic]], then $\paren {\Z / n \Z}^\times$ cannot be [[Definition:Cyclic Group|cyclic]]. {{explain|Link to a result establishing the above fact.}} Therefore suppose that $\paren {\Z / p_i \Z}^\times$ and $\paren {\Z / p_j \Z}^\times$ are [[Definition:Cyclic Group|cyclic]]. By [[Order of Group of Units of Integers Modulo m]] these [[Definition:Group|groups]] have [[Definition:Order of Structure|orders]]: :$\map \phi {p_i^{e_i} }$ and: :$\map \phi { p_j^{e_j} }$ respectively, where $\phi$ is the [[Definition:Euler Phi Function|Euler $\phi$ function]]. By [[Euler Phi Function of Integer]] we have: :$\map \phi {p_i^{e_i} } = p_i^{e_i - 1} \paren {p_i - 1}$ and :$\map \phi {p_j^{e_j} } = p_j^{e_j - 1} \paren {p_j - 1}$ If $p_i, p_j$ are [[Definition:Odd Integer|odd]], $2$ divides $p_i - 1$ and $p_j - 1$. Therefore $2$ divides $\map \phi {p_i^{e_i} }$ and $\map \phi {p_j^{e_j} }$. In particular, $\map \phi {p_i^{e_i} }$ and $\map \phi {p_j^{e_j} }$ are not [[Definition:Coprime Integers|coprime]]. Now by [[Group Direct Product of Cyclic Groups]], $\left({\Z / n \Z}\right)^\times$ is not [[Definition:Cyclic Group|cyclic]]. Let $p_i$ or $p_j$ be [[Definition:Even Integer|even]]. {{WLOG}}, we can assume $p_i = 2$. Then: :$\map \phi {p_i^{e_i} } = \map \phi {2^{e_i} } = p_i^{e_i - 1} \paren {p_i - 1}$ So if $e_i \ge 2$, then $2$ divides $\map \phi {p_i^{e_i} }$ and $\map \phi {p_j^{e_j} }$. In particular $\map \phi {p_i^{e_i} }$ and $\map \phi {p_j^{e_j} }$ are not [[Definition:Coprime Integers|coprime]]. Again by [[Group Direct Product of Cyclic Groups]], $\paren {\Z / n \Z}^\times$ is not [[Definition:Cyclic Group|cyclic]]. Thus if $\paren {\Z / n \Z}^\times$ is [[Definition:Cyclic Group|cyclic]], then $n = 2^e \times p^\alpha$ with $e = 0$ or $e = 1$, $\alpha \ge 0$ and $p \ge 3$ [[Definition:Prime Number|prime]]. {{Qed|lemma}} === Necessary Condition === {{ProofWanted}} [[Category:Ring of Integers Modulo m]] kzf5rgrqazm8xul4km4k01d3vtkttqk	0
{{begin-eqn}} {{eqn | l = \nabla \times \paren {g \, \mathbf f} | r = \paren {\dfrac {\partial g f_z} {\partial y} - \dfrac {\partial g f_y} {\partial z} } \mathbf i + \paren {\dfrac {\partial g f_x} {\partial z} - \dfrac {\partial g f_z} {\partial x} } \mathbf j + \paren {\dfrac {\partial g f_y} {\partial x} - \dfrac {\partial g f_x} {\partial y} } \mathbf k | c = {{Defof|Curl Operator}} }} {{eqn | r = \paren {g \dfrac {\partial f_z} {\partial y} + \dfrac {\partial g} {\partial y} f_z - g \dfrac {\partial f_y} {\partial z} - \dfrac {\partial g} {\partial z} f_y} \mathbf i | c = [[Product Rule for Derivatives]] }} {{eqn | o = | ro= + | r = \paren {g \dfrac {\partial f_x} {\partial z} + \dfrac {\partial g} {\partial z} f_x - g \dfrac {\partial f_z} {\partial x} - \dfrac {\partial g} {\partial x} f_z} \mathbf j | c = }} {{eqn | o = | ro= + | r = \paren {g \dfrac {\partial f_y} {\partial x} + \dfrac {\partial g} {\partial x} f_y - g \dfrac {\partial f_x} {\partial y} - \dfrac {\partial g} {\partial y} f_x } \mathbf k | c = }} {{eqn | r = \map g {\paren {\dfrac {\partial f_z} {\partial y} - \dfrac {\partial f_y} {\partial z} } \mathbf i + \paren {\dfrac {\partial f_x} {\partial z} - \dfrac {\partial f_z} {\partial x} } \mathbf j + \paren {\dfrac {\partial f_y} {\partial x} - \dfrac {\partial f_x} {\partial y} } \mathbf k} | c = rearrangement }} {{eqn | o = | ro= + | r = \paren {\dfrac {\partial g} {\partial y} f_z - \dfrac {\partial g} {\partial z} f_y} \mathbf i + \paren {\dfrac {\partial g} {\partial z} f_x - \dfrac {\partial g} {\partial x} f_z} \mathbf j + \paren {\dfrac {\partial g} {\partial x} f_y - \dfrac {\partial g} {\partial y} f_x} \mathbf k | c = }} {{eqn | r = \map g {\nabla \times \mathbf f} + \paren {\dfrac {\partial g} {\partial y} f_z - \dfrac {\partial g} {\partial z} f_y} \mathbf i + \paren {\dfrac {\partial g} {\partial z} f_x - \dfrac {\partial g} {\partial x} f_z} \mathbf j + \paren {\dfrac {\partial g} {\partial x} f_y - \dfrac {\partial g} {\partial y} f_x} \mathbf k | c = {{Defof|Curl Operator}} }} {{eqn | r = \map g {\nabla \times \mathbf f} + \paren {\dfrac {\partial g} {\partial x} \mathbf i + \dfrac {\partial g} {\partial y} \mathbf j + \dfrac {\partial g} {\partial z} \mathbf k} \times \paren {f_x \mathbf i + f_y \mathbf j + f_z \mathbf k} | c = {{Defof|Cross Product}} }} {{eqn | r = \map g {\nabla \times \mathbf f} + \paren {\nabla g} \times \mathbf f | c = {{Defof|Gradient Operator}}, {{Defof|Vector (Linear Algebra)|Vector}} }} {{end-eqn}} {{qed}}	0
The [[Definition:Complex Number|complex numbers]] $\C$ are formed by the [[Definition:Complex Number/Construction from Cayley-Dickson Construction|Cayley-Dickson Construction]] from the [[Definition:Real Number|real numbers]] $\R$. From [[Real Numbers form Algebra]], we have that $\R$ forms: :$(1): \quad$ An [[Definition:Associative Algebra|associative algebra]]. :$(2): \quad$ A [[Definition:Commutative Algebra|commutative algebra]]. :$(3): \quad$ A [[Definition:Normed Division Algebra|normed division algebra]]. :$(4): \quad$ A [[Definition:Nicely Normed Star-Algebra|nicely normed $*$-algebra]] whose $*$ operator is the [[Definition:Identity Mapping|identity mapping]]. :$(5): \quad$ A [[Definition:Real Star-Algebra|real $*$-algebra]]. From [[Cayley-Dickson Construction forms Star-Algebra]], $\C$ is a [[Definition:Star-Algebra|$*$-algebra]]. From [[Cayley-Dickson Construction from Nicely Normed Algebra is Nicely Normed]], $\C$ is a [[Definition:Nicely Normed Star-Algebra|nicely normed $*$-algebra]]. From [[Cayley-Dickson Construction from Real Algebra is Commutative]], $\C$ is a [[Definition:Commutative Algebra|commutative algebra]]. From [[Cayley-Dickson Construction from Commutative Associative Algebra is Associative]], $\C$ is an [[Definition:Associative Algebra|associative algebra]]. However, from [[Algebra from Cayley-Dickson Construction Never Real]], $\C$ is not a [[Definition:Real Algebra|real algebra]]. === Proof of Normed Division Algebra === Consider the element $\left({1, 0}\right)$ of $\R^2$. We have: {{begin-eqn}} {{eqn | o = | r = \left({x_1, x_2}\right) \times \left({1, 0}\right) | c = }} {{eqn | r = \left({x_1 \times 1 - 0 \times x_2, x_1 \times 0 + x_2 \times 1}\right) | c = }} {{eqn | r = \left({x_1, x_2}\right) | c = }} {{end-eqn}} As $\times$ has already been shown to be [[Definition:Commutative Operation|commutative]], it follows that $\left({1, 0}\right) \times \left({x_1, x_2}\right) = \left({x_1, x_2}\right)$. So $\left({1, 0}\right) \in \R^2$ functions as a [[Definition:Unit of Algebra|unit]]. That is, $\left({\R^2, \times}\right)$ is a [[Definition:Unitary Algebra|unitary algebra]]. <!-- From [[Inverses for Real Multiplication]], every element of $\left({\R, \times}\right)$ except $0$ has a [[Definition:Multiplicative Inverse|multiplicative inverse]]. So $\left({\R, \times}\right)$ is a [[Definition:Division Algebra|division algebra]] and hence a [[Definition:Unitary Division Algebra|unitary division algebra]]. --> We define a [[Definition:Norm on Vector Space|norm]] on $\left({\R^2, \times}\right)$ by: :$\forall \mathbf a = \left({a_1, a_2}\right) \in \R^2: \left \Vert {\mathbf a} \right \Vert = \sqrt {a_1^2 + a_2^2}$ This is a [[Definition:Norm on Vector Space|norm]] because: : $(1): \quad \left \Vert \mathbf x \right \Vert = 0 \iff \mathbf x = \mathbf 0$ : $(2): \quad \left \Vert \lambda \mathbf x \right \Vert = \left \vert \lambda \right \vert \left \Vert x \right \Vert$ : $(3): \quad \left \Vert x - y \right \Vert \le \left \Vert x - z \right \Vert + \left \Vert z - y \right \Vert$ It also follows that: : $\left \Vert x \times y \right \Vert = \left \vert x \times y \right \vert = \left \vert x \right \vert \times \left \vert y \right \vert = \left \Vert x \right \Vert \times \left \Vert y \right \Vert$ and so $\left({\R^2, \times}\right)$ is a [[Definition:Normed Division Algebra|normed division algebra]]. {{proofread|Make sure the above are all proved properly.}} {{qed}}	0
The [[Definition:Quaternion|quaternions]] $\Bbb H$ are formed by the [[Definition:Quaternion/Construction from Cayley-Dickson Construction|Cayley-Dickson Construction]] from the [[Definition:Complex Number|complex numbers]] $\C$. From [[Complex Numbers form Algebra]], we have that $\C$ forms: :$(1): \quad$ An [[Definition:Associative Algebra|associative algebra]] :$(2): \quad$ A [[Definition:Commutative Algebra|commutative algebra]] :$(3): \quad$ A [[Definition:Normed Division Algebra|normed division algebra]] :$(4): \quad$ A [[Definition:Nicely Normed Star-Algebra|nicely normed $*$-algebra]]. From [[Cayley-Dickson Construction forms Star-Algebra]], $\Bbb H$ is a [[Definition:Star-Algebra|$*$-algebra]]. From [[Cayley-Dickson Construction from Nicely Normed Algebra is Nicely Normed]], $\Bbb H$ is a [[Definition:Nicely Normed Star-Algebra|nicely normed $*$-algebra]]. From [[Cayley-Dickson Construction from Commutative Associative Algebra is Associative]], $\Bbb H$ is an [[Definition:Associative Algebra|associative algebra]]. Now suppose $\Bbb H$ formed a [[Definition:Commutative Algebra|commutative algebra]]. Then from [[Cayley-Dickson Construction from Real Algebra is Commutative]], that would mean $\C$ is a [[Definition:Real Algebra|real algebra]]. But from [[Complex Numbers form Algebra]] it is explicitly demonstrated that $\C$ is '''not''' a [[Definition:Real Algebra|real algebra]]. So $\Bbb H$ can not be a [[Definition:Commutative Algebra|commutative algebra]]. === Proof of Normed Division Algebra === Consider the element $\left({1, 0}\right)$ of $\C^2$. We have: {{begin-eqn}} {{eqn | o = | r = \left({x_1, x_2}\right) \times \left({1, 0}\right) | c = }} {{eqn | r = \left({x_1 \times 1 - 0 \times x_2, x_1 \times 0 + x_2 \times 1}\right) | c = }} {{eqn | r = \left({x_1, x_2}\right) | c = }} {{end-eqn}} As $\times$ is [[Definition:Commutative Operation|commutative]] on $\C$, it follows that $\left({1, 0}\right) \times \left({x_1, x_2}\right) = \left({x_1, x_2}\right)$. So $\left({1, 0}\right) \in \C^2$ functions as a [[Definition:Unit of Algebra|unit]]. That is, $\left({\C^2, \times}\right)$ is a [[Definition:Unitary Algebra|unitary algebra]]. <!-- From [[Inverses for Complex Multiplication]], every element of $\left({\C, \times}\right)$ except $0$ has a [[Definition:Multiplicative Inverse|multiplicative inverse]]. So $\left({\C, \times}\right)$ is a [[Definition:Division Algebra|division algebra]] and hence a [[Definition:Unitary Division Algebra|unitary division algebra]]. --> We define a [[Definition:Norm on Vector Space|norm]] on $\left({\C^2, \times}\right)$ by: :$\forall \mathbf a = \left({a_1, a_2}\right) \in \C^2: \left \Vert {\mathbf a} \right \Vert = \sqrt {a_1^2 + a_2^2}$ This is a [[Definition:Norm on Vector Space|norm]] because: : $(1): \quad \left \Vert \mathbf x \right \Vert = 0 \iff \mathbf x = \mathbf 0$ : $(2): \quad \left \Vert \lambda \mathbf x \right \Vert = \left \vert \lambda \right \vert \left \Vert x \right \Vert$ : $(3): \quad \left \Vert x - y \right \Vert \le \left \Vert x - z \right \Vert + \left \Vert z - y \right \Vert$ It also follows that: : $\left \Vert x \times y \right \Vert = \left \vert x \times y \right \vert = \left \vert x \right \vert \times \left \vert y \right \vert = \left \Vert x \right \Vert \times \left \Vert y \right \Vert$ and so $\left({\C^2, \times}\right)$ is a [[Definition:Normed Division Algebra|normed division algebra]]. {{Proofread|Make sure the above are all proved properly.}} {{qed}}	0
Let $\struct {R, \norm {\,\cdot\,} }$ be a [[Definition:Normed Division Ring|normed division ring]] with [[Definition:Non-Archimedean Division Ring Norm|non-Archimedean norm]] $\norm{\,\cdot\,}$, Let $x, y \in R$ and $\norm x \lt \norm y$. Then: :$\norm {x + y} = \norm {x - y} = \norm {y - x} = \norm y$	0
Let $\struct {R, \norm {\, \cdot \,} }$ be a [[Definition:Normed Division Ring|normed division ring]]. Let $\struct {R', \norm {\, \cdot \,}' }$ be a [[Definition:Completion (Normed Division Ring)|normed division ring completion]] of $\struct {R, \norm {\, \cdot \,} }$ Then: :$\struct {R, \norm {\, \cdot \,} }$ is [[Definition:Isometric Isomorphism|isometrically isomorphic]] to a [[Definition:Everywhere Dense|dense]] [[Definition:Normed Division Subring|normed division subring]] of $\struct {R', \norm {\, \cdot \,}' }$.	0
Let $K$ be a [[Definition:Field (Abstract Algebra)|field]]. Let $M$ be a [[Definition:Vector Subspace|subspace]] of the [[Definition:Dimension of Vector Space|$n$-dimensional]] [[Definition:Vector Space|vector space $K^n$]]. The following statements are equivalent: :$(1): \quad \map \dim M = n - 1$ :$(2): \quad M$ is the [[Definition:Kernel of Linear Transformation|kernel]] of a nonzero [[Definition:Linear Form|linear form]] :$(3): \quad$ There exists a [[Definition:Sequence|sequence]] $\sequence {\alpha_n} $ of [[Definition:Scalar (Vector Space)|scalars]], not all of which are zero, such that: :::$M = \set {\tuple {\lambda_1, \ldots, \lambda_n} \in K^n: \alpha_1 \lambda_1 + \cdots + \alpha_n \lambda_n = 0}$ Also, suppose the above hold. Let $\sequence {\beta_n}$ be a [[Definition:Sequence|sequence]] of [[Definition:Scalar (Vector Space)|scalars]] such that: :$M = \set {\tuple {\lambda_1, \ldots, \lambda_n} \in K^n: \beta_1 \lambda_1 + \cdots + \beta_n \lambda_n = 0}$ Then there is a non-zero [[Definition:Scalar (Vector Space)|scalar]] $\gamma$ such that: :$\forall k \in \closedint 1 n: \beta_k = \gamma \alpha_k$	0
{{ProofWanted|Need to consider which definition you start from}}	0
There are no [[Definition:Sequence|sequences]] at all of $n$ terms of the [[Definition:Empty Set|empty set]] for any $n > 0$. Hence the result holds [[Definition:Vacuous Truth|vacuously]]. {{qed}}	0
If the conditions are fulfilled, then: :$x \in H \implies -x = \left({- 1_R}\right) \circ x \in H$ Thus $H$ is a [[Definition:Subgroup|subgroup]] of $\left({G, +}\right)$ by the [[Two-Step Subgroup Test]], and hence a [[Definition:Submodule|submodule]]. {{qed}}	0
A [[Definition:Totally Bounded Metric Space|totally bounded metric space]] is [[Definition:Separable Space|separable]].	0
Let $T = \struct {S, \tau_p}$ be the [[Definition:Fortissimo Space|fortissimo space]] on an [[Definition:Uncountable Set|uncountable set]] $S$. Then $T$ is not a [[Definition:Separable Space|separable space]].	0
Let $\mathbf A$ be a [[Definition:Square Matrix|square matrix]] of [[Definition:Order of Square Matrix|order $n$]]. Then $\mathbf A$ is [[Definition:Non-Invertible Matrix|non-invertible]] if there exists a [[Definition:Vector (Linear Algebra)|vector]] $\mathbf v$ of $n$ such that: :$\mathbf v \ne \mathbf 0$ :$\mathbf A \mathbf v = \mathbf 0$ where $\mathbf 0$ is the [[Definition:Zero Vector|zero vector]].	0
=== Existence === The existence of $C$ follows immediately from the definition of a [[Definition:Basis (Linear Algebra)|basis]]. {{qed|lemma}} === Uniqueness === Let $C, D$ be [[Definition:Finite Set|finite]] [[Definition:Subset|subsets]] of $R \times B$ satisfying the requirements. Let $Q = \left\{{v: \exists r \in R: \left({r, v}\right) \in C \cup D}\right\}$. Let $V' = \operatorname{span} \left({Q}\right)$. Then $V'$ is a [[Definition:Finite Dimensional Vector Space|finite-dimensional vector space]] with [[Definition:Basis (Linear Algebra)|basis]] $Q$ and $x \in V'$. Thus the theorem follows from [[Expression of Vector as Linear Combination from Basis is Unique]]. {{explain}} {{qed}} [[Category:Vector Spaces]] [[Category:Linear Algebra]] 0cxx8banz3dgsvjrbnh5fx843yhiku0	0
Let $p > 3$. Then there exists $a \in \Z: 1 < a < p-1$. Consider the [[Definition:Sequence|sequence]] $\sequence {x_n} \subseteq \Q$ where $x_n = a^{p^n}$ for some $a \in \Z: 1 < a < p-1$. Let $n \in \N$. Then: :$\norm {a^{p^{n + 1} } - a^{p^n} }_p = \norm {a^{p^n} (a^{p^n \left({p - 1}\right)} - 1) }_p$ From the [[Euler's Theorem/Corollary 1|corollary to Euler's Theorem]]: :$a^{p^n \left({p - 1}\right)} - 1 \equiv 0 \pmod {p^n}$ so: :$\norm {a^{p^n} \paren {a^{p^n \paren {p - 1} } - 1} }_p \le p^{-n} \xrightarrow {n \to \infty} 0$ That is: :$\displaystyle \lim_{n \mathop \to \infty} \norm {x_{n + 1} - x_n}_p = 0$ By [[Characterisation of Cauchy Sequence in Non-Archimedean Norm]] :$\sequence {x_n }$ is a [[Definition:Cauchy Sequence|cauchy sequence]] in $\struct {\Q, \norm {\,\cdot\,}_p }$. {{AimForCont}} $\sequence {x_n}$ [[Definition:Convergent Sequence|converges]] to some $x \in \Q$. That is: :$x = \displaystyle \lim_{n \mathop \to \infty} x_n$ By [[Modulus of Limit/Normed Division Ring|Modulus of Limit on a Normed Division Ring]]: :$\displaystyle \lim_{n \mathop \to \infty} \norm {x_n }_p = \norm {x }_p$ Since $\forall n, p \nmid a^{p^n} = x_n$, then: :$ \norm {x_n }_p = 1$ So: :$\norm x_p = \displaystyle \lim_{n \mathop \to \infty} \norm {x_n}_p = 1$ By Axiom (N1) of a [[Definition:Norm on Division Ring|norm on a division ring]] then: :$x \ne 0$. Since: {{begin-eqn}} {{eqn | l = x | r = \lim_{n \mathop \to \infty} x_n | c = Definition of $x$ }} {{eqn | r = \lim_{n \mathop \to \infty} x_{n + 1} | c = [[Limit of Subsequence equals Limit of Sequence]] }} {{eqn | r = \lim_{n \mathop \to \infty} \paren {x_n}^p | c = Definition of $x_n$ }} {{eqn | r = \paren {\lim_{n \mathop \to \infty} x_n}^p | c = [[Combination Theorem for Sequences/Normed Division Ring/Product Rule|Product rule for Normed Division Rings]] }} {{eqn | r = x^p | c = Definition of $x$ }} {{end-eqn}} and $x \ne 0$ then: :$x^{p-1} = 1$ So: :$x = 1$ or $x = -1$ and so $a-x$ is an integer: :$0 < a - x < p$ It follows that: :$p \nmid \paren {a - x}$ and so: :$\norm {x - a}_p = 1$ Since $x_n \to x$ as $n \to \infty$ then: :$\exists N: \forall n > N: \norm {x_n - x}_p < \norm {x - a}_p$ That is: :$\exists N: \forall n > N: \norm {a^{p^n} - x}_p < \norm {x - a}_p$ Let $n > N$: {{begin-eqn}} {{eqn | l = \norm {x - a}_p | r = \norm {x - a^{p^n} + a^{p^n} - a}_p }} {{eqn | o = \le | r = \max \set {\norm {x - a^{p^n} }_p, \norm {a^{p^n} - a}_p} | c = [[P-adic Norm is Non-Archimedean Norm]] }} {{end-eqn}} As $\norm {x - a^{p^n} }_p < \norm {x - a}_p$: {{begin-eqn}} {{eqn | l = \norm {x - a}_p | r = \norm {a^{p^n} - a}_p | c = [[Three Points in Ultrametric Space have Two Equal Distances]] }} {{eqn | r = \norm a_p \norm {a^{p^n - 1} - 1}_p | c = Axiom (N2) of a [[Definition:Norm on Division Ring|norm on a division ring]] }} {{eqn | r = \norm {a^{p^n - 1} - 1}_p | c = as $\norm a_p = 1$ }} {{eqn | o = < | r = 1 | c = [[Fermat's Little Theorem/Corollary 4|corollary 4 to Fermat's Little Theorem]] }} {{end-eqn}} This [[Definition:Contradiction|contradicts]] the earlier assertion that $\norm {x - a}_p = 1$. In conclusion: :$\sequence {x_n}$ is a [[Definition:Cauchy Sequence|Cauchy sequence]] that does not [[Definition:Convergent Sequence|converge]] in $\struct {\Q, \norm {\,\cdot\,}_p }$.	0
{{begin-eqn}} {{eqn | l = \left({\mathbf u + \mathbf v}\right) \cdot \mathbf w | r = \sum_{i \mathop = 1}^n \left({u_i + v_i}\right) w_i | c = {{Defof|Vector Sum}} and {{Defof|Dot Product}} }} {{eqn | r = \sum_{i \mathop = 1}^n \left({u_i w_i + v_i w_i}\right) | c = [[Real Multiplication Distributes over Real Addition]] }} {{eqn | r = \sum_{i \mathop = 1}^n u_i w_i + \sum_{i \mathop = 1}^n v_i w_i | c = }} {{eqn | r = \mathbf u \cdot \mathbf w + \mathbf v \cdot \mathbf w | c = {{Defof|Dot Product}} }} {{end-eqn}} {{qed}}	0
Let $\struct {R, +, \circ}$ be a [[Definition:Ring (Abstract Algebra)|ring]]. Let $\map {\MM_R} {m, n}$ be a [[Definition:Matrix Space|$m \times n$ matrix space]] over $R$. For $\mathbf A, \mathbf B \in \map {\MM_R} {m, n}$, let $\mathbf A + \mathbf B$ be defined as the [[Definition:Matrix Entrywise Addition over Ring|matrix entrywise sum]] of $\mathbf A$ and $\mathbf B$. The operation $+$ is [[Definition:Associative Operation|associative]] on $\map {\MM_R} {m, n}$. That is: :$\paren {\mathbf A + \mathbf B} + \mathbf C = \mathbf A + \paren {\mathbf B + \mathbf C}$ for all $\mathbf A$, $\mathbf B$ and $\mathbf C$ in $\map {\MM_R} {m, n}$.	0
We have by definition that [[Definition:Matrix Entrywise Addition|matrix entrywise addition]] is a specific instance of a [[Definition:Hadamard Product|Hadamard product]]. By definition of a [[Definition:Ring (Abstract Algebra)|ring]], the [[Definition:Algebraic Structure|structure]] $\struct {R, +}$ is a [[Definition:Group|group]]. As $\struct {R, +}$ is [[Definition:A Fortiori|a fortiori]] a [[Definition:Monoid|monoid]], it follows from [[Matrix Space Semigroup under Hadamard Product]] that $\struct {\map {\MM_R} {m, n}, +}$ is also a [[Definition:Monoid|monoid]]. As $\struct {R, +}$ is a [[Definition:Group|group]], it follows from [[Negative Matrix is Inverse for Matrix Entrywise Addition]] that all [[Definition:Element|elements]] of $\struct {\map {\MM_R} {m, n}, +}$ have an [[Definition:Inverse Element|inverse element]]. From [[Matrix Entrywise Addition is Commutative]] it follows that $\struct {\map {\MM_R} {m, n}, +}$ is an [[Definition:Abelian Group|Abelian group]]. The result follows. {{Qed}}	0
Let $x_1, x_2 \in A$. Let $a \in A$ be a [[Definition:Star Convex Set/Star Center|star center]] of $A$. By [[Definition:Star Convex Set|definition of star convex set]], it follows that for all $t \in \left[{0 \,.\,.\, 1}\right]$, we have $t x_1 + \left({1 - t}\right) a, t x_2 + \left({1 - t}\right) a \in A$. Define two [[Definition:Path (Topology)|paths]] $\gamma_1, \gamma_2: t \in \left[{0 \,.\,.\, 1}\right] \to A$ by $\gamma_1 \left({t}\right) = t x_1 + \left({1 - t}\right) a$, and $\gamma_2 \left({t}\right) = t a + \left({1 - t}\right) x_2$. As $\gamma_2 \left({t}\right) = \left({1 - t}\right) x_2 + \left({1 - \left({1 - t}\right) }\right) a$, and $\left({1 - t}\right) \in \left[{0 \,.\,.\, 1}\right]$, it follows that $\gamma_2 \left({t}\right) \in A$. Note that $\gamma_1 \left({0}\right) = x_1$, $\gamma_1 \left({1}\right) = \gamma_2 \left({0}\right) = a$, and $\gamma_2 \left({1}\right) = x_2$. Define $\gamma: \left[{0 \,.\,.\, 1}\right] \to A$ as the [[Definition:Concatenation (Topology)|concatenation]] $\gamma_1 * \gamma_2$. Then $\gamma$ is a path in $A$ joining $x_1$ and $x_2$, so $A$ is [[Definition:Path-Connected Set (Topology)|path-connected]]. {{qed}}	0
{{AimForCont}} $x^2 + 1$ has a [[Definition:Non-Trivial Factorization|non-trivial factorization]] in $\R \sqbrk X$. Then: :$\exists \alpha, \beta \in \R: \paren {X - \alpha} \paren {X - \beta}$ and from the [[Polynomial Factor Theorem]]: :$\alpha^2 + 1 = 0$ But that means: :$\alpha^2 = -1$ and such an $\alpha$ does not exist in $\R$. Hence the result by [[Proof by Contradiction]]. {{qed}}	0
Let $\struct {R, \norm {\, \cdot \,} }$ be a [[Definition:Normed Division Ring|normed division ring]] with [[Definition:Ring Zero|zero]]: $0$. Let $\sequence {x_n}$ be a [[Definition:Sequence|sequence in $R$]]. Let $\sequence {x_n}$ be [[Definition:Convergent Sequence in Normed Division Ring|convergent in the norm]] $\norm {\, \cdot \,}$ to the following [[Definition:Limit of Sequence (Normed Division Ring)|limit]]: :$\displaystyle \lim_{n \mathop \to \infty} x_n = l$ Let $\sequence {x_{n_r} }$ be a [[Definition:Subsequence|subsequence]] of $\sequence {x_n}$. Then: :$\sequence {x_{n_r} }$ is [[Definition:Convergent Sequence in Normed Division Ring|convergent]] and $\displaystyle \lim_{r \mathop \to \infty} x_{n_r} = l$	0
The eigenvectors of a Hermitian [[Definition:Operation|operation]] are [[Definition:Orthogonal (Linear Algebra)|orthogonal]].	0
Let: : $\mathbf r: x \mapsto \left\langle{r_1 \left({x}\right), r_2 \left({x}\right), \ldots, r_n \left({x}\right)}\right\rangle$ : $\mathbf q: x \mapsto \left\langle{q_1 \left({x}\right), q_2 \left({x}\right), \ldots, q_n \left({x}\right)}\right\rangle$ be [[Definition:Differentiable Vector-Valued Function|differentiable]] [[Definition:Vector-Valued Function|vector-valued functions]]. The [[Definition:Derivative of Vector-Valued Function|derivative]] of their [[Definition:Dot Product|dot product]] is given by: :$\dfrac \d {\d x} \left({\mathbf r \left({x}\right) \cdot \mathbf q \left({x}\right)}\right) = \mathbf r' \left({x}\right) \cdot \mathbf q \left({x}\right) + \mathbf r \left({x}\right) \cdot \mathbf q' \left({x}\right)$	0
By definition of [[Definition:Dot Product|dot product]]: :$\mathbf a \cdot \mathbf b = \norm {\mathbf a} \norm {\mathbf b} \cos \theta$ where $\theta$ is the [[Definition:Angle|angle]] between $\mathbf a$ and $\mathbf b$. When $\mathbf a$ and $\mathbf b$ be [[Definition:Perpendicular|perpendicular]], by definition $\theta = 90 \degrees$. The result follows by [[Cosine of Right Angle]], which gives that $\cos 90 \degrees = 0$. {{qed}}	0
=== [[Triangle Inequality/Geometry|Geometry]] === {{:Triangle Inequality/Geometry}} === [[Triangle Inequality/Real Numbers|Real Numbers]] === {{:Triangle Inequality/Real Numbers}} === [[Triangle Inequality/Complex Numbers|Complex Numbers]] === {{:Triangle Inequality/Complex Numbers}}	0
:$\mathbf u \cdot \mathbf u \ge 0$	0
Taking the [[Definition:Group Axioms|group axioms]] in turn: === $G \, 0$: Closure === Let $\mathbf A, \mathbf B \in S$. By definition of [[Definition:Matrix Product (Conventional)|matrix product]], $\mathbf {A B}$ is a [[Definition:Square Matrix|square matrix]] of [[Definition:Order of Square Matrix|order]] $n$. From [[Determinant of Matrix Product]]: :$\det \mathbf A \det \mathbf B = \map \det {\mathbf {A B} }$ Hence the [[Definition:Determinant of Matrix|determinant]] of $\mathbf {A B}$ is either $1$ or $-1$. Thus $\mathbf {A B} \in S$ and so $\struct {S, \times}$ is [[Definition:Closed Algebraic Structure|closed]]. {{qed|lemma}} === $G \, 1$: Associativity === We have that [[Matrix Multiplication is Associative]]. Thus $\times$ is [[Definition:Associative|associative]] on $\struct {S, \times}$. {{qed|lemma}} === $G \, 2$: Identity === From [[Unit Matrix is Unity of Ring of Square Matrices]], the [[Definition:Unit Matrix|unit matrix]] $\mathbf I$ serves as the [[Definition:Identity Element|identity element]] of $\struct {S, \times}$. {{qed|lemma}} === $G \, 3$: Inverses === Because the [[Definition:Determinant of Matrix|determinants]] of the [[Definition:Element|elements]] of $S$ are $1$ or $-1$, they are by definition [[Definition:Invertible Matrix|invertible]]. We have that $\mathbf I$ is the [[Definition:Identity Element|identity element]] of $\struct {\R, \circ}$. From the definition of [[Definition:Invertible Matrix|invertible matrix]], the [[Definition:Inverse Element|inverse]] of any [[Definition:Invertible Matrix|invertible matrix]] $\mathbf A$ is $\mathbf A^{-1}$. {{qed|lemma}} All the [[Definition:Group Axioms|group axioms]] are thus seen to be fulfilled, and so $\struct {S, \times}$ is a [[Definition:Group|group]]. {{qed}}	0
For every $t\in N$, the [[Definition:Mapping|mapping]]: :$f_t : M \to M : x \mapsto f(x,t)$ is a [[Definition:Contraction Mapping|contraction]]. By the [[Banach Fixed-Point Theorem]], there exists a [[Definition:unique|unique]] $g(t) \in M$ such that $f_t(g(t)) = g(t)$. We show that $g$ is [[Definition:Lipschitz Continuous|Lipschitz continuous]]. Let $K<1$ be a [[Definition:Uniform Lipschitz Constant|uniform Lipschitz constant]] for $f$. Let $L$ be a [[Definition:Lipschitz Constant|Lipschitz constant]] for $f$. Let $s,t\in N$. Then {{begin-eqn}} {{eqn | l = d(g(s), g(t)) | r = d(f(g(s), s), f(g(t), t)) | c = Definition of $g$ }} {{eqn | o = \leq | r = d(f(g(s), s), f(g(t), s)) + d(f(g(t), s), f(g(t), t)) | c = {{defof|Metric}} }} {{eqn | o = \leq | r = K \cdot d(g(s), g(t)) + d(f(g(t), s), f(g(t), t)) | c = $f$ is a [[Definition:Uniform Contraction Mapping|uniform contraction]] }} {{end-eqn}} and thus: {{begin-eqn}} {{eqn | l = d(g(s), g(t)) | o = \leq | r = \dfrac1{1-K}d(f(g(t), s), f(g(t), t)) }} {{eqn | o = \leq | r = \dfrac L{1-K} d(s,t) | c = $f$ is [[Definition:Lipschitz Continuous|lipschitz continuous]] }} {{end-eqn}} Thus $g$ is [[Definition:Lipschitz Continuous|lipschitz continuous]]. {{qed}} [[Category:Implicit Functions]] 66rdm27e18ivrvk98jlfgzalfq9xt22	0
=== [[Characterisation of Non-Archimedean Division Ring Norms/Necessary Condition|Necessary Condition]] === {{:Characterisation of Non-Archimedean Division Ring Norms/Necessary Condition}}{{qed|lemma}} === [[Characterisation of Non-Archimedean Division Ring Norms/Sufficient Condition|Sufficient Condition]] === {{:Characterisation of Non-Archimedean Division Ring Norms/Sufficient Condition}}{{qed}}	0
The [[Test for Ideal]] is applied to prove the result. === [[Null Sequences form Maximal Left and Right Ideal/Lemma 1/Lemma 1.1|Lemma 1.1]] === {{:Null Sequences form Maximal Left and Right Ideal/Lemma 1/Lemma 1.1|Lemma 1}}{{qed|lemma}} === [[Null Sequences form Maximal Left and Right Ideal/Lemma 1/Lemma 1.2|Lemma 1.2]] === {{:Null Sequences form Maximal Left and Right Ideal/Lemma 1/Lemma 1.2}}{{qed|lemma}} === [[Null Sequences form Maximal Left and Right Ideal/Lemma 1/Lemma 1.3|Lemma 1.3]] === {{:Null Sequences form Maximal Left and Right Ideal/Lemma 1/Lemma 1.3}}{{qed|lemma}} By [[Test for Ideal]] then the result follows. {{qed}}	0
=== Euclidean 2-space === Define the [[Definition:Ordered Tuple|ordered 2-tuples]]: {{begin-eqn}} {{eqn | l = \mathbf i | r = \left\langle{1, 0}\right\rangle }} {{eqn | l = \mathbf j | r = \left\langle{0, 1}\right\rangle }} {{end-eqn}} From [[Standard Ordered Basis is Basis]], we have that any [[Definition:Vector (Euclidean Space)|vector in $\R^2$]] can be represented by: :$c_1 \mathbf i + c_2 \mathbf j$ where $c_1, c_2 \in \R$. This way of presenting vectors is called '''engineering notation'''. === Euclidean 3-space === Define the [[Definition:Ordered Tuple|ordered 3-tuples]]: {{begin-eqn}} {{eqn | l = \mathbf i | r = \left\langle{1, 0, 0}\right\rangle }} {{eqn | l = \mathbf j | r = \left\langle{0, 1, 0}\right\rangle }} {{eqn | l = \mathbf k | r = \left\langle{0, 0, 1}\right\rangle }} {{end-eqn}} By the same logic as the above definition, we can write any [[Definition:Vector (Euclidean Space)|vector in $\R^3$]] as: :$c_1 \mathbf i + c_2 \mathbf j + c_3 \mathbf k$ where $c_1, c_2, c_3 \in \R$. Note that $\mathbf i$ and $\mathbf j$ take on a different meaning in $3$-space than in $2$-space. === Euclidean $n$-space === In higher [[Definition:Dimension|dimensions]], rather than writing $\mathbf l, \mathbf m, \mathbf n$, and so on, the convention is to use: {{begin-eqn}} {{eqn | l = \mathbf e_1 | r = \left\langle{1, 0, 0, \ldots, 0, 0}\right\rangle }} {{eqn | l = \mathbf e_2 | r = \left\langle{0, 1, 0, \ldots, 0, 0}\right\rangle }} {{eqn | o = \vdots }} {{eqn | l = \mathbf e_n | r = \left\langle{0, 0, 0, \ldots, 0, 1}\right\rangle }} {{end-eqn}} Then any vector in $\R^n$ can be expressed as: :$c_1 \mathbf e_1 + c_2 \mathbf e_2 + \cdots + c_n \mathbf e_n$ where $c_1, c_2, \cdots, c_n \in \R$. This convention is also frequently seen for $2$-space and $3$-space.	0
Let $\displaystyle \bigoplus_{i \mathop \in I} M_i$ be the [[Definition:Direct Sum of Modules|external direct sum]] of $\left\langle{M_i}\right\rangle_{i \mathop \in I}$. $M$ is the '''internal direct sum''' of $\left\langle{M_i}\right\rangle_{i \mathop \in I}$ {{iff}} the [[Definition:Mapping|mapping]] given by [[Universal Property of Direct Sum of Modules]] is an [[Definition:Module Isomorphism|isomorphism]] onto $M$.	0
Let $x, y \in S_1$. Let $\sequence {x_n}$ and $\sequence {y_n}$ be [[Definition:Sequence|sequences]] in $R_1$ such that $\displaystyle \lim_{n \mathop \to \infty} x_n = x, \lim_{n \mathop \to \infty} y_n = y$. Then: {{begin-eqn}} {{eqn | l = x - y | r = \lim_{n \mathop \to \infty} x_n - y_n | c = [[Combination Theorem for Sequences/Normed Division Ring/Difference Rule|Difference Rule for Convergent Sequences]] }} {{eqn | o = }} {{eqn | ll= \leadsto | l = \norm {x - y} | r = \lim_{n \mathop \to \infty} \norm {x_n - y_n} | c = [[Modulus of Limit/Normed Division Ring|Modulus of Limit]] }} {{eqn | r = \lim_{n \mathop \to \infty} \norm {\map {\psi'} {x_n} - \map {\psi'} {y_n} } | c = {{Defof|Isometry (Metric Spaces)}} }} {{end-eqn}} On the other hand: {{begin-eqn}} {{eqn | l = \map \psi x - \map \psi y | r = \paren {\lim_{n \mathop \to \infty} \map {\psi'} {x_n} } - \paren {\lim_{n \mathop \to \infty} \map {\psi'} {y_n} } | c = Definition of $\psi$ }} {{eqn | r = \lim_{n \mathop \to \infty} \map {\psi'} {x_n} - \map {\psi'} {y_n} | c = [[Combination Theorem for Sequences/Normed Division Ring/Difference Rule|Difference Rule for Convergent Sequences]] }} {{eqn | o = }} {{eqn | ll= \leadsto | l = \norm {\map \psi x - \map \psi y} | r = \lim_{n \mathop \to \infty} \norm {\map {\psi'} {x_n} - \map {\psi'} {y_n} } | c = [[Modulus of Limit/Normed Division Ring|Modulus of Limit]] }} {{end-eqn}} By [[Convergent Sequence in Metric Space has Unique Limit]]: :$\norm {x - y} = \norm {\map \psi x - \map \psi y}$ It follows that $\psi$ is [[Definition:Distance-Preserving Mapping|distance-preserving]]. By [[Distance-Preserving Surjection is Isometry of Metric Spaces]] then $\psi$ is an [[Definition:Isometry (Metric Spaces)|isometry]]. {{qed}} [[Category:Completion of Normed Division Ring]] powpdrlvt5p4znr4rmcsoi3ipftmw7j	0
Let $G$ and $H$ be [[Definition:Module|$R$-modules]]. Then $\map {\mathrm {Hom}_R} {G, H}$ is the '''set of all [[Definition:Linear Transformation|linear transformations]]''' from $G$ to $H$: :$\map {\mathrm {Hom}_R} {G, H} := \set {\phi: G \to H: \phi \mbox{ is a linear transformation} }$ If it is clear (and therefore does not need to be stated) that the [[Definition:Scalar Ring of Module|scalar ring]] is $R$, then this can be written $\map {\mathrm {Hom} } {G, H}$. Similarly, $\map {\mathrm {Hom}_R} G$ is the set of all [[Definition:Linear Operator|linear operators]] on $G$: :$\map {\mathrm {Hom}_R} G := \set {\phi: G \to G: \phi \text{ is a linear operator} }$ Again, this can also be written $\map {\mathrm {Hom} } G$.	0
Let: :$\map {\mathbf f} x = \displaystyle \sum_{k \mathop = 1}^n \map {f_k} x \mathbf e_k$ be a [[Definition:Differentiable Vector-Valued Function|differentiable]] [[Definition:Vector-Valued Function|vector-valued function]]. Let $\map {\mathbf f} x$ be such that its [[Definition:Magnitude|magnitude]] is [[Definition:Constant|constant]]: :$\size {\map {\mathbf f} x} = c$ for some $c \in \R$. Then the [[Definition:Dot Product|dot product]] of $\mathbf f$ with its [[Definition:Derivative of Vector-Valued Function|derivative]] is zero: :$\map {\mathbf f} x \cdot \dfrac {\d \map {\mathbf f} x} {\d x} = 0$	0
Let $\struct {X, \norm {\, \cdot \,} }$ be a [[Definition:Normed Vector Space|normed vector space]]. Let $\map {B_1^-} 0$ be a [[Definition:Closed Unit Ball|closed unit ball]] in $X$. Then $\map {B_1^-} 0$ is [[Definition:Convex Set (Vector Space)|convex]].	0
Let $m \in M$ be arbitrary. By definition there is an [[Definition:Open Neighborhood|open neighborhood]] $U$ of $m$, [[Definition:Homeomorphic Metric Spaces|homeomorphic]] to an [[Definition:Open Set of Metric Space|open subset]] of $\R^d$. By the definition of an [[Definition:Open Set of Metric Space|open set]], there is some [[Definition:Open Ball of Metric Space|open ball]]: :$B = B_\delta \left({\phi \left({m}\right)}\right) = \left\{{x \in \R^d: \left|{x - \phi \left({m}\right)}\right| < \delta}\right\}$ of [[Definition:Radius of Open Ball|radius]] $\delta$ containing $\phi \left({m}\right)$, contained in $U$. By [[Closure of Open Ball in Metric Space]] and [[Topological Closure is Closed]], the set: :$C = \left\{{x \in \R^d: \left|{x - \phi \left({m}\right)}\right| \le \dfrac \delta 2}\right\}$ is [[Definition:Closed Set (Topology)|closed]], and $C \subseteq B \subseteq U$. Moreover, $C$ is trivially [[Definition:Bounded Metric Space|bounded]], hence [[Definition:Compact Topological Space|compact]] by the [[Heine-Borel Theorem]]. Now if $\phi$ is a [[Definition:Homeomorphism (Metric Spaces)|homeomorphism]] $U \to \R^d$, then by definition $\phi^{-1}$ is [[Definition:Everywhere Continuous Mapping (Topology)|continuous]]. Therefore by [[Continuous Image of Compact Space is Compact]], $\phi^{-1} \left({C}\right) \subseteq M$ is [[Definition:Compact Topological Space|compact]]. Furthermore $m \in \phi^{-1} \left({C}\right)$ because $\phi \left({m}\right) \in C$. Thus every point of $M$ has a [[Definition:Compact Topological Subspace|compact]] [[Definition:Neighborhood (Topology)|neighborhood]]. {{Qed}} {{explain|Clarification is needed as to why this result should be categorised in [[:Category:Manifolds]].}} [[Category:Manifolds]] atj03zp0r9bpm24yi9z708tx91dy20y	0
Let $e_2$ be the [[Definition:Elementary Row Operation|elementary row operation]] $\text {ERO} 2$: {{begin-axiom}} {{axiom | n = \text {ERO} 2 | t = For some $\lambda$, add $\lambda$ [[Definition:Matrix Scalar Product|times]] [[Definition:Row of Matrix|row]] $j$ to [[Definition:Row of Matrix|row]] $i$ | m = r_i \to r_i + \lambda r_j }} {{end-axiom}} which is to operate on some arbitrary [[Definition:Matrix Space|matrix space]]. Let $\mathbf E_2$ be the [[Definition:Elementary Row Matrix|elementary row matrix]] corresponding to $e_2$. The [[Definition:Determinant of Matrix|determinant]] of $\mathbf E_2$ is: :$\map \det {\mathbf E_2} = 1$	0
Let $\struct {R, +, \circ}$ be a [[Definition:Ring with Unity|ring with unity]]. Let $n \in \Z_{>0}$ be a [[Definition:Strictly Positive Integer|(strictly) positive integer]]. Let $\mathbf A$ be an [[Definition:Element|element]] of the [[Definition:Ring of Square Matrices|ring of square matrices]] $\struct {\map {\mathcal M_R} n, +, \times}$. The following definitions for $\mathbf A$ to be [[Definition:Non-Invertible Matrix|non-invertible]] are [[Definition:Logical Equivalence|equivalent]]:	0
$M$ is the '''internal direct sum''' of $(M_i)_{i\in I}$ {{Iff}} every $m\in M$ can be written uniquely as a sum $\sum m_i$ with each $m_i\in M_i$.	0
For $a + b \sqrt 2$ to be a [[Definition:Unit of Ring|unit]] of $\struct {\Z \sqbrk {\sqrt 2}, +, \times}$, we require that: :$\exists c, d \in \Z: \paren {a + b \sqrt 2} \paren {c + d \sqrt 2} = 1$ In [[Numbers of Type Integer a plus b root 2 are Not a Field]] it is shown that the [[Definition:Product Inverse|product inverse]] of $\paren {a + b \sqrt 2}$ is $\dfrac a {a^2 - 2 b^2} + \dfrac {b \sqrt 2} {a^2 - 2 b^2}$. So if $a^2 - 2 b^2 = \pm 1$ it follows that $c$ and $d$ are [[Definition:Integer|integers]]. Hence the result. {{qed}}	0
Let $K$ be a [[Definition:Field (Abstract Algebra)|field]]. Let $\mathbf A$ be an [[Definition:Matrix|$m \times n$ matrix]] over $K$. Then the [[Definition:Rank of Matrix|rank]] of $\mathbf A$ is the [[Definition:Dimension of Vector Space|dimension]] of the [[Definition:Vector Subspace|subspace]] of $K^n$ [[Definition:Generator of Module|generated]] by the [[Definition:Row Matrix|rows]] of $\mathbf A$.	0
Follows directly from: : [[Characterisation of Linearly Independent Set through Free Module Indexed by Set]] : [[Characterisation of Spanning Set through Free Module Indexed by Set]]. {{qed}} [[Category:Module Theory]] d3onr5592y2nzbayp16sgunznhp5emy	0
'''Preliminaries''': [[Vandermonde Matrix Identity for Cauchy Matrix]] supplies matrix equation :$\displaystyle (1)\quad - C = PV_x^{-1} V_y Q^{-1}$ :Definitions of symbols: ::$\displaystyle V_x=\paren {\begin{smallmatrix} 1 & 1 & \cdots & 1 \\ x_1 & x_2 & \cdots & x_n \\ \vdots & \vdots & \ddots & \vdots \\ x_1^{n-1} & x_2^{n-1} & \cdots & x_n^{n-1} \\ \end{smallmatrix} },\quad V_y=\paren {\begin{smallmatrix} 1 & 1 & \cdots & 1 \\ y_1 & y_2 & \cdots & y_n \\ \vdots & \vdots & \ddots & \vdots \\ y_1^{n-1} & y_2^{n-1} & \cdots & y_n^{n-1} \\ \end{smallmatrix} }$ [[Definition:Vandermonde Matrix|Vandermonde matrices]] ::$\displaystyle P= \paren {\begin{smallmatrix} p_1(x_1) & \cdots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \cdots & p_n(x_n) \\ \end{smallmatrix} }, \quad Q= \paren {\begin{smallmatrix} p(y_1) & \cdots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \cdots & p(y_n) \\ \end{smallmatrix} }$ [[Definition:Diagonal Matrix|Diagonal matrices]] ::$\displaystyle p(x) = \prod_{i \mathop = 1}^n \paren {x - x_i}, \quad \displaystyle p_k(x) = \prod_{i \mathop = 1,i \mathop \ne k}^n \, \paren {x - x_i}, \quad 1 \mathop \le k \mathop \le n$ [[Definition:Polynomial/Complex Numbers|Polynomials]] '''Compute the inverse''' $C^{-1}$ for: {{begin-eqn}} {{eqn | l = C | r = \begin{bmatrix} \dfrac 1 {x_1 - y_1} & \dfrac 1 {x_1 - y_2} & \cdots & \dfrac 1 {x_1 - y_n} \\ \dfrac 1 {x_2 - y_1} & \dfrac 1 {x_2 - y_2} & \cdots & \dfrac 1 {x_2 - y_n} \\ \vdots & \vdots & \ddots & \vdots \\ \dfrac 1 {x_n - y_1} & \dfrac 1 {x_n - y_2} & \cdots & \dfrac 1 {x_n - y_n} \\ \end{bmatrix} | c = Assume $\set {x_1,\ldots,x_n,y_1,\ldots,y_n}$ has distinct elements. }} {{end-eqn}} Replacement $y_k \to -y_k$ then gives the inverse $C_n^{-1}$ in the theorem. [[Inverse of Matrix Product]] applied to equation (1) gives: :$ C^{-1} = -Q V_y^{-1} V_x P^{-1}$ Let ${\vec K}_1,\ldots,{\vec K}_n$ denote the columns of the $n\times n$ identity matrix. Then $n\times n$ matrix $B = C^{-1}$ has entries $b_{ij} = {\vec K}_i^T C^{-1} {\vec K}_j$. Hold fixed until the end of the proof the row and column index symbols $i$ and $j$. Define column vectors $\vec A$, $\vec B$ so that $b_{ij} = {\vec A}^T \vec B$: :$\displaystyle \vec A = \paren { {\vec K}_i^T \, Q \, V_y^{-1} }^T, \quad \vec B = -V_x \, P^{-1} \, {\vec K}_j $ Define $u = x_j$ and simplify: {{begin-eqn}} {{eqn | l = \vec A | r = {\map p {y_i} } \, \paren { V_y^{-1} }^T \, {\vec K}_i | c = [[Transpose of Matrix Product]] }} {{eqn | r = \dfrac{ \map p {y_i} }{\det \paren {V_y} } \paren { \adj {V_y} }^T {\vec K}_i | c = [[Matrix Product with Adjugate Matrix]] }} {{eqn | r = \dfrac{ \map p {y_i} }{\det \paren {V_y} } \begin{bmatrix} {\mathbf {Cofactor} } \paren {V_y,1,i } \\ \vdots \\ {\mathbf {Cofactor} } \paren {V_y,n,i } \\ \end{bmatrix} | c = ${\mathbf {Cofactor} } \paren {M,r,s}$ denotes [[Definition:Cofactor|cofactor]] $M_{rs}$ }} {{eqn | l = \vec B | r = -\dfrac{1}{\map {p_j} {x_j} } \, V_x \, {\vec K}_j }} {{eqn | r = -\dfrac{1}{\map {p_j} {x_j} } \, \begin{bmatrix} 1 \\ u \\ \vdots \\ u^{n-1} \\ \end{bmatrix} | c = Symbol $u = x_j$. }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = A^T\, B | r = \dfrac { -\map p {y_i} } {\map {p_j} {x_j} \det \paren {V_y} } \sum_{k \mathop = 1}^n {\mathbf {Cofactor} } \paren {V_y,k,i } \, u^{k-1} | c = A [[Expansion Theorem for Determinants|Cofactor expansion]] along column $i$. }} {{eqn | r = \dfrac { -\map p {y_i} } {\map {p_j} {x_j} \det \paren {V_y} } \det \paren { \begin{matrix} 1 & \cdots & 1 & 1 & 1 & \cdots & 1 \\ y_1 & \cdots & y_{i-1} & u & y_{i+1} & \cdots & y_n \\ \vdots & \cdots & \vdots &\vdots & \vdots & \cdots & \vdots \\ y_1^{n-1} & \cdots & y_{i-1}^{n-1} & u^{n-1} & y_{i+1}^{n-1} & \cdots & y_n^{n-1} \\ \end{matrix} } }} {{eqn | r = \dfrac { -\map p {y_i} } {\map {p_j} {x_j} } \,\, \dfrac { \left. \paren { \det \paren {V_y} } \right \vert_{y_i \mathop = u} } { \det \paren {V_y} } }} {{end-eqn}} Simplify the fraction on the right: {{begin-eqn}} {{eqn | l = (2)\quad \displaystyle \dfrac { \displaystyle \left. \paren { \det \paren {V_y} } \right\vert_{y_i \mathop = u} } { \displaystyle \det \paren {V_y} } | r = \displaystyle \dfrac {\displaystyle \left. \paren { \prod_{1 \mathop \le m \mathop \lt k \mathop \le n} \paren { y_k - y_m } } \right\vert_{ y_i \mathop = u } } {\displaystyle \prod_{1 \mathop \le m \mathop \lt k \mathop \le n} \paren { y_k - y_m } } | c = [[Vandermonde Determinant]] }} {{end-eqn}} Define sets $D,A,B,C$ with disjoint decomposition $D = A \cup B \cup C$: {{begin-eqn}} {{eqn | l = D | r = \set { \paren { m,k } : 1 \le m \lt k \le n } }} {{eqn | l = A | r = \set { \paren { m,k } \in D : m \neq i \mbox{ and } k \neq i } }} {{eqn | l = B | r = \set { \paren { m,k } \in D : m = i } }} {{eqn | l = C | r = \set { \paren { m,k } \in D : k = i } }} {{end-eqn}} Use $\prod_{D} = \prod_{A} \prod_{B} \prod_{C}$ to convert the numerator and denominator in the right side of (2). Then: {{begin-eqn}} {{eqn | l = \displaystyle \dfrac { \displaystyle \left. \paren { \det \paren {V_y} } \right\vert_{y_i \mathop = u} } { \displaystyle \det \paren {V_y} } | r = \displaystyle \dfrac {\displaystyle \prod_{k \mathop = 1,\, k \mathop \neq i}^n \paren { u - y_k } } {\displaystyle \prod_{k \mathop = 1,\, k \mathop \neq i}^n \paren { y_i - y_k } } | c = Common factors canceled in (2). }} {{end-eqn}} Replacement of ${ \map p {y_i} }$ and ${ \map {p_j} {x_j} }$ by products gives: {{begin-eqn}} {{eqn | l = (3)\quad \displaystyle b_{ij} | r = \paren {-1} \, \dfrac { \displaystyle \prod_{k \mathop = 1}^n \paren {y_i - x_k } } { \displaystyle \prod_{k \mathop = 1,\, k \mathop \neq j}^n \paren { x_j - x_k } } \,\, \prod_{k \mathop = 1,\, k \mathop \neq i}^n \paren { \dfrac { x_j - y_k }{ y_i - y_k } } | c = Replaced $u = x_j$. }} {{end-eqn}} After replacement $y_k \to -y_k$ and canceling a common factor, ''Knuth's original identity'' (1997) becomes: {{begin-eqn}} {{eqn | l = \displaystyle (4)\quad b_{ij} | r = \displaystyle \dfrac { \displaystyle \prod_{k \mathop = 1}^n \paren { x_k - y_i } } { \displaystyle \prod_{k \mathop = 1,\, k \mathop \neq j}^n \paren { x_j - x_k } } \dfrac { \displaystyle \prod_{k \mathop = 1,\, k \mathop \neq i}^n \paren { x_j - y_k } } { \displaystyle \prod_{k \mathop = 1,\, k \mathop \neq i}^n \paren { - y_i + y_k } } }} {{end-eqn}} In (3), factor $(-1)^{n+1}$ from the numerator and $(-1)^{n-1}$ from the denominator. Then $(-1)^{n+1} = (-1)^{n-1}$ verifies that (3) matches (4).{{qed}}	0
Let $\struct {R, \norm {\, \cdot \,} }$ be a [[Definition:Normed Division Ring|normed division ring]]. Let $\struct {R', \norm {\, \cdot \,}' }$ be a [[Definition:Completion (Normed Division Ring)|normed division ring completion]] of $\struct {R, \norm {\, \cdot \,} }$ Then: :$R$ is a [[Definition:Field (Abstract Algebra)|field]] {{iff}} $R'$ is a [[Definition:Field (Abstract Algebra)|field]].	0
The vectors $\left\Vert{\mathbf u}\right\Vert \mathbf v$ and $\left\Vert{\mathbf v}\right\Vert \mathbf u$ have equal length from [[Vector Times Magnitude Same Length As Magnitude Times Vector]]. Thus $\left\Vert{\mathbf u}\right\Vert \mathbf v + \left\Vert{\mathbf v}\right\Vert \mathbf u$ is the diagonal of a [[Definition:Rhombus|rhombus]]. The result follows from [[Diagonals of Rhombus Bisect Angles]]. {{qed}}	0
Let $\mathbf a = \begin{bmatrix} a_1 \\ a_2 \\ a_3 \end{bmatrix}$, and $\mathbf b = \begin{bmatrix} b_1 \\ b_2 \\ b_3 \end{bmatrix}$. Then the [[Definition:Dot Product|dot product]] of $\mathbf a$ and $\mathbf a \times \mathbf b$ is: {{begin-eqn}} {{eqn | l = \mathbf a \cdot \left({\mathbf a \times \mathbf b}\right) | r = a_1 \left({a_2 b_3 - a_3 b_2}\right) + a_2 \left({a_3 b_1 - a_1 b_3}\right) + a_3 \left({a_1 b_2 - a_2 b_1}\right) | c = {{Defof|Dot Product}} and {{Defof|Vector Cross Product}} }} {{eqn | r = a_1 a_2 b_3 - a_1 a_3 b_2 + a_2 a_3 b_1 - a_1 a_2 b_3 + a_1 a_3 b_2 - a_2 a_3 b_1 }} {{eqn | r = 0 }} {{end-eqn}} Since the [[Definition:Dot Product|dot product]] is equal to zero, the vectors are [[Definition:Orthogonal (Linear Algebra)|orthogonal]] by definition. Similarly, $\mathbf b$ and $\mathbf a \times \mathbf b$ are [[Definition:Orthogonal (Linear Algebra)|orthogonal]]: {{begin-eqn}} {{eqn | l = \mathbf b \cdot \left({\mathbf a \times \mathbf b}\right) | r = b_1 \left({a_2 b_3 - a_3 b_2}\right) + b_2 \left({a_3 b_1 - a_1 b_3}\right) + b_3 \left({a_1 b_2 - a_2 b_1}\right) }} {{eqn | r = a_2 b_1 b_3 - a_3 b_1 b_2 + a_3 b_1 b_2 - a_1 b_2 b_3 + a_1 b_2 b_3 - a_2 b_1 b_3 }} {{eqn | r = 0 }} {{end-eqn}} {{qed}}	0
{{ProofWanted|tedious}}	0
From [[Hilbert Matrix is Cauchy Matrix]], $H_n$ is a special case of a [[Definition:Cauchy Matrix|Cauchy matrix]]: :$\begin{bmatrix} c_{i j} \end{bmatrix} = \begin{bmatrix} \dfrac 1 {x_i + y_j} \end{bmatrix}$ where: :$x_i = i$ :$y_j = j - 1$ From [[Inverse of Cauchy Matrix]], the [[Definition:Inverse Matrix|inverse]] of the [[Definition:Square Matrix|square]] [[Definition:Cauchy Matrix|Cauchy matrix]] of [[Definition:Order of Square Matrix|order $n$]] is: :$\begin{bmatrix} b_{i j} \end{bmatrix} = \begin{bmatrix} \dfrac {\displaystyle \prod_{k \mathop = 1}^n \paren {x_j + y_k} \paren {x_k + y_i} } {\displaystyle \paren {x_j + y_i} \paren {\prod_{\substack {1 \mathop \le k \mathop \le n \\ k \mathop \ne j} } \paren {x_j - x_k} } \paren {\prod_{\substack {1 \mathop \le k \mathop \le n \\ k \mathop \ne i} } \paren {y_i - x_k} } } \end{bmatrix}$ Thus $H_n^{-1}$ can be specified as: :$\begin{bmatrix} b_{i j} \end{bmatrix} = \begin{bmatrix} \dfrac {\displaystyle \prod_{k \mathop = 1}^n \paren {i + k - 1} \paren {j + k - 1} } {\displaystyle \paren {i + j - 1} \paren {\prod_{\substack {1 \mathop \le k \mathop \le n \\ k \mathop \ne i} } \paren {i - k} } \paren {\prod_{\substack {1 \mathop \le k \mathop \le n \\ k \mathop \ne j} } \paren {j - k} } } \end{bmatrix}$ First, from [[Product of Products]]: :$\displaystyle \prod_{k \mathop = 1}^n \paren {i + k - 1} \paren {j + k - 1} = \prod_{k \mathop = 1}^n \paren {i + k - 1} \prod_{k \mathop = 1}^n \paren {j + k - 1}$ We address in turn the various [[Definition:Factor|factors]] of this [[Definition:Expression|expression]] for $b_{i j}$. {{begin-eqn}} {{eqn | l = \prod_{k \mathop = 1}^n \paren {i + k - 1} | r = \prod_{k \mathop = 0}^{n - 1} \paren {i + k} | c = [[Translation of Index Variable of Product]] }} {{eqn | r = i^{\overline n} | c = Definition of [[Definition:Rising Factorial|Rising Factorial]] }} {{eqn | r = \frac {\paren {i + n - 1}!} {\paren {i - 1}!} | c = [[Rising Factorial as Quotient of Factorials]] }} {{end-eqn}} and similarly: :$\displaystyle \prod_{k \mathop = 1}^n \paren {j + k - 1} = \frac {\paren {j + n - 1}!} {\paren {j - 1}!}$ Then: {{begin-eqn}} {{eqn | l = \prod_{\substack {1 \mathop \le k \mathop \le n \\ k \mathop \ne i} } \paren {i - k} | r = \paren {\prod_{1 \mathop \le k \mathop < i} \paren {i - k} } \paren {\prod_{i \mathop < k \mathop \le n} \paren {i - k} } | c = }} {{eqn | r = \paren {i - 1}! \paren {\prod_{i \mathop < k \mathop \le n} \paren {i - k} } | c = {{Defof|Factorial}} }} {{eqn | r = \paren {i - 1}! \paren {\prod_{0 \mathop < k \mathop \le n - i} \paren {-k} } | c = [[Translation of Index Variable of Product]] }} {{eqn | r = \paren {i - 1}! \paren {-1}^{n - i} \paren {\prod_{0 \mathop < k \mathop \le n - i} k} | c = }} {{eqn | r = \paren {i - 1}! \paren {-1}^{n - i} \paren {n - i}! | c = {{Defof|Factorial}} }} {{end-eqn}} and similarly: :$\displaystyle \prod_{\substack {1 \mathop \le k \mathop \le n \\ k \mathop \ne j} } \paren {j - k} = \paren {j - 1}! \paren {-1}^{n - j} \paren {n - j}!$ Thus we can write: {{begin-eqn}} {{eqn | l = \begin{bmatrix} b_{i j} \end{bmatrix} | r = \frac {\paren {\dfrac {\paren {i + n - 1}!} {\paren {i - 1}!} } \paren {\dfrac {\paren {j + n - 1}!} {\paren {j - 1}!} } } {\paren {i + j - 1} \paren {i - 1}! \paren {-1}^{n - i} \paren {n - i}! \paren {j - 1}! \paren {-1}^{n - j} \paren {n - j}!} | c = }} {{eqn | r = \frac {\paren {-1}^{i + j} \paren {i + n - 1}! \paren {j + n - 1}!} {\paren {\paren {i - 1}!}^2 \paren {\paren {j - 1}!}^2 \paren {n - i}! \paren {n - j}! \paren {i + j - 1} } | c = }} {{end-eqn}} {{qed}}	0
:[[File:Straight-line-normal-form.png|400px]] Let $A$ be the [[Definition:X-Intercept|$x$-intercept]] of $\mathcal L$. Let $B$ be the [[Definition:Y-Intercept|$y$-intercept]] of $\mathcal L$. Let $A = \tuple {a, 0}$ and $B = \tuple {0, b}$. From the [[Equation of Straight Line in Plane/Two-Intercept Form|Equation of Straight Line in Plane: Two-Intercept Form]], $\mathcal L$ can be expressed in the form: :$(1): \quad \dfrac x a + \dfrac y a = 1$ Then: {{begin-eqn}} {{eqn | l = p | r = a \cos \alpha | c = {{Defof|Cosine of Angle}} }} {{eqn | ll= \leadsto | l = a | r = \dfrac p {\cos \alpha} | c = }} {{end-eqn}} {{begin-eqn}} {{eqn | l = p | r = b \sin \alpha | c = {{Defof|Sine of Angle}} }} {{eqn | ll= \leadsto | l = b | r = \dfrac p {\sin \alpha} | c = }} {{end-eqn}} Substituting for $a$ and $b$ in $(1)$: {{begin-eqn}} {{eqn | l = \dfrac x a + \dfrac y a | r = 1 | c = }} {{eqn | ll= \leadsto | l = \dfrac {x \cos \alpha} p + \dfrac {y \sin \alpha} p | r = 1 | c = }} {{eqn | ll= \leadsto | l = x \cos \alpha + y \sin \alpha | r = p | c = }} {{end-eqn}} {{Qed}}	0
Let $A$ be a [[Definition:Commutative and Unitary Ring|commutative ring with unity]]. Let $\left\{ {M_i}\right\}_{i \in I}$ be a [[Definition:Indexed Family|family]] of [[Definition:Module|$A$-modules]] [[Definition:Indexing Set|indexed]] by $I$. Let $\displaystyle M = \bigoplus_{i \mathop \in I} M_i$ be their [[Definition:Module Direct Sum|direct sum]]. Then $M$ is a [[Definition:Module|module]].	0
The [[Definition:Taxicab Norm|taxicab norm]] is a [[Definition:Norm on Vector Space|norm]] on the [[Definition:Real Number|real]] and [[Definition:Complex Number|complex numbers]].	0
This follows by [[Principle of Mathematical Induction|induction]] from {{Module-axiom|1}}, as follows: For all $m \in \N_{>0}$, let $\map P m$ be the [[Definition:Proposition|proposition]]: :$\ds \lambda \circ \paren {\sum_{k \mathop = 1}^m x_k} = \sum_{k \mathop = 1}^m \paren {\lambda \circ x_k}$ === Basis for the Induction === $\map P 1$ is true, as this just says: :$\lambda \circ x_1 = \lambda \circ x_1$ This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P n$ is true, where $n \ge 1$, then it logically follows that $\map P {n + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\ds \lambda \circ \paren {\sum_{k \mathop = 1}^n x_k} = \sum_{k \mathop = 1}^n \paren {\lambda \circ x_k}$ Then we need to show: :$\ds \lambda \circ \paren {\sum_{k \mathop = 1}^{n + 1} x_k} = \sum_{k \mathop = 1}^{n + 1} \paren {\lambda \circ x_k}$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \lambda \circ \paren {\sum_{k \mathop = 1}^{n + 1} x_k} | r = \lambda \circ \paren {\sum_{k \mathop = 1}^n x_k + x_{n + 1} } | c = }} {{eqn | r = \lambda \circ \paren {\sum_{k \mathop = 1}^n x_k} + \lambda \circ x_{n + 1} | c = {{Module-axiom|1}} }} {{eqn | r = \sum_{k \mathop = 1}^n \paren {\lambda \circ x_k} + \lambda \circ x_{n + 1} | c = [[Scalar Product with Sum#Induction Hypothesis|Induction hypothesis]] }} {{eqn | r = \sum_{k \mathop = 1}^{n + 1} \paren {\lambda \circ x_k} | c = }} {{end-eqn}} So $\map P n \implies \map P {n + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\ds \forall m \in \N_{>0}: \lambda \circ \paren {\sum_{k \mathop = 1}^m x_k} = \sum_{k \mathop = 1}^m \paren {\lambda \circ x_k}$ {{qed}}	0
Let $\struct {X, \norm {\, \cdot \,}}$ be a [[Definition:Normed Vector Space|normed vector space]]. Let $\displaystyle \sum_{n \mathop = 1}^\infty a_n$ be an [[Definition:Absolutely Convergent Series|absolutely convergent series]] in $X$. Then $\displaystyle \sum_{n \mathop = 1}^\infty a_n$ is [[Definition:Convergent Series|convergent]] {{iff}} $X$ is a [[Definition:Banach Space|Banach space]].	0
Let $R$ be a [[Definition:Division Ring|division ring]]. Let $\norm {\, \cdot \,}_1: R \to \R_{\ge 0}$ and $\norm {\, \cdot \,}_2: R \to \R_{\ge 0}$ be [[Definition:Norm on Division Ring|norms]] on $R$. Let $d_1$ and $d_2$ be the [[Definition:Metric Induced by Norm|metrics induced]] by the [[Definition:Norm on Division Ring|norms]] $\norm {\, \cdot \,}_1$ and $\norm {\, \cdot \,}_2$ respectively. {{TFAE|def = Equivalent Division Ring Norms}}	0
Let $\struct {R, +, \circ}$ be a [[Definition:Commutative and Unitary Ring|commutative ring with unity]] whose [[Definition:Ring Zero|zero]] is $0_R$ and whose [[Definition:Unity of Ring|unity]] is $1_R$. Then $\struct {R, +, \circ}$ is a [[Definition:Field (Abstract Algebra)|field]] {{iff}} the only [[Definition:Ideal of Ring|ideals]] of $\struct {R, +, \circ}$ are $\struct {R, +, \circ}$ and $\set {0_R}$.	0
Let $\mathbf A = \sqbrk a_n$ and $\mathbf B = \sqbrk b_n$ be [[Definition:Square Matrix|square matrices]] of [[Definition:Order of Square Matrix|order]] $n$. Let $\mathbf A$ and $\mathbf B$ be [[Definition:Similar Matrices|similar]]. Then: :$\map \tr {\mathbf A} = \map \tr {\mathbf B}$ where $\map \tr {\mathbf A}$ denotes the [[Definition:Trace of Matrix|trace]] of $\mathbf A$.	0
Let $\struct {R, \norm {\, \cdot \,} }$ be a [[Definition:Normed Division Ring|normed division ring]]. Let $\CC$ be the [[Definition:Ring of Cauchy Sequences|ring of Cauchy sequences over $R$]] Let $\phi: R \to \CC$ be the [[Definition:Mapping|mapping]] from $R$ to $\CC$ defined as: :$\forall a \in R: \map \phi a = \tuple {a, a, a, \dots}$ where $\tuple {a, a, a, \dots}$ is the [[Definition:Constant Sequence|constant sequence]]. Then $\phi$ is a [[Definition:Ring Monomorphism|ring monomorphism]].	0
Let $\mathbb K$ be a [[Definition:Field (Abstract Algebra)|field]]. Let $V$ be a [[Definition:Vector Space|vector space]] over $\mathbb K$. Let $b$ be a [[Definition:Bilinear Form|bilinear form]] on $V$. Let $b$ be [[Definition:Alternating Bilinear Form|alternating]]. Then $b$ is [[Definition:Reflexive Bilinear Form|reflexive]].	0
Let $R$ be a [[Definition:Ring with Unity|ring with unity]]. Let $I$ be a [[Definition:Set|set]]. Let $R^{\paren I}$ be the [[Definition:Free Module on Set|free $R$-module on $I$]]. Then $R^{\paren I}$ is a [[Definition:Free Module|free $R$-module]].	0
From [[Negative of Triangular Matrix]], if $\mathbf B \in \map {U_R} n$ then $-\mathbf B \in \map {U_R} n$. Then from [[Sum of Triangular Matrices]], if $\mathbf A, -\mathbf B \in \map {U_R} n$ then $\mathbf A + \paren {-\mathbf B} \in \map {U_R} n$. From [[Product of Triangular Matrices]], if $\mathbf A, \mathbf B \in \map {U_R} n$ then $\mathbf A \mathbf B \in \map {U_R} n$. The result follows from the [[Subring Test]]. The same argument can be applied to matrices in $\map {L_R} n$. {{qed}}	0
=== Non-Vertical Tangent Lines === From [[Equation of Circle]], $\mathcal C$ can be described on the [[Definition:Cartesian Plane|$x y$-plane]] in the form: :$\paren {x - a}^2 + \paren {y - b}^2 = r^2$ where $P = \tuple {a, b}$ is the [[Definition:Center of Circle|center of the circle]] and $r$ is the [[Definition:Radius of Circle|radius]]. We use the definition of the [[Definition:Derivative|derivative]] as the [[Definition:Gradient|gradient]] of the [[Definition:Tangent to Curve|tangent line]] $\mathcal T$. Taking the [[Definition:Derivative|derivative]] {{WRT|Differentiation}} $x$ of both sides of the equation we get: {{begin-eqn}} {{eqn | l = 2 \paren {x - a} + 2 \paren {y - b} \frac {\d y} {\d x} | r = 0 | c = [[Derivative of Constant]], [[Chain Rule for Derivatives]], [[Power Rule for Derivatives]] }} {{eqn | ll= \leadsto | l = \frac {\d y} {\d x} | r = \frac {a - x} {y - b} | c = }} {{end-eqn}} This is the [[Definition:Gradient|slope]] at any [[Definition:Point|point]] on $\mathcal C$. From the [[Equation of Straight Line in Plane/Slope-Intercept Form|slope-intercept form]] of a [[Definition:Straight Line|line]], the equation of such a line is: :$y - y_n = m \paren {x - x_n}$ given any point $\paren {x_n, y_n}$ and the [[Definition:Gradient|gradient]] $m$. For $\mathcal T$: :$m = \left.{\dfrac {\d y} {\d x} }\right\vert^{x = x_n}_{y = y_n}$ Thus the equation of $\mathcal T$ is: :$y - y_n = \dfrac {a - x_n} {y_n - b} \paren {x - x_n}$ {{qed|lemma}} === Vertical Tangent Lines === {{ProofWanted|by the [[Infinite Limit Theorem]]}}	0
Let $\struct {\Q, \tau_d}$ be the [[Definition:Rational Number Space|rational number space]] under the [[Definition:Euclidean Topology on Real Number Line|Euclidean topology]] $\tau_d$. Then $\struct {\Q, \tau_d}$ is [[Definition:Separable Space|separable]].	0
Let: :$V_n = \begin{vmatrix} 1 & x_1 & x_1^2 & \cdots & x_1^{n - 2} & x_1^{n - 1} \\ 1 & x_2 & x_2^2 & \cdots & x_2^{n - 2} & x_2^{n - 1} \\ \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\ 1 & x_n & x_n^2 & \cdots & x_n^{n - 2} & x_n^{n - 1} \end{vmatrix}$ Let $\map f x$ be '''any''' [[Definition:Monic Polynomial|monic polynomial]] of [[Definition:Degree of Polynomial|degree]] $n - 1$: :$\ds \map f x = x^{n - 1} + \sum_{i \mathop = 0}^{n - 2} a_i x^i$ Apply [[Effect of Elementary Row Operations on Determinant|elementary column operations]] to $V_n$ repeatedly to show: :$V_n = W$ where: :$ W = \begin{vmatrix} 1 & x_1 & x_1^2 & \cdots & x_1^{n - 2} & \map f {x_1} \\ 1 & x_2 & x_2^2 & \cdots & x_2^{n - 2} & \map f {x_2} \\ \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\ 1 & x_n & x_n^2 & \cdots & x_n^{n - 2} & \map f {x_n} \end{vmatrix}$ Select a specific degree $n - 1$ monic polynomial: :$\ds \map f x = \prod_{k \mathop = 1}^{n - 1} \paren {x - x_k}$ The selected polynomial is zero at all values $x_1, \ldots, x_{n - 1}$. Then the last column of $W$ is all zeros except the entry $\map f {x_n}$. Expand $\map \det W$ by cofactors along the last column to prove: {{begin-eqn}} {{eqn | n = 1 | l = V_n | r = \map f {x_n} V_{n - 1} | c = [[Expansion Theorem for Determinants]] for columns }} {{eqn | r = V_{n - 1} \prod_{k \mathop = 1}^{n - 1} \paren {x_n - x_k} }} {{end-eqn}} For $n \ge 2$, let $\map P n$ be the statement: :$\ds V_n = \prod_{1 \mathop \le i \mathop < j \mathop \le n} \paren {x_j - x_i}$ [[Definition:Mathematical Induction|Mathematical induction]] will be applied. === Basis for the Induction === By definition, determinant $V_1 = 1$. To prove $\map P 2$ is true, use equation $(1)$ with $n = 2$: :$V_2 = \paren {x_2 - x_1} V_1$ This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Step === This is the [[Definition:Induction Step|induction step]]: Let $\map P n$ is be assumed true. We are to prove that $\map P {n + 1}$ is true. As follows: {{begin-eqn}} {{eqn | l = V_{n + 1} | r = V_n \prod_{k \mathop = 1}^n \paren {x_{n + 1} - x_k} | c = from $(1)$, setting $n \to n + 1$ }} {{eqn | r = \prod_{1 \mathop \le m \mathop < k \mathop \le n} \paren {x_k - x_m} \prod_{k \mathop = 1}^n \paren {x_{n + 1} - x_k} | c = [[Vandermonde Determinant/Proof 4#Induction Hypothesis|Induction hypothesis]] with new indexing symbols: $i \to m, j \to k$ }} {{eqn | r = \prod_{1 \mathop \le i \mathop < j \mathop \le n + 1} \paren {x_j - x_i} | c = simplifying }} {{end-eqn}} Thus $\map P {n + 1}$ has been shown to be true. The induction is complete. {{qed}}	0
Let $b = 0$. From [[Primitive of Reciprocal of a x squared plus b x plus c]], we have: :$\displaystyle \int \frac {\mathrm d x} {a x^2 + b x + c} = \begin{cases} \dfrac 2 {\sqrt {4 a c - b^2} } \arctan \left({\dfrac {2 a x + b} {\sqrt {4 a c - b^2} } }\right) + C & : b^2 - 4 a c < 0 \\ \dfrac 1 {\sqrt {b^2 - 4 a c} } \ln \left\vert{\dfrac {2 a x + b - \sqrt {b^2 - 4 a c} } {2 a x + b + \sqrt {b^2 - 4 a c} } }\right\vert + C & : b^2 - 4 a c > 0 \\ \dfrac {-2} {2 a x + b} + C & : b^2 = 4 a c \end{cases}$ Let $a c > 0$. Then $b^2 - 4 a c = 0 - 4 a c < 0$ and so: {{begin-eqn}} {{eqn | l = \int \frac {\mathrm d x} {a x^2 + 0 x + c} | r = \frac 2 {\sqrt {4 a c - 0^2} } \arctan \left({\frac {2 a x + 0} {\sqrt {4 a c - 0^2} } }\right) + C | c = }} {{eqn | r = \frac 2 {\sqrt {4 a c} } \arctan \left({\frac {2 a x} {\sqrt {4 a c} } }\right) + C | c = }} {{eqn | r = \frac 1 {\sqrt {a c} } \arctan \left({x \sqrt {\dfrac a c} }\right) + C | c = simplifying }} {{end-eqn}} {{qed|lemma}} Let $a c < 0$. Then $b^2 - 4 a c = 0 - 4 a c > 0$ and so: {{begin-eqn}} {{eqn | l = \int \frac {\mathrm d x} {a x^2 + 0 x + c} | r = \frac 1 {\sqrt {0^2 - 4 a c} } \ln \left\vert{\frac {2 a x + 0 - \sqrt {0^2 - 4 a c} } {2 a x + 0 + \sqrt {0^2 - 4 a c} } }\right\vert + C | c = }} {{eqn | r = \frac 1 {\sqrt {- 4 a c} } \ln \left\vert{\frac {2 a x - \sqrt {- 4 a c} } {2 a x + \sqrt {- 4 a c} } }\right\vert + C | c = }} {{eqn | r = \dfrac 1 {2 \sqrt {-a c} } \ln \left\vert{\dfrac {a x - \sqrt {-a c} } {a x + \sqrt {-a c} } }\right\vert + C | c = simplifying }} {{end-eqn}} {{qed|lemma}} Let $c = 0$. Then $b^2 - 4 a c = 0 - 0 = 0$ and so: {{begin-eqn}} {{eqn | l = \int \frac {\mathrm d x} {a x^2 + 0 x + 0} | r = \frac {-2} {2 a x + 0} + C | c = }} {{eqn | r = \frac {-1} {a x} + C | c = }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \dfrac 1 {\paren {1 - z}^2} | r = \sum_{n \mathop = 0}^\infty \paren {n + 1} z^n }} {{eqn | r = 1 + 2 z + 3 z^2 + 4 z^3 + \cdots }} {{end-eqn}}	0
The [[Definition:Positive Integer|positive]] [[Definition:Even Integer|even integers]] which cannot be expressed as the [[Definition:Integer Addition|sum]] of $2$ [[Definition:Composite Number|composite]] [[Definition:Odd Integer|odd numbers]] are: :$2, 4, 6, 8, 10, 12, 14, 16, 20, 22, 26, 28, 32, 38$ {{OEIS|A118081}}	0
:$\displaystyle \int_0^\infty \frac {\cos a x} {\cosh b x} \rd x = \frac \pi {2 b} \sech \frac {a \pi} {2 b}$	0
The [[Definition:Set|set]] of [[Definition:Integer|integers]] under [[Definition:Integer Multiplication|multiplication]] $\struct {\Z, \times}$ has a [[Definition:Zero Element|zero element]], which is $0$.	0
Let $\epsilon > 0$. We need to show that there exists $N$ such that: :$\forall n > N: \size {\paren {\size {x_n - l} - 0} } < \epsilon$ But: :$\size {\paren {\size {x_n - l} - 0} } = \size {x_n - l}$ So what needs to be shown is just: :$x_n \to l$ as $n \to \infty$ which is the definition of $\displaystyle \lim_{n \mathop \to \infty} x_n = l$. {{qed}}	0
Let $\struct {\Q, \tau_d}$ be the [[Definition:Rational Number Space|rational number space]] under the [[Definition:Euclidean Topology on Real Number Line|usual (Euclidean) topology]] $\tau_d$. Let $B_\alpha$ denote the [[Definition:Singleton|singleton]] containing the [[Definition:Rational Number|rational number]] $\alpha$. Then the [[Definition:Set Union|union]] of the [[Definition:Closure (Topology)|closures]] in the [[Definition:Set|set]] of [[Definition:Real Number|real numbers]] $\R$ of all $B_\alpha$ is $\Q$: :$\displaystyle \bigcup_{\alpha \mathop \in \Q} \map \cl {B_\alpha} = \Q$	0
For every $n$ greater than $23$, there exists a [[Definition:Binomial Coefficient|binomial coefficient]] $\dbinom n k$ that is not [[Definition:Square-Free Integer|square-free]]. More specifically, the list of numbers $n$ such that $\dbinom n k$ are squarefree for all $k = 0, \dots, n$ is given by: :$1, 2, 3, 5, 7, 11, 23$ {{OEIS|A048278}}	0
{{begin-eqn}} {{eqn | l = \dfrac 1 2 \paren {\mathbf c + \mathbf d} | r = \dfrac 1 2 \paren {\paren {\mathbf a + \mathbf b} + \paren {\mathbf a - \mathbf b} } | c = }} {{eqn | r = \dfrac 1 2 \paren {\mathbf a + \mathbf b + \mathbf a - \mathbf b} | c = }} {{eqn | r = \dfrac 1 2 \paren {2 \mathbf a} | c = }} {{eqn | r = \mathbf a | c = }} {{end-eqn}} {{begin-eqn}} {{eqn | l = \dfrac 1 2 \paren {\mathbf c - \mathbf d} | r = \dfrac 1 2 \paren {\paren {\mathbf a + \mathbf b} - \paren {\mathbf a - \mathbf b} } | c = }} {{eqn | r = \dfrac 1 2 \paren {\mathbf a + \mathbf b - \mathbf a + \mathbf b} | c = }} {{eqn | r = \dfrac 1 2 \paren {2 \mathbf b} | c = }} {{eqn | r = \mathbf b | c = }} {{end-eqn}} {{qed}}	0
Let: {{begin-eqn}} {{eqn | l = m | r = {p_1}^{k_1} {p_2}^{k_2} \dotsm {p_r}^{k_r} }} {{eqn | l = n | r = {p_1}^{l_1} {p_2}^{l_2} \dotsm {p_r}r^{l_r} | c = }} {{end-eqn}} From [[LCM from Prime Decomposition]]: :$\lcm \set {m, n} = p_1^{\max \set {k_1, l_1} } p_2^{\max \set {k_2, l_2} } \dotsm p_r^{\max \set {k_r, l_r} }$ From [[GCD from Prime Decomposition]]: :$\gcd \set {m, n} = p_1^{\min \set {k_1, l_1} } p_2^{\min \set {k_2, l_2} } \dotsm p_r^{\min \set {k_r, l_r} }$ From [[Sum of Maximum and Minimum]], for all $i \in \set {1, 2, \ldots, r}$: :$\min \set {k_i, l_i} + \max \set {k_i, l_i} = k_i + l_i$ Hence: {{begin-eqn}} {{eqn | l = \gcd \set {m, n} \times \lcm \set {m, n} | r = p_1^{k_1 + l_1} p_2^{k_2 + l_2} \dotsm p_r^{k_r + l_r} | c = }} {{eqn | r = p_1^{k_1} p_1^{l_1} p_2^{k_2} p_2^{l_2} \dotsm p_r^{k_r} p_r^{l_r} | c = }} {{eqn | r = p_1^{k_1} p_2^{k_2} \dotsm p_r^{k_r} \times p_1^{l_1} p_2^{l_2} \dotsm p_r^{l_r} | c = }} {{eqn | r = m n | c = }} {{end-eqn}} {{qed}}	0
This page gathers together [[Definition:Derivative|derivatives]] of [[Definition:Inverse Trigonometric Function|inverse trigonometric functions]].	0
:$\displaystyle \int_0^1 \frac {x^m - x^n} {\ln x} \rd x = \map \ln {\frac {m + 1} {n + 1} }$	0
We need to check that all of [[Axiom:Peano's Axioms|Peano's axioms]] hold for $\left({\omega, \cdot^+, \varnothing}\right)$. Suppose first that for $m, n \in \omega$, we have $m^+ = n^+$. Since $n \in n^+$ it follows that $n \in m^+$. Hence, either $n \in m$ or $n = m$. Similarly, either $m \in n$ or $m = n$. Now if $n \ne m$, both $m \in n$ and $n \in m$. By [[Element of Minimal Infinite Successor Set is Transitive Set]], it follows that $n \subseteq m$. As $m \in n$, this contradicts [[Finite Ordinal is not Subset of one of its Elements]]. Hence it must be that $n = m$, and [[Axiom:Peano's Axioms|Axiom $(P3)$]] holds. Next, since $n \in n^+$ for all $n \in \omega$, it follows that $n^+ \ne \varnothing$. Hence, [[Axiom:Peano's Axioms|Axiom $(P4)$]] holds as well. Finally, let $S \subseteq \omega$ satisfy: :$\varnothing \in S$ :$\forall n \in S: n^+ \in S$ Then by definition, $S$ is an [[Definition:Infinite Successor Set|infinite successor set]]. Therefore, by definition of $\omega$ as the [[Definition:Minimal Infinite Successor Set|minimal infinite successor set]]: :$\omega \subseteq S$ Consequently $S = \omega$ by the definition of [[Definition:Set Equality/Definition 2|set equality]]. Thus [[Axiom:Peano's Axioms|Axiom $(P5)$]] is seen to hold. That is, $\left({\omega, \cdot^+, \varnothing}\right)$ is a [[Definition:Peano Structure|Peano structure]]. {{qed}}	0
Let $n$ be a [[Definition:Number|number]] expressed in a particular [[Definition:Number Base|number base]], $b$ for example. Then $n$ can be expressed as: :$\sqbrk {r_m r_{m - 1} \ldots r_2 r_1 r_0 . r_{-1} r_{-2} \ldots}_b$ where: :$m$ is such that $b^m \le n < b^{m+1}$; :all the $r_i$ are such that $0 \le r_i < b$. Each of the $r_i$ are known as the '''digits of $n$ (base $b$)'''.	0
:$e^x \ge 1 + x$ for all $x \in \R$.	0
The [[Definition:Canonical Form of Rational Number|canonical form]] of a [[Definition:Rational Number|rational number]] is [[Definition:Unique|unique]].	0
Let $n \Z$ be the [[Definition:Set of Integer Multiples|set of integer multiples]] of $n$. Then $\struct {n \Z, +, \times}$ is a [[Definition:Commutative Ring|commutative ring]]. Unless $n = 1$, $\struct {n \Z, +, \times}$ is not a [[Definition:Ring with Unity|ring with unity]].	0
The [[Definition:Plastic Constant|plastic constant]] $P$ is evaluated as: {{begin-eqn}} {{eqn | l = P | r = \sqrt [3] {\frac {9 + \sqrt {69} } {18} } + \sqrt [3] {\frac {9 - \sqrt {69} } {18} } | c = }} {{eqn | r = 1 \cdotp 32471 \, 79572 \, 44746 \, 02596 \, 09088 \, 54 \ldots | c = }} {{end-eqn}}	0
For every pair of [[Definition:Integer|integers]] $a, b$ where $b > 0$, there exist [[Definition:Integer|integers]] $q, r$ such that $a = q b + r$ and $0 \le r < b$: :$\forall a, b \in \Z, b > 0: \exists q, r \in \Z: a = q b + r, 0 \le r < b$	0
We use the definition of the [[Definition:Natural Logarithm|natural logarithm]] as an [[Definition:Natural Logarithm/Positive Real/Definition 1|integral]]: :$\displaystyle \ln x = \int_1^x \frac {\mathrm d t} t$ From [[Integral on Zero Interval]]: :$\displaystyle \ln 1 = \int_1^1 \frac {\mathrm d t} t = 0$ {{qed}}	0
This result can be split into two parts: === [[Division Theorem/Positive Divisor/Positive Dividend/Existence|Proof of Existence]] === {{:Division Theorem/Positive Divisor/Positive Dividend/Existence}} === [[Division Theorem/Positive Divisor/Positive Dividend/Uniqueness|Proof of Uniqueness]] === {{:Division Theorem/Positive Divisor/Positive Dividend/Uniqueness}} [[Category:Division Theorem]] 5mooiyv6ltjxhds9a5ijyjvoog14knh	0
Let $a$ be a [[Definition:Composite Number|composite number]]. Then there exists a [[Definition:Prime Number|prime number]] $p$ such that: :$p \divides a$ where $\divides$ means '''is a [[Definition:Divisor of Integer|divisor]] of'''. {{:Euclid:Proposition/VII/31}}	0
We know that [[Terms in Convergent Series Converge to Zero]]. This is the [[Definition:Contrapositive Statement|contrapositive statement]] of this theorem. Thus, the theorem holds by [[Rule of Transposition]]. {{qed}}	0
Let $U$ be an [[Definition:Open Set (Complex Analysis)|open subset]] of $\C$. Let $\left\langle{f_n}\right\rangle_{n \mathop \in \N}$ be a [[Definition:Sequence|sequence]] of [[Definition:Analytic Function|analytic functions]] $f_n : U \to \C$. Let $\left\langle{f_n}\right\rangle$ [[Definition:Locally Uniform Convergence|converge locally uniformly]] to $f$ on $U$. Then the [[Definition:Sequence|sequence]] $\left\langle{f_n'}\right\rangle_{n \mathop \in \N}$ [[Definition:Locally Uniform Convergence|converges locally uniformly]] to $f'$.	0
:$\displaystyle \int \frac {\d x} {1 + \sin a x} = -\frac 1 a \map \tan {\frac \pi 4 - \frac {a x} 2} + C$	0
Let $n$ be an [[Definition:Integer|integer]] such that $n \ge 2$. Let the [[Definition:Prime Decomposition|prime decomposition]] of $n$ be: :$n = p_1^{k_1} p_2^{k_2} \ldots p_r^{k_r}$ Then from [[Sigma Function of Integer]] we have that: : $\displaystyle \sigma \left({n}\right) = \prod_{1 \mathop \le i \mathop \le r} \frac {p_i^{k_i + 1} - 1} {p_i - 1}$ That is: : $\displaystyle \sigma \left({n}\right) = \prod_{1 \mathop \le i \mathop \le r} \left({1 + p_i + p_i^2 + \ldots + p_i^{k_i}}\right)$ Let $\sigma \left({n}\right)$ be [[Definition:Odd Integer|odd]]. Then all factors of $\displaystyle \prod_{i \mathop = 1}^r \left({1 + p_i + p_i^2 + \ldots + p_i^{k_i}}\right)$ are [[Definition:Odd Integer|odd]] (and of course $\ge 3$). For $1 + p_i + p_i^2 + \ldots + p_i^{k_i}$ to be odd, one of two conditions must hold: : $p_i$ is [[Definition:Even Integer|even]] (so that all terms of $1 + p_i + p_i^2 + \ldots + p_i^{k_i}$ are even except the $1$); : $k_i$ is even (so that $1 + p_i + p_i^2 + \ldots + p_i^{k_i}$ has an odd number of odd terms). In the first case, that means $p_i^{k_i}$ is a power of $2$. In the second case, that means $p_i^{k_i}$ is a [[Definition:Square Number|square]]. The result follows. The argument reverses. {{qed}} [[Category:Square Numbers]] [[Category:Sigma Function]] 1r15nrfitzxoo9w1hh0p2kez3vvryz5	0
For every pair of [[Definition:Integer|integers]] $a, b$ where $b > 0$, there exist [[Definition:Integer|integers]] $q, r$ such that $a = q b + r$ and $0 \le r < b$: :$\forall a, b \in \Z, b > 0: \exists q, r \in \Z: a = q b + r, 0 \le r < b$	0
Let $x \in \R$ be a [[Definition:Real Number|real number]]. Then: :$x - x = 0$ where $x - x$ denotes the operation of [[Definition:Real Subtraction|real subtraction]].	0
That no [[Definition:Rational Number|rational number]] such that $x \ge \dfrac {\pi^2} 6 - 1$ can be so expressed follows from [[Riemann Zeta Function of 2]]: :$\displaystyle \sum_{n \mathop = 1}^n \dfrac 1 {n^2} = 1 + \dfrac 1 {2^2} + \dfrac 1 {3^2} + \dotsb = \dfrac {\pi^2} 6$ That is, using ''all'' the [[Definition:Reciprocal|reciprocals]] of [[Definition:Distinct Objects|distinct]] [[Definition:Square Number|squares]], you can never get as high as $\dfrac {\pi^2} 6 - 1$. It remains to be shown that for all [[Definition:Rational Number|rational numbers]] $x$ less than $\dfrac {\pi^2} 6 - 1$, you can make $x$ with a [[Definition:Subset|subset]] of them. {{ProofWanted}}	0
With a view to expressing the [[Definition:Primitive|primitive]] in the form: :$\displaystyle \int u \frac {\mathrm d v}{\mathrm d x} \ \mathrm d x = u v - \int v \frac {\mathrm d u}{\mathrm d x} \ \mathrm d x$ let: {{begin-eqn}} {{eqn | l = u | r = x | c = }} {{eqn | ll= \implies | l = \frac {\mathrm d u} {\mathrm d x} | r = 1 | c = [[Derivative of Identity Function]] }} {{end-eqn}} and let: {{begin-eqn}} {{eqn | l = \frac {\mathrm d v} {\mathrm d x} | r = \csc^2 a x | c = }} {{eqn | ll= \implies | l = v | r = \frac {-\cot a x} a | c = [[Primitive of Square of Cosecant of a x|Primitive of $\csc^2 a x$]] }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = \int x \csc^2 a x \ \mathrm d x | r = \frac {-x \cot a x} a - \int \frac {-\cot a x} a \ \mathrm d x + C | c = [[Integration by Parts]] }} {{eqn | r = \frac {-x \cot a x} a + \frac 1 a \int \cot a x \ \mathrm d x + C | c = [[Primitive of Constant Multiple of Function]] }} {{eqn | r = \frac {-x \cot a x} a + \frac 1 a \left({\frac 1 a \ln \left\vert{\sin a x}\right\vert}\right) + C | c = [[Primitive of Cotangent of a x|Primitive of $\cot a x$]] }} {{eqn | r = \frac {-x \cot a x} a + \frac 1 {a^2} \ln \left\vert{\sin a x}\right\vert + C | c = simplifying }} {{end-eqn}} {{qed}}	0
{{ProofWanted|Some sort of computer program can be implemented, I suppose}}	0
:$\displaystyle \int \frac {x^2 \rd x} {a^2 - x^2} = -x + \frac a 2 \map \ln {\frac {a + x} {a - x} } + C$ for $x^2 < a^2$.	0
From [[Number to Reciprocal Power is Decreasing]] we have that the [[Definition:Real Sequence|real sequence]] $\sequence {n^{1/n} }$ is [[Definition:Decreasing Real Sequence|decreasing]] for $n \ge 3$. Now, as $n^{1 / n} > 0$ for all [[Definition:Positive Integer|positive]] $n$, it follows that $\sequence {n^{1 / n} }$ is [[Definition:Bounded Below Real Sequence|bounded below]] (by $0$, for a start). Thus the [[Definition:Subsequence|subsequence]] of $\sequence {n^{1 / n} }$ consisting of all the [[Definition:Term of Sequence|terms]] of $\sequence {n^{1 / n} }$ where $n \ge 3$ is [[Definition:Convergent Real Sequence|convergent]] by the [[Monotone Convergence Theorem (Real Analysis)]]. Now we need to demonstrate that this [[Definition:Limit of Real Sequence|limit]] is in fact $1$. Let $n^{1 / n} \to l$ as $n \to \infty$. Having established this, we can investigate the [[Definition:Subsequence|subsequence]] $\sequence {\paren {2 n}^{1 / {2 n} } }$. By [[Limit of Subsequence equals Limit of Real Sequence]], this will converge to $l$ also. From [[Limit of Root of Positive Real Number]], we have that $2^{1 / {2 n} } \to 1$ as $n \to \infty$. So $n^{1 / {2 n} } \to l$ as $n \to \infty$ by the [[Combination Theorem for Sequences]]. Thus: :$n^{1 / n} = n^{1 / {2 n} } \cdot n^{1 / {2 n} } \to l \cdot l = l^2$ as $n \to \infty$. So $l^2 = l$, and as $l \ge 1$ the result follows. {{qed}}	0
The proof will proceed by the [[Principle of Mathematical Induction]] on $\N$. Let $T$ be the [[Definition:Set|set]] defined as: :$\displaystyle T := \set {n \in \N: \bigoplus_{k \mathop = 1}^n a_k = \oplus^n a}$ First, recall the definition of the [[Definition:Composite (Abstract Algebra)|composite]] of $\tuple {a_1, a_2, \ldots, a_n}$ for $\oplus$: :$\displaystyle \bigoplus_{k \mathop = 1}^n a_k = \begin{cases} a: & n = 1 \\ \map {\oplus_m} {a_1, \ldots, a_m} \oplus a_{m + 1}: & n = m + 1 \end{cases}$ Secondly, recall the definition of the [[Definition:Power of Element of Semigroup|$n$th power of $a$ under $\oplus$]]: :$\forall n \in \N_{>0}: \oplus^n a = \begin{cases} a & : n = 1 \\ \paren {\oplus^m a} \oplus a & : n = m + 1 \end{cases}$ === Basis for the Induction === We have that: {{begin-eqn}} {{eqn | l = \bigoplus_{k \mathop = 1}^1 a_k | r = a_1 | c = {{Defof|Composite (Abstract Algebra)|Composite}} of $\paren {a_1}$ }} {{eqn | r = a | c = Definition of $\tuple {a_1, a_2, \ldots, a_n}$: $\forall k \in \N_n: a_k = a$ }} {{eqn | r = \oplus^1 a | c = {{Defof|Power of Element of Semigroup}} }} {{end-eqn}} So $1 \in T$. This is our [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === It is to be shown that, if $j \in T$ where $j \ge 1$, then it follows that $j + 1 \in T$. This is the [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$\displaystyle \bigoplus_{k \mathop = 1}^j a_k = \oplus^j a$ It is to be demonstrated that it follows that: :$\displaystyle \bigoplus_{k \mathop = 1}^{j + 1} a_k = \oplus^{j + 1} a$ === Induction Step === This is our [[Principle of Mathematical Induction#Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \bigoplus_{k \mathop = 1}^{j + 1} a_k | r = \map {\oplus_j} {a_1, \ldots, a_j} \oplus a_{j + 1} | c = Definition of [[Definition:Composite (Abstract Algebra)|Composite]] of $\left({a_1, \ldots, a_j, a_{j+1} }\right)$ }} {{eqn | r = \paren {\bigoplus_{k \mathop = 1}^j a_k} \oplus a_{j + 1} | c = {{Defof|Composite (Abstract Algebra)|Composite}} of $\tuple {a_1, \ldots, a_j}$ }} {{eqn | r = \paren {\oplus^j a} \oplus a_{j + 1} | c = [[Power of Element/Semigroup#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \paren {\oplus^j a} \oplus a | c = Definition of $\tuple {a_1, a_2, \ldots, a_{j + 1} }$: $\forall k \in \N_{j + 1}: a_k = a$ }} {{eqn | r = \oplus^{j + 1} a | c = {{Defof|Power of Element of Semigroup}} }} {{end-eqn}} So $k \in T \implies k + 1 \in T$ and the result follows by the [[Principle of Mathematical Induction]]: :$\displaystyle \forall n \in \N: \bigoplus_{k \mathop = 1}^n a_k = \oplus^n a$	0
{{begin-eqn}} {{eqn | l = \cos^4 x | r = \left({\cos^2 x}\right)^2 }} {{eqn | r = \left({\frac {1 + \cos 2 x} 2}\right)^2 | c = [[Square of Cosine]] }} {{eqn | r = \frac {1 + 2 \cos 2 x + \cos^2 2 x} 4 | c = multiplying out }} {{eqn | r = \frac {1 + 2 \cos 2 x + \frac {1 + \cos 4 x} 2} 4 | c = [[Square of Cosine]] }} {{eqn | r = \frac {2 + 4 \cos 2 x + 1 + \cos 4 x} 8 | c = multiplying top and bottom by $2$ }} {{eqn | r = \frac {3 + 4 \cos 2 x + \cos 4 x} 8 | c = rearrangement }} {{end-eqn}} {{qed}}	0
:$\sin 225 \degrees = \sin \dfrac {5 \pi} 4 = -\dfrac {\sqrt 2} 2$	0
{{begin-eqn}} {{eqn | l = \sin \paren {a + b i} | r = \sin a \cos \paren {b i} + \cos a \sin \paren {b i} | c = [[Sine of Sum]] }} {{eqn | r = \sin a \cosh b + \cos a \sin \paren {b i} | c = [[Hyperbolic Cosine in terms of Cosine]] }} {{eqn | r = \sin a \cosh b + i \cos a \sinh b | c = [[Hyperbolic Sine in terms of Sine]] }} {{end-eqn}} {{qed}}	0
Let $T = \left({S, \tau}\right)$ be a [[Definition:Discrete Space|discrete topological space]]. Let $H = \left \langle{x_n}\right \rangle_{n \in \N}$ be a [[Definition:Sequence|sequence]] in $S$. Then $H$ [[Definition:Convergent Sequence (Topology)|converges]] in $T$ to a [[Definition:Limit Point of Sequence|limit]] [[Definition:Iff|iff]]: :$\exists k \in \N: \forall m \in \N: m > k: x_m = x_k$ That is, [[Definition:Iff|iff]] the sequence reaches some value of $S$ and "stays there".	0
Let $x, y \in \R$ be such that $x < y$. Since $0 < a < 1$, we have that: :$\dfrac 1 a > 1$ Then we have that: {{begin-eqn}} {{eqn | l = \paren {\dfrac 1 a}^x | o = < | r = \paren {\dfrac 1 a}^y | c = [[Real Power Function on Base Greater than One is Strictly Increasing]] }} {{eqn | ll= \leadstoandfrom | l = \dfrac 1 {a^x} | o = < | r = \dfrac 1 {a^y} | c = }} {{eqn | ll= \leadstoandfrom | l = a^x | o = > | r = a^y | c = [[Reciprocal Function is Strictly Decreasing]] }} {{end-eqn}} The result follows. {{qed}} [[Category:Power Function on Base between Zero and One is Strictly Decreasing]] 5b3907fc75dupddxgephkodb55l5y9t	0
:$\displaystyle \int x \left({\sqrt {a^2 - x^2} }\right)^3 \ \mathrm d x = \frac {-\left({\sqrt {a^2 - x^2} }\right)^5} 5 + C$	0
=== Case 1: $a > 1$ === If $a > 1$, then: :$\displaystyle \lim_{x \mathop \to 0} \map f x = 1$ from [[Power Function on Base greater than One tends to One as Power tends to Zero/Rational Number]]. === Case 2: $a = 1$ === If $a = 1$, then: {{begin-eqn}} {{eqn | l = \lim_{x \mathop \to 0} \map f x | r = \lim_{x \mathop \to 0} 1^x | c = Definition of $f$ }} {{eqn | r = \lim_{x \mathop \to 0} 1 | c = [[Exponential with Base One is Constant/Rational Number]] }} {{eqn | r = 1 | c = [[Real Polynomial Function is Continuous]] }} {{end-eqn}} === Case 3: $0 < a < 1$ === If $0 < a < 1$, then: :$\displaystyle \lim_{x \mathop \to 0} \map f x = 1$ from [[Power Function on Base between Zero and One Tends to One as Power Tends to Zero/Rational Number]]. Hence the result. {{qed}} [[Category:Powers]] 4cfp0fmmaqxg4pnvnse02adeir3ajq5	0
From [[Reduction Formula for Primitive of Power of a x + b by Power of p x + q/Decrement of Power|Reduction Formula for Primitive of Power of $a x + b$ by Power of $p x + q$: Decrement of Power]]: :$\displaystyle \int \paren {a x + b}^m \paren {p x + q}^n \rd x = \frac {\paren {a x + b}^m \paren {p x + q}^{n + 1} } {\paren {m + n + 1} a} + \frac {m \paren {b p - a q} } {\paren {m + n + 1} p} \int \paren {a x + b}^{m - 1} \paren {p x + q}^n \rd x$ Setting $n := -n$: {{begin-eqn}} {{eqn | o = | r = \int \frac {\paren {a x + b}^m} {\paren {p x + q}^n} \rd x | c = }} {{eqn | r = \int \paren {a x + b}^m \paren {p x + q}^{-n} \rd x | c = }} {{eqn | r = \frac {\paren {a x + b}^m \paren {p x + q}^{-n + 1} } {\paren {m - n + 1} p} + \frac {m \paren {b p - a q} } {\paren {m - n + 1} p} \int \paren {a x + b}^{m - 1} \paren {p x + q}^{-n} \rd x | c = }} {{eqn | r = \frac {-1} {\paren {n - m - 1} p} \paren {\frac {\paren {a x + b}^m} {\paren {p x + q}^{n - 1} } + m \paren {b p - a q} \int \frac {\paren {a x + b}^{m - 1} } {\paren {p x + q}^n} \rd x} | c = }} {{end-eqn}} {{qed}}	0
:$1 - \dfrac {x^2} 2 \le \cos x$ for all $x \in \R$.	0
Let $\sequence {f_n}$ be a [[Definition:Sequence|sequence]] of [[Definition:Real Function|real functions]]. Let each of $\sequence {f_n}$ be [[Definition:Continuous on Interval|continuous]] on the [[Definition:Half-Open Real Interval|interval]] $\hointr a b$. {{explain|Investigation needed as to whether there is a mistake in {{BookReference|Special Functions of Mathematics for Engineers|1992|Larry C. Andrews|ed = 2nd|edpage = Second Edition}} -- should it actually be a closed interval?}} Let the [[Definition:Series|series]]: :$\displaystyle \map f x := \sum_{n \mathop = 1}^\infty \map {f_n} x$ be [[Definition:Uniform Convergence|uniformly convergent]] for all $x \in \closedint a b$. Then: :$\displaystyle \int_a^b \map f x \rd x = \sum_{n \mathop = 1}^\infty \int_a^b \map {f_n} x \rd x$	0
Using the [[Axiom:Axiomatization of 1-Based Natural Numbers|following axioms]]: {{:Axiom:Axiomatization of 1-Based Natural Numbers}} Let $x, y \in \N_{> 0}$ be arbitrary. For all $n \in \N_{> 0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\paren {x + y} + n = x + \paren {y + n}$ === Basis for the Induction === From [[Axiom:Axiomatization of 1-Based Natural Numbers|Axiom $\text C$]], we have by definition that: :$\forall x, y \in \N_{> 0}: \paren {x + y} + 1 = x + \paren {y + 1}$ and so $\map P 1$ holds. This is our [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now we need to show that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is our [[Definition:Induction Hypothesis|induction hypothesis]]: :$\paren {x + y} + k = x + \paren {y + k}$ Then we need to show: :$\paren {x + y} + \paren {k + 1} = x + \paren {y + \paren {k + 1} }$ === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \paren {x + y} + \paren {k + 1} | r = \paren {\paren {x + y} + k} + 1 | c = [[Natural Number Addition is Associative/Proof 3#Basis for the Induction|Basis for the Induction]] }} {{eqn | r = \paren {x + \paren {y + k} } + 1 | c = [[Natural Number Addition is Associative/Proof 3#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = x + \paren {\paren {y + k} + 1} | c = [[Natural Number Addition is Associative/Proof 3#Basis for the Induction|Basis for the Induction]] }} {{eqn | r = x + \paren {y + \paren {k + 1} } | c = [[Natural Number Addition is Associative/Proof 3#Basis for the Induction|Basis for the Induction]] }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. {{qed}}	0
By definition, [[Definition:Matrix Entrywise Addition|matrix entrywise addition]] is the '''[[Definition:Hadamard Product|Hadamard product]]''' of $\mathbf A$ and $\mathbf B$ with respect to [[Definition:Ring Addition|ring addition]]. We have from {{Ring-axiom|A1}} that [[Definition:Ring Addition|ring addition]] is [[Definition:Associative Operation|associative]]. The result then follows directly from [[Associativity of Hadamard Product]]. {{qed}}	0
Let $\family {\struct {X_i, \tau_i} }_{i \mathop \in I}$ be a [[Definition:Indexed Family|family]] of [[Definition:Topological Space|topological spaces]] where $I$ is an arbitrary [[Definition:Indexing Set|index set]]. Let $\displaystyle \struct {X, \tau} = \prod_{i \mathop \in I} \struct {X_i, \tau_i}$ be the [[Definition:Product Space of Topological Spaces|product space]] of $\family {\struct {X_i, \tau_i} }_{i \mathop \in I}$. Let $z \in X$. Let $i \in I$. Let $Y_i = \set {x \in X: \forall j \in I \setminus \set i: x_j = z_j}$. Let $\upsilon_i$ be the [[Definition:Subspace Topology|subspace topology]] of $Y_i$ relative to $\tau$. Let $p_i = \pr_i {\restriction_{Y_i}}$, where $\pr_i$ is the [[Definition:Projection on Family of Sets|projection]] from $X$ to $X_i$. Then: :$p_i$ is [[Definition:Continuous Mapping|continuous]].	0
{{begin-eqn}} {{eqn | l = \cos 5 x | r = 16 \cos^5 x - 20 \cos^3 x + 5 \cos x | c = [[Quintuple Angle Formula for Cosine]] }} {{eqn | ll= \leadsto | l = 16 \cos^5 x | r = \cos 5 x + 20 \cos^3 x - 5 \cos x | c = rearranging }} {{eqn | r = \cos 5 x + 20 \paren {\frac {3 \cos x + \cos 3 x} 4} - 5 \cos x | c = [[Power Reduction Formula for Cube of Sine]] }} {{eqn | r = \cos 5 x + 15 \cos x + 5 \cos 3 x - 5 \cos x | c = multipying out }} {{eqn | r = 10 \cos x + 5 \cos 3 x + \cos 5 x | c = rearranging }} {{eqn | ll= \leadsto | l = \cos^5 x | r = \frac {10 \cos x + 5 \cos 3 x + \cos 5 x} {16} | c = dividing both sides by 16 }} {{end-eqn}} {{qed}}	0
Let $\struct{S, \tau_{_S}}$ be a [[Definition:Topological Space|topological space]]. Let $\struct{R, +, *, \tau_{_R}}$ be a [[Definition:Topological Ring|topological ring]]. Let $\lambda \in R$. Let $f,g : \struct{S, \tau_{_S}} \to \struct{R, \tau_{_R}}$ be [[Definition:Continuous Mapping on Set|continuous mappings]]. Then the following results hold: === [[Combination Theorem for Continuous Mappings/Topological Ring/Sum Rule|Sum Rule]] === {{:Combination Theorem for Continuous Mappings/Topological Ring/Sum Rule}} === [[Combination Theorem for Continuous Mappings/Topological Ring/Translation Rule|Translation Rule]] === {{:Combination Theorem for Continuous Mappings/Topological Ring/Translation Rule}} === [[Combination Theorem for Continuous Mappings/Topological Ring/Negation Rule|Negation Rule]] === {{:Combination Theorem for Continuous Mappings/Topological Ring/Negation Rule}} === [[Combination Theorem for Continuous Mappings/Topological Ring/Product Rule|Product Rule]] === {{:Combination Theorem for Continuous Mappings/Topological Ring/Product Rule}} === [[Combination Theorem for Continuous Mappings/Topological Ring/Multiple Rule|Multiple Rule]] === {{:Combination Theorem for Continuous Mappings/Topological Ring/Multiple Rule}}	0
The [[Definition:Set|set]] of [[Definition:Complex Number|complex numbers]] $\C$ is [[Definition:Closed Algebraic Structure|closed]] under [[Definition:Complex Multiplication|multiplication]]: :$\forall z, w \in \C: z \times w \in \C$	0
{{ProofWanted}} {{Namedfor|Jacques Philippe Marie Binet|cat = Binet}}	0
With a view to expressing the [[Definition:Primitive|primitive]] in the form: :$\displaystyle \int u \frac {\mathrm d v}{\mathrm d x} \ \mathrm d x = u v - \int v \frac {\mathrm d u}{\mathrm d x} \ \mathrm d x$ let: {{begin-eqn}} {{eqn | l = u | r = \csc^{n - 2} a x | c = }} {{eqn | ll= \implies | l = \frac {\mathrm d u} {\mathrm d x} | r = -a \left({n - 2}\right) \csc^{n - 3} a x \csc a x \cot a x | c = [[Derivative of Power]], [[Derivative of Cosecant Function|Derivative of $\csc$]], [[Chain Rule for Derivatives]] }} {{eqn | ll= \implies | l = \frac {\mathrm d u} {\mathrm d x} | r = -a \left({n - 2}\right) \csc^{n - 2} a x \cot a x | c = }} {{end-eqn}} and let: {{begin-eqn}} {{eqn | l = \frac {\mathrm d v} {\mathrm d x} | r = \csc^2 a x | c = }} {{eqn | ll= \implies | l = v | r = \frac {-\cot a x} a | c = [[Primitive of Square of Cosecant of a x|Primitive of $\csc^2 a x$]] }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = \int \csc^n a x \ \mathrm d x | r = \int \csc^{n - 2} a x \csc^2 a x \ \mathrm d x | c = }} {{eqn | r = \csc^{n - 2} a x \left({\frac {-\cot a x} a}\right) - \int \left({\frac {-\cot a x} a}\right) \left({-a \left({n - 2}\right) \csc^{n - 2} a x \cot a x }\right) \ \mathrm d x | c = [[Integration by Parts]] }} {{eqn | r = \frac {-\csc^{n - 2} a x \cot a x} a - \left({n - 2}\right) \int \cot^2 a x \csc^{n - 2} a x \ \mathrm d x | c = simplifying }} {{eqn | r = \frac {-\csc^{n - 2} a x \cot a x} a - \left({n - 2}\right) \int \left({\csc^2 a x - 1}\right) \csc^{n - 2} a x \ \mathrm d x | c = [[Difference of Squares of Cosecant and Cotangent|Difference of $\csc^2$ and $\cot^2$]] }} {{eqn | r = \frac {-\csc^{n - 2} a x \cot a x} a - \left({n - 2}\right) \int \csc^n a x \ \mathrm d x | c = [[Linear Combination of Integrals]] }} {{eqn | o = | ro= + | r = \left({n - 2}\right) \int \csc^{n - 2} a x \ \mathrm d x | c = }} {{eqn | l = \left({n - 1}\right) \int \csc^n a x \ \mathrm d x | r = \frac {-\csc^{n - 2} a x \cot a x} a + \left({n - 2}\right) \int \csc^{n - 2} a x \ \mathrm d x | c = gathering terms }} {{eqn | l = \int \csc^n a x \ \mathrm d x | r = \frac{-\csc^{n - 2} a x \cot a x} {a \left({n - 1}\right)} + \frac {n - 2} {n - 1} \int \csc^{n - 2} a x \ \mathrm d x | c = dividing by $n - 1$ }} {{end-eqn}} {{qed}}	0
From [[Set Difference Intersection with Second Set is Empty Set]]: :$\Q \cap \paren {\R \setminus \Q} = \O$ By [[Empty Set is Closed in Topological Space]], $\O$ is [[Definition:Closed Set (Topology)|closed]] in $\R$. From [[Closed Set Equals its Closure]]: :$\O^- = \O$ Hence the result. {{qed}}	0
:$\left({w f}\right)' \left({z}\right) = w f' \left({z}\right)$	0
Let $P$ be a [[Definition:Geometric Sequence|geometric sequence]] of [[Definition:Natural Number|natural numbers]] of [[Definition:Length of Sequence|length]] $n$. Let the [[Definition:Common Ratio|common ratio]] of $P$ be expressed in [[Definition:Canonical Form of Rational Number|canonical form]] as $\dfrac p q$. From [[Construction of Geometric Sequence in Lowest Terms]]: :$P = \paren {q^n, p q^{n - 1}, p^2 q^{n - 2}, \ldots, p^{n - 1} q, p^n}$ By definition of [[Definition:Canonical Form of Rational Number|canonical form]]: :$p \perp q$ It follows from [[Powers of Coprime Numbers are Coprime]] that: :$p^n \perp q^n$ Hence the result. {{qed}}	0
With a view to expressing the [[Definition:Primitive|primitive]] in the form: :$\displaystyle \int u \frac {\d v} {\d x} \rd x = u v - \int v \frac {\d u} {\d x} \rd x$ let: {{begin-eqn}} {{eqn | l = u | r = x^2 | c = }} {{eqn | ll= \leadsto | l = \frac {\d u} {\d x} | r = 2 x | c = [[Derivative of Power]] }} {{end-eqn}} and let: {{begin-eqn}} {{eqn | l = \frac {\d v} {\d x} | r = e^{a x} | c = }} {{eqn | ll= \leadsto | l = v | r = \frac {e^{a x} } a | c = [[Primitive of Exponential of a x|Primitive of $e^{a x}$]] }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = \int x e^{a x} \rd x | r = x^2 \paren {\frac {e^{a x} } a} - \int 2 x \frac {e^{a x} } a \rd x + C | c = [[Integration by Parts]] }} {{eqn | r = x^2 \paren {\frac {e^{a x} } a} - \frac 2 a \int x e^{a x} \rd x + C | c = [[Primitive of Constant Multiple of Function]] }} {{eqn | r = x^2 \paren {\frac {e^{a x} } a} - \frac 2 a \paren {\frac {e^{a x} } a \paren {x - \frac 1 a} } + C | c = [[Primitive of x by Exponential of a x|Primitive of $x e^{a x}$]] }} {{eqn | r = \frac {e^{a x} } a \paren {x^2 - \frac {2 x} a + \frac 2 {a^2} } + C | c = simplifying }} {{end-eqn}} {{qed}}	0
From: :[[Integers form Ring]] :[[Rational Numbers form Ring]] :[[Real Numbers form Ring]] :[[Complex Numbers form Ring]] the [[Definition:Standard Number System|standard number systems]] $\Z$, $\Q$, $\R$ and $\C$ are [[Definition:Ring (Abstract Algebra)|rings]]. Hence we can apply [[Matrix Entrywise Addition over Ring is Commutative]]. {{qed|lemma}} The above cannot be applied to the [[Definition:Natural Numbers|natural numbers]] $\N$, as they do not form a [[Definition:Ring (Abstract Algebra)|ring]]. However, from [[Natural Numbers under Addition form Commutative Monoid]], the [[Definition:Algebraic Structure|algebraic structure]] $\struct {\N, +}$ is a [[Definition:Commutative Monoid|commutative monoid]]. By definition, [[Definition:Matrix Entrywise Addition|matrix entrywise addition]] is the '''[[Definition:Hadamard Product|Hadamard product]]''' with respect to [[Definition:Addition|addition of numbers]]. The result follows from [[Commutativity of Hadamard Product]]. {{qed}}	0
=== $(1)$ implies $(2)$ === Suppose: :$\forall p, q \in S: \neg p \vee \neg q = \neg \left({p \wedge q}\right)$ Then applying this to $\neg p$ and $\neg q$: :$\neg \neg p \vee \neg \neg q = \neg \left({\neg p \wedge \neg q}\right)$ By [[Complement of Complement in Uniquely Complemented Lattice]], $\neg \neg p = p$ and $\neg \neg q = q$. Thus: :$p \vee q = \neg \left({\neg p \wedge \neg q}\right)$. Taking [[Definition:Complement (Lattice Theory)|complements]] of both sides: :$\neg \left({p \vee q}\right) = \neg \neg \left({\neg p \wedge \neg q}\right)$ Again applying [[Complement of Complement in Uniquely Complemented Lattice]]: :$\neg \left({p \vee q}\right) = \neg p \wedge \neg q$ {{qed|lemma}} === $(2)$ implies $(1)$ === By [[Dual Pairs (Order Theory)]], $\wedge$ and $\vee$ are [[Definition:Dual Statement (Order Theory)|dual]]. Thus this implication follows from the above by [[Duality Principle (Order Theory)|Duality]]. {{qed|lemma}} === $(1)$ implies $(3)$ === By the definition of a [[Definition:Lattice/Definition 3|lattice]]: :$p \preceq q \iff p \vee q = q$ Applying this to $\neg q$ and $\neg p$: :$\neg q \preceq \neg p \iff \neg q \vee \neg p = \neg p$ By $(1)$: :$\neg q \vee \neg p = \neg \left({q \wedge p}\right)$ So: :$\neg q \preceq \neg p \iff \neg \left({q \wedge p}\right) = \neg p$ Taking the [[Definition:Complement (Lattice Theory)|complements]] of both sides of the equation on the right, and applying [[Complement of Complement in Uniquely Complemented Lattice]]: :$\neg q \preceq \neg p \iff q \wedge p = p$ But the right side is equivalent to $p \preceq q$ {{explain|We define the ordering on a lattice (definition 3) based on joins. We need an equivalent one based on meets, or maybe we have it somewhere already.}} Therefore: :$\neg q \preceq \neg p \iff p \preceq q$ {{qed|lemma}} === $(3)$ implies $(1)$ === {{improve|This is ugly}} {{MissingLinks}} Suppose that $p \preceq q \iff \neg q \preceq \neg p$ By the definition of join: :$\neg p, \neg q \preceq \neg p \vee \neg q$ Thus $\neg \left({\neg p \vee \neg q}\right) \preceq p, q$. By the definition of meet: :$\neg \left({\neg p \vee \neg q}\right) \preceq p \wedge q$ Thus: :$\neg\left({p \wedge q}\right) \preceq \neg\neg \left({\neg p \vee \neg q}\right)$ By [[Complement of Complement in Uniquely Complemented Lattice]]: $*\quad \neg\left({p \wedge q}\right) \preceq \neg p \vee \neg q$ Dually: :$\neg x \wedge \neg y \preceq \neg \left({x \vee y}\right)$ Letting $x = \neg p$ and $y = \neg q$: :$\neg \neg p \wedge \neg \neg q \preceq \neg \left({\neg p \vee \neg q}\right)$ By [[Complement of Complement in Uniquely Complemented Lattice]]: :$p \wedge q \preceq \neg \left({\neg p \vee \neg q}\right)$ By the premise and [[Complement of Complement in Uniquely Complemented Lattice]], then: $**\quad \neg p \vee \neg q \preceq \neg \left({p \wedge q}\right)$ By $*$ and $**$: $\quad \neg\left({p \wedge q}\right) = \neg p \vee \neg q$ {{qed|lemma}} === $(1)$, $(2)$, and $(3)$ together imply $(4)$ === $b, c \preceq b \vee c$, so :$a \wedge b \preceq a \wedge \left({b \vee c}\right)$ :$a \wedge c \preceq a \wedge \left({b \vee c}\right)$ By the definition of join: :$\left({a \wedge b}\right) \vee \left({a \wedge c}\right) \preceq a \wedge \left({b \vee c}\right)$ {{finish}}	0
{{begin-eqn}} {{eqn | l = \frac 1 2 + \sum_{k \mathop = 1}^n \cos \left({k x}\right) | r = \frac 1 2 + \cos x + \cos 2 x + \cos 3 x + \cdots + \cos n x | c = }} {{eqn| r = \frac {\sin \left({\left({2 n + 1}\right) x / 2}\right)} {2 \sin \left({x / 2}\right)} | c = }} {{end-eqn}} where $x$ is not an [[Definition:Integer Multiple|integer multiple]] of $2 \pi$.	0
Let $S \subseteq \R$. Let $\sequence {f_n}$ be a [[Definition:Sequence|sequence]] of [[Definition:Real Function|real functions]] $S \to \R$. Then the infinite series: :$\displaystyle \sum_{n \mathop = 1}^\infty f_n$ [[Definition:Uniform Convergence/Infinite Series|converges uniformly]] on $S$ {{iff}} for all $\varepsilon \in \R_{> 0}$ there exists $N \in \N$ such that: :$\displaystyle \size {\sum_{k \mathop = m + 1}^n \map {f_k} x} < \varepsilon$ for all $x \in S$ and $n > m > N$.	0
{{begin-eqn}} {{eqn | l = \map {\log_b} {\log_b x} | r = \map {\log_b} {\frac {\ln x} {\ln b} } | c = [[Change of Base of Logarithm]] }} {{eqn | r = \map {\log_b} {\ln x} - \map {\log_b} {\ln b} | c = [[Difference of Logarithms]] }} {{eqn | r = \frac {\map \ln {\ln x} } {\ln b} - \frac {\map \ln {\ln b} } {\ln b} | c = [[Change of Base of Logarithm]] }} {{eqn | r = \frac {\map \ln {\ln x} - \map \ln {\ln b} } {\ln b} | c = simplifying }} {{end-eqn}} {{qed}}	0
:$\displaystyle \int \frac {\d x} {x \paren {a^2 - x^2}^2} = \frac 1 {2 a^2 \paren {a^2 - x^2} } + \frac 1 {2 a^4} \map \ln {\frac {x^2} {a^2 - x^2} } + C$ for $x^2 < a^2$.	0
First note that: :$\forall a, b \in \Z: a \ne b \implies \dfrac a 1 = \map \phi a \ne \map \phi b = \dfrac b 1$ and so clearly $\phi$ is an [[Definition:Injection|injection]]. However, take for example $\dfrac 1 2$: :$\not \exists a \in \Z: \map \phi a = \dfrac 1 2$ as $\dfrac 1 2 \notin \Img \phi$. So $\phi$ is not a [[Definition:Surjection|surjection]]. Next let $a, b \in \Z$. {{begin-eqn}} {{eqn | l = \map \phi {a + b} | r = \frac {a + b} 1 | c = }} {{eqn | r = \frac a 1 + \frac b 1 | c = }} {{eqn | r = \map \phi a + \map \phi b | c = }} {{end-eqn}} {{begin-eqn}} {{eqn | l = \map \phi {a \times b} | r = \frac {a \times b} 1 | c = }} {{eqn | r = \frac {a \times b} {1 \times 1} | c = }} {{eqn | r = \frac a 1 \times \frac b 1 | c = }} {{eqn | r = \map \phi a \times \map \phi b | c = }} {{end-eqn}} So $\phi$ can be seen to be an [[Definition:Injection|injective]], but not [[Definition:Surjection|surjective]], [[Definition:Ring Homomorphism|ring homomorphism]]. Hence the result by definition of [[Definition:Ring Monomorphism|ring monomorphism]] and [[Definition:Ring Epimorphism|ring epimorphism]]. {{qed}}	0
Consider the [[Definition:Real Function|function]]: :$\map f x = \begin{cases} 0 & : x = a \\ \dfrac 1 {\sqrt{x - a} } & : x \in \hointl a b \end{cases}$ Since $\dfrac 1 {\sqrt{x - a} }$ is [[Definition:Continuous Real Function on Open Interval|continuous]] on $\openint a b$, $f$ is [[Definition:Continuous Real Function on Open Interval|continuous]] on $\openint a b$. Therefore, $f$ satisfies $(1)$ in the requirements of a [[Definition:Piecewise Continuous Function with Improper Integrals|piecewise continuous function with improper integrals]] for the [[Definition:Subdivision (Real Analysis)|subdivision]] $\set {a, b}$ of $\closedint a b$. Also: {{begin-eqn}} {{eqn | l = \int_{a+}^{b-} \map f x \rd x | r = \int_{a+}^{b-} \dfrac 1 {\sqrt{x - a} } \rd x }} {{eqn | r = \bigintlimits {2 \sqrt {x - a} } {a+} {b-} }} {{eqn | r = \lim_{x \mathop \to b-} 2 \sqrt{x - a} - \lim_{x \mathop \to a+} 2 \sqrt{x - a} }} {{eqn | r = 2 \sqrt {b - a} - 2 \sqrt {a - a} | c = as $2 \sqrt{x - a}$ is [[Definition:Left-Continuous at Point|left-continuous]] at $b$ and [[Definition:Right-Continuous at Point|right-continuous]] at $a$ }} {{eqn | r = 2 \sqrt{b - a} }} {{end-eqn}} Hence $\displaystyle \int_{a+}^{b-} \map f x \rd x$ exists. Thus $f$ is a [[Definition:Piecewise Continuous Function with Improper Integrals|piecewise continuous function with improper integrals]]. However, we have that $\map f x$ approaches $\infty$ as $x$ approaches $a$ from above. Thus $f$ is not [[Definition:Bounded Real-Valued Function|bounded]]. Therefore $f$ is not [[Definition:Bounded Piecewise Continuous Function|piecewise continuous and bounded]]. Hence the result. {{qed}}	0
Established by inspecting the [[Definition:Mersenne Number/Sequence|sequence of Mersenne numbers]]: :$3, 7, 31, 127, 2047, 8191, 131 \, 071, 524 \, 287, 8 \, 388 \, 607, 536 \, 870 \, 911, 2 \, 147 \, 483 \, 647, \ldots$ and removing from it the [[Mersenne Prime/Current Status|sequence of Mersenne primes]]: :$3, 7, 31, 127, 8191, 131 \, 071, 524 \, 287, 2 \, 147 \, 483 \, 647, \ldots$ {{qed}}	0
Let $p: \Z_{>0} \to \Z_{>0}$ be the [[Definition:Mapping|mapping]] defined as: :$\forall n \in \Z_{>0}: p \left({n}\right) = $ the number of [[Definition:Prime Number|prime numbers]] with no more than $n$ [[Definition:Digit|digits]] Then the value of $p$ for the first few numbers is given below: :{| border="1" |- ! align="right" style = "padding: 2px 10px" | $n$ ! align="right" style = "padding: 2px 10px" | $p \left({n}\right)$ |- | align="right" style = "padding: 2px 10px" | $1$ | align="right" style = "padding: 2px 10px" | $4$ |- | align="right" style = "padding: 2px 10px" | $2$ | align="right" style = "padding: 2px 10px" | $25$ |- | align="right" style = "padding: 2px 10px" | $3$ | align="right" style = "padding: 2px 10px" | $168$ |- | align="right" style = "padding: 2px 10px" | $4$ | align="right" style = "padding: 2px 10px" | $1229$ |- | align="right" style = "padding: 2px 10px" | $5$ | align="right" style = "padding: 2px 10px" | $9592$ |- | align="right" style = "padding: 2px 10px" | $6$ | align="right" style = "padding: 2px 10px" | $78 \, 498$ |- | align="right" style = "padding: 2px 10px" | $7$ | align="right" style = "padding: 2px 10px" | $664 \, 579$ |- | align="right" style = "padding: 2px 10px" | $8$ | align="right" style = "padding: 2px 10px" | $5 \, 761 \, 455$ |- | align="right" style = "padding: 2px 10px" | $9$ | align="right" style = "padding: 2px 10px" | $50 \, 847 \, 534$ |- | align="right" style = "padding: 2px 10px" | $10$ | align="right" style = "padding: 2px 10px" | $455 \, 052 \, 511$ |} {{OEIS|A006880}}	0
{{begin-eqn}} {{eqn | l = \left({\mathbf u + \mathbf v}\right) \cdot \mathbf w | r = \sum_{i \mathop = 1}^n \left({u_i + v_i}\right) w_i | c = {{Defof|Vector Sum}} and {{Defof|Dot Product}} }} {{eqn | r = \sum_{i \mathop = 1}^n \left({u_i w_i + v_i w_i}\right) | c = [[Real Multiplication Distributes over Real Addition]] }} {{eqn | r = \sum_{i \mathop = 1}^n u_i w_i + \sum_{i \mathop = 1}^n v_i w_i | c = }} {{eqn | r = \mathbf u \cdot \mathbf w + \mathbf v \cdot \mathbf w | c = {{Defof|Dot Product}} }} {{end-eqn}} {{qed}}	0
Let $q \in \N_{>0}$. Let $n \in \N$. Let $\map {c_q} n$ be [[Definition:Ramanujan Sum|Ramanujan's sum]]. Let $\mu$ denote the [[Definition:Möbius Function|Möbius function]]. Then: :$\displaystyle \map {c_q} n = \sum_{d \mathop \divides \gcd \set {q, n} } d \map \mu {\frac q d}$ where $\divides$ denotes [[Definition:Divisor of Integer|divisibility]].	0
{{begin-eqn}} {{eqn | l = \left({\ln \dfrac 1 {1 - z} }\right)^n | r = z^n + \dfrac 1 {n + 1} \left[{ {n + 1} \atop n}\right] z^{n + 1} + \cdots | c = }} {{eqn | r = n! \sum_{k \mathop \in \Z} \left[{k \atop n}\right] \frac {z^k} {k!} | c = }} {{end-eqn}} where $\displaystyle \left[{k \atop n}\right]$ denotes an [[Definition:Unsigned Stirling Numbers of the First Kind|unsigned Stirling number of the first kind]].	0
Let $n$ be the number of [[Definition:Digit|digits]] in $9^{9^9}$ From [[Number of Digits in Number]]: :$n = 1 + \floor {\map {\log_{10} } {9^{9^9} } }$ where $\floor {\ldots}$ denotes the [[Definition:Floor Function|floor function]]. Then: {{begin-eqn}} {{eqn | l = \map {\log_{10} } {9^{9^9} } | o = \approx | r = 369 \, 693 \, 099 \cdotp 63157 \, 03685 \, 87876 \, 1 | c = [[Largest Integer Expressible by 3 Digits/Logarithm Base 10|Largest Integer Expressible by 3 Digits: Logarithm Base 10]] }} {{eqn | ll= \leadsto | l = n | r = 1 + \floor {369 \, 693 \, 099 \cdotp 63157 \, 03685 \, 87876 \, 1} | c = }} {{eqn | r = 1 + 369 \, 693 \, 099 | c = {{Defof|Floor Function}} }} {{eqn | r = 369 \, 693 \, 100 | c = }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \sum_{k \mathop = 1}^n \dfrac {H_k} k | r = \sum_{k \mathop = 1}^n \sum_{j \mathop = 1}^k \dfrac 1 {j k} | c = {{Defof|Harmonic Number}} }} {{eqn | r = \sum_{k \mathop = 1}^n \sum_{j \mathop = 1}^k \dfrac 1 j \dfrac 1 k | c = }} {{eqn | r = \dfrac 1 2 \paren {\paren {\sum_{k \mathop = 1}^n \dfrac 1 k}^2 + \paren {\sum_{k \mathop = 1}^n \dfrac 1 {k^2} } } | c = [[Summation of Products of n Numbers taken m at a time with Repetitions]] }} {{eqn | r = \dfrac { {H_n}^2 + H_n^{\paren 2} } 2 | c = {{Defof|Harmonic Number}} and {{Defof|General Harmonic Numbers}} }} {{end-eqn}} Hence the result. {{qed}}	0
Consider the [[Prime Number Race between 4n+1 and 4n-1|prime number race between $4 n + 1$ and $4 n - 1$]]. While the [[Definition:Prime Number|prime numbers]] of the form $4 n - 1$ appear usually to be in the majority, the lead changes from one to the other an [[Definition:Infinite Set|infinite number]] of times.	0
By definition of [[Definition:Half-Range Fourier Sine Series|half-range Fourier sine series]]: :$\displaystyle \map f x \sim \sum_{n \mathop = 1}^\infty b_n \sin \dfrac {n x} 2$ where: {{begin-eqn}} {{eqn | l = b_n | r = \frac 2 {2 \pi} \int_0^{2 \pi} \map f x \sin \frac {n \pi x} {2 \pi} \rd x | c = }} {{eqn | r = \frac 1 \pi \int_0^{2 \pi} \map f x \sin \frac {n x} 2 \rd x | c = }} {{end-eqn}} for all $n \in \Z_{>0}$. Thus: {{begin-eqn}} {{eqn | l = b_n | r = \frac 1 \pi \int_0^{2 \pi} \map f x \sin \dfrac {n x} 2 \rd x | c = }} {{eqn | r = \frac 1 \pi \int_0^\pi \sin \dfrac x 2 \sin \dfrac {n x} 2 \rd x + \frac 1 \pi \int_\pi^{2 \pi} -\sin \dfrac x 2 \sin \dfrac {n x} 2 \rd x | c = Definition of $f$ }} {{end-eqn}} When $\dfrac {n x} 2 \ne \dfrac x 2$, that is, when $n \ne 1$, we have: {{begin-eqn}} {{eqn | l = \int \sin \dfrac x 2 \sin \dfrac {n x} 2 \rd x | r = \frac {\sin \paren {\dfrac x 2 - \dfrac {n x} 2} } {2 \paren {\dfrac 1 2 - \dfrac n 2} } - \frac {\sin \paren {\dfrac x 2 + \dfrac {n x} 2} } {2 \paren {\dfrac 1 2 + \dfrac n 2} } + C | c = [[Primitive of Sine of p x by Sine of q x|Primitive of Sine of $\dfrac x 2$ by Sine of $\dfrac {n x} 2$]] }} {{eqn | r = \frac {\sin \paren {\dfrac {\paren {n - 1} x} 2} } {n - 1} - \frac {\sin \paren {\dfrac {\paren {n + 1} x} 2} } {n + 1} + C | c = }} {{end-eqn}} and so for $n \ne 1$: {{begin-eqn}} {{eqn | l = b_n | r = \frac 1 \pi \int_0^{2 \pi} \map f x \sin \dfrac {n x} 2 \rd x | c = }} {{eqn | r = \frac 1 \pi \intlimits {\frac {\sin \paren {\dfrac {\paren {n - 1} x} 2} } {n - 1} - \frac {\sin \paren {\dfrac {\paren {n + 1} x} 2} } {n + 1} } 0 \pi - \frac 1 \pi \intlimits {\frac {\sin \paren {\dfrac {\paren {n - 1} x} 2} } {n - 1} - \frac {\sin \paren {\dfrac {\paren {n + 1} x} 2} } {n + 1} } \pi {2 \pi} | c = }} {{eqn | r = \frac 1 \pi \paren {\paren {\frac {\sin \paren {\dfrac {\paren {n - 1} \pi} 2} } {n - 1} - \frac {\sin \paren {\dfrac {\paren {n + 1} \pi} 2} } {n + 1} } - \paren {\frac {\sin \paren {\dfrac {\paren {n - 1} 0} 2} } {n - 1} - \frac {\sin \paren {\dfrac {\paren {n + 1} 0} 2} } {n + 1} } } | c = }} {{eqn | o = | ro= - | r = \frac 1 \pi \paren {\paren {\frac {\sin \paren {\dfrac {\paren {n - 1} 2 \pi} 2} } {n - 1} - \frac {\sin \paren {\dfrac {\paren {n + 1} 2 \pi} 2} } {n + 1} } - \paren {\frac {\sin \paren {\dfrac {\paren {n - 1} \pi} 2} } {n - 1} - \frac {\sin \paren {\dfrac {\paren {n + 1} \pi} 2} } {n + 1} } } | c = }} {{eqn | r = \frac 2 \pi \paren {\frac {\sin \paren {\dfrac {\paren {n - 1} \pi} 2} } {n - 1} - \frac {\sin \paren {\dfrac {\paren {n + 1} \pi} 2} } {n + 1} } | c = [[Sine of Multiple of Pi]] and simplifying }} {{end-eqn}} When $\dfrac {n x} 2 = \dfrac x 2$, that is, when $n = 1$, we have: {{begin-eqn}} {{eqn | l = \int \sin \dfrac x 2 \sin \dfrac x 2 \rd x | r = \int \sin^2 \dfrac x 2 \rd x + C | c = }} {{eqn | r = \frac x 2 - \frac {\sin 2 \dfrac x 2} {4 \dfrac 1 2} + C | c = [[Primitive of Square of Sine of a x|Primitive of $\sin^2 \dfrac x 2$]] }} {{eqn | r = \frac x 2 - \frac {\sin x} 2 + C | c = simplifying }} {{end-eqn}} and so for $n = 1$: {{begin-eqn}} {{eqn | l = b_n | r = \frac 1 \pi \int_0^{2 \pi} \map f x \sin \dfrac x 2 \rd x | c = }} {{eqn | r = \frac 1 \pi \intlimits {\frac x 2 - \frac {\sin x} 2} 0 \pi - \frac 1 \pi \intlimits {\frac x 2 - \frac {\sin x} 2} \pi {2 \pi} | c = }} {{eqn | r = \frac 1 \pi \paren {\paren {\frac \pi 2 - \frac {\sin \pi} 2} - \paren {\frac 0 2 - \frac {\sin 0} 2} } | c = }} {{eqn | o = | ro= - | r = \frac 1 \pi \paren {\paren {\frac {2 \pi} 2 - \frac {\sin 2 \pi} 2} - \paren {\frac \pi 2 - \frac {\sin \pi} 2} } | c = }} {{eqn | r = \frac 1 \pi \paren {\frac \pi 2 - \frac {2 \pi} 2 + \frac \pi 2} | c = [[Sine of Multiple of Pi]] }} {{eqn | r = 0 | c = everything vanishes }} {{end-eqn}} Hence: {{begin-eqn}} {{eqn | l = \map f x | o = \sim | r = \sum_{n \mathop = 1}^\infty b_n \sin \dfrac {n x} 2 | c = }} {{eqn | r = \sum_{n \mathop = 2}^\infty \frac 2 \pi \paren {\frac {\sin \paren {\dfrac {\paren {n - 1} \pi} 2} } {n - 1} - \frac {\sin \paren {\dfrac {\paren {n + 1} \pi} 2} } {n + 1} } \sin \dfrac {n x} 2 | c = substituting for $b_n$ from above }} {{end-eqn}} When $n$ is [[Definition:Odd Integer|odd]], we have $n = 2 r + 1$ for $r \ge 1$, and so: {{begin-eqn}} {{eqn | o = | r = \sum_{r \mathop = 1}^\infty \frac 2 \pi \paren {\frac {\sin \paren {\dfrac {\paren {\paren {2 r + 1} - 1} \pi} 2} } {\paren {2 r + 1} - 1} - \frac {\sin \paren {\dfrac {\paren {\paren {2 r + 1} + 1} \pi} 2} } {\paren {2 r + 1} + 1} } \sin \dfrac {\paren {2 r + 1} x} 2 | c = }} {{eqn | r = \sum_{r \mathop = 1}^\infty \frac 2 \pi \paren {\frac {\sin \paren {\dfrac {2 r \pi} 2} } {2 r} - \frac {\sin \paren {\dfrac {\paren {2 r + 2} \pi} 2} } {2 r + 2} } \sin \dfrac {\paren {2 r + 1} x} 2 | c = }} {{eqn | r = \sum_{r \mathop = 1}^\infty \frac 2 \pi \paren {\frac {\sin r \pi} {2 r} - \frac {\sin \paren {r + 1} \pi} {2 r + 2} } \sin \dfrac {\paren {2 r + 1} x} 2 | c = }} {{eqn | r = 0 | c = [[Sine of Multiple of Pi]] }} {{end-eqn}} When $n$ is [[Definition:Even Integer|even]], we have $n = 2 r$ for $r \ge 1$, and so: {{begin-eqn}} {{eqn | o = | r = \sum_{r \mathop = 1}^\infty \frac 2 \pi \paren {\frac {\sin \paren {\dfrac {\paren {2 r - 1} \pi} 2} } {2 r - 1} - \frac {\sin \paren {\dfrac {\paren {2 r + 1} \pi} 2} } {2 r + 1} } \sin \dfrac {2 r x} 2 | c = }} {{eqn | r = \frac 2 \pi \sum_{r \mathop = 1}^\infty \paren {\frac {\sin \paren {r - \frac 1 2} \pi} {2 r - 1} - \frac {\sin \paren {r + \frac 1 2} \pi} {2 r + 1} } \sin r x | c = }} {{eqn | r = \frac 2 \pi \sum_{r \mathop = 1}^\infty \paren {\frac {\paren {-1}^{r - 1} } {2 r - 1} - \frac {\paren {-1}r} {2 r + 1} } \sin r x | c = [[Sine of Half-Integer Multiple of Pi]] }} {{eqn | r = \frac 2 \pi \sum_{r \mathop = 1}^\infty \paren {\frac {\paren {-1}^{r - 1} } {2 r - 1} + \frac {\paren {-1}^{r - 1} } {2 r + 1} } \sin r x | c = }} {{eqn | r = \frac 2 \pi \sum_{r \mathop = 1}^\infty \paren {-1}^{r - 1} \paren {\frac {2 r + 1 + 2 r - 1} {\paren {2 r - 1} \paren {2 r + 1} } } \sin r x | c = }} {{eqn | r = \frac 2 \pi \sum_{r \mathop = 1}^\infty \paren {-1}^{r - 1} \frac {4 r} {4 r^2 - 1} \sin r x | c = [[Difference of Two Squares]] }} {{eqn | r = \frac 8 \pi \sum_{r \mathop = 1}^\infty \paren {-1}^{r - 1} \frac {r \sin r x} {4 r^2 - 1} | c = simplifying }} {{end-eqn}} {{qed}}	0
Proof by [[Principle of Mathematical Induction|induction]]: For all $n \in \N$, let $P \left({n}\right)$ be the [[Definition:Proposition|proposition]]: :The sum of $n$ [[Definition:Even Integer|even integers]] is an [[Definition:Even Integer|even integer]]. $P(1)$ is trivially true, as this just says: :The sum of $1$ [[Definition:Even Integer|even integers]] is an [[Definition:Even Integer|even integer]]. The sum of $0$ [[Definition:Even Integer|even integers]] is understood, from the definition of a [[Definition:Vacuous Summation|vacuous summation]], to be $0$, which is [[Definition:Even Integer|even]]. So $P(0)$ is also true. === Basis for the Induction === $P(2)$ is the case: :The [[Definition:Integer Addition|sum]] of any two [[Definition:Even Integer|even integers]] is itself [[Definition:Even Integer|even]]. Consider two [[Definition:Even Integer|even integers]] $x$ and $y$. Since they are [[Definition:Even Integer|even]], they can be written as $x = 2a$ and $y = 2b$ respectively for [[Definition:Integer|integers]] $a$ and $b$. Therefore, the sum is: :$x + y = 2 a + 2 b = 2 \left({a + b}\right)$ Thus $x + y$ has $2$ as a [[Definition:Divisor of Integer|divisor]] and is [[Definition:Even Integer|even]] by definition. This is our [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. {{qed|lemma}} === Induction Hypothesis === Now we need to show that, if $P \left({k}\right)$ is true, where $k \ge 2$, then it logically follows that $P \left({k + 1}\right)$ is true. So this is our [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :The [[Definition:Integer Addition|sum]] of any $k$ [[Definition:Even Integer|even integers]] is itself even. Then we need to show: :The [[Definition:Integer Addition|sum]] of any $k+1$ [[Definition:Even Integer|even integers]] is itself even. === Induction Step === This is our [[Principle of Mathematical Induction#Induction Step|induction step]]: Consider the [[Definition:Integer Addition|sum]] of any $k + 1$ [[Definition:Even Integer|even integers]]. This is the [[Definition:Integer Addition|sum]] of: : $k$ [[Definition:Even Integer|even integers]] (which is even by the [[Sum of Even Integers is Even#Induction Hypothesis|induction hypothesis]]) and: : another [[Definition:Even Integer|even integer]]. That is, it is the [[Definition:Integer Addition|sum]] of two [[Definition:Even Integer|even integers]]. By the [[Sum of Even Integers is Even#Basis for the Induction|basis for the induction]], this is also [[Definition:Even Integer|even]]. So $P \left({k}\right) \implies P \left({k + 1}\right)$ and the result follows by the [[Principle of Mathematical Induction]]. That is: :The [[Definition:Integer Addition|sum]] of any [[Definition:Finite Set|finite number]] of [[Definition:Even Integer|even integers]] is itself [[Definition:Even Integer|even]]. {{qed}}	0
Let the [[Definition:Vector|vectors]] $\mathbf u$, $\mathbf v$ and $\mathbf w$ be embedded in a [[Definition:Cartesian 3-Space|Cartesian $3$-space]]. It is noted that $\mathbf u$, $\mathbf v$ and $\mathbf w$ are not necessarily [[Definition:Coplanar Vectors|coplanar]]. :[[File:Dot-product-distributes-over-addition.png|520px]] Let instances of $\mathbf u$ and $\mathbf w$ be selected so their [[Definition:Initial Point of Vector|initial points]] are at some point $O$. Let an instance of $\mathbf v$ be selected so its [[Definition:Initial Point of Vector|initial point]] is positioned at the [[Definition:Terminal Point of Vector|terminal point]] $U$ of $\mathbf u$. Let the [[Definition:Terminal Point of Vector|terminal point]] $\mathbf v$ be $V$. Let $UA$ be dropped [[Definition:Perpendicular|perpendicular]] to $\mathbf w$. Let $VB$ be dropped [[Definition:Perpendicular|perpendicular]] to $\mathbf w$. Let another instance of $\mathbf w$ be selected so that its [[Definition:Initial Point of Vector|initial point]] is at $U$. Let $VC$ be dropped [[Definition:Perpendicular|perpendicular]] to this second instance of $\mathbf w$. Let $CB$ be dropped from $C$ to the first instance of $\mathbf w$. We have that: :$UA \parallel CB$ and: :$UC \parallel AB$ Thus $\Box ABCU$ is a [[Definition:Parallelogram|parallelogram]]. Hence: :$AB = UC$ Then we have that: {{begin-eqn}} {{eqn | l = OA | r = OU \cos \angle \mathbf u, \mathbf w | c = }} {{eqn | r = \norm {\mathbf u} \cos \angle \mathbf u, \mathbf w | c = }} {{eqn | l = AB | r = UV \cos \angle \mathbf v, \mathbf w | c = }} {{eqn | r = \norm {\mathbf v} \cos \angle \mathbf v, \mathbf w | c = }} {{eqn | l = OB | r = OV \cos \angle \paren {\mathbf u + \mathbf v}, \mathbf w | c = }} {{eqn | r = \norm {\paren {\mathbf u + \mathbf v} } \cos \angle \paren {\mathbf u + \mathbf v}, \mathbf w | c = }} {{eqn | r = \norm {\mathbf u} \cos \angle \mathbf u, \mathbf w + \norm {\mathbf v} \cos \angle \mathbf v, \mathbf w | c = }} {{eqn | ll= \leadsto | l = \norm {\paren {\mathbf u + \mathbf v} } \norm {\mathbf w} \cos \angle \paren {\mathbf u + \mathbf v}, \mathbf w | r = \norm {\mathbf u} \norm {\mathbf w} \cos \angle \mathbf u, \mathbf w + \norm {\mathbf v} \norm {\mathbf w} \cos \angle \mathbf v, \mathbf w | c = }} {{eqn | ll= \leadsto | l = \paren {\mathbf u + \mathbf v} \cdot \mathbf w | r = \mathbf u \cdot \mathbf w + \mathbf v \cdot \mathbf w | c = {{Defof|Dot Product|index = 2}} }} {{end-eqn}} Hence the result. {{qed}}	0
Let: : $z_1 = r_1 \left({\cos \theta_1 + i \sin \theta_1}\right)$ : $z_2 = r_2 \left({\cos \theta_2 + i \sin \theta_2}\right)$ Then: {{begin-eqn}} {{eqn | l = \left\vert{z_1 z_2}\right\vert | r = \left\vert{r_1 \left({\cos \theta_1 + i \sin \theta_1}\right) r_2 \left({\cos \theta_2 + i \sin \theta_2}\right)}\right\vert | c = {{Defof|Polar Form of Complex Number}} }} {{eqn | r = \left\vert{r_1 r_2 \left({\cos \left({\theta_1 + \theta_2}\right) + i \sin \left({\theta_1 + \theta_2}\right)}\right)}\right\vert | c = [[Product of Complex Numbers in Polar Form]] }} {{eqn | r = r_1 r_2 | c = {{Defof|Polar Form of Complex Number}} }} {{eqn | r = \left\vert{z_1}\right\vert \left\vert{z_2}\right\vert | c = {{Defof|Polar Form of Complex Number}} }} {{end-eqn}} {{qed}}	0
This page gathers together [[Definition:Derivative|derivatives]] of [[Definition:Trigonometric Function|trigonometric functions]].	0
From [[Power Series Expansion for Real Inverse Hyperbolic Tangent]]: {{begin-eqn}} {{eqn | l = \tanh^{-1} x | r = \sum_{n \mathop = 0}^\infty \frac {x^{2 n + 1} } {2 n + 1} | c = }} {{eqn | r = x + \frac {x^3} 3 + \frac {x^5} 5 + \frac {x^7} 7 + \cdots | c = }} {{end-eqn}} for $\size x < 1$. From [[Inverse Hyperbolic Tangent of Reciprocal equals Inverse Hyperbolic Cotangent]] :$\map {\tanh^{-1} } {\dfrac 1 x} = \coth^{-1} x$ So: {{begin-eqn}} {{eqn | l = \coth^{-1} x | r = \sum_{n \mathop = 0}^\infty \frac 1 {2 n + 1} \times \frac 1 {x^{2 n + 1} } | c = }} {{eqn | r = \frac 1 x + \frac 1 3 \times \frac 1 {x^3} + \frac 1 5 \times \frac 1 {x^5} + \frac 1 7 \times \frac 1 {x^7} + \cdots | c = }} {{end-eqn}} Hence the result. {{qed}}	0
Follows directly from [[Nth Derivative of Reciprocal of Mth Power]] by putting $m = 1$. {{Qed}} [[Category:Derivatives]] [[Category:Reciprocals]] 5esfog7mo3vmt4mb8i0vdfikz5koxty	0
Let $a \divides b$. From [[Integer Divides Zero]]: :$a \divides 0$ Thus $a$ is a [[Definition:Common Divisor of Integers|common divisor]] of $b$ and $0$. From [[Common Divisor Divides Integer Combination]]: :$\forall p, q \in \Z: a \divides \paren {p \cdot b + q \cdot 0}$ Putting $p = c$ and $q = 1$ (for example): :$a \divides \paren {c b + 0}$ Hence the result. {{qed}}	0
{{begin-eqn}} {{eqn | l = x | r = y | c = }} {{eqn | ll= \leadsto | l = x - y | r = 0 | c = }} {{eqn | ll= \leadsto | l = x - y | r = 0 \cdot z | c = }} {{eqn | ll= \leadsto | l = x | o = \equiv | r = y | rr= \pmod z | c = {{Defof|Congruence (Number Theory)|Congruence Modulo $z$}} }} {{end-eqn}} {{qed}}	0
Let $\left \langle {a_n}\right \rangle$ be a [[Definition:Real Sequence|sequence in $\R$]]. Let $a_n \to l$ as $n \to \infty$, and let $c < l$ where $c \in \R$. Then $\exists N \in \N$ such that: : $\forall n \in \N, n \ge N: c < a_n$	0
Let $f: \N \to A$ be a [[Definition:Mapping|mapping]] from the [[Definition:Natural Numbers|set of natural numbers]] $\N$ to a [[Definition:Class (Class Theory)|class]] $A$. Let $f$ have the property that: :$\forall n \in \N: \map f n \subseteq \map f {n^+}$ where $n^+$ is the [[Definition:Halmos Function|successor]] of $n$. Then: :$\forall n, m \in N: n \le m \implies \map f n \subseteq \map f m$	0
:$\displaystyle x^6 = \frac {\pi^6} 7 + \sum_{n \mathop = 1}^\infty \frac {12 n^4 \pi^4 - 240 n^2 \pi^2 + 1440} {n^6} \cos n \pi \cos n x$	0
By [[Geometrical Interpretation of Complex Subtraction]]: :$z_1 - z_3$ can be represented as the [[Definition:Line Segment|line segment]] from $z_3$ to $z_1$ :$z_3 - z_2$ can be represented as the [[Definition:Line Segment|line segment]] from $z_2$ to $z_3$. Thus we have that $z_1$, $z_2$ and $z_3$ are [[Definition:Collinear Points|collinear]] {{iff}} $z_1 - z_3$ is [[Definition:Parallel Lines|parallel]] to $z_3 - z_2$, when expressed as [[Definition:Line Segment|line segments]]. Let $\dfrac {z_1 - z_3} {z_3 - z_2} = \lambda$ for $\lambda \in \C$. That is: :$z_1 - z_3 = \lambda \paren {z_3 - z_2}$ By [[Complex Multiplication as Geometrical Transformation]]: :$\map \arg {z_1 - z_3} = \map \arg {z_3 - z_2} \iff \map \arg {z_3 - z_2} \arg \lambda \in \R_{>0}$ and: :$\map \arg {z_1 - z_3} = -\map \arg {z_3 - z_2} \iff \map \arg {z_3 - z_2} \arg \lambda \in \R_{<0}$ where $\arg$ denotes the [[Definition:Argument of Complex Number|argument]] of a [[Definition:Complex Number|complex number]]. Also by [[Complex Multiplication as Geometrical Transformation]], $z_1 - z_3$ is $\lambda$ the [[Definition:Length of Line|length]] of $z_3 - z_2$. The result follows. {{Qed}}	0
The proof of these results can be found in: :[[GCD from Prime Decomposition]] :[[LCM from Prime Decomposition]] {{Qed}} [[Category:Greatest Common Divisor]] [[Category:Lowest Common Multiple]] [[Category:Prime Numbers]] iur6iagonkv1hmri44ycxc6lbtsc4ux	0
Let $p: \N \to \N$ be the [[Definition:Prime Enumeration Function|prime enumeration function]]. Then $\forall n \in \N$, the value of $\map p n$ is [[Definition:Bounded Above Mapping|bounded above]]. In particular:	0
Let: :$a \tan \theta = x$ for $\theta \in \openint {-\dfrac \pi 2} {\dfrac \pi 2}$. From [[Shape of Tangent Function]], this substitution is valid for all [[Definition:Real Number|real]] $x$. Then: {{begin-eqn}} {{eqn | l = x | r = a \tan \theta | c = from above }} {{eqn | ll= \leadsto | l = \frac {\d x} {\d \theta} | r = a \sec^2 \theta | c = [[Derivative of Tangent Function]] }} {{eqn | ll= \leadsto | l = \int \frac 1 {x^2 + a^2} \rd x | r = \int \frac {a \ \sec^2 \theta} {a^2 \tan^2 \theta + a^2} \rd \theta | c = [[Integration by Substitution]] }} {{eqn | r = \frac a {a^2} \int \frac {\sec^2 \theta} {\tan^2 \theta + 1} rd \theta | c = [[Primitive of Constant Multiple of Function]] }} {{eqn | r = \frac 1 a \int \frac {\sec^2 \theta} {\sec^2 \theta} \rd \theta | c = [[Difference of Squares of Secant and Tangent]] }} {{eqn | r = \frac 1 a \int \rd \theta }} {{eqn | r = \frac 1 a \theta + C | c = [[Integral of Constant]] }} {{end-eqn}} As $\theta$ was stipulated to be in the [[Definition:Open Real Interval|open interval]] $\openint {-\dfrac \pi 2} {\dfrac \pi 2}$: :$\tan \theta = \dfrac x a \iff \theta = \arctan \dfrac x a$ Thus: :$\displaystyle \int \frac 1 {x^2 + a^2} \rd x = \frac 1 a \arctan \frac x a + C$ {{qed|lemma}} When $a = 0$, both $\dfrac x a$ and $\dfrac 1 a$ are undefined. However, consider the limit of the above [[Definition:Primitive (Calculus)|primitive]] as $a \to 0$: {{begin-eqn}} {{eqn | l = \lim_{a \mathop \to 0} \frac 1 a \arctan {\frac x a} | r = \lim_{a \mathop \to 0} \frac {\arctan {\frac x a} } a }} {{eqn | ll= \leadsto | r = \lim_{a \mathop \to 0} \frac {-x a^{-2} } {1 + \frac {x^2} {a^2} } | c = [[L'Hôpital's Rule]], [[Derivative of Arctangent Function]] }} {{eqn | r = \lim_{a \mathop \to 0} \frac {a^{-2} } {a^{-2} } \frac {-x} {x^2 + a^2} }} {{eqn | r = -\frac 1 x }} {{end-eqn}} This corresponds with the result: :$\displaystyle \int \frac 1 {x^2} \rd x = \frac {-1} x + C$ which follows from [[Primitive of Power]]. {{qed}}	0
The [[Definition:Euclidean Metric on Real Number Line|Euclidean metric]] on the [[Definition:Real Number Line|real number line]] $\R$ is a [[Definition:Metric|metric]].	0
The [[Definition:Derivative|derivative]] of the [[Definition:Riemann Zeta Function|Riemann zeta function]] is: :$\displaystyle \map {\zeta'} z = \frac {\d \zeta} {\d z} = -\sum_{n \mathop = 2}^\infty \frac {\map \ln n} {n^z}$	0
{{begin-eqn}} {{eqn | l = \csc 165 \degrees | r = \map \csc {180 \degrees - 15 \degrees} | c = }} {{eqn | r = \csc 15 \degrees | c = [[Cosecant of Supplementary Angle]] }} {{eqn | r = \sqrt 6 + \sqrt 2 | c = [[Cosecant of 15 Degrees]] }} {{end-eqn}} {{qed}}	0
$2^{16} = 65 \, 536$ is the only known [[Definition:Integer Power|power]] of $2$, up to $2^{31 \, 000}$, whose [[Definition:Digit|digits]] do not contain $1$, $2$, $4$ or $8$.	0
We have: :$d \divides n \implies \forall i: 1 \le i \le r: d = p_1^{l_1} p_2^{l_2} \ldots p_1^{l_1}, 0 \le l_i \le k_i$ For each $i$, there are $k_i + 1$ choices for $l_i$, making $\paren {k_1 + 1} \paren {k_2 + 1} \cdots \paren {k_r + 1}$ choices in all. By the [[Fundamental Theorem of Arithmetic]] and hence the uniqueness of [[Definition:Prime Decomposition|prime decomposition]], each of these choices results in a different number, therefore a distinct [[Definition:Divisor of Integer|divisor]]. {{qed}}	0
: $a^{-x} = \dfrac 1 {a^x}$	0
{{begin-eqn}} {{eqn | l = \int x \sec a x \rd x | r = \frac 1 {a^2} \int \theta \sec \theta \rd \theta | c = [[Integration by Substitution|Substitution of $a x \to \theta$]] }} {{eqn | r = \frac 1 {a^2} \int \theta \sum_{n \mathop = 0}^\infty \frac{ \paren {-1}^n E_{2 n} \theta^{2 n} } {\paren {2 n}!} \rd \theta | c = [[Power Series Expansion for Secant Function]] }} {{eqn | r = \frac 1 {a^2} \sum_{n \mathop = 0}^\infty \frac {\paren {-1}^n E_{2 n} } {\paren {2 n}!} \int \theta^{2 n + 1} \rd \theta | c = [[Fubini's Theorem]] }} {{eqn | r = \frac 1 {a^2} \sum_{n \mathop = 0}^\infty \frac {\paren {-1}^n E_{2 n} \paren {a x}^{2 n + 2} } {\paren {2 n + 2} \paren {2 n}!} + C | c = [[Integration by Substitution|Substituting back $\theta \to ax$]] }} {{end-eqn}} {{qed}}	0
From [[Primitive of Reciprocal of x by Power of x plus Power of a]]: :$\displaystyle \int \frac {\mathrm d x} {x \left({x^n + a^n}\right)} = \frac 1 {n a^n} \ln \left\vert{\frac {x^n} {x^n + a^n} }\right\vert + C$ So: {{begin-eqn}} {{eqn | l = \int \frac {\mathrm d x} {x \left({x^2 + a^2}\right)} | r = \frac 1 {2 a^2} \ln \left\vert{\frac {x^2} {x^2 + a^2} }\right\vert + C | c = [[Primitive of Reciprocal of x by Power of x plus Power of a|Primitive of $\dfrac 1 {x \left({x^n + a^n}\right)}$]] with $n = 2$ }} {{eqn | r = \frac 1 {2 a^2} \ln \left({\frac {x^2} {x^2 + a^2} }\right) + C | c = [[Absolute Value of Even Power]] }} {{end-eqn}} {{qed}}	0
:$\displaystyle \sum_{j \mathop = 1}^n \frac 1 {j \paren {j + 1} \paren {j + 2} } = \frac {n \paren {n + 3} } {4 \paren {n + 1} \paren {n + 2} }$	0
Using the technique of [[Evaluation of Integral using Laplace Transform]]: {{begin-eqn}} {{eqn | l = \int_0^\infty e^{-s t} \map {J_0} t \rd t | r = \dfrac 1 {\sqrt {s^2 + 1} } | c = [[Laplace Transform of Bessel Function of the First Kind of Order Zero]] }} {{eqn | ll= \leadsto | l = \int_0^\infty \map {J_0} t \rd t | r = 1 | c = letting $s \to 0^+$ }} {{end-eqn}} {{qed}}	0
From [[Tau of Power of Prime]] we have: :$\forall j \in \closedint 1 r: \map \tau {p_j^{k_j} } = k_j + 1$ The result follows immediately from [[Tau Function is Multiplicative]]. {{qed}}	0
Let $M = \struct {A, d}$ be a [[Definition:Metric Space|metric space]]. Let $\tau_A$ be the [[Definition:Topology Induced by Metric|topology on $A$ induced by $d$]]. Let $\struct {A \times A, \tau}$ be the [[Definition:Product Space (Topology)|product space]] of $\struct {A, \tau_A}$ and itself. Then the [[Definition:Distance Function|distance function]] $d: A \times A \to \R$ is a [[Definition:Everywhere Continuous Mapping (Topology)|continuous mapping]].	0
We note that all of $\Q, \R, \C$ can be considered as [[Definition:Euclidean Space|metric spaces]]. Then under the [[Definition:Usual Metric|usual metric]]: : $d \left({x_n, l}\right) = \left|{x_n - l}\right|$. The result follows from the definition of [[Definition:Metric|metric]]: $d \left({x_n, l}\right) = 0 \iff x_n = l$. {{qed}}	0
{{AimForCont}} that $P \nmid L$. Then by the [[Division Theorem/Real Number Index|Division Theorem]] we have $L = q P + r$ where $q \in \Z$ and $0 < r < P$. And so: {{begin-eqn}} {{eqn | l = \map f {x + L} | r = \map f {x + \paren {q P + r} } }} {{eqn | r = \map f {\paren {x + r} + q P} }} {{eqn | r = \map f {x + r} | c = [[General Periodicity Property]] }} {{eqn | r = \map f x | c = {{Defof|Periodic Element}} }} {{end-eqn}} But then $r$ is a [[Definition:Periodic Element|periodic element]] of $f$ that is less than $P$. Therefore $P$ cannot be the [[Definition:Period of Function|period]] of $f$. The result follows from [[Proof by Contradiction]]. {{qed}} [[Category:Periodic Functions]] 8ozj1819qzmmkun1rf2fdo4ry2m0wqc	0
:$\displaystyle \int x \cos a x \rd x = \frac {\cos a x} {a^2} + \frac {x \sin a x} a + C$	0
The total [[Definition:Length of Curve|length]] of the [[Definition:Lemniscate of Bernoulli|lemniscate of Bernoulli]] given in [[Definition:Polar Coordinates|polar coordinates]] as: :$r^2 = a^2 \cos 2 \theta$ is given by: {{begin-eqn}} {{eqn | l = L | r = 4 a \map F {\sqrt 2, \dfrac \pi 4} | c = }} {{eqn | r = \dfrac 1 {\sqrt {2 \pi} } \paren {\map \Gamma {\dfrac 1 4} }^2 | c = }} {{end-eqn}} where $F$ denotes the [[Definition:Incomplete Elliptic Integral of the First Kind|incomplete elliptic integral of the first kind]].	0
:$\map {\dfrac \d {\d x} } {\dfrac 1 {2 a} \map \ln {\dfrac {a + x} {a - x} } } = \dfrac 1 {a^2 - x^2}$ where $\size x < a$.	0
{{begin-eqn}} {{eqn | l = \sec x | r = \map \sech {i x} | c = [[Secant in terms of Hyperbolic Secant]] }} {{eqn | r = \sum_{n \mathop = 0}^\infty \frac {E_n \paren {i x}^n} {n!} | c = {{Defof|Euler Numbers}} }} {{eqn | r = \sum_{n \mathop = 0}^\infty \frac {E_{2 n} \paren {i x}^{2 n} } {\paren {2 n}!} | c = [[Definition:Odd Integer|Odd]] terms vanish }} {{eqn | r = \sum_{n \mathop = 0}^\infty \frac {\paren {-1}^n E_{2 n} x^{2 n} } {\paren {2 n}!} }} {{end-eqn}} {{qed}}	0
A [[Definition:Semiprime Number|semiprime]] with [[Definition:Distinct|distinct]] [[Definition:Prime Factor|prime factors]] is a [[Definition:Square-Free|square-free]] [[Definition:Integer|integer]]. By [[Sigma Function of Square-Free Integer]]: :$\ds \map \sigma n = \prod_{1 \mathop \le i \mathop \le r} p_i + 1$ Hence the result. {{qed}}	0
:$\displaystyle \int \frac {x^3 \rd x} {a x + b} = \frac {\paren {a x + b}^3} {3 a^4} - \frac {3 b \paren {a x + b}^2} {2 a^4} - \frac {3 b^2 \paren {a x + b} } {a^4} + \frac {b^3} {a^4} \ln \size {a x + b} + C$	0
From the [[Multiple Rule for Real Sequences]], we have: :$\displaystyle \lim_{n \mathop \to \infty} \paren {\lambda x_n} = \lambda l$ :$\displaystyle \lim_{n \mathop \to \infty} \paren {\mu y_n} = \mu m$ The result now follows directly from the [[Sum Rule for Real Sequences]]: :$\displaystyle \lim_{n \mathop \to \infty} \paren {\lambda x_n + \mu y_n} = \lambda l + \mu m$ {{qed}}	0
We have that: :[[Infinite Cyclic Group is Isomorphic to Integers]]. :[[Integer Multiples under Addition form Infinite Cyclic Group]]. :[[Infinite Cyclic Group is Unique up to Isomorphism]] Hence the result. {{qed}}	0
From [[Roots of Unity under Multiplication form Cyclic Group]], $\struct {U_n, \times}$ is a [[Definition:Group|group]]. The result follows from [[Power of Generator of Cyclic Group is Generator iff Power is Coprime with Order]]. {{qed}}	0
{{begin-eqn}} {{eqn | l = \map {\frac \d {\d x} } {\ln e^x} | r = \map {\frac \d {\d x} } x | c = [[Exponential of Natural Logarithm]] }} {{eqn | ll= \leadsto | l = \frac 1 {e^x} \map {\frac \d {\d x} } {e^x} | r = 1 | c = [[Chain Rule for Derivatives]], [[Derivative of Natural Logarithm Function]], [[Derivative of Identity Function]] }} {{eqn | ll= \leadsto | l = \map {\frac \d {\d x} } {e^x} | r = e^x | c = multiply both sides by $e^x$ }} {{end-eqn}} {{qed}}	0
Let $0_D$ and $1_D$ be the [[Definition:Ring Zero|zero]] and [[Definition:Unity of Ring|unity]] respectively of $D$. Let $J$ be the [[Definition:Set|set]] of all [[Definition:Linear Combination|linear combinations]] in $D$ of $\set {a_1, a_2, \dotsc, a_n}$. From [[Set of Linear Combinations of Finite Set of Elements of Principal Ideal Domain is Principal Ideal]]: :$J = \ideal x$ for some $x \in D$, where $\ideal x$ denotes the [[Definition:Principal Ideal of Ring|principal ideal]] [[Definition:Generator of Ideal|generated]] by $x$. We have that each $a_i$ can be expressed as a [[Definition:Linear Combination|linear combination]] of $\set {a_1, a_2, \dotsc, a_n}$: :$a_i = 0_D a_1 + 0_d a_2 + \dotsb + 1_D a_i + \dotsb + 0_D a_n$ Thus: :$\forall i \in \set {0, 1, \dotsc, n}: a_i \in J$ and so by definition of $J$: :$\forall i \in \set {0, 1, \dotsc, n}: a_i = t_i x$ for some $t_i \in D$. Thus $x$ is a [[Definition:Common Divisor of Ring Elements|common divisor]] of $a_1, a_2, \dotsc, a_n$. As $x \in \ideal x = J$, we have: :$x = c_1 a_1 + c_2 a_2 + \dotsb + c_n a_n$ for some $c_1, c_2, \dotsc, c_n \in D$. Thus every [[Definition:Common Divisor of Ring Elements|common divisor]] of $a_1, a_2, \dotsc, a_n$ also is a [[Definition:Divisor of Ring Element|divisor]] of $x$. Thus $x$ is a [[Definition:Greatest Common Divisor of Ring Elements|greatest common divisor]] of $a_1, a_2, \dotsc, a_n$. {{qed}}	0
{{begin-eqn}} {{eqn | l = \cos x | r = 2 \cos^2 \frac x 2 - 1 | c = [[Double Angle Formulas/Cosine/Corollary 1|Cosine Double Angle Formula]] }} {{eqn | ll= \leadstoandfrom | l = 1 + \cos x | r = 2 \cos^2 \frac x 2 | c = adding $1$ to both sides }} {{eqn | ll= \leadstoandfrom | l = \frac 1 {1 + \cos x} | r = \frac 1 2 \frac 1 {\cos^2 \frac x 2} | c = taking the [[Definition:Reciprocal|reciprocal]] of both sides }} {{eqn | r = \frac 1 2 \sec^2 \frac x 2 | c = {{Defof|Secant Function}} }} {{end-eqn}} {{qed}}	0
{{ProofWanted}} {{Namedfor|Magnus Gustaf Mittag-Leffler|cat = Mittag-Leffler}}	0
{{ProofWanted}} {{Namedfor|Alfred Cardew Dixon}}	0
{{:Euclid:Proposition/V/8}} That is: :$a > b \implies a : c > b : c$ :$a > b \implies c : a < c : b$	0
By [[Null Sequences form Maximal Left and Right Ideal]] then $\NN$ is an [[Definition:Ideal of Ring|ideal]] of the [[Definition:Ring of Sequences|ring $\CC$]] that is also a [[Definition:Maximal Left Ideal of Ring|maximal left ideal]]. By [[Maximal Left and Right Ideal iff Quotient Ring is Division Ring]] then the [[Definition:Quotient Ring|quotient ring]] $\CC / \NN$ is a [[Definition:Division Ring|division ring]] {{qed}}	0
The proof proceeds by [[Principle of Mathematical Induction|induction]] on $m$. For all $m \in \Z_{\ge 0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\displaystyle \forall n \in \Z_{\ge 0}: \sum_k \binom m k \paren {-1}^{m - k} k^n = m! {n \brace m}$ === Basis for the Induction === $\map P 0$ is the case: {{begin-eqn}} {{eqn | r = \sum_k \binom 0 k \paren {-1}^{0 - k} k^n | o = | c = }} {{eqn | r = \sum_k \delta_{0 k} \paren {-1}^{- k} k^n | c = [[Zero Choose n]] }} {{eqn | r = \paren {-1}^{- 0} 0^n | c = all terms vanish except for $k = 0$ }} {{eqn | r = \delta_{0 n} | c = $0^n = 0$ except when $n = 0$, as $0^0 = 1$ }} {{eqn | r = 0! {n \brace 0} | c = {{Defof|Stirling Numbers of the Second Kind}} }} {{end-eqn}} So $\map P 0$ is seen to hold. This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that, if $\map P r$ is true, where $r \ge 1$, then it logically follows that $\map P {r + 1}$ is true. So this is the [[Definition:Induction Hypothesis|induction hypothesis]]: :$\displaystyle \sum_k \binom r k \paren {-1}^{r - k} k^n = r! {n \brace r}$ from which it is to be shown that: :$\displaystyle \sum_k \binom {r + 1} k \paren {-1}^{r + 1 - k} k^n = \paren {r + 1}! {n \brace r + 1}$ === Induction Step === This is the [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | o = | r = \sum_k \binom {r + 1} k \paren {-1}^{r + 1 - k} k^n | c = }} {{eqn | r = \sum_k \paren {\binom r k + \binom r {k - 1} } \paren {-1}^{r + 1 - k} k^n | c = [[Pascal's Rule]] }} {{eqn | r = \sum_k \binom r k \paren {-1}^{r + 1 - k} k^n + \sum_k \binom r {k - 1} \paren {-1}^{r + 1 - k} k^n | c = }} {{eqn | r = -\sum_k \binom r k \paren {-1}^{r - k} k^n + \sum_k \binom r {k - 1} \paren {-1}^{r - \paren {k - 1} } k^n | c = }} {{eqn | r = -r! {n \brace r} + \sum_k \binom r {k - 1} \paren {-1}^{r - \paren {k - 1} } k^n | c = [[Sum over k of m choose k by -1^m-k by k to the n#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = -r! {n \brace r} + \sum_k \binom r k \paren {-1}^{r - k} \paren {k + 1}^n | c = [[Translation of Index Variable of Summation]] }} {{end-eqn}} {{finish|The next step to take is not clear.}} So $\map P r \implies \map P {r + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\displaystyle \forall m, n \in \Z_{\ge 0}: \sum_k \binom m k \paren {-1}^{m - k} k^n = m! {n \brace m}$ {{qed}}	0
By admitting $y = \left({x + y}\right) - x$, we have that: :$\left({x + y}\right)^n = \left({x + \left({x + y}\right) - x}\right)^n$ Expanding the {{RHS}} in powers of $\left({x + y}\right)$: {{begin-eqn}} {{eqn | o = | r = \sum_k \binom n k x \left({x - k z}\right)^{k - 1} \left({y + k z}\right)^{n - k} | c = }} {{eqn | r = \sum_k \binom n k x \left({x - k z}\right)^{k - 1} \left({x + \left({x + y}\right) + k z}\right)^{n - k} | c = }} {{eqn | r = \sum_k \binom n k x \left({x - k z}\right)^{k - 1} \sum_j \left({x + y}\right)^j \left({-x + k z}\right)^{n - k - j} \binom {n - k} j | c = }} {{eqn | r = \sum_j \binom n j \left({x + y}\right)^j \sum_k \binom {n - j} {n - j - k} x \left({x - k z}\right)^{k - 1} \left({-x + k z}\right)^{n - k - j} | c = }} {{eqn | r = \sum_{j \mathop \le n} \binom n j \left({x + y}\right)^j 0^{n - j} | c = [[Binomial Theorem/Abel's Generalisation/x+y = 0|Abel's Generalisation of Binomial Theorem: Special Case $x + y = 0$]] }} {{eqn | r = \left({x + y}\right)^n | c = [[Binomial Theorem]] }} {{end-eqn}} {{qed}}	0
The operation of [[Definition:Complex Addition|addition]] on the [[Definition:Set|set]] of [[Definition:Complex Number|complex numbers]] $\C$ is [[Definition:Associative|associative]]: :$\forall z_1, z_2, z_3 \in \C: z_1 + \paren {z_2 + z_3} = \paren {z_1 + z_2} + z_3$	0
Let $p$ be a [[Definition:Prime Number|prime number]]. Let $\norm {\,\cdot\,}_p$ be the [[Definition:P-adic Norm|$p$-adic norm]] on the [[Definition:Rational Number|rational numbers]] $\Q$. Let $\struct {\Q_p, \norm {\,\cdot\,}_p}$ be the [[Definition:P-adic Numbers as Quotient of Cauchy Sequences|$p$-adic numbers as a quotient of Cauchy sequences]]. Let $\sequence{\alpha_n}$ and $\sequence{\beta_n}$ be [[Definition:Cauchy Sequence in Normed Division Ring|Cauchy sequences]] in $\struct {Q, \norm {\,\cdot\,}_p}$. Then: :$\sequence {\alpha_n}$ and $\sequence {\beta_n}$ are [[Definition:Representative of Equivalence Class|representatives]] of the same [[Definition:Equivalence Class|equivalence class]] in $\Q_p$ {{iff}}: :the [[Definition:Sequence|sequence]] $\sequence {\alpha_n - \beta_n}$ is a [[Definition:Null Sequence in Normed Division Ring|null sequence]].	0
This proof assumes the definition of the [[Definition:Natural Logarithm|natural logarithm]] as the inverse of the [[Definition:Exponential Function/Real/Differential Equation|exponential function as defined by differential equation]]: :$y = \dfrac {\d y} {\d x}$ :$y = e^x \iff \ln y = x$ {{begin-eqn}} {{eqn | l = \frac {\d y} {\d x} | r = y | c = {{Defof|Exponential Function/Real|subdef = Differential Equation|Exponential Function}} }} {{eqn | l = \int \frac 1 y \rd y | r = \int \rd x | c = [[Separation of Variables]] }} {{eqn | r = x + C_0 | c = [[Integral of Constant]] where that constant is $1$ }} {{eqn | r = \ln y + C_0 | c = {{Defof|Natural Logarithm/Positive Real|index = 2|Natural Logarithm}}: $x = \ln y$ }} {{end-eqn}} The result follows from the definition of the [[Definition:Primitive (Calculus)|antiderivative]] and the [[Definition:Exponential Function/Real/Differential Equation|defined]] [[Definition:Initial Condition|initial condition]]: :$\tuple {x_0, y_0} = \tuple {0, 1}$ {{qed}}	0
:$18 \bmod -3 = 0$	0
Let $f: \C \to \C$ be an [[Definition:Entire Function|entire function]]. Let $\ln$ denote the [[Definition:Natural Logarithm|natural logarithm]]. {{TFAE| def = Order of Entire Function}}	0
Let $x < 0$. {{AimForCont}} $\dfrac 1 x > 0$. Then: {{begin-eqn}} {{eqn | l = x | o = < | r = 0 | c = }} {{eqn | ll= \leadsto | l = x \times \dfrac 1 x | o = < | r = 0 \times 0 | c = [[Real Number Ordering is Compatible with Multiplication/Negative Factor|Real Number Ordering is Compatible with Multiplication: Negative Factor]] }} {{eqn | ll= \leadsto | l = 1 | o = < | r = 0 | c = [[Definition:Real Number Axioms|Real Number Axioms: $\R \text M 4$: Inverse]] }} {{end-eqn}} But from [[Real Zero is Less than Real One]]: :$1 > 0$ Therefore by [[Proof by Contradiction]]: :$\dfrac 1 x < 0$ {{qed}}	0
{{ProofWanted|To be proved that there are no smaller such $4$th powers.}}	0
From [[Positive Real Complex Root of Unity]], we have that $1$ is the only element of $U_n$ which is a [[Definition:Positive Real Number|positive real number]]. We note that $\paren {-1}^n = 1$ as $n$ is [[Definition:Even Integer|even]]. Thus $-1$ is also an element of $U_n$. Now let $z \in U_n$ such that $\cmod z \ne 1$. Let $z > 0$. From [[Positive Power Function on Non-negative Reals is Strictly Increasing]] it follows that: :$z < 1 \implies z^n < 1$ and: :$z > 1 \implies z^n > 1$ Let $z < 0$. From [[Positive Power Function on Negative Reals is Strictly Decreasing]] it follows that: :$z < -1 \implies z^n > 1$ and: :$z > -1 \implies z^n < 1$ That is, in all cases where $\cmod z \ne 1$ we have that $z^n \ne 1$. {{qed}}	0
Let $i : A \to A_S$ and $j : A \to A_T$ be the [[Definition:Localization Homomorphism of Ring|localization homomorphisms]]. === 1 implies 2 === Let $h : A_S \to A_T$ be an $A$-[[Definition:Unital Associative Commutative Algebra Homomorphism|algebra homomorphism]]. Then by definition, $j = h \circ i$: :$\xymatrix{ A \ar[d]_i \ar[r]^{j} & A_T\\ A_S \ar[ru]_{h} }$ Let $s \in S$. By definition of [[Definition:Localization of Ring|localization]], $i(s)$ is a [[Definition:Unit of Ring|unit]] of $A_S$. By [[Ring Homomorphism Preserves Invertible Elements]], $j(s) = h(i(s))$ is a [[Definition:Unit of Ring|unit]] of $A_T$. Thus $s$ is an [[Definition:Element of Set|element]] of the [[Definition:Saturation of Multiplicatively Closed Subset of Ring|saturation]] of $T$. {{qed|lemma}} === 2 implies 1 === Let $S$ be a [[Definition:Subset|subset]] of the [[Definition:Saturation of Multiplicatively Closed Subset of Ring|saturation]] of $T$. Then its [[Definition:Image of Subset under Mapping|image]] $j(S) \subseteq A_T^\times$ consists of [[Definition:Unit of Ring|units]] of $A_T$. By definition of [[Definition:Localization of Ring|localization]] at $S$, there exists a [[Definition:Unique|unique]] $A$-[[Definition:Unital Associative Commutative Algebra Homomorphism|algebra homomorphism]] $h : A_S \to A_T$. {{qed|lemma}} === 2 implies 3 === Let $S$ be a [[Definition:Subset|subset]] of the [[Definition:Saturation of Multiplicatively Closed Subset of Ring|saturation]] of $T$. By definition, its [[Definition:Saturation of Multiplicatively Closed Subset of Ring|saturation]] is the [[Definition:Smallest|smallest]] [[Definition:Saturated Multiplicatively Closed Subset of Ring|saturated multiplicatively closed subset]] of $A$ containing $S$. Thus the [[Definition:Saturation of Multiplicatively Closed Subset of Ring|saturation]] of $S$ is a subset of the saturation of $T$. {{qed|lemma}} === 3 implies 2 === By definition, $S$ is a [[Definition:Subset|subset]] of its [[Definition:Saturation of Multiplicatively Closed Subset of Ring|saturation]]. {{qed|lemma}} === 3 iff 4 === By definition, the [[Definition:Saturation of Multiplicatively Closed Subset of Ring|saturation]] of $S$ is the [[Definition:Relative Complement|complement]] of the [[Definition:Set Union|union]] of [[Definition:Prime Ideal of Ring|prime ideals]] that are [[Definition:Disjoint Sets|disjoint]] from $S$: :$\operatorname{Sat}(S) = A - \displaystyle \bigcup \left\{ \mathfrak p \in \operatorname{Spec} A : \mathfrak p \cap S = \varnothing \right\}$ Thus: {{begin-eqn}} {{eqn | l = \operatorname{Sat}(S) \subseteq \operatorname{Sat}(T) | r = A - \bigcup \left\{ \mathfrak p \in \operatorname{Spec} A : \mathfrak p \cap S = \varnothing \right\} \subseteq A - \bigcup \left\{ \mathfrak p \in \operatorname{Spec} A : \mathfrak p \cap T = \varnothing \right\} | o = \iff }} {{eqn | r = \bigcup \left\{ \mathfrak p \in \operatorname{Spec} A : \mathfrak p \cap S = \varnothing \right\} \supseteq \bigcup \left\{ \mathfrak p \in \operatorname{Spec} A : \mathfrak p \cap T = \varnothing \right\} | o = \iff | c = [[Subset iff Complement is Superset of Complement]] }} {{eqn | r = \forall \mathfrak p \in \operatorname{Spec} A : \left( \mathfrak p \cap T = \varnothing \implies \mathfrak p \subseteq \bigcup \left\{ \mathfrak q \in \operatorname{Spec} A : \mathfrak q \cap S = \varnothing \right\} \right) | o = \iff | c = [[Sets are Subset iff Union is Subset]] }} {{end-eqn}} To finish, we show that the last statement is equivalent to: :$\forall \mathfrak p \in \operatorname{Spec} A : \mathfrak p \cap T = \varnothing \implies \mathfrak p \cap S = \varnothing$ We show that, for $\mathfrak p \in \operatorname{Spec} A$: :$\mathfrak p \subseteq \displaystyle \bigcup \left\{ \mathfrak q \in \operatorname{Spec} A : \mathfrak q \cap S = \varnothing \right\} \iff \mathfrak p \cap S = \varnothing$ Let $\mathfrak p \in \operatorname{Spec} A$. If $\mathfrak p \cap S = \varnothing$, then by [[Set is Subset of Union]]: :$\mathfrak p \subseteq \displaystyle \bigcup \left\{ \mathfrak q \in \operatorname{Spec} A : \mathfrak q \cap S = \varnothing \right\}$ Conversely, let $\mathfrak p \subseteq \displaystyle \bigcup \left\{ \mathfrak q \in \operatorname{Spec} A : \mathfrak q \cap S = \varnothing \right\}$. By: :[[Union of Sets Disjoint with Set]] :[[Subset of Disjoint Set]] we have $\mathfrak p \cap S = \varnothing$. We conclude that $ \operatorname{Sat}(S) \subseteq \operatorname{Sat}(T)$ {{iff}} :$\forall \mathfrak p \in \operatorname{Spec} A : \mathfrak p \cap T = \varnothing \implies \mathfrak p \cap S = \varnothing$ That is: :$\forall \mathfrak p \in \operatorname{Spec} A : \mathfrak p \cap S \neq \varnothing \implies \mathfrak p \cap T \neq \varnothing$ {{qed}}	0
For all $n \in \N_{\ge 2}$: :$F_n \ge \phi^{n - 2}$ where: :$F_n$ is the $n$th [[Definition:Fibonacci Numbers|Fibonacci number]] :$\phi$ is the [[Definition:Golden Section|golden section]]: $\phi = \dfrac {1 + \sqrt 5} 2$	0
:$\displaystyle \int \frac {\mathrm d x} {x^2 \left({x^3 + a^3}\right)^2} = \frac {-1} {a^6 x} - \frac {x^2} {3 a^6 \left({x^3 + a^3}\right)} - \frac 4 {3 a^6} \int \frac {x \ \mathrm d x} {x^3 + a^3}$	0
=== 1 implies 2 === It suffices to show that: :$(1): \quad \displaystyle \sum_{n \mathop = 1}^\infty \map \Re {\ln f_n} = \map \Re {\ln f}$ [[Definition:Locally Uniform Convergence|locally uniformly]] :$(2): \quad \displaystyle \sum_{n \mathop = 1}^\infty \map \Im {\ln f_n} = \map \Im {\ln f} + 2 k \pi$ [[Definition:Locally Uniform Convergence|locally uniformly]] for some $k: K \to \Z$ ==== Real part ==== By [[Absolute Value of Uniformly Convergent Product]], $\displaystyle \prod_{n \mathop = 1}^\infty \cmod {f_n} = \cmod f$ [[Definition:Locally Uniform Convergence of Product|locally uniformly]]. By [[Logarithm of Infinite Product of Real Functions]] $\displaystyle \sum_{n \mathop = 1}^\infty \ln \cmod {f_n} = \ln \cmod f$ [[Definition:Locally Uniform Convergence|locally uniformly]]. Hence the result. ==== Imaginary Part ==== Let $K\subset X$ be [[Definition:Compact Space|compact]]. Let $P_n$ denote the $n$th [[Definition:Partial Product|partial product]]. Then $P_n \to f$ [[Definition:Uniform Convergence|uniformly]] on $K$. Let $\theta$ be the [[Definition:Argument of Complex Number|argument]] of $f$. Let $\theta_n = \arg P_n$ be the argument of $P_n$ in the [[Definition:Half-Open Real Interval|half-open interval]] $\hointl {\theta - \pi} {\theta + \pi}$. By [[Uniform Convergence of Complex Functions in Polar Form/Corollary|the corollary to Uniform Convergence of Complex Functions in Polar Form]]: :$\theta_n \to \theta$ [[Definition:Uniform Convergence|uniformly]] on $K$. Let $k_n: K \to \Z$ be such that: :$\displaystyle \sum_{j \mathop = 1}^n \map \Im {\ln \map {f_n} x} = \map {\theta_n} x + 2 \map {k_n} x \pi$ We show that $k_n$ is eventually equal to a fixed function $k: K \to \Z$. By the [[Triangle Inequality for Complex Numbers]]: :$2 \pi \sup_{x \mathop \in K} \size {\map {k_{n + 1} } x - \map {k_n} x} \le \sup_{x \mathop \in K} \cmod {\map {\theta_{n + 1} } x - \map {\theta_n} x} + \sup_{x \mathop \in K} \size {\map \Im {\ln \map {f_{n + 1} } x } }$ By [[Factors in Uniformly Convergent Product Converge Uniformly to One]], $f_n \to 1$ [[Definition:Uniform Convergence|uniformly]] on $K$. Let $n_0 \in \N$ be such that $\cmod {f_n - 1} \le \dfrac 1 2$ for $n \ge n_0$. By [[Complex Logarithm is Continuous Outside Branch]] and [[Heine-Cantor Theorem]], $\ln$ is [[Definition:Uniform Continuity|uniformly continuous]] on $\map {\overline B} {1, \dfrac 1 2}$. By [[Uniformly Continuous Function Preserves Uniform Convergence]], $\ln f_n \to 0$ [[Definition:Uniform Convergence|uniformly]] on $K$. Thus $\displaystyle 2 \pi \sup_{x \mathop \in K} \cmod {\map {k_{n + 1} } x - \map {k_n} x} \to 0$. So the sequence $k_n$ is eventually constant, say equal to $k: K \to \Z$. Then: :$\displaystyle \sum_{j \mathop = 1}^n \map \Im {\ln f_n} \to \theta + 2 k \pi$ [[Definition:Uniform Convergence|uniformly]] on $K$. {{qed|lemma}} === 2 implies 1 === Follows from [[Complex Exponential is Uniformly Continuous on Half-Planes]]. {{ProofWanted|Explain how.}}	0
From [[Aurifeuillian Factorization of 2 Mod 4th Power of Two plus 1]], we have: :$2^{4 n + 2} + 1 = \left({2^{2 n + 1} - 2^{n + 1} + 1}\right) \left({2^{2 n + 1} + 2^{n + 1} + 1}\right)$ Setting $n = 14$: {{begin-eqn}} {{eqn | l = 2^{58} + 1 | r = \left({2^{29} - 2^{15} + 1}\right) \left({2^{29} + 2^{15} + 1}\right) | c = }} {{eqn | r = \left({536 \, 870 \, 912 - 32 \, 768 + 1}\right) \left({536 \, 870 \, 912 + 32 \, 768 + 1}\right) | c = }} {{eqn | r = 536 \, 838 \, 145 \times 536 \, 903 \, 681 | c = }} {{eqn | r = 5 \times 107 \, 367 \, 629 \times 536 \, 903 \, 681 | c = }} {{end-eqn}} {{qed}}	0
Let $I_1$ and $I_2$ be [[Definition:Real Interval|real intervals]]. Then $I_1 \cup I_2$ is not necessarily a [[Definition:Real Interval|real interval]].	0
Let $\map D n$ denote the [[Definition:Integer Multiplication|product]] of '''all''' the [[Definition:Divisor of Integer|divisors]] of $n$. From [[Product of Divisors]]: :$\map D n = n^{\map \tau n / 2}$ The [[Definition:Proper Divisor of Integer|proper divisors]] of $n$ are defined as being the [[Definition:Divisor of Integer|divisors]] of $n$ excluding $n$ itself. Thus: :$\map P n = \dfrac {\map D n} n = \dfrac {n^{\map \tau n / 2} } n = n^{\map \tau n / 2 - 1}$ {{qed}}	0
Let $p$ be a [[Definition:Prime Number|prime number]]. Let $\struct {\Q_p, \norm {\,\cdot\,}_p}$ be the [[Definition:P-adic Number|$p$-adic numbers]]. Let $\Z_p$ denote the [[Definition:P-adic Integers|$p$-adic integers]]. Let $a \in \Q_p$. For all $\epsilon \in \R_{>0}$, let $\map { {B_\epsilon}^-} a$ denote the [[Definition:Closed Ball in P-adic Numbers|closed ball]] of $a$ of [[Definition:Radius of Closed Ball in P-adic Numbers|radius]] $\epsilon$. Then: :$\forall n \in Z : \map {B^-_{p^{-n} } } a = a + p^n \Z_p$ where $a + p^n \Z_p$ denotes the [[Definition:Left Coset|left coset]] of the [[Definition:Principal Ideal|principal ideal]] $p^n \Z_p$ containing $a$ in the [[Definition:Subring|subring]] $\Z_p$. That is, the [[Definition:Closed Ball in P-adic Numbers|closed ball]] $\map { {B_\epsilon}^-} a$ is the [[Definition:Set|set]]: :$a + p^n \Z_p = \set{a + p^n z : z \in \Z_p}$	0
Let $n!$ denote the [[Definition:Factorial|factorial]] of $n$. The number of [[Definition:Digit|digits]] in $n!$ is approximately: :$1 + \left\lfloor{\dfrac 1 2 \left({\log_{10} 2 + \log_{10} \pi}\right) + \dfrac 1 2 \log_{10} n + n \left({\log_{10} n - \log_{10} e}\right)}\right\rfloor$ when $n!$ is shown in [[Definition:Decimal Notation|decimal notation]]. This evaluates to: :$1 + \left\lfloor{\left({n + \dfrac 1 2}\right) \log_{10} n - 0.43429 \ 4481 \, n + 0.39908 \ 9934}\right\rfloor$	0
{{begin-eqn}} {{eqn | l = \int \frac {\mathrm d x} {\cos^2 a x} | r = \int \sec^2 a x \ \mathrm d x | c = Definition of [[Definition:Cosecant/Analysis|Cosecant]] }} {{eqn | r = \frac {\tan a x} a + C | c = [[Primitive of Square of Secant of a x|Primitive of $\sec^2 a x$]] }} {{end-eqn}} {{qed}}	0
Let $\map \Re p > 1$. Then the [[Definition:P-Series|$p$-series]]: :$\displaystyle \sum_{n \mathop = 1}^\infty n^{-p}$ [[Definition:Absolutely Convergent Series|converges absolutely]].	0
For any $\epsilon \in \R_{>0}$ and $a \in \Q_p$ let $\map {B_\epsilon^-} a$ denote the [[Definition:Closed Ball in P-adic Numbers|closed $\epsilon$-ball]] of $a$. From [[Closed Balls of P-adic Number]]: :$\BB_p = \set {q + p^n \Z_p : q \in \Q, n \in \Z} = \set {\map {B^-_{p^{-n} } } q : q \in \Q, n \in \Z}$ From [[Countable Closed Ball Basis for P-adic Numbers]]: :$\BB_p$ is a [[Definition:Countable Basis|countable basis]] for $\struct{\Q_p, \tau_p}$. {{qed}}	0
Let $S_n$ denote the [[Definition:Set|set]] of all [[Definition:Positive Integer|positive integers]] less than and [[Definition:Coprime Integers|coprime]] to $n$, excluding $1$. Let $\map P n$ denote the [[Definition:Propositional Function|propositional function]]: :All [[Definition:Positive Integer|positive integers]] less than and [[Definition:Coprime Integers|coprime]] to $n$, excluding $1$, are [[Definition:Prime Number|prime]]. We establish that $\map P n = \mathrm T$ for all the [[Definition:Positive Integer|positive integers]] given: {{begin-eqn}} {{eqn | l = S_1 | r = \varnothing | c = trivially }} {{eqn | l = S_2 | r = \varnothing | c = trivially }} {{eqn | l = S_3 | r = \set 2 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = S_4 | r = \set 3 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = S_6 | r = \set 5 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = S_8 | r = \set {3, 5, 7} | c = all [[Definition:Prime Number|prime]] }} {{eqn | l = S_{12} | r = \set {5, 7, 11} | c = all [[Definition:Prime Number|prime]] }} {{eqn | l = S_{18} | r = \set {5, 7, 11, 13, 17} | c = all [[Definition:Prime Number|prime]] }} {{eqn | l = S_{24} | r = \set {5, 7, 11, 13, 17, 19, 23} | c = all [[Definition:Prime Number|prime]] }} {{eqn | l = S_{30} | r = \set {7, 11, 13, 17, 19, 23, 29} | c = all [[Definition:Prime Number|prime]] }} {{end-eqn}} From [[Schatunowsky's Theorem]]: :$30$ is the greatest [[Definition:Positive Integer|positive integer]] $n$ such that $\map P n$ is [[Definition:True|true]] We note that for all [[Definition:Prime Number|primes]] $p$ greater than $3$, $p - 1$ is [[Definition:Composite Number|composite]], and so $\map P p = \mathrm F$. The remaining [[Definition:Composite Number|composite numbers]] less than $30$ are investigated: {{begin-eqn}} {{eqn | l = S_9 | r = \set {2, 4, 5, 7, 8} | c = of which $2, 4, 8$ are [[Definition:Composite Number|composite]] }} {{eqn | l = S_{10} | r = \set {3, 7, 9} | c = of which $9$ is [[Definition:Composite Number|composite]], }} {{eqn | l = S_{14} | r = \set {3, 5, 9, 11, 13} | c = of which $9$ is [[Definition:Composite Number|composite]] }} {{eqn | l = S_{15} | r = \set {2, 4, 7, 8, 11, 13, 14} | c = of which $4, 8, 14$ are [[Definition:Composite Number|composite]] }} {{eqn | l = S_{16} | r = \set {3, 5, 7, 9, 11, 13, 15} | c = of which $9, 15$ are [[Definition:Composite Number|composite]] }} {{eqn | l = S_{20} | r = \set {3, 7, 9, 11, 13, 17, 19} | c = of which $9$ is [[Definition:Composite Number|composite]] }} {{eqn | l = S_{21} | r = \set {2, 4, 5, 8, 10, 11, 13, 16, 17, 19, 20} | c = of which $4, 8, 10, 16, 20$ are [[Definition:Composite Number|composite]] }} {{eqn | l = S_{22} | r = \set {3, 5, 7, 9, 13, 15, 17, 19, 21} | c = of which $9, 15, 21$ are [[Definition:Composite Number|composite]] }} {{eqn | l = S_{25} | r = \set {2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24} | c = of which $4, 6, 8, 9, 12, 14, 16, 18, 21, 22, 24$ are [[Definition:Composite Number|composite]] }} {{eqn | l = S_{26} | r = \set {3, 5, 7, 9, 11, 15, 17, 19, 21, 23, 25} | c = of which $9, 15, 21, 25$ are [[Definition:Composite Number|composite]] }} {{eqn | l = S_{27} | r = \set {2, 4, 5, 7, 8, 10, 11, 13, 14, 16, 17, 19, 20, 22, 23, 25, 26} | c = of which $4, 8, 10, 14, 16, 20, 22, 25, 26$ are [[Definition:Composite Number|composite]] }} {{eqn | l = S_{28} | r = \set {3, 5, 9, 11, 13, 15, 17, 19, 23, 25, 27} | c = of which $9, 15, 25, 27$ are [[Definition:Composite Number|composite]] }} {{end-eqn}} That exhausts the list. Hence the result. {{qed}}	0
{{begin-eqn}} {{eqn | l = \int_0^\infty \frac {x^{p - 1} \ln x} {1 + x} \rd x | r = \int_0^\infty \frac 1 {1 + x} \map {\frac \partial {\partial p} } {x^{p - 1} } \rd x | c = [[Derivative of Power of Constant]] }} {{eqn | r = \frac \d {\d p} \int_0^\infty \frac {x^{p - 1} } {1 + x} \rd x | c = [[Definite Integral of Partial Derivative]] }} {{eqn | r = \map {\frac \d {\d p} } {\pi \csc p \pi} | c = [[Definite Integral to Infinity of Power of x over 1 + x|Definite Integral to Infinity of $\dfrac {x^{p - 1} } {1 + x}$]] }} {{eqn | r = -\pi^2 \csc p \pi \cot p \pi | c = [[Chain Rule for Derivatives]], [[Derivative of Cosecant Function]] }} {{end-eqn}} {{qed}}	0
Let $n \in \Z_{> 0}$ be a [[Definition:Strictly Positive Integer|(strictly) positive integer]]. {{begin-eqn}} {{eqn | l = E_{2 n} | r = \paren {-1}^{n + 1} \dfrac {2^{2 n + 2} \paren {2 n}!} {\pi^{2 n + 1} } \sum_{j \mathop = 0}^\infty \frac {\paren {-1}^j} {\paren {2 j + 1}^{2 n + 1} } | c = }} {{eqn | r = \paren {-1}^{n + 1} \dfrac {2^{2 n + 2} \paren {2 n}!} {\pi^{2 n + 1} } \paren {\frac 1 {1^{2 n + 1} } - \frac 1 {3^{2 n + 1} } + \frac 1 {5^{2 n + 1} } - \frac 1 {7^{2 n + 1} } + \cdots} | c = }} {{end-eqn}}	0
{{begin-eqn}} {{eqn | l = a | o = \equiv | r = b | rr= \pmod z | c = }} {{eqn | l = c | o = \equiv | r = d | rr= \pmod z | c = }} {{eqn | ll= \leadsto | l = a \bmod z | r = b \bmod z | c = {{Defof|Congruence (Number Theory)|Congruence}} }} {{eqn | l = x \bmod z | r = y \bmod z | c = }} {{eqn | ll= \leadsto | lo= \exists k_1 \in \Z: | l = a - b | r = k_1 z | c = }} {{eqn | lo= \exists k_2 \in \Z: | l = x - y | r = k_2 z | c = }} {{eqn | ll= \leadsto | l = \paren {a + x} - \paren {b + y} | r = \paren {k_1 + k_2} z | c = {{Defof|Integer Addition}} }} {{eqn | ll= \leadsto | l = a + x | o = \equiv | r = b + y | rr= \pmod z | c = {{Defof|Congruence (Number Theory)|Congruence}} }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \int \frac {\d x} {p^2 \sin^2 a x - q^2 \cos^2 a x} | r = \int \frac {\sec^2 a x} {p^2 \tan^2 a x - q^2} \rd x | c = multiplying by $\dfrac {\sec^2 a x} {\sec^2 a x}$ }} {{eqn | r = \frac 1 a \int \frac 1 {p^2 t^2 - q^2} \rd t | c = [[Integration by Substitution|substituting]] $t = \tan a x$ }} {{eqn | r = \frac 1 {a p^2} \int \frac 1 {t^2 - \paren {\frac q p}^2} \rd t }} {{eqn | r = \frac 1 {2 a \frac {p^2} p q} \ln \size {\frac {t - \frac q p} {t + \frac q p} } + C | c = [[Primitive of Reciprocal of x squared minus a squared/Logarithm Form|Primitive of $\dfrac 1 {x^2 - a^2}$: Logarithm Form]] }} {{eqn | r = \frac 1 {2 a p q} \ln \size {\frac {p t - q} {p t + q} } + C }} {{eqn | r = \frac 1 {2 a p q} \ln \size {\frac {p \tan a x - q} {p \tan a x + q} } + C | c = substituting back for $t$ }} {{end-eqn}} {{qed}}	0
Let $P = \tuple {x, y}$ be a [[Definition:Point|point]] in the [[Definition:Cartesian Plane|cartesian plane]] whose [[Definition:Origin|origin]] is at $O$. Let $\theta$ be the [[Definition:Angle|angle]] between the [[Definition:X-Axis|$x$-axis]] and the [[Definition:Line Segment|line]] $OP$. Let $r$ be the [[Definition:Length (Linear Measure)|length]] of $OP$. Then: :$\cot \theta = \dfrac x y$ where $\cot$ denotes the [[Definition:Cotangent of Angle|cotangent]] of $\theta$.	0
{{begin-eqn}} {{eqn | l = \int x \map \ln {x^2 + a^2} \rd x | r = \frac {x^2 \map \ln {x^2 + a^2} } 2 - \int \frac {x^3} {x^2 + a^2} \rd x + C | c = [[Primitive of Power of x by Logarithm of x squared plus a squared|Primitive of $x^m \map \ln {x^2 + a^2}$]] with $m = 1$ }} {{eqn | r = \frac {x^2 \map \ln {x^2 + a^2} } 2 - \paren {\frac {x^2} 2 - \frac {a^2} 2 \map \ln {x^2 + a^2} } + C | c = [[Primitive of x cubed over x squared plus a squared|Primitive of $\dfrac {x^3} {x^2 + a^2}$]] }} {{eqn | r = \frac {\paren {x^2 + a^2} \map \ln {x^2 + a^2} - x^2} 2 + C | c = simplifying }} {{end-eqn}} {{qed}}	0
The [[Definition:Divisor of Integer|factors]] of $P$ are: :$1, 2, 4, \dots, 2^{n - 1}, 2^n - 1, 2 \paren {2^n - 1}, \dots, 2^{n - 1} \paren {2^n - 1}$ Therefore their product is: {{begin-eqn}} {{eqn | l = \prod_{d \mathop \divides P} d | r = \paren {\prod_{i \mathop = 0}^{n - 1} 2^i} \paren {\prod_{i \mathop = 0}^{n - 1} 2^i \paren {2^n - 1} } }} {{eqn | r = \paren {\prod_{i \mathop = 0}^{n - 1} 2^i}^2 \paren {2^n - 1}^n }} {{eqn | r = \paren {2^\frac {n \paren {n - 1} } 2}^2 \paren {2^n - 1}^n }} {{eqn | r = \paren {2^{n - 1} }^n \paren {2^n - 1}^n }} {{eqn | r = P^n }} {{end-eqn}} {{qed}}	0
We begin by proving the [[Definition:Theorem|theorem]] for the [[Definition:Closed Ball in P-adic Numbers|closed ball]] $\map {B^-_{p^{-n} } } a$. From [[Open Ball in P-adic Numbers is Closed Ball]] then the [[Definition:Theorem|theorem]] will be proved. Let $d$ denote the [[Definition:Metric Subspace|subspace metric induced]] on $\map {B^-_{p^{-n}}} a$ by the [[Definition:P-adic Metric|$p$-adic Metric]]. From [[Open and Closed Balls in P-adic Numbers are Totally Bounded]], the [[Definition:Closed Ball in P-adic Numbers|closed ball]] $\map {B^-_{p^{-n}}} a$ is [[Definition:Totally Bounded Metric Space|totally bounded]] in $d$. Recall that by definition, the [[Definition:P-adic Number|$p$-adic numbers]] $\struct {\Q_p, \norm {\,\cdot\,}_p}$ are [[Definition:Complete|complete]]. {{disambiguate|Definition:Complete}} From [[Open and Closed Balls in P-adic Numbers are Clopen in P-adic Metric]], the [[Definition:Closed Ball in P-adic Numbers|closed ball]] $\map {B^-_{p^{-n}}} a$ is [[Definition:Closed|closed]] in the [[Definition:P-adic Metric|$p$-adic metric]]. {{disambiguate|Definition:Closed}} From [[Subspace of Complete Metric Space is Closed iff Complete]], the [[Definition:Closed Ball in P-adic Numbers|closed ball]] $\map {B^-_{p^{-n}}} a$ is [[Definition:Complete|complete]] in $d$. {{disambiguate|Definition:Complete}} From [[Complete and Totally Bounded Metric Space is Sequentially Compact]], the [[Definition:Closed Ball in P-adic Numbers|closed ball]] $\map {B^-_{p^{-n}}} a$ is [[Definition:Sequentially Compact Space|sequentially compact]] in $d$. From [[Sequentially Compact Metric Space is Compact]], the [[Definition:Closed Ball in P-adic Numbers|closed ball]] $\map {B^-_{p^{-n} } } a$ is [[Definition:Compact Space|compact]] in $d$. Hence the [[Definition:Closed Ball in P-adic Numbers|closed ball]] $\map {B^-_{p^{-n} } } a$ is a [[Definition:Compact Subspace|compact subspace]] in the [[Definition:P-adic Metric|$p$-adic metric]] by definition. The result follows. {{qed}} [[Category:Topology of P-adic Numbers]] tecnqtzfnasm0wj0ebbetr8rdidprs1	0
{{begin-eqn}} {{eqn | l = \map \sgn x | r = 1 | c = }} {{eqn | ll= \leadstoandfrom | l = x | o = > | r = 0 | c = {{Defof|Signum Function}} }} {{eqn | ll= \leadstoandfrom | l = \frac 1 x | o = > | r = 0 | c = [[Reciprocal of Strictly Positive Real Number is Strictly Positive]] }} {{eqn | ll= \leadstoandfrom | l = \map \sgn {\dfrac 1 x} | r = 1 | c = {{Defof|Signum Function}} }} {{end-eqn}} {{qed}} [[Category:Signum Function]] 3fktxynn8ed1viz3c18ts1pma7lwj8f	0
Let $\R \sqbrk X$ be the [[Definition:Ring of Polynomials in Ring Element|ring of polynomials]] in $X$ over the [[Definition:Real Number|real numbers]] $\R$. Then the [[Definition:Polynomial in Ring Element|polynomial]] $X^2 + 1$ is an [[Definition:Irreducible Element of Ring|irreducible element]] of $\R \sqbrk X$.	0
=== [[Equivalence of Definitions of Convergent Sequence in Metric Space/Definition 1 iff Definition 2|Definition 1 iff Definition 2]] === {{:Equivalence of Definitions of Convergent Sequence in Metric Space/Definition 1 iff Definition 2}}{{qed|lemma}} === [[Equivalence of Definitions of Convergent Sequence in Metric Space/Definition 1 iff Definition 3|Definition 1 iff Definition 3]] === {{:Equivalence of Definitions of Convergent Sequence in Metric Space/Definition 1 iff Definition 3}}{{qed|lemma}} === [[Equivalence of Definitions of Convergent Sequence in Metric Space/Definition 2 implies Definition 4|Definition 2 implies Definition 4]] === {{:Equivalence of Definitions of Convergent Sequence in Metric Space/Definition 2 implies Definition 4}}{{qed|lemma}} === [[Equivalence of Definitions of Convergent Sequence in Metric Space/Definition 4 implies Definition 2|Definition 4 implies Definition 2]] === {{:Equivalence of Definitions of Convergent Sequence in Metric Space/Definition 4 implies Definition 2}}{{qed}} [[Category:Metric Spaces]] [[Category:Convergence]] [[Category:Sequences]] [[Category:Convergent Sequences (Metric Space)]] [[Category:Equivalence of Definitions of Convergent Sequence in Metric Space]] 864bpf0i2do43t0vip30y80zhx1hbd6	0
Denote $\norm {\, \cdot \,}$ as the [[Definition:Norm on Vector Space|norm]] on $V$. Let $\epsilon > 0$. By [[Definition:Bounded Mapping|boundedness]] of $g$: :$\exists M \in \R: \forall x \in X: \norm {\map g x} < M$ By [[Definition:Uniformly Convergent|uniformly convergence]] of $\sequence {f_n}$: :$\exists f:X \to \mathbb K: \exists N \in \R: \forall x \in X: \norm {\map {f_n} x - \map f x} < \dfrac \epsilon M$ Pick any $x \in X$. Then: {{begin-eqn}} {{eqn | l = \norm {\map {f_n} x \map g x - \map f x \map g x} | r = \norm {\map g x \paren {\map {f_n} x - \map f x} } }} {{eqn | r = \norm {\map g x} \norm {\map {f_n} x - \map f x} | c = [[Definition:Norm Axioms|Norm Axiom $(\text N 2)$]] (Multiplicativity) }} {{eqn | o = < | r = M \cdot \dfrac \epsilon M }} {{eqn | r = \epsilon }} {{end-eqn}} As the choice of $x$ is arbitrary, $\sequence {f_n g}$ [[Definition:Uniformly Convergent|uniformly converges]] to $\sequence {f g}$. {{qed}}	0
Let $m \in \Z$ and $a \equiv b \pmod z$. Suppose $m = 0$. Then the {{RHS}} of the assertion degenerates to $0 \equiv 0 \pmod z$ which is trivially true. Otherwise, from [[Congruence by Product of Moduli]], we have: :$a \equiv b \iff m a \equiv m b \pmod z$ As $m \in \Z$, it follows that $m z$ is an [[Definition:Integer Multiple|integer multiple]] of $z$. Hence from [[Congruence by Divisor of Modulus]], it follows that: :$m a \equiv m b \implies m a \equiv m b \pmod z$ {{qed}}	0
Let $x \in \R$ such that $-1 < x < 1$. Then: {{begin-eqn}} {{eqn | l = \dfrac 1 {\paren {1 + x}^3} | r = \sum_{k \mathop = 0}^\infty \paren {-1}^k \frac {\paren {k + 2} \paren {k + 1} } 2 x^k | c = }} {{eqn | r = 1 - 3 x + 6 x^2 - 10 x^3 + 15 x^4 - \cdots | c = }} {{end-eqn}}	0
:$\map {\psi_n} z - \paren {-1}^n \map {\psi_n} {1 - z} = -\pi \dfrac {\d^n} {\d z^n} \cot \pi z$	0
{{begin-eqn}} {{eqn | l = \sin b \sin c \cos A | r = \cos a - \cos b \cos c | c = [[Spherical Law of Cosines]] }} {{eqn | ll= \leadsto | l = \sin^2 b \sin^2 c \cos^2 A | r = \cos^2 a - 2 \cos a \cos b \cos c + \cos^2 b \cos^2 c | c = }} {{eqn | ll= \leadsto | l = \sin^2 b \sin^2 c \paren {1 - \sin^2 A} | r = \cos^2 a - 2 \cos a \cos b \cos c + \cos^2 b \cos^2 c | c = [[Sum of Squares of Sine and Cosine]] }} {{eqn | ll= \leadsto | l = \sin^2 b \sin^2 c - \sin^2 b \sin^2 c \sin^2 A | r = \cos^2 a - 2 \cos a \cos b \cos c + \cos^2 b \cos^2 c | c = multiplying out }} {{eqn | ll= \leadsto | l = \paren {1 - \cos^2 b} \paren {1 - \cos^2 c} - \sin^2 b \sin^2 c \sin^2 A | r = \cos^2 a - 2 \cos a \cos b \cos c + \cos^2 b \cos^2 c | c = [[Sum of Squares of Sine and Cosine]] }} {{eqn | ll= \leadsto | l = 1 - \cos^2 b - \cos^2 c + \cos^2 b \cos^2 c - \sin^2 b \sin^2 c \sin^2 A | r = \cos^2 a - 2 \cos a \cos b \cos c + \cos^2 b \cos^2 c | c = multiplying out }} {{eqn | n = 1 | ll= \leadsto | l = \sin^2 b \sin^2 c \sin^2 A | r = 1 - \cos^2 a - \cos^2 b - \cos^2 c + 2 \cos a \cos b \cos c | c = rearranging and simplifying }} {{end-eqn}} Let $X \in \R_{>0}$ such that: :$X^2 \sin^2 a \sin^2 b \sin^2 c = 1 - \cos^2 a - \cos^2 b - \cos^2 c + 2 \cos a \cos b \cos c$ Then from $(1)$: {{begin-eqn}} {{eqn | l = \dfrac {X^2 \sin^2 a \sin^2 b \sin^2 c} {\sin^2 b \sin^2 c \sin^2 A} | o = = | r = \dfrac {1 - \cos^2 a - \cos^2 b - \cos^2 c + 2 \cos a \cos b \cos c} {1 - \cos^2 a - \cos^2 b - \cos^2 c + 2 \cos a \cos b \cos c} | c = }} {{eqn | ll= \leadsto | l = X^2 | r = \dfrac {\sin^2 A} {\sin^2 a} | c = }} {{end-eqn}} In a [[Definition:Spherical Triangle|spherical triangle]], all of the [[Definition:Side of Spherical Triangle|sides]] are less than $\pi$ [[Definition:Radian|radians]]. The same applies to the [[Definition:Spherical Angle|angles]]. From [[Shape of Sine Function]]: :$\sin \theta > 0$ for all $0 < \theta < \pi$ Hence the [[Definition:Negative Square Root|negative root]] of $\dfrac {\sin^2 A} {\sin^2 a}$ does not apply, and so: :$X = \dfrac {\sin A} {\sin a}$ Similarly, from applying the [[Spherical Law of Cosines]] to $\cos B$ and $\cos C$: {{begin-eqn}} {{eqn | l = \sin a \sin c \cos B | r = \cos b - \cos a \cos c }} {{eqn | l = \sin a \sin b \cos C | r = \cos c - \cos a \cos b }} {{end-eqn}} we arrive at the same point: {{begin-eqn}} {{eqn | l = X | r = \dfrac {\sin B} {\sin b} }} {{eqn | r = \dfrac {\sin A} {\sin a} }} {{end-eqn}} where: :$X^2 \sin^2 a \sin^2 b \sin^2 c = 1 - \cos^2 a - \cos^2 b - \cos^2 c + 2 \cos a \cos b \cos c$ as before. Hence we have: :$\dfrac {\sin a} {\sin A} = \dfrac {\sin b} {\sin B} = \dfrac {\sin c} {\sin C}$ {{qed}}	0
Let $A_1 \times A_1$ and $A_2 \times A_2$ be considered with the [[Definition:Product Topology|product topology]]. Let $F: A_1 \times A_1 \to A_2 \times A_2$ be the [[Definition:Mapping|mapping]] defined as: :$\map F {x, y} = \tuple {\map f x, \map f y}$ By [[Projection from Product Topology is Continuous]], we have that the (first and second) [[Definition:Projection (Mapping Theory)|projections]] on $A_1 \times A_1$ are [[Definition:Continuous Mapping (Topology)|continuous]]. By [[Continuity of Composite Mapping]] and [[Continuous Mapping to Topological Product]], it follows that $F$ is [[Definition:Continuous Mapping (Topology)|continuous]]. By [[Distance Function of Metric Space is Continuous]] and [[Continuity of Composite Mapping]], it follows that $d_2 \circ F: A_1 \times A_1 \to \R$ is [[Definition:Continuous Mapping (Topology)|continuous]]. Let $\epsilon \in \R_{>0}$ be a [[Definition:Strictly Positive Real Number|strictly positive real number]]. By [[Continuity Defined from Closed Sets]], the [[Definition:Set|set]]: :$C = \paren {d_2 \circ F}^{-1} \sqbrk {\hointr \epsilon \to} = \set {\tuple {x, y} \in A_1 \times A_1: \map {d_2} {\map f x, \map f y} \ge \epsilon}$ is [[Definition:Closed Set (Topology)|closed]] in $A_1 \times A_1$. By [[Topological Product of Compact Spaces]], $A_1 \times A_1$ is [[Definition:Compact Space|compact]]. By [[Closed Subspace of Compact Space is Compact]], $C$ is [[Definition:Compact Space|compact]]. By [[Distance Function of Metric Space is Continuous]] and [[Continuous Image of Compact Space is Compact]], $d_1 \sqbrk C$ is [[Definition:Compact Space|compact]]. Therefore, $d_1 \sqbrk C$ has a [[Definition:Smallest Element|smallest element]] $\delta$. {{explain}} By [[Definition:Metric Space Axioms|metric space axioms $(\text M 1)$ and $(\text M 4)$]], we have that $\delta > 0$. By construction, it follows that: :$\forall x, y \in A_1: \map {d_1} {x, y} < \delta \implies \map {d_2} {\map f x, \map f y} < \epsilon$ Hence, $f$ is [[Definition:Uniformly Continuous Mapping (Metric Spaces)|uniformly continuous]]. {{qed}}	0
Let $L = \left({S, \vee, \wedge, \preceq}\right)$ be a [[Definition:Complete Lattice|complete lattice]]. Then :$L$ is [[Definition:Bounded Ordered Set|bounded]]	0
We demonstrate that this is indeed an [[Definition:Arithmetic Sequence|arithmetic sequence]]: {{begin-eqn}} {{eqn | l = 66 - 30 | r = 36 }} {{eqn | l = 102 - 66 | r = 36 }} {{eqn | l = 138 - 102 | r = 36 }} {{end-eqn}} demonstrating the [[Definition:Common Difference|common difference]] of $36$. Then we note: {{begin-eqn}} {{eqn | l = 30 | r = 2 \times 3 \times 5 }} {{eqn | l = 66 | r = 2 \times 3 \times 11 }} {{eqn | l = 102 | r = 2 \times 3 \times 17 }} {{eqn | l = 138 | r = 2 \times 3 \times 23 }} {{end-eqn}} It is understood that '''smallest arithmetic sequence''' means: :[[Definition:Integer Sequence|integer sequence]] of [[Definition:Length of Sequence|length]] $4$ whose [[Definition:Term of Sequence|terms]] are in [[Definition:Arithmetic Sequence|arithmetic sequence]] such that their [[Definition:Integer Addition|sum]] is the [[Definition:Smallest Element|smallest]] of all such [[Definition:Integer Sequence|sequences]]. To demonstrate that this [[Definition:Integer Sequence|sequence]] is indeed the smallest, according to this definition, we list all [[Definition:Positive Integer|positive integers]] less than $138$, each with $3$ [[Definition:Distinct|distinct]] [[Definition:Prime Factor|prime factors]]. They are: {{begin-eqn}} {{eqn | l = 30 | r = 2 \times 3 \times 5 }} {{eqn | l = 42 | r = 2 \times 3 \times 7 }} {{eqn | l = 66 | r = 2 \times 3 \times 11 }} {{eqn | l = 70 | r = 2 \times 5 \times 7 }} {{eqn | l = 78 | r = 2 \times 3 \times 13 }} {{eqn | l = 102 | r = 2 \times 3 \times 17 }} {{eqn | l = 105 | r = 3 \times 5 \times 7 }} {{eqn | l = 110 | r = 2 \times 5 \times 11 }} {{eqn | l = 114 | r = 2 \times 3 \times 17 }} {{eqn | l = 130 | r = 2 \times 5 \times 13 }} {{end-eqn}} One cannot pick any other $4$ numbers from the list to form an [[Definition:Arithmetic Sequence|arithmetic sequence]]. Hence any further such [[Definition:Arithmetic Sequence|arithmetic sequence]] will contain larger [[Definition:Term of Sequence|terms]] whose [[Definition:Integer Addition|sum]] will be consequently larger. {{qed}}	0
Let $F_n = 2^{2^n} + 1$ be a [[Definition:Fermat Number|Fermat number]]. Then $F_n$ is [[Definition:Prime Number|prime]] {{iff}}: :$3^{\paren {F_n - 1} / 2} \equiv -1 \pmod {F_n}$	0
:[[File:Complex-Subtraction-as-Parallelogram.png|400px]] By definition of [[Definition:Vector Sum|vector addition]]: :$OB + BA = OA$ That is: :$\mathbf b + \vec {BA} = \mathbf a$ which leads directly to: :$\vec {BA} = \mathbf a - \mathbf b$ {{qed}}	0
First it is necessary to establish that every [[Definition:Element|element]] of the [[Definition:Set|set]] $\set {1, p, p^2, \ldots, p^{n - 1}, p^n}$ is in fact a [[Definition:Divisor of Integer|divisor]] of $p^n$. For any $j \in \set {1, 2, \ldots, n}$: :$p^n = p^j p^{n - j}$ and so each of $1, p, p^2, \ldots, p^{n - 1}, p^n$ is a [[Definition:Divisor of Integer|divisor]] of $p^n$. {{qed|lemma}} Let: :$a \in \Z_{>0}: a \notin \set {1, p, p^2, \ldots, p^{n - 1}, p^n}$ Let $a = p^j$ where $j \in \Z: j > n$. Then: :$p^j = p^n p^{j - n}$ and so $p^n$ is a [[Definition:Divisor of Integer|divisor]] of $p^j$. Hence $p_j \nmid p^n$. Now let: :$a \notin \set {p^k: k \in \Z_{>0} }$ Then: :$\exists q \in \Bbb P: q \divides a$ where: :$\Bbb P$ is the [[Definition:Set|set]] of all [[Definition:Prime Number|prime numbers]] :$\divides$ denotes [[Definition:Divisor of Integer|divisibility]]. {{AimForCont}} $a \divides p^n$. From [[Divisor Relation is Transitive]] it follows that $q \divides p^n$. From [[Euclid's Lemma for Prime Divisors/General Result|Euclid's Lemma for Prime Divisors: General Result]] it follows that: :$q \divides p$ As $p$ is a [[Definition:Prime Number|prime]], by definition its only [[Definition:Divisor of Integer|divisors]] are $1$ and $p$. This [[Proof by Contradiction|contradicts]] the supposition that $q$ is a [[Definition:Divisor of Integer|divisor]] of $p^n$. Hence $a \nmid p^n$. {{qed}} [[Category:Prime Numbers]] 7rk579ji8oqt9bogdoui6eysst01x2q	0
The operation of [[Definition:Subtraction|subtraction]] on the [[Definition:Number|numbers]] is [[Definition:Anticommutative|anticommutative]]. That is: :$a - b = b - a \iff a = b$	0
Consider the [[Definition:Trinomial Coefficient|trinomial coefficient]]: :$\dbinom r {k, m - k, r - m}$ We use [[Multinomial Coefficient expressed as Product of Binomial Coefficients]]: :$\dbinom {k_1 + k_2 + k_3} {k_1, k_2, k_3} = \dbinom {k_1 + k_2} {k_1} \dbinom {k_1 + k_2 + k_3} {k_1 + k_2}$ and substitute as appropriate for $k_1, k_2, k_3$. We have: {{begin-eqn}} {{eqn | r = \dbinom r {k, m - k, r - m} | o = | c = }} {{eqn | r = \dbinom {\left({m - k}\right) + \left({r - m}\right) + k} {m - k, r - m, k} | c = }} {{eqn | r = \dbinom {\left({m - k}\right) + \left({r - m}\right)} {m - k} \dbinom {\left({m - k}\right) + \left({r - m}\right) + k} {\left({m - k}\right) + \left({r - m}\right)} | c = [[Multinomial Coefficient expressed as Product of Binomial Coefficients]] }} {{eqn | r = \dbinom {r - k} {m - k} \dbinom r m | c = }} {{end-eqn}} Similarly: {{begin-eqn}} {{eqn | r = \dbinom r {k, m - k, r - m} | o = | c = }} {{eqn | r = \dbinom {k + \left({m - k}\right) + \left({r - m}\right)} {k, m - k, r - m} | c = }} {{eqn | r = \dbinom {k + \left({m - k}\right)} k \dbinom {k + \left({m - k}\right) + \left({r - m}\right)} {\left({m - k}\right) + k} | c = [[Multinomial Coefficient expressed as Product of Binomial Coefficients]] }} {{eqn | r = \dbinom m k \dbinom r m | c = }} {{end-eqn}} {{qed}} The result follows on equating the two expressions.	0
Let $f: \R \to \R$ be a [[Definition:Real Function|real function]]. Then $L$ is a [[Definition:Periodic Element|periodic element]] of $f$ {{iff}}: :$\forall x \in \R: \map f {x \bmod L} = \map f x$ where $x \bmod L$ is the [[Definition:Modulo Operation|modulo operation]].	0
Let $\struct {\R, \tau}$ denote the [[Definition:Real Number Line with Euclidean Topology|real number line with the usual (Euclidean) topology]]. Let $\Q$ be the [[Definition:Rational Number|rational numbers]]. Let $\mathbb I$ be the [[Definition:Irrational Number|irrational numbers]]. Then $\set {\Q, \mathbb I}$ is a [[Definition:Partition (Set Theory)|partition]] of $\R$. Let $\sim$ be the [[Definition:Equivalence Relation|equivalence relation]] [[Definition:Relation Induced by Partition|induced]] on $\R$ by $\set {\Q, \mathbb I}$. Let $T_\sim := \struct {\R / {\sim}, \tau_\sim} $ be the [[Definition:Quotient Space (Topology)|quotient space]] of $\R$ by $\sim$. Then $T_\sim$ is an [[Definition:Indiscrete Space|indiscrete space]].	0
Let $D \subset \C$ be an [[Definition:Open Set (Complex Analysis)|open]] [[Definition:Connected Topological Space|connected set]]. Let $\left\langle{f_n}\right\rangle$ be a [[Definition:Sequence|sequence]] of [[Definition:Analytic Function|analytic functions]] $f_n: D \to \C$. Let $\displaystyle \prod_{n \mathop = 1}^\infty f_n$ [[Definition:Locally Uniform Convergence of Product|converge locally uniformly]] to $f$. Let $z_0\in D$. Then: :$(1): \quad$ $f$ is [[Definition:Identically Zero|identically zero]] {{Iff}} some $f_n$ is [[Definition:Identically Zero|identically zero]] :$(2): \quad$ $f_n \left({z_0}\right) = 0$ for [[Definition:Finite Set|finitely many]] $n \in \N$ :$(3): \quad$ If $f$ is not identically zero, $\operatorname {mult}_{z_0} \left({f}\right) = \displaystyle \sum_{n \mathop = 1}^\infty \operatorname{mult}_{z_0} \left({f_n}\right)$ where $\operatorname{mult}$ denotes [[Definition:Multiplicity (Complex Analysis)|multiplicity]].	0
{{:Sum of Logarithms/General Logarithm}}	0
:$\displaystyle \int \frac {x^2 \rd x} {a^2 - x^2} = -x + a \tanh^{-1} \frac x a + C$ for $x^2 < a^2$.	0
The proof proceeds by [[Principle of Mathematical Induction|induction]]. For all $n \in \Z_{\ge 0}$, let $P \left({n}\right)$ be the [[Definition:Proposition|proposition]]: :$a_n = F_{n - 1} r + F_n s$ $P \left({0}\right)$ is the case: {{begin-eqn}} {{eqn | l = F_{-1} r + F_0 s | r = \left({-1}\right)^0 F_1 r + F_0 s | c = [[Fibonacci Number with Negative Index]] }} {{eqn | r = 1 \times r + 0 \times s | c = {{Defof|Fibonacci Number}}: $F_0 = 0, F_1 = 1$ }} {{eqn | r = r | c = }} {{eqn | r = a_0 | c = {{Defof|General Fibonacci Sequence}} }} {{end-eqn}} Thus $P \left({0}\right)$ is seen to hold. === Basis for the Induction === $P \left({1}\right)$ is the case: {{begin-eqn}} {{eqn | l = F_0 r + F_1 s | r = 0 \times r + 1 \times s | c = {{Defof|Fibonacci Number}}: $F_0 = 0, F_1 = 1$ }} {{eqn | r = s | c = }} {{eqn | r = a_1 | c = {{Defof|General Fibonacci Sequence}} }} {{end-eqn}} Thus $P \left({1}\right)$ is seen to hold. This is the [[Principle of Mathematical Induction#Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that, if $P \left({k}\right)$ is true, where $k \ge 1$, then it logically follows that $P \left({k + 1}\right)$ is true. So this is the [[Principle of Mathematical Induction#Induction Hypothesis|induction hypothesis]]: :$a_k = F_{k - 1} r + F_k s$ from which it is to be shown that: :$a_{k + 1} = F_k r + F_{k + 1} s$ === Induction Step === This is the [[Principle of Mathematical Induction#Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = a_{k + 1} | r = a_{k - 1} + a_k | c = }} {{eqn | r = \left({F_{k - 2} r + F_{k - 1} s}\right) + \left({F_{k - 1} r + F_k s}\right) | c = [[General Fibonacci Number in terms of Fibonacci Numbers#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \left({F_{k - 2} + F_{k - 1} }\right) r + \left({F_{k - 1} + F_k}\right) s | c = }} {{eqn | r = F_k r + F_{k + 1} s | c = {{Defof|Fibonacci Number}} }} {{end-eqn}} So $P \left({k}\right) \implies P \left({k + 1}\right)$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\forall n \in \Z_{\ge 0}: a_n = F_{n - 1} r + F_n s$ {{qed}}	0
We have: {{begin-eqn}} {{eqn | l = 2 \sin \theta | r = \frac {e^{i \theta} - e^{-i \theta} } i | c = [[Sine Exponential Formulation]] }} {{eqn | r = \frac {e^{i \theta} e^{-i \theta} - e^{-i \theta} e^{-i \theta} } {i e^{-i \theta} } | c = }} {{eqn | r = \left({1 - e^{-2 i \theta} }\right) \left({-i e^{i \theta} }\right) | c = }} {{eqn | r = \left({1 - e^{-2 i \theta} }\right) \left({e^{i \theta} e^{-i \pi / 2} }\right) | c = [[Euler's Formula/Examples/e^-i pi by 2]] }} {{eqn | r = \left({1 - e^{-2 i \theta} }\right) \left({e^{i \theta - i \pi / 2} }\right) | c = }} {{eqn | ll= \leadsto | l = \prod_{k \mathop = 0}^{n - 1} \left({2 \sin \pi \left({x + \frac k n}\right)}\right) | r = \prod_{k \mathop = 0}^{n - 1} \left({1 - e^{-2 i \pi \left({x + k / n}\right)} }\right) \left({e^{i \pi \left({x - \left({1 / 2}\right) + \left({k / n}\right)}\right)} }\right) | c = }} {{eqn | r = \left({1 - e^{-2 i \pi n x} }\right) \left({e^{i \pi \left({n x - 1 / 2}\right)} }\right) | c = }} {{eqn | r = 2 \sin \pi n x | c = }} {{end-eqn}} {{finish|Work to be done to establish the identities used here}} [[Category:Sine Function]] q4axqqt74dpubye91mw95qozyaxc7st	0
{{begin-eqn}} {{eqn | n = 1 | l = 2 \sin a \cos b | r = \sin \paren {a + b} + \sin \paren {a - b} | c = [[Simpson's Formulas/Sine by Cosine/Proof 2|Simpson's Formula for Sine by Cosine: Proof 2]] }} {{eqn | n = 2 | l = 2 \cos a \sin b | r = \sin \paren {a + b} - \sin \paren {a - b} | c = [[Simpson's Formulas/Cosine by Sine/Proof 2|Simpson's Formula for Cosine by Sine: Proof 2]] }} {{eqn | ll= \leadsto | l = 2 \sin \paren {a + b} | r = 2 \sin a \cos b + 2 \cos a \sin b | c = $(1) + (2)$ }} {{eqn | ll= \leadsto | l = \sin \paren {a + b} | r = \sin a \cos b + \cos a \sin b | c = }} {{end-eqn}} {{qed}}	0
We have that $\sqrt {x^2 - a^2}$ is defined only when $x^2 \ge a^2$, that is, either: :$x \ge a$ or: :$x \le -a$ where it is assumed that $a > 0$. First let $x \ge a$. {{begin-eqn}} {{eqn | l = x | r = a \cosh u }} {{eqn | n = 1 | ll= \leadsto | l = \frac {\d x} {\d u} | r = a \sinh u | c = [[Derivative of Hyperbolic Cosine]] }} {{end-eqn}} Also: {{begin-eqn}} {{eqn | l = x | r = a \cosh u }} {{eqn | ll= \leadsto | l = x^2 - a^2 | r = a^2 \cosh^2 u - a^2 | c = }} {{eqn | r = a^2 \paren {\cosh^2 u + 1} | c = }} {{eqn | r = a^2 \sinh^2 u | c = [[Difference of Squares of Hyperbolic Cosine and Sine]] }} {{eqn | n = 2 | ll= \leadsto | l = \sqrt {x^2 - a^2} | r = a \sinh u | c = }} {{end-eqn}} and: {{begin-eqn}} {{eqn | l = x | r = a \cosh u }} {{eqn | n = 3 | ll= \leadsto | l = u | r = \cosh^{-1} \frac x a | c = {{Defof|Inverse Hyperbolic Cosine/Real|index = 1|Real Inverse Hyperbolic Cosine}} }} {{end-eqn}} Thus: {{begin-eqn}} {{eqn | l = \int \sqrt {x^2 - a^2} \rd x | r = \int \sqrt {x^2 - a^2} \, a \sinh u \rd u | c = [[Integration by Substitution]] from $(1)$ }} {{eqn | r = \int a^2 \sinh^2 u \rd u | c = substituting for $\sqrt {x^2 - a^2}$ from $(2)$ }} {{eqn | r = a^2 \int \sinh^2 u \rd u | c = [[Primitive of Constant Multiple of Function]] }} {{eqn | r = a^2 \frac {\sinh u \cosh u - u} 2 + C | c = [[Primitive of Square of Hyperbolic Sine Function/Corollary|Primitive of $\sinh^2 u$: Corollary]] }} {{eqn | r = \frac 1 2 a \sinh u a \cosh u - \frac {a^2 u} 2 + C | c = rearranging }} {{eqn | r = \frac 1 2 x a \sinh u - \frac {a^2 u} 2 + C | c = substituting $x = a \cosh u$ }} {{eqn | r = \frac 1 2 x \sqrt {x^2 - a^2} - \frac {a^2 u} 2 + C | c = substituting $\sqrt {x^2 - a^2} = a \sinh u$ from $(2)$ }} {{eqn | r = \frac {x \sqrt {x^2 - a^2} } 2 - \frac {a^2} 2 \cosh^{-1} \frac x a + C | c = substituting for $\theta$ from $(3)$ }} {{eqn | r = \frac {x \sqrt {x^2 - a^2} } 2 - \frac {a^2} 2 \paren {\map \ln {x + \sqrt {x^2 - a^2} } - \ln a} + C | c = [[Inverse Hyperbolic Cosine of x over a in Logarithm Form|$\cosh^{-1} \dfrac x a$ in Logarithm Form]] }} {{eqn | r = \frac {x \sqrt {x^2 - a^2} } 2 - \frac {a^2} 2 \map \ln {x + \sqrt {x^2 - a^2} } + \frac {a^2} 2 \ln a + C | c = simplifying }} {{eqn | r = \frac {x \sqrt {x^2 - a^2} } 2 - \frac {a^2} 2 \map \ln {x + \sqrt {x^2 - a^2} } + C | c = subsuming $\dfrac {a^2} 2 \ln a$ into [[Definition:Arbitrary Constant (Calculus)|arbitrary constant]] }} {{eqn | r = \frac {x \sqrt {x^2 - a^2} } 2 - \frac {a^2} 2 \ln \size {x + \sqrt {x^2 - a^2} } + C | c = {{Defof |Absolute Value}} }} {{end-eqn}} Now suppose $x \le -a$. Let $z = -x$. Then: :$\d x = -\d z$ and we then have: {{begin-eqn}} {{eqn | l = \int \sqrt {x^2 - a^2} \rd x | r = -\int \sqrt {\paren {-z}^2 - a^2} \rd z | c = [[Integration by Substitution]] }} {{eqn | r = -\int \sqrt {\paren z^2 - a^2} \rd z | c = simplifying }} {{eqn | r = -\frac {z \sqrt {z^2 - a^2} } 2 + \frac {a^2} 2 \map \ln {z + \sqrt {z^2 - a^2} } + C | c = from above }} {{eqn | r = -\frac {z \sqrt {z^2 - a^2} } 2 - \frac {a^2} 2 \paren {\map \ln {z - \sqrt {z^2 - a^2} } - \map \ln {a^2} } + C | c = [[Negative of Logarithm of x plus Root x squared minus a squared|Negative of $\map \ln {z + \sqrt {z^2 - a^2} }$]] }} {{eqn | r = -\frac {z \sqrt {z^2 - a^2} } 2 - \frac {a^2} 2 \map \ln {z - \sqrt {z^2 - a^2} } + C | c = subsuming $-\frac {a^2 \map \ln {a^2} } 2$ into [[Definition:Arbitrary Constant (Calculus)|constant]] }} {{eqn | r = -\frac {\paren {-x} \sqrt {\paren {-x}^2 - a^2} } 2 - \frac {a^2} 2 \map \ln {\paren {-x} - \sqrt {\paren {-x}^2 - a^2} } + C | c = substituting back for $x$ }} {{eqn | r = \frac {x \sqrt {x^2 - a^2} } 2 - \frac {a^2} 2 \map \ln {-x - \sqrt {x^2 - a^2} } + C | c = simplifying }} {{eqn | r = \frac {x \sqrt {x^2 - a^2} } 2 - \frac {a^2} 2 \ln \size {x + \sqrt {x^2 - a^2} } + C | c = as $-x - \sqrt {x^2 - a^2} > 0$: {{Defof |Absolute Value}} }} {{end-eqn}} The result follows. {{qed}}	0
{{begin-eqn}} {{eqn | l = \int \frac {\d x} {x^4 - a^4} | r = \int \frac {\d x} {\paren {x^2 + a^2} \paren {x^2 - a^2} } | c = [[Difference of Two Squares]] }} {{eqn | r = \int \frac {a^2 \rd x} {a^2 \paren {x^2 + a^2} \paren {x^2 - a^2} } | c = multiplying [[Definition:Numerator|top]] and [[Definition:Denominator|bottom]] by $a^2$ }} {{eqn | r = \int \frac {\paren {x^2 + a^2 - x^2} \rd x} {a^2 \paren {x^2 + a^2} \paren {x^2 - a^2} } | c = }} {{eqn | r = \frac 1 {a^2} \int \frac {\paren {x^2 + a^2} \d x} {\paren {x^2 + a^2} \paren {x^2 - a^2} } - \frac 1 {a^2} \int \frac {x^2 \rd x} {\paren {x^2 + a^2} \paren {x^2 - a^2} } | c = [[Linear Combination of Integrals]] }} {{eqn | r = \frac 1 {a^2} \int \frac {\d x} {x^2 - a^2} - \frac 1 {a^2} \int \frac {x^2 \rd x} {\paren {x^2 + a^2} \paren {x^2 - a^2} } | c = simplifying }} {{eqn | r = \frac 1 {a^2} \int \frac {\d x} {x^2 - a^2} - \frac 1 {a^2} \int \frac {\paren {x^2 - a^2 + a^2} \rd x} {\paren {x^2 + a^2} \paren {x^2 - a^2} } | c = [[Difference of Two Squares]] }} {{eqn | r = \frac 1 {a^2} \int \frac {\d x} {x^2 - a^2} - \frac 1 {a^2} \int \frac {\paren {x^2 - a^2} \rd x} {\paren {x^2 + a^2} \paren {x^2 - a^2} } | c = [[Linear Combination of Integrals]] }} {{eqn | o = | ro= - | r = \frac 1 {a^2} \int \frac {a^2 \rd x} {\paren {x^2 + a^2} \paren {x^2 - a^2} } | c = }} {{eqn | r = \frac 1 {a^2} \int \frac {\d x} {x^2 - a^2} - \frac 1 {a^2} \int \frac {\d x} {x^2 + a^2} - \int \frac {\d x} {\paren {x^2 + a^2} \paren {x^2 - a^2} } | c = simplification }} {{eqn | r = \frac 1 {a^2} \int \frac {\d x} {x^2 - a^2} - \frac 1 {a^2} \int \frac {\d x} {x^2 + a^2} - \int \frac {\d x} {x^4 - a^4} | c = [[Difference of Two Squares]] }} {{eqn | ll= \leadsto | l = 2 \int \frac {\d x} {x^4 - a^4} | r = \frac 1 {a^2} \int \frac {\d x} {x^2 - a^2} - \frac 1 {a^2} \int \frac {\d x} {x^2 + a^2} | c = gathering terms }} {{eqn | ll= \leadsto | l = \int \frac {\d x} {x^4 - a^4} | r = \frac 1 {2 a^2} \int \frac {\d x} {x^2 - a^2} - \frac 1 {2 a^2} \int \frac {\d x} {x^2 + a^2} | c = gathering terms }} {{eqn | r = \frac 1 {4 a^3} \ln \size {\frac {x - a} {x + a} } - \frac 1 {2 a^2} \int \frac {\d x} {x^2 + a^2} | c = [[Primitive of Reciprocal of x squared minus a squared|Primitive of $\dfrac 1 {x^2 - a^2}$]] }} {{eqn | r = \frac 1 {4 a^3} \ln \size {\frac {x - a} {x + a} } - \frac 1 {2 a^3} \arctan \frac x a | c = [[Primitive of Reciprocal of x squared plus a squared/Arctangent Form|Primitive of $\dfrac 1 {x^2 + a^2}$]] }} {{end-eqn}} {{qed}}	0
=== [[Sine of x plus Cosine of x/Sine Form|Sine of x plus Cosine of x: Sine Form]] === {{:Sine of x plus Cosine of x/Sine Form}} === [[Sine of x plus Cosine of x/Cosine Form|Sine of x plus Cosine of x: Cosine Form]] === {{:Sine of x plus Cosine of x/Cosine Form}} === [[Sine of x minus Cosine of x/Sine Form|Sine of x minus Cosine of x: Sine Form]] === {{:Sine of x minus Cosine of x/Sine Form}} === [[Sine of x minus Cosine of x/Cosine Form|Sine of x minus Cosine of x: Cosine Form]] === {{:Sine of x minus Cosine of x/Cosine Form}} === [[Cosine of x minus Sine of x/Sine Form|Cosine of x minus Sine of x: Sine Form]] === {{:Cosine of x minus Sine of x/Sine Form}} === [[Cosine of x minus Sine of x/Cosine Form|Cosine of x minus Sine of x: Cosine Form]] === {{:Cosine of x minus Sine of x/Cosine Form}} == [[Multiple of Sine plus Multiple of Cosine]] == {{:Multiple of Sine plus Multiple of Cosine}}	0
:$x^6 - y^6 = \paren {x - y} \paren {x + y} \paren {x^2 + x y + y^2} \paren {x^2 - x y + y^2}$	0
The smallest $18$ [[Definition:Prime Number|primes]] in [[Definition:Arithmetic Sequence|arithmetic sequence]] are: :$107\,928\,278\,317 + 9\,922\,782\,870 n$ for $n = 0, 1, \ldots, 16$.	0
Since $S$ is [[Definition:Bounded Above Set|bounded above]], $\exists M \in \Z: \forall s \in S: s \le M$. Hence we can define the set $S' = \set {-s: s \in S}$. $S'$ is [[Definition:Bounded Below Set|bounded below]] by $-M$. So from [[Set of Integers Bounded Below by Integer has Smallest Element]], $S'$ has a [[Definition:Smallest Element|smallest element]], $-g_S$, say, where $\forall s \in S: -g_S \le -s$. Therefore $g_S \in S$ (by definition of $S'$) and $\forall s \in S: s \le g_S$. So $g_S$ is the [[Definition:Greatest Element|greatest element]] of $S$. {{qed}}	0
The [[Definition:Integer|integers]] $11$ and $26$ cannot be represented by the [[Definition:Integer Addition|sum]] of less than $6$ [[Definition:Hexagonal Number|hexagonal numbers]].	0
Two [[Definition:Ordered Pair|ordered pairs]] are [[Definition:Equality|equal]] {{iff}} corresponding [[Definition:Coordinate System/Coordinate/Element of Ordered Pair|coordinates]] are equal: :$\tuple {a, b} = \tuple {c, d} \iff a = c \land b = d$	0
Let $n \in \Z_{\ge 0}$ be the [[Definition:Integer Addition|sum]] of three [[Definition:Integer Power|$4$th powers]]. Then: :$n$ is [[Definition:Divisor of Integer|divisible]] by $5$ {{iff}} all three [[Definition:Addend|addends]] are also [[Definition:Divisor of Integer|divisible]] by $5$ :$n$ is [[Definition:Divisor of Integer|divisible]] by $29$ {{iff}} all three [[Definition:Addend|addends]] are also [[Definition:Divisor of Integer|divisible]] by $29$.	0
Let $r, s \in \Z$. Then: {{begin-eqn}} {{eqn | l = \map {f_c} {r s} | r = \paren {r s}^c | c = }} {{eqn | r = r^c s^c | c = [[Exponent Combination Laws/Product of Powers|Exponent Combination Laws: Product of Powers]] }} {{eqn | r = \map {f_c} r \map {f_c} s | c = }} {{end-eqn}} {{Qed}}	0
Let row $i$ of $A$ be multiplied by column $i$ of $A^\intercal$. This is the same as multiplying row $i$ of $A$ by row $i$ of $A$. Each row of $A$ has $r$ entries (since any point must be in $r$ blocks). Then: : $ \left({a_{ii}}\right) = r = \sum $ of the all the $1$'s in row $i$ This completes the [[Definition:Main Diagonal|main diagonal]]. Let row $i$ of $A$ be multiplied by column $j$ of $A^\intercal$. This is the same as multiplying row $i$ of $A$ by the row $j$ row of $A$. This will give the number of times point $i$ point is the same block as point $j$. Therefore: : $i \ne j \implies \left({a_{ij}}\right) = \lambda$ So: :$A^\intercal \cdot A = \left({a_{ij}}\right) = \left({r - \lambda}\right) I_v + \lambda{J_v}$ {{qed}} {{explain|The order of this matrix is not apparent - it needs to be made more explicit.}} {{explain|Better idea - write a separate page to express this result for a general [[Definition:Logical Matrix|logical matrix]]. I think this is a valid construction. Establish the result as the fact that it is a [[Definition:Combinatorial Matrix|combinatorial matrix]].}} [[Category:Design Theory]] 8y5b1s3g8bnl9z93k5vclpp7tpd9vo1	0
Let $n \in \N_{>0}$. {{begin-eqn}} {{eqn | l = \frac 1 n - \frac 1 {n + 1} | r = \frac {\paren {n + 1} - n} {n \paren {n + 1} } }} {{eqn | r = \frac 1 {n^2 + n} }} {{eqn | o = > | r = 0 }} {{eqn | ll= \leadsto | l = \frac 1 n | o = > | r = \frac 1 {n + 1} }} {{end-eqn}} Hence the result, as $n$ was arbitrary. {{qed}}	0
{{begin-eqn}} {{eqn | l = \int \frac {\mathrm d x} {x^2 \left({a x + b}\right)^3} | r = \int \left({\frac {-3 a} {b^4 x} + \frac 1 {b^3 x^2} + \frac {3 a^2} {b^4 \left({a x + b}\right)} + \frac {2 a^2} {b^3 \left({a x + b}\right)^2} + \frac {a^2} {b^2 \left({a x + b}\right)^3} }\right) \ \mathrm d x | c = [[Primitive of Reciprocal of x squared by a x + b cubed/Partial Fraction Expansion|Partial Fraction Expansion]] }} {{eqn | r = \frac {-3 a} {b^4} \int \frac {\mathrm d x} x + \frac 1 {b^3} \int \frac {\mathrm d x} {x^2} + \frac {3 a^2} {b^4} \int \frac {\mathrm d x} {\left({a x + b}\right)} + \frac {2 a^2} {b^3} \int \frac {\mathrm d x} {\left({a x + b}\right)^2} + \frac {a^2} {b^2} \int \frac {\mathrm d x} {\left({a x + b}\right)^3} | c = [[Linear Combination of Integrals]] }} {{eqn | r = \frac {-3 a} {b^4} \ln \left\vert{x}\right\vert + \frac 1 {b^3} \int \frac {\mathrm d x} {x^2} + \frac {3 a^2} {b^4} \int \frac {\mathrm d x} {\left({a x + b}\right)} + \frac {2 a^2} {b^3} \int \frac {\mathrm d x} {\left({a x + b}\right)^2} + \frac {a^2} {b^2} \int \frac {\mathrm d x} {\left({a x + b}\right)^3} + C | c = [[Primitive of Reciprocal]] }} {{eqn | r = \frac {-3 a} {b^4} \ln \left\vert{x}\right\vert + \frac 1 {b^3} \int \frac {\mathrm d x} {x^2} + \frac {3 a^2} {b^4} \ln \left\vert{a x + b}\right\vert + \frac {2 a^2} {b^3} \int \frac {\mathrm d x} {\left({a x + b}\right)^2} + \frac {a^2} {b^2} \int \frac {\mathrm d x} {\left({a x + b}\right)^3} + C | c = [[Primitive of Reciprocal of a x + b]] }} {{eqn | r = \frac {-3 a} {b^4} \ln \left\vert{x}\right\vert + \frac 1 {b^3} \int \frac {\mathrm d x} {x^2} + \frac {3 a^2} {b^4} \ln \left\vert{a x + b}\right\vert + \frac {2 a^2} {b^3} \frac {-1} {a \left({a x + b}\right)} + \frac {a^2} {b^2} \int \frac {\mathrm d x} {\left({a x + b}\right)^3} + C | c = [[Primitive of Reciprocal of a x + b squared]] }} {{eqn | r = \frac {-3 a} {b^4} \ln \left\vert{x}\right\vert + \frac 1 {b^3} \int \frac {\mathrm d x} {x^2} + \frac {3 a^2} {b^4} \ln \left\vert{a x + b}\right\vert - \frac {2 a} {b^3 \left({a x + b}\right)} + \frac {a^2} {b^2} \frac {-1} {2 a \left({a x + b}\right)^2} + C | c = [[Primitive of Reciprocal of a x + b cubed]] }} {{eqn | r = \frac {-3 a} {b^4} \ln \left\vert{x}\right\vert + \frac 1 {b^3} \frac {-1} x + \frac {3 a^2} {b^4} \ln \left\vert{a x + b}\right\vert - \frac {2 a} {b^3 \left({a x + b}\right)} - \frac a {2 b^2 \left({a x + b}\right)^2} + C | c = [[Primitive of Power]] }} {{eqn | r = \frac {-a} {2 b^2 \left({a x + b}\right)^2} - \frac {2 a} {b^3 \left({a x + b}\right)} - \frac 1 {b^3 x} + \frac {3 a} {b^4} \ln \left\vert{\frac {a x + b} x}\right\vert + C | c = [[Difference of Logarithms]] and rearranging }} {{end-eqn}} {{qed}}	0
From [[Sum of Geometric Sequence]]: :$\dfrac 1 {1 - p^{-z} } = 1 + \dfrac 1 {p^z} + \dfrac 1 {p^{2 z} } + \cdots$ From [[Convergence of P-Series]]: :$\displaystyle \sum_{n \mathop = 1}^\infty n^{-z}$ is [[Definition:Absolutely Convergent Series|absolutely convergent]] {{iff}}: :$\cmod z \ge 1$ Thus: {{begin-eqn}} {{eqn | l = \sum_p \dfrac 1 {1 - p^{-z} } | r = \sum_p \paren {1 + \dfrac 1 {p^z} + \dfrac 1 {p^{2 z} } + \dfrac 1 {p^{3 z} } + \cdots} | c = }} {{eqn | r = \paren {1 + \dfrac 1 {2^z} + \dfrac 1 {2^{2 z} } + \dfrac 1 {2^{3 z} } + \cdots} | c = }} {{eqn | o = | ro= \times | r = \paren {1 + \dfrac 1 {3^z} + \dfrac 1 {3^{2 z} } + \dfrac 1 {3^{3 z} } + \cdots} | c = }} {{eqn | o = | ro= \times | r = \paren {1 + \dfrac 1 {5^z} + \dfrac 1 {5^{2 z} } + \dfrac 1 {5^{3 z} } + \cdots} | c = }} {{eqn | o = | ro= \times | r = \cdots | c = }} {{eqn | r = 1 + \dfrac 1 {2^z} + \dfrac 1 {3^z} + \dfrac 1 {2^{2 z} } + \dfrac 1 {5^z} | c = }} {{eqn | o = | ro= + | r = \dfrac 1 {2^z 3^z} + \dfrac 1 {7^z} + \dfrac 1 {2^{3 z} } + \dfrac 1 {3^{2 z} } | c = }} {{eqn | o = | ro= + | r = \cdots | c = }} {{end-eqn}} The result follows from the [[Fundamental Theorem of Arithmetic]]. {{qed}} {{handwaving}}	0
Let $a, b \in \Z$ such that not both of $a$ and $b$ are zero. Let $c$ be any [[Definition:Common Divisor of Integers|common divisor]] of $a$ and $b$. That is, let $c \in \Z: c \divides a, c \divides b$. Then: :$c \divides \gcd \set {a, b}$ where $\gcd \set {a, b}$ is the [[Definition:Greatest Common Divisor of Integers|greatest common divisor]] of $a$ and $b$.	0
Let $y \in \R_{\ge 0}$. Let $z \in \R$. Then: :$\left\vert{x - z}\right\vert < y \iff z - y < x < z + y$	0
{{begin-eqn}} {{eqn | l = \int \tan x \rd x | r = -\ln \size {\cos x} | c = [[Primitive of Tangent Function/Cosine Form|Primitive of $\tan x$: Cosine Form]] }} {{eqn | ll= \leadsto | l = \int \tan a x \rd x | r = \frac 1 a \paren {-\ln \size {\cos a x} } + C | c = [[Primitive of Function of Constant Multiple]] }} {{eqn | r = \frac {-\ln \size {\cos a x} } a + C | c = simplifying }} {{end-eqn}} {{qed}}	0
From [[Bell Number as Summation over Lower Index of Stirling Numbers of the Second Kind]], we have that: :$B_n = \displaystyle \sum_{k \mathop = 0}^n {n \brace k}$ But when $n > 0$: :$\displaystyle {n \brace 0} = 0$ Hence the result. {{qed}} [[Category:Bell Numbers]] [[Category:Stirling Numbers]] ldgte9oswzxmfqn4olwei3ptsrjkkxs	0
Let $a \in \R_{>0}$ be a [[Definition:Constant|constant]] such that $a \ne 1$. Then: :$\ds \int a^x \rd x = \frac {a^x} {\ln a} + C$ where $C$ is an [[Definition:Arbitrary Constant (Calculus)|arbitrary constant]].	0
Let $n$ be a [[Definition:Natural Number|natural number]]. Then the $n$th [[Definition:Alternating Group|alternating group]] $A_n$ is [[Definition:Ambivalent Group|ambivalent]] {{iff}} $n\in \{1, 2, 5, 6, 10, 14\}$. {{OEIS|A115200}}	0
:[[File:Euclid-X-103.png|300px]] Let $AB$ be an [[Definition:Apotome|apotome]]. Let $CD$ be [[Definition:Commensurable in Length|commensurable in length]] with $AB$. It is to be demonstrated that: :$CD$ is an [[Definition:Apotome|apotome]] and: :the [[Definition:Order of Apotome|order]] of $CD$ is the same as the [[Definition:Order of Apotome|order]] of $AB$. Let $BE$ be the [[Definition:Annex of Apotome|annex]] of $CD$. This can be constructed uniquely by [[Construction of Apotome is Unique]]. By definition, $AE$ and $EB$ are [[Definition:Rational Line Segment|rational straight lines]] which are [[Definition:Commensurable in Square Only|commensurable in square only]]. From {{EuclidPropLink|book = VI|prop = 12|title = Construction of Fourth Proportional Straight Line}}, let it be contrived that: :$BE : DF = AB : CD$ From {{EuclidPropLink|book = V|prop = 12|title = Sum of Components of Equal Ratios}}: :$AE : CF = AB : CD$ and so from {{EuclidPropLink|book = V|prop = 11|title = Equality of Ratios is Transitive}}: :$AE : CF = BE : DF$ But $AB$ is [[Definition:Commensurable in Length|commensurable in length]] with $CD$. Therefore from {{EuclidPropLink|book = X|prop = 11|title = Commensurability of Elements of Proportional Magnitudes}}: :$AE$ is [[Definition:Commensurable in Length|commensurable in length]] with $CF$ and: :$BE$ is [[Definition:Commensurable in Length|commensurable in length]] with $DF$. We have that $AE$ and $EB$ are [[Definition:Rational Line Segment|rational straight lines]] which are [[Definition:Commensurable in Square Only|commensurable in square only]]. Therefore from {{EuclidPropLink|book = X|prop = 13|title = Commensurable Magnitudes are Incommensurable with Same Magnitude}}: : $CF$ and $FD$ are [[Definition:Rational Line Segment|rational straight lines]] which are [[Definition:Commensurable in Square Only|commensurable in square only]]. Thus $CD$ is an [[Definition:Apotome|apotome]]. {{qed|lemma}} It remains to be shown that the [[Definition:Order of Apotome|order]] of $CD$ is the same as the [[Definition:Order of Apotome|order]] of $AB$. We have that: :$AE : CF = BE : DF$ So from {{EuclidPropLink|book = V|prop = 16|title = Proportional Magnitudes are Proportional Alternately}}: :$AE : EB = CF : FD$ We have that: : $AE^2 = EB^2 + \lambda^2$ where either: :$\lambda$ is [[Definition:Commensurable in Length|commensurable in length]] with $AE$ or: :$\lambda$ is [[Definition:Incommensurable in Length|incommensurable in length]] with $AE$. Suppose $\lambda$ is [[Definition:Commensurable in Length|commensurable in length]] with $AE$. Then by {{EuclidPropLink|book = X|prop = 14|title = Commensurability of Squares on Proportional Straight Lines}}: :$CF^2 > FD^2 + \mu^2$ where $\mu$ is [[Definition:Commensurable in Length|commensurable in length]] with $CF$. Let $AE$ be [[Definition:Commensurable in Length|commensurable in length]] with a [[Definition:Rational Line Segment|rational straight line]] $\alpha$ set out. Then by {{EuclidPropLink|book = X|prop = 12|title = Commensurability is Transitive Relation}}: :$CD$ is [[Definition:Commensurable in Length|commensurable in length]] with $\alpha$. Similarly, let $BE$ be [[Definition:Commensurable in Length|commensurable in length]] with $\alpha$. Then by {{EuclidPropLink|book = X|prop = 12|title = Commensurability is Transitive Relation}}: :$DF$ is [[Definition:Commensurable in Length|commensurable in length]] with $\alpha$. Suppose neither $AE$ nor $BE$ is [[Definition:Commensurable in Length|commensurable in length]] with $\alpha$. Then by {{EuclidPropLink|book = X|prop = 13|title = Commensurable Magnitudes are Incommensurable with Same Magnitude}}: :neither $CF$ nor $FD$ will be [[Definition:Commensurable in Length|commensurable in length]] with $\alpha$. Let $\lambda$ be [[Definition:Incommensurable in Length|incommensurable in length]] with $AE$. Then by {{EuclidPropLink|book = X|prop = 14|title = Commensurability of Squares on Proportional Straight Lines}}: :$CF^2 > FD^2 + \mu^2$ where $\mu$ is [[Definition:Incommensurable in Length|incommensurable in length]] with $CF$. Let $AE$ be [[Definition:Commensurable in Length|commensurable in length]] with a [[Definition:Rational Line Segment|rational straight line]] $\alpha$ set out. Then by {{EuclidPropLink|book = X|prop = 12|title = Commensurability is Transitive Relation}}: :$CD$ is [[Definition:Commensurable in Length|commensurable in length]] with $\alpha$. Similarly, let $BE$ be [[Definition:Commensurable in Length|commensurable in length]] with $\alpha$. Then by {{EuclidPropLink|book = X|prop = 12|title = Commensurability is Transitive Relation}}: :$DF$ is [[Definition:Commensurable in Length|commensurable in length]] with $\alpha$. Suppose neither $AE$ nor $BE$ is [[Definition:Commensurable in Length|commensurable in length]] with $\alpha$. Then by {{EuclidPropLink|book = X|prop = 13|title = Commensurable Magnitudes are Incommensurable with Same Magnitude}}: :neither $CF$ nor $FD$ will be [[Definition:Commensurable in Length|commensurable in length]] with $\alpha$. It follows that $CD$ is an [[Definition:Apotome|apotome]] of the same as the [[Definition:Order of Apotome|order]] as $AB$. {{qed}} {{Euclid Note|103|X}}	0
Let $r$ be a [[Definition:Rational Number|rational number]] such that $r \ne 0$. Then: :$e^r$ is [[Definition:Irrational Number|irrational]] where $e$ is [[Definition:Euler's Number|Euler's number]].	0
=== Necessary Condition === Assume that $g$ exists. We need to prove that the limits $\displaystyle \lim_{x \mathop \to a^+} \map f x$ and $\displaystyle \lim_{x \mathop \to b^-} \map f x$ exist. $g$ is [[Definition:Continuous Real Function at Point|continuous]] at the [[Definition:Endpoint of Real Interval|end points]] $a$ and $b$ of its [[Definition:Domain of Mapping|domain]] as $g$ is [[Definition:Continuous Real Function on Closed Interval|continuous]] on $\closedint a b$. $g$ is [[Definition:Right-Continuous at Point|right-continuous]] at $a$ and [[Definition:Left-Continuous at Point|left-continuous]] at $b$. This means that $\map g a = \displaystyle \lim_{x \mathop \to a^+} \map g x$ and $\map g b = \displaystyle \lim_{x \mathop \to b^-} \map g x$. In turn, this means that the expressions $\displaystyle \lim_{x \mathop \to a^+} \map g x$ and $\displaystyle \lim_{x \mathop \to b^-} \map g x$ exist. The two $x$ parameters as being part of the two limiting processes in these expressions can be considered confined to $\openint a b$. Therefore, $g$ in these two expressions can be replaced by $f$ as $g = f$ on $\openint a b$. We conclude that $\displaystyle \lim_{x \mathop \to a^+} \map f x$ and $\displaystyle \lim_{x \mathop \to b^-} \map f x$ exist. {{qed|lemma}} === Sufficient Condition === Let $\displaystyle \lim_{x \mathop \to a^+} \map f x$ and $\displaystyle \lim_{x \mathop \to b^-} \map f x$ exist. We need to prove that a [[Definition:Real Function|function]] $g$ with the properties listed in the theorem exists. Define $g = f$ on $\openint a b$. Define: :$\map g a = \displaystyle \lim_{x \mathop \to a^+} \map f x$ :$\map g b = \displaystyle \lim_{x \mathop \to b^-} \map f x$ $g$ is defined at $a$ and $b$ as ensured by the existence of the [[Definition:Limit from Right|limits on the right hand sides]] of these two equations. We know that $f$ is [[Definition:Continuous Real Function on Open Interval|continuous]] on $\openint a b$. Therefore, $g$ too is [[Definition:Continuous Real Function on Open Interval|continuous]] on $\openint a b$ as $g = f$ there. It remains to show that $g$ is [[Definition:Continuous Real Function at Point|continuous]] at $a$ and $b$. $\map g a = \displaystyle \lim_{x \mathop \to a^+} \map f x$ per definition. $x$ can be considered as being an element of $\openint a b$ as the limiting process at $a$ requires $x$ to approach $a$ from above. $\map g b = \displaystyle \lim_{x \mathop \to b^-} \map f x$ per definition. $x$ can be considered as being an element of $\openint a b$ as the limiting process at $b$ requires $x$ to approach $b$ from below. Therefore, the two equations above can be written: :$\map g a = \displaystyle \lim_{x \mathop \to a^+} \map g x$ :$\map g b = \displaystyle \lim_{x \mathop \to b^-} \map g x$ as $g = f$ on $\openint a b$. We conclude that $g$ is [[Definition:Continuous Real Function at Point|continuous]] at $a$ and $b$ as these two equations are exactly the definitions of [[Definition:Continuous Real Function at Point|continuity]] for $g$ at respectively $a$ and $b$. {{qed}} [[Category:Continuous Functions]] gwexoblpllrjrg5fmsbn6p203oqt2xg	0
By the [[Division Theorem]], $n$ can be expressed as: :$n = 4 k + r$ where: :$k, r \in \Z$ :$0 \le r < 4$ That is, one of the following holds: {{begin-eqn}} {{eqn | l = n | r = 4 k }} {{eqn | l = n | r = 4 k + 1 }} {{eqn | l = n | r = 4 k + 2 }} {{eqn | l = n | r = 4 k + 3 }} {{end-eqn}} Of these: {{begin-eqn}} {{eqn | l = n | r = 4 k }} {{eqn | r = 2 \paren {2 k} }} {{end-eqn}} and: {{begin-eqn}} {{eqn | l = n | r = 4 k + 2 }} {{eqn | r = 2 \paren {2 k + 1} }} {{end-eqn}} and so are [[Definition:Even Integer|even]] by definition. Then: {{begin-eqn}} {{eqn | l = n | r = 4 k + 1 }} {{eqn | r = 2 \paren {2 k} + 1 }} {{end-eqn}} and: {{begin-eqn}} {{eqn | l = n | r = 4 k + 3 }} {{eqn | r = 2 \paren {2 k + 1} + 1 }} {{end-eqn}} and so are [[Definition:Odd Integer|odd]] by definition. {{qed}}	0
Let $x \in \R: \size x > 1$. Let $x > 1$. Then: :$-\map \ln {x + \sqrt {x^2 - a^2} } = \map \ln {x - \sqrt {x^2 - a^2} } - \map \ln {a^2}$	0
Let $n \in \Z_{>0}$ be a [[Definition:Strictly Positive Integer|(strictly) positive integer]]. Let $\map t n$ denote the number of ways $n$ can be [[Definition:Integer Partition|partitioned]] into [[Definition:Part of Integer Partition|parts]] which are specifically not [[Definition:Integer Multiplication|multiples]] of $3$. Let $\map v n$ denote the number of ways $n$ can be [[Definition:Integer Partition|partitioned]] such that no [[Definition:Part of Integer Partition|part]] appears twice. Then: :$\forall n \in \Z_{>0}: \map t n = \map v n$	0
Let: {{begin-eqn}} {{eqn | l = \alpha | r = \frac {a + b} 2 }} {{eqn | l = \epsilon | r = \frac {b - a} 2 }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = a | r = \alpha - \epsilon }} {{eqn | l = b | r = \alpha + \epsilon }} {{end-eqn}} Thus: :$\openint a b = \openint {\alpha - \epsilon} {\alpha + \epsilon}$ From [[Open Ball in Real Number Line is Open Interval]]: :$\openint {\alpha - \epsilon} {\alpha + \epsilon} = \map {B_\epsilon} \alpha$ where $\map {B_\epsilon} \alpha$ is the [[Definition:Open Ball|open $\epsilon$-ball]] of $\alpha$ in $\R$. Hence the result {{qed}}	0
From the definition of the [[Definition:Dirichlet Convolution|Dirichlet convolution]]: :$\displaystyle \left({f * g}\right) \left({n}\right) = \sum_{a b \mathop = n} f \left({a}\right) g \left({b}\right)$ By definition, [[Definition:Arithmetic Function|arithmetic functions]] are mappings from the [[Definition:Natural Numbers|natural numbers]] $\N$ to the [[Definition:Complex Number|complex numbers]] $\C$. Thus $f \left({a}\right), g \left({b}\right) \in \C$ and commutativity follows from [[Complex Multiplication is Commutative|commutativity of multiplication of complex numbers]]. {{qed}}	0
We have for $s \notin \Z$ [[Euler's Reflection Formula]]: :$\map \Gamma s \, \map \Gamma {1 - s} = \dfrac \pi {\map \sin {\pi s} }$ Replacing $s \mapsto \dfrac {1 + s} 2$ we deduce: {{begin-eqn}} {{eqn | l = \map \Gamma {\frac {1 + s} 2} \, \map \Gamma {\frac {1 - s} 2} | r = \frac \pi {\map \sin {\pi \paren {1 + s} / 2} } | c = substituting $s \mapsto \dfrac {1 + s} 2$ }} {{eqn | r = \frac \pi {\map \cos {\pi s / 2} } | c = [[Sine and Cosine are Periodic on Reals]] }} {{end-eqn}} Also, we have [[Legendre's Duplication Formula]] for $z \notin -\dfrac 1 2 \N_0$: :$\map \Gamma s \, \map \Gamma {s + \dfrac 1 2} = 2^{1 - 2 s} \sqrt \pi \map \Gamma {2 s}$ Replacing $s \mapsto s / 2$ this yields: :$\map \Gamma {\dfrac s 2} \, \map \Gamma {\dfrac {1 + s } 2} = 2^{1 - s} \sqrt \pi \, \map \Gamma s$ Together these give: :$(1): \quad \dfrac {\map \Gamma {s / 2} } {\map \Gamma {\paren {1 - s} / 2} } = 2^{1 - s} \pi^{-1/2} \, \map \Gamma s \, \map \cos {\pi s / 2}$ Now we take the [[Functional Equation for Riemann Zeta Function]]: :$\pi^{-s/2} \, \map \zeta s \, \map \Gamma {s / 2} \, \map \Gamma {\dfrac {1 - s} 2}^{-1} = \pi^{\paren {s - 1} / 2} \, \map \zeta {1 - s}$ and substitute $(1)$ to give: :$\pi^{\paren {s - 1} / 2} \, \map \zeta {1 - s} = \pi^{-\paren {s + 1} / 2} \, \map \zeta s 2^{1 - s} \, \map \Gamma s \, \map \cos {\pi s / 2}$ Multiplying by $\pi^{\paren {s - 1} / 2}$ this becomes: :$\map \zeta {1 - s} = \pi^{-s} 2^{1 - s} \, \map \cos {\pi s / 2} \, \map \Gamma s \, \map \zeta s$ as desired. {{qed}} [[Category:Riemann Zeta Function]] e0b4dqr0ckvuouvjabqz7z7qo1p7ry1	0
Let $N$ be [[Definition:Divisor of Integer|divisible]] by each of the [[Definition:Integer|integers]] from $1$ to $100$. Each [[Definition:Prime Number|prime number]] between $2$ and $97$ must be a [[Definition:Divisor of Integer|divisor]] of $N$. Also: :$2^6 = 64 \divides N$ :$3^4 = 81 \divides N$ :$5^2 = 25 \divides N$ :$7^2 = 49 \divides N$ Every other [[Definition:Integer|integer]] between $1$ and $100$ is the [[Definition:Integer Multiplication|product]] of a [[Definition:Subset|subset]] of all of these. Hence by [[Euclid's Lemma]]: {{begin-eqn}} {{eqn | l = N | o = \ge | r = 2^6 \times 3^4 \times 5^2 \times 7^2 \times 11 \times 13 \times 17 \times 19 \times 23 \times 29 \times 31 \times 37 \times 41 \times 43 \times 47 \times 53 \times 59 \times 61 \times 67 \times 71 \times 73 \times 79 \times 83 \times 89 \times 97 | c = }} {{eqn | r = 69 \, 720 \, 375 \, 229 \, 712 \, 477 \, 164 \, 533 \, 808 \, 935 \, 312 \, 303 \, 556 \, 800 | c = }} {{end-eqn}} {{qed}}	0
Start with the following manipulations: {{begin-eqn}} {{eqn | l = \sum_{k \mathop = m}^{m + n} \paren {\dfrac k p} | r = \frac 1 p \sum_{k \mathop = 0}^{p - 1} \sum_{x \mathop = m}^{m + n} \sum_{a \mathop = 0}^{p - 1} \paren {\dfrac k p} e^{2 \pi i a \paren {x - k} / p} | c = }} {{eqn | r = \frac 1 p \sum_{a \mathop = 1}^{p - 1} \sum_{x \mathop = m}^{m + n} e^{2 \pi i a x / p} \sum_{k \mathop = 0}^{p - 1} \paren {\dfrac k p} e^{-2 \pi i a t / p} | c = }} {{end-eqn}} The [[Definition:Expression|expression]]: :$\displaystyle \sum_{k \mathop = 0}^{p - 1} \paren {\dfrac k p} e^{-2 \pi i a t / p}$ is a [[Definition:Gauss Sum|Gauss sum]], and has magnitude $\sqrt p$. {{explain|The above statement.}} Hence: {{begin-eqn}} {{eqn | l = \size {\sum_{t \mathop = m}^{m + n} \paren {\dfrac t p} } | o = \le | r = \size {\frac {\sqrt p} p \sum_{a \mathop = 1}^{p - 1} \sum_{x \mathop = m}^{m + n} e^{2 \pi a i x / p} } | c = }} {{eqn | r = \size {\frac {\sqrt p} p \sum_{a \mathop = 1}^{p - 1} e^{2 \pi i a m / p} \sum_{x \mathop = 0}^n e^{2 \pi i a x / p} } | c = }} {{eqn | o = \le | r = \size {\frac {\sqrt p} p \sum_{a \mathop = 1}^{p - 1} \frac {e^{2 \pi i a n / p} - 1} {e^{2 \pi i a / p} - 1} } | c = }} {{eqn | r = \size {\frac {\sqrt p} p \sum_{a \mathop = 1}^{p - 1} \frac {e^{\pi i a n / p} \, \map \sin {\pi a n / p} } {e^{\pi i a / p} \, \map \sin {\pi a / p} } } | c = }} {{eqn | o = \le | r = \frac {\sqrt p} p \sum_{a \mathop = 1}^{p - 1} \size {\frac 1 {\map \sin {\pi \left\langle{a / p}\right\rangle} } } | c = }} {{eqn | o = \le | r = \frac {\sqrt p} p \sum_{a \mathop = 1}^{p - 1} \frac 1 {2 \norm {a / p} } | c = }} {{end-eqn}} {{explain|$\left\langle{a / p}\right\rangle$}} Here $\norm x$ denotes the difference between $x$ and the closest [[Definition:Integer|integer]] to $x$, that is: :$\displaystyle \norm x = \inf_{z \mathop \in \Z} \set {\size {x - z} }$ Since $p$ is [[Definition:Odd Integer|odd]], we have: {{begin-eqn}} {{eqn | l = \frac 1 2 \sum_{a \mathop = 1}^{p-1} \frac 1 {\norm{a / p} } | r = \sum_{0 \mathop < a \mathop < \frac p 2} \frac p a | c = }} {{eqn | r = p \sum_{a \mathop = 1}^{\frac {p - 1} 2} \frac 1 a | c = }} {{end-eqn}} Now: :$\ln \dfrac {2 x + 1} {2 x - 1} > \dfrac 1 x$ for $x > 1$. To prove this, it suffices to show that the [[Definition:Function|function]] $f: \hointr 1 \infty \to \R$ given by: :$\map f x = x \ln \dfrac {2 x + 1} {2 x - 1}$ is [[Definition:Decreasing|decreasing]] and approaches $1$ as $x \to \infty$. To prove the latter statement, substitute $v = 1/x$ and take the [[Definition:Limit|limit]] as $v \to 0$ using [[L'Hospital's Rule]]. To prove the former statement, it will suffice to show that $f'$ is less than zero on the [[Definition:Real Interval|interval]] $\hointr 1 \infty$. Now we have that: :$\map {f''} x = \dfrac {-4} {4 x^2 - 1} \paren {1 - \dfrac {4 x^2 + 1} {4 x^2 - 1} } > 0$ for $x > 1$. So $f'$ is [[Definition:Increasing|increasing]] on $\hointr 1 \infty$. But $\map {f'} x \to 0$ as $x \to \infty$. So $f'$ is less than zero for $x > 1$. With this in hand, we have: {{begin-eqn}} {{eqn | l = \size {\sum_{t \mathop = m}^{m + n} \paren {\frac t p} } | o = \le | r = \frac {\sqrt p} p \cdot p \sum_{a \mathop = 1}^{\frac {p - 1} 2} \frac 1 a | c = }} {{eqn | o = < | r = \sqrt p \sum_{a \mathop = 1}^{\frac {p - 1} 2} \ln \frac {2 a + 1} {2 a - 1} | c = }} {{eqn | r = \sqrt p \, \ln p | c = }} {{end-eqn}} {{qed}} {{Namedfor|George Pólya|name2 = Ivan Matveevich Vinogradov|cat = Pólya|cat2 = Vinogradov I M}}	0
We have that: :$0 < y_1 < y_2 \implies y_1^n < y_2^n$ so there exists at most one $y \in \R: y \ge 0$ such that $y^n = x$. {{Qed}}	0
First we note that: :$107\,928\,278\,317 - 9\,922\,782\,870 = 98\,005\,495\,447 = 29 \times 149 \times 22\,681\,207$ and so this [[Definition:Arithmetic Sequence|arithmetic sequence]] of [[Definition:Prime Number|primes]] does not extend to $n < 0$. {{begin-eqn}} {{eqn | l = 107\,928\,278\,317 + 0 \times 9\,922\,782\,870 | r = 107\,928\,278\,317 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 107\,928\,278\,317 + 1 \times 9\,922\,782\,870 | r = 117\,851\,061\,187 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 107\,928\,278\,317 + 2 \times 9\,922\,782\,870 | r = 127\,773\,844\,057 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 107\,928\,278\,317 + 3 \times 9\,922\,782\,870 | r = 137\,696\,626\,927 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 107\,928\,278\,317 + 4 \times 9\,922\,782\,870 | r = 147\,619\,409\,797 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 107\,928\,278\,317 + 5 \times 9\,922\,782\,870 | r = 157\,542\,192\,667 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 107\,928\,278\,317 + 6 \times 9\,922\,782\,870 | r = 167\,464\,975\,537 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 107\,928\,278\,317 + 7 \times 9\,922\,782\,870 | r = 177\,387\,758\,407 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 107\,928\,278\,317 + 8 \times 9\,922\,782\,870 | r = 187\,310\,541\,277 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 107\,928\,278\,317 + 9 \times 9\,922\,782\,870 | r = 197\,233\,324\,147 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 107\,928\,278\,317 + 10 \times 9\,922\,782\,870 | r = 207\,156\,107\,017 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 107\,928\,278\,317 + 11 \times 9\,922\,782\,870 | r = 217\,078\,889\,887 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 107\,928\,278\,317 + 12 \times 9\,922\,782\,870 | r = 227\,001\,672\,757 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 107\,928\,278\,317 + 13 \times 9\,922\,782\,870 | r = 236\,924\,455\,627 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 107\,928\,278\,317 + 14 \times 9\,922\,782\,870 | r = 246\,847\,238\,497 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 107\,928\,278\,317 + 15 \times 9\,922\,782\,870 | r = 256\,770\,021\,367 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 107\,928\,278\,317 + 16 \times 9\,922\,782\,870 | r = 266\,692\,804\,237 | c = which is [[Definition:Prime Number|prime]] }} {{eqn | l = 107\,928\,278\,317 + 17 \times 9\,922\,782\,870 | r = 276\,615\,587\,107 | c = which is [[Definition:Prime Number|prime]] }} {{end-eqn}} But note that $107\,928\,278\,317 + 18 \times 9\,922\,782\,870 = 286\,538\,369\,977 = 23 \times 181 \times 68\,829\,779$ and so is not [[Definition:Prime Number|prime]]. {{ProofWanted|It remains to be shown that there are no smaller such APs}}	0
{{begin-eqn}} {{eqn | l = \map {f'} x | r = \frac \d {\d x} x^{1/x} }} {{eqn | r = \frac \d {\d x} e^{\ln x / x} }} {{eqn | r = e^{\ln x / x} \paren {\frac 1 {x^2} - \frac {\ln x} {x^2} } }} {{eqn | r = \frac {x^{1/x} } {x^2} \paren {1 - \ln x} }} {{end-eqn}} $\dfrac {x^{1/x} } {x^2}$ is always greater than $0$. Therefore: :$\map {f'} x > 0$ for $\ln x < 1$ :$\map {f'} x = 0$ for $\ln x = 1$ :$\map {f'} x < 0$ for $\ln x > 1$ By [[Derivative at Maximum or Minimum]], maximum is obtained when $\ln x = 1$, that is, when $x = e$. {{qed}} {{Namedfor|Jakob Steiner|cat = Steiner}}	0
Let $L/k$ be a [[Definition:Field Extension|field extension]]. Let $L$ be [[Definition:Finitely Generated Algebra|finitely generated]] [[Definition:Algebra Defined by Ring Homomorphism|as an algebra]] over $k$. Then $L/k$ is a [[Definition:Finite Field Extension|finite field extension]].	0
:$\displaystyle \int \frac {\d x} {\csc a x} = \frac {-\cos a x} a + C$	0
Consider the [[Definition:Graph of Mapping|graph]] $f$ of the [[Definition:Real Exponential Function|exponential function]] in the [[Definition:Cartesian Plane|real Cartesian plane]] $\R^2$: :$f := \set {\tuple {x, y} \in \R^2: y = e^x}$ The only [[Definition:Rational Point in Plane|rational point]] of $f$ is $\tuple {0, 1}$.	0
Let $r \in \R$, $m \in \Z$. :$\displaystyle \sum_{k \mathop \in \Z} \binom r k \binom {-r} {m - 2 k} \paren {-1}^{m + k} = \binom r m$	0
:$\displaystyle \int \frac {\sin a x \rd x} {p + q \cos a x} = \frac {-1} {a q} \ln \size {p + q \cos a x} + C$	0
We use partial fraction expansion to expand $\dfrac 1 {j^2 \paren {j + 1}^2 \paren {j + 2}^2}$. Let $\dfrac 1 {j^2 \paren {j + 1}^2 \paren {j + 2}^2} = \dfrac A j + \dfrac B {j^2} + \dfrac C {j + 1} + \dfrac D {\paren {j + 1}^2} + \dfrac E {j + 2} + \dfrac F {\paren {j + 2}^2}$. This has solutions $A = - \dfrac 3 4, B = \dfrac 1 4, C = 0, D = 1, E = \dfrac 3 4, F = \dfrac 1 4$. Thus: {{begin-eqn}} {{eqn | l = \sum_{j \mathop = 1}^\infty \frac 1 {j^2 \paren {j + 1}^2 \paren {j + 2}^2} | r = \sum_{j \mathop = 1}^\infty \paren {-\frac 3 {4j} + \frac 1 {4 j^2} + \frac 1 {\paren {j + 1}^2} + \frac 3 {4 \paren {j + 2} } + \frac 1 {4 \paren {j + 2}^2} } }} {{eqn | r = \sum_{j \mathop = 1}^\infty \paren {\frac 1 {4 j^2} + \frac 1 {\paren {j + 1}^2} + \frac {3 j - 3 \paren {j + 2} } {4 j \paren {j + 2} } + \frac 1 {4 \paren {j + 2}^2} } }} {{eqn | r = \sum_{j \mathop = 1}^\infty \frac 1 {4 j^2} + \sum_{j \mathop = 1}^\infty \frac 1 {\paren {j + 1}^2} + \sum_{j \mathop = 1}^\infty \frac 1 {4 \paren {j + 2}^2} - \sum_{j \mathop = 1}^\infty \frac 6 {4 j \paren {j + 2} } }} {{eqn | r = \frac 1 4 \sum_{j \mathop = 1}^\infty \frac 1 {j^2} + \sum_{j \mathop = 2}^\infty \frac 1 {j^2} + \frac 1 4 \sum_{j \mathop = 3}^\infty \frac 1 {j^2} - \frac 3 2 \sum_{j \mathop = 1}^\infty \frac 1 {j \paren {j + 2} } | c = [[Translation of Index Variable of Summation]] }} {{eqn | r = \frac 3 2 \sum_{j \mathop = 1}^\infty \frac 1 {j^2} - 1 - \frac 1 4 - \frac 1 {16} - \frac 3 2 \paren {\frac 3 4} | c = [[Sum of Sequence of Products of Consecutive Odd and Consecutive Even Reciprocals/Corollary|Corollary to Sum of Sequence of Products of Consecutive Odd and Consecutive Even Reciprocals]] }} {{eqn | r = \frac 3 2 \paren {\frac {\pi^2} 6} - \frac {21} {16} - \frac 9 8 | c = [[Basel Problem]] }} {{eqn | r = \frac {4 \pi^2 - 39} {16} }} {{end-eqn}} {{qed}}	0
:$\displaystyle \int \cos^3 a x \rd x = \frac {\sin a x} a - \frac {\sin^3 a x} {3 a} + C$	0
:$\csc 315^\circ = \csc \dfrac {7 \pi} 4 = -\sqrt 2$	0
By definition of a [[Definition:Power (Algebra)/Real Number/Definition 1|power to a real number]]: :$a^x = \exp \left({x \ln a}\right)$ As $x \ln a$ is itself a [[Definition:Real Number|real number]], we can use [[Power Series Expansion for Exponential Function]]: {{begin-eqn}} {{eqn | ll= \forall x \in \R: | l = \exp x | r = \sum_{n \mathop = 0}^\infty \frac {x^n} {n!} | c = }} {{eqn | r = 1 + x + \frac {x^2} {2!} + \frac {x^3} {3!} + \cdots | c = }} {{end-eqn}} substituting $x \ln a$ for $x$. {{qed}}	0
We prove the result by [[Principle of Mathematical Induction|induction]] on $n$. === Basis for the Induction === The case $n = 7$ is verified by direct calculation: :$12! \times 13! > 20!$ This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === We suppose for some $k \ge 7$, we have: :$\paren {2 k - 2}! \, \paren {2 k - 1}! > \paren {3 k - 1}!$ This is our [[Definition:Induction Hypothesis|induction hypothesis]]. === Induction Step === This is our [[Definition:Induction Step|induction step]]: {{begin-eqn}} {{eqn | l = \paren {2 k}! \, \paren {2 k + 1}! | o = > | r = \paren {2 k} \paren {2 k - 1} \paren {2 k + 1} \paren {2 k} \paren {3 k - 1}! | c = [[Factorial as Product of Consecutive Factorials/Lemma 2#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | o = > | r = k \paren {2 k - 1} \paren {2 k + 1} \paren {3 k} \paren {3 k - 1}! | c = because $4 k > 3 k$ }} {{eqn | o = > | r = 4 \paren {2 k - 1} \paren {2 k + 1} \paren {3 k} \paren {3 k - 1}! | c = because $k > 4$ }} {{eqn | r = \paren {4 k - 2} \paren {4 k + 2} \paren {3 k} \paren {3 k - 1}! }} {{eqn | o = \ge | r = \paren {3 k + 5} \paren {3 k + 9} \paren {3 k} \paren {3 k - 1}! | c = because $k \ge 7$ }} {{eqn | o = > | r = \paren {3 k + 1} \paren {3 k + 2} \paren {3 k} \paren {3 k - 1}! }} {{eqn | r = \paren {3 k + 2}! | c = {{Defof|Factorial}} }} {{end-eqn}} The result follows by the [[Principle of Mathematical Induction]]. {{qed}} [[Category:Factorials]] [[Category:Factorial as Product of Consecutive Factorials]] 7puvni7rhyv8vm98h7ysu1va71syvvp	0
:$\displaystyle \int \sin^m a x \cos^n a x \rd x = \frac {-\sin^{m - 1} a x \cos^{n + 1} a x} {a \paren {m + n} } + \frac {m - 1} {m + n} \int \sin^{m - 2} a x \cos^n a x \rd x + C$	0
For $n \in \N$: {{begin-eqn}} {{eqn | l = \map H n | r = \gamma + \frac {\map {\Gamma'} {n + 1} } {\map \Gamma {n + 1} } }} {{eqn | r = \gamma - \gamma + \sum_{m \mathop = 1}^\infty \paren {\frac 1 m - \frac 1 {n + m} } | c = [[Reciprocal times Derivative of Gamma Function]] }} {{eqn | r = \lim_{k \mathop \to \infty} \sum_{m \mathop = 1}^k \paren {\frac 1 m - \frac 1 {n + m} } }} {{eqn | r = \lim_{k \mathop \to \infty} \paren {\sum_{m \mathop = 1}^k \paren {\frac 1 m} - \sum_{m \mathop = 1}^k \paren {\frac 1 {n + m} } } }} {{eqn | r = \lim_{k \mathop \to \infty} \paren {\sum_{m \mathop = 1}^k \paren {\frac 1 m} - \sum_{m \mathop = n + 1}^{k + n} \paren {\frac 1 m } } }} {{eqn | r = \lim_{k \mathop \to \infty} \paren {\sum_{m \mathop = 1}^n \paren {\frac 1 m} - \sum_{m \mathop = k + 1}^{k + n} \paren {\frac 1 m } } }} {{eqn | r = \sum_{m \mathop = 1}^n \paren {\frac 1 m} - \lim_{k \mathop \to \infty} \sum_{m \mathop = k + 1}^{k + n} \paren {\frac 1 m } | c = this limit will vanish since it is positive but less than $\dfrac n {k + 1}$ }} {{eqn | r = H_n - 0 | c = {{Defof|Harmonic Number}} }} {{eqn | r = H_n }} {{end-eqn}} {{qed}}	0
Let $\map f t := \map \Si t = \displaystyle \int_0^t \dfrac {\sin u} u \rd u$. Then: :$\map f 0 = 0$ and: {{begin-eqn}} {{eqn | l = \map \Si t | r = \int_0^t \dfrac {\sin u} u \rd u | c = {{Defof|Sine Integral Function}} }} {{eqn | r = \int_0^t \dfrac 1 u \paren {u - \dfrac {u^3} {3!} + \dfrac {u^5} {5!} - \dfrac {u^7} {7!} + \dotsb} \rd u | c = {{Defof|Real Sine Function}} }} {{eqn | r = t - \dfrac {t^3} {3 \times 3!} + \dfrac {t^5} {5 \times 5!} - \dfrac {t^7} {7 \times 7!} + \dotsb | c = [[Primitive of Power]] }} {{eqn | ll= \leadsto | l = \laptrans {\map \Si t} | r = \laptrans {t - \dfrac {t^3} {3 \times 3!} + \dfrac {t^5} {5 \times 5!} - \dfrac {t^7} {7 \times 7!} + \dotsb} | c = }} {{eqn | r = \dfrac 1 {s^2} - \dfrac 1 {3 \times 3!} \dfrac {3!} {s^4} + \dfrac 1 {5 \times 5!} \dfrac {5!} {s^6} - \dfrac 1 {7 \times 7!} \dfrac {7!} {s^8} + \dotsb | c = [[Laplace Transform of Positive Integer Power]] }} {{eqn | r = \dfrac 1 {s^2} - \dfrac 1 {3 s^4} + \dfrac 1 {5 s^6} - \dfrac 1 {7 s^8} + \dotsb | c = simplifying }} {{eqn | r = \dfrac 1 s \paren {\dfrac {\paren {1 / s} } 1 - \dfrac {\paren {1 / s}^3} 3 + \dfrac {\paren {1 / s}^5} 5 - \dfrac {\paren {1 / s}^7} 7 + \dotsb} | c = rearranging }} {{eqn | r = \dfrac 1 s \arctan \dfrac 1 s | c = [[Power Series Expansion for Real Arctangent Function]] }} {{end-eqn}} {{qed}}	0
Let $M = \struct {S, \mathscr I}$ be a [[Definition:Matroid|matroid]]. Let $C$ be a [[Definition:Dependent Subset (Matroid)|dependent subset]] of $M$. Let $x \in S$. Let $X$ be an [[Definition:Independent Subset (Matroid)|independent subset]] of $M$ such that: :$C \setminus \set x \subseteq X$. Then: :$x \notin X$	0
Let $\N$ be the [[Definition:Natural Numbers|natural numbers]]. Let $\times$ be [[Definition:Natural Number Multiplication|multiplication]] on $\N$. Then: :$\forall x, y, z \in \N_{>0}: x \times z = y \times z \implies x = y$ :$\forall x, y, z \in \N_{>0}: x \times y = x \times z \implies y = z$ That is, $\times$ is [[Definition:Cancellable Operation|cancellable]] on $\N_{>0}$.	0
By definition of [[Definition:Vector Cross Product/Complex/Definition 2|complex cross product]]: :$z_1 \times z_2 = \cmod {z_1} \, \cmod {z_2} \sin \theta$ :$\cmod {z_1}$ denotes the [[Definition:Complex Modulus|complex modulus]] of $z_1$ :$\theta$ denotes the [[Definition:Angle|angle]] from $z_1$ to $z_2$, measured in the [[Definition:Positive Direction|positive direction]]. === Necessary Condition === Let $z_1$ and $z_2$ be [[Definition:Parallel Vectors|parallel]]. Then either $\theta = 0^\circ$ or $\theta = 180^\circ$. Either way, from [[Sine of Zero is Zero]] or [[Sine of Straight Angle]]: :$\sin \theta = 0$ and so: :$\cmod {z_1} \, \cmod {z_2} \sin \theta = 0$ Hence by definition: :$z_1 \times z_2 = 0$ {{qed|lemma}} === Sufficient Condition === Let $z_1 \times z_2 = 0$. Then by definition: :$\cmod {z_1} \, \cmod {z_2} \sin \theta = 0$ As neither $z_1 = 0$ or $z_2 = 0$ it follows that $\sin \theta = 0$. From [[Sine of Multiple of Pi]] it follows that either: :$\theta = 0^\circ$ :$\theta = 180^\circ$ or: :$\theta$ is either of the above plus a full circle. That is, $z_1$ and $z_2$ are [[Definition:Parallel Vectors|parallel]]. {{qed}}	0
Let $T = \struct {S, \tau}$ be a [[Definition:Topological Space|topological space]]. Let $H \subseteq S$. Let $x \in H$. Let $\BB_x$ be a [[Definition:Local Basis|local basis]] of $x$. Then $x$ is an [[Definition:Isolated Point (Topology)|isolated point]] of $H$ {{iff}}: :$\exists U \in \BB_x : U \cap H = \set x$	0
Let $T = \struct {S, \tau}$ be a [[Definition:Topological Space|topological space]]. Let $x \in S$. Then the [[Definition:Singleton|singleton]] $\set{x}$ is [[Definition:Connected (Topology)|connected]].	0
From [[Change of Base of Logarithm]]: :$\log_a x = \log_a b \ \log_b x$ Substituting $a = 10$ and $b = 2$ gives: :$\log_{10} x = \left({\lg x}\right) \left({\log_{10} 2}\right)$ The [[Common Logarithm of 2|common logarithm of $2$]]: :$\log_{10} 2 = 0 \cdotp 30102 \, 99956 \, 63981 \, 19521 \, 37389 \ldots$ can be calculated or looked up. {{qed}}	0
Consider the numbers $\sqbrk {999 \, 999 \, 9ab}$. Since $999 \, 999 \, 000$ is [[Definition:Divisor|divisible]] by $2, 3, 5, 7, 11, 13$, if $\sqbrk {9ab}$ is [[Definition:Divisor|divisible]] by these [[Definition:Prime Number|primes]], so is $\sqbrk {999 \, 999 \, 9ab}$. After this elimination the only $\sqbrk {ab} > 37$ that remains are: :$41, 43, 47, 53, 61, 67, 71, 77, 83, 89, 91, 97$ We have: {{begin-eqn}} {{eqn | l = 999 \, 999 \, 941 | r = 113 \times 149 \times 59 \, 393 }} {{eqn | l = 999 \, 999 \, 943 | r = 5 \, 623 \times 177 \, 841 }} {{eqn | l = 999 \, 999 \, 947 | r = 163 \times 6 \, 134 \, 969 }} {{eqn | l = 999 \, 999 \, 953 | r = 29 \times 31 \times 773 \times 1 \, 439 }} {{eqn | l = 999 \, 999 \, 961 | r = 3 \, 673 \times 272 \, 257 }} {{eqn | l = 999 \, 999 \, 967 | r = 3 \, 257 \times 307 \, 031 }} {{eqn | l = 999 \, 999 \, 971 | r = 193 \times 5 \, 181 \, 347 }} {{eqn | l = 999 \, 999 \, 977 | r = 2 \, 971 \times 336 \, 587 }} {{eqn | l = 999 \, 999 \, 983 | r = 337 \times 2 \, 967 \, 359 }} {{eqn | l = 999 \, 999 \, 989 | r = 4 \, 327 \times 231 \, 107 }} {{eqn | l = 999 \, 999 \, 991 | r = 67 \times 14 \, 925 \, 373 }} {{eqn | l = 999 \, 999 \, 997 | r = 71 \times 2 \, 251 \times 6 \, 257 }} {{end-eqn}} And we do have $999 \, 999 \, 937$ is [[Definition:Prime Number|prime]]. {{qed}}	0
Let $n \in \N_{>0}$. Let $M_1 = \left({A_1, d_1}\right), M_2 = \left({A_2, d_2}\right), \ldots, M_n = \left({A_n, d_n}\right)$ be [[Definition:Metric Space|metric spaces]]. Let $N_1 = \left({B_1, d'_1}\right), N_2 = \left({B_2, d'_2}\right), \ldots, N_n = \left({B_n, d'_n}\right)$ be [[Definition:Metric Space|metric spaces]]. Let $f_i: M_i \to N_i$ be [[Definition:Continuous Mapping (Metric Spaces)|continuous mappings]] for all $i \in \left\{{1, 2, \ldots, n}\right\}$. Let $\displaystyle \mathcal M = \prod_{i \mathop = 1}^n M_i$ be the [[Definition:Finite Cartesian Product|cartesian product]] of $A_1, A_2, \ldots, A_n$. Let $\displaystyle \mathcal N = \prod_{i \mathop = 1}^n N_i$ be the [[Definition:Finite Cartesian Product|cartesian product]] of $B_1, B_2, \ldots, B_n$. Let $d_\infty$ be the [[Definition:Chebyshev Distance/General Definition|Chebyshev distance]] on $\displaystyle \mathcal A = \prod_{i \mathop = 1}^n A_i$, and $\displaystyle \mathcal B = \prod_{i \mathop = 1}^n B_i$, defined as: : $\displaystyle d_\infty \left({x, y}\right) = \max_{i \mathop = 1}^n \left\{ {d_i \left({x_i, y_i}\right)}\right\}$ : $\displaystyle d_\infty \left({x, y}\right) = \max_{i \mathop = 1}^n \left\{ {d'_i \left({x_i, y_i}\right)}\right\}$ where $x = \left({x_1, x_2, \ldots, x_n}\right), y = \left({y_1, y_2, \ldots, y_n}\right) \in \mathcal A$ or $\mathcal B$. Let $F: M \to N$ be the [[Definition:Mapping|mapping]] defined as: :$\forall x \in \mathcal A: F \left({x_1, x_2, \ldots, x_n}\right) = \left({f \left({x_1}\right), \left({x_2}\right), \ldots, \left({x_n}\right)}\right)$ Then $F$ is [[Definition:Continuous Mapping (Metric Spaces)|continuous]].	0
Let $C_N$ be the square with vertices $\left({N + \frac 1 2}\right) \left({\pm 1 \pm i}\right)$ for $N \in \N$. Then there exists a constant $A$ independent of $N$ such that: :$\displaystyle \left\vert{\cot \left({\pi z}\right)}\right\vert < A$ for all $z$ on $C_N$.	0
Let $\CC \closedint a b$ be the [[Definition:Space of Continuous on Closed Interval Real-Valued Functions|space of continuous on closed interval real-valued functions]]. Let $x \in \CC \closedint a b$ be a [[Definition:Continuous Real-Valued Vector Function|continuous real valued function]]. Let $\displaystyle \norm x_1 := \int_a^b \size {\map x t} \rd t$ be the [[Definition:P-Seminorm|1-seminorm]]. Then $\norm {\, \cdot \,}_1$ is a [[Definition:Norm on Vector Space|norm]] on $\CC \closedint a b$.	0
Let $\mathbb I = \R \setminus \Q$ be the [[Definition:Set|set]] of all [[Definition:Irrational Number|irrational numbers]]. Let $d: \mathbb I \times \mathbb I \to \R$ be defined as: :$\map d {x_1, x_2} = \size {x_1 - x_2}$ where $\size x$ is the [[Definition:Absolute Value|absolute value]] of $x$. Then $d$ is a [[Definition:Metric|metric]] on $\mathbb I$ and so $\struct {\mathbb I, d}$ is a [[Definition:Metric Space|metric space]].	0
Let $V$ be a [[Definition:Banach Space|Banach space]], and let $\left\Vert{\cdot}\right\Vert$ denote its [[Definition:Norm on Vector Space|norm]]. Let $\left({v_i}\right)_{i\in I}$ be an [[Definition:Indexed Set|indexed]] [[Definition:Subset|subset]] of $V$. Let the [[Definition:Generalized Sum|generalized sum]] $\displaystyle \sum \left\{{v_i: i \in I}\right\}$ [[Definition:Absolutely Convergent Generalized Sum|converge absolutely]]. Then $\displaystyle \left\Vert{\sum \left\{{v_i: i \in I}\right\}}\right\Vert \le \sum \left\{{\left\Vert{v_i}\right\Vert: i \in I}\right\}$.	0
Let $z \in S$. {{begin-eqn}} {{eqn | l = \map {\lambda_x \circ \lambda_y} z | r = \map {\lambda_x} {\map {\lambda_y} z} | c = {{Defof|Composition of Mappings}} }} {{eqn | r = \map {\lambda_x} {y * z} | c = {{Defof|Left Regular Representation}} }} {{eqn | r = x * \paren {y * z} | c = {{Defof|Left Regular Representation}} }} {{eqn | r = \paren {x * y} * z | c = {{SemigroupAxiom|1}} }} {{eqn | r = \map {\lambda_{x * y} } z | c = {{Defof|Left Regular Representation}} }} {{end-eqn}} {{qed}}	0
{{ProofWanted|First the concept of [[Definition:Wallpaper Group|wallpaper group]] needs to be explored.}}	0
Let $A, B, C, D \in \powerset S$. Let $A \subseteq B$ and $C \subseteq D$. Then: :$A \circ_\PP C \subseteq B \circ_\PP D$	0
{{begin-eqn}} {{eqn | l = \int \cot x \rd x | r = \int \frac {\cos x} {\sin x} \rd x | c = {{Defof|Real Cotangent Function}} }} {{eqn | r = \int \frac {\paren {\sin x}'} {\sin x} \rd x | c = [[Derivative of Sine Function]] }} {{eqn | r = \ln \size {\sin x} + C | c = [[Primitive of Function under its Derivative]] }} {{end-eqn}} {{qed}}	0
By [[Compact Space is Weakly Locally Compact]], $T$ is [[Definition:Weakly Locally Compact Space|weakly locally compact]]. Thus $T$ is a [[Definition:Locally Compact Hausdorff Space|locally compact Hausdorff space]]. {{qed}}	0
Let $m, n \in \N$ such that $m < n$. Then: : $\left|{\left[{m + 1 \,.\,.\, n}\right]}\right| = n - m$ Let $h: \N_{n - m} \to \left[{m + 1 \,.\,.\, n}\right]$ be the [[Definition:Mapping|mapping]] defined as: :$\forall x \in \N_{n - m}: h \left({x}\right) = x + m + 1$ Let the [[Definition:Ordering|orderings]] on $\left[{m + 1 \,.\,.\, n}\right]$ and $\N_{n - m}$ be those [[Definition:Restriction of Relation|induced]] by the [[Definition:Ordering|ordering]] of $\N$. Then $h$ a unique [[Definition:Order Isomorphism|order isomorphism]].	0
Let $T = \struct {S, \tau}$ be the [[Definition:Either-Or Space|either-or space]]. Then $T$ is a [[Definition:T4 Space|$T_4$ space]].	0
Let $a$ and $b$ both be [[Definition:Smallest Element|smallest elements]] of $S$. Then by definition: :$\forall y \in S: a \preceq y$ :$\forall y \in S: b \preceq y$ Thus it follows that: :$a \preceq b$ :$b \preceq a$ But as $\preceq$ is an [[Definition:Ordering|ordering]], it is [[Definition:Antisymmetric Relation|antisymmetric]]. Hence by definition of [[Definition:Antisymmetric Relation|antisymmetric]], $a = b$. {{qed}}	0
Taking the [[Definition:Group Axioms|group axioms]] in turn: === $\text G 0$: Closure === [[Non-Zero Complex Numbers Closed under Multiplication]]. {{qed|lemma}} === $\text G 1$: Associativity === [[Complex Multiplication is Associative]]. {{qed|lemma}} === $\text G 2$: Identity === From [[Complex Multiplication Identity is One]], the identity element of $\struct {\C_{\ne 0}, \times}$ is the [[Definition:Complex Number|complex number]] $1 + 0 i$. {{qed|lemma}} === $\text G 3$: Inverses === From [[Inverse for Complex Multiplication]], the inverse of $x + i y \in \struct {\C_{\ne 0}, \times}$ is: :$\dfrac 1 z = \dfrac {x - i y} {x^2 + y^2} = \dfrac {\overline z} {z \overline z}$ where $\overline z$ is the [[Definition:Complex Conjugate|complex conjugate]] of $z$. {{qed|lemma}} === $\text C$: Commutativity === [[Complex Multiplication is Commutative]]. {{qed|lemma}} === Infinite === [[Complex Numbers are Uncountable]]. {{qed}}	0
{{begin-eqn}} {{eqn | l = \wp\left({-z; \omega_1, \omega_2}\right) | r = \frac 1 {\left({-z}\right)^2} + \sum_{\left({n, m}\right) \mathop \in \Z^2 \setminus \left({0, 0}\right)} \left({ \frac 1 {\left({-z - 2 m \omega_1 - 2 n \omega_2}\right)^2} - \frac 1 {\left({2 m \omega_1 + 2 n \omega_2}\right)^2} }\right) | c = {{Defof|Weierstrass's Elliptic Function}} }} {{eqn | r = \frac 1 {z^2} + \left({\sum_{\left({n, m}\right) \mathop \in \Z_{\ge 0}^2 \setminus \left({0, 0}\right)} + \sum_{\left({n, m}\right) \mathop \in \Z_{<0}^2} }\right) \left({ \frac 1 {\left({z - 2 m \omega_1 - 2 n \omega_2}\right)^2} - \frac 1 {\left({-2 m \omega_1 - 2 n \omega_2}\right)^2} }\right) }} {{eqn | r = \frac 1 {z^2} + \left({ \sum_{\left({n, m}\right) \mathop \in \Z_{\le 0}^2 \setminus \left({0, 0}\right)} } + \sum_{\left({n, m}\right) \mathop \in \Z_{> 0}^2 }\right) \left({ \frac 1 {\left({z - 2 m \omega_1 - 2 n \omega_2}\right)^2} - \frac 1 {\left({2 m \omega_1 + 2 n \omega_2}\right)^2} }\right) | c = letting $\left({n, m}\right) \to \left({-n, -m}\right)$ }} {{eqn | r = \frac 1 {z^2} + {\sum_{\left({n, m}\right) \mathop \in \Z^2 \setminus \left({0, 0}\right) } } \left({ \frac 1 {\left({z - 2 m \omega_1 - 2 n \omega_2}\right)^2} - \frac 1 {\left({2 m \omega_1 + 2 n \omega_2}\right)^2} }\right) }} {{eqn | r = \wp\left({z; \omega_1, \omega_2}\right) | c = {{Defof|Weierstrass's Elliptic Function}} }} {{end-eqn}} {{qed}}	0
:$\displaystyle \int e^{a x} \sinh b x \rd x = \frac {e^{a x} \paren {a \sinh b x - b \cosh b x} } {a^2 - b^2} + C$	0
{{TFAE|def = Independent Subgroups}} Let $G$ be a [[Definition:Group|group]] whose [[Definition:Identity Element|identity]] is $e$. Let $\left \langle {H_n} \right \rangle$ be a [[Definition:Sequence|sequence]] of [[Definition:Independent Subgroups|independent subgroups]] of $G$.	0
Let $H$ be a [[Definition:Subgroup|subgroup]] of $G$ such that $K \subseteq H$. Consider the [[Definition:Restriction of Mapping|restriction]] of $\phi$ to $H$. By [[Group Homomorphism Preserves Subgroups]], $\phi_{\restriction_H} \sqbrk H$ is a [[Definition:Group|group]]. From [[Group Epimorphism Induces Bijection between Subgroups]] it follows that the [[First Isomorphism Theorem]] can be applied. Hence the result. {{qed}}	0
:$\displaystyle \int \frac {\sqrt {x^2 - a^2} } {x^3} \rd x = \frac {-\sqrt {x^2 - a^2} } {2 x^2} + \frac 1 {2 a} \arcsec \size {\frac x a} + C$	0
From [[Intersection of Subgroups is Subgroup]], we have that $H \cap K \le H$. Let the number of [[Definition:Left Coset|left cosets]] of $H \cap K$ in $H$ be $r$. Then the [[Definition:Left Coset Space|left coset space]] of $H \cap K$ in $H$ is: : $\set {x_1 \paren {H \cap K}, x_2 \paren {H \cap K}, \ldots, x_r \paren {H \cap K} }$ So each element of $H$ is in $x_i \paren {H \cap K}$ for some $1 \le i \le r$. Also, if $i \ne j$, we have: :$x_j^{-1} x_i \notin H \cap K$ Let $h k \in H K$. We can write $h = x_i g$ for some $1 \le i \le r$ and some $g \in K$. Thus: :$h k = x_i \paren {g k}$ Since $g, k \in K$, this shows $h k \in x_i K$. {{AimForCont}} the [[Definition:Left Coset|left cosets]] $x_i K$ are not all [[Definition:Disjoint Sets|disjoint]]. Then by [[Left Coset Space forms Partition]]: :$x_i K = x_j K$ for some $i, j$. So by [[Left Congruence Class Modulo Subgroup is Left Coset]]: :$x_j^{-1} x_i \in K$ Since $x_i, x_j \in H$, we have: :$x_j^{-1} x_i \in H \cap K$ which [[Definition:Contradiction|contradicts]] the definition. Therefore the [[Definition:Left Coset|left cosets]] $x_i K$ are [[Definition:Disjoint Sets|disjoint]] for $1 \le i \le r$. This leads us to: :$\dfrac {\order H} {\order {H \cap K} } = \dfrac {\order {H K} } {\order K} = r$ whence the result. {{qed}}	0
Let $\R^2$ be the [[Definition:Real Number Plane|real number plane]]. Let $d_\infty$ be the [[Definition:Chebyshev Distance/Real Number Plane|Chebyshev distance]] on $\R^2$. Let $f: \R^2 \to \R$ be the [[Definition:Real-Valued Function|real-valued function]] defined as: :$\forall \left({x_1, x_2}\right) \in \R^2: f \left({x_1, x_2}\right) = x_1 + x_2$ Then $f$ is [[Definition:Continuous Mapping (Metric Spaces)|continuous]].	0
:[[Excluded Point Topology is Open Extension Topology of Discrete Topology]] :[[Open Extension Topology is not Perfectly T4]] {{qed}}	0
Let $T = \struct {S, \tau_p}$ be a [[Definition:Particular Point Topology|particular point space]] such that $S$ is not a [[Definition:Singleton|singleton]]. Then $T$ is not a [[Definition:T3 Space|$T_3$ space]].	0
By definition of [[Definition:Neighborhood of Point|neighborhood]], there exists an [[Definition:Open Set (Topology)|open set]] $V$ with $x\in V\subset U$. Then $X \setminus V$ is [[Definition:Closed Set (Topology)|closed]]. By [[Compact Hausdorff Space is T4]], there exist [[Definition:Disjoint Sets|disjoint]] [[Definition:Open Set (Topology)|open sets]] $A,B$ such that: :$X\setminus V\subset A$ :$x\in B$ Then: :$X \setminus A$ is [[Definition:Compact Subspace|compact]] by [[Closed Subspace of Compact Space is Compact]] :$B \subset X \setminus A$ by [[Empty Intersection iff Subset of Relative Complement]] :$X \setminus A \subset X \setminus \paren{X \setminus V}$ by [[Relative Complement inverts Subsets]] :$X \setminus \paren{X \setminus V} = V$ by [[Relative Complement of Relative Complement]] Thus $x\in B \subset X\setminus A \subset V$, so $X\setminus A$ is a [[Definition:Compact Subspace|compact]] [[Definition:Neighborhood of Point|neighborhood]] of $x$ contained in $V$. {{qed}}	0
:$\displaystyle \int_0^{2 \pi} \frac {\d x} {\paren {a + b \sin x}^2} = \frac {2 \pi a} {\paren {a^2 - b^2}^{3/2} }$	0
Let $x$ be an element of one of the [[Definition:Standard Number Field|standard number fields]]: $\Q, \R, \C$ such that $x \ne 1$. Let $n \in \N_{>0}$. Then: :$\displaystyle \sum_{j \mathop = 0}^{n - 1} x^j = \frac {x^n - 1} {x - 1}$	0
{{begin-eqn}} {{eqn | l = \int \frac {\d x} {x^3 \paren {x^2 - a^2}^2} | r = \int \paren {\frac 1 {a^4 x^3} + \frac 2 {a^6 x} - \frac {2 x} {a^6 \paren {x^2 - a^2} } + \frac x {a^4 \paren {x^2 - a^2}^2} } \rd x | c = [[Primitive of Reciprocal of x cubed by x squared minus a squared squared/Partial Fraction Expansion|Partial Fraction Expansion]] }} {{eqn | r = \frac 1 {a^4} \int \frac {\d x} {x^3} + \frac 2 {a^6} \int \frac {\d x} x - \frac 2 {a^6} \int \frac {x \rd x} {x^2 - a^2} + \frac 1 {a^4} \int \frac {x \rd x} {\paren {x^2 - a^2}^2} | c = [[Linear Combination of Integrals]] }} {{eqn | r = \frac 1 {a^4} \frac {-1} {2 x^2} + \frac 2 {a^6} \int \frac {\d x} x - \frac 2 {a^6} \int \frac {x \rd x} {x^2 - a^2} + \frac 1 {a^4} \int \frac {x \rd x} {\paren {x^2 - a^2}^2} + C | c = [[Primitive of Power]] }} {{eqn | r = \frac {-1} {2 a^4 x^2} + \frac 2 {a^6} \ln \size x - \frac 2 {a^6} \int \frac {x \rd x} {x^2 - a^2} + \frac 1 {a^4} \int \frac {x \rd x} {\paren {x^2 - a^2}^2} + C | c = [[Primitive of Reciprocal]] }} {{eqn | r = \frac {-1} {2 a^4 x^2} + \frac 2 {a^6} \ln \size x - \frac 2 {a^6} \frac 1 2 \map \ln {x^2 - a^2} + \frac 1 {a^4} \int \frac {x \rd x} {\paren {x^2 - a^2}^2} + C | c = [[Primitive of x over x squared minus a squared|Primitive of $\dfrac x {x^2 - a^2}$]] }} {{eqn | r = \frac {-1} {2 a^4 x^2} + \frac 2 {a^6} \ln \size x - \frac 1 {a^6} \map \ln {x^2 - a^2} + \frac 1 {a^4} \frac {-1} {2 \paren {x^2 - a^2} } + C | c = [[Primitive of x over x squared minus a squared squared|Primitive of $\dfrac x {\paren {x^2 - a^2}^2}$]] }} {{eqn | r = \frac {-1} {2 a^4 x^2} + \frac 1 {a^6} \map \ln {x^2} - \frac 1 {a^6} \map \ln {x^2 - a^2} + \frac 1 {a^4} \frac {-1} {2 \paren {x^2 - a^2} } + C | c = [[Logarithm of Power]] and $x^2 > 0$ }} {{eqn | r = \frac {-1} {2 a^4 x^2} - \frac 1 {2 a^4 \paren {x^2 - a^2} } + \frac 1 {a^6} \map \ln {\frac {x^2} {x^2 - a^2} } + C | c = [[Difference of Logarithms]] }} {{end-eqn}} {{qed}}	0
Let $H$ be a [[Definition:Hilbert Space|Hilbert space]]. Let $A$ be a [[Definition:Projection (Hilbert Spaces)|projection]]. Then the [[Definition:Complementary Projection|complementary projection]] $I - A$ is also a [[Definition:Projection (Hilbert Spaces)|projection]].	0
From [[Derivative of Sine Function]]: :$\dfrac \d {\d x} \sin x = \cos x$ From [[Derivative of Cosine Function]]: :$\dfrac \d {\d x} \cos x = -\sin x$ Hence: {{begin-eqn}} {{eqn | l = \dfrac {\d^2} {\d x^2} \sin x | r = -\sin x | c = }} {{eqn | l = \dfrac {\d^3} {\d x^3} \sin x | r = -\cos x | c = }} {{eqn | l = \dfrac {\d^4} {\d x^4} \sin x | r = \sin x | c = }} {{end-eqn}} and so for all $m \in \N$: {{begin-eqn}} {{eqn | ll= m = 4 k: | l = \dfrac {\d^m} {\d x^m} \sin x | r = \sin x | c = }} {{eqn | ll= m = 4 k + 1: | l = \dfrac {\d^m} {\d x^m} \sin x | r = \cos x | c = }} {{eqn | ll= m = 4 k + 2: | l = \dfrac {\d^m} {\d x^m} \sin x | r = -\sin x | c = }} {{eqn | ll= m = 4 k + 3: | l = \dfrac {\d^m} {\d x^m} \sin x | r = -\cos x | c = }} {{end-eqn}} where $k \in \Z$. This leads to the [[Definition:Maclaurin Series|Maclaurin series expansion]]: {{begin-eqn}} {{eqn | l = \sin x | r = \sum_{r \mathop = 0}^\infty \paren {\frac {x^{4 k} } {\paren {4 k}!} \map \sin 0 + \frac {x^{4 k + 1} } {\paren {4 k + 1}!} \map \cos 0 - \frac {x^{4 k + 2} } {\paren {4 k + 2}!} \map \sin 0 - \frac {x^{4 k + 3} } {\paren {4 k + 3}!} \map \cos 0} | c = }} {{eqn | r = \sum_{r \mathop = 0}^\infty \paren {\frac {x^{4 k + 1} } {\paren {4 k + 1}!} - \frac {x^{4 k + 3} } {\paren {4 k + 3}!} } | c = [[Sine of Zero is Zero]], [[Cosine of Zero is One]] }} {{eqn | r = \sum_{n \mathop = 0}^\infty \paren {-1}^n \frac {x^{2 n + 1} } {\paren {2 n + 1}!} | c = setting $n = 2 k$ }} {{end-eqn}} From [[Series of Power over Factorial Converges]], it follows that this series is [[Definition:Convergent Series|convergent]] for all $x$. {{qed}}	0
Let $\struct {G \times H, \circ}$ be the [[Definition:Group Direct Product|group direct product]] of the two [[Definition:Group|groups]] $\struct {G, \circ_1}$ and $\struct {H, \circ_2}$. Let $g^{-1}$ be an [[Definition:Inverse Element|inverse]] of $g \in \struct {G, \circ_1}$. Let $h^{-1}$ be an [[Definition:Inverse Element|inverse]] of $h \in \struct {H, \circ_2}$. Then $\tuple {g^{-1}, h^{-1} }$ is the [[Definition:Inverse Element|inverse]] of $\tuple {g, h} \in \struct {G \times H, \circ}$.	0
From the definition as a [[Definition:Cantor Set/Ternary Representation|ternary representation]], $\CC$ consists of all the elements of $\closedint 0 1$ which can be written without using a $1$. So let $x \in \CC$. Then in [[Definition:Ternary Notation|base $3$ notation]], we have (as $0 \le x \le 1$): :$\displaystyle x = \sum_{i \mathop = 1}^\infty r_j 3^{-j}$ From the definition of the [[Definition:Cantor Set/Ternary Representation|Cantor set]], we have $\forall j: r_j \in \set {0, 2}$. Furthermore, from [[Representation of Ternary Expansions]], the $r_j$ are unique. Now define the following function: :$\displaystyle f: \CC \to \closedint 0 1,\quad \map f {\sum_{i \mathop = 1}^\infty r_j 3^{-j} } = \sum_{i \mathop = 1}^\infty \frac {r_j} 2 2^{-j}$ Observe that $\forall j: \dfrac {r_j} 2 \in \set {0, 1}$. That the {{RHS}} expression is in fact an [[Definition:Element|element]] of $\closedint 0 1$ now follows from [[Definition:Binary Notation|binary notation]]. Furthermore by [[Existence of Base-N Representation]], any element $y$ of $\closedint 0 1$ may be written in the following form (where $\forall j: b_j \in \set {0, 1}$): :$\displaystyle y = \sum_{i \mathop = 1}^\infty b_j 2^{-j}$ Obviously, $y = \map f x$, where $x \in \CC$ is defined as follows: :$\displaystyle x = \sum_{i \mathop = 1}^\infty 2 b_j 3^{-j}$ It follows that $f$ is [[Definition:Surjective|surjective]]. From [[Closed Interval in Reals is Uncountable]], the [[Definition:Closed Real Interval|closed interval]] $\closedint 0 1$ is [[Definition:Uncountable Set|uncountable]]. The result follows. {{explain|it is obvious, but most likely there is some result that could be referred to}} {{qed}}	0
By [[Ordering on 1-Based Natural Numbers is Trichotomy|Ordering on $1$-Based Natural Numbers is Trichotomy]], one and only one of the following holds: :$a = b$ :$a < b$ :$b < a$ Suppose $a < b$. Then by [[Ordering on 1-Based Natural Numbers is Compatible with Addition|Ordering on $1$-Based Natural Numbers is Compatible with Addition]]: :$a + c < b + c$ By [[Ordering on 1-Based Natural Numbers is Trichotomy|Ordering on $1$-Based Natural Numbers is Trichotomy]], this contradicts the fact that $a + c = b + c$. Similarly, suppose $b > a$. Then by [[Ordering on 1-Based Natural Numbers is Compatible with Addition|Ordering on $1$-Based Natural Numbers is Compatible with Addition]]: :$b + c < a + c$ By [[Ordering on 1-Based Natural Numbers is Trichotomy|Ordering on $1$-Based Natural Numbers is Trichotomy]], this also contradicts the fact that $a + c = b + c$. The only other possibility is that $a = b$. So :$\forall a, b, c \in \N_{>0}: a + c = b + c \implies a = b$ and so $+$ is [[Definition:Right Cancellable Operation|right cancellable]] on $\N_{>0}$. From [[Natural Number Addition is Commutative]] and [[Right Cancellable Commutative Operation is Left Cancellable]]: :$\forall a, b, c \in \N_{>0}: a + b = a + c \implies b = c$ So $+$ is both [[Definition:Right Cancellable Operation|right cancellable]] and [[Definition:Left Cancellable Operation|left cancellable]] on $\N_{>0}$. Hence the result. {{qed}}	0
Let $I_{\Z_{>0}}: \Z_{>0} \to \Z_{>0}$ be the [[Definition:Identity Mapping|identity function]]: :$\forall n \in \Z_{>0}: \map {I_{\Z_{>0} } } n = n$ Thus we have: :$\displaystyle \map \sigma n = \sum_{d \mathop \divides n} d = \sum_{d \mathop \divides n} \map {I_{\Z_{>0} } } d$ But from [[Identity Function is Completely Multiplicative]], $I_{\Z_{>0} }$ is [[Definition:Multiplicative Arithmetic Function|multiplicative]]. The result follows from [[Sum Over Divisors of Multiplicative Function]]. {{qed}}	0
Let $f$ be such that: :$\forall B \subseteq T: B = \paren {f \circ f^{-1} } \sqbrk B$ In particular, it holds for $T$ itself. Hence: {{begin-eqn}} {{eqn | l = T | r = \paren {f \circ f^{-1} } \sqbrk T | c = }} {{eqn | l = T | r = f \sqbrk {f^{-1} \sqbrk T} | c = {{Defof|Composition of Mappings}} }} {{eqn | o = \subseteq | r = f \sqbrk S | c = [[Image of Subset under Relation is Subset of Image/Corollary 2|Image of Subset under Relation is Subset of Image: Corollary 2]] }} {{eqn | r = \Img f | c = {{Defof|Image of Mapping}} }} {{eqn | o = \subseteq | r = T | c = [[Image is Subset of Codomain/Corollary 1|Image is Subset of Codomain: Corollary 1]] }} {{end-eqn}} So: :$T \subseteq \Img f \subseteq T$ and so by definition of [[Definition:Set Equality/Definition 2|set equality]]: :$\Img f = T$ So, by definition, $f$ is a [[Definition:Surjection|surjection]]. {{qed}}	0
{{begin-eqn}} {{eqn | l = x \in y | o = \implies | r = x^+ \in y^+ | c = [[Subset is Compatible with Ordinal Successor]] }} {{eqn | l = x \in y | o = \impliedby | r = x^+ \in y^+ | c = [[Successor is Less than Successor/Sufficient Condition|Sufficient Condition]] }} {{eqn | ll = \implies | l = x \in y | o = \iff | r = x^+ \in y^+ | c = }} {{end-eqn}} {{qed}} [[Category:Ordinals]] 3ybapwazqv3gj3077nq7eh4lzn0vjqb	0
Let $M = \left({A, d}\right)$ be a [[Definition:Standard Discrete Metric|standard discrete metric space]]. Let $S \subseteq A$ be a [[Definition:Subset|subset]] of $A$. Then $S$ is an [[Definition:Open Set (Metric Space)|open set]] of $M$.	0
{{begin-eqn}} {{eqn|l = x = y |o = \implies |r = x^+ = y^+ |c = [[Substitutivity of Equality]] }} {{end-eqn}} Conversely, {{begin-eqn}} {{eqn|l = x^+ = y^+ |o = \implies |r = \bigcup x^+ = \bigcup y^+ |c = [[Substitutivity of Equality]] }} {{eqn|o = \implies |r = x = y |c = [[Union of Successor Ordinal]] }} {{end-eqn}} {{qed}}	0
By [[Meet Precedes Operands]]: :$\paren {\sup D} \wedge x \preceq \sup D$ By assumption: :$\paren {\sup D} \wedge x \preceq \sup \set {\paren {\sup D} \wedge x \wedge d: d \in D}$ By definition of [[Definition:Supremum of Set|supremum]]: :$\forall d \in D: d \preceq \sup D$ By [[Preceding iff Meet equals Less Operand]]: :$\forall d \in D: d \wedge \sup D = d$ By [[Meet is Associative]] and [[Meet is Commutative]]: :$\paren {\sup D} \wedge x \preceq \sup \set {d \wedge x: d \in D}$ By [[Meet Semilattice is Ordered Structure]]: :$\forall d \in D: d \wedge x \preceq \paren {\sup D} \wedge x$ By definition: :$\paren {\sup D} \wedge x$ is [[Definition:Upper Bound of Set|upper bound]] for $\set {d \wedge x: d \in D}$ By definition of [[Definition:Supremum of Set|supremum]]: :$\sup \set {d \wedge x: d \in D} \preceq \paren {\sup D} \wedge x$ if $\set {d \wedge x: d \in D}$ admits a [[Definition:Supremum of Set|supremum]] We will prove that: :$\set {d \wedge x: d \in D}$ is [[Definition:Directed Subset|directed]] Let $y, z \in \set {d \wedge x: d \in D}$. Then :$\exists d_1 \in D: y = d_1 \wedge x$ and :$\exists d_2 \in D: z = d_2 \wedge x$ By definition of [[Definition:Directed Subset|directed subset]]: :$\exists d \in D: d_1 \preceq d \land d_2 \preceq d$ By [[Meet Semilattice is Ordered Structure]]: :$y \preceq d \wedge x$ and $z \preceq d \wedge x$ Thus :$d \wedge x \in \set {d \wedge x: d \in D}$ Hence by definition: :$\set {d \wedge x: d \in D}$ is [[Definition:Directed Subset|directed]]. {{qed|lemma}} By definition of [[Definition:Up-Complete|up-complete]]: :$\set {d \wedge x: d \in D}$ admits a [[Definition:Supremum of Set|supremum]] Thus by definition of [[Definition:Antisymmetric Relation|antisymmetry]]: :$\paren {\sup D} \wedge x = \sup \set {d \wedge x: d \in D}$ {{qed}}	0
Let $S$ and $T$ be [[Definition:Set|sets]]. Let $f: S \to T$ be a [[Definition:Mapping|mapping]]. The [[Definition:Image of Subset under Mapping|image of $S$]] is the [[Definition:Image of Mapping|image set of $f$]]: :$f \sqbrk S = \Img f$	0
Let $G$ be a [[Definition:Group|group]] of [[Definition:Order of Group|order]] $105$. Then $G$ has a [[Definition:Normal Subgroup|normal]] [[Definition:Cyclic Group|cyclic]] [[Definition:Subgroup|subgroup]] $N$ such that: :$\index G N = 3$ where $\index G N$ denotes the [[Definition:Index of Subgroup|index]] of $N$ in $G$.	0
Let $G$ and $H$ be [[Definition:Unitary Module|unitary $R$-modules]]. Let $\phi: G \to H$ be a non-zero [[Definition:Linear Transformation|linear transformation]]. Let $G$ be [[Definition:Dimension of Module|$n$-dimensional]]. Let $\left \langle {a_n} \right \rangle$ be any [[Definition:Ordered Basis|ordered basis]] of $G$ such that $\left\{{a_k: r + 1 \le k \le n}\right\}$ is the [[Definition:Basis (Linear Algebra)|basis]] of the [[Definition:Kernel of Linear Transformation|kernel]] of $\phi$. Then $\left \langle {\phi \left({a_r}\right)} \right \rangle$ is an [[Definition:Ordered Basis|ordered basis]] of the [[Definition:Image of Mapping|image]] of $\phi$.	0
Consider the [[Definition:Symmetric Group on n Letters|symmetric group on $n$ letters]] $S_n$. From [[Symmetric Group on n Letters is Isomorphic to Symmetric Group]] we have that: :$\struct {\map \Gamma {T_1}, \circ}$ is [[Definition:Group Isomorphism|isomorphic]] to $S_n$ :$\struct {\map \Gamma {T_2}, \circ}$ is [[Definition:Group Isomorphism|isomorphic]] to $S_n$ and hence from [[Isomorphism is Equivalence Relation]]: :$\struct {\map \Gamma {T_1}, \circ}$ is [[Definition:Group Isomorphism|isomorphic]] to $\struct {\map \Gamma {T_2}, \circ}$. {{qed}}	0
Let $\struct {G, \circ}$ be a [[Definition:Group|group]]. Let $\RR, \QQ$ be [[Definition:Endorelation|relations]] on $G$ which are [[Definition:Relation Compatible with Operation|compatible]] with $\circ$. Then the [[Definition:Set Difference|difference]] $\RR \setminus \QQ$ is [[Definition:Relation Compatible with Operation|compatible]] with $\circ$.	0
The following definition of the concept of the [[Definition:Real Exponential Function|real exponential function]]:	0
:$\tan 315^\circ = \tan \dfrac {7 \pi} 4 = -1$	0
Let $t \in T$, and suppose that $t' \in t^{\succ T}$. By definition of [[Definition:Strict Upper Closure of Element|strict upper closure]], this is equivalent to: :$t \preceq \restriction_T t' \land t \ne t'$ By [[Definition:Restricted Ordering|definition of $\preceq \restriction_T$]], the first condition comes down to: :$t \preceq t' \land t' \in T$ as it is assumed that $t \in T$. In conclusion, $t' \in t^{\succ T}$ is equivalent to: :$t' \in T \land t \preceq t' \land t \ne t'$ These last two conjuncts precisely express that $t' \in t^{\succ S}$. By definition of [[Definition:Set Intersection|set intersection]], it also holds that: :$t' \in T \cap t^{\succ S}$ precisely when $t' \in T$ and $t' \in t^{\succ S}$. Thus, it follows that the following are equivalent: :$t' \in t^{\succ T}$ :$t' \in T \cap t^{\succ S}$ and hence the result follows, by definition of [[Definition:Set Equality|set equality]]. {{qed}} [[Category:Upper Closures]] 97c1pqbo4j3pty83ysgosc5ligkdtqx	0
{{begin-eqn}} {{eqn | l = \dbinom n k | r = \dbinom {n - 1} k + \dbinom {n - 1} {k - 1} | c = [[Pascal's Rule]] }} {{eqn | r = \paren {\dbinom {n - 2} {k - 1} + \dbinom {n - 2} k} + \paren {\dbinom {n - 2} {k - 2} + \dbinom {n - 2} {k - 1} } | c = [[Pascal's Rule]] (twice) }} {{eqn | r = \dbinom {n - 2} {k - 2} + 2 \dbinom {n - 2} {k - 1} + \dbinom {n - 2} k | c = simplifying }} {{end-eqn}} In the expression $\dbinom {n - 2} {k - 2} + 2 \dbinom {n - 2} {k - 1} + \dbinom {n - 2} k$ we note that: :if $k < 2$ then $\dbinom {n - 2} {k - 2}$ has a [[Definition:Negative Integer|negative]] coefficient on the bottom :if $k > n - 2$ then $\dbinom {n - 2} k$ has a coefficient on the bottom that is greater than $n$. Hence the usual comfortable range of $k$ is exceeded and so it cannot be guaranteed that the conditions are satisfied for the equation to be true. If $n \le 3$ then $2 \le k \le n - 2$ cannot be fulfilled. Hence the bounds on both $k$ and $n$. {{qed}}	0
Let $X$ be a [[Definition:Set|set]], and let $\mathcal D$ be a [[Definition:Dynkin System|Dynkin system]] on $X$. Let $D, E \in \mathcal D$ and suppose that $E \subseteq D$. Then the [[Definition:Set Difference|set difference]] $D \setminus E$ is also an element of $\mathcal D$.	0
We have that: :$720 = 2^4 \times 3^2 \times 5$ It remains to inspect the [[Definition:Divisor of Integer|divisibility]] of $2$, $3$ and $5$ in $720!$ Thus: === [[De Polignac's Formula/Examples/2 in 720 Factorial|Multiplicity of $2$ in $720!$]] === {{:De Polignac's Formula/Examples/2 in 720 Factorial}} === [[De Polignac's Formula/Examples/3 in 720 Factorial|Multiplicity of $3$ in $720!$]] === {{:De Polignac's Formula/Examples/3 in 720 Factorial}} === [[De Polignac's Formula/Examples/5 in 720 Factorial|Multiplicity of $5$ in $720!$]] === {{:De Polignac's Formula/Examples/5 in 720 Factorial}} We calculate the [[Definition:Multiplicity of Prime Factor|multiplicity]] of the [[Definition:Integer Power|powers]] of $2$ and $3$ in $720!$ thus: {{begin-eqn}} {{eqn | l = 716 | r = 4 \times 179 | c = }} {{eqn | ll= \leadsto | l = \paren {2^4}^{179} | o = \divides | r = 720! | c = }} {{end-eqn}} {{begin-eqn}} {{eqn | l = 356 | r = 2 \times 178 | c = }} {{eqn | ll= \leadsto | l = \paren {3^2}^{178} | o = \divides | r = 720! | c = }} {{end-eqn}} Thus it is seen that the smallest [[Definition:Integer Power|power]] of the [[Definition:Prime Power|prime powers]] that are [[Definition:Divisor of Integer|divisors]] of $720$ that [[Definition:Divisor of Integer|divide]] $720!$ is that of $3^2$, which is $178$. Hence: :$720^{178} \divides 720!$ but: :$720^{179} \nmid 720!$ {{qed}}	0
Let $y \in \map { {B_r}^-} x$. Let $a \in \map { {B_r}^-} y$. By the definition of an [[Definition:Closed Ball of Normed Division Ring|closed ball]], then: :$\norm {a - y} \le r$ :$\norm {y - x} \le r$ Hence: {{begin-eqn}} {{eqn | l = \norm {a - x} | r = \norm {a - y + y - x} }} {{eqn | r = \max \set {\norm {a - y}, \norm {y - x} } | o = \le | c = {{Defof|Non-Archimedean Division Ring Norm}} }} {{eqn | r = r | o = \le | c = }} {{end-eqn}} By the definition of a [[Definition:Closed Ball of Normed Division Ring|closed ball]], then: :$a \in \map { {B_r}^-} x$. Hence: :$\map { {B_r}^-} y \subseteq \map { {B_r}^-} x$ By [[Properties of Norm on Division Ring/Norm of Negative|Norm of Negative]] then: :$\norm {x - y} \le r$ By the definition of a [[Definition:Closed Ball of Normed Division Ring|closed ball]], then: :$x \in \map { {B_r}^-} y$ Similarly it follows that: :$\map { {B_r}^-} x \subseteq \map { {B_r}^-} y$ By [[Definition:Set Equality/Definition 2|set equality]]: :$\map { {B_r}^-} x = \map { {B_r}^-} y$ {{qed}}	0
Let $\struct {S, \tau}$ be a [[Definition:Topological Space|topological space]]. Let $f: S \to S$ be a [[Definition:Continuous Mapping (Topology)|continuous]] [[Definition:Involution (Mapping)|involution]]. Then $f$ is a [[Definition:Homeomorphism|homeomorphism]].	0
:$\sin 18 \degrees = \sin \dfrac \pi {10} = \dfrac {\sqrt 5 - 1} 4$ where $\sin$ denotes the [[Definition:Sine Function|sine function]].	0
Let $\struct {R, \norm {\,\cdot\,}_R}$ and $\struct {S, \norm {\,\cdot\,}_S}$ be [[Definition:Normed Division Ring|normed division rings]]. Let $\phi: R \to S$ be a [[Definition:Ring Isomorphism|ring isomorphism]]. Then $\phi: R \to S$ is an [[Definition:Isometric Isomorphism|isometric isomorphism]] {{iff}} $\phi$ satisfies: :$\forall x \in R: \norm {\map \phi x}_S = \norm x_R $	0
From [[Existence of Cyclic Group of Order n]] we have that one such [[Definition:Group|group]] of [[Definition:Order of Group|order]] $4$ is the [[Definition:Cyclic Group|cyclic group]] of [[Definition:Order of Group|order]] $4$: This is exemplified by the [[Definition:Additive Group of Integers Modulo m|additive group of integers modulo $4$]], whose [[Modulo Addition/Cayley Table/Modulo 4|Cayley table]] can be presented as: {{:Modulo Addition/Cayley Table/Modulo 4}} From [[Group whose Order equals Order of Element is Cyclic]], any [[Definition:Group|group]] with an [[Definition:Element|element]] of [[Definition:Order of Group Element|order]] $4$ is [[Definition:Cyclic Group|cyclic]]. From [[Cyclic Groups of Same Order are Isomorphic]], no other [[Definition:Group|groups]] of [[Definition:Order of Group|order]] $4$ which are not [[Definition:Isomorphic Groups|isomorphic]] to $C_4$ can have an [[Definition:Element|element]] of [[Definition:Order of Group Element|order]] $4$. {{qed|lemma}} From [[Order of Element Divides Order of Finite Group]], any other [[Definition:Group|group]] of [[Definition:Order of Group|order]] $4$ must have [[Definition:Element|elements]] of [[Definition:Order of Group|order]] $2$. We have the [[Definition:Klein Four-Group|Klein $4$-group]], whose [[Klein Four-Group/Cayley Table|Cayley table]] can be presented as: {{:Klein Four-Group/Cayley Table}} and is seen to have that property. {{qed|lemma}} We have that [[Klein Four-Group and Group of Cyclic Group of Order 4 are not Isomorphic]]. {{qed|lemma}} It remains to be shown that the [[Definition:Klein Four-Group|Klein $4$-group]] is the only [[Definition:Group|groups]] of [[Definition:Order of Group|order]] $4$ whose [[Definition:Element|elements]] are all of [[Definition:Order of Group|order]] $2$ (except the [[Definition:Identity Element|identity]]). Let the [[Definition:Cayley Table|Cayley table]] be populated as far as can be directly established: :$\begin{array}{c|cccc} & e & a & b & c \\ \hline e & e & a & b & c \\ a & a & e & & \\ b & b & & e & \\ c & c & & & e \\ \end{array}$ Consider $a b$. As $a^2 = e$, $a b \ne e$. As $a e = a$, $a b \ne a$. As $e b = b$, $a b \ne b$. It follows that $a b = c$. Hence we have: :$\begin{array}{c|cccc} & e & a & b & c \\ \hline e & e & a & b & c \\ a & a & e & c & \\ b & b & & e & \\ c & c & & & e \\ \end{array}$ and the rest of the table is completed by following the result that [[Group has Latin Square Property]]. {{qed}}	0
;[[Proof by Counterexample]]: Let $f_1: S_1 \to S_2$ and $f_2: S_2 \to S_3$ be [[Definition:Mapping|mappings]]. First note that unless $S_1 = S_3$ then $f_2 \circ f_1$ is not even defined. So in that case $f_2 \circ f_1$ is definitely not the same thing as $f_1 \circ f_2$. So, let us suppose $S_1 = S_3$ and so we define $f_1: S_1 \to S_2$ and $f_2: S_2 \to S_1$. If $S_1 \ne S_2$ then: :$f_2 \circ f_1: S_1 \to S_1$ :$f_1 \circ f_2: S_2 \to S_2$ and so by [[Equality of Mappings]] they are unequal because their [[Definition:Domain of Mapping|domains]] and [[Definition:Codomain of Mapping|codomains]] are different. Finally, suppose $S_1 = S_2$, and consider the following. :$S_1 = S_2 = \set {a, b}$ :$f_1 = \set {\tuple {a, a}, \tuple {b, a} }$ :$f_2 = \set {\tuple {a, b}, \tuple {b, b} }$ It is straightforward to check that $f_1$ and $f_2$ are [[Definition:Mapping|mappings]], and that: :$f_1 \circ f_2 = \set {\tuple {a, b}, \tuple {b, b} }$ :$f_2 \circ f_1 = \set {\tuple {a, a}, \tuple {b, a} }$ Thus, even in this limitingly simple case, we see that: :$f_2 \circ f_1 \ne f_1 \circ f_2$ {{qed}}	0
{{NotZFC}} Let: :$T = \bigcap \left\{ x \in \operatorname{On} : \forall y \in S: \operatorname{rank} \left({ y }\right) < x \right\}$ Let $y \in S$. Then by [[Membership Rank Inequality]]: :$\operatorname{rank} \left({ x }\right) < \operatorname{rank} \left({ S }\right)$ {{explain|$x$ or $y$?}} Therefore: :$T \subseteq \operatorname{rank} \left({ S }\right)$ Conversely, take any $x \in T$. By the definition of $T$: :$\forall y \in S: \operatorname{rank} \left({ y }\right) < x$ From [[Ordinal is Subset of Rank of Small Class iff Not in Von Neumann Hierarchy]]: : $\forall y \in S: y \in V \left({ x }\right)$ where $V \left({x}\right)$ denotes the [[Definition:Von Neumann Hierarchy|von Neumann hierarchy]]. Therefore by the definition of [[Definition:Subset|subset]]: :$S \subseteq V \left({x}\right)$ By the definition of [[Definition:Rank (Set Theory)|rank]]. :$\operatorname{rank} \left({ S }\right) \le x$ Therefore: : $\operatorname{rank} \left({ S }\right) = T$ {{qed}}	0
The following [[Definition:Positive Integer|positive integers]] $p$ have [[Definition:Reciprocal|reciprocals]] whose [[Definition:Decimal Expansion|decimal expansions]]: :$(1): \quad$ have the maximum [[Definition:Period of Recurrence|period]], that is: $p - 1$ :$(2): \quad$ have an equal number, $\dfrac {p - 1} {10}$, of each of the [[Definition:Digit|digits]] from $0$ to $9$: ::$61, 131,\ldots$	0
Let $S \ne \O$ be a [[Definition:Non-Empty Set|non-empty set]]. Consider a [[Definition:Pseudometric Space|pseudometric space]] $\struct {S, d}$ where $d: S \times S \to \R_{\ge 0}$ is a [[Definition:Pseudometric|pseudometric]]. Then $\struct {S, d}$ gives rise to a [[Definition:Topological Space|topological space]] $\struct {S, \tau_d}$ whose [[Definition:Topology|topology]] $\tau_d$ is '''defined''' (or '''induced''') by $d$.	0
First let $x \ne 1$. Then: {{begin-eqn}} {{eqn | l = \int_1^\infty \dfrac {\d t} {t^x} | r = \lim_{P \mathop \to \infty} \int_1^P t^{-x} \rd t | c = {{Defof|Improper Integral}} }} {{eqn | r = \lim_{P \mathop \to \infty} \intlimits {\dfrac {t^{-x + 1} } {-x + 1} } 1 P | c = [[Primitive of Power]] }} {{eqn | r = \lim_{P \mathop \to \infty} \paren {\dfrac {P^{1 - x} } {1 - x} - \dfrac {1^{1 - x} } {1 - x} } | c = }} {{eqn | r = \lim_{P \mathop \to \infty} \dfrac 1 {x - 1} \paren {1 - \dfrac 1 {P^{x - 1} } } | c = simplifying }} {{end-eqn}} If $x > 1$, then $x - 1 > 0$. Hence from [[Sequence of Powers of Reciprocals is Null Sequence]], $\dfrac 1 {P^{x - 1} } \to 0$ as $P \to +\infty$. If $x < 1$, then $x - 1 < 0$. Hence $P^{x - 1} \to 0$ as $P \to +\infty$. Then from [[Reciprocal of Null Sequence]] it follows that $\dfrac 1 {P^{x - 1} } \to \infty$ as $P \to +\infty$. Finally we have that from [[Integral of Reciprocal is Divergent]]: :$\displaystyle \lim_{P \mathop \to \infty} \int_1^P \dfrac {\d t} t \to \infty$ All cases are covered, and the result follows. {{qed}}	0
{{begin-eqn}} {{eqn | l = \int_0^{\pi/2} \sin x \map \ln {\sin x} \rd x | r = \intlimits {\cos x \paren {1 - \map \ln {\sin x} } + \map \ln {\tan \frac x 2} } 0 {\pi/2} | c = [[Primitive of Sine x by Logarithm of Sine x|Primitive of $\sin x \map \ln {\sin x}$]] }} {{eqn | r = \cos \frac \pi 2 \paren {1 - \map \ln {\sin \frac \pi 2} } + \map \ln {\tan \frac \pi 4} - \cos 0 + \lim_{x \mathop \to 0^+} \paren {\map \ln {\sin x} - \map \ln {\tan \frac x 2} } }} {{eqn | r = -1 + \lim_{x \mathop \to 0^+} \paren {\map \ln {\sin x} - \map \ln {\tan \frac x 2} } | c = [[Cosine of Right Angle]], [[Tangent of 45 Degrees]], [[Natural Logarithm of 1 is 0]], [[Cosine of Zero is One]] }} {{end-eqn}} It remains to compute: :$\displaystyle \lim_{x \mathop \to 0^+} \paren {\map \ln {\sin x} - \map \ln {\tan \frac x 2} }$ We have: {{begin-eqn}} {{eqn | l = \lim_{x \mathop \to 0^+} \paren {\map \ln {\sin x} - \map \ln {\tan \frac x 2} } | r = \lim_{x \mathop \to 0^+} \paren {\map \ln {2 \sin \frac x 2 \cos \frac x 2} - \map \ln {\sin \frac x 2} + \map \ln {\cos \frac x 2} } | c = [[Double Angle Formula for Sine]], {{Defof|Real Tangent Function}}, [[Difference of Logarithms]] }} {{eqn | r = \lim_{x \mathop \to 0^+} \paren {\ln 2 + \map \ln {\sin \frac x 2} + \map \ln {\cos \frac x 2} - \map \ln {\sin \frac x 2} + \map \ln {\cos \frac x 2} } | c = [[Sum of Logarithms]] }} {{eqn | r = \ln 2 + 2 \lim_{x \mathop \to 0^+} \map \ln {\cos \frac x 2} | c = [[Combination Theorem for Limits of Functions/Sum Rule|Combination Theorem for Limits of Functions: Sum Rule]] }} {{eqn | r = \ln 2 + 2 \map \ln {\lim_{x \mathop \to 0^+} \cos \frac x 2} }} {{eqn | r = \ln 2 + 2 \ln 1 | c = [[Cosine of Zero is One]] }} {{eqn | r = \ln 2 | c = [[Natural Logarithm of 1 is 0]] }} {{end-eqn}} giving: :$\displaystyle \int_0^{\pi/2} \sin x \map \ln {\sin x} \rd x = \ln 2 - 1$ {{qed}}	0
A direct application of [[Set of Invertible Mappings forms Symmetric Group]]. {{qed}}	0
Let $\Z$ be the [[Definition:Integer|set of integers]]. Let $\le$ be the [[Definition:Ordering on Integers|ordering on the integers]]. Let $\O \subset S \subseteq \Z$ such that $S$ is [[Definition:Bounded Below Set|bounded below]] in $\struct {\Z, \le}$. Then $S$ has a [[Definition:Smallest Element|smallest element]].	0
Let $A$ be a [[Definition:Class (Class Theory)|class]]. Let $\mathcal R$ be a [[Definition:Relation|relation]] that is [[Definition:Foundational Relation|foundational]] on $A$. Let every [[Definition:Initial Segment|$\mathcal R$-initial segment]] of any element $x$ of $A$ be a [[Definition:Small Class|small class]]. Let $K$ be a [[Definition:Class (Class Theory)|class]] of mappings $f$ that satisfy: :$(1): \quad$ The [[Definition:Domain (Set Theory)|domain]] of $f$ is some [[Definition:Subset|subset]] $y \subseteq A$ such that $y$ is [[Definition:Transitive with Respect to a Relation|transitive]] with respect to $\mathcal R$. :$(2): \quad \forall x \in y: f \left({x}\right) = G \left({F \restriction \mathcal R^{-1} x}\right)$ where $F \restriction R^{-1} x$ denotes the [[Definition:Restriction of Relation|restriction]] of $F$ to the [[Definition:Initial Segment|$\mathcal R$-initial segment]] of $x$. {{explain|What is $G$? And should $F$ not be introduced before it is used, instead of after?}} Let $F = \bigcup K$, the [[Definition:Set Union|union]] of $K$. Then: : $F$ is a [[Definition:Mapping|mapping]] with [[Definition:Domain (Set Theory)|domain]] $A$ : $\forall x \in A: F \left({x}\right) = G \left({F \restriction \mathcal R^{-1} x}\right)$ : $F$ is [[Definition:Unique|unique]], in the sense that if another mapping $A$ has the above two properties, then $A = F$.	0
Let $R$ be a [[Definition:Dedekind Domain|Dedekind domain]]. Let $f, g \in R \sqbrk X$ be [[Definition:Polynomial over Ring in One Variable|polynomials]]. Let $\cont f$ denote the [[Definition:Content of Polynomial|content]] of $f$. Then $\cont {f g} = \cont f \cont g$ is the [[Definition:Product of Ideals of Ring|product]] of $\cont f$ and $\cont g$.	0
We have that [[Integers under Addition form Abelian Group]]. The result then follows from combining: : [[Epimorphism from Integers to Cyclic Group]] : [[Epimorphism Preserves Commutativity]]. {{qed}}	0
{{begin-eqn}} {{eqn | l = z^{-m} G \left({z}\right) | r = z^{-m} \sum_{n \mathop \ge 0} a_n z^n | c = {{Defof|Generating Function}} }} {{eqn | r = \sum_{n \mathop \ge 0} a_n z^{n - m} | c = }} {{eqn | r = \sum_{n + m \mathop \ge 0} a_{n + m} z^n | c = [[Translation of Index Variable of Summation]] }} {{eqn | r = \sum_{n \mathop \ge 0} a_{n + m} z^n + \sum_{k \mathop = -m}^{-1} a_{k + m} z^k | c = splitting up and changing variable }} {{eqn | r = \sum_{n \mathop \ge 0} a_{n + m} z^n + \sum_{k \mathop = 0}^{m - 1} a_k z^{k - m} | c = [[Translation of Index Variable of Summation]] }} {{eqn | r = \sum_{n \mathop \ge 0} a_{n + m} z^n + z^{-m} \sum_{k \mathop = 0}^{m - 1} a_k z^k | c = }} {{end-eqn}} Hence the result. {{qed}}	0
From [[Test for Left Ideal]], the following need to be proved: :$(1): \quad G \ne \O$ :$(2): \quad \forall \mathop {\mathbf X}, \mathop {\mathbf Y} \in G: \mathbf X + \paren {-\mathbf Y} \in G$ :$(3): \quad \forall \mathop{\mathbf J} \in G, \mathop {\mathbf R} \in \map {\MM_S} 2: \mathbf R \times \mathbf J \in G$ === Condition $(1): \quad G \ne \O$ === By definition of $G$: :$\quad \begin{bmatrix} 0 & 0 \\ 0 & 0 \end{bmatrix} \in G$ {{qed|lemma}} === Condition $(2): \quad \forall \mathop {\mathbf X}, \mathop{\mathbf Y} \in G: \mathbf X + \paren {-\mathbf Y} \in G$ === Let: :$\quad \mathbf X = \begin{bmatrix} x_1 & 0 \\ x_2 & 0 \end{bmatrix}, \quad \mathbf Y = \begin{bmatrix} y_1 & 0 \\ y_2 & 0 \end{bmatrix} \in G$ Then: :$\quad \mathbf X - \mathbf Y = \begin{bmatrix} x_1 - y_1 & 0 \\ x_2 - y_2 & 0 \end{bmatrix} \in G$ {{qed|lemma}} === Condition $(3): \quad \forall \mathop{\mathbf J} \in G, \mathop{\mathbf R} \in \map {\MM_S} 2: \mathbf R \times \mathbf J \in G$ === Let: :$\quad \mathbf J = \begin{bmatrix} j_1 & 0 \\ j_2 & 0 \end{bmatrix} \in G, \quad \mathbf R = \begin{bmatrix} r_{1 1} & r_{2 1} \\ r_{1 2} & r_{2 2} \end{bmatrix} \in \map {\MM_S} 2$ Then: :$\quad \mathbf R \times \mathbf J = \begin{bmatrix} r_{1 1} \times j_1 + r_{2 1} \times j_2 & 0 \\ r_{1 2} \times j_1 + r_{2 2} \times j_2 & 0 \end{bmatrix} \in G$ {{qed}} [[Category:Left Module Does Not Necessarily Induce Right Module over Ring]] sm252o3vjhqgi1ob3en3cqc03cxnxv6	0
{{begin-eqn}} {{eqn | l = y | r = \coth^{-1} x | c = }} {{eqn | ll= \leadsto | l = x | r = \coth y | c = {{Defof|Real Inverse Hyperbolic Cotangent}} }} {{eqn | ll= \leadsto | l = \frac {\d x} {\d y} | r = -\csch^2 y | c = [[Derivative of Hyperbolic Cotangent]] }} {{eqn | ll= \leadsto | l = \frac {\d y} {\d x} | r = \frac {-1} {\csch^2 y} | c = [[Derivative of Inverse Function]] }} {{eqn | r = \frac {-1} {\coth^2 y - 1} | c = [[Difference of Squares of Hyperbolic Cotangent and Cosecant]] }} {{eqn | ll= \leadsto | l = \map {\frac \d {\d x} } {\coth^{-1} x} | r = \frac {-1} {x^2 - 1} | c = Definition of $x$ and $y$ }} {{end-eqn}} {{qed}}	0
:$\dbinom r k = \paren {-1}^k \dbinom {k - r - 1} k$	0
The relevant justifications are listed as follows: * [[Definition:Perfectly Normal Space|Perfectly Normal]] implies [[Definition:Perfectly T4 Space|Perfectly $T_4$]] implies [[Definition:T4 Space|$T_4$]] by definition. * [[Perfectly Normal Space is Completely Normal Space]]. * [[Definition:Completely Normal Space|Completely Normal]] implies [[Definition:T5 Space|$T_5$]] by definition. * [[Completely Normal Space is Normal Space]]. * [[T5 Space is T4 Space|$T_5$ space is $T_4$ space]]. * [[Definition:Normal Space|Normal]] implies [[Definition:T4 Space|$T_4$]] by definition. * [[Normal Space is Tychonoff Space|Normal Space is Tychonoff (Completely Regular) Space]]. * [[Definition:Completely Regular Space|Completely Regular (Tychonoff)]] implies [[Definition:T3 1/2 Space|$T_{3 \frac 1 2}$]] by definition. * [[Tychonoff Space is Regular, T2 and T1|Completely Regular (Tychonoff) Space is Regular Space]]. * [[T3 1/2 Space is T3 Space|$T_{3 \frac 1 2}$ Space is $T_3$ Space]]. * [[Definition:Regular Space|Regular]] implies [[Definition:T3 Space|$T_3$]] by definition. * [[Tychonoff Space is Urysohn Space|Completely Regular (Tychonoff) Space is Urysohn Space]]. * [[Urysohn Space is Completely Hausdorff Space]]. * [[Regular Space is Completely Hausdorff Space]]. * [[Regular Space is Semiregular Space]]. * [[Completely Hausdorff Space is Hausdorff Space|Completely Hausdorff Space is $T_2$ (Hausdorff) Space]]. * [[Definition:Semiregular Space|Semiregular]] implies [[Definition:Hausdorff Space|$T_2$ (Hausdorff)]] by definition. * [[T2 Space is T1 Space|$T_2$ (Hausdorff) Space is $T_1$ (Fréchet) Space]]. * [[T1 Space is T0 Space|$T_1$ (Fréchet) Space is $T_0$ (Kolmogorov) Space]]. {{qed}}	0
:$\displaystyle \int \frac {\d x} {p + q \sin a x} = \begin{cases} \displaystyle \frac 2 {a \sqrt {p^2 - q^2} } \map \arctan {\frac {p \tan \dfrac {a x} 2 + q} {\sqrt {p^2 - q^2} } } + C & : q^2 - p^2 < 0 \\ \displaystyle \frac 1 {a \sqrt {q^2 - p^2} } \ln \size {\frac {p \tan \dfrac {a x} 2 + q - \sqrt {p^2 - q^2} } {p \tan \dfrac {a x} 2 + q + \sqrt {p^2 - q^2} } } + C & : q^2 - p^2 > 0 \\ \end{cases}$	0
Let $\sin$ denote the [[Definition:Real Sine Function|real sine function]]. Let $\laptrans f$ denote the [[Definition:Laplace Transform|Laplace transform]] of a [[Definition:Real Function|real function]] $f$. Then: :$\laptrans {t^2 \cos a t} = \dfrac {2 s^3 - 6 a^2 s} {\paren {s^2 + a^2}^3}$	0
[[Definition:Vacuous Truth|Vacuously]], every [[Definition:Element of Class|element]] of $\O$ is also a [[Definition:Subclass|subclass]] of $\O$. Hence $\O$ is [[Definition:Transitive Class|transitive]] by definition. [[Definition:Vacuous Truth|Vacuously]], every [[Definition:Subclass|subclass]] of every [[Definition:Element of Class|element]] of $\O$ is also an [[Definition:Element of Class|element]] of $\O$. Hence $\O$ is [[Definition:Swelled Class|swelled]] by definition. The result follows by definition of [[Definition:Supercomplete Class|supercomplete]]. {{qed}}	0
Let $\eqclass {a, b} {}$ and $\eqclass {c, d} {}$ be [[Definition:Integer|integers]], as defined by the [[Definition:Integer/Formal Definition|formal definition of integers]]. Then exactly one of the following holds: {{begin-eqn}} {{eqn | l = \eqclass {a, b} {} | o = < | r = \eqclass {c, d} {} | c = }} {{eqn | l = \eqclass {a, b} {} | o = = | r = \eqclass {c, d} {} | c = }} {{eqn | l = \eqclass {a, b} {} | o = > | r = \eqclass {c, d} {} | c = }} {{end-eqn}} That is, [[Definition:Strict Ordering on Integers|strict ordering]] is a [[Definition:Trichotomy|trichotomy]].	0
Suppose $P$ and $Q$ are [[Definition:Sylow p-Subgroup|Sylow $p$-subgroups]] of $G$. By the [[Second Sylow Theorem]], $Q$ is a [[Definition:Subset|subset]] of a [[Definition:Conjugate of Group Subset|conjugate]] of $P$. But since $\order P = \order Q$, it follows that $Q$ must equal a [[Definition:Conjugate of Group Subset|conjugate]] of $P$. {{qed}}	0
From [[Metric Space is Open in Itself]], $A$ is [[Definition:Open Set (Metric Space)|open]] in $M$. From [[Metric Space is Closed in Itself]], $A$ is [[Definition:Closed Set (Metric Space)|closed]] in $M$. {{qed}}	0
From [[Group equals Center iff Abelian]], the [[Definition:Center of Ring|center]] of a [[Definition:Commutative Ring|commutative ring]] is the entire ring. The result follows from [[Linear Transformation from Center of Scalar Ring]]. {{qed}}	0
:$\displaystyle \int_0^{\frac \pi 2} \cos^{2 n + 1} x \rd x = \dfrac {\left({2^n n!}\right)^2} {\left({2 n + 1}\right)!}$	0
The existence and uniqueness of $f$ follows from the [[Definition:Universal Property of Polynomial Ring in One Variable|universal property]]. Likewise, there is a unique [[Definition:Ring Homomorphism|ring homomorphism]] $g: R \sqbrk Y \to R \sqbrk X$ such that: :$g \circ \kappa = \iota$ :$\map g Y = X$ and a unique [[Definition:Ring Homomorphism|ring homomorphism]] $h: R \sqbrk X \to R \sqbrk X$ such that: :$h \circ \iota = \iota$ :$\map X = X$ By uniqueness and [[Identity Mapping is Ring Homomorphism]], $h = \operatorname{id}$ is the [[Definition:Identity Mapping|identity mapping]] on $R \sqbrk X$. Again by uniqueness and [[Composition of Ring Homomorphisms is Ring Homomorphism]], $g\circ f = \operatorname{id}_{R \sqbrk X}$. By symmetry, $f \circ g = \operatorname{id}_{R \sqbrk Y}$. Thus $f$ is an [[Definition:Ring Isomorphism|isomorphism]]. {{qed}} [[Category:Polynomial Theory]] 7oevp9mhpny0q2646gcng8tg9nsbvwj	0
First: {{begin-eqn}} {{eqn | l = n | o = > | r = \left\lceil{\left\vert{x}\right\vert}\right\rceil }} {{eqn | ll= \implies | l = n | o = > | r = -x | c = [[Negative of Absolute Value]] and [[Real Number is between Ceiling Functions]] }} {{eqn | ll= \implies | l = \frac n {n + x} | o = > | r = 0 }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = n | o = > | m = \left\lceil{\left\vert{x}\right\vert}\right\rceil }} {{eqn | ll= \implies | l = n | o = > | m = \left\vert{x}\right\vert | c = [[Real Number is between Ceiling Functions]] }} {{eqn | ll= \implies | l = \left\vert{\frac x n}\right\vert | o = < | m = 1 | c = dividing both sides by $n$ }} {{eqn | ll= \implies | l = -1 | o = < | m = \frac x n | mo= < | r = 1 | c = [[Negative of Absolute Value/Corollary 1|Negative of Absolute Value: Corollary 1]] }} {{eqn | ll= \implies | l = 0 | o = < | m = 1 + \frac x n }} {{eqn | ll= \implies | l = 0 | o = < | m = \left({1 + \frac x n}\right)^n | c = [[Power of Positive Real Number is Positive/Natural Number|Power of Positive Real Number is Positive: Natural Number]] }} {{end-eqn}} So, for $n \ge \left\lceil{\left\vert{x}\right\vert}\right\rceil$: :$\left\langle{\dfrac n {n + x} }\right\rangle$ and: :$\left\langle{\left({1 + \dfrac x n}\right)^n}\right\rangle$ are [[Definition:Positive Real Number| positive]]. Now let $n \ge \left\lceil{\left\vert{x}\right\vert}\right\rceil$. Suppose first that $x \in \R_{\ge 0}$. Then: {{begin-eqn}} {{eqn | l = \frac n {n + x} | o = \le | r = \frac {n + 1} {n + x + 1} }} {{eqn | ll= \iff | l = n \left({n + x + 1}\right) | o = \le | r = \left({n + 1}\right) \left({n + x}\right) | c = [[Real Number Ordering is Compatible with Multiplication]] }} {{eqn | ll= \iff | l = n^2 + n x + n | o = \le | r = n^2 + n x + n + x }} {{eqn | ll= \iff | l = 0 | o = \le | r = x }} {{end-eqn}} So $\left\langle{\dfrac n {n + x} }\right\rangle$ is [[Definition:Increasing Real Sequence|increasing]]. Further, from [[Exponential Sequence is Eventually Increasing]]: :$\left\langle{\left({1 + \dfrac x n}\right)^n}\right\rangle$ is [[Definition:Increasing Real Sequence|increasing]]. Hence, from [[Product of Positive Increasing Functions is Increasing]]: :$n \ge \left\lceil{\left\vert{x}\right\vert }\right\rceil \implies \left\langle{\dfrac n {n + x} \left({1 + \dfrac x n}\right)^n}\right\rangle$ is [[Definition:Increasing Real Sequence|increasing]]. Suppose instead that $x \in \R_{<0}$. {{AimForCont}} that: :$\left\langle{\dfrac n {n + x} \left({1 + \dfrac x n}\right)^n}\right\rangle$ is [[Definition:Decreasing Real Sequence|decreasing]]. From above: $\left\langle{1 + \dfrac x n}\right\rangle = \left\langle{\dfrac {n + x} n}\right\rangle$ is [[Definition:Decreasing Real Sequence|decreasing]]. Thus, from [[Product of Positive Increasing and Decreasing Functions is Decreasing]]: :$\left\langle{\dfrac {n + x} n \dfrac n {n + x} \left({1 + \dfrac x n}\right)^n}\right\rangle = \left\langle{\left({1 + \dfrac x n}\right)^n}\right\rangle$ is [[Definition:Decreasing Real Sequence|decreasing]]. This [[Definition:Contradiction|contradicts]] [[Exponential Sequence is Eventually Increasing]]. Hence the result, by [[Proof by Contradiction]]. {{qed}} [[Category:Derivative of Exponential Function]] ckqbhfr7zj6nuyrsadq9uq2v596uvtk	0
Let $\map \MM {m, n}$ be a [[Definition:Matrix Space|$m \times n$ matrix space]] over one of the [[Definition:Standard Number System|standard number systems]]. For $\mathbf A, \mathbf B \in \map \MM {m, n}$, let $\mathbf A + \mathbf B$ be defined as the [[Definition:Matrix Entrywise Addition|matrix entrywise sum]] of $\mathbf A$ and $\mathbf B$. The operation $+$ is [[Definition:Associative Operation|associative]] on $\map \MM {m, n}$. That is: :$\paren {\mathbf A + \mathbf B} + \mathbf C = \mathbf A + \paren {\mathbf B + \mathbf C}$ for all $\mathbf A$, $\mathbf B$ and $\mathbf C$ in $\map \MM {m, n}$.	0
We have: {{begin-eqn}} {{eqn | l = \tan 270^\circ | r = \tan \left({360^\circ - 90^\circ}\right) | c = }} {{eqn | r = -\tan 90^\circ | c = [[Tangent of Conjugate Angle]] }} {{end-eqn}} But from [[Tangent of Right Angle]], $\tan 90^\circ$ is undefined. Hence so is $\tan 270^\circ$. {{qed}}	0
Let $\struct {D, +, \circ}$ be a [[Definition:Principal Ideal Domain|principal ideal domain]]. Let $x \in D$ be a [[Definition:Proper Element of Ring|proper element]] of $D$. Let there be two [[Definition:Complete Factorization|complete factorizations]] of $x$: :$x = u_y \circ y_1 \circ y_2 \circ \cdots \circ y_m = F_1$ :$x = u_z \circ z_1 \circ z_2 \circ \cdots \circ z_n = F_2$ Then $F_1$ and $F_2$ are [[Definition:Equivalent Factorizations|equivalent]].	0
Let $\left({S, \preceq,\tau}\right)$ be a [[Definition:Linearly Ordered Space|linearly ordered space]]. Let $A \subseteq S$ be a [[Definition:Convex Set (Order Theory)|convex set]] in $S$. Let $\upsilon$ be the [[Definition:Order Topology|order topology]] on $A$. Let $\tau'$ be the $\tau$-relative [[Definition:Subspace Topology|subspace topology]] on $A$. Then $\upsilon = \tau'$.	0
Let $\UU_0$ be a [[Definition:Local Basis|local basis]] for $\tuple {0, 0}$. Let $U \in \UU_0$. By definition of [[Definition:Local Basis|local basis]], $U$ is [[Definition:Open Set (Topology)|open]] in $T$. From [[Clopen Points in Arens-Fort Space]], $\set {\tuple {0, 0} }$ is not [[Definition:Open Set (Topology)|open]] in $T$. So $U \ne \set {\tuple {0, 0} }$. Therefore: :$\exists p \in U: p \ne \tuple {0, 0}$ From [[Singleton of Element is Subset]]: :$\set p \subseteq U$ From [[Clopen Points in Arens-Fort Space]] it follows that $\set p$ is [[Definition:Clopen Set|clopen]]. As $U \in U_0$ it follows by definition of [[Definition:Local Basis|local basis]] that: :$\tuple {0, 0} \in U$ and so: :$U \ne \set p$ That is: :$\set p \subsetneq U$ From [[Connected iff no Proper Clopen Sets]], the set $U$ is not [[Definition:Connected Topological Space|connected]]. {{explain|Re-establish the definition of [[Definition:Connected Topological Space]] as the current flow does not make it obvious that a connected subset has no proper clopen sets, only that this condition applies to the full space.}} It is deduced that any [[Definition:Local Basis|local basis]] is formed with [[Definition:Disconnected Set (Topology)|disconnected sets]]. Thus, by definition, $T$ is not [[Definition:Locally Connected Space|locally connected]]. {{qed}}	0
Let $\mathbf C_0$ and $\mathbf C_1$ be collections of [[Definition:Object|objects]]. Let $\operatorname{cod}$ and $\operatorname{dom}$ assign to every element of $\mathbf C_1$ an element of $\mathbf C_0$. Let $\operatorname{id}$ assign to every element of $\mathbf C_0$ an element of $\mathbf C_1$. Denote with $\mathbf C_2$ the collection of pairs $\left({f, g}\right)$ of elements of $\mathbf C_1$ satisfying: :$\operatorname{dom} g = \operatorname{cod} f$ Let $\circ$ assign to every such pair an element of $\mathbf C_1$. Then $\mathbf C_0, \mathbf C_1, \operatorname{cod}, \operatorname{dom}, \operatorname{id}$ and $\circ$ together determine a [[Definition:Metacategory|metacategory]] $\mathbf C$ [[Definition:Iff|iff]] the following seven axioms are satisfied: {{begin-eqn}} {{eqn|l = \operatorname{dom} \operatorname{id}_A = A |o = \qquad |r = \operatorname{cod} \operatorname{id}_A = A }} {{eqn|l = f \circ \operatorname{id}_{\operatorname{dom} f} = f |o = |r = \operatorname{id}_{\operatorname{cod} f} \circ f = f }} {{eqn|l = \operatorname{dom} \left({g \circ f}\right) = \operatorname{dom} f |o = |r = \operatorname{cod} \left({g \circ f}\right) = \operatorname{cod} g }} {{eqn|l = h \circ \left({g \circ f}\right) |r = \left({h \circ g}\right) \circ f }} {{end-eqn}} with $A$ and $f,g,h$ arbitrary elements of $\mathbf C_0$ and $\mathbf C_1$, respectively. Further, in the last two lines it is presumed that all compositions are defined. Hence it follows that: * $\mathbf C_0$ and $\mathbf C_1$ represent the collections of [[Definition:Object (Category Theory)|objects]] and [[Definition:Morphism (Category Theory)|morphisms]] of $\mathbf C$ * $\operatorname{dom}$ and $\operatorname{cod}$ represent the [[Definition:Domain (Category Theory)|domain]] and [[Definition:Codomain (Category Theory)|codomain]] of a [[Definition:Morphism (Category Theory)|morphism]] of $\mathbf C$ * $\operatorname{id}$ represents the [[Definition:Identity Morphism|identity morphisms]] of $\mathbf C$ * $\mathbf C_2$ represents the collection of [[Definition:Composable Morphisms|composable morphisms]] of $\mathbf C$ * $\circ$ represents the [[Definition:Composition of Morphisms|composition of morphisms]] in $\mathbf C$	0
Every [[Definition:Group|group]] has [[Definition:Exactly One|exactly one]] [[Definition:Idempotent Element|idempotent element]]: the [[Definition:Identity Element|identity]].	0
Let $m, n \in \Z$. Then: :$\exists n' \in \Z: n n' \equiv d \pmod m$ where $d = \gcd \set {m, n}$.	0
As defined, $M$ is a [[Definition:Metric Subspace|subspace]] of the [[Definition:Hilbert Sequence Space|Hilbert sequence space]] $\ell^2$. We have that [[Hilbert Sequence Space is Metric Space]]. The result follows from [[Subspace of Metric Space is Metric Space]]. {{qed}}	0
:$\displaystyle \int \paren {a x + b}^n \rd x = \frac {\paren {a x + b}^{n + 1} } {\paren {n + 1} a} + C$	0
By definition of [[Definition:Galois Connection|Galois connection]]: :$g_1$, $g_2$, $d_2$, and $d_1$ are [[Definition:Increasing Mapping|increasing mappings]]. Thus by [[Composition of Increasing Mappings is Increasing]]: :$g_2 \circ g_1$ and $d_1 \circ d_2$ are [[Definition:Increasing Mapping|increasing mappings]]. Let $s \in S_3, t \in S_1$. We will prove that :$s \preceq_3 \left({g_2 \circ g_1}\right)\left({t}\right) \implies \left({d_1 \circ d_2}\right)\left({s}\right) \preceq_1 t$ Assume that :$s \preceq_3 \left({g_2 \circ g_1}\right)\left({t}\right)$ By definition of [[Definition:Composition of Mappings|composition of mappings]]: :$s \preceq_3 g_2\left({g_1\left({t}\right)}\right)$ By definition of [[Definition:Galois Connection|Galois connection]]: :$d_2\left({s}\right) \preceq_2 g_1\left({t}\right)$ By definition of [[Definition:Increasing Mapping|increasing mapping]]: :$d_1\left({d_2\left({s}\right)}\right) \preceq_1 d_1\left({g_1\left({t}\right)}\right)$ By [[Galois Connection Implies Order on Mappings]] :$d_1 \circ g_1 \preceq_1 I_{S_1}$ By definitions of [[Definition:Ordering on Mappings|ordering on mappings]] and [[Definition:Composition of Mappings|composition of mappings]]: :$g_1\left({d_1\left({t}\right)}\right) \preceq_1 I_{S_1}\left({t}\right)$ By definition of [[Definition:Identity Mapping|identity mapping]]: :$g_1\left({d_1\left({t}\right)}\right) \preceq_1 t$ By definition of [[Definition:Transitivity|transitivity]]: :$d_1\left({d_2\left({s}\right)}\right) \preceq_1 t$ Thus by definition of [[Definition:Composition of Mappings|composition of mappings]]: :$\left({d_1 \circ d_2}\right)\left({s}\right) \preceq_1 t$ {{qed|lemma}} Assume that :$\left({d_1 \circ d_2}\right)\left({s}\right) \preceq_1 t$ By definition of [[Definition:Composition of Mappings|composition of mappings]]: :$d_1\left({d_2\left({s}\right)}\right) \preceq_1 t$ By definition of [[Definition:Galois Connection|Galois connection]]: :$d_2\left({s}\right) \preceq_2 g_1\left({t}\right)$ By definition of [[Definition:Increasing Mapping|increasing mapping]]: :$g_2\left({d_2\left({s}\right)}\right) \preceq_1 g_2\left({g_1\left({t}\right)}\right)$ By [[Galois Connection Implies Order on Mappings]] :$I_{S_3} \preceq_3 g_2 \circ d_2$ By definitions of [[Definition:Ordering on Mappings|ordering on mappings]] and [[Definition:Composition of Mappings|composition of mappings]]: :$I_{S_3}\left({s}\right) \preceq_3 g_2\left({d_2\left({s}\right)}\right)$ By definition of [[Definition:Identity Mapping|identity mapping]]: :$s \preceq_3 g_2\left({d_2\left({s}\right)}\right)$ By definition:Transitivity|transitivity]]: :$s \preceq_3 g_2\left({g_1\left({t}\right)}\right)$ Thus by definition of [[Definition:Composition of Mappings|composition of mappings]]: :$s \preceq_3 \left({g_2 \circ g_1}\right)\left({t}\right)$ {{qed}}	0
:$\map {\laptrans {e^{b t} \sin a t} } s = \dfrac a {\paren {s - b}^2 + a^2}$	0
By definition of [[Definition:Neighborhood of Point|neighborhood]]: :$\exists U \in \tau: x \in U \subseteq N \subseteq S$ where $U$ is an [[Definition:Open Set (Topology)|open set]] of $T$. By [[Set is Open iff Neighborhood of all its Points]], $N' = U$ fulfils the conditions of the statement. {{qed}}	0
==== [[Left Cosets are Equal iff Product with Inverse in Subgroup]] ==== {{:Left Cosets are Equal iff Product with Inverse in Subgroup}} ==== [[Right Cosets are Equal iff Product with Inverse in Subgroup]] ==== {{:Right Cosets are Equal iff Product with Inverse in Subgroup}}	0
{{begin-eqn}} {{eqn | l = \log_b x - \log_b y | r = \map {\log_b} {b^{\log_b x - \log_b y} } | c = {{Defof|General Logarithm}} }} {{eqn | r = \map {\log_b} {\frac {\paren {b^{\log_b x} } } {\paren {b^{\log_b y} } } } | c = [[Quotient of Powers]] }} {{eqn | r = \map {\log_b} {\frac x y} | c = {{Defof|General Logarithm}} }} {{end-eqn}} {{qed}}	0
Let $A$, $B$, and $S$ be [[Definition:Set|sets]]. Let $A \subseteq B$. Then: :$A \setminus S \subseteq B \setminus S$	0
{{begin-eqn}} {{eqn | l = \omega + 1 | r = \omega \cup \set {\omega} | c = {{Defof|Successor Set}} }} {{eqn | r = \set {0, 1, 2, \ldots} \cup \set \omega | c = {{Defof|Von Neumann Construction of Natural Numbers}} }} {{eqn | r = \set {0, 1, 2, \ldots; \omega} | c = {{Defof|Set Union}} }} {{end-eqn}} {{qed}}	0
Let $x \in S$ be an arbitrary point of $T$. From [[Set in Discrete Topology is Clopen]] it follows that $\left\{{x}\right\}$ is [[Definition:Open Set (Topology)|open]] in $T$. The result follows from [[Space with Open Point is Non-Meager]]. {{qed}}	0
Let $X$ be a [[Definition:Topological Space|topological space]]. Let $Y\subset X$ be an [[Definition:Irreducible Space|irreducible]] [[Definition:Topological Subspace|subspace]]. Then there exists an [[Definition:Irreducible Component|irreducible component]] of $X$ [[Definition:Set Inclusion|containing]] $Y$.	0
We have that $\sqrt {x^2 - a^2}$ is defined only when $x^2 \ge a^2$, that is, either: :$x \ge a$ or: :$x \le -a$ where it is assumed that $a > 0$. First let $x \ge a$. Let: {{begin-eqn}} {{eqn | l = z | r = x^2 }} {{eqn | ll= \leadsto | l = \frac {\d z} {\d x} | r = 2 x | c = [[Power Rule for Derivatives]] }} {{eqn | ll= \leadsto | l = \int x^2 \sqrt {x^2 - a^2} \rd x | r = \int \frac {z \sqrt {z - a^2} \rd z} {2 \sqrt z} | c = [[Integration by Substitution]] }} {{eqn | r = \frac 1 2 \int \sqrt z \sqrt {z - a^2} \rd z | c = [[Primitive of Constant Multiple of Function]] }} {{eqn | r = \frac 1 2 \paren {\frac {2 z - a^2} 4 \sqrt z \sqrt {z - a^2} - \frac {a^4} 8 \int \frac {\d z} {\sqrt z \sqrt {z - a^2} } } + C | c = [[Primitive of Root of a x + b by Root of p x + q|Primitive of $\sqrt {\paren {a x + b} \paren {p x + q} }$]] }} {{eqn | r = \frac {2 z - a^2} 8 \sqrt z \sqrt {z - a^2} - \frac {a^4} {16} \paren {2 \map \ln {\sqrt {z - a^2} + \sqrt z} } + C | c = [[Primitive of Reciprocal of Root of a x + b by Root of p x + q|Primitive of $\dfrac 1 {\sqrt {\paren {a x + b} \paren {p x + q} } }$]] }} {{eqn | r = \frac {2 z - 2 a^2} 8 \sqrt z \sqrt {z - a^2} + \frac {a^2} 8 \sqrt z \sqrt {z - a^2} - \frac {a^4} 8 \ln \paren {\sqrt {z - a^2} + \sqrt z} + C | c = }} {{eqn | r = \frac {z - a^2} 4 \sqrt z \sqrt {z - a^2} + \frac {a^2} 8 \sqrt z \sqrt {z - a^2} - \frac {a^4} 8 \ln \paren {\sqrt {z - a^2} + \sqrt z} + C | c = }} {{eqn | r = \frac {x \paren {\sqrt {x^2 - a^2} }^3} 4 + \frac {a^2 x \sqrt {x^2 - a^2} } 8 - \frac {a^4} 8 \ln \paren {x + \sqrt {x^2 - a^2} } + C | c = substituting for $z$ }} {{eqn | r = \frac {x \paren {\sqrt {x^2 - a^2} }^3} 4 + \frac {a^2 x \sqrt {x^2 - a^2} } 8 - \frac {a^4} 8 \ln \size {x + \sqrt {x^2 - a^2} } + C | c = as $x + \sqrt {x^2 - a^2} > 0$ }} {{end-eqn}} Now suppose $x \le -a$. Let $z = -x$. Then: :$\d x = -\d z$ and we then have: {{begin-eqn}} {{eqn | l = \int x^2 \sqrt {x^2 - a^2} \rd x | r = -\int \paren {-z}^2 \sqrt {\paren {-z}^2 - a^2} \rd z | c = [[Integration by Substitution]] }} {{eqn | r = -\int z^2 \sqrt {z^2 - a^2} \rd z | c = simplifying }} {{eqn | r = -\paren {\frac {z \paren {\sqrt {z^2 - a^2} }^3} 4 + \frac {a^2 z \sqrt {z^2 - a^2} } 8 - \frac {a^4} 8 \map \ln {z + \sqrt {z^2 - a^2} } } + C | c = from above }} {{eqn | r = -\frac {z \paren {\sqrt {z^2 - a^2} }^3} 4 - \frac {a^2 z \sqrt {z^2 - a^2} } 8 + \frac {a^4} 8 \map \ln {z + \sqrt {z^2 - a^2} } + C | c = simplifying }} {{eqn | r = -\frac {z \paren {\sqrt {z^2 - a^2} }^3} 4 - \frac {a^2 z \sqrt {z^2 - a^2} } 8 - \frac {a^4} 8 \paren {\map \ln {z - \sqrt {z^2 - a^2} } - \map \ln {a^2} } + C | c = [[Negative of Logarithm of x plus Root x squared minus a squared|Negative of $\map \ln {z + \sqrt {z^2 - a^2} }$]] }} {{eqn | r = -\frac {z \paren {\sqrt {z^2 - a^2} }^3} 4 - \frac {a^2 z \sqrt {z^2 - a^2} } 8 - \frac {a^4} 8 \paren {\map \ln {z - \sqrt {z^2 - a^2} } } + C | c = subsuming $\dfrac {a^4 \map \ln {-a^2} } 8$ into [[Definition:Arbitrary Constant (Calculus)|constant]] }} {{eqn | r = -\frac {\paren {-x} \paren {\sqrt {\paren {-x}^2 - a^2} }^3} 4 - \frac {a^2 \paren {-x} \sqrt {\paren {-x}^2 - a^2} } 8 - \frac {a^4} 8 \paren {\map \ln {\paren {-x} - \sqrt {\paren {-x}^2 - a^2} } } + C | c = substituting back for $x$ }} {{eqn | r = \frac {x \paren {\sqrt {x^2 - a^2} }^3} 4 + \frac {a^2 x \sqrt {x^2 - a^2} } 8 - \frac {a^4} 8 \map \ln {-\paren {x + \sqrt {x^2 - a^2} } } + C | c = simplifying }} {{eqn | r = \frac {x \paren {\sqrt {x^2 - a^2} }^3} 4 + \frac {a^2 x \sqrt {x^2 - a^2} } 8 - \frac {a^4} 8 \ln \size {x + \sqrt {x^2 - a^2} } + C | c = as $-\paren {x + \sqrt {x^2 - a^2} } > 0$: {{Defof |Absolute Value}} }} {{end-eqn}} {{qed}}	0
The '''[[Definition:Complete Elliptic Integral of the Second Kind|complete elliptic integral of the second kind]]''': :$\displaystyle \map E k = \int_0^{\pi / 2} \sqrt {1 - k^2 \sin^2 \phi} \, \rd \phi = \int_0^1 \dfrac {\sqrt {1 - k^2 v^2} } {\sqrt {1 - v^2}} \, \rd v$ can be expressed as the [[Definition:Power Series|power series]]: {{begin-eqn}} {{eqn | l = \map E k | r = \frac \pi 2 \sum_{i \mathop \ge 0} \paren {\prod_{j \mathop = 1}^i \frac {2 j - 1} { 2 j} }^2 \frac {k^{2 i} } {1 - 2 i} | c = }} {{eqn | r = \frac \pi 2 \paren {1 - \paren {\frac 1 2}^2 k^2 - \paren {\frac {1 \cdot 3} {2 \cdot 4} }^2 \frac {k^4} 3 - \paren {\frac {1 \cdot 3 \cdot 5} {2 \cdot 4 \cdot 6} }^2 \frac {k^6} 5 - \cdots} | c = }} {{end-eqn}}	0
Let $z \in \C$ be a [[Definition:Complex Number|complex number]]. Then: :$z^n - 1 = \displaystyle \prod_{k \mathop = 0}^{n - 1} \paren {z - \alpha^k}$ where $\alpha$ is a [[Definition:Primitive Complex Root of Unity|primitive complex $n$th root of unity]].	0
By definition of [[Definition:Minimally Inductive Class under General Mapping|minimally inductive class]], $M$ is [[Definition:Minimally Closed Class|minimally closed under $g$ with respect to $\O$]]. The result is then seen to be a direct application of [[Sandwich Principle for Minimally Closed Class]]. {{qed}}	0
Let $\left({S, \prec}\right)$ be a [[Definition:Relational Structure|relational structure]] such that $\prec$ is a [[Definition:Strict Total Ordering|strict total ordering]]. Then the [[Definition:Complement of Relation|complement]] of $\prec$ is a [[Definition:Weak Total Ordering|weak total ordering]].	0
Let $\tuple {\lambda_1, \lambda_2} = \tuple {\rho \cos \sigma, \rho \sin \sigma}$. Then: {{begin-eqn}} {{eqn | l = r_\alpha \left({\lambda_1, \lambda_2}\right) | r = \tuple {\rho \cos \alpha \cos \sigma - \rho \sin \alpha \sin \sigma, \rho \sin \alpha \cos \sigma + \rho \cos \alpha \sin \sigma} | c = }} {{eqn | r = \tuple {\lambda_1 \cos \alpha - \lambda_2 \sin \alpha, \lambda_1 \sin \alpha + \lambda_2 \cos \alpha} | c = }} {{end-eqn}} The result follows from [[Linear Operator on the Plane]]. {{ProofWanted|This definition requires to be approached from several conceptual directions.}}	0
We need to show that $\phi: \tuple {x, y} \mapsto x + y i$ is a [[Definition:Group Isomorphism|group isomorphism]]. === $\phi$ is a [[Definition:Group Homomorphism|group homomorphism]] === {{begin-eqn}} {{eqn | ll = \forall a, b, c, d \in \R: | l = \map \phi {a, b} + \map \phi {c, d} | r = \paren {a + b i} + \paren {c + d i} }} {{eqn | r = \paren {a + c} + \paren {b + d} i | c = [[Complex Addition is Commutative]] }} {{eqn | r = \map \phi {a + c, b + d} }} {{end-eqn}} {{qed|lemma}} === $\phi$ is [[Definition:Bijection|bijective]] === We show that $\phi^{-1}: z \mapsto \tuple {\map \Re z, \map \Im z}$ is the [[Definition:Inverse Mapping|inverse]] of $\phi$. We have: :$\map \phi {\map {\phi^{-1} } z} = \map \phi {\map \Re z, \map \Im z} = \map \Re z + i \map \Im z = z$ :$\map {\phi^{-1} } {\map \phi {a, b} } = \map {\phi^{-1} } {a + b i} = \tuple {a, b}$ hence $\phi^{-1}$ is the [[Definition:Inverse Mapping|inverse]] of $\phi$. {{qed|lemma}} Hence $\phi$ is a [[Definition:Group Isomorphism|group isomorphism]], and thus the [[Definition:Group Direct Product|direct product]] $\struct {\R, +} \times \struct {\R, +}$ is [[Definition:Group Isomorphism|isomorphic]] with $\struct {\C, +}$. {{qed}}	0
From [[Odd-Even Topology is Second-Countable]], $T$ is [[Definition:Second-Countable Space|second-countable]]. The result follows from [[Second-Countable Space is Lindelöf]]. {{qed}}	0
From [[Sum of Powers of Positive Integers]]: {{begin-eqn}} {{eqn | l = \sum_{i \mathop = 1}^n i^p | r = 1^p + 2^p + \cdots + n^p | c = }} {{eqn | r = \frac {n^{p + 1} } {p + 1} + \sum_{k \mathop = 1}^p \frac {B_k \, p^{\underline {k - 1} } \, n^{p - k + 1} } {k!} | c = }} {{end-eqn}} where $B_k$ are the [[Definition:Bernoulli Numbers|Bernoulli numbers]]. Setting $p = 3$: {{begin-eqn}} {{eqn | l = \sum_{i \mathop = 1}^n i^3 | r = \frac {n^{3 + 1} } {3 + 1} + \sum_{k \mathop = 1}^3 \frac {B_k \, 3^{\underline {k - 1} } \, n^{3 - k + 1} } {k!} | c = }} {{eqn | r = \frac {n^4} 4 + \frac {B_1 \, 3^{\underline 0} \, n^3} {1!} + \frac {B_2 \, 3^{\underline 1} \, n^2} {2!} + \frac {B_3 \, 3^{\underline 2} \, n^1} {3!} | c = }} {{eqn | r = \frac {n^4} 4 + \frac 1 2 \frac {n^3} {1!} + \frac 1 6 \frac {3 n^2} {2!} + 0 \frac {3 \times 2 n} {3!} | c = {{Defof|Bernoulli Numbers}} and {{Defof|Falling Factorial}} }} {{eqn | r = \frac {n^4} 4 + \frac {n^3} 2 + \frac {n^2} 4 | c = simplifying }} {{eqn | r = \frac {n^2 \left({n + 1}\right)^2} 4 | c = after algebra }} {{end-eqn}}	0
Let $T = \struct {S, \tau}$ be a [[Definition:Discrete Topology|discrete topological space]]. Then $T$ is a [[Definition:Complete Metric Space|complete metric space]].	0
From [[Arc in Topological Space is Path]], $f$ and $g$ are also [[Definition:Path (Topology)|paths]] in $T$. So by [[Joining Paths makes Another Path]] it follows that $h$ is a [[Definition:Path (Topology)|path]] in $T$. Now if $\operatorname{Im} \left({f}\right) \cap \operatorname{Im} \left({g}\right) = b$ it can be seen that: :$\displaystyle \forall x \in \operatorname{Im} \left({h}\right): x = \begin{cases} f \left({y}\right) & \text{for some } y \in \left[{0 \,.\,.\, \dfrac 1 2}\right], \text{ or} \\ g \left({z}\right) & \text{for some } z \in \left[{\dfrac 1 2 \,.\,.\, 1}\right] \\ \end{cases}$ and it follows that $h$ is an [[Definition:Injection|injection]], and therefore an [[Definition:Arc (Topology)|arc]]. {{mistake|that should be an XOR, really. And the intervals for $y$ and $z$ are simply $I$}} On the other hand, suppose: : $\exists y \in \left[{0 \,.\,.\, \dfrac 1 2}\right]: \exists z \in \left[{\dfrac 1 2 \,.\,.\, 1}\right]: f \left({y}\right) = g \left({z}\right)$ such that $f \left({y}\right) \ne b$. {{finish|It remains to show that you can built an arc out of the bits up till where the arcs cross. It's intuitively obvious but requires some analysis work.}} {{qed}} [[Category:Topology]] dd45te87wsxmhkn1yz0eacd2javv00r	0
Let $\le$ be the standard ordering on the [[Definition:Natural Number|natural numbers]] $\N$. Then the [[Definition:Order Topology|order topology]] $\tau$ on $\N$ is the [[Definition:Discrete Topology|discrete topology]].	0
Let $S$ be a [[Definition:Subset|subset]] of the set of [[Definition:Real Number|real numbers]] $\R$. Let $x \in \R$ be a [[Definition:Real Number|real number]]. Let $\map d {x, S}$ be the [[Definition:Distance between Element and Subset of Real Numbers|distance]] between $x$ and $S$. Then: {{:Distance from Subset of Real Numbers to Element}}	0
Let $\family{X_i}_{i \mathop \in I}$ be an [[Definition:Indexed Family|indexed family]] of [[Definition:Non-Empty Set|non-empty]] [[Definition:Hausdorff Space|Hausdorff spaces]] where $I$ is an arbitrary [[Definition:Indexing Set|index set]]. Let $\displaystyle X := \prod_{i \mathop \in I} X_i$ be the corresponding [[Definition:Product Space of Topological Spaces|product space]]. Let $\pr_i: X \to X_i$ denote the [[Definition:Projection (Mapping Theory)|projection]] from $X$ onto $X_i$. Let $\FF \subset \powerset X$ be a [[Definition:Filter on Set|filter]] on $X$. Then $\FF$ [[Definition:Convergent Filter|converges]] {{iff}} for each $i \in I$ the [[Definition:Image Filter|image filter]] $\map {\pr_i} \FF$ converges.	0
$G$ can be seen as functions: :$\displaystyle f: A \to \bigcup_{a \mathop \in A} G_a$ {{explain|Clarify the above sentence.}} Let $a \in A$. Let $x, y \in G_a$. Let $r \in R$. So both $x + y \in G_a$ and $r x \in G_a$. Let $b \in A$. === Case 1 === {{explain|Explain and clarify the notation}} Let $b = a$. Then: :$\map {\map {\inj_a} {x + y} } b = x + y = \map {\map {\inj_a} x} b + \map {\map {\inj_a} y} b$ and: :$\map {\map {\inj_a} {r x} } b = r x = r \, \map {\map {\inj_a} x} b$ {{qed|lemma}} === Case 2 === Let $b \ne a$. Then: :$\map {\map {\inj_a} {x + y} } b = 0 + 0 = \map {\map {\inj_a} x} b + \map {\map {\inj_a} y} b$ and: :$\map {\map {\inj_a} {r x} } b = 0 = \map r 0 = r \, \map {\map {\inj_a} x} b$ Therefore: :$\map {\inj_a} {x + y} = \map {\inj_a} x + \map {\inj_a} y$ and: :$\map {\inj_a} {r x} = r \, \map {\inj_a} x$ {{qed|lemma}} So $\inj_a$ is a [[Definition:R-Algebraic Structure Homomorphism|homomorphism]]. Combined with [[Canonical Injection is Injection]] gives that $\inj_a$ is a [[Definition:R-Algebraic Structure Monomorphism|monomorphism]]. {{qed}}	0
Let $\Omega$ denote the first [[Definition:Uncountable Ordinal|uncountable ordinal]]. Let $\closedint 0 \Omega$ denote the [[Definition:Uncountable Closed Ordinal Space|closed ordinal space]] on $\Omega$. Then $\closedint 0 \Omega$ is not a [[Definition:Separable Space|separable space]].	0
Let $T = \struct {S, \tau}$ be a [[Definition:Topological Space|topological space]] where $S$ is a [[Definition:Finite Set|finite set]]. Then $T$ satisfies the following [[Definition:Compact Topological Space|compactness properties]]: : $T$ is [[Definition:Compact Topological Space|compact]]. : $T$ is [[Definition:Sequentially Compact Space|sequentially compact]]. : $T$ is [[Definition:Countably Compact Space|countably compact]]. : $T$ is [[Definition:Weakly Countably Compact Space|weakly countably compact]]. : $T$ is a [[Definition:Lindelöf Space|Lindelöf space]]. : $T$ is [[Definition:Pseudocompact Space|pseudocompact]]. : $T$ is [[Definition:Sigma-Compact Space|$\sigma$-compact]]. : $T$ is [[Definition:Strongly Locally Compact Space|strongly locally compact]]. : $T$ is [[Definition:Sigma-Locally Compact Space|$\sigma$-locally compact]]. : $T$ is [[Definition:Weakly Sigma-Locally Compact Space|weakly $\sigma$-locally compact]]. : $T$ is [[Definition:Locally Compact Space|locally compact]]. : $T$ is [[Definition:Weakly Locally Compact Space|weakly locally compact]]. : $T$ is [[Definition:Paracompact Space|paracompact]]. : $T$ is [[Definition:Countably Paracompact Space|countably paracompact]]. : $T$ is [[Definition:Metacompact Space|metacompact]]. : $T$ is [[Definition:Countably Metacompact Space|countably metacompact]].	0
Let $\left({X, d}\right)$ be a [[Definition:Metric Space|metric space]]. Let $G \subseteq X$. Then the following are equivalent: :$(1): \quad G \subseteq X$ is an [[Definition:Open Set (Metric Space)|open set]] of $\left({X, d}\right)$ :$(2): \quad \forall x \in G: \forall \left\langle{x_n}\right\rangle \in X: x_n \to x: \exists n_0 \in \N: \forall n \ge n_0: \left\langle{x_n}\right\rangle \in G$	0
Suppose that $S_2 = f \left({S_1}\right)$ is not [[Definition:Connected Set (Topology)|connected]] in $T_2$. Then [[Definition:Connected (Topology)/Set/Definition 2|by definition]] there exist [[Definition:Open Set (Topology)|open sets]] $U_2$ and $V_2$ in $T_2$ such that: :$S_2 \subseteq U_2 \cup V_2$ :$U_2 \cap V_2 \cap S_2 = \varnothing$ :$U_2 \cap S_2 \ne \varnothing$ :$V_2 \cap S_2 \ne \varnothing$ [[Definition:By Hypothesis|By hypothesis]], $f: T_1 \to T_2$ is [[Definition:Continuous Mapping (Topology)|continuous]]. Thus $U_1 = f^{-1} \left({U_2}\right)$ and $V_1 = f^{-1} \left({V_2}\right)$ are [[Definition:Open Set (Topology)|open]] in $T_1$. We have that: :$U_2 \cap S_2 \ne \varnothing$ Therefore: :$\exists x \in S_1: f \left({x}\right) \in U_2$ Then: :$x \in f^{-1} \left({U_2}\right) = U_1$ and: :$x \in S_1$ so: :$U_1 \cap S_1 \ne \varnothing$ Similarly: :$V_1 \cap S_1 \ne \varnothing$ Suppose there exists $x \in S_1$ such that $x \in U_1 \cap V_1 \cap S_1$. Then: :$f \left({x}\right) \in U_2 \cap V_2 \cap S_2$ which is a [[Definition:Contradiction|contradiction]]. It follows that: :$U_1 \cap V_1 \cap S_1 = \varnothing$ Thus by definition $S_1$ is not [[Definition:Connected Set (Topology)|connected]] in $T_1$. The result follows by the [[Rule of Transposition]].	0
From [[Sum of Sequence of Odd Cubes]]: :$1^3 + 3^3 + 5^3 + \cdots + \paren {2 m − 1}^3 = m^2 \paren {2 m^2 − 1}$ By the [[Theorem of Even Perfect Numbers]]: :$n = 2^{r - 1} \paren {2^r - 1}$ for some $r$. Setting $m = 2^{r - 2}$: :$m^2 = 2^{r - 1}$ and so: :$2 m^2 = 2^r$ and it follows that: :$\displaystyle n = \sum_{k \mathop = 1}^{2^{r - 2} } \paren {2 k - 1}^3$ and hence the result. When $n = 6$ we have: :$6 = 2^1 \paren {2^2 - 1}$ leading to $r = 2$ and thence $m^2 = 2$, at which point the formula fails to work. {{qed}}	0
Let $H = S \setminus \left\{{p}\right\}$ where $\setminus$ denotes [[Definition:Set Difference|set difference]]. By definition, $H$ is an [[Definition:Uncountable Discrete Topology|uncountable discrete space]]. The result follows from [[Uncountable Discrete Space is not Second-Countable]]. {{qed}}	0
Let $M_1, M_2, M_3$ be [[Definition:Metric Space|metric spaces]]. Let $f: M_1 \to M_2$ and $g: M_2 \to M_3$ be [[Definition:Homeomorphic Metric Spaces|homeomorphisms]]. Then $g \circ f: M_1 \to M_3$ is also a [[Definition:Homeomorphic Metric Spaces|homeomorphism]].	0
Let $T = \left({S, \tau_p}\right)$ be a [[Definition:Particular Point Topology|particular point space]], whose [[Definition:Particular Point Topology|particular point]] is $p$. Let $H = S \setminus \left\{ {p}\right\}$ where $\setminus$ denotes [[Definition:Set Difference|set difference]]. Then the [[Definition:Topological Subspace|topological subspace]] $T_H = \left({H, \tau_H}\right)$ induced on $H$ by $\tau_p$ is a [[Definition:Discrete Space|discrete space]].	0
Let $\sup \set {\norm {n \cdot 1_R}: n \in \N_{> 0} } = C < +\infty$.	0
We examine each of the criteria for being a [[Definition:Topology|topology]] separately. :$(1): \quad$ By [[Union of Open Sets of Metric Space is Open]], the [[Definition:Set Union|union]] of any collection of [[Definition:Open Set of Metric Space|open sets]] of a [[Definition:Metric Space|metric space]] is [[Definition:Open Set of Metric Space|open]]. :$(2): \quad$ By [[Finite Intersection of Open Sets of Metric Space is Open]], a [[Definition:Finite Intersection|finite intersection]] of [[Definition:Open Set of Metric Space|open sets]] of a [[Definition:Metric Space|metric space]] is [[Definition:Open Set of Metric Space|open]]. :$(3): \quad$ By [[Open Sets in Metric Space]], $\O \in \tau$ and $A \in \tau$. Hence the result. {{qed}}	0
Checking the criteria for $\PP$ to be a [[Definition:Synthetic Basis|synthetic basis]] for $\tau$: We have that $\displaystyle S = \bigcup \PP$ from the definition of a [[Definition:Partition (Set Theory)|partition]]. Therefore, $\displaystyle S \subseteq \bigcup \PP$ and $\PP$ is a [[Definition:Cover of Set|cover]] for $S$. Next, let $B_1, B_2 \in \PP$. Then as $\PP$ is a [[Definition:Partition (Set Theory)|partition]] of $S$, we have that $B_1 \cap B_2 = \O$. But from [[Union of Empty Set]] we have that $\O$ is the (vacuous) [[Definition:Set Union|union]] of [[Definition:Set|sets]] of $\PP$. Hence $\PP$ is a [[Definition:Synthetic Basis|synthetic basis]] for $\tau$. {{qed}}	0
Let $n_0 \in \N$ be such that the [[Definition:Sequence of Partial Products|sequence of partial products]] of $\displaystyle \prod_{n \mathop = n_0}^\infty f_n$ [[Definition:Uniform Convergence|converges uniformly]]. By the [[Uniform Limit Theorem]], $\displaystyle \prod_{n \mathop = n_0}^\infty f_n$ is [[Definition:Continuous Mapping|continuous]]. Because $f_1, \ldots, f_{n_0 - 1}$ are continuous, so is $\displaystyle \prod_{n \mathop = 1}^\infty f_n$. {{qed}}	0
From [[Real Number Line is Metric Space]], $\R$ under the [[Definition:Euclidean Metric on Real Number Line|Euclidean metric]] is a [[Definition:Metric Space|metric space]]. The result follows by [[Uniformly Continuous Function is Continuous/Metric Space|Uniformly Continuous Function is Continuous: Metric Space]]. {{qed}}	0
Let $\struct {X, \norm {\, \cdot \,} }$ be a [[Definition:Normed Vector Space|normed vector space]]. Then: :$\forall x, y \in X: \norm {x - y} \ge \size {\norm x - \norm y}$	0
Any [[Definition:Smooth Manifold|smooth]], [[Definition:Compact Space|compact]], [[Definition:Path-Connected|path-connected]] [[Definition:Topological Manifold|manifold]] of [[Definition:Dimension (Topology)|dimension $2$]] is [[Definition:Diffeomorphism|diffeomorphic]] to [[Definition:Sphere (Topology)|the sphere $\mathbb S^2$]], a [[Definition:Connected Sum|connected sum]] of [[Definition:Torus (Topology)|tori $\mathbb T^2$]], or a [[Definition:Connected Sum|connected sum]] of [[Definition:Projective Space|projective spaces $\mathbb{RP}^2$]]. Any such [[Definition:Topological Manifold|$2$-manifold]] with [[Definition:Boundary of Manifold|boundary]] is [[Definition:Diffeomorphism|diffeomorphic]] to [[Definition:Sphere (Topology)|the sphere $\mathbb S^2$]], a [[Definition:Connected Sum|connected sum]] of [[Definition:Torus (Topology)|tori $\mathbb T^2$]], or a [[Definition:Connected Sum|connected sum]] of [[Definition:Projective Space|projective spaces $\mathbb{RP}^2$]], with a number of [[Definition:Open Disk|open disks]] removed. The [[Definition:Euler Characteristic|Euler characteristic]], [[Definition:Orientability|orientability]], and number of [[Definition:Boundary Curve|boundary curves]] suffice to describe a [[Definition:Topological Surface|surface]].	0
Let $N_n$ denote the [[Definition:Edgeless Graph|edgeless graph]] with $n$ [[Definition:Vertex of Graph|vertices]]. Then $N_n$ has $n$ [[Definition:Component of Graph|components]].	0
Let $T$ be the [[Definition:Sorgenfrey Line|Sorgenfrey line]]. Let $T' = T \times T$ be [[Definition:Sorgenfrey's Half-Open Square Topology|Sorgenfrey's half-open square topology]]. From [[Sorgenfrey Line is Metacompact Space]], $T$ is a [[Definition:Metacompact Space|metacompact space]]. From [[Sorgenfrey's Half-Open Square Topology is Not Metacompact Space]], $T'$ is not a [[Definition:Metacompact Space|metacompact space]]. Hence the result. {{qed}}	0
Let $\map S x$ be a [[Definition:Trigonometric Series|trigonometric series]]: :$\map S x = \dfrac {a_0} 2 + \displaystyle \sum_{n \mathop = 1}^\infty \paren {a_n \cos n x + b_n \sin n x}$ Let the [[Definition:Series|series]]: :$\displaystyle \sum_{n \mathop = 1}^\infty \paren {\size {a_n} + \size {b_n} }$ be [[Definition:Convergent Series of Numbers|convergent]]. Then $S$ is a [[Definition:Convergent Series of Numbers|convergent series]].	0
Let $\mathbf 0_H$ be the [[Definition:Zero Vector|zero]] of $H$. Since for every $k \in K$, we have: :$\map d {h, k} = \norm {h - k} = \map d {\mathbf 0_H, k - h}$ it follows that: :$\map d {h, K} = \map d {\mathbf 0_H, K - h}$ {{WLOG}}, we may therefore assume that $h = \mathbf 0_H$. The problem has therefore reduced to finding $k_0 \in K$ such that: :$\norm {k_0} = \map d {\mathbf 0_H, K} = \inf \set {\norm k : k \in K}$ Let $d = \map d {\mathbf 0_H, K}$. By definition of [[Definition:Infimum of Subset of Real Numbers|infimum]], there exists a [[Definition:Sequence|sequence]] $\sequence {k_n}_{n \mathop \in \N}$ such that: :$\displaystyle \lim_{n \mathop \to \infty} \norm {k_n} = d$ By the [[Parallelogram Law (Hilbert Space)|Parallelogram Law]], we have that for all $m, n \in \N$: :$(1): \quad \norm {\dfrac {k_n - k_m} 2 } = \dfrac 1 2 \paren {\norm {k_n}^2 + \norm {k_m}^2} - \norm {\dfrac {k_n + k_m} 2 }^2$ Since $K$ is [[Definition:Convex Set (Vector Space)|convex]], $\dfrac {k_n + k_m} 2 \in K$. Hence: :$\norm {\dfrac {k_n + k_m} 2 }^2 \ge d^2$ Now given $\epsilon > 0$, choose $N$ such that for all $n \ge N$: :$\norm {k_n}^2 < d^2 + \epsilon$ From $(1)$, it follows that: :$\norm {\dfrac {k_n - k_m} 2} < d^2 + \epsilon - d^2 = \epsilon$ and hence that $\sequence {k_n}_{n \mathop \in \N}$ is a [[Definition:Cauchy Sequence (Metric Space)|Cauchy sequence]]. Since $H$ is a [[Definition:Hilbert Space|Hilbert space]] and $K$ is [[Definition:Closed Set (Metric Space)|closed]], it follows that there is a $k_0 \in K$ such that: :$\displaystyle \lim_{n \mathop \to \infty} k_n = k_0$ From [[Norm is Continuous]], we infer that $\norm {k_0} = d$. This demonstrates existence of $k_0$. For uniqueness, suppose that $h_0 \in K$ has $\norm {h_0} = d$. Since $K$ is [[Definition:Convex Set (Vector Space)|convex]], it follows that $\dfrac {h_0 + k_0} 2 \in K$. This implies that $\norm {\dfrac {h_0 + k_0} 2} \ge d$. Now from the [[Triangle Inequality]]: :$\norm {\dfrac {h_0 + k_0} 2} \le \dfrac {\norm {h_0} + \norm {k_0} } 2 = d$ meaning that $\norm {\dfrac {h_0 + k_0} 2} = d$. Thus, the [[Parallelogram Law (Hilbert Space)|Parallelogram Law]] implies that: :$d^2 = \norm {\dfrac {h_0 + k_0} 2}^2 = d^2 - \norm {\dfrac {h_0 - k_0} 2}^2$ from which we conclude that $h_0 = k_0$. {{qed}}	0
Let $\struct {R, \norm { \, \cdot \, } }$ be a [[Definition:Normed Division Ring|normed division ring]]. Let $\sequence {x_n}$ be a [[Definition:Sequence|sequence]] in $R$. Let $N \in \N$ Let $\sequence {y_n}$ be the [[Definition:Sequence|sequence]] defined by: :$\forall n, y_n = x_{N+n}$ Let $\sequence {y_n}$ be a [[Definition:Convergent Sequence in Normed Division Ring|convergent sequence]] in $R$ with limit $l$. Then: :$\sequence {x_n}$ is a [[Definition:Convergent Sequence in Normed Division Ring|convergent sequence]] in $R$ with limit $l$.	0
Let $\left({M_1, d_1}\right)$ and $\left({M_2, d_2}\right)$ be [[Definition:Metric Space|metric spaces]]. Let $g: M_1 \to M_2$ satisfy the [[Definition:Lipschitz Condition|Lipschitz condition]]. Then $g$ is [[Definition:Uniformly Continuous Mapping (Metric Spaces)|uniformly continuous]] on $M_1$.	0
=== $(1)$ implies $(2)$ === Suppose: :$\forall p, q \in S: \neg p \vee \neg q = \neg \left({p \wedge q}\right)$ Then applying this to $\neg p$ and $\neg q$: :$\neg \neg p \vee \neg \neg q = \neg \left({\neg p \wedge \neg q}\right)$ By [[Complement of Complement in Uniquely Complemented Lattice]], $\neg \neg p = p$ and $\neg \neg q = q$. Thus: :$p \vee q = \neg \left({\neg p \wedge \neg q}\right)$. Taking [[Definition:Complement (Lattice Theory)|complements]] of both sides: :$\neg \left({p \vee q}\right) = \neg \neg \left({\neg p \wedge \neg q}\right)$ Again applying [[Complement of Complement in Uniquely Complemented Lattice]]: :$\neg \left({p \vee q}\right) = \neg p \wedge \neg q$ {{qed|lemma}} === $(2)$ implies $(1)$ === By [[Dual Pairs (Order Theory)]], $\wedge$ and $\vee$ are [[Definition:Dual Statement (Order Theory)|dual]]. Thus this implication follows from the above by [[Duality Principle (Order Theory)|Duality]]. {{qed|lemma}} === $(1)$ implies $(3)$ === By the definition of a [[Definition:Lattice/Definition 3|lattice]]: :$p \preceq q \iff p \vee q = q$ Applying this to $\neg q$ and $\neg p$: :$\neg q \preceq \neg p \iff \neg q \vee \neg p = \neg p$ By $(1)$: :$\neg q \vee \neg p = \neg \left({q \wedge p}\right)$ So: :$\neg q \preceq \neg p \iff \neg \left({q \wedge p}\right) = \neg p$ Taking the [[Definition:Complement (Lattice Theory)|complements]] of both sides of the equation on the right, and applying [[Complement of Complement in Uniquely Complemented Lattice]]: :$\neg q \preceq \neg p \iff q \wedge p = p$ But the right side is equivalent to $p \preceq q$ {{explain|We define the ordering on a lattice (definition 3) based on joins. We need an equivalent one based on meets, or maybe we have it somewhere already.}} Therefore: :$\neg q \preceq \neg p \iff p \preceq q$ {{qed|lemma}} === $(3)$ implies $(1)$ === {{improve|This is ugly}} {{MissingLinks}} Suppose that $p \preceq q \iff \neg q \preceq \neg p$ By the definition of join: :$\neg p, \neg q \preceq \neg p \vee \neg q$ Thus $\neg \left({\neg p \vee \neg q}\right) \preceq p, q$. By the definition of meet: :$\neg \left({\neg p \vee \neg q}\right) \preceq p \wedge q$ Thus: :$\neg\left({p \wedge q}\right) \preceq \neg\neg \left({\neg p \vee \neg q}\right)$ By [[Complement of Complement in Uniquely Complemented Lattice]]: $*\quad \neg\left({p \wedge q}\right) \preceq \neg p \vee \neg q$ Dually: :$\neg x \wedge \neg y \preceq \neg \left({x \vee y}\right)$ Letting $x = \neg p$ and $y = \neg q$: :$\neg \neg p \wedge \neg \neg q \preceq \neg \left({\neg p \vee \neg q}\right)$ By [[Complement of Complement in Uniquely Complemented Lattice]]: :$p \wedge q \preceq \neg \left({\neg p \vee \neg q}\right)$ By the premise and [[Complement of Complement in Uniquely Complemented Lattice]], then: $**\quad \neg p \vee \neg q \preceq \neg \left({p \wedge q}\right)$ By $*$ and $**$: $\quad \neg\left({p \wedge q}\right) = \neg p \vee \neg q$ {{qed|lemma}} === $(1)$, $(2)$, and $(3)$ together imply $(4)$ === $b, c \preceq b \vee c$, so :$a \wedge b \preceq a \wedge \left({b \vee c}\right)$ :$a \wedge c \preceq a \wedge \left({b \vee c}\right)$ By the definition of join: :$\left({a \wedge b}\right) \vee \left({a \wedge c}\right) \preceq a \wedge \left({b \vee c}\right)$ {{finish}}	0
Let $T$ be a [[Definition:Topological Space|topological space]]. Let $H \subseteq T$. === [[Definition:Exterior (Topology)/Definition 1|Definition 1]] === {{:Definition:Exterior (Topology)/Definition 1}} === [[Definition:Exterior (Topology)/Definition 2|Definition 2]] === {{:Definition:Exterior (Topology)/Definition 2}}	0
Let $\struct {S, \circ}$ be the [[Definition:External Direct Product|external direct product]] of the [[Definition:Algebraic Structure|algebraic structures]] $\struct {S_1, \circ_1}$ and $\struct {S_2, \circ_2}$. Then: :$\pr_1$ is an [[Definition:Epimorphism (Abstract Algebra)|epimorphism]] from $\struct {S, \circ}$ to $\struct {S_1, \circ_1}$ :$\pr_2$ is an [[Definition:Epimorphism (Abstract Algebra)|epimorphism]] from $\struct {S, \circ}$ to $\struct {S_2, \circ_2}$ where $\pr_1$ and $\pr_2$ are the [[Definition:First Projection|first]] and [[Definition:Second Projection|second projection]] respectively of $\struct {S, \circ}$.	0
{{begin-eqn}} {{eqn | l = \norm x_1 | r = \norm {x - 0}_1 | c = }} {{eqn | r = \norm {\map \phi x - \map \phi 0}_2 | c = As $\phi$ is [[Definition:Distance-Preserving Mapping|distance-preserving]] }} {{eqn | r = \norm {\map \phi {x - 0} }_2 | c = As $\phi$ is a [[Definition:Ring Homomorphism|ring homomorphism]] }} {{eqn | r = \norm {\map \phi x}_2 | c = }} {{end-eqn}} {{qed}} [[Category:Completion of Normed Division Ring]] jwy6taffeba678zhowexgahutv7yko8	0
Let $\CC_x = \set {A \subseteq S : x \in A \land A \text{ is connected in } T}$ Let $C = \bigcup \CC_x$ === [[Equivalence of Definitions of Component/Lemma 1|Lemma]] === {{:Equivalence of Definitions of Component/Lemma 1}}{{qed|lemma}} Let $C'$ be the [[Definition:Equivalence Class|equivalence class containing $x$]] of the [[Definition:Equivalence Relation|equivalence relation]] $\sim$ defined by: :$y \sim z$ {{iff}} $y$ and $z$ are [[Definition:Connected Points (Topology)|connected]] in $T$. === [[Equivalence of Definitions of Component/Equivalence Class equals Union of Connected Sets|Equivalence Class equals Union of Connected Sets]] === It needs to be shown that $C = C'$. {{:Equivalence of Definitions of Component/Equivalence Class equals Union of Connected Sets}}{{qed|lemma}} === [[Equivalence of Definitions of Component/Union of Connected Sets is Maximal Connected Set|Union of Connected Sets is Maximal Connected Set]] === {{:Equivalence of Definitions of Component/Union of Connected Sets is Maximal Connected Set}}{{qed|lemma}} === [[Equivalence of Definitions of Component/Maximal Connected Set is Union of Connected Sets|Maximal Connected Set is Union of Connected Sets]] === {{:Equivalence of Definitions of Component/Maximal Connected Set is Union of Connected Sets}}{{qed}}	0
Consider the [[Definition:Open Cover|open cover]] of $T$: :$\CC = \set {\set {x, p}: x \in S, x \ne p}$ As $S$ is [[Definition:Infinite|infinite]], then so is $\CC$, as we can set up a [[Definition:Bijection|bijection]] from $\phi: S \setminus \set p \leftrightarrow \CC$: :$\forall x \in S \setminus \set p: \map \phi x = \set {x, p}$ Hence $\CC$ has no [[Definition:Finite Subcover|finite subcover]]. The result follows by definition of [[Definition:Compact Topological Space|compactness]]. {{qed}}	0
:[[File:Sum of Sequences of Squares.jpg]] We can observe from the above diagram that: : $\displaystyle \forall n \in \N: \sum_{i \mathop = 1}^n i^2 = \sum_{i \mathop = 1}^n \left({\sum_{j \mathop = i}^n j}\right)$ Therefore we have: {{begin-eqn}} {{eqn | l = \sum_{i \mathop = 1}^n i^2 | r = \sum_{i \mathop = 1}^n \left({\sum_{j \mathop = i}^n j}\right) | c = }} {{eqn | r = \sum_{i \mathop = 1}^n \left( {\sum_{j \mathop = 1}^n j - \sum_{j \mathop = 1}^{i - 1} j} \right) | c = }} {{eqn | r = \sum_{i \mathop = 1}^n \left({\frac {n \left({n + 1}\right)} 2 - \frac {i \left({i - 1}\right)} 2}\right) | c = }} {{eqn | ll= \implies | l = 2 \sum_{i \mathop = 1}^n i^2 | r = n^2 \left({n + 1}\right) - \sum_{i \mathop = 1}^n i^2 + \sum_{i \mathop = 1}^n i | c = }} {{eqn | ll= \implies | l = 3 \sum_{i \mathop = 1}^n i^2 | r = n^2 \left({n + 1}\right) + \sum_{i \mathop = 1}^n i | c = }} {{eqn | ll= \implies | l = 3 \sum_{i \mathop = 1}^n i^2 | r = n^2 \left({n + 1}\right) + \frac {n \left({n + 1}\right)} 2 | c = [[Closed Form for Triangular Numbers]] }} {{eqn | ll= \implies | l = 6 \sum_{i \mathop = 1}^n i^2 | r = 2 n^2 \left({n + 1}\right) + n \left({n + 1}\right) | c = }} {{eqn | r = n \left({n + 1}\right) \left({2 n + 1}\right) | c = }} {{eqn | ll= \implies | l = \sum_{i \mathop = 1}^n i^2 | r = \frac {n \left({n + 1}\right) \left({2 n + 1}\right)} 6 | c = }} {{end-eqn}} {{qed}}	0
Assume that :$\complement_S\left({A}\right)$ is [[Definition:Irreducible Subset (Topology)|irreducible]]. Let $x, y \in \tau$ such that :$A = x \wedge y$ By definition of [[Definition:Topological Space|topological space]]: :$x \cap y \in \tau$ By [[Meet in Inclusion Ordered Set]]: :$x \wedge y = x \cap y$ By [[De Morgan's Laws (Set Theory)/Relative Complement/Complement of Intersection]]: :$\complement_S\left({A}\right) = \complement_S\left({x}\right) \cup \complement_S\left({y}\right)$ By definition: :$\complement_S\left({x}\right)$ and $\complement_S\left({y}\right)$ are [[Definition:Closed Set (Topology)|closed]]. By definition of [[Definition:Irreducible Subset (Topology)|irreducible]]: :$\complement_S\left({A}\right) = \complement_S\left({x}\right)$ or $\complement_S\left({A}\right) = \complement_S\left({y}\right)$ Thus by [[Relative Complement of Relative Complement]]: :$A = x$ or $A = y$ {{qed}}	0
Let $X$ be a [[Definition:Set|set]]. Let $I$ be an [[Definition:Indexing Set|indexing set]]. Let $\family {\struct {Y_i, \tau_i} }_{i \mathop \in I}$ be an [[Definition:Indexed Family|indexed family]] of [[Definition:Topological Space|topological spaces]] [[Definition:Indexing Set|indexed]] by $I$. Let $\family {f_i: Y_i \to X}_{i \mathop \in I}$ be an [[Definition:Indexed Family|indexed family]] of [[Definition:Mapping|mappings]] [[Definition:Indexing Set|indexed]] by $I$. {{TFAE|def = Final Topology}}	0
Let $f: \R \to \R$ be a [[Definition:Continuous Real Function|continuous real function]]. Let $a \in \R$ such that $f \left({a}\right) > 0$. Then: :$\exists k \in \R_{>0}: \exists \delta \in \R_{>0}: \forall x \in \left[{a - \delta \,.\,.\, a + \delta}\right]: f \left({x}\right) \ge k$	0
Let $M_1 = \left({A_1, d_1}\right), M_2 = \left({A_2, d_2}\right), \ldots, M_n = \left({A_n, d_n}\right)$ be [[Definition:Metric Space|metric spaces]]. Let $\displaystyle \mathcal A = \prod_{i \mathop = 1}^n A_i$ be the [[Definition:Finite Cartesian Product|cartesian product]] of $A_1, A_2, \ldots, A_n$. Let $d_\infty: \mathcal A \times \mathcal A \to \R$ be the [[Definition:Chebyshev Distance|Chebyshev distance]] on $\mathcal A$: : $\displaystyle d_\infty \left({x, y}\right) = \max_{i \mathop = 1}^n \left\{ {d_i \left({x_i, y_i}\right)}\right\}$ where $x = \left({x_1, x_2, \ldots, x_n}\right), y = \left({y_1, y_2, \ldots, y_n}\right) \in \mathcal A$. For $i \in \left\{ {1, 2, \ldots, n}\right\}$, let $U_i$ be [[Definition:Open Set (Metric Space)|open]] in $M_i$. Then $\displaystyle \prod_{i \mathop = 1}^n U_i$ is [[Definition:Open Set (Metric Space)|open]] in $M = \left({\mathcal A, d_\infty}\right)$.	0
Let $T_A = \struct {S_A, \tau_A}$ and $T_B = \struct {S_B, \tau_B}$ be [[Definition:Topological Space|topological spaces]]. Let $\phi: T_A \to T_B$ be a [[Definition:Everywhere Continuous Mapping (Topology)|continuous]] [[Definition:Surjection|surjection]]. If $T_A$ is [[Definition:Compact Topological Space|compact]], then $T_B$ is also [[Definition:Compact Topological Space|compact]].	0
Let $T = \struct {S, \tau}$ be a [[Definition:Topological Space|topological space]]. Let $H \subseteq S$ be [[Definition:Closed Set (Topology)|closed]] in $T$. Let $K \subseteq S$ be [[Definition:Compact Topological Subspace|compact]] in $T$. Then $H \cap K$ is [[Definition:Compact Topological Subspace|compact]] in $T$.	0
From [[Limit Points in Excluded Point Space]], the only [[Definition:Limit Point of Set|limit point]] of $H$ is $p$. So by definition, all points of $H$ are [[Definition:Isolated Point of Subset|isolated in $H$]] except $p$. So if $H \ne \set p$, $H$ contains at least one point which is [[Definition:Isolated Point of Subset|isolated in $H$]]. As for $p$ itself, from [[Singleton Point is Isolated]] we have that $p$ is itself [[Definition:Isolated Point of Subset|isolated]] in $\set p$. So if $H = \set p$, $H$ also contains one point which is [[Definition:Isolated Point of Subset|isolated in $H$]]. Hence the result, by definition of [[Definition:Dense-in-itself|dense-in-itself]]. {{qed}}	0
While every [[Convergent Sequence is Bounded]], it does not follow that every [[Definition:Bounded Sequence|bounded sequence]] is [[Definition:Convergent Sequence|convergent]]. That is, there exist [[Definition:Bounded Sequence|bounded sequences]] which are [[Definition:Divergent Sequence|divergent]].	0
Let $T = \struct {S, \tau}$ be a [[Definition:Lindelöf Space|Lindelöf space]] which is also [[Definition:Countably Metacompact Space|countably metacompact]]. Then $T$ is [[Definition:Metacompact Space|metacompact]].	0
There is a [[Definition:Bijection|one-to-one correspondence]] between [[Definition:Prüfer Sequence|Prüfer sequences]] and [[Definition:Labeled Graph|labeled]] [[Definition:Tree (Graph Theory)|trees]]. That is, every [[Definition:Labeled Graph|labeled]] [[Definition:Tree (Graph Theory)|tree]] has a unique [[Definition:Prüfer Sequence|Prüfer sequence]] that defines it, and every [[Definition:Prüfer Sequence|Prüfer sequence]] defines just one [[Definition:Labeled Graph|labeled]] [[Definition:Tree (Graph Theory)|tree]].	0
By [[Cancellable Elements of Semigroup form Subsemigroup]], $\left({C, \circ {\restriction_C}}\right)$ is a [[Definition:Subsemigroup|subsemigroup]] of $\left({S, \circ}\right)$, where $\circ {\restriction_C}$ is the [[Definition:Restriction of Operation|restriction]] of $\circ$ to $C$. By [[Restriction of Commutative Operation is Commutative]], as $\left({C, \circ {\restriction_C}}\right)$ is a [[Definition:Algebraic Substructure|substructure]] of a [[Definition:Commutative Algebraic Structure|commutative structure]], it is also [[Definition:Commutative Algebraic Structure|commutative]]. From: : [[External Direct Product of Semigroups|the external direct product preserves the nature of semigroups]] : [[External Direct Product Commutativity|the external direct product preserves commutativity]] we see that $\left({S \times C, \oplus}\right)$ is a [[Definition:Commutative Semigroup|commutative semigroup]]. {{Qed}}	0
{{begin-eqn}} {{eqn | lo=\forall x, y \in A: | l=d \left({x, y}\right) + d \left({y, x}\right) | o=\ge | r=d \left({x, x}\right) | c=from $(M2)$ }} {{eqn | ll=\implies | l=2 d \left({x, y}\right) | o=\ge | r=0 | c=from $(M1')$ and $(M3)$ }} {{eqn | ll=\implies | l=d \left({x, y}\right) | o=\ge | r=0 }} {{end-eqn}} {{qed}} [[Category:Metric Spaces]] 7kxzz1voxpwwkchjinbb4k00ozu82bi	0
Let $L = \struct {S, \preceq, \tau}$ be a [[Definition:Complete Lattice|complete]] [[Definition:Scott Topology|Scott]] [[Definition:Topological Lattice|topological lattice]]. Let $D = \struct {\map \sigma L, \precsim}$ be an [[Definition:Inclusion Ordered Set|inclusion ordered set]] of the [[Definition:Scott Sigma|Scott sigma]] of $L$. Let $x \in S$. Then: :$\relcomp S {x^\preceq}$ is a [[Definition:Prime Element (Order Theory)|prime element]] in $D$ and: :$\relcomp S {x^\preceq} \ne S$	0
Let $N$ be a [[Definition:Neighborhood (Metric Space)|neighborhood]] of $a$ in $M$. Then by definition: :$\exists \epsilon' \in \R_{>0}: \map {B_{\epsilon'} } a \subseteq N$ where $\map {B_{\epsilon'} } a$ is the [[Definition:Open Ball|open $\epsilon'$-ball at $a$]]. From [[Open Ball in Real Number Line is Open Interval]]: :$\map {B_{\epsilon'} } a = \openint {a - \epsilon'} {a + \epsilon'}$ Let $\epsilon \in \R_{>0}: \epsilon < \epsilon'$. Then by definition of [[Definition:Closed Real Interval|closed interval]] and [[Definition:Open Real Interval|open interval]]: :$\closedint {a - \epsilon} {a + \epsilon} \subseteq \openint {a - \epsilon'} {a + \epsilon'}$ From [[Subset Relation is Transitive]]: :$\closedint {a - \epsilon} {a + \epsilon} \subseteq N$ Also by definition of [[Definition:Closed Real Interval|closed interval]] and [[Definition:Open Real Interval|open interval]]: :$\openint {a - \epsilon} {a + \epsilon} \subseteq \closedint {a - \epsilon} {a + \epsilon}$ From [[Open Real Interval is Open Ball]], $\openint {a - \epsilon} {a + \epsilon}$ is the [[Definition:Open Ball|open $\epsilon$-ball at $a$]]. Thus by definition, $\closedint {a - \epsilon} {a + \epsilon}$ is a [[Definition:Neighborhood (Metric Space)|neighborhood]] of $a$ in $M$. Hence there exists a [[Definition:Neighborhood (Metric Space)|neighborhood]] $\closedint {a - \epsilon} {a + \epsilon}$ of $a$ which is a [[Definition:Subset|subset]] of $N$. Hence the result by definition of [[Definition:Basis for Neighborhood System|basis for the neighborhood system]] of $a$. {{qed}}	0
Let $T = \left({S, \tau}\right)$ be a [[Definition:Topological Space|topological space]]. Let every [[Definition:Ultrafilter on Set|ultrafilter]] on $S$ be [[Definition:Convergent Filter|convergent]]. Then every [[Definition:Filter on Set|filter]] on $S$ has a [[Definition:Limit Point of Filter|limit point]].	0
Let $\struct {\R, \tau_d}$ be the [[Definition:Real Number Line with Euclidean Topology|real number line with the usual (Euclidean) topology]]. Let $\closedint a b$ be a [[Definition:Closed Real Interval|closed interval]] of $\R$. Then $\closedint a b$ is [[Definition:Regular Closed Set|regular closed]] in $\struct {\R, \tau_d}$.	0
Let $G$ be a [[Definition:Graph (Graph Theory)|graph]]. Let $v$ be a [[Definition:Cut-Vertex|cut-vertex]] of $G$. Then the [[Definition:Vertex Deletion|vertex deletion]] $G - v$ contains $2$ or more [[Definition:Component (Graph Theory)|components]].	0
From [[Power Set of Finite Set is Finite]], the [[Definition:Power Set|power set]] of $S$ is [[Definition:Finite Set|finite]]. Since the [[Definition:Topology|topology]] $\tau$ is by definition a [[Definition:Set of Sets|set]] of [[Definition:Subset|subsets]] of $S$, it follows that $\tau$ is [[Definition:Finite Set|finite]] as well. Let $\VV$ be an [[Definition:Open Cover|open cover]] of $S$. By definition $\VV \subseteq \tau$ and so is also a [[Definition:Finite Set|finite set]]. From [[Set is Subset of Itself]], $\VV \subseteq \VV$. Thus by definition $\VV$ is a [[Definition:Finite Subcover|finite subcover]] of $\VV$. The result follows by definition of [[Definition:Compact Topological Space|compact]]. {{qed}}	0
Let $T = \struct {S, \tau}$ be [[Definition:Strongly Locally Compact Space|strongly locally compact]]. Let $x \in S$. By definition, there exists an [[Definition:Open Set (Topology)|open set]] $U_x$ of $T$ such that: :$x \in U_x$ :${U_x}^-$ (the [[Definition:Closure (Topology)|closure]] of $U_x$) is [[Definition:Compact Topological Subspace|compact]]. From [[Set is Subset of its Topological Closure]], $U_x \subseteq {U_x}^-$ and so $x \in {U_x}^-$. Thus $x$ is contained in a [[Definition:Compact Topological Subspace|compact]] [[Definition:Neighborhood of Point|neighborhood]]. As this holds for all $x$, $T$ is a [[Definition:Weakly Locally Compact Space|weakly locally compact]]. {{qed}}	0
We show that $\displaystyle d_r \left({x, y}\right) \ge d_t \left({x, y}\right)$, which is equivalent to proving that: :$\displaystyle \left({\sum_{i \mathop = 1}^n \left|{x_i - y_i}\right|^r}\right)^{1/r} \ge \left({\sum_{i \mathop = 1}^n \left|{x_i - y_i}\right|^t}\right)^{1/t}$ Let $\forall i \in \left[{1 \,.\,.\, n}\right]: s_i = \left|{x_i - y_i}\right|$. Suppose $s_k = 0$ for some $k \in \left[{1 \,.\,.\, n}\right]$. {{improve|Putting off the analysis of s_k being 0 until near the end of the proof should shorten it without losing any clarity.}} Then the problem reduces to the equivalent one of showing that: : $\displaystyle \left({\sum_{i \mathop = 1}^{n-1} \left|{x_i - y_i}\right|^r}\right)^{1/r} \ge \left({\sum_{i \mathop = 1}^{n-1} \left|{x_i - y_i}\right|^t }\right)^{1/t}$ that is, of reducing the index by $1$. Note that when $n = 1$, from simple algebra $d_r \left({x, y}\right) = d_t \left({x, y}\right)$. So, let us start with the assumption that $\forall i \in \left[{1 \,.\,.\, n}\right]: s_i > 0$. Let $\displaystyle u = \sum_{i \mathop = 1}^n \left|{x_i - y_i}\right|^r = \sum_{i \mathop = 1}^n s_i^r$, and $v = \dfrac 1 r$. From [[Derivative of Function to Power of Function]], $D_r \left({u^v}\right) = v u^{v-1} D_r \left({u}\right) + u^v \ln u D_r \left({v}\right)$. Here: :$\displaystyle D_r \left({u}\right) = \sum_{i \mathop = 1}^n s_i^r \ln s_i$ from [[Derivative of Exponential Function]] and [[Sum Rule for Derivatives]] :$D_r \left({v}\right) = - \dfrac 1 {r^2}$ from [[Power Rule for Derivatives]] In the case where $r=1$, we have: :$D_r \left({u^v}\right) = 0$ When $r > 1$, we have: {{begin-eqn}} {{eqn | l = D_r \left({\left({\sum_{i \mathop = 1}^n s_i^r}\right)^{1/r} }\right) | r = \dfrac 1 r \left({\sum_{i \mathop = 1}^n s_i^r}\right)^{1/ \left({r - 1}\right) } \left({\sum_{i \mathop = 1}^n s_i^r \ln s_i}\right) - \dfrac {\left({\sum_{i \mathop = 1}^n s_i^r}\right)^{1/r} \ln \left({\sum_{i \mathop = 1}^n s_i^r}\right)} {r^2} | c = }} {{eqn | r = \dfrac {\left({\sum_{i \mathop = 1}^n s_i^r}\right)^{1/r} } r \left({\dfrac {\sum_{i \mathop = 1}^n s_i^r \ln s_i} {\sum_{i \mathop = 1}^n s_i^r} - \dfrac {\ln \left({\sum_{i \mathop = 1}^n s_i^r}\right)} r}\right) | c = }} {{eqn | r = \dfrac {\left({\sum_{i \mathop = 1}^n s_i^r}\right)^{1/r} } r \left({\dfrac {r \left({\sum_{i \mathop = 1}^n s_i^r \ln s_i}\right) - \left({\sum_{i \mathop = 1}^n s_i^r}\right) \ln \left({\sum_{i \mathop = 1}^n s_i^r}\right)} {r \left({\sum_{i \mathop = 1}^n s_i^r}\right)} }\right) | c = }} {{eqn | r = K \left({r \left({\sum_{i \mathop = 1}^n s_i^r \ln s_i}\right) - \left({\sum_{i \mathop = 1}^n s_i^r}\right) \ln \left({\sum_{i \mathop = 1}^n s_i^r}\right)}\right) | c = where $\displaystyle K = \dfrac {\left({\sum_{i \mathop = 1}^n s_i^r}\right)^{1/r} } {r^2 \left({\sum_{i \mathop = 1}^n s_i^r}\right)} > 0$ }} {{eqn | r = K \left({\sum_{i \mathop = 1}^n s_i^r \ln \left({s_i^r}\right) - \left({\sum_{i \mathop = 1}^n s_i^r}\right) \ln \left({\sum_{i \mathop = 1}^n s_i^r}\right)}\right) | c = [[Logarithms of Powers]] }} {{eqn | r = K \left({\sum_{j \mathop = 1}^n \left({s_j^r \left({\ln \left({s_j^r}\right) - \ln \left({\sum_{i \mathop = 1}^n s_i^r}\right)}\right)}\right)}\right) | c = }} {{eqn | r = K \left({\sum_{j \mathop = 1}^n \left({s_j^r \ln \left({\frac {s_j^r} {\sum_{i \mathop = 1}^n s_i^r} }\right)}\right)}\right) | c = }} {{end-eqn}} where $K > 0$ because all of $s_i, r > 0$. For the same reason, $\displaystyle \dfrac{s_j^r} {\sum_{i \mathop = 1}^n s_i^r} < 1$ for all $j \in \left\{ {1, \ldots, n}\right\}$. From [[Logarithm of 1 is 0]] and [[Logarithm is Strictly Increasing]], their logarithms are therefore negative. So for $r > 1$: : $\displaystyle D_r \left({\left({\sum_{i \mathop = 1}^n s_i^r}\right)^{1/r}}\right) < 0$ So, from [[Derivative of Monotone Function]], it follows that (given the conditions on $r$ and $s_i$) $\displaystyle \left({\sum_{i \mathop = 1}^n s_i^r}\right)^{1/r}$ is [[Definition:Decreasing Real Function|decreasing]]. As we assumed $r \le t$, we have $d_r \left({x, y}\right) \ge d_t \left({x, y}\right)$. {{qed|lemma}}	0
Let $\struct {X, \tau}$ be a [[Definition:Topological Space|topological space]]. Then $\struct {X, \tau}$ is a [[Definition:Hausdorff Space|Hausdorff space]] {{iff}}: :For all $x, y \in X$ such that $x \ne y$, there exists an [[Definition:Open Set (Topology)|open set]] $U$ such that $x \in U$ and $y \notin U^-$, where $U^-$ is the [[Definition:Topological Closure|closure]] of $U$.	0
Let $T = \struct {S, \tau_p}$ be a [[Definition:Particular Point Topology|particular point space]]. Then $p$ is [[Definition:Dispersion Point|dispersion point]] of $T$.	0
=== Necessary Condition === Follows directly from the definitions of the [[Definition:Topology Generated by Synthetic Sub-Basis/Definition 1|generated topology]] and an [[Definition:Analytic Sub-Basis|analytic sub-basis]]. {{qed|lemma}} === Sufficient Condition === Suppose that $\mathcal S$ is an [[Definition:Analytic Sub-Basis|analytic sub-basis]] for $\tau$. Let $\tau'$ be the [[Definition:Topology Generated by Synthetic Sub-Basis|topology on $X$ generated by the synthetic sub-basis $\mathcal S$]]. By [[Definition:Topology Generated by Synthetic Sub-Basis/Definition 1|definition $1$ of the generated topology]] and the definition of an [[Definition:Analytic Sub-Basis|analytic sub-basis]], we have $\tau \subseteq \tau'$. By [[Definition:Topology Generated by Synthetic Sub-Basis/Definition 2|definition $2$ of the generated topology]], it follows that $\tau' \subseteq \tau$. By definition of [[Definition:Set Equality|set equality]]: : $\tau = \tau'$ {{qed}} [[Category:Topological Bases]] hv5mlxe6etmjncam5p72a5gh3a78g00	0
Let $n \in \N$. Let $A$ be the set of all [[Definition:Ordered Tuple|ordered $n+1$-tuples]] $\tuple {x_1, x_2, \ldots, x_{n + 1} }$ of [[Definition:Real Number|real numbers]] such that $x_{n + 1} = 0$. Let $d: A \times A \to \R$ be the [[Definition:Real-Valued Function|function]] defined as: :$\displaystyle \forall x, y \in A: \map d {x, y} = \max_{i \mathop = 1}^n \set {\size {x_i - y_i} }$ where $x = \tuple {x_1, x_2, \ldots, x_{n + 1} }, y = \tuple {y_1, y_2, \ldots, y_{n + 1} }$. Then $\struct {A, d}$ is a [[Definition:Metric Subspace|metric subspace]] of $\struct {\R^{n + 1}, d_\infty}$ where $d_\infty$ is the [[Definition:Chebyshev Distance/Real Vector Space|Chebyshev distance]] on the [[Definition:Real Vector Space|real vector space]] $\R^{n + 1}$.	0
We have that: : A [[Finite Topological Space is Compact]]. : A [[Finite Space is Sequentially Compact]]. The remaining properties are demonstrated in: : [[Sequence of Implications of Global Compactness Properties]] : [[Sequence of Implications of Local Compactness Properties]] : [[Sequence of Implications of Paracompactness Properties]] {{qed}} [[Category:Finite Topological Spaces]] [[Category:Compact Spaces]] 41h380j70f2hy79vyo0sjcjwk1rof12	0
Let $M_1 = \left({X_1, d_1}\right), M_2 = \left({X_2, d_2}\right), M_3 = \left({X_3, d_3}\right)$ be [[Definition:Metric Space|metric spaces]]. Let $f: M_1 \to M_2$ be [[Definition:Continuous at Point of Metric Space|continuous at $a \in X_1$]]. Let $g: M_2 \to M_3$ be [[Definition:Continuous at Point of Metric Space|continuous at $f \left({a}\right) \in X_2$]]. Then their [[Definition:Composition of Mappings|composite]] $g \circ f: M_1 \to M_3$ is [[Definition:Continuous at Point of Metric Space|continuous at $a \in X_1$]].	0
Let $T = \left({S, \tau}\right)$ be a [[Definition:Hausdorff Space|Hausdorff]] [[Definition:Topological Space|topological space]]. === [[Definition:Locally Compact Hausdorff Space/Definition 1|Definition 1]] === {{:Definition:Locally Compact Hausdorff Space/Definition 1}} === [[Definition:Locally Compact Hausdorff Space/Definition 2|Definition 2]] === {{:Definition:Locally Compact Hausdorff Space/Definition 2}}	0
By definition, an [[Definition:Open Set in Normed Vector Space|open set]] $S \subseteq X$ is one where every [[Definition:Point|point]] inside it is an [[Definition:Element|element]] of an [[Definition:Open Ball|open ball]] contained entirely within that [[Definition:Set|set]]. That is, there are no [[Definition:Point|points]] in $S$ which have an [[Definition:Open Ball in Normed Vector Space|open ball]] some of whose [[Definition:Element|elements]] are not in $S$. As there are no [[Definition:Element|elements]] in $\O$, the result follows [[Definition:Vacuous Truth|vacuously]]. {{qed}}	0
Let $S$ be a [[Definition:Set|set]]. Let $\tau$ be the [[Definition:Maximal Set|minimal]] [[Definition:Subset|subset]] of the [[Definition:Power Set|power set]] $\powerset S$ such that $\struct {S, \tau}$ is a [[Definition:Compact Topological Space|compact topological space]]. Then it is not necessarily the case that $\struct {S, \tau}$ is a [[Definition:Hausdorff Space|Hausdorff space]].	0
The [[Definition:L1 Metric/Closed Real Interval|$L^1$ metric]] on $X$ is defined as: :$\displaystyle \forall f, g \in S: d_1 \left({f, g}\right) := \int_a^b \left\vert{f \left({t}\right) - g \left({t}\right)}\right\vert \ \mathrm d t$ Let $\epsilon \in \R_{>0}$. Let $f \in X$. Let $\delta = \epsilon$. Then: {{begin-eqn}} {{eqn | lo= \forall g \in X: | l = d_1 \left({f, g}\right) | o = < | r = \delta | c = }} {{eqn | ll= \implies | l = \int_a^b \left\vert{f \left({t}\right) - g \left({t}\right)}\right\vert \ \mathrm d t | o = < | r = \delta | c = Definition of [[Definition:L1 Metric/Closed Real Interval|$L^1$ Metric]] }} {{eqn | ll= \implies | l = \left\vert{\int_a^b \left({f \left({t}\right) - g \left({t}\right)}\right) \ \mathrm d t}\right\vert | o = < | r = \delta | c = [[Absolute Value of Definite Integral]] }} {{eqn | ll= \implies | l = \left\vert{\int_a^b f \left({t}\right) \ \mathrm d t - \int_a^b g \left({t}\right) \ \mathrm d t}\right\vert | o = < | r = \delta | c = [[Linear Combination of Integrals]] }} {{eqn | ll= \implies | l = \left\vert{I \left({f}\right) - I \left({g}\right)}\right\vert | o = < | r = \delta | c = Definition of $I$ }} {{eqn | ll= \implies | l = d \left({I \left({f}\right), I \left({g}\right)}\right) | o = < | r = \delta | c = Definition of $d$ }} {{eqn | ll= \implies | l = d \left({I \left({f}\right), I \left({g}\right)}\right) | o = < | r = \epsilon | c = Definition of $\delta$ }} {{end-eqn}} Thus it has been demonstrated that: :$\forall \epsilon \in \R_{>0}: \exists \delta \in \R_{>0}: \forall g \in X: d_1 \left({f, g}\right) < \delta \implies d \left({I \left({f}\right), I \left({g}\right)}\right) < \epsilon$ Hence by definition of [[Definition:Continuous at Point of Metric Space|continuity at a point]], $I$ is [[Definition:Continuous at Point of Metric Space|continuous]] at $f$. As $f$ is chosen arbitrarily, it follows that $I$ is [[Definition:Continuous at Point of Metric Space|continuous]] for all $f \in X$. The result follows by definition of [[Definition:Continuous Mapping (Metric Spaces)|continuous mapping]]. {{qed}}	0
Let $\struct {R, \norm {\,\cdot\,} }$ be a [[Definition:Normed Division Ring|normed division ring]] with [[Definition:Non-Archimedean Division Ring Norm|non-Archimedean norm]] $\norm {\,\cdot\,}$. Let $\sequence {x_n}$ be a [[Definition:Sequence|sequence]] in $R$. Let $\displaystyle \lim_{n \mathop \to \infty} \norm {x_{n + 1} - x_n} = 0$. Then: :$\sequence {x_n}$ is a [[Definition:Cauchy Sequence (Normed Division Ring)|Cauchy sequence]].	0
Let $\closedint a b$ be a [[Definition:Closed Real Interval|closed real interval]]. Let $f: \closedint a b \to \R$ be a [[Definition:Continuous Real Function|continuous function]]. Then $f$ is [[Definition:Uniformly Continuous Real Function|uniformly continuous]] on $\closedint a b$.	0
A [[Definition:Banach Space|Banach space]] is a [[Definition:Normed Vector Space|normed vector space]], where a [[Definition:Cauchy Sequence|Cauchy sequence]] [[Definition:Convergent Sequence in Normed Vector Space|converges]] {{WRT}} the supplied [[Definition:Norm on Vector Space|norm]]. To prove the theorem, we need to show that a [[Definition:Cauchy Sequence in Normed Vector Space|Cauchy sequence]] in $\struct {\ell^p, \norm {\,\cdot\,}_p}$ [[Definition:Convergent Sequence in Normed Vector Space|converges]]. We take a [[Definition:Cauchy Sequence in Normed Vector Space|Cauchy sequence]] $\sequence {x_n}_{n \mathop \in \N}$ in $\struct {\ell^p, \norm {\,\cdot\,}_p}$. Then we consider the $k$th component and show, that a [[Definition:Real Cauchy Sequence|real Cauchy sequence]] $\sequence {x_n^{\paren k}}_{n \mathop \in \N}$ [[Definition:Convergent Real Sequence|converges]] in $\struct {\R, \size {\, \cdot \,}}$ with the [[Definition:Limit of Real Sequence|limit]] $x^{\paren k}$ and denote the entire set as $\mathbf x$. Finally, we show that $\sequence {\mathbf x_n}_{n \in \N}$, composed of components $x_n^{\paren k},$ [[Definition:Convergent Sequence in Normed Vector Space|converges]] in $\struct {\ell^p, \norm {\,\cdot\,}_p}$ with the [[Definition:Limit of Sequence in Normed Vector Space|limit]] $\mathbf x$. Let $\sequence {\mathbf x_n}_{n \mathop \in \N}$ be a [[Definition:Cauchy Sequence|Cauchy sequence]] in $\struct {\ell^p, \norm{\, \cdot \,}_p}$. Denote the $k$th component of $\mathbf x_n$ by $x_n^{\paren k}$. === $\sequence {x_n^{\paren k}}_{n \mathop \in \N}$ converges in $\struct {\R, \size {\, \cdot \,}}$=== Let $\epsilon >0$. Then: :$\displaystyle \exists N \in \N : \forall m,n \in \N : m,n > N : \norm {\mathbf x_n - \mathbf x_m}_p < \epsilon$ For same $N, m, n$ consider $\size {x_n^{\paren k} - x_m^{\paren k} } $: {{begin-eqn}} {{eqn | l = \size {x_n^{\paren k} - x_m^{\paren k} } | r = \paren {\size {x_n^{\paren k} - x_m^{\paren k} }^p}^{\frac 1 p} }} {{eqn | o = \le | r = \paren {\sum_{k \mathop = 0}^\infty \size {x_n^{\paren k} - x_m^{\paren k} }^p}^{\frac 1 p} }} {{eqn | r = \norm {\mathbf x_n - \mathbf x_m}_p | c = {{defof|P-Norm}} }} {{eqn | o = < | r = \epsilon }} {{end-eqn}} Hence, $\sequence {x_n^{\paren k}}_{n \mathop \in \N}$ is a [[Definition:Cauchy Sequence|Cauchy sequence]] in $\struct {\R, \size {\, \cdot \,}}$. From [[Real Number Line is Complete Metric Space]], $\R$ is a [[Definition:Complete Metric Space|complete metric space]]. Consequently, $\sequence {x_n^{\paren k}}_{n \mathop \in \N}$ [[Definition:Convergent Sequence|converges]] in $\struct {\R, \size {\, \cdot \,}}$. {{qed|lemma}} Denote the [[Definition:Limit of Real Sequence|limit]] $\displaystyle \lim_{n \mathop \to \infty} \sequence {x_n^{\paren k}}_{n \mathop \in \N} = x^{\paren k}$. Denote $\sequence {x^{\paren k}}_{k \mathop \in \N} = \mathbf x$. === $\mathbf x$ belongs to $\ell^p$ === Let $\epsilon > 0$. Then: :$\exists N \in \N : \forall n,m \in \N : n,m > N : \norm {\mathbf x_n - \mathbf x_m}_p < \epsilon$. Let $K \in \N$, $1 \le p < \infty$. Then: {{begin-eqn}} {{eqn | l = \sum_{k \mathop = 1}^K \size {x_n^{\paren k} - x_m^{\paren k} }^p | o = \le | r = \sum_{k \mathop = 1}^\infty \size {x_n^{\paren k} - x_m^{\paren k} }^p }} {{eqn | r = \norm {\mathbf x_n - \mathbf x_m}_p^p }} {{eqn | o = < | r = \epsilon^p }} {{eqn | o = < | r = \infty }} {{end-eqn}} Take the [[Definition:Limit of Rational Sequence|limit]] $m \to \infty$: :$\displaystyle \sum_{k \mathop = 1}^K \size {x_n^{\paren k} - x^{\paren k}}^p < \infty$ Since $K$ was arbitrary, we can take the [[Definition:Limit of Real Sequence|limit]] $K \to \infty$. By [[Definition:P-Sequence Space|definition]], $\forall k \in \N : x_n^{\paren k} - x^{\paren k} \in \ell^p$. In other words, $\mathbf x_n - \mathbf x \in \ell^p$. But, by [[Definition:Assumption|assumption]], $\mathbf x_n \in \ell^p$. Therefore: :$\paren {\mathbf x - \mathbf x_n} + \mathbf x_n = \mathbf x \in \ell^p$ {{qed|lemma}} === $\sequence {\mathbf x_n}_{n \mathop \in \N}$ converges in $\struct {\ell^p, \norm {\, \cdot \,}_p}$ to $\mathbf x$=== Let $1 \le p < \infty$. Let $\epsilon > 0$. Fix $N \in \N$, $m > N$. Then: :$\displaystyle \forall n > N : \norm {\mathbf x_n - \mathbf x_m}_p < \epsilon$ We have that $\sequence {x_n^{\paren k}}_{n \mathop \in \N}$ [[Definition:Convergent Real Sequence|converges]] in $\struct {\R, \size {\, \cdot \,}}$. Take the [[Definition:Limit of Real Sequence|limit]] $m \to \infty$: {{begin-eqn}} {{eqn | l = \lim_{m \mathop \to \infty} \norm {\mathbf x_n - \mathbf x_m}_p | r = \lim_{m \mathop \to \infty} \paren {\sum_{k \mathop = 0}^\infty \size {x_n^{\paren k} - x_m^{\paren k} }^p }^{\frac 1 p} }} {{eqn | r = \paren {\sum_{k \mathop = 0}^\infty \size {x_n^{\paren k} - x^{\paren k} }^p }^{\frac 1 p} | c = [[Limit of Composite Function]] }} {{eqn | r = \norm {\mathbf x_n - \mathbf x}_p }} {{eqn | o = < | r = \epsilon }} {{end-eqn}} So $\sequence {\mathbf x_n}_{n \mathop \in \N}$ [[Definition:Convergent Sequence in Normed Vector Space|converges]] in $\struct {\ell^p, \norm {\, \cdot \,}_p}$. {{qed}}	0
Let $\family {T_i}_{i \mathop \in I} = \family {\struct{S_i, \tau_i}}_{i \mathop \in I}$ be an [[Definition:Indexed Family|indexed family]] of [[Definition:Topological Space|topological spaces]] where $I$ is an arbitrary [[Definition:Indexing Set|index set]]. Let $\displaystyle S = \prod_{i \mathop \in I} S_i$ be the corresponding [[Definition:Product Space of Topological Spaces|product space]]. Let $\tau$ denote the [[Definition:Tychonoff Topology|Tychonoff topology]] on $S$. Let $\pr_i: S \to S_i$ be the corresponding [[Definition:Projection (Mapping Theory)|projection]] from $S$ onto $S_i$. Then $\pr_i$ is [[Definition:Continuous Mapping (Topology)|continuous]] for all $i \in I$.	0
{{ProofWanted}} [[Category:Continuous Functions]] 3zxv4kbrjj9spwd8xn2jozgn9coeict	0
Let $A$ and $B$ be [[Definition:Closed Set (Topology)|closed]] in $X$. Let $f : A \to Y$ and $g : B \to Y$ be [[Definition:Continuous Mapping on Set|continuous mappings]] that [[Definition:Agreement of Mappings|agree]] on $A \cap B$. Then the mapping $f \cup g : A \cup B \to Y$ is [[Definition:Continuous Mapping on Set|continuous]].	0
By [[Form of Geometric Sequence of Integers from One]], the general [[Definition:Term of Geometric Sequence|term]] of $G_n$ can be expressed as: :$a_j = q^j$ for some $q \in \Z$. Let $k \nmid m$. Then by the [[Division Theorem]] there exists a unique $q \in \Z$ such that: :$m = k q + b$ for some $b$ such that $0 < b < k$. Thus: :$a_m = a^{k q} a^b$ which is not a [[Definition:Integer Power|power]] of $k$. {{qed}} {{Euclid Note|10|IX}}	0
Let $T = \left({S, \tau}\right)$ be a [[Definition:Topological Space|topological space]] which is [[Definition:Irreducible Space|irreducible]]. Then $T$ is not necessarily [[Definition:Path-Connected Space|path-connected]].	0
A set $U$ is [[Definition:Closed Set (Topology)|closed]] in a [[Definition:Topology|topology]] $\tau$ {{iff}}: :$\relcomp S U \in \tau$ where $\relcomp S U$ denotes the [[Definition:Relative Complement|complement]] of $U$ in $S$. That is, the [[Definition:Closed Set (Topology)|closed sets]] are the [[Definition:Relative Complement|complements]] of the [[Definition:Open Set (Topology)|open sets]]. From [[Open Sets in Indiscrete Topology]], in $\tau = \set {\O, S}$, the only [[Definition:Open Set (Topology)|open sets]] are $\O$ and $S$. Hence the only [[Definition:Closed Set (Topology)|closed sets]] in the [[Definition:Indiscrete Topology|indiscrete topology]] on $S$ are: :$\relcomp S \O = S$ from [[Relative Complement of Empty Set]] and: :$\relcomp S S = \O$ from [[Relative Complement with Self is Empty Set]] as stated. {{qed}}	0
We have from [[Closed Set of Countable Fort Space is G-Delta|Closed Set of Countable Fort Space is $G_\delta$]] that every [[Definition:Closed Set (Topology)|closed set]] in $T$ is a [[Definition:G-Delta Set|$G_\delta$ set]]. From [[Fort Space is T5|Fort Space is $T_5$]] and [[T5 Space is T4 Space|$T_5$ Space is $T_4$ Space]], we have that a [[Definition:Fort Space|Fort space]] is a [[Definition:T4 Space|$T_4$ space]]. From [[Fort Space is T1|Fort Space is $T_1$]] it follows by definition that $T$ is a [[Definition:Perfectly Normal Space|perfectly normal space]]. {{qed}}	0
Let $A \subseteq \R$ be the [[Definition:Set|set]] of all points on $\R$ defined as: :$A := \set {\dfrac 1 n : n \in \Z_{>0} }$ Let $M = \struct {A, \tau_d}$ be the [[Definition:Integer Reciprocal Space|integer reciprocal space]] under the [[Definition:Euclidean Topology on Real Number Line|usual (Euclidean) topology]]. Let $\sequence {x_n}$ be a [[Definition:Sequence|sequence]] in $A$ that [[Definition:Convergent Sequence in Metric Space|converges]] to the [[Definition:Limit of Sequence (Metric Space)|limit]] $l \in A$. From [[Integer Reciprocal Space contains Cauchy Sequence with no Limit Point]], $\sequence {x_n}$ is a [[Definition:Cauchy Sequence in Metric Space|Cauchy sequence]] in $M$ which does not [[Definition:Convergent Sequence in Metric Space|converge]] in $M$. {{qed}}	0
Suppose $T$ is a [[Definition:T3 Space|$T_3$ space]]. As $S_\alpha \ne \O$ we also have $S \ne \O$ by the [[Axiom:Axiom of Choice|axiom of choice]]. Let $\alpha \in I$. From [[Subspace of Product Space Homeomorphic to Factor Space]], $\struct{S_\alpha, \tau_\alpha}$ is [[Definition:Homeomorphism (Topological Spaces)|homeomorphic]] to a [[Definition:Subspace|subspace]] $T_\alpha$ of $T$. From [[T3 Property is Hereditary|$T_3$ property is hereditary]], $T_\alpha$ is $T_3$. From [[T3 Space is Preserved under Homeomorphism]], $\struct {S_\alpha, \tau_\alpha}$ is $T_3$. As $\alpha \in I$ was arbitrary, the result follows.	0
Let $P_1$ and $P_2$ be [[Definition:Compact Topological Space|compactness properties]] and let: :$P_1 \implies P_2$ mean: :If a [[Definition:T3 Space|$T_3$ space]] $T$ satsifies property $P_1$, then $T$ also satisfies property $P_2$. Then the following sequence of implications holds: {| |- | align="center" | [[Definition:Second-Countable Space|Second-Countable]] || | align="center" | $\implies$ || | align="center" | [[Definition:Lindelöf Space|Lindelöf]] || |- | align="center" | $\Big\Downarrow$ || | align="center" | || | align="center" | $\Big\Downarrow$ || |- | align="center" | $\Downarrow$|| | align="center" | || | align="center" | [[Definition:Fully T4 Space|Fully $T_4$]] $\iff$ [[Definition:Paracompact Space|Paracompact]] || |- | align="center" | $\Big\Downarrow$ || | align="center" | || | align="center" | $\Big\Downarrow$ || |- | align="center" | [[Definition:T5 Space|$T_5$]] || | align="center" | $\implies$ || | align="center" | [[Definition:T4 Space|$T_4$]] || |- |}	0
This is an instance of [[P-Product Metric is Metric|$p$-Product Metric is Metric]]. {{qed}}	0
Let $P_a = \tuple {a_0, a_1, \ldots, a_n}$ be a [[Definition:Geometric Sequence|geometric sequence]] of [[Definition:Natural Number|natural numbers]] such that $a_0 \nmid a_1$. {{AimForCont}} $a_0 \divides a_k$ for some $k: 2 \le k \le n$. Let $b_0, b_1, \ldots, b_k$ be the least [[Definition:Natural Number|natural numbers]] which have the same [[Definition:Common Ratio of Geometric Sequence|common ratio]] as $a_0, a_1, \ldots, a_k$. These can be found by means of {{EuclidPropLink|book = VII|prop = 33|title = Least Ratio of Numbers}}. From {{EuclidPropLink|book = VII|prop = 14|title = Proportion of Numbers is Transitive}} :$a_0 : a_k = b_0 : b_k$ Also: :$a_0 : a_1 = b_0 : b_1$ and so as $a_0 \nmid a_1$ it follows by {{EuclidDefLink|VII|20|Proportional}}: :$b_0 \nmid b_1$ From [[One Divides all Integers]] it follows that: :$b_0 \ne 1$ From {{EuclidPropLink|book = VIII|prop = 3|title = Construction of Sequence of Numbers with Given Ratios}}: :$b_0 \perp b_k$ But as: :$a_0 : a_k = b_0 : b_k$ it follows that: :$a_0 \nmid a_k$ Now suppose $a_j \divides a_k$ such that $0 < j < k$. Let $b_j, \ldots, b_k$ be the least [[Definition:Natural Number|natural numbers]] which have the same [[Definition:Common Ratio of Geometric Sequence|common ratio]] as $a_j, \ldots, a_k$. These can be found by means of {{EuclidPropLink|book = VII|prop = 33|title = Least Ratio of Numbers}}. From {{EuclidPropLink|book = VII|prop = 14|title = Proportion of Numbers is Transitive}}: :$a_j : a_k = b_j : b_k$ The other cases follow similarly. {{qed}}	0
Follows directly from [[Subspace Topology is Initial Topology with respect to Inclusion Mapping]]. {{qed}}	0
We have by [[Definition:First Projection|definition of first projection]] that: :$\map {\pr_1} w = \map {\pr_1} {a, b} = a$ Then: {{begin-eqn}} {{eqn | l = \bigcup \bigcap w | r = \bigcup \bigcap \tuple {a, b} | c = Definition of $w$ }} {{eqn | r = \bigcup \bigcap \set {\set a, \set {a, b} } | c = {{Defof|Kuratowski Formalization of Ordered Pair|Ordered Pair}} }} {{eqn | r = \map \bigcup {\set a \cap \set {a, b} } | c = [[Intersection of Doubleton]] }} {{eqn | r = \bigcup \set a | c = {{Defof|Set Intersection}} }} {{eqn | r = a | c = [[Union of Singleton]] }} {{end-eqn}} {{qed}}	0
=== Necessary Condition === Follows directly from [[Topological Group is Hausdorff iff Identity is Closed]]. {{explain|How?}} {{qed|lemma}} === Sufficient Condition === Let $G$ be a [[Definition:Hausdorff Space|Hausdorff]] [[Definition:Topological Group|topological group]]. Let $H \leq G$ be a [[Definition:Closed Set (Topology)|closed]] [[Definition:Discrete Subgroup|discrete subgroup]]. Let $e$ be the [[Definition:Identity Element|identity]] of $G$. By [[Set in Discrete Topology is Clopen]], $\left\{{e}\right\}$ is [[Definition:Closed Set (Topology)|closed]] in $H$. By [[Closed Set in Topological Subspace/Corollary|Closed Set in Topological Subspace: Corollary]], $\left\{{e}\right\}$ is [[Definition:Closed Set (Topology)|closed]] in $G$. By [[Topological Group is Hausdorff iff Identity is Closed]], $G$ is [[Definition:Hausdorff Space|Hausdorff]]. {{qed}}	0
Let $A$ and $B$ be [[Definition:Class (Class Theory)|classes]]. Let $A \times B$ be the '''[[Definition:Cartesian Product|cartesian product]]''' of $A$ and $B$. Then $A \times B$ exists and is [[Definition:Unique|unique]].	0
Let $x, y \in Y_i$. Then for all $j \in I \setminus \set i$: :$x_j = z_j = y_j$ Let $\map {p_i} x = \map {p_i} y$. Then: :$x_i = y_i$ Thus: :$x = y$ It follows that $p_i$ is an [[Definition:Injection|injection]] by definition.	0
Let $\struct {\R^\omega, d}$ be the '''[[Definition:Fréchet Space (Functional Analysis)|Fréchet space]] on $\R^\omega$'''. Then $\struct {\R^\omega, d}$ is a [[Definition:Metric Space|metric space]].	0
Let $\struct {X, \tau}$ be a topological space. Let $\struct {Y, \norm {\, \cdot \, } }$ be a normed vector space. Let $f: X \to Y$ be continuous. Then $f$ is bounded.	0
We have that: :[[Real Vector Space is Vector Space]] :By [[Euclidean Space is Normed Space]], $\norm {\, \cdot \,}_2$ is a [[Definition:Norm on Vector Space|norm]] on $\R^n$ By [[Definition:Definition|definition]], $\struct {\R^n, \norm {\, \cdot \,}_2}$ is a [[Definition:Normed Vector Space|normed vector space]]. {{qed}}	0
Let $\tilde C$ be a [[Definition:Maximal Set|maximal]] [[Definition:Connected Set (Topology)|connected set]] of $T$ that contains $x$.	0
Let $\epsilon > 0$. For $x, y \in \C$ with $\map \Re x, \map \Re y \le a$: {{begin-eqn}} {{eqn | l = \cmod {e^x - e^y} | r = \cmod {e^y} \cdot \cmod {e^{x - y} - 1} }} {{eqn | r = e^{\map \Re y} \cdot \cmod {e^{x - y} - 1} | c = [[Absolute Value of Complex Exponential]] }} {{eqn | o = \le | r = e^a \cdot \cmod {e^{x - y} - 1} | c = [[Exponential is Strictly Increasing]] }} {{end-eqn}} Because [[Exponential Function is Continuous]], there exists $\delta > 0$ such that $\cmod {e^z - 1} < \epsilon$ for $\cmod z < \delta$. Thus if $\cmod {x - y} < \delta$, $\cmod {e^x - e^y} < e^a \epsilon$. Thus $\exp$ is [[Definition:Uniform Continuity|uniformly continuous]]. {{qed}} [[Category:Exponential Function]] [[Category:Uniform Continuity]] h0ifso4s6wse84h58wc3segqt32krs2	0
Let $\struct{S_\alpha, \tau_\alpha}$ is a [[Definition:T3 1/2 Space|$T_{3 \frac 1 2}$ space]] for each $\alpha \in I$. Let $x \in S$. Let $F$ be a [[Definition:Closed Set|closed subset]] of $S$ such that $x \notin F$. By definition of a [[Definition:Closed Set|closed subset]]: :$S \setminus F \in \tau$ By definition of the [[Definition:Tychonoff Topology|Tychonoff topology]] there exists an [[Definition:Open Set|open set]] $B$ of the [[Definition:Natural Basis|natural basis]] containing $x$ which is [[Definition:Disjoint|disjoint]] from $F$. By definition of the [[Definition:Natural Basis|natural basis]], $B$ is of the form: :$\map {\pr_{\alpha_1}^\gets} {U_1} \cap \dotsb \cap \map {\pr_{\alpha_n}^\gets} {U_n}$ where: :$\pr_{\alpha_k}$ is the [[Definition:Projection|$\alpha_k$-th projection]] from $S$ :$U_k$ is open in $S_{\alpha_k}$ for all $1 \le k \le n$ By definition of a [[Definition:T3 1/2 Space|$T_{3 \frac 1 2}$ space]], for each $1 \le k \le n$ there exists a [[Definition:Continuous Mapping (Topology)|continuous mapping]]: :$f_k: S_{\alpha_k} \to \closedint 0 1$ such that: :$\map {f_k} {x_{\alpha_k} } = 1$ and: :$\map {f_k} {S_{\alpha_k} \setminus U_k} = 0$ Let $g_k = f_k \circ \pr_{\alpha_k}$ be the [[Definition:Composite Mapping|composite mapping]] of $f_k$ with $\pr_{\alpha_k}$ for each $1 \le k \le n$. From [[Composite of Continuous Mappings is Continuous]] each $g_k: S \to \closedint 0 1$ is a [[Definition:Continuous Mapping (Topology)|continuous mapping]]. We define $g: S \to \closedint 0 1$ by setting: :$\map g y = \min \set {\map {g_k} {y_{\alpha_k} }: k = 1, \dotsc, n}$ From [[Minimum Rule for Continuous Functions]]: :$g$ is [[Definition:Continuous Mapping (Topology)|continuous]]. Now: {{begin-eqn}} {{eqn | l = \map g x | r = \min \set{\map {g_k} x : k = 1, \dotsc, n} | c = Definition of $g$ }} {{eqn | r = \min \set {\map {f_k} {\map {\pr_{\alpha_k} } x} : k = 1, \dotsc, n} | c = {{Defof|Composite Mapping}} }} {{eqn | r = \min \set {\map {f_k} {x_{\alpha_k} } : k = 1, \dotsc, n} | c = {{Defof|Projection}} }} {{eqn | r = \min \set {1 : k = 1, \dotsc, n} | c = Definition of $f_k$ }} {{eqn | r = 1 | c = {{Defof|Minimum}} }} {{end-eqn}} Let $y \in F$. By definition of [[Definition:Disjoint Sets|disjoint sets]]: :$\exists j \in \set {1, \dotsc, n} : y \notin \map {\pr_{\alpha_j}^\gets} {U_j}$ By definition of the [[Definition:Inverse Image Mapping|inverse image mapping]] of $\pr_{\alpha_j}$: :$y_{\alpha_j} \notin U_j$ Thus: :$\map {f_j} {y_{\alpha_j} } = 0$ So: {{begin-eqn}} {{eqn | l = \map g y | r = \min \set {\map {g_k} y : k = 1, \dotsc, n} | c = Definition of $g$ }} {{eqn | r = \min \set {\map {f_k} {\map {\pr_{\alpha_k} } y} : k = 1, \dotsc, n} | c = {{Defof|Composite Mapping}} }} {{eqn | r = \min \set {\map {f_k} {y_{\alpha_k} } : k = 1, \dotsc, n} | c = {{Defof|Projection}} }} {{eqn | r = 0 | c = {{Defof|Minimum}} and $\map {f_k} {y_{\alpha_k} } = 0$ }} {{end-eqn}} Therefore $T$ is a [[Definition:T3 1/2 Space|$T_{3 \frac 1 2}$ space]].	0
We first show that $\openint 0 1 \cap \Q$ is [[Definition:Totally Bounded Metric Space|totally bounded]]. Let $\epsilon \in \R_{> 0}$. By the [[Definition:Archimedean Property|Archimedean Property of $\R$]]: :$\exists n \in \N: \dfrac 1 n < \epsilon$ We pick the numbers $\dfrac i n \in \openint 0 1 \cap \Q$, where $i \in \N$ and $0 < i < n$. Then for all $x \in \openint 0 1 \cap \Q$ and $x \ge \dfrac 1 n$: {{begin-eqn}} {{eqn | l = \inf_{0 \mathop < i \mathop < n} \map d {x, \frac i n} | r = \inf_{0 \mathop < i \mathop < n} \size {x - \frac i n} | c = {{Defof|Euclidean Metric on Real Number Line}} }} {{eqn | o = \le | r = \size {\frac {n x} n - \frac {\floor {n x} } n } | c = $\floor {n x}$ is an [[Definition:Integer|integer]] strictly between $0$ and $n$ }} {{eqn | o = < | r = \frac 1 n | c = [[Real Number minus Floor]] }} {{eqn | o = < | r = \epsilon }} {{end-eqn}} For $x \le \dfrac 1 n$: {{begin-eqn}} {{eqn | l = \inf_{0 \mathop < i \mathop < n} \map d {x, \frac i n} | r = \inf_{0 \mathop < i \mathop < n} \size {x - \frac i n} | c = {{Defof|Euclidean Metric on Real Number Line}} }} {{eqn | o = \le | r = \frac 1 n - x }} {{eqn | o = \le | r = \frac 1 n }} {{eqn | o = < | r = \epsilon }} {{end-eqn}} This shows that $\openint 0 1 \cap \Q$ [[Definition:Totally Bounded Metric Space|totally bounded]]. From the [[Heine-Borel Theorem/Metric Space|Heine-Borel Theorem on a metric space]], $\openint 0 1 \cap \Q$ is [[Definition:Compact Metric Space|compact]] {{iff}} it is both [[Definition:Totally Bounded Metric Space|totally bounded]] and [[Definition:Complete Metric Space|complete]]. From [[Rational Number Space is not Complete Metric Space]] it follows that $\openint 0 1 \cap \Q$ is not [[Definition:Compact Metric Space|compact]]. {{qed}}	0
Let $T = \struct {X, \tau}$ be a [[Definition:Topological Space|topological space]]. Let $A \subseteq X$. Let: :$C$ be the set of [[Definition:Condensation Point|condensation points]] of $A$ :$W$ be the set of [[Definition:Omega-Accumulation Point|$\omega$-accumulation points]] of $A$ :$L$ be the set of [[Definition:Limit Point of Set|limit points]] of $A$ :$D$ be the set of [[Definition:Adherent Point|adherent points]] of $A$. Then: :$C \subseteq W \subseteq L \subseteq D$ That is: :Every [[Definition:Condensation Point|condensation point]] is an [[Definition:Omega-Accumulation Point|$\omega$-accumulation point]] :Every [[Definition:Omega-Accumulation Point|$\omega$-accumulation point]] is a [[Definition:Limit Point of Set|limit point]] :Every [[Definition:Limit Point of Set|limit point]] is an [[Definition:Adherent Point|adherent point]]. In general, the inclusions do not hold in the other direction.	0
Let $T = \struct {S, \tau}$ be the [[Definition:Arens-Fort Space|Arens-Fort space]]. Then $T$ is a [[Definition:Separable Space|separable space]].	0
Let $T = \left({S, \tau}\right)$ be a [[Definition:Hausdorff Space|$T_2$ (Hausdorff) space]]. Let $X \subseteq T$ be [[Definition:Finite Set|finite]]. From [[Separation Properties Preserved in Subspace]], it follows that $\left({X, \tau_X}\right)$ is also a [[Definition:Hausdorff Space|$T_2$ (Hausdorff) space]]. From [[T2 Space is T1 Space|$T_2$ Space is $T_1$ Space]] it follows that $\left({X, \tau_X}\right)$ is a [[Definition:Fréchet Space (Topology)|$T_1$ (Fréchet) space]]. From [[Finite T1 Space is Discrete|Finite $T_1$ Space is Discrete]], it follows that $\left({X, \tau_X}\right)$ is a [[Definition:Discrete Space|discrete space]]. The result follows from [[Topological Space is Discrete iff All Points are Isolated]]. {{qed}}	0
Let $G$ be an [[Definition:Undirected Network|undirected network]]. Let every [[Definition:Edge of Graph|edge]] of $G$ have a [[Definition:Unique|unique]] [[Definition:Weight (Network Theory)|weight]]. Let $e$ be an [[Definition:Edge of Graph|edge]] of $G$ that belongs to every [[Definition:Minimum Spanning Tree|minimum spanning tree]] of $G$. Let $e$ have maximum [[Definition:Weight (Network Theory)|weight]] in $G$. Then $e$ is a [[Definition:Bridge|bridge]] in $G$.	0
We have to check that $\BB = \set {\hointr a b: a, b \in \R}$ fulfills the axioms of being a [[Definition:Basis (Topology)|basis]] for a [[Definition:Topology|topology]]. From [[Equivalent Definitions of Synthetic Basis]] we only have to check that: :$(1): \quad \bigcup \BB = \R$ :$(2): \quad \forall B_1, B_2 \in \BB: \exists V \in \BB: V \subseteq B_1 \cap B_2$ We have that: :$\forall n \in \Z: \hointr n {n + 1} \in \BB$ :$\R = \displaystyle \bigcup_{n \mathop \in \Z} \hointr n {n + 1} \subseteq \bigcup \BB$ Hence $\R = \bigcup \BB$ and condition $(1)$ is fulfilled. Now take $ B_1, B_2 \in \BB$ where: :$B_1 = \hointr {a_1} {b_1}$ :$B_2 = \hointr {a_2} {b_2}$ Let $B_3$ be constructed as: :$B_3 := \hointr {\max \set {a_1, a_2} } {\min \set {b_1, b_2} } \in \BB$ From the method of construction, it is clear that $B_3 = B_1 \cap B_2$. Thus taking $V = B_3$, condition $(2)$ is fulfilled. {{qed}}	0
Let $\sequence {x_n}$ be a [[Definition:Bounded Real Sequence|bounded sequence in $\R$]]. By the [[Peak Point Lemma]], $\sequence {x_n}$ has a [[Definition:Monotone Real Sequence|monotone]] [[Definition:Subsequence|subsequence]] $\sequence {x_{n_r} }$. Since $\sequence {x_n}$ is [[Definition:Bounded Sequence|bounded]], so is $\sequence {x_{n_r} }$. Hence, by the [[Monotone Convergence Theorem (Real Analysis)]], the result follows. {{qed}}	0
For all $n \in \N_{\gt 0}$, let $n \cdot 1_R$ denote the sum of $1_R$ with itself $n$-times. That is: :$n \cdot 1_R = \underbrace {1_R + 1_R + \dots + 1_R}_{n \, times}$ Then: :$\norm {n \cdot 1_R} \le n$.	0
Let $U \in \tau$. Then $V = \R \setminus U$ is [[Definition:Compact Topological Subspace|compact]]. So by definition $V$ is [[Definition:Closed Set (Topology)|closed]] in the [[Definition:Euclidean Topology on Real Number Line|Euclidean topology]]. That is, $U = \R \setminus V$ is [[Definition:Open Set (Topology)|open]] in the [[Definition:Euclidean Topology on Real Number Line|Euclidean topology]]. That is, every [[Definition:Open Set (Topology)|open set]] in the [[Definition:Compact Complement Topology|compact complement topology]] is also [[Definition:Open Set (Topology)|open]] in the [[Definition:Euclidean Topology on Real Number Line|Euclidean topology]]. Hence the result, by definition of [[Definition:Coarser Topology|coarser topology]]. {{qed}}	0
Consider the [[Definition:Subset|subset]] $S$ of the [[Definition:Real Number|real numbers]] $\R$ defined as: :$S = \set {\dfrac 1 n: n \in \Z_{>0} }$ It is seen that: :$S = \set {1, \dfrac 1 2, \dfrac 1 3, \ldots}$ and hence $\sup S = 1$. Thus $\sup S \in S$. Consider the [[Definition:Subset|subset]] $T$ of the [[Definition:Real Number|real numbers]] $\R$ defined as: :$T = \set {-\dfrac 1 n: n \in \Z_{>0} }$ It is seen that: :$T = \set {-1, -\dfrac 1 2, -\dfrac 1 3, \ldots}$ and hence $\sup T = 0$. Thus $\sup T \notin T$. {{Qed}}	0
Let $S$ be a [[Definition:Set|set]] and let $\mathcal P \left({S}\right)$ be the [[Definition:Power Set|power set]] of $S$. Let $\Theta_S$ be the set of all [[Definition:Topology|topologies]] on $S$: :$\Theta_S = \left\{{\tau \in \mathcal P \left({S}\right): \tau}\right.$ is a [[Definition:Topology|topology]] on $\left.{S}\right\}$ Let $\Phi: \Theta_S \to \left\{{T, F}\right\}$ be a [[Definition:Propositional Function|propositional function]] on $\Theta_S$. Let $\vartheta \in \Theta_S$ have the [[Definition:Property|property]] that $\Phi \left({\vartheta}\right)$ and: :$\forall \tau \in \Theta_S: \Phi \left({\tau}\right) \implies \vartheta \subseteq \tau$ That is, $\vartheta$ is the [[Definition:Coarser Topology|coarsest topology]] on $S$ which satisfies the [[Definition:Propositional Function|propositional function]] $\Phi$. Then $\vartheta$ is the '''minimal topology satisfying $\Phi$'''. [[Category:Definitions/Topology|{{SUBPAGENAME}}]] htipkwppnixkuhckesep3patmjqucql	0
By definition, $\tau_d$ is the [[Definition:Topology Induced by Metric|topology induced]] by the [[Definition:Euclidean Metric on Real Number Plane|Euclidean metric]] $d$. Consider the [[Definition:Relative Complement|complement of $A$ in $\R^2$]]: :$A' := \R^2 \setminus A$ Thus: :$A := \set {\tuple {x, y} \in \R^2: x y < 1}$ Let $a = \tuple {x_a, y_a} \in A^2$. Let $\epsilon = \size {1 - x_a y_a}$. Then the [[Definition:Open Ball of Metric Space|open $\epsilon$-ball]] of $a$ in $\R^2$ lies entirely in $A'$. As $a$ is arbitrary, it follows that any such $a$ has an [[Definition:Open Ball of Metric Space|open $\epsilon$-ball]] of $a$ in $\R^2$ which lies entirely in $A'$. Thus, by definition, $A'$ is [[Definition:Open Set of Metric Space|open]] in $\R^2$. So, also by definition, $A$ is [[Definition:Closed Set of Metric Space|closed]] in $\R^2$. {{qed}}	0
:$\map f {x_1} \equiv 0 \pmod p$	0
Let $\struct {X, \preceq, \tau}$ be a [[Definition:Linearly Ordered Space|linearly ordered space]]. Let $C$ be a [[Definition:Subset|subset]] of $X$. Then $C$ is [[Definition:Closed Set (Topology)|closed]] in $X$ {{iff}} for all [[Definition:Non-Empty Set|non-empty]] [[Definition:Subset|subsets]] $S$ of $C$: :If $s \in X$ is a [[Definition:Supremum of Set|supremum]] or [[Definition:Infimum of Set|infimum]] of $S$ in $X$, then $s \in C$.	0
Let $\sequence {S_n}$ be a [[Definition:Sequence|sequence]] of [[Definition:Finite Set|finite sets]]. Let $\displaystyle \prod_{k \mathop = 1}^n S_k$ be their [[Definition:Finite Cartesian Product|Cartesian product]]. Then $\displaystyle \prod_{k \mathop = 1}^n S_k$ is also a [[Definition:Finite Set|finite set]].	0
By definition, a [[Definition:Perfect Set|perfect set]] is a set which equals its set of [[Definition:Limit Point of Set|limit points]]. Let $x \in \R$. Consider the [[Definition:Sequence|sequence]]: :$\left \langle{y_k}\right \rangle = x + \dfrac 1 k$ Then as $\left \langle{z_k}\right \rangle = \dfrac 1 k$ is a [[Definition:Basic Null Sequences|basic null sequence]] it follows that: :$\displaystyle \lim_{n \to \infty} \left \langle{y_k}\right \rangle = x$ Thus we see that $x$ is a [[Definition:Limit Point of Set|limit point]] of $S$. {{qed}} [[Category:Real Numbers]] [[Category:Perfect Sets]] p7sv1yxcmud2uc77hsudekcha3vuuoi	0
Let $f$ be a [[Definition:Real Function|real function]] that is everywhere [[Definition:Differentiable Real Function|differentiable]]. Let $I \subseteq \Dom f$ be a [[Definition:Real Interval|real interval]]. Then: :$f' \sqbrk I$ is a [[Definition:Real Interval|real interval]] where $f'$ denotes the [[Definition:Derivative|derivative]] of $f$	0
Take any two [[Definition:Non-Adjacent Vertices (Graph Theory)|non-adjacent vertices]] $u, v \in G$. Then: :$\displaystyle \deg u + \deg v \ge \frac n 2 + \frac n 2 = n$ The result follows by a direct application of [[Ore's Theorem]]. {{qed}}	0
By [[Subgroup of Real Numbers is Discrete or Dense]], there exists $a\in \R$ such that $G=a\Z$. If $a=0$, then $G$ is [[Definition:Closed Set/Real Analysis|closed]]. Let $a>0$. Then: :$\displaystyle\R\setminus G = \bigcup_{z\in \Z}(az,az+a)$ By [[Union of Open Sets of Metric Space is Open]], $\R\setminus G$ is [[Definition:Open Set/Real Analysis|open]]. Thus $G$ is [[Definition:Closed Set/Real Analysis|closed]]. {{qed}}	0
{{begin-eqn}} {{eqn | l = \sec x + \tan x | r = \sec x + \frac {\sin x} {\cos x} | c = [[Tangent is Sine divided by Cosine]] }} {{eqn | r = \frac 1 {\cos x} + \frac {\sin x} {\cos x} | c = [[Secant is Reciprocal of Cosine]] }} {{eqn | r = \frac {1 + \sin x} {\cos x} | c = }} {{end-eqn}} {{qed}}	0
From [[Derivative of Sine Function]]: :$\dfrac \d {\d x} \sin x = \cos x$ From [[Derivative of Cosine Function]]: :$\dfrac \d {\d x} \cos x = -\sin x$ Hence: {{begin-eqn}} {{eqn | l = \dfrac {\d^2} {\d x^2} \sin x | r = -\sin x | c = }} {{eqn | l = \dfrac {\d^3} {\d x^3} \sin x | r = -\cos x | c = }} {{eqn | l = \dfrac {\d^4} {\d x^4} \sin x | r = \sin x | c = }} {{end-eqn}} and so for all $m \in \N$: {{begin-eqn}} {{eqn | ll= m = 4 k: | l = \dfrac {\d^m} {\d x^m} \sin x | r = \sin x | c = }} {{eqn | ll= m = 4 k + 1: | l = \dfrac {\d^m} {\d x^m} \sin x | r = \cos x | c = }} {{eqn | ll= m = 4 k + 2: | l = \dfrac {\d^m} {\d x^m} \sin x | r = -\sin x | c = }} {{eqn | ll= m = 4 k + 3: | l = \dfrac {\d^m} {\d x^m} \sin x | r = -\cos x | c = }} {{end-eqn}} where $k \in \Z$. This leads to the [[Definition:Maclaurin Series|Maclaurin series expansion]]: {{begin-eqn}} {{eqn | l = \sin x | r = \sum_{r \mathop = 0}^\infty \paren {\frac {x^{4 k} } {\paren {4 k}!} \map \sin 0 + \frac {x^{4 k + 1} } {\paren {4 k + 1}!} \map \cos 0 - \frac {x^{4 k + 2} } {\paren {4 k + 2}!} \map \sin 0 - \frac {x^{4 k + 3} } {\paren {4 k + 3}!} \map \cos 0} | c = }} {{eqn | r = \sum_{r \mathop = 0}^\infty \paren {\frac {x^{4 k + 1} } {\paren {4 k + 1}!} - \frac {x^{4 k + 3} } {\paren {4 k + 3}!} } | c = [[Sine of Zero is Zero]], [[Cosine of Zero is One]] }} {{eqn | r = \sum_{n \mathop = 0}^\infty \paren {-1}^n \frac {x^{2 n + 1} } {\paren {2 n + 1}!} | c = setting $n = 2 k$ }} {{end-eqn}} From [[Series of Power over Factorial Converges]], it follows that this series is [[Definition:Convergent Series|convergent]] for all $x$. {{qed}}	0
:$\dfrac 2 {\pi} x \le \sin x \le x$ for all $x$ in the [[Definition:Real Interval/Closed|interval]] $\left[{0 \,.\,.\, \dfrac {\pi} 2}\right]$	0
We have: {{begin-eqn}} {{eqn | l = \cos 3 \theta + i \sin 3 \theta | r = \paren {\cos \theta + i \sin \theta}^3 | c = [[De Moivre's Formula]] }} {{eqn | r = \paren {\cos \theta}^3 + \binom 3 1 \paren {\cos \theta}^2 \paren {i \sin \theta} }} {{eqn | o = | ro=+ | r = \binom 3 2 \paren {\cos \theta} \paren {i \sin \theta}^2 + \paren {i \sin \theta}^3 | c = [[Binomial Theorem]] }} {{eqn | r = \cos^3 \theta + 3 i \cos^2 \theta \sin \theta + 3 i^2 \cos \theta \sin^2 \theta + i^3 \sin^3 \theta | c = substituting for [[Definition:Binomial Coefficient|binomial coefficients]] }} {{eqn | r = \cos^3 \theta + 3 i \cos^2 \theta \sin \theta - 3 \cos \theta \sin^2 \theta - i \sin^3 \theta | c = $i^2 = -1$ }} {{eqn | n = 1 | r = \cos^3 \theta - 3 \cos \theta \sin^2 \theta }} {{eqn | o = | ro=+ | r = i \paren {3 \cos^2 \theta \sin \theta - \sin^3 \theta} | c = rearranging }} {{end-eqn}} Hence: {{begin-eqn}} {{eqn | l = \sin 3 \theta | r = 3 \cos^2 \theta \sin \theta - \sin^3 \theta | c = equating [[Definition:Imaginary Part|imaginary parts]] in $(1)$ }} {{eqn | r = 3 \paren {1 - \sin^2 \theta} \sin \theta - \sin^3 \theta | c = [[Sum of Squares of Sine and Cosine]] }} {{eqn | r = 3 \sin \theta - 4 \sin^3 \theta | c = multiplying out and gathering terms }} {{end-eqn}} {{qed}}	0
Firstly, we have: {{begin-eqn}} {{eqn | n = 1 | l = \tan x | r = \frac {2 \tan \frac x 2} {1 - \tan ^2 \frac x 2} | c = [[Double Angle Formula for Tangent]] }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = \map \tan {\frac x 2 + \frac \pi 4} | r = \frac {\tan \frac x 2 + \tan \frac \pi 4} {1 - \tan \frac x 2 \tan \frac \pi 4} | c = [[Tangent of Sum]] }} {{eqn | r = \frac {\tan \frac x 2 + 1} {1 - \tan \frac x 2} | c = [[Tangent of 45 Degrees|Tangent of $45 \degrees$]] }} {{eqn | r = \frac {\paren {\tan \frac x 2 + 1} \paren {\tan \frac x 2 + 1} } {\paren {1 - \tan \frac x 2} \paren {\tan \frac x 2 + 1} } }} {{eqn | r = \frac {\tan^2 \frac x 2 + 2 \tan \frac x 2 + 1} {1 - \tan^2 \frac x 2} | c = [[Difference of Two Squares]], [[Square of Sum]] }} {{eqn | r = \frac {2 \tan \frac x 2} {1 - \tan^2 \frac x 2} + \frac {\tan^2 \frac x 2 + 1} {1 - \tan^2 \frac x 2} }} {{eqn | r = \tan x + \frac {\tan^2 \frac x 2 + 1} {1 - \tan^2 \frac x 2} | c = [[Double Angle Formula for Tangent]]: see $(1)$ above }} {{eqn | r = \tan x + \frac {\sin^2 \frac x 2 + \cos^2 \frac x 2} {\cos^2 \frac x 2 - \sin^2 \frac x 2} | c = multiplying [[Definition:Denominator|Denominator]] and [[Definition:Numerator|Numerator]] by $\cos^2 \frac x 2$ }} {{eqn | r = \tan x + \frac {\sin^2 \frac x 2 + \cos^2 \frac x 2} {\cos 2 \frac x 2} | c = [[Double Angle Formula for Cosine]] }} {{eqn | r = \tan x + \frac 1 {\cos x} | c = [[Sum of Squares of Sine and Cosine]] }} {{eqn | r = \tan x + \sec x | c = [[Secant is Reciprocal of Cosine]] }} {{end-eqn}} {{qed}} [[Category:Trigonometric Identities]] [[Category:Tangent Function]] [[Category:Secant Function]] 0wwp1p2ickye49m0s6kfoq8lv5b8409	0
{{begin-eqn}} {{eqn | l = \tan x | r = +\sqrt {\sec^2 x - 1} | c = if there exists an [[Definition:Integer|integer]] $n$ such that $n \pi < x < \paren {n + \dfrac 1 2} \pi$ }} {{eqn | l = \tan x | r = -\sqrt {\sec^2 x - 1} | c = if there exists an [[Definition:Integer|integer]] $n$ such that $\paren {n + \dfrac 1 2} \pi < x < \paren {n + 1} \pi$ }} {{end-eqn}}	0
:$\sin 5 \theta = 5 \sin \theta - 20 \sin^3 \theta + 16 \sin^5 \theta$	0
{{begin-eqn}} {{eqn | l = \sin x - \cos x | r = \sin x - \sin \left({\frac \pi 2 - x}\right) | c = [[Sine of Complement equals Cosine]] }} {{eqn | r = 2 \cos \left({\frac {x + \left({\frac \pi 2 - x}\right)} 2}\right) \sin \left({\frac {x - \left({\frac \pi 2 - x}\right)} 2}\right) | c = [[Prosthaphaeresis Formula for Sine minus Sine]] }} {{eqn | r = 2 \cos \frac \pi 4 \sin \left({x - \frac \pi 4}\right) | c = simplifying }} {{eqn | r = \sqrt 2 \sin \left({x - \frac \pi 4}\right) | c = [[Cosine of 45 Degrees|Cosine of $\dfrac \pi 4$]] }} {{end-eqn}} {{qed}} [[Category:Sine Function]] [[Category:Cosine Function]] mhg93r8g7ltbh2e0t9nwjzdio0bfyfm	0
{{begin-eqn}} {{eqn | l = y | r = \tan^{-1} \paren {i x} | c = }} {{eqn | ll= \implies | l = \tan y | r = i x | c = {{Defof|Inverse Tangent}} }} {{eqn | ll= \implies | l = i \tan y | r = - x | c = $i^2 = -1$ }} {{eqn | ll= \implies | l = \tanh \paren {i y} | r = -x | c = [[Tangent in terms of Hyperbolic Tangent]] }} {{eqn | ll= \implies | l = i y | r = \tanh^{-1} \paren {-x} | c = {{Defof|Inverse Hyperbolic Tangent}} }} {{eqn | ll= \implies | l = i y | r = -\tanh^{-1} x | c = [[Inverse Hyperbolic Tangent is Odd Function]] }} {{eqn | ll= \implies | l = y | r = i \tanh^{-1} x | c = multiplying both sides by $-i$ }} {{end-eqn}} {{qed}}	0
With a view to expressing the [[Definition:Primitive|primitive]] in the form: :$\displaystyle \int u \frac {\mathrm d v}{\mathrm d x} \ \mathrm d x = u v - \int v \frac {\mathrm d u}{\mathrm d x} \ \mathrm d x$ let: {{begin-eqn}} {{eqn | l = u | r = \arcsin \frac x a | c = }} {{eqn | ll= \implies | l = \frac {\mathrm d u} {\mathrm d x} | r = \frac 1 {\sqrt {a^2 - x^2} } | c = [[Derivative of Arcsine of x over a|Derivative of $\arcsin \dfrac x a$]] }} {{end-eqn}} and let: {{begin-eqn}} {{eqn | l = \frac {\mathrm d v} {\mathrm d x} | r = x | c = }} {{eqn | ll= \implies | l = v | r = \frac {x^2} 2 | c = [[Primitive of Power]] }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = \int x \arcsin \frac x a \ \mathrm d x | r = \frac {x^2} 2 \arcsin \frac x a - \int \frac {x^2} 2 \left({\frac 1 {\sqrt {a^2 - x^2} } }\right) \ \mathrm d x + C | c = [[Integration by Parts]] }} {{eqn | r = \frac {x^2} 2 \arcsin \frac x a - \frac 1 2 \int \frac {x^2 \ \mathrm d x} {\sqrt {a^2 - x^2} } + C | c = [[Primitive of Constant Multiple of Function]] }} {{eqn | r = \frac {x^2} 2 \arcsin \frac x a - \frac 1 2 \left({\frac {-x \sqrt {a^2 - x^2} } 2 + \frac {a^2} 2 \arcsin \frac x a}\right) + C | c = [[Primitive of x squared over Root of a squared minus x squared|Primitive of $\dfrac {x^2} {\sqrt {a^2 - x^2} }$]] }} {{eqn | r = \left({\frac {x^2} 2 - \frac {a^2} 4}\right) \arcsin \frac x a + \frac {x \sqrt {a^2 - x^2} } 4 + C | c = simplifying }} {{end-eqn}} {{qed}}	0
The nature of the [[Definition:Real Secant Function|secant function]] on the [[Definition:Real Number|set of real numbers]] $\R$ is as follows: :$(1): \quad \sec x$ is [[Definition:Continuous on Interval|continuous]] and [[Definition:Strictly Increasing Real Function|strictly increasing]] on the [[Definition:Half-Open Real Interval|intervals]] $\hointr 0 {\dfrac \pi 2}$ and $\hointl {\dfrac \pi 2} \pi$ :$(2): \quad \sec x$ is [[Definition:Continuous on Interval|continuous]] and [[Definition:Strictly Decreasing Real Function|strictly decreasing]] on the [[Definition:Half-Open Real Interval|intervals]] $\hointr {-\pi} {-\dfrac \pi 2}$ and $\hointl {-\dfrac \pi 2} 0$ :$(3): \quad \sec x \to + \infty$ as $x \to -\dfrac \pi 2^+$ :$(4): \quad \sec x \to + \infty$ as $x \to \dfrac \pi 2^-$ :$(5): \quad \sec x \to - \infty$ as $x \to \dfrac \pi 2^+$ :$(6): \quad \sec x \to - \infty$ as $x \to \dfrac {3 \pi} 2^-$	0
Let $\sin: \C \to \C$ be the [[Definition:Sine/Complex Function|complex sine function]]. Then $\sin$ is [[Definition:Entire Function|entire]].	0
Let $\map f t := \map \Si t = \displaystyle \int_0^t \dfrac {\sin u} u \rd u$. Then: :$\map f 0 = 0$ and: {{begin-eqn}} {{eqn | l = \map \Si t | r = \int_0^t \dfrac {\sin u} u \rd u | c = {{Defof|Sine Integral Function}} }} {{eqn | r = \int_0^t \dfrac 1 u \paren {u - \dfrac {u^3} {3!} + \dfrac {u^5} {5!} - \dfrac {u^7} {7!} + \dotsb} \rd u | c = {{Defof|Real Sine Function}} }} {{eqn | r = t - \dfrac {t^3} {3 \times 3!} + \dfrac {t^5} {5 \times 5!} - \dfrac {t^7} {7 \times 7!} + \dotsb | c = [[Primitive of Power]] }} {{eqn | ll= \leadsto | l = \laptrans {\map \Si t} | r = \laptrans {t - \dfrac {t^3} {3 \times 3!} + \dfrac {t^5} {5 \times 5!} - \dfrac {t^7} {7 \times 7!} + \dotsb} | c = }} {{eqn | r = \dfrac 1 {s^2} - \dfrac 1 {3 \times 3!} \dfrac {3!} {s^4} + \dfrac 1 {5 \times 5!} \dfrac {5!} {s^6} - \dfrac 1 {7 \times 7!} \dfrac {7!} {s^8} + \dotsb | c = [[Laplace Transform of Positive Integer Power]] }} {{eqn | r = \dfrac 1 {s^2} - \dfrac 1 {3 s^4} + \dfrac 1 {5 s^6} - \dfrac 1 {7 s^8} + \dotsb | c = simplifying }} {{eqn | r = \dfrac 1 s \paren {\dfrac {\paren {1 / s} } 1 - \dfrac {\paren {1 / s}^3} 3 + \dfrac {\paren {1 / s}^5} 5 - \dfrac {\paren {1 / s}^7} 7 + \dotsb} | c = rearranging }} {{eqn | r = \dfrac 1 s \arctan \dfrac 1 s | c = [[Power Series Expansion for Real Arctangent Function]] }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \arcsec x | r = \map \arccos {\frac 1 x} | c = [[Arcsecant of Reciprocal equals Arccosine]] }} {{eqn | r = -i \map \Ln {i \sqrt {1 - \paren {\frac 1 x}^2} + \frac 1 x} | c = [[Arccosine Logarithmic Formulation]] }} {{eqn | r = -i \map \Ln {i \sqrt {1 - \frac 1 {x^2} } + \frac 1 x} }} {{end-eqn}} {{qed}}	0
:$\csc 300^\circ = \csc \dfrac {5 \pi} 3 = -\dfrac {2 \sqrt 3} 3$	0
:$\map {\dfrac \d {\d x} } {\tan^2 x} = 2 \tan x \sec^2 x$ when $\cos x \ne 0$.	0
:$\displaystyle \int \frac {\cot a x} x \ \mathrm d x = \frac {-1} a x - \frac {a x} 3 - \frac {\paren {a x}^3} {135} - \cdots - \frac {\paren {-1}^{n - 1} 2^{2 n} B_{2 n} \paren {a x}^{2 n - 1} } {\paren {2 n - 1} \paren {2 n}!} - \cdots + C$ where $B_n$ denotes the $n$th [[Definition:Bernoulli Numbers|Bernoulli number]].	0
Everywhere that the function is defined: :$\map \arcsin {-x} = -\arcsin x$	0
:$\map \cos {\theta + n \pi} = \paren {-1}^n \cos \theta$	0
Let $P = \tuple {x, y}$ be a [[Definition:Point|point]] on the [[Definition:Circumference of Circle|circumference]] of a [[Definition:Unit Circle|unit circle]] whose [[Definition:Center of Circle|center]] is at the [[Definition:Origin|origin]] of a [[Definition:Cartesian Plane|cartesian plane]]. From [[Sine of Angle in Cartesian Plane]] and [[Cosine of Angle in Cartesian Plane]]: :$P = \tuple {\cos \theta, \sin \theta}$ The [[Definition:Graph of Relation|graph]] of the [[Definition:Unit Circle|unit circle]] is the [[Definition:Locus|locus]] of: :$x^2 + y^2 = 1$ as given by [[Equation of Circle]]. Substituting $x = \cos \theta$ and $y = \sin \theta$ yields: :$\cos^2 \theta + \sin^2 \theta = 1$ {{qed}}	0
:$\cot 345 \degrees = \cot \dfrac {23 \pi} {12} = -\paren {2 + \sqrt 3}$	0
:$\sec^{-1} x = \pm i \sech^{-1} x$	0
Assume $y \in \R$ such that $0 \le y \le \pi$. {{begin-eqn}} {{eqn | l = y | r = \arccos x }} {{eqn | ll= \leadstoandfrom | l = x | r = \cos y }} {{eqn | ll= \leadstoandfrom | l = x | r = \frac 1 2 \paren {e^{-i y} + e^{i y} } | c = [[Cosine Exponential Formulation]] }} {{eqn | ll= \leadstoandfrom | l = 2 x | r = e^{-i y} + e^{i y} }} {{eqn | ll= \leadstoandfrom | l = 2 x e^{i y} | r = 1 + e^{2 i y} }} {{eqn | ll= \leadstoandfrom | l = e^{2 i y} - 2 x e^{i y} | r = -1 }} {{eqn | ll= \leadstoandfrom | l = e^{2 i y} - 2 x e^{i y} + x^2 | r = x^2 - 1 }} {{eqn | ll= \leadstoandfrom | l = \paren {e^{i y} - x}^2 | r = x^2 - 1 }} {{eqn | ll= \leadstoandfrom | l = e^{i y} - x | r = \sqrt {x^2 - 1} }} {{eqn | ll= \leadstoandfrom | l = i y | r = \map \ln {x + \sqrt {x^2 - 1} } }} {{eqn | ll= \leadstoandfrom | l = y | r = \dfrac 1 i \map \ln {x + \sqrt {x^2 - 1} } }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \cos 6 \theta + i \sin 6 \theta | r = \paren {\cos \theta + i \sin \theta}^6 | c = [[De Moivre's Formula]] }} {{eqn | r = \paren {\cos \theta}^6 + \binom 6 1 \paren {\cos \theta}^5 \paren {i \sin \theta} + \binom 6 2 \paren {\cos \theta}^4 \paren {i \sin \theta}^2 | c = [[Binomial Theorem]] }} {{eqn | o = | ro=+ | r = \binom 6 3 \paren {\cos \theta}^3 \paren {i \sin \theta}^3 + \binom 6 4 \paren {\cos \theta}^2 \paren {i \sin \theta}^4 + \binom 6 5 \paren {\cos \theta} \paren {i \sin \theta}^5 + \paren {i \sin \theta}^6 }} {{eqn | r = \cos^6 \theta + 6 i \cos^5 \theta \sin \theta - 15 \cos^4 \sin^2 \theta | c = substituting for [[Definition:Binomial Coefficient|binomial coefficients]] }} {{eqn | o = | ro=- | r = 20 i \cos^3 \theta \sin^3 \theta + 15 \cos^2 \theta \sin^4 \theta + 6 i \cos \theta \sin^5 \theta - \sin^6 \theta | c = and using $i^2 = -1$ }} {{eqn | n = 1 | r = \cos^6 \theta - 15 \cos^4 \sin^2 \theta + 15 \cos^2 \theta \sin^4 \theta - \sin^6 \theta }} {{eqn | o = | ro=+ | r = i \paren {6 \cos^5 \theta \sin \theta - 20 \cos^3 \theta \sin^3 \theta + 6 \cos \theta \sin^5 \theta} | c = rearranging }} {{end-eqn}} Hence: {{begin-eqn}} {{eqn | l = \map \sin {6 \theta} | r = 6 \cos^5 \theta \sin \theta - 20 \cos^3 \theta \sin^\theta + 6 \cos \theta \sin^5 \theta | c = equating [[Definition:Imaginary Part|imaginary parts]] in $(1)$ }} {{eqn | ll= \leadsto | l = \dfrac {\map \sin {6 \theta} } {\sin \theta} | r = 6 \cos^5 \theta - 20 \cos^3 \theta \sin^2 \theta + 6 \cos \theta \sin^4 \theta | c = }} {{eqn | r = 6 \cos^5 \theta - 20 \cos^3 \theta \paren {1 - \cos^2 \theta} + 6 \cos \theta \paren {1 - \cos^2 \theta}^2 | c = [[Sum of Squares of Sine and Cosine]] }} {{eqn | r = 32 \cos^5 \theta - 32 \cos^3 \theta + 6 \cos \theta | c = multiplying out and gathering terms }} {{end-eqn}} {{qed}}	0
{{TFAE|def = Complex Inverse Cotangent}} Let $S$ be the [[Definition:Subset|subset]] of the [[Definition:Complex Plane|complex plane]]: :$S = \C \setminus \left\{{0 + i, 0 - i}\right\}$	0
:$\displaystyle \int \sinh a x \cos p x \ \mathrm d x = \frac {a \cosh a x \cos p x + p \sinh a x \sin p x} {a^2 + p^2} + C$	0
{{begin-eqn}} {{eqn | l = I_n | r = \int \cos^n x \rd x }} {{eqn | r = \dfrac {\cos^{n - 1} x \sin x} n + \dfrac {n - 1} n I_{n-2} | c = [[Reduction Formula for Integral of Power of Cosine]] }} {{eqn | l = I_0 | r = \int \left({\cos x}\right)^0 \rd x | c = }} {{eqn | r = \int \rd x | c = }} {{eqn | r = x + C | c = [[Primitive of Constant]] }} {{eqn | ll= \leadsto | l = I_2 | r = \frac {\cos x \sin x} 2 + \frac x 2 + \frac C 2 | c = setting $n = 2$ }} {{eqn | r = \frac {\sin 2 x} 4 + \frac x 2 + C' | c = [[Double Angle Formula for Sine]] }} {{end-eqn}} {{qed}}	0
:$\displaystyle \int \frac {\mathrm d x} {1 - \cos a x} = \frac {-1} a \cot \frac {a x} 2 + C$	0
:$\map \cos {\dfrac \pi 2 - \theta} = \sin \theta$	0
Let $\lambda \in \R \setminus \Z$ be a [[Definition:Real Number|real number]] which is not an [[Definition:Integer|integer]]. :[[File:Sneddon-1-Exercise-5.png|500px|thumb|right|$\map f x$ for $\lambda = 4 \cdotp 6$ and its $5$th approximation]] Let $\map f x$ be the [[Definition:Real Function|real function]] defined on $\openint 0 \pi$ as: :$\map f x = \cos \lambda x$ Then its [[Definition:Half-Range Fourier Cosine Series|half-range Fourier cosine series]] can be expressed as: {{begin-eqn}} {{eqn | l = \map f x | o = \sim | r = \frac {2 \lambda \sin \lambda \pi} \pi \paren {\frac 1 {2 \lambda^2} + \sum_{n \mathop = 1}^\infty \paren {-1}^n \frac {\cos n x} {\lambda^2 - n^2} } | c = }} {{eqn | r = \frac {2 \lambda \sin \lambda \pi} \pi \paren {\frac 1 {2 \lambda^2} - \frac {\cos x} {\lambda^2 - 1} + \frac {\cos 2 x} {\lambda^2 - 4} - \frac {\cos 3 x} {\lambda^2 - 9} + \frac {\cos 4 x} {\lambda^2 - 16} - \dotsb} | c = }} {{end-eqn}}	0
:$\map {\dfrac \d {\d x} } {\arccot u} = -\dfrac 1 {1 + u^2} \dfrac {\d u} {\d x}$	0
:$\sec 180 \degrees = \sec \pi = -1$	0
{{begin-eqn}} {{eqn | l = \map \csc {\frac \pi 2 - \theta} | r = \frac 1 {\map \sin {\frac \pi 2 - \theta} } | c = [[Cosecant is Reciprocal of Sine]] }} {{eqn | r = \frac 1 {\cos \theta} | c = [[Sine of Complement equals Cosine]] }} {{eqn | r = \sec \theta | c = [[Secant is Reciprocal of Cosine]] }} {{end-eqn}} The above is valid only where $\cos \theta \ne 0$, as otherwise $\dfrac 1 {\cos \theta}$ is undefined. From [[Cosine of Half-Integer Multiple of Pi]] it follows that this happens when $\theta \ne \paren {2 n + 1} \dfrac \pi 2$. {{qed}}	0
{{begin-eqn}} {{eqn | l = \frac {\map \d {\arccot x} } {\d x} | r = \map {\frac \d {\d x} } {\frac \pi 2 - \arctan x} | c = [[Tangent of Complement equals Cotangent]] }} {{eqn | r = -\frac 1 {1 + x^2} | c = [[Derivative of Arctangent Function]] }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \cot 150 \degrees | r = \map \cot {90 \degrees + 60 \degrees} | c = }} {{eqn | r = -\tan 60 \degrees | c = [[Cotangent of Angle plus Right Angle]] }} {{eqn | r = -\sqrt 3 | c = [[Tangent of 60 Degrees|Tangent of $60 \degrees$]] }} {{end-eqn}} {{qed}}	0
:$\sin 72 \degrees = \sin \dfrac {2 \pi} 5 = \dfrac {\sqrt{10 + 2 \sqrt 5} } 4$ where $\sin$ denotes the [[Definition:Sine Function|sine function]].	0
{{begin-eqn}} {{eqn | l = \csc \left({x + \frac \pi 2}\right) | r = \frac 1 {\sin \left({x + \frac \pi 2}\right)} | c = [[Cosecant is Reciprocal of Sine]] }} {{eqn | r = \frac 1 {\cos x} | c = [[Sine of Angle plus Right Angle]] }} {{eqn | r = \sec x | c = [[Secant is Reciprocal of Cosine]] }} {{end-eqn}} {{qed}}	0
Let $f$ be a [[Definition:Real Function|real function]] which is [[Definition:Square-Integrable Function|square-integrable]] over the [[Definition:Open Real Interval|interval]] $\openint {-\pi} \pi$. Let $f$ be expressed by the [[Definition:Fourier Series over Range 2 Pi|Fourier series]]: :$\map f x \sim \dfrac {a_0} 2 + \displaystyle \sum_{n \mathop = 1}^\infty \paren {a_n \cos n x + b_n \sin n x}$ Then: :$\displaystyle \frac 1 \pi \int_{-\pi}^\pi \size {\map {f^2} x} \rd x = \frac { {a_0}^2} 2 + \sum_{n \mathop = 1}^\infty \paren { {a_n}^2 + {b_n}^2}$	0
:$\displaystyle x^2 = \frac {\pi^2} 3 + \sum_{n \mathop = 1}^\infty \paren {\paren {-1}^n \frac 4 {n^2} \cos n x}$	0
:$\displaystyle \int \cot a x \rd x = \frac {\ln \size {\sin a x} } a + C$	0
:$\ds \int \sin^2 x \rd x = \frac x 2 - \frac {\sin 2 x} 4 + C$ where $C$ is an [[Definition:Arbitrary Constant (Calculus)|arbitrary constant]].	0
{{begin-eqn}} {{eqn | o = | r = 2 \, \map \cos {\frac {\alpha + \beta} 2} \, \map \cos {\frac {\alpha - \beta} 2} | c = }} {{eqn | r = 2 \frac {\map \cos {\dfrac {\alpha + \beta} 2 - \dfrac {\alpha - \beta} 2} + \map \cos {\dfrac {\alpha + \beta} 2 + \dfrac {\alpha - \beta} 2} } 2 | c = [[Simpson's Formula for Cosine by Cosine]] }} {{eqn | r = \cos \frac {2 \beta} 2 + \cos \frac {2 \alpha} 2 | c = }} {{eqn | r = \cos \alpha + \cos \beta | c = }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \map \cos {x + \pi} | r = \frac 1 2 \paren {e^{i \paren {x + \pi} } + e^{-i \paren {x + \pi} } } | c = [[Cosine Exponential Formulation]] }} {{eqn | r = \frac 1 2 \paren {e^{i x} e^{i \pi} + e^{-i x} e^{-i \pi} } | c = [[Exponential of Sum/Complex Numbers|Exponential of Sum: Complex Numbers]] }} {{eqn | r = \frac 1 2 \paren {-e^{i x} - e^{-i x} } | c = [[Euler's Identity]] }} {{eqn | r = -\frac 1 2 \paren {e^{i x} + e^{-i x} } | c = }} {{eqn | r = -\cos x | c = [[Cosine Exponential Formulation]] }} {{end-eqn}} {{qed}}	0
:$\sin \theta = \dfrac 1 {\csc \theta}$	0
:$\cos 315 \degrees = \cos \dfrac {7 \pi} 4 = \dfrac {\sqrt 2} 2$	0
From [[Mittag-Leffler Expansion for Cotangent Function]]: :$\displaystyle \pi \cot \pi z = \frac 1 z + 2 \sum_{k \mathop = 1}^\infty \frac z {z^2 - k^2}$ Factoring $-\dfrac 1 {k^2}$: :$\displaystyle \pi \cot \pi z = \frac 1 z - 2 \sum_{k \mathop = 1}^\infty \frac z {k^2} \cdot \frac 1 {1 - \frac {z^2} {k^2} }$ Taking $\cmod z < 1$, and noting that $k \ge 1$, we have, by [[Sum of Infinite Geometric Sequence]]: :$\displaystyle \pi \cot \pi z = \frac 1 z - 2 \sum_{k \mathop = 1}^\infty \frac z {k^2} \cdot \sum_{n \mathop = 1}^\infty \paren {\frac {z^2} {k^2} }^{n - 1}$ from which: {{begin-eqn}} {{eqn | l = \pi \cot \pi z | r = \frac 1 z - 2 \sum_{k \mathop = 1}^\infty \sum_{n \mathop = 1}^\infty \frac {z^{2 n - 2} \cdot z} {k^{2 n - 2} \cdot k^2} }} {{eqn | r = \frac 1 z - 2 \sum_{k \mathop = 1}^\infty \sum_{n \mathop = 1}^\infty \frac 1 {k^{2 n} } \cdot z^{2 n - 1} }} {{eqn | r = \frac 1 z - 2 \sum_{n \mathop = 1}^\infty \map \zeta {2 n} z^{2 n - 1} | c = {{Defof|Riemann Zeta Function}} }} {{end-eqn}} {{qed}} [[Category:Laurent Series Expansion for Cotangent Function]] [[Category:Laurent Series Expansions]] [[Category:Cotangent Function]] tmigxwb63elg6ab0xcb4011tt72zbp1	0
{{begin-eqn}} {{eqn | l = \sin 45 \degrees | r = \map \sin {3 \times 15 \degrees} | c = }} {{eqn | r = 3 \sin 15 \degrees - 4 \sin^3 15 \degrees | c = [[Triple Angle Formula for Sine]] }} {{eqn | r = 3 \paren {\frac {\sqrt 6 - \sqrt 2} 4} - 4 \paren {\frac {\sqrt 6 - \sqrt 2} 4}^3 | c = [[Sine of 15 Degrees|Sine of $15 \degrees$]] }} {{eqn | r = \frac {3 \sqrt 6 - 3 \sqrt 2} 4 - \frac {6 \sqrt 6 - 18 \sqrt 2 + 6 \sqrt 6 - 2 \sqrt 2} {16} | c = }} {{eqn | r = \frac {3 \sqrt 6 - 3 \sqrt 2} 4 - \frac {12 \sqrt 6 - 20\sqrt 2} {16} | c = }} {{eqn | r = \frac {3 \sqrt 6 - 3 \sqrt 2} 4 - \frac {3 \sqrt 6 - 5 \sqrt 2} 4 | c = }} {{eqn | r = \frac {2 \sqrt 2} 4 | c = }} {{eqn | r = \frac {\sqrt 2} 2 | c = }} {{end-eqn}} {{qed}}	0
:$\tan 330^\circ = \tan \dfrac {11 \pi} 6 = -\dfrac {\sqrt 3} 3$	0
{{begin-eqn}} {{eqn | l=\csc \left({\pi - \theta}\right) | r=\frac 1 {\sin \left({\pi - \theta}\right)} | c=[[Cosecant is Reciprocal of Sine]] }} {{eqn | r=\frac 1 {\sin \theta} | c=[[Sine of Supplementary Angle]] }} {{eqn | r=\csc \theta | c=[[Cosecant is Reciprocal of Sine]] }} {{end-eqn}} {{qed}}	0
The proof proceeds by [[Principle of Mathematical Induction|induction]]. For all $n \in \Z_{> 0}$, let $\map P n$ be the [[Definition:Proposition|proposition]]: :$\displaystyle \int_0^{\frac \pi 2} \cos^{2 n} x \rd x = \dfrac {\paren {2 n}!} {\paren {2^n n!}^2} \dfrac \pi 2$ === Basis for the Induction === $\map P 1$ is the case: {{begin-eqn}} {{eqn | l = \int_0^{\frac \pi 2} \cos^2 x \rd x | r = \frac \pi 4 | c = [[Definite Integral from 0 to Half Pi of Square of Cosine x]] }} {{eqn | r = \dfrac 1 2 \times \dfrac \pi 2 | c = }} {{eqn | r = \dfrac 2 {\paren {2 \times 1}^2} \dfrac \pi 2 | c = }} {{eqn | r = \dfrac {\paren {2 \times 1}!} {\paren {2^1 \times 1!}^2} \dfrac \pi 2 | c = }} {{end-eqn}} Thus $\map P 1$ is seen to hold. This is the [[Definition:Basis for the Induction|basis for the induction]]. === Induction Hypothesis === Now it needs to be shown that, if $\map P k$ is true, where $k \ge 1$, then it logically follows that $\map P {k + 1}$ is true. So this is the [[Definition:Induction Hypothesis|induction hypothesis]]: :$\displaystyle \int_0^{\frac \pi 2} \cos^{2 k} x \rd x = \dfrac {\paren {2 k}!} {\paren {2^k k!}^2} \dfrac \pi 2$ from which it is to be shown that: :$\displaystyle \int_0^{\frac \pi 2} \cos^{2 \paren {k + 1} } x \rd x = \dfrac {\paren {2 \paren {k + 1} }!} {\paren {2^{k + 1} \paren {k + 1}!}^2} \dfrac \pi 2$ === Induction Step === This is the [[Definition:Induction Step|induction step]]: Let $I_k = \displaystyle \int_0^{\frac \pi 2} \cos^{2 k} x \rd x$. {{begin-eqn}} {{eqn | l = I_{k + 1} | r = \frac {2 \paren {k + 1} - 1} {2 \paren {k + 1} } I_k | c = [[Reduction Formula for Definite Integral of Power of Cosine]] }} {{eqn | r = \frac {2 \paren {k + 1} - 1} {2 \paren {k + 1} } \dfrac {\paren {2 k}!} {\paren {2^k k!}^2} \dfrac \pi 2 | c = [[Definite Integral from 0 to Half Pi of Even Power of Cosine x#Induction Hypothesis|Induction Hypothesis]] }} {{eqn | r = \frac {2 \paren {k + 1} \paren {2 \paren {k + 1} - 1} } {2^2 \paren {k + 1}^2} \dfrac {\paren {2 k}!} {\paren {2^k k!}^2} \dfrac \pi 2 | c = }} {{eqn | r = \dfrac {\paren {2 \paren {k + 1} }!} {\paren {2^{k + 1} \paren {k + 1}!}^2} \dfrac \pi 2 | c = }} {{end-eqn}} So $\map P k \implies \map P {k + 1}$ and the result follows by the [[Principle of Mathematical Induction]]. Therefore: :$\displaystyle \forall n \in \Z_{> 0}: \int_0^{\frac \pi 2} \cos^{2 n} x \rd x = \dfrac {\paren {2 n}!} {\paren {2^n n!}^2} \dfrac \pi 2$ {{qed}}	0
This proof assumes the truth of the [[Derivative of Cosine Function]]: From [[Cosine of Zero is One]]: :$\cos 0 = 1$ From [[Derivative of Cosine Function]]: :$D_x \left({\cos x}\right) = - \sin x$ and by [[Derivative of Constant]]: :$D_x \left({-1}\right) = 0$ So by [[Sum Rule for Derivatives]]: :$D_x \left({\cos x - 1}\right) = - \sin x$ By [[Sine of Zero is Zero]]: :$\sin 0 = 0$ From [[Derivative of Identity Function]]: :$D_x \left({x}\right) = 1$ Thus [[L'Hôpital's Rule]] applies and so: : $\displaystyle \lim_{x \mathop \to 0} \frac {\cos x - 1} x = \lim_{x \mathop \to 0} \frac {-\sin x} 1 = \frac {-0} 1 = 0$ {{qed}}	0
:$\displaystyle \map \ln {\sin x} = -\ln 2 - \sum_{n \mathop = 1}^\infty \frac {\cos 2 n x} n$	0
{{begin-eqn}} {{eqn | l = \int \tan x \rd x | r = -\ln \size {\cos x} | c = [[Primitive of Tangent Function/Cosine Form|Primitive of $\tan x$: Cosine Form]] }} {{eqn | ll= \leadsto | l = \int \tan a x \rd x | r = \frac 1 a \paren {-\ln \size {\cos a x} } + C | c = [[Primitive of Function of Constant Multiple]] }} {{eqn | r = \frac {-\ln \size {\cos a x} } a + C | c = simplifying }} {{end-eqn}} {{qed}}	0
By definition, $\arcsin$ is the [[Definition:Inverse Mapping|inverse]] of the [[Definition:Restriction/Mapping|restriction]] of the [[Definition:Sine Function|sine function]] to $\closedint {-\dfrac \pi 2} {\dfrac \pi 2}$. Therefore, if: :$\sin x = 0$ and $-\dfrac \pi 2 \le x \le \dfrac \pi 2$, then $\arcsin 0 = x$. From [[Sine of Zero is Zero]], we have that: :$\sin 0 = 0$ We have $-\dfrac \pi 2 < 0 < \dfrac \pi 2$, so: :$\arcsin 0 = 0$ {{qed}} [[Category:Arcsine Function]] 11wtbduj29rils37p0iwqxcsqlyu7xl	0
Let $m \in \Z$ such that $m > 1$. Then: :$\displaystyle \prod_{k \mathop = 1}^{m - 1} \cot \frac {k \pi} {2 m} = 1$	0
Recall [[Euler's Formula]]: :$\exp \paren {i z} = \cos z + i \sin z$ Then, starting from the {{RHS}}: {{begin-eqn}} {{eqn | l = \frac {\exp \paren {i z} - \exp \paren {-i z} }{2 i} | r = \frac {\paren {\cos z + i \sin z} - \paren {\cos \paren {-z} + i \sin \paren {-z} } } {2 i} }} {{eqn | r = \frac {\paren {\cos z + i \sin z - \cos z - i \sin \paren {-z} } } {2 i} | c = [[Cosine Function is Even]] }} {{eqn | r = \frac {i \sin z - i \sin \paren {-z} } {2 i} | c = }} {{eqn | r = \frac {i \sin z - i \paren {-\sin \paren {-z} } } {2 i} | c = [[Sine Function is Odd]] }} {{eqn | r = \frac {2 i \sin z} {2 i} | c = }} {{eqn | r = \sin z | c = }} {{end-eqn}} {{qed}}	0
By definition of [[Definition:Fourier Series over Range 2 Pi|Fourier series]]: :$\displaystyle \map f x \sim \frac {a_0} 2 + \sum_{n \mathop = 1}^\infty \paren {a_n \cos n x + b_n \sin n x}$ where: {{begin-eqn}} {{eqn | l = a_n | r = \dfrac 1 \pi \int_0^{2 \pi} \map f x \cos n x \rd x }} {{eqn | l = b_n | r = \dfrac 1 \pi \int_0^{2 \pi} \map f x \sin n x \rd x }} {{end-eqn}} for all $n \in \Z_{>0}$. Thus: {{begin-eqn}} {{eqn | l = a_0 | r = \frac 1 \pi \int_0^{2 \pi} \map f x \rd x | c = [[Cosine of Zero is One]] }} {{eqn | r = \frac 1 \pi \int_0^{2 \pi} \pi - x \rd x | c = Definition of $f$ }} {{eqn | r = \frac 1 \pi \intlimits {\pi x - \frac 1 2 x^2} 0 {2 \pi} | c = [[Primitive of Power]] }} {{eqn | r = 2 \pi^2 - \frac 4 2 \pi^2 | c = }} {{eqn | r = 0 }} {{end-eqn}} {{qed|lemma}} For $n > 0$: {{begin-eqn}} {{eqn | l = a_n | r = \frac 1 \pi \int_0^{2 \pi} \map f x \cos n x \rd x | c = }} {{eqn | r = \frac 1 \pi \int_0^{2 \pi} \paren {\pi - x} \cos n x \rd x | c = Definition of $f$ }} {{eqn | r = \pi \int_0^{2 \pi} \cos n x \rd x - \frac 1 \pi \int_0^{2 \pi} x \cos n x \rd x | c = }} {{eqn | r = - \frac 1 \pi \int_0^{2 \pi} x \cos n x \rd x | c = [[Integral over 2 pi of Cosine of n x|Integral over $2 \pi$ of $\cos n x$]] }} {{eqn | r = - \frac 1 \pi \intlimits {\frac {\cos n x} {n^2} + \frac {x \sin n x} n} 0 {2 \pi} | c = [[Primitive of x by Cosine of a x|Primitive of $x \cos n x$]] }} {{eqn | r = - \frac 1 \pi \paren {\cos 0 - \cos 2 \pi} | c = [[Sine of Integer Multiple of Pi]] }} {{eqn | r = 0 | c = [[Sine and Cosine are Periodic on Reals]] }} {{end-eqn}} {{qed|lemma}} Now for the $\sin n x$ terms: {{begin-eqn}} {{eqn | l = b_n | r = \frac 1 \pi \int_0^{2 \pi} \map f x \sin n x \rd x | c = }} {{eqn | r = \frac 1 \pi \int_0^{2 \pi} \paren {\pi - x} \sin n x \rd x | c = Definition of $f$ }} {{eqn | r = \int_0^{2 \pi} \sin n x \rd x - \frac 1 \pi \int_0^{2 \pi} x \sin n x \rd x | c = }} {{eqn | r = - \frac 1 \pi \int_0^{2 \pi} x \sin n x \rd x | c = [[Integral over 2 pi of Sine of n x|Integral over $2 \pi$ of $\sin n x$]] }} {{eqn | r = - \frac 1 \pi \intlimits {\frac {\sin n x} {n^2} - \frac {x \cos n x} n} 0 {2 \pi} | c = [[Primitive of x by Sine of a x|Primitive of $x \sin n x$]] }} {{eqn | r = \frac 1 \pi \frac {2 \pi \cos 2 n \pi} n | c = [[Sine of Multiple of Pi]] }} {{eqn | r = \frac 2 n | c = [[Cosine of Multiple of Pi]] }} {{end-eqn}} Finally: {{begin-eqn}} {{eqn | l = \map f x | o = \sim | r = \frac {a_0} 2 + \sum_{n \mathop = 1}^\infty \paren {a_n \cos n x + b_n \sin n x} | c = }} {{eqn | r = \sum_{n \mathop = 1}^\infty \frac 2 n \sin n x | c = substituting for $a_0$, $a_n$ and $b_n$ from above }} {{eqn | r = 2 \sum_{n \mathop = 1}^\infty \frac {\sin n x} n | c = rearranging }} {{end-eqn}} {{qed}}	0
Let $\map f x$ be a [[Definition:Real Function|real function]] defined on the [[Definition:Open Real Interval|open real interval]] $\openint 0 \lambda$. Let $f$ be expressed using the [[Definition:Half-Range Fourier Cosine Series|half-range Fourier cosine series]] over $\openint 0 \lambda$: :$\displaystyle \map C x \sim \frac {a_0} 2 + \sum_{n \mathop = 1}^\infty a_n \cos \frac {n \pi x} \lambda$ where: :$a_n = \displaystyle \frac 2 \lambda \int_0^\lambda \map f x \cos \frac {n \pi x} \lambda \rd x$ for all $n \in \Z_{\ge 0}$. Then over the [[Definition:Closed Real Interval|closed real interval]] $\openint {-\lambda} 0$, $\map C x$ takes the values: :$\map C x = \map f {-x}$ {{refactor|This following bit depends upon what happens at $x {{=}} 0$ which needs to be carefully considered, so put it here as a corollary}} That is, the [[Definition:Real Function|real function]] expressed by the [[Definition:Half-Range Fourier Cosine Series|half-range Fourier cosine series]] over $\openint 0 \lambda$ is an [[Definition:Even Function|even function]] over $\openint {-\lambda} \lambda$.	0
:$\csc 240 \degrees = \csc \dfrac {4 \pi} 3 = -\dfrac {2 \sqrt 3} 3$	0
Let $m, n \in \Z$ be [[Definition:Integer|integers]]. Let $\alpha \in \R$ be a [[Definition:Real Number|real number]]. Then: :$\displaystyle \int_\alpha^{\alpha + 2 \pi} \sin m x \cos n x \rd x = 0$	0
{{begin-eqn}} {{eqn | l = \int x \sec a x \rd x | r = \frac 1 {a^2} \paren {\frac {\paren {a x}^2} 2 - \frac {\paren {a x}^4} 8 + \frac {5 \paren {a x}^6} {144} - \cdots + \frac {\paren {-1}^n E_{2 n} \paren {a x}^{2 n + 2} } {\paren {2 n + 2} \paren {2 n}!} + \cdots} + C | c = }} {{eqn | r = \frac 1 {a^2} \sum_{n \mathop = 0}^\infty \frac {\paren {-1}^n E_{2 n} \paren {a x}^{2 n + 2} } {\paren {2 n + 2} \paren {2 n}!} + C | c = }} {{end-eqn}} where $E_{2 n}$ is the $2 n$th [[Definition:Euler Numbers|Euler number]].	0
{{begin-eqn}} {{eqn | l = \tan 4 \theta | r = \frac {\sin 4 \theta} {\cos 4 \theta} | c = [[Tangent is Sine divided by Cosine]] }} {{eqn | r = \frac {4 \sin \theta \cos \theta - 8 \sin^3 \theta \cos \theta} {8 \cos^4 \theta - 8 \cos^2 \theta + 1} | c = [[Quadruple Angle Formula for Sine]] and [[Quadruple Angle Formula for Cosine]] }} {{eqn | r = \frac {4 \frac {\tan \theta} {\cos^2 \theta} - 8 \tan^3 \theta} {8 - \frac 8 {\cos^2 \theta} + \frac 1 {\cos^4 \theta} } | c = dividing top and bottom by $\cos^4 \theta$ }} {{eqn | r = \frac {4 \tan \theta \sec^2 \theta - 8 \tan^3 \theta} {8 - 8 \sec^2 \theta + \sec^4 \theta} | c = [[Secant is Reciprocal of Cosine]] }} {{eqn | r = \frac {4 \tan \theta \paren {1 + \tan^2 \theta} - 8 \tan^3 \theta} {8 - 8 \paren {1 + \tan^2 \theta} + \paren {1 + \tan^2 \theta}^2} | c = [[Difference of Squares of Secant and Tangent]] }} {{eqn | r = \frac {4 \tan \theta - 4 \tan^3 \theta} {1 - 6 \tan^2 \theta + \tan^4 \theta} | c = multiplying out and gathering terms }} {{end-eqn}} {{qed}}	0
:$\cot \left({a + b}\right) = \dfrac {\cot a \cot b - 1} {\cot b + \cot a}$ where $\cot $ is [[Definition:Cotangent|cotangent]]. === [[Cotangent of Sum/Corollary|Corollary]] === {{:Cotangent of Sum/Corollary}}	0
:$\displaystyle \int \frac {\mathrm d x} {\sin^n a x} = \frac {- \cos a x} {a \left({n - 1}\right) \sin^{n - 1} a x} + \frac {n - 2} {n - 1} \int \frac {\mathrm d x} {\sin^{n - 2} a x}$	0
Recall the definition of the [[Definition:Real Cosine Function|cosine function]]: :$\displaystyle \cos z = \sum_{n \mathop = 0}^\infty \left({-1}\right)^n \frac {z^{2 n} } {\left({2 n}\right)!} = 1 - \frac {z^2} {2!} + \frac {z^4} {4!} - \cdots$ From [[Even Power is Non-Negative]]: : $\forall n \in \N: z^{2 n} = \paren {-z}^{2 n}$ The result follows. {{qed}}	0
Let $x$ belong to the [[Definition:Open Real Interval|open real interval]] $\openint {-1} 1$. Then: :$\map {\tan^{-1} } {i x} = \dfrac i 2 \map \ln {\dfrac {1 + x} {1 - x} }$ where $\tan$ is the [[Definition:Complex Tangent Function|complex tangent function]], $\ln$ is the [[Definition:Real Natural Logarithm|real natural logarithm]], and $i$ is the [[Definition:Imaginary Unit|imaginary unit]].	0
:$\dfrac {\map \d {\arctan x} } {\d x} = \dfrac 1 {1 + x^2}$	0
{{begin-eqn}} {{eqn | l = \map \cosh {-x} | r = \frac {e^{-x} + e^{-\paren {-x} } } 2 | c = {{Defof|Hyperbolic Cosine}} }} {{eqn | r = \frac {e^{-x} + e^x} 2 }} {{eqn | r = \frac {e^x + e^{-x} } 2 }} {{eqn | r = \cosh x }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \int \frac {\d x} {p^2 \sin^2 a x + q^2 \cos^2 a x} | r = \int \frac {\sec^2 a x \d x} {p^2 \tan^2 a x + q^2} | c = multiplying by $\dfrac {\sec^2 a x} {\sec^2 a x}$ }} {{eqn | r = \frac 1 a \int \frac {\d t} {p^2 t^2 + q^2} | c = [[Integration by Substitution|substituting]] $t = \tan a x$ }} {{eqn | r = \frac 1 {a p^2} \int \frac {\d t} {t^2 + \paren {\frac q p}^2} }} {{eqn | r = \frac 1 {a p^2} \times \frac p q \map \arctan {\frac {p t} q} + C | c = [[Primitive of Reciprocal of x squared plus a squared/Arctangent Form|Primitive of $\dfrac 1 {x^2 + a^2}$]] }} {{eqn | r = \frac 1 {a p q} \map \arctan {\frac {p \tan a x} q} + C | c = substituting back for $t$ }} {{end-eqn}} {{qed}}	0
Let $\triangle A'B'C'$ be the [[Definition:Polar Triangle|polar triangle]] of $\triangle ABC$. Let the [[Definition:Side of Spherical Triangle|sides]] $a', b', c'$ of $\triangle A'B'C'$ be [[Definition:Opposite (in Triangle)|opposite]] $A', B', C'$ respectively. From [[Spherical Triangle is Polar Triangle of its Polar Triangle]] we have that: :not only is $\triangle A'B'C'$ be the [[Definition:Polar Triangle|polar triangle]] of $\triangle ABC$ :but also $\triangle ABC$ is the [[Definition:Polar Triangle|polar triangle]] of $\triangle A'B'C'$. Let $s' = \dfrac {a' + b' + c'} 2$. We have: {{begin-eqn}} {{eqn | l = \cos \dfrac {A'} 2 | r = \sqrt {\dfrac {\sin s' \, \map \sin {s' - a'} } {\sin b' \sin c'} } | c = [[Cosine of Half Angle for Spherical Triangles]] }} {{eqn | ll= \leadsto | l = \cos \dfrac {\pi - a} 2 | r = \sqrt {\dfrac {\sin s' \, \map \sin {s' - a'} } {\map \sin {\pi - B} \, \map \sin {\pi - C} } } | c = [[Side of Spherical Triangle is Supplement of Angle of Polar Triangle]] }} {{eqn | ll= \leadsto | l = \map \cos {\dfrac \pi 2 - \dfrac a 2} | r = \sqrt {\dfrac {\sin s' \, \map \sin {s' - a'} } {\sin B \sin C} } | c = [[Sine of Supplementary Angle]] }} {{eqn | ll= \leadsto | l = \sin \dfrac a 2 | r = \sqrt {\dfrac {\sin s' \, \map \sin {s' - a'} } {\sin B \sin C} } | c = [[Sine of Complement equals Cosine]] }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = s' - a' | r = \dfrac {\paren {\pi - A} + \paren {\pi - B} + \paren {\pi - C} } 2 - \paren {\pi - A} | c = [[Side of Spherical Triangle is Supplement of Angle of Polar Triangle]] }} {{eqn | r = \dfrac \pi 2 - \dfrac {A + B + C} 2 + A | c = simplifying }} {{eqn | r = \dfrac \pi 2 - \paren {S - A} | c = where $S = \dfrac {A + B + C} 2$ }} {{eqn | ll= \leadsto | l = \map \sin {s' - a'} | r = \map \sin {\dfrac \pi 2 - \paren {S - A} } | c = }} {{eqn | r = \map \cos {S - A} | c = [[Sine of Complement equals Cosine]] }} {{end-eqn}} and: {{begin-eqn}} {{eqn | l = s' | r = \dfrac {\paren {\pi - A} + \paren {\pi - B} + \paren {\pi - C} } 2 | c = [[Side of Spherical Triangle is Supplement of Angle of Polar Triangle]] }} {{eqn | r = \dfrac {3 \pi} 2 - \dfrac {A + B + C} 2 | c = simplifying }} {{eqn | r = \dfrac {3 \pi} 2 - S | c = where $S = \dfrac {A + B + C} 2$ }} {{eqn | ll= \leadsto | l = \sin s' | r = \map \sin {\dfrac {3 \pi} 2 - S} | c = }} {{eqn | ll= \leadsto | l = \sin s' | r = -\map \sin {\dfrac \pi 2 - S} | c = [[Sine of Angle plus Straight Angle]] }} {{eqn | r = -\cos S | c = [[Sine of Complement equals Cosine]] }} {{end-eqn}} The result follows. {{qed}}	0
:$\displaystyle \int \frac {\mathrm d x} {p \sin a x + q \cos a x} = \frac 1 {a \sqrt {p^2 + q^2} } \ln \tan \left\vert{\frac {a x + \arctan \dfrac q p} 2}\right\vert + C$	0
From [[Fourier Series/Logarithm of Sine of x over 0 to Pi|Fourier Series of $\map \ln {\sin x}$ from $0$ to $\pi$]]: :$\displaystyle \map \ln {\sin x} = -\ln 2 - \sum_{n \mathop = 1}^\infty \frac {\cos 2 n x} n$ Then, by [[Parseval's Theorem]]: {{begin-eqn}} {{eqn | l = \frac 2 \pi \int_0^\pi \paren {\map \ln {\sin x} }^2 \rd x | r = 2 \paren {\ln 2}^2 + \sum_{n = 1}^\infty \frac 1 {n^2} }} {{eqn | r = 2 \paren {\ln 2}^2 + \frac {\pi^2} 6 | c = [[Basel Problem]] }} {{end-eqn}} We then have: {{begin-eqn}} {{eqn | l = \int_0^\pi \paren {\map \ln {\sin x} }^2 \rd x | r = \int_0^{\pi/2} \paren {\map \ln {\sin x} }^2 \rd x + \int_{\pi/2}^\pi \paren {\map \ln {\sin x} }^2 \rd x | c = [[Sum of Integrals on Adjacent Intervals for Integrable Functions]] }} {{eqn | r = \int_0^{\pi/2} \paren {\map \ln {\sin x} }^2 \rd x + \int_0^{\pi/2} \paren {\map \ln {\map \sin {\pi - x} } }^2 \rd x }} {{eqn | r = 2 \int_0^{\pi/2} \paren {\map \ln {\sin x} }^2 \rd x | c = [[Sine of Supplementary Angle]] }} {{end-eqn}} So we have: :$\displaystyle \frac 4 \pi \int_0^{\pi/2} \paren {\map \ln {\sin x} }^2 \rd x = 2 \paren {\ln 2}^2 + \frac {\pi^2} 6$ multiplying by $\dfrac \pi 4$ we have: :$\displaystyle \int_0^{\pi/2} \paren {\map \ln {\sin x} }^2 \rd x = \frac \pi 2 \paren {\ln 2}^2 + \frac {\pi^3} {24}$ {{qed}}	0
{{begin-eqn}} {{eqn | l = \sin 45 \degrees | r = \map \sin {30 \degrees + 15 \degrees} | c = }} {{eqn | r = \sin 30 \degrees \cos 15 \degrees + \cos 30 \degrees \sin 15 \degrees | c = [[Sine of Sum]] }} {{eqn | r = \paren {\frac 1 2} \paren {\frac {\sqrt 6 + \sqrt 2} 4} + \paren {\frac {\sqrt 3} 2} \paren {\dfrac {\sqrt 6 - \sqrt 2} 4} | c = [[Sine of 30 Degrees|Sine of $30 \degrees$]], [[Cosine of 15 Degrees|Cosine of $15 \degrees$]], [[Cosine of 30 Degrees|Cosine of $30 \degrees$]], [[Sine of 15 Degrees|Sine of $15 \degrees$]] }} {{eqn | r = \frac 1 8 \paren {\sqrt 6 + \sqrt 2 + \sqrt 3 \paren {\sqrt 6 - \sqrt 2} } | c = }} {{eqn | r = \frac 1 8 \paren {\sqrt 3 \sqrt 2 + \sqrt 2 + \sqrt 3 \sqrt 3 \sqrt 2 - \sqrt 3 \sqrt 2} | c = }} {{eqn | r = \frac 1 8 \paren {\sqrt 2 + 3 \sqrt 2} | c = }} {{eqn | r = \frac 1 8 \paren {4 \sqrt 2} | c = }} {{eqn | r = \frac {\sqrt 2} 2 | c = }} {{end-eqn}} {{qed}}	0
{{TFAE|def = Complex Inverse Tangent}} Let $S$ be the [[Definition:Subset|subset]] of the [[Definition:Complex Plane|complex plane]]: :$S = \C \setminus \set {0 + i, 0 - i}$	0
Fix $a$ and define: :$\displaystyle \map I b = \int_0^\infty e^{-a x^2} \cos b x \rd x$ for all $b \in \R$. Then, we have: {{begin-eqn}} {{eqn | l = \map {I'} b | r = \frac \d {\d b} \paren {\int_0^\infty e^{-a x^2} \cos b x \rd x} }} {{eqn | r = \int_0^\infty \frac \partial {\partial b} \paren {e^{-a x^2} \cos b x} \rd x | c = [[Definite Integral of Partial Derivative]] }} {{eqn | r = -\int_0^\infty \paren {x e^{-a x^2} } \sin b x \rd x | c = [[Derivative of Cosine of a x|Derivative of $\cos a x$]] }} {{eqn | r = -\paren {\intlimits {-\frac 1 {2 a} e^{-a x^2} \sin b x} 0 \infty - b \int_0^\infty \paren {-\frac 1 {2 a} e^{-a x^2} } \cos b x \rd x} | c = [[Integration by Parts]] }} {{end-eqn}} Note that: {{begin-eqn}} {{eqn | l = \size {\frac 1 {2 a} e^{-a x^2} \sin b x} | o = \le | r = \frac 1 {2 a} e^{-a x^2} | c = noting that $\size {\sin x} \le 1$ }} {{eqn | o = \to | r = 0 | c = [[Exponential Tends to Zero and Infinity]] }} {{end-eqn}} So: {{begin-eqn}} {{eqn | l = -\paren {\intlimits {-\frac 1 {2 a} e^{-a x^2} \sin b x} 0 \infty - b \int_0^\infty \paren {-\frac 1 {2 a} e^{-a x^2} } \cos b x \rd x} | r = -\frac b {2 a} \int_0^\infty e^{-a x^2} \cos b x \rd x }} {{eqn | r = -\frac b {2 a} \map I b }} {{end-eqn}} We then have: :$\displaystyle \frac {\map {I'} b} {\map I b} = -\frac b {2 a}$ Integrating, by [[Primitive of Function under its Derivative]] and [[Primitive of Constant]]: :$\displaystyle \ln \size {\map I b} = -\frac {b^2} {4 a} + C$ for some $C \in \R$. {{finish|This obviously only gives us an expression for $\ln \size {\map I b}$, we then need to determine that $\map I b > 0$ which seems nontrivial}} So: :$\displaystyle \map I b = A \map \exp {-\frac {b^2} {4 a} }$ for some $A \in \R$. We have: {{begin-eqn}} {{eqn | l = \map I 0 | r = \int_0^\infty e^{-a x^2} \rd x }} {{eqn | r = \frac 1 2 \sqrt {\frac \pi a} | c = [[Definite Integral to Infinity of Exponential of -a x^2|Definite Integral to Infinity of $e^{-a x^2}$]] }} {{end-eqn}} on the other hand we have: {{begin-eqn}} {{eqn | l = \map I 0 | r = A \map \exp 0 }} {{eqn | r = A | c = [[Exponential of Zero]] }} {{end-eqn}} So we have: $\displaystyle \map I b = \int_0^\infty e^{-a x^2} \cos b x \rd x = \frac 1 2 \sqrt {\frac \pi a} \map \exp {-\frac {b^2} {4 a} }$ for all $b \in \R$ as required. {{qed}}	0
With a view to expressing the [[Definition:Primitive|primitive]] in the form: :$\displaystyle \int u \frac {\mathrm d v}{\mathrm d x} \ \mathrm d x = u v - \int v \frac {\mathrm d u}{\mathrm d x} \ \mathrm d x$ let: {{begin-eqn}} {{eqn | l = u | r = \arcsin \frac x a | c = }} {{eqn | ll= \implies | l = \frac {\mathrm d u} {\mathrm d x} | r = \frac 1 {\sqrt {a^2 - x^2} } | c = [[Derivative of Arcsine of x over a|Derivative of $\arcsin \dfrac x a$]] }} {{end-eqn}} and let: {{begin-eqn}} {{eqn | l = \frac {\mathrm d v} {\mathrm d x} | r = x | c = }} {{eqn | ll= \implies | l = v | r = \frac {x^2} 2 | c = [[Primitive of Power]] }} {{end-eqn}} Then: {{begin-eqn}} {{eqn | l = \int x \arcsin \frac x a \ \mathrm d x | r = \frac {x^2} 2 \arcsin \frac x a - \int \frac {x^2} 2 \left({\frac 1 {\sqrt {a^2 - x^2} } }\right) \ \mathrm d x + C | c = [[Integration by Parts]] }} {{eqn | r = \frac {x^2} 2 \arcsin \frac x a - \frac 1 2 \int \frac {x^2 \ \mathrm d x} {\sqrt {a^2 - x^2} } + C | c = [[Primitive of Constant Multiple of Function]] }} {{eqn | r = \frac {x^2} 2 \arcsin \frac x a - \frac 1 2 \left({\frac {-x \sqrt {a^2 - x^2} } 2 + \frac {a^2} 2 \arcsin \frac x a}\right) + C | c = [[Primitive of x squared over Root of a squared minus x squared|Primitive of $\dfrac {x^2} {\sqrt {a^2 - x^2} }$]] }} {{eqn | r = \left({\frac {x^2} 2 - \frac {a^2} 4}\right) \arcsin \frac x a + \frac {x \sqrt {a^2 - x^2} } 4 + C | c = simplifying }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \sin b \sin c \cos A | r = \cos a - \cos b \cos c | c = [[Spherical Law of Cosines]] }} {{eqn | ll= \leadsto | l = \sin^2 b \sin^2 c \cos^2 A | r = \cos^2 a - 2 \cos a \cos b \cos c + \cos^2 b \cos^2 c | c = }} {{eqn | ll= \leadsto | l = \sin^2 b \sin^2 c \paren {1 - \sin^2 A} | r = \cos^2 a - 2 \cos a \cos b \cos c + \cos^2 b \cos^2 c | c = [[Sum of Squares of Sine and Cosine]] }} {{eqn | ll= \leadsto | l = \sin^2 b \sin^2 c - \sin^2 b \sin^2 c \sin^2 A | r = \cos^2 a - 2 \cos a \cos b \cos c + \cos^2 b \cos^2 c | c = multiplying out }} {{eqn | ll= \leadsto | l = \paren {1 - \cos^2 b} \paren {1 - \cos^2 c} - \sin^2 b \sin^2 c \sin^2 A | r = \cos^2 a - 2 \cos a \cos b \cos c + \cos^2 b \cos^2 c | c = [[Sum of Squares of Sine and Cosine]] }} {{eqn | ll= \leadsto | l = 1 - \cos^2 b - \cos^2 c + \cos^2 b \cos^2 c - \sin^2 b \sin^2 c \sin^2 A | r = \cos^2 a - 2 \cos a \cos b \cos c + \cos^2 b \cos^2 c | c = multiplying out }} {{eqn | n = 1 | ll= \leadsto | l = \sin^2 b \sin^2 c \sin^2 A | r = 1 - \cos^2 a - \cos^2 b - \cos^2 c + 2 \cos a \cos b \cos c | c = rearranging and simplifying }} {{end-eqn}} Let $X \in \R_{>0}$ such that: :$X^2 \sin^2 a \sin^2 b \sin^2 c = 1 - \cos^2 a - \cos^2 b - \cos^2 c + 2 \cos a \cos b \cos c$ Then from $(1)$: {{begin-eqn}} {{eqn | l = \dfrac {X^2 \sin^2 a \sin^2 b \sin^2 c} {\sin^2 b \sin^2 c \sin^2 A} | o = = | r = \dfrac {1 - \cos^2 a - \cos^2 b - \cos^2 c + 2 \cos a \cos b \cos c} {1 - \cos^2 a - \cos^2 b - \cos^2 c + 2 \cos a \cos b \cos c} | c = }} {{eqn | ll= \leadsto | l = X^2 | r = \dfrac {\sin^2 A} {\sin^2 a} | c = }} {{end-eqn}} In a [[Definition:Spherical Triangle|spherical triangle]], all of the [[Definition:Side of Spherical Triangle|sides]] are less than $\pi$ [[Definition:Radian|radians]]. The same applies to the [[Definition:Spherical Angle|angles]]. From [[Shape of Sine Function]]: :$\sin \theta > 0$ for all $0 < \theta < \pi$ Hence the [[Definition:Negative Square Root|negative root]] of $\dfrac {\sin^2 A} {\sin^2 a}$ does not apply, and so: :$X = \dfrac {\sin A} {\sin a}$ Similarly, from applying the [[Spherical Law of Cosines]] to $\cos B$ and $\cos C$: {{begin-eqn}} {{eqn | l = \sin a \sin c \cos B | r = \cos b - \cos a \cos c }} {{eqn | l = \sin a \sin b \cos C | r = \cos c - \cos a \cos b }} {{end-eqn}} we arrive at the same point: {{begin-eqn}} {{eqn | l = X | r = \dfrac {\sin B} {\sin b} }} {{eqn | r = \dfrac {\sin A} {\sin a} }} {{end-eqn}} where: :$X^2 \sin^2 a \sin^2 b \sin^2 c = 1 - \cos^2 a - \cos^2 b - \cos^2 c + 2 \cos a \cos b \cos c$ as before. Hence we have: :$\dfrac {\sin a} {\sin A} = \dfrac {\sin b} {\sin B} = \dfrac {\sin c} {\sin C}$ {{qed}}	0
:$\displaystyle \int \frac {\d x} {\cot a x} = \frac {-\ln \size {\cos a x} } a + C$	0
{{begin-eqn}} {{eqn | l = \paren {\cos 30 \degrees}^2 | r = 1 - \paren {\sin 30 \degrees}^2 | c = [[Sum of Squares of Sine and Cosine]] }} {{eqn | r = 1 - \paren {\frac 1 2}^2 | c = [[Sine of 30 Degrees|Sine of $30 \degrees$]] }} {{eqn | r = \frac 3 4 | c = }} {{eqn | ll= \leadsto | l = \cos 30 \degrees | r = \sqrt {\frac 3 4} | c = }} {{eqn | r = \dfrac {\sqrt 3} 2 | c = [[Definition:Positive Real Number|positive]] because $\cos 30 \degrees$ is in [[Definition:Cosine/Definition from Circle/First Quadrant|Quadrant I]] }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \map \sin {\frac {3 \pi} 2 - \theta} | r = \sin \frac {3 \pi} 2 \cos \theta - \cos \frac {3 \pi} 2 \sin \theta | c = [[Sine of Difference]] }} {{eqn | r = \paren {-1} \times \cos \theta - 0 \times \sin \theta | c = [[Sine of Three Right Angles]] and [[Cosine of Three Right Angles]] }} {{eqn | r = -\cos \theta }} {{end-eqn}} {{qed}}	0
Let $\triangle ABC$ be a [[Definition:Triangle (Geometry)|triangle]] whose sides $a, b, c$ are such that $a$ is opposite $A$, $b$ is opposite $B$ and $c$ is opposite $C$. Then: :$c^2 = a^2 + b^2 - 2 a b \cos C$	0
{{begin-eqn}} {{eqn | l = 1 + \cos x | r = \cos 0 + \cos x | c = [[Cosine of Zero is One]] }} {{eqn | r = 2 \map \cos {\dfrac {0 + x} 2} \map \cos {\dfrac {0 - x} 2} | c = [[Prosthaphaeresis Formula for Cosine plus Cosine]] }} {{eqn | r = 2 \map \cos {\dfrac x 2} \map \cos {\dfrac {-x} 2} | c = simplifying }} {{eqn | r = 2 \map \cos {\dfrac x 2} \map \cos {\dfrac x 2} | c = [[Cosine Function is Even]] }} {{eqn | r = 2 \map {\cos^2} {\frac x 2} | c = simplifying }} {{eqn | ll= \leadsto | l = \frac 1 {1 + \cos x} | r = \frac 1 2 \map {\sec^2} {\frac x 2} | c = {{Defof|Secant Function}} }} {{end-eqn}} {{qed}}	0
With a view to expressing the [[Definition:Primitive|primitive]] in the form: :$\displaystyle \int u \frac {\mathrm d v}{\mathrm d x} \ \mathrm d x = u v - \int v \frac {\mathrm d u}{\mathrm d x} \ \mathrm d x$ let: {{begin-eqn}} {{eqn | l = u | r = \operatorname{arcsec} \frac x a | c = }} {{eqn | ll= \implies | l = \frac {\mathrm d u} {\mathrm d x} | r = \begin{cases} \dfrac a {x \sqrt {x^2 - a^2} } & : 0 < \operatorname{arcsec} \dfrac x a < \dfrac \pi 2 \\ \dfrac {-a} {x \sqrt {x^2 - a^2} } & : \dfrac \pi 2 < \operatorname{arcsec} \dfrac x a < \pi \\ \end{cases} | c = [[Derivative of Arcsecant of x over a|Derivative of $\operatorname{arcsec} \dfrac x a$]] }} {{end-eqn}} and let: {{begin-eqn}} {{eqn | l = \frac {\mathrm d v} {\mathrm d x} | r = \frac 1 {x^2} | c = }} {{eqn | ll= \implies | l = v | r = \frac {-1} x | c = [[Primitive of Power]] }} {{end-eqn}} First let $\operatorname{arcsec} \dfrac x a$ be in the [[Definition:Open Real Interval|interval]] $\left({0 \,.\,.\,\dfrac \pi 2}\right)$. Then: {{begin-eqn}} {{eqn | l = \int \frac {\operatorname{arcsec} \frac x a} {x^2} | r = \frac {-1} x \operatorname{arcsec} \frac x a - \int \frac {-1} x \left({\frac a {x \sqrt {x^2 - a^2} } }\right) \ \mathrm d x + C | c = [[Integration by Parts]] }} {{eqn | r = \frac {-\operatorname{arcsec} \frac x a} x + a \int \frac {\mathrm d x} {x \sqrt {x^2 - a^2} } + C | c = [[Primitive of Constant Multiple of Function]] }} {{eqn | r = \frac {-\operatorname{arcsec} \frac x a} x + a \left({\frac {\sqrt {x^2 - a^2} } {a^2 x} }\right) + C | c = [[Primitive of Reciprocal of x squared by Root of x squared minus a squared|Primitive of $\dfrac 1 {x^2 \sqrt {x^2 - a^2} }$]] }} {{eqn | r = \frac {-\operatorname{arcsec} \frac x a} x + \frac {\sqrt{x^2 - a^2} } {a x} + C | c = simplifying }} {{end-eqn}} Similarly, let $\operatorname{arcsec} \dfrac x a$ be in the [[Definition:Open Real Interval|interval]] $\left({\dfrac \pi 2 \,.\,.\, \pi}\right)$. Then: {{begin-eqn}} {{eqn | l = \int \frac {\operatorname{arcsec} \frac x a} {x^2} | r = \frac {-1} x \operatorname{arcsec} \frac x a - \int \frac {-1} x \left({\frac {-a} {x \sqrt {x^2 - a^2} } }\right) \ \mathrm d x + C | c = [[Integration by Parts]] }} {{eqn | r = \frac {-\operatorname{arcsec} \frac x a} x - a \int \frac {\mathrm d x} {x \sqrt {x^2 - a^2} } + C | c = [[Primitive of Constant Multiple of Function]] }} {{eqn | r = \frac {-\operatorname{arcsec} \frac x a} x - a \left({\frac {\sqrt {x^2 - a^2} } {a^2 x} }\right) + C | c = [[Primitive of Reciprocal of x squared by Root of x squared minus a squared|Primitive of $\dfrac 1 {x^2 \sqrt {x^2 - a^2} }$]] }} {{eqn | r = \frac {-\operatorname{arcsec} \frac x a} x - \frac {\sqrt{x^2 - a^2} } {a x} + C | c = simplifying }} {{end-eqn}} {{qed}}	0
:$\displaystyle \int \frac {\mathrm d x} {\sin a x \cos a x} = \frac 1 a \ln \left\vert{\tan a x}\right\vert + C$	0
For $n \in \Z, \theta \in \R$:	0
{{begin-eqn}} {{eqn | l = \frac 1 {\tan \theta} | r = \cot \theta | c = [[Cotangent is Reciprocal of Tangent]] }} {{eqn | ll= \implies | l = \tan \theta | r = \frac 1 {\cot \theta} }} {{end-eqn}} $\tan \theta$ is not defined when $\cos \theta = 0$, and $\cot \theta$ is not defined when $\sin \theta = 0$. {{qed}}	0
:$\sin 330 \degrees = \sin \dfrac {11 \pi} 6 = -\dfrac 1 2$	0
{{begin-eqn}} {{eqn | l = y | r = \cos^{-1} x | c = }} {{eqn | ll= \leadsto | l = \cos y | r = x | c = {{Defof|Inverse Cosine}} }} {{eqn | ll= \leadsto | l = \map \cos {\pm \, y} | r = x | c = [[Cosine Function is Even]] }} {{eqn | ll= \leadsto | l = \map \cosh {\pm \, i y} | r = x | c = [[Cosine in terms of Hyperbolic Cosine]] }} {{eqn | ll= \leadsto | l = \pm \, i y | r = \cosh^{-1} x | c = {{Defof|Inverse Hyperbolic Cosine}} }} {{eqn | ll= \leadsto | l = y | r = \pm \, i \cosh^{-1} x | c = multiplying both sides by $\pm \, i$ }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \map \arcsin {-x} | r = y | c = }} {{eqn | ll= \leadstoandfrom | l = -x | r = \sin y: | rr = -\frac \pi 2 \le y \le \frac \pi 2 | c = {{Defof|Arcsine}} }} {{eqn | ll= \leadstoandfrom | l = x | r = -\sin y: | rr = -\frac \pi 2 \le y \le \frac \pi 2 | c = }} {{eqn | ll= \leadstoandfrom | l = x | r = \map \sin {-y}: | rr = -\frac \pi 2 \le y \le \frac \pi 2 | c = [[Sine Function is Odd]] }} {{eqn | ll= \leadstoandfrom | l = \arcsin x | r = -y | c = {{Defof|Arcsine}} }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \cos 285^\circ | r = \cos \left({360^\circ - 75^\circ}\right) | c = }} {{eqn | r = \cos 75^\circ | c = [[Cosine of Conjugate Angle]] }} {{eqn | r = \frac {\sqrt 6 - \sqrt 2} 4 | c = [[Cosine of 75 Degrees]] }} {{end-eqn}} {{qed}}	0
Recall [[Euler's Formula]]: :$\exp \paren {i z} = \cos z + i \sin z$ Then, starting from the {{RHS}}: {{begin-eqn}} {{eqn | l = \frac {\exp \paren {i z} + \exp \paren {-i z} } 2 | r = \frac {\cos z + i \sin z + \cos \paren {-z} + i \sin \paren {-z} } 2 }} {{eqn | r = \frac {\cos z + \cos \paren {-z} } 2 | c = [[Sine Function is Odd]] }} {{eqn | r = \frac {2 \cos z} 2 | c = [[Cosine Function is Even]] }} {{eqn | r = \cos z }} {{end-eqn}} {{qed}}	0
Let $\map s x: \R \to \R$, $\map c x: \R \to \R$ be two [[Definition:Real Function|functions]] that satisfy: :$(1): \quad \map {s'} x = \map c x$ :$(2): \quad \map {c'} x = -\map s x$ :$(3): \quad \map s 0 = 0$ :$(4): \quad \map c 0 = 1$ :$(5): \quad \forall x: \map {s^2} x + \map {c^2} x = 1$ where $s'$ denotes the [[Definition:Derivative|derivative]] {{WRT|Differentiation}} $x$. Let $\map f x: \R \to \R$, $\map g x: \R \to \R$ also be two functions that satisfy: :$(1): \quad \map {f'} x = \map g x$ :$(2): \quad \map {g'} x = -\map f x$ :$(3): \quad \map f 0 = 0$ :$(4): \quad \map g 0 = 1$ :$(5): \quad \forall x: \map {f^2} x + \map {g^2} x = 1$ It will be shown that: :$\map f x = \map s x$ and: :$\map g x = \map c x$ Define: :$\map h x = \paren {\map c x - \map g x}^2 + \paren {\map s x - \map f x}^2$ Notice that: :$\paren {\forall x: \map h x = 0} \iff \paren {\forall x: \map c x = \map g x, \map s x = \map f x}$ Then: {{begin-eqn}} {{eqn | l = \map h x | r = \map {c^2} x - 2 \map c x \map g x + \map {g^2} x + \map {s^2} x - 2 \map s x \map f x + \map {f^2} x | c = }} {{eqn | r = 2 - 2 \paren {\map c x \map g x + \map s x \map f x} | c = Property $(5)$ }} {{end-eqn}} By taking $\map {h'} x$: {{begin-eqn}} {{eqn | l = \map {h'} x | r = -2 \paren {\map c x \paren {-\map f x} + \map g x \paren {-\map s x} + \map s x \map g x + \map c x \map f x} | c = Properties $(1)$ and $(2)$ and [[Product Rule]] }} {{eqn | r = 0 | c = }} {{end-eqn}} By [[Zero Derivative implies Constant Function]], $\map h x$ is a constant function: :$\map h x = k$ Also: {{begin-eqn}} {{eqn | l = \map h 0 | r = \paren {1 - 1}^2 + \paren {0 - 0}^2 | c = Properties $(3)$ and $(4)$ }} {{eqn | r = 0 | c = }} {{end-eqn}} Since $\map h x$ is constant, then: : $\forall x: \map h x = 0$ Then: :$\map c x = \map g x$ and: :$\map s x = \map f x$ By: :[[Derivative of Sine Function]] :[[Derivative of Cosine Function]] :[[Sine of Zero is Zero]] :[[Cosine of Zero is One]] :[[Sum of Squares of Sine and Cosine]] both definitions satisfy all these properties. Therefore they must be the same. {{qed}} [[Category:Sine Function]] [[Category:Cosine Function]] [[Category:Definition Equivalences]] da4v7o00c8r9abiknxjy95m7utal6f4	0
:$\cos^{-1} x = \pm \, i \cosh^{-1} x$	0
{{begin-eqn}} {{eqn | l = \int \frac {\mathrm d x} {\sin^m a x \cos^n a x} | r = \int \frac {\sin^{-m} a x \ \mathrm d x} {\cos^n a x} | c = }} {{eqn | r = \frac {\sin^{-m + 1} a x} {a \left({n - 1}\right) \cos^{n - 1} a x} - \frac {-m - n + 2} {n - 1} \int \frac {\sin^{-m} a x} {\cos^{n - 2} a x} \ \mathrm d x + C | c = [[Primitive of Power of Sine of a x over Power of Cosine of a x/Reduction of Power of Cosine|Primitive of $\dfrac {\sin^m a x} {\cos^n a x}$]] }} {{eqn | r = \frac 1 {a \left({n - 1}\right) \sin^{m - 1} a x \cos^{n - 1} a x} + \frac {m + n - 2} {n - 1} \int \frac {\mathrm d x} {\sin^m a x \cos^{n - 2} a x} + C | c = }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l=\left({a \cos x + b \sin x}\right)^2 + \left({b \cos x - a \sin x}\right)^2 | r=a^2 \cos^2 x + 2 a b \cos x \ \sin x + b^2 \sin^2 x }} {{eqn | o= | r=\quad + \ b^2 \cos^2 x - 2 a b \sin x \ \cos x + a^2 \sin^2 x }} {{eqn | r=\left({a^2 + b^2}\right) \left({\sin^2 x + \cos^2 x}\right) }} {{eqn | r=a^2 + b^2 | c=[[Sum of Squares of Sine and Cosine]] }} {{end-eqn}} {{qed}} [[Category:Trigonometric Identities]] p3ven6bi1sv54ounhwlbp1pmwqtvuor	0
{{begin-eqn}} {{eqn | l = \int \frac {\mathrm d x} {\left({1 - \sin a x}\right)^2} | r = \int \left({\frac 1 2 \sec^2 \left({\frac \pi 4 + \frac {a x} 2}\right)}\right)^2 \ \mathrm d x | c = [[Reciprocal of One Minus Sine]] }} {{eqn | r = \frac 1 4 \int \sec^4 \left({\frac \pi 4 + \frac {a x} 2}\right) \ \mathrm d x | c = simplifying }} {{end-eqn}} Let: {{begin-eqn}} {{eqn | l = z | r = \frac \pi 4 + \frac {a x} 2 | c = }} {{eqn | ll= \implies | l = \frac {\mathrm d z} {\mathrm d x} | r = \frac a 2 | c = simplifying }} {{end-eqn}} Thus: {{begin-eqn}} {{eqn | l = \frac 1 4 \int \sec^4 \left({\frac \pi 4 + \frac {a x} 2}\right) \ \mathrm d x | r = \frac 1 4 \int \frac 2 a \sec^4 z \ \mathrm d z | c = [[Integration by Substitution]] }} {{eqn | r = \frac 1 {2 a} \int \sec^4 z \ \mathrm d z | c = simplifying }} {{eqn | r = \frac 1 {2 a} \left({\frac{\sec^2 z \tan z} 3 + \frac 2 3 \int \sec^2 z \ \mathrm d z}\right) + C | c = [[Primitive of Power of Secant of a x|Primitive of $\sec^n a x$]] }} {{eqn | r = \frac 1 {2 a} \left({\frac{\sec^2 z \tan z} 3 + \frac 2 3 \tan z}\right) + C | c = [[Primitive of Square of Secant of a x|Primitive of $\sec^2 a x$]] }} {{eqn | r = \frac 1 {2 a} \left({\frac{\left({1 + \tan^2 z}\right) \tan z} 3 + \frac 2 3 \tan z}\right) + C | c = [[Difference of Squares of Secant and Tangent]] }} {{eqn | r = \frac 1 {2 a} \tan z + \frac 1 {6 a} \tan^3 z + C | c = simplifying }} {{eqn | r = \frac 1 {2 a} \tan \left({\frac \pi 4 + \frac {a x} 2}\right) + \frac 1 {6 a} \tan^3 \left({\frac \pi 4 + \frac {a x} 2}\right) + C | c = substituting for $z$ }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \cos i | r = \cosh 1 | c = [[Hyperbolic Cosine in terms of Cosine]] }} {{eqn | r = \frac {e^1 + e^{-1} } 2 | c = {{Defof|Hyperbolic Cosine}} }} {{eqn | r = \frac e 2 + \frac 1 {2 e} }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l=\cot \left({\frac \pi 2 - \theta}\right) | r=\frac {\cos \left({\frac \pi 2 - \theta}\right)} {\sin \left({\frac \pi 2 - \theta}\right)} | c=[[Cotangent is Cosine divided by Sine]] }} {{eqn | r=\frac {\sin \theta} {\cos \theta} | c=[[Sine and Cosine of Complementary Angles]] }} {{eqn | r=\tan \theta | c=[[Tangent is Sine divided by Cosine]] }} {{end-eqn}} The above is valid only where $\cos \theta \ne 0$, as otherwise $\dfrac {\sin \theta} {\cos \theta}$ is undefined. From [[Cosine of Half-Integer Multiple of Pi]] it follows that this happens when $\theta \ne \left({2 n + 1}\right) \dfrac \pi 2$. {{qed}}	0
The [[Definition:Inverse Secant|arcsecant]] function has a [[Definition:Taylor Series|Taylor Series]] expansion: {{begin-eqn}} {{eqn | l = \operatorname {arcsec} x | r = \frac \pi 2 - \sum_{n \mathop = 0}^\infty \frac {\left({2 n}\right)!} {2^{2 n} \left({n!}\right)^2 \left({2 n + 1}\right) x^{2 n + 1} } | c = }} {{eqn | r = \frac \pi 2 - \left({\frac 1 x + \frac 1 2 \frac 1 {3 x^3} + \frac {1 \times 3} {2 \times 4} \frac 1 {5 x^5} + \frac {1 \times 3 \times 5} {2 \times 4 \times 6} \frac 1 {7 x^7} + \cdots}\right) | c = }} {{end-eqn}} which [[Definition:Convergent Series|converges]] for $\left\lvert{x}\right\rvert \ge 1$.	0
{{begin-eqn}} {{eqn | l = \tan i | r = \frac {\sin i} {\cos i} | c = {{Defof|Complex Tangent Function}} }} {{eqn | r = \frac {\left({\frac e 2 - \frac 1 {2 e} }\right) i} {\frac e 2 + \frac 1 {2 e} } | c = [[Sine of i|Sine of $i$]] and [[Cosine of i|Cosine of $i$]] }} {{eqn | r = \left({\frac {e - \frac 1 e } {e + \frac 1 e} }\right) i | c = multiplying [[Definition:Denominator|denominator]] and [[Definition:Numerator|numerator]] by $2$ }} {{eqn | r = \left({\frac {e^2 - 1} {e^2 + 1} }\right) i | c = multiplying [[Definition:Denominator|denominator]] and [[Definition:Numerator|numerator]] by $e$ }} {{end-eqn}} {{qed}}	0
:$\ds \int \tan a x \rd x = \frac {-\ln \size {\cos a x} } a + C$	0
{{begin-eqn}} {{eqn | l = \map {\frac \d {\d x} } {\cos x} | r = \lim_{h \mathop \to 0} \frac {\map \cos {x + h} - \cos x} h | c = {{Defof|Derivative of Real Function at Point}} }} {{eqn | r = \lim_{h \mathop \to 0} \frac {\cos x \cos h - \sin x \sin h - \cos x} h | c = [[Cosine of Sum]] }} {{eqn | r = \lim_{h \mathop \to 0} \frac {\cos x \cos h - \cos x} h + \lim_{h \mathop \to 0} \frac {-\sin x \sin h} h | c = [[Sum Rule for Limits of Functions]] }} {{eqn | r = \cos x \lim_{h \mathop \to 0} \frac {\cos h - 1} h - \sin x \lim_{h \mathop \to 0} \frac {\sin h} h | c = [[Multiple Rule for Limits of Functions]] }} {{eqn | r = \cos x \times 0 - \sin x \times 1 | c = [[Limit of (Cosine (X) - 1) over X]] and [[Limit of Sine of X over X]] }} {{eqn | r = -\sin x }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \int \tan^2 x \ \mathrm d x | r = \tan x - x + C | c = [[Primitive of Square of Tangent Function|Primitive of $\tan^2 x$]] }} {{eqn | ll= \implies | l = \int \tan^2 a x \ \mathrm d x | r = \frac 1 a \left({\tan a x - a x}\right)+ C | c = [[Primitive of Function of Constant Multiple]] }} {{eqn | r = \frac {\tan a x} a - x + C | c = simplifying }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \int \cot^n a x \ \mathrm d x | r = \int \cot^{n - 2} a x \cot^2 a x \ \mathrm d x | c = }} {{eqn | r = \int \cot^{n - 2} a x \left({\csc^2 a x - 1}\right) \ \mathrm d x | c = [[Difference of Squares of Cosecant and Cotangent]] }} {{eqn | r = \int \cot^{n - 2} a x \csc^2 a x \ \mathrm d x - \int \cot^{n - 2} \ \mathrm d x | c = [[Linear Combination of Integrals]] }} {{eqn | r = \frac {-\cot^{n - 1} a x} {\left({n - 1}\right) a} - \int \cot^{n - 2} \ \mathrm d x + C | c = [[Primitive of Power of Cotangent of a x by Square of Cosecant of a x|Primitive of $\cot^n a x \csc^2 a x$]] }} {{end-eqn}} {{qed}}	0
:$\cosh x - \cosh y = 2 \map \sinh {\dfrac {x + y} 2} \map \sinh {\dfrac {x - y} 2}$	0
By [[Combination Theorem for Limits of Functions]] we can deduce the following. {{begin-eqn}} {{eqn | o = | r = \lim_{n \mathop \to \infty} \size {\frac {\frac {\paren {-1}^n 2^{2 n + 2} \paren {2^{2 n + 2} - 1} B_{2 n + 2} } {\paren {2 n + 2}!} x^{2 n + 1} } {\frac {\paren {-1}^{n - 1} 2^{2 n} \paren {2^{2 n} - 1} B_{2 n} } {\paren {2 n}!} x^{2 n - 1} } } | c = }} {{eqn | r = \lim_{n \mathop \to \infty} \size {\frac {\paren {2^{2 n + 2} - 1} } {\paren {2^{2 n} - 1} } \frac 1 {\paren {2 n + 1} \paren {2 n + 2} } \frac {B_{2 n + 2} } {B_{2 n} } } 4 x^2 | c = }} {{eqn | r = \lim_{n \mathop \to \infty} \size {\frac {2^{2 n + 2} - 1} {2^{2 n} - 1} } \size {\frac 1 {\paren {2 n + 1} \paren {n + 1} } \frac {B_{2 n + 2} } {B_{2 n} } } 2 x^2 | c = }} {{eqn | r = \lim_{n \mathop \to \infty} \size {4 \frac {2^{2 n} } {2^{2 n} - 1} - \frac 1 {2^{2 n} - 1} } \size {\frac 1 {\paren {2 n + 1} \paren {n + 1} } \frac {B_{2 n + 2} } {B_{2 n} } } 2 x^2 | c = }} {{eqn | r = \lim_{n \mathop \to \infty} \size {4 + \frac 4 {2^{2 n} - 1} - \frac 1 {2^{2 n} - 1} } \size {\frac 1 {\paren {2 n + 1} \paren {n + 1} } \frac {B_{2 n + 2} } {B_{2 n} } } 2 x^2 | c = }} {{eqn | r = \lim_{n \mathop \to \infty} \size {\frac 1 {\paren {2 n + 1} \paren {n + 1} } \frac {B_{2 n + 2} } { B_{2 n} } } 8 x^2 | c = }} {{eqn | r = \lim_{n \mathop \to \infty} \size {\frac 1 {\paren {2 n + 1} \paren {n + 1} } \frac {\paren {-1}^{n + 2} 4 \sqrt {\pi \paren {n + 1} } \paren {\frac {n + 1} {\pi e} }^{2 n + 2} } {\paren {-1}^{n + 1} 4 \sqrt {\pi n} \paren {\frac n {\pi e} }^{2 n} } } 8 x^2 | c = [[Asymptotic Formula for Bernoulli Numbers]] }} {{eqn | r = \lim_{n \mathop \to \infty} \size {\frac {\paren {n + 1}^2} {\paren {2 n + 1} \paren {n + 1} } \sqrt {\frac {n + 1} n } \paren {\frac {n + 1} n}^{2 n} } \frac 8 {\pi^2 e^2} x^2 | c = }} {{eqn | r = \lim_{n \mathop \to \infty} \size {\paren {\frac {n + 1} n}^{2 n} } \frac 4 {\pi^2 e^2} x^2 | c = }} {{eqn | r = \lim_{n \mathop \to \infty} \size {\paren {\paren {1 + \frac 1 n}^n}^2} \frac 4 {\pi^2 e^2} x^2 | c = }} {{eqn | r = \frac {4 e^2} {\pi^2 e^2} x^2 | c = {{Defof|Euler's Number/Limit of Sequence|Euler's Number}} }} {{eqn | r = \frac 4 {\pi^2} x^2 | c = }} {{end-eqn}} This is less than $1$ {{iff}}: :$\size x < \dfrac \pi 2$ Hence by the [[Ratio Test]], the series [[Definition:Convergent Series|converges]] for $\size x < \dfrac \pi 2$.	0
:$\displaystyle \int_0^{\pi/2} \frac {\d x} {1 + \tan^m x} = \frac \pi 4$	0
{{begin-eqn}} {{eqn | l = \sin 144 \degrees | r = \sin \paren {180 \degrees - 36 \degrees} | c = }} {{eqn | r = \sin 36 \degrees | c = [[Sine of Supplementary Angle]] }} {{eqn | r = \sqrt {\dfrac 5 8 - \dfrac {\sqrt 5} 8} | c = [[Sine of 36 Degrees|Sine of $36 \degrees$]] }} {{end-eqn}} {{qed}} [[Category:Sine Function]] 4fz8zck3sk6pp1v6vules5zy4kohf9u	0
{{begin-eqn}} {{eqn | n = 1 | l = e^{i x} | r = \cos x + i \sin x | c = [[Euler's Formula/Real Domain|Euler's Formula]] }} {{eqn | n = 2 | l = e^{-i x} | r = \cos x - i \sin x | c = [[Euler's Formula/Real Domain/Corollary|Euler's Formula: Corollary]] }} {{eqn | ll= \leadsto | l = e^{i x} - e^{-i x} | r = \paren {\cos x + i \sin x} - \paren {\cos x - i \sin x} | c = $(1) - (2)$ }} {{eqn | r = 2 i \sin x | c = simplifying }} {{eqn | ll= \leadsto | l = \frac {e^{i x} - e^{-i x} } {2 i} | r = \sin x | c = }} {{end-eqn}} {{qed}}	0
{{begin-eqn}} {{eqn | l = \map \coth {a + b} | r = \frac {\map \cosh {a + b} } {\map \sinh {a + b} } | c = {{Defof|Hyperbolic Cotangent|index = 2}} }} {{eqn | r = \frac {\cosh a \cosh b + \sinh a \sinh b} {\sinh a \cosh b + \cosh a \sinh b} | c = [[Hyperbolic Sine of Sum]] and [[Hyperbolic Cosine of Sum]] }} {{eqn | r = \frac {\frac {\cosh a \cosh b} {\sinh a \sinh b} + 1} {\frac {\cosh b} {\sinh b} + \frac {\cosh a} {\sinh a} } | c = dividing the [[Definition:Numerator|numerator]] and [[Definition:Denominator|denominator]] by $\sinh a \sinh b$ }} {{eqn | r = \frac {\coth a \coth b + 1} {\coth b + \coth a} | c = Definition of [[Definition:Hyperbolic Cotangent/Definition 2|Hyperbolic Cotangent]] }} {{end-eqn}} {{qed}}	0
:[[File:Spherical-Cosine-Formula-Analog.png|500px]] Suppose $c$ is less than $\dfrac \pi 2$. Let $BA$ be [[Definition:Production|produced]] to $D$ so that $BD = \dfrac \pi 2$. Then: :$AD = \dfrac \pi 2 - c$ and: :$\angle CAD = pi - A$ Let $C$ and $D$ be joined by an [[Definition:Arc of Circle|arc]] of a [[Definition:Great Circle|great circle]], denoted $x$. From the [[Definition:Spherical Triangle|triangle]] $\sphericalangle DAC$, using the [[Spherical Law of Cosines]]: {{begin-eqn}} {{eqn | l = \cos x | r = \map \cos {\dfrac \pi 2 - c} \cos b + \map \sin {\dfrac \pi 2 - c} \sin b \, \map \cos {\pi - A} | c = }} {{eqn | r = \sin c \cos b - \cos c \sin b \cos A | c = }} {{end-eqn}} From the [[Definition:Spherical Triangle|triangle]] $\sphericalangle DBC$, using the [[Spherical Law of Cosines]]: {{begin-eqn}} {{eqn | l = \cos x | r = \cos \dfrac \pi 2 \cos a + \sin \pi 2 \sin a \cos B | c = }} {{eqn | r = \sin a \cos B | c = }} {{end-eqn}} Hence: :$\sin a \cos B = \sin c \cos b - \cos c \sin b \cos A$ The case where $c > \dfrac \pi 2$ is worked similarly, but by making $D$ the [[Definition:Point|point]] between $A$ and $B$ such that $BD$ is $\dfrac \pi 2$. {{qed}}	0
